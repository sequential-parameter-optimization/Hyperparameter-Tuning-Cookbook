---
execute:
  cache: false
  eval: true
  echo: true
  warning: false
---

# Using `sklearn` Surrogates in `spotPython` {#sec-sklearn-surrogates}

This chapter explains how different surrogate models from `scikit-learn` can be used as surrogates in `spotPython` optimization runs.

```{python}
import numpy as np
from math import inf
from spotPython.fun.objectivefunctions import analytical
from spotPython.spot import spot
```

## Example: Branin Function with `spotPython`'s Internal Kriging Surrogate

### The Objective Function Branin

* The `spotPython` package provides several classes of objective functions.
* We will use an analytical objective function, i.e., a function that can be described by a (closed) formula.
* Here we will use the Branin function:

        y = a * (x2 - b * x1**2 + c * x1 - r) ** 2 + s * (1 - t) * np.cos(x1) + s,
        where values of a, b, c, r, s and t are: a = 1, b = 5.1 / (4*pi**2),
        c = 5 / pi, r = 6, s = 10 and t = 1 / (8*pi).

* It has three global minima:


        f(x) = 0.397887 at (-pi, 12.275), (pi, 2.275), and (9.42478, 2.475).

```{python}
from spotPython.fun.objectivefunctions import analytical
lower = np.array([-5,-0])
upper = np.array([10,15])
```

```{python}
fun = analytical().fun_branin
```

:::{.callout-note}
#### TensorBoard

Similar to the one-dimensional case, which was introduced in Section @sec-visualizing-tensorboard-01, we can use TensorBoard to monitor the progress of the optimization. We will use the same code, only the prefix is different:

```{python}
from spotPython.utils.file import get_experiment_name
from spotPython.utils.init import fun_control_init
from spotPython.utils.file import get_spot_tensorboard_path

PREFIX = "04"
experiment_name = get_experiment_name(prefix=PREFIX)
print(experiment_name)

fun_control = fun_control_init(
    spot_tensorboard_path=get_spot_tensorboard_path(experiment_name))
```

:::

### Running the surrogate model based optimizer `Spot`:

```{python}
spot_2 = spot.Spot(fun=fun,
                   lower = lower,
                   upper = upper,
                   fun_evals = 20,
                   max_time = inf,
                   seed=123,
                   design_control={"init_size": 10},
                   fun_control=fun_control)
```

```{python}
spot_2.run()
```

### TensorBoard

Now we can start TensorBoard in the background with the following command:

```{raw}
tensorboard --logdir="./runs"
```

We can access the TensorBoard web server with the following URL:

```{raw}
http://localhost:6006/
```

The TensorBoard plot illustrates how `spotPython` can be used as a microscope for the internal mechanisms of the surrogate-based optimization process. Here, one important parameter, the learning rate $\theta$ of the Kriging surrogate is plotted against the number of optimization steps.

![TensorBoard visualization of the spotPython optimization process and the surrogate model.](figures_static/04_tensorboard_01.png){width="100%"}



### Print the Results

```{python}
spot_2.print_results()
```

### Show the Progress and the Surrogate

```{python}
spot_2.plot_progress(log_y=True)
```

```{python}
spot_2.surrogate.plot()
```

## Example: Using Surrogates From scikit-learn

* Default is the `spotPython` (i.e., the internal) `kriging` surrogate.
* It can be called explicitely and passed to `Spot`.

```{python}
from spotPython.build.kriging import Kriging
S_0 = Kriging(name='kriging', seed=123)
```

* Alternatively, models from `scikit-learn` can be selected, e.g., Gaussian Process, RBFs, Regression Trees, etc.

```{python}
# Needed for the sklearn surrogates:
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn import linear_model
from sklearn import tree
import pandas as pd
```

* Here are some additional models that might be useful later:

```{python}
S_Tree = DecisionTreeRegressor(random_state=0)
S_LM = linear_model.LinearRegression()
S_Ridge = linear_model.Ridge()
S_RF = RandomForestRegressor(max_depth=2, random_state=0)
```

### GaussianProcessRegressor as a Surrogate

* To use a Gaussian Process model from `sklearn`, that is similar to `spotPython`'s `Kriging`, we can proceed as follows:

```{python}
kernel = 1 * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2))
S_GP = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)
```

* The scikit-learn GP model `S_GP` is selected for `Spot` as follows: 

    `surrogate = S_GP`

* We can check the kind of surogate model with the command `isinstance`:

```{python}
isinstance(S_GP, GaussianProcessRegressor)
 
```

```{python}
isinstance(S_0, Kriging)
```

* Similar to the `Spot` run with the internal `Kriging` model, we can call the run with the `scikit-learn` surrogate:

```{python}
fun = analytical(seed=123).fun_branin
spot_2_GP = spot.Spot(fun=fun,
                   lower = lower,
                   upper = upper,
                   fun_evals = 20,
                   seed=123,
                   design_control={"init_size": 10},
                   surrogate = S_GP)
spot_2_GP.run()
```

```{python}
spot_2_GP.plot_progress()
```

```{python}
spot_2_GP.print_results()
```

## Example: One-dimensional Sphere Function With `spotPython`'s Kriging

* In this example, we will use an one-dimensional function, which allows us to visualize the optimization process.
  * `show_models= True` is added to the argument list.

```{python}
from spotPython.fun.objectivefunctions import analytical
lower = np.array([-1])
upper = np.array([1])
fun = analytical(seed=123).fun_sphere
```

```{python}
spot_1 = spot.Spot(fun=fun,
                   lower = lower,
                   upper = upper,
                   fun_evals = 10,
                   max_time = inf,
                   seed=123,
                   show_models= True,
                   tolerance_x = np.sqrt(np.spacing(1)),
                   design_control={"init_size": 3},)
spot_1.run()
```

### Results

```{python}
spot_1.print_results()
```

```{python}
spot_1.plot_progress(log_y=True)
```

* The method `plot_model` plots the final surrogate:

```{python}
spot_1.plot_model()
```

## Example: `Sklearn` Model GaussianProcess

* This example visualizes the search process on the `GaussianProcessRegression` surrogate from `sklearn`.
* Therefore `surrogate = S_GP` is added to the argument list.

```{python}
fun = analytical(seed=123).fun_sphere
spot_1_GP = spot.Spot(fun=fun,
                   lower = lower,
                   upper = upper,
                   fun_evals = 10,
                   max_time = inf,
                   seed=123,
                   show_models= True,
                   design_control={"init_size": 3},
                   surrogate = S_GP)
spot_1_GP.run()
```

```{python}
spot_1_GP.print_results()
```

```{python}
spot_1_GP.plot_progress(log_y=True)
```

```{python}
spot_1_GP.plot_model()
```

## Exercises

### `DecisionTreeRegressor`

* Describe the surrogate model.
* Use the surrogate as the model for optimization.

### `RandomForestRegressor`

* Describe the surrogate model.
* Use the surrogate as the model for optimization.

### `linear_model.LinearRegression` 

* Describe the surrogate model.
* Use the surrogate as the model for optimization.

### `linear_model.Ridge`

* Describe the surrogate model.
* Use the surrogate as the model for optimization.

## Exercise 2

* Compare the performance of the five different surrogates on both objective functions:
  
  * `spotPython`'s internal Kriging
  * `DecisionTreeRegressor`
  * `RandomForestRegressor`
  * `linear_model.LinearRegression`
  * `linear_model.Ridge`



