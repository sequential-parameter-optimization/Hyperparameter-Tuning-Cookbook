[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hyperparameter Tuning Cookbook",
    "section": "",
    "text": "Preface",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#book-structure",
    "href": "index.html#book-structure",
    "title": "Hyperparameter Tuning Cookbook",
    "section": "Book Structure",
    "text": "Book Structure\nThis document is structured in three parts. The first part presents an introduction to optimization. The second part describes numerical methods, and the third part presents hyperparameter tuning.\n\n\n\n\n\n\nHyperparameter Tuning Reference\n\n\n\n\nThe open access book Bartz et al. (2022) provides a comprehensive overview of hyperparameter tuning. It can be downloaded from https://link.springer.com/book/10.1007/978-981-19-5170-1.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe .ipynb notebook (Bartz-Beielstein 2023) is updated regularly and reflects updates and changes in the spotpython package. It can be downloaded from https://github.com/sequential-parameter-optimization/spotpython/blob/main/notebooks/14_spot_ray_hpt_torch_cifar10.ipynb.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#software-used-in-this-book",
    "href": "index.html#software-used-in-this-book",
    "title": "Hyperparameter Tuning Cookbook",
    "section": "Software Used in this Book",
    "text": "Software Used in this Book\nscikit-learn is a Python module for machine learning built on top of SciPy and is distributed under the 3-Clause BSD license. The project was started in 2007 by David Cournapeau as a Google Summer of Code project, and since then many volunteers have contributed.\nPyTorch is an optimized tensor library for deep learning using GPUs and CPUs. Lightning is a lightweight PyTorch wrapper for high-performance AI research. It allows you to decouple the research from the engineering.\nRiver is a Python library for online machine learning. It is designed to be used in real-world environments, where not all data is available at once, but streaming in.\nspotpython (“Sequential Parameter Optimization Toolbox in Python”) is the Python version of the well-known hyperparameter tuner SPOT, which has been developed in the R programming environment for statistical analysis for over a decade. The related open-access book is available here: Hyperparameter Tuning for Machine and Deep Learning with R—A Practical Guide.\nspotriver provides an interface between spotpython and River.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#citation",
    "href": "index.html#citation",
    "title": "Hyperparameter Tuning Cookbook",
    "section": "Citation",
    "text": "Citation\nIf this document has been useful to you and you wish to cite it in a scientific publication, please refer to the following paper, which can be found on arXiv: https://arxiv.org/abs/2307.10262.\n@ARTICLE{bart23iArXiv,\n      author = {{Bartz-Beielstein}, Thomas},\n      title = \"{Hyperparameter Tuning Cookbook:\n          A guide for scikit-learn, PyTorch, river, and spotpython}\",\n     journal = {arXiv e-prints},\n    keywords = {Computer Science - Machine Learning,\n      Computer Science - Artificial Intelligence, 90C26, I.2.6, G.1.6},\n         year = 2023,\n        month = jul,\n          eid = {arXiv:2307.10262},\n        pages = {arXiv:2307.10262},\n          doi = {10.48550/arXiv.2307.10262},\narchivePrefix = {arXiv},\n       eprint = {2307.10262},\n primaryClass = {cs.LG},\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2023arXiv230710262B},\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\n}\n\n\n\n\n\n\nBartz, Eva, Thomas Bartz-Beielstein, Martin Zaefferer, and Olaf Mersmann, eds. 2022. Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide. Springer.\n\n\nBartz-Beielstein, Thomas. 2023. “PyTorch Hyperparameter Tuning with SPOT: Comparison with Ray Tuner and Default Hyperparameters on CIFAR10.” https://github.com/sequential-parameter-optimization/spotpython/blob/main/notebooks/14_spot_ray_hpt_torch_cifar10.ipynb.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "001_optimization_surrogate.html",
    "href": "001_optimization_surrogate.html",
    "title": "1  Introduction: Optimization",
    "section": "",
    "text": "1.1 Optimization, Simulation, and Surrogate Modeling",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction: Optimization</span>"
    ]
  },
  {
    "objectID": "001_optimization_surrogate.html#optimization-simulation-and-surrogate-modeling",
    "href": "001_optimization_surrogate.html#optimization-simulation-and-surrogate-modeling",
    "title": "1  Introduction: Optimization",
    "section": "",
    "text": "We will consider the interplay between\n\nmathematical models,\nnumerical approximation,\nsimulation,\ncomputer experiments, and\nfield data\n\nExperimental design will play a key role in our developments, but not in the classical regression and response surface methodology sense\nChallenging real-data/real-simulation examples benefiting from modern surrogate modeling methodology\nWe will consider the classical, response surface methodology (RSM) approach, and then move on to more modern approaches\nAll approaches are based on surrogates",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction: Optimization</span>"
    ]
  },
  {
    "objectID": "001_optimization_surrogate.html#surrogates",
    "href": "001_optimization_surrogate.html#surrogates",
    "title": "1  Introduction: Optimization",
    "section": "1.2 Surrogates",
    "text": "1.2 Surrogates\n\nGathering data is expensive, and sometimes getting exactly the data you want is impossible or unethical\nSurrogate: substitute for the real thing\nIn statistics, draws from predictive equations derived from a fitted model can act as a surrogate for the data-generating mechanism\nBenefits of the surrogate approach:\n\nSurrogate could represent a cheaper way to explore relationships, and entertain “what ifs?”\nSurrogates favor faithful yet pragmatic reproduction of dynamics:\n\ninterpretation,\nestablishing causality, or\nidentification\n\nMany numerical simulators are deterministic, whereas field observations are noisy or have measurement error\n\n\n\n1.2.1 Costs of Simulation\n\nComputer simulations are generally cheaper (but not always!) than physical observation\nSome computer simulations can be just as expensive as field experimentation, but computer modeling is regarded as easier because:\n\nthe experimental apparatus is better understood\nmore aspects may be controlled.\n\n\n\n\n1.2.2 Mathematical Models and Meta-Models\n\nUse of mathematical models leveraging numerical solvers has been commonplace for some time\nMathematical models became more complex, requiring more resources to simulate/solve numerically\nPractitioners increasingly relied on meta-models built off of limited simulation campaigns\n\n\n\n1.2.3 Surrogates = Trained Meta-models\n\nData collected via expensive computer evaluations tuned flexible functional forms that could be used in lieu of further simulation to\n\nsave money or computational resources;\ncope with an inability to perform future runs (expired licenses, off-line or over-impacted supercomputers)\n\nTrained meta-models became known as surrogates\n\n\n\n1.2.4 Computer Experiments\n\nComputer experiment: design, running, and fitting meta-models.\n\nLike an ordinary statistical experiment, except the data are generated by computer codes rather than physical or field observations, or surveys\n\nSurrogate modeling is statistical modeling of computer experiments\n\n\n\n1.2.5 Limits of Mathematical Modeling\n\nMathematical biologists, economists and others had reached the limit of equilibrium-based mathematical modeling with cute closed-form solutions\nStochastic simulations replace deterministic solvers based on FEM, Navier–Stokes or Euler methods\nAgent-based simulation models are used to explore predator-prey (Lotka–Voltera) dynamics, spread of disease, management of inventory or patients in health insurance markets\nConsequence: the distinction between surrogate and statistical model is all but gone\n\n\n\n1.2.6 Example: Why Computer Simulations are Necessary\n\nYou can’t seed a real community with Ebola and watch what happens\nIf there’s (real) field data, say on a historical epidemic, further experimentation may be almost entirely limited to the mathematical and computer modeling side\nClassical statistical methods offer little guidance\n\n\n\n1.2.7 Simulation Requirements\n\nSimulation should\n\nenable rich diagnostics to help criticize that models\nunderstanding its sensitivity to inputs and other configurations\nproviding the ability to optimize and\nrefine both automatically and with expert intervention\n\nAnd it has to do all that while remaining computationally tractable\nOne perspective is so-called response surface methods (RSMs):\na poster child from industrial statistics’ heyday, well before information technology became a dominant industry\n\n\n\n\n\n\n\nGoals\n\n\n\n\nHow to choose models and optimizers for solving real-world problems\nHow to use simulation to understand and improve processes",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction: Optimization</span>"
    ]
  },
  {
    "objectID": "001_optimization_surrogate.html#jupyter-notebook",
    "href": "001_optimization_surrogate.html#jupyter-notebook",
    "title": "1  Introduction: Optimization",
    "section": "1.3 Jupyter Notebook",
    "text": "1.3 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction: Optimization</span>"
    ]
  },
  {
    "objectID": "002_awwe.html",
    "href": "002_awwe.html",
    "title": "2  Aircraft Wing Weight Example",
    "section": "",
    "text": "2.1 AWWE Equation\n\\[ W = 0.036 S_W^{0.758} \\times W_{fw}^{0.0035} \\left( \\frac{A}{\\cos^2 \\Lambda} \\right)^{0.6} \\times  q^{0.006}  \\times \\lambda^{0.04} \\] \\[ \\times \\left( \\frac{100 R_{tc}}{\\cos \\Lambda} \\right)^{-0.3} \\times (N_z W_{dg})^{0.49}\\]",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#awwe-equation",
    "href": "002_awwe.html#awwe-equation",
    "title": "2  Aircraft Wing Weight Example",
    "section": "",
    "text": "Example from Forrester et al. \nUnderstand the weight of an unpainted light aircraft wing as a function of nine design and operational parameters:",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#awwe-parameters-and-equations-part-1",
    "href": "002_awwe.html#awwe-parameters-and-equations-part-1",
    "title": "2  Aircraft Wing Weight Example",
    "section": "2.2 AWWE Parameters and Equations (Part 1)",
    "text": "2.2 AWWE Parameters and Equations (Part 1)\n\n\n\nTable 2.1: Aircraft Wing Weight Parameters\n\n\n\n\n\n\n\n\n\n\n\n\nSymbol\nParameter\nBaseline\nMinimum\nMaximum\n\n\n\n\n\\(S_W\\)\nWing area (\\(ft^2\\))\n174\n150\n200\n\n\n\\(W_{fw}\\)\nWeight of fuel in wing (lb)\n252\n220\n300\n\n\n\\(A\\)\nAspect ratio\n7.52\n6\n10\n\n\n\\(\\Lambda\\)\nQuarter-chord sweep (deg)\n0\n-10\n10\n\n\n\\(q\\)\nDynamic pressure at cruise (\\(lb/ft^2\\))\n34\n16\n45\n\n\n\\(\\lambda\\)\nTaper ratio\n0.672\n0.5\n1\n\n\n\\(R_{tc}\\)\nAerofoil thickness to chord ratio\n0.12\n0.08\n0.18\n\n\n\\(N_z\\)\nUltimate load factor\n3.8\n2.5\n6\n\n\n\\(W_{dg}\\)\nFlight design gross weight (lb)\n2000\n1700\n2500\n\n\n\\(W_p\\)\npaint weight (lb/ft^2)\n0.064\n0.025\n0.08\n\n\n\n\n\n\nThe study begins with a baseline Cessna C172 Skyhawk Aircraft as its reference point. It aims to investigate the impact of wing area and fuel weight on the overall weight of the aircraft. Two crucial parameters in this analysis are the aspect ratio (\\(A\\)), defined as the ratio of the wing’s length to the average chord (thickness of the airfoil), and the taper ratio (\\(\\lambda\\)), which represents the ratio of the maximum to the minimum thickness of the airfoil or the maximum to minimum chord.\nIt’s important to note that the equation used in this context is not a computer simulation but will be treated as one for the purpose of illustration. This approach involves employing a true mathematical equation, even if it’s considered unknown, as a useful tool for generating realistic settings to test the methodology. The functional form of this equation was derived by “calibrating” known physical relationships to curves obtained from existing aircraft data, as referenced in Raymer 2012. Essentially, it acts as a surrogate for actual measurements of aircraft weight.\nExamining the mathematical properties of the AWWE (Aircraft Weight With Wing Area and Fuel Weight Equation), it is evident that the response is highly nonlinear concerning its inputs. While it’s common to apply the logarithm to simplify equations with complex exponents, even when modeling the logarithm, which transforms powers into slope coefficients and products into sums, the response remains nonlinear due to the presence of trigonometric terms. Given the combination of nonlinearity and high input dimension, simple linear and quadratic response surface approximations are likely to be inadequate for this analysis.",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#goals-understanding-and-optimization",
    "href": "002_awwe.html#goals-understanding-and-optimization",
    "title": "2  Aircraft Wing Weight Example",
    "section": "2.3 Goals: Understanding and Optimization",
    "text": "2.3 Goals: Understanding and Optimization\nThe primary goals of this study revolve around understanding and optimization:\n\nUnderstanding: One of the straightforward objectives is to gain a deep understanding of the input-output relationships in this context. Given the global perspective implied by this setting, it becomes evident that a more sophisticated model is almost necessary. At this stage, let’s focus on this specific scenario to establish a clear understanding.\nOptimization: Another application of this analysis could be optimization. There may be an interest in minimizing the weight of the aircraft, but it’s likely that there will be constraints in place. For example, the presence of wings with a nonzero area is essential for the aircraft to be capable of flying. In situations involving (constrained) optimization, a global perspective and, consequently, the use of flexible modeling are vital.\n\nThe provided Python code serves as a genuine computer implementation that “solves” a mathematical model. It accepts arguments encoded in the unit cube, with defaults used to represent baseline settings, as detailed in the table labeled as Table 2.1. To map values from the interval \\([a, b]\\) to the interval \\([0, 1]\\), the following formula can be employed:\n\\[y = f(x) = \\frac{x - a}{b - a}.\\]\nTo reverse this mapping and obtain the original values, the formula \\[g(y) = a + (b - a) y\\] can be used.\n\nimport numpy as np\n\ndef wingwt(Sw=0.48, Wfw=0.4, A=0.38, L=0.5, q=0.62, l=0.344,  Rtc=0.4, Nz=0.37, Wdg=0.38):\n    # put coded inputs back on natural scale\n    Sw = Sw * (200 - 150) + 150 \n    Wfw = Wfw * (300 - 220) + 220 \n    A = A * (10 - 6) + 6 \n    L = (L * (10 - (-10)) - 10) * np.pi/180\n    q = q * (45 - 16) + 16 \n    l = l * (1 - 0.5) + 0.5  \n    Rtc = Rtc * (0.18 - 0.08) + 0.08\n    Nz = Nz * (6 - 2.5) + 2.5\n    Wdg = Wdg*(2500 - 1700) + 1700\n    # calculation on natural scale\n    W = 0.036 * Sw**0.758 * Wfw**0.0035 * (A/np.cos(L)**2)**0.6 * q**0.006 \n    W = W * l**0.04 * (100*Rtc/np.cos(L))**(-0.3) * (Nz*Wdg)**(0.49)\n    return(W)",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#properties-of-the-python-solver",
    "href": "002_awwe.html#properties-of-the-python-solver",
    "title": "2  Aircraft Wing Weight Example",
    "section": "2.4 Properties of the Python “Solver”",
    "text": "2.4 Properties of the Python “Solver”\nThe compute time required by the “wingwt” solver is extremely short and can be considered trivial in terms of computational resources. The approximation error is exceptionally small, effectively approaching machine precision, which indicates the high accuracy of the solver’s results.\nTo simulate time-consuming evaluations, a deliberate delay is introduced by incorporating a sleep(3600) command, which effectively synthesizes a one-hour execution time for a particular evaluation.\nMoving on to the AWWE visualization, plotting in two dimensions is considerably simpler than dealing with nine dimensions. To aid in creating visual representations, the code provided below establishes a grid within the unit square to facilitate the generation of sliced visuals. This involves generating a “meshgrid” as outlined in the code.\n\nimport numpy as np\nx = np.linspace(0, 1, 3)\ny = np.linspace(0, 1, 3)\nX, Y = np.meshgrid(x, y)\nzp = zip(np.ravel(X), np.ravel(Y))\nlist(zp)\n\n[(0.0, 0.0),\n (0.5, 0.0),\n (1.0, 0.0),\n (0.0, 0.5),\n (0.5, 0.5),\n (1.0, 0.5),\n (0.0, 1.0),\n (0.5, 1.0),\n (1.0, 1.0)]\n\n\nThe coding used to transform inputs from natural units is largely a matter of taste, so long as it’s easy to undo for reporting back on original scales\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\n# plt.style.use('seaborn-white')\nimport numpy as np\nx = np.linspace(0, 1, 100)\ny = np.linspace(0, 1, 100)\nX, Y = np.meshgrid(x, y)",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#plot-1-load-factor-n_z-and-aspect-ratio-a",
    "href": "002_awwe.html#plot-1-load-factor-n_z-and-aspect-ratio-a",
    "title": "2  Aircraft Wing Weight Example",
    "section": "2.5 Plot 1: Load Factor (\\(N_z\\)) and Aspect Ratio (\\(A\\))",
    "text": "2.5 Plot 1: Load Factor (\\(N_z\\)) and Aspect Ratio (\\(A\\))\nWe will vary \\(N_z\\) and \\(A\\), with other inputs fixed at their baseline values.\n\nz = wingwt(A = X, Nz = Y)\nfig = plt.figure(figsize=(7., 5.))\nplt.contourf(X, Y, z, 20, cmap='jet')\nplt.xlabel(\"A\")\nplt.ylabel(\"Nz\")\nplt.title(\"Load factor (Nz) vs. Aspect Ratio (A)\")\nplt.colorbar()\nplt.show()\n\n\n\n\n\n\n\n\nContour plots can be refined, e.g., by adding explicit contour lines as shown in the following figure.\n\ncontours = plt.contour(X, Y, z, 4, colors='black')\nplt.clabel(contours, inline=True, fontsize=8)\nplt.xlabel(\"A\")\nplt.ylabel(\"Nz\")\n\nplt.imshow(z, extent=[0, 1, 0, 1], origin='lower',\n           cmap='jet', alpha=0.9)\nplt.colorbar()\n\n\n\n\n\n\n\n\nThe interpretation of the AWWE plot can be summarized as follows:\n\nThe figure displays the weight response as a function of two variables, \\(N_z\\) and \\(A\\), using an image-contour plot.\nThe slight curvature observed in the contours suggests an interaction between these two variables.\nNotably, the range of outputs depicted in the figure, spanning from approximately 160 to 320, nearly encompasses the entire range of outputs observed from various input settings within the full 9-dimensional input space.\nThe plot indicates that aircraft wings tend to be heavier when the aspect ratios (\\(A\\)) are high.\nThis observation aligns with the idea that wings are designed to withstand and accommodate high gravitational forces (\\(g\\)-forces, large \\(N_z\\)), and there may be a compounding effect where larger values of \\(N_z\\) contribute to increased wing weight.\nIt’s plausible that this phenomenon is related to the design considerations of fighter jets, which cannot have the efficient and lightweight glider-like wings typically found in other types of aircraft.",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#plot-2-taper-ratio-and-fuel-weight",
    "href": "002_awwe.html#plot-2-taper-ratio-and-fuel-weight",
    "title": "2  Aircraft Wing Weight Example",
    "section": "2.6 Plot 2: Taper Ratio and Fuel Weight",
    "text": "2.6 Plot 2: Taper Ratio and Fuel Weight\n\nThe same experiment for two other inputs, e.g., taper ratio \\(\\lambda\\) and fuel weight \\(W_{fw}\\)\n\n\nz = wingwt(Wfw = X,  Nz = Y)\ncontours = plt.contour(X, Y, z, 4, colors='black')\nplt.clabel(contours, inline=True, fontsize=8)\nplt.xlabel(\"WfW\")\nplt.ylabel(\"l\")\n\nplt.imshow(z, extent=[0, 1, 0, 1], origin='lower',\n           cmap='jet', alpha=0.9)\nplt.colorbar();\n\n\n\n\n\n\n\n\n\nInterpretation of Taper Ratio (\\(l\\)) and Fuel Weight (\\(W_{fw}\\))\n\nApparently, neither input has much effect on wing weight:\n\nwith \\(\\lambda\\) having a marginally greater effect, covering less than 4 percent of the span of weights observed in the \\(A \\times N_z\\) plane\n\nThere’s no interaction evident in \\(\\lambda \\times W_{fw}\\)",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#the-big-picture-combining-all-variables",
    "href": "002_awwe.html#the-big-picture-combining-all-variables",
    "title": "2  Aircraft Wing Weight Example",
    "section": "2.7 The Big Picture: Combining all Variables",
    "text": "2.7 The Big Picture: Combining all Variables\n\npl = [\"Sw\", \"Wfw\", \"A\", \"L\", \"q\", \"l\",  \"Rtc\", \"Nz\", \"Wdg\"]\n\n\nimport math\n\nZ = []\nZlab = []\nl = len(pl)\n# lc = math.comb(l,2)\nfor i in range(l):\n    for j in range(i+1, l):\n    # for j in range(l):\n        # print(pl[i], pl[j])\n        d = {pl[i]: X, pl[j]: Y}\n        Z.append(wingwt(**d))\n        Zlab.append([pl[i],pl[j]])\n\nNow we can generate all 36 combinations, e.g., our first example is combination p = 19.\n\np = 19\nZlab[p]\n\n['A', 'Nz']\n\n\nTo help interpret outputs from experiments such as this one—to level the playing field when comparing outputs from other pairs of inputs—code below sets up a color palette that can be re-used from one experiment to the next. We use the arguments vmin=180 and vmax =360 to implement comparibility\n\nplt.contourf(X, Y, Z[p], 20, cmap='jet', vmin=180, vmax=360)\nplt.xlabel(Zlab[p][0])\nplt.ylabel(Zlab[p][1])\nplt.colorbar()\n\n\n\n\n\n\n\n\n\nLet’s plot the second example, taper ratio \\(\\lambda\\) and fuel weight \\(W_{fw}\\)\nThis is combination 11:\n\n\np = 11\nZlab[p]\n\n['Wfw', 'l']\n\n\n\nplt.contourf(X, Y, Z[p], 20, cmap='jet', vmin=180, vmax=360)\nplt.xlabel(Zlab[p][0])\nplt.ylabel(Zlab[p][1])\nplt.colorbar()\n\n\n\n\n\n\n\n\n\nUsing a global colormap indicates that these variables have minor effects on the wing weight.\nImportant factors can be detected by visual inspection\nPlotting the Big Picture: we can plot all 36 combinations in one figure.\n\n\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nimport numpy as np\n\nfig = plt.figure(figsize=(20., 20.))\ngrid = ImageGrid(fig, 111,  # similar to subplot(111)\n                 nrows_ncols=(6,6),  # creates 2x2 grid of axes\n                 axes_pad=0.5,  # pad between axes in inch.\n                 share_all=True,\n                 label_mode=\"all\",\n                 ) \ni = 0\nfor ax, im in zip(grid, Z):\n    # Iterating over the grid returns the Axes.\n    ax.set_xlabel(Zlab[i][0])\n    ax.set_ylabel(Zlab[i][1])\n    # ax.set_title(Zlab[i][1] + \" vs. \" + Zlab[i][0])\n    ax.contourf(X, Y, im, 30, cmap = \"jet\",  vmin = 180, vmax = 360)\n    i = i + 1\n       \nplt.show()",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#awwe-landscape",
    "href": "002_awwe.html#awwe-landscape",
    "title": "2  Aircraft Wing Weight Example",
    "section": "2.8 AWWE Landscape",
    "text": "2.8 AWWE Landscape\n\nOur Observations\n\nThe load factor \\(N_z\\), which determines the magnitude of the maximum aerodynamic load on the wing, is very active and involved in interactions with other variables.\n\n\nClassic example: the interaction of \\(N_z\\) with the aspect ratio \\(A\\) indicates a heavy wing for high aspect ratios and large \\(g\\)-forces\nThis is the reaon why highly manoeuvrable fighter jets cannot have very efficient, glider wings)\n\n\nAspect ratio \\(A\\) and airfoil thickness to chord ratio \\(R_{tc}\\) have nonlinear interactions.\nMost important variables:\n\n\nUltimate load factor \\(N_z\\), wing area \\(S_w\\), and flight design gross weight\\(W_{dg}\\).\n\n\nLittle impact: dynamic pressure \\(q\\), taper ratio \\(l\\), and quarter-chord sweep \\(L\\).\n\nExpert Knowledge\n\nAircraft designers know that the overall weight of the aircraft and the wing area must be kept to a minimum\nthe latter usually dictated by constraints such as required stall speed, landing distance, turn rate, etc.",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#summary-of-the-first-experiments",
    "href": "002_awwe.html#summary-of-the-first-experiments",
    "title": "2  Aircraft Wing Weight Example",
    "section": "2.9 Summary of the First Experiments",
    "text": "2.9 Summary of the First Experiments\n\nFirst, we considered two pairs of inputs, out of 36 total pairs\nThen, the “Big Picture”:\n\nFor each pair we evaluated wingwt 10,000 times\n\nDoing the same for all pairs would require 360K evaluations:\n\nnot a reasonable number with a real computer simulation that takes any non-trivial amount of time to evaluate\nOnly 1s per evaluation: \\(&gt;100\\) hours\n\nMany solvers take minutes/hours/days to execute a single run\nAnd: three-way interactions?\nConsequence: a different strategy is needed",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#exercise",
    "href": "002_awwe.html#exercise",
    "title": "2  Aircraft Wing Weight Example",
    "section": "2.10 Exercise",
    "text": "2.10 Exercise\n\n2.10.1 Adding Paint Weight\n\nPaint weight is not considered.\nAdd Paint Weight \\(W_p\\) to formula (the updated formula is shown below) and update the functions and plots in the notebook.\n\n\\[ W = 0.036S_W^{0.758} \\times W_{fw}^{0.0035} \\times \\left( \\frac{A}{\\cos^2 \\Lambda} \\right)^{0.6} \\times q^{0.006} \\times \\lambda^{0.04} \\] \\[ \\times \\left( \\frac{100 R_{tc}}{\\cos \\Lambda} \\right)^{-0.3} \\times (N_z W_{dg})^{0.49} + S_w W_p\\]",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#jupyter-notebook",
    "href": "002_awwe.html#jupyter-notebook",
    "title": "2  Aircraft Wing Weight Example",
    "section": "2.11 Jupyter Notebook",
    "text": "2.11 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "003_scipy_optimize_intro.html",
    "href": "003_scipy_optimize_intro.html",
    "title": "3  Introduction to scipy.optimize",
    "section": "",
    "text": "3.1 Derivative-free Optimization Algorithms\nSection 3.1.1 and Section 3.1.2 present two approaches that do not need gradient information to find the minimum. They use function evaluations to find the minimum.",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to `scipy.optimize`</span>"
    ]
  },
  {
    "objectID": "003_scipy_optimize_intro.html#derivative-free-optimization-algorithms",
    "href": "003_scipy_optimize_intro.html#derivative-free-optimization-algorithms",
    "title": "3  Introduction to scipy.optimize",
    "section": "",
    "text": "3.1.1 Nelder-Mead Simplex Algorithm\nmethod='Nelder-Mead': In the example below, the minimize routine is used with the Nelder-Mead simplex algorithm (selected through the method parameter):\n\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef rosen(x):\n    \"\"\"The Rosenbrock function\"\"\"\n    return sum(100.0 * (x[1:] - x[:-1]**2.0)**2.0 + (1 - x[:-1])**2.0)\n\nx0 = np.array([1.3, 0.7, 0.8, 1.9, 1.2])\nres = minimize(rosen, x0, method='nelder-mead',\n               options={'xatol': 1e-8, 'disp': True})\n\nprint(res.x)\n\nOptimization terminated successfully.\n         Current function value: 0.000000\n         Iterations: 339\n         Function evaluations: 571\n[1. 1. 1. 1. 1.]\n\n\nThe simplex algorithm is probably the simplest way to minimize a well-behaved function. It requires only function evaluations and is a good choice for simple minimization problems. However, because it does not use any gradient evaluations, it may take longer to find the minimum.\n\n\n3.1.2 Powell’s Method\nAnother optimization algorithm that needs only function calls to find the minimum is Powell’s method, which can be selected by setting the method parameter to 'powell' in the minimize function.\nTo demonstrate how to supply additional arguments to an objective function, let’s consider minimizing the Rosenbrock function with an additional scaling factor \\(a\\) and an offset \\(b\\):\n\\[\nf(J, a, b) = \\sum_{i=1}^{N-1} a (x_{i+1} - x_i^2)^2 + (1 - x_i)^2 + b\n\\]\nYou can achieve this using the minimize routine with the example parameters \\(a=0.5\\) and \\(b=1\\):\n\ndef rosen_with_args(x, a, b):\n    \"\"\"The Rosenbrock function with additional arguments\"\"\"\n    return sum(a * (x[1:] - x[:-1]**2.0)**2.0 + (1 - x[:-1])**2.0) + b\n\nx0 = np.array([1.3, 0.7, 0.8, 1.9, 1.2])\nres = minimize(rosen_with_args, x0, method='nelder-mead',\n               args=(0.5, 1.), options={'xatol': 1e-8, 'disp': True})\n\nprint(res.x)\n\nOptimization terminated successfully.\n         Current function value: 1.000000\n         Iterations: 319\n         Function evaluations: 525\n[1.         1.         1.         1.         0.99999999]\n\n\nAs an alternative to using the args parameter of minimize, you can wrap the objective function in a new function that accepts only x. This approach is also useful when it is necessary to pass additional parameters to the objective function as keyword arguments.\n\ndef rosen_with_args(x, a, *, b):  # b is a keyword-only argument\n    return sum(a * (x[1:] - x[:-1]**2.0)**2.0 + (1 - x[:-1])**2.0) + b\n\ndef wrapped_rosen_without_args(x):\n    return rosen_with_args(x, 0.5, b=1.)  # pass in `a` and `b`\n\nx0 = np.array([1.3, 0.7, 0.8, 1.9, 1.2])\nres = minimize(wrapped_rosen_without_args, x0, method='nelder-mead',\n               options={'xatol': 1e-8,})\n\nprint(res.x)\n\n[1.         1.         1.         1.         0.99999999]\n\n\nAnother alternative is to use functools.partial.\n\nfrom functools import partial\n\npartial_rosen = partial(rosen_with_args, a=0.5, b=1.)\nres = minimize(partial_rosen, x0, method='nelder-mead',\n               options={'xatol': 1e-8,})\n\nprint(res.x)\n\n[1.         1.         1.         1.         0.99999999]",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to `scipy.optimize`</span>"
    ]
  },
  {
    "objectID": "003_scipy_optimize_intro.html#gradient-based-optimization-algorithms",
    "href": "003_scipy_optimize_intro.html#gradient-based-optimization-algorithms",
    "title": "3  Introduction to scipy.optimize",
    "section": "3.2 Gradient-based optimization algorithms",
    "text": "3.2 Gradient-based optimization algorithms\n\n3.2.1 An Introductory Example: Broyden-Fletcher-Goldfarb-Shanno Algorithm (BFGS)\nThis section introduces an optimization algorithm that uses gradient information to find the minimum. The Broyden-Fletcher-Goldfarb-Shanno (BFGS) algorithm (selected by setting method='BFGS') is an optimization algorithm that aims to converge quickly to the solution. This algorithm uses the gradient of the objective function. If the gradient is not provided by the user, it is estimated using first-differences. The BFGS method typically requires fewer function calls compared to the simplex algorithm, even when the gradient needs to be estimated.\n\nExample 3.1 (BFGS) To demonstrate the BFGS algorithm, let’s use the Rosenbrock function again. The gradient of the Rosenbrock function is a vector described by the following mathematical expression:\n\\[\\begin{align}\n\\frac{\\partial f}{\\partial x_j} = \\sum_{i=1}^{N} 200(x_i - x_{i-1}^2)(\\delta_{i,j} - 2x_{i-1}\\delta_{i-1,j}) - 2(1 - x_{i-1})\\delta_{i-1,j} \\\\\n= 200(x_j - x_{j-1}^2) - 400x_j(x_{j+1} - x_j^2) - 2(1 - x_j)\n\\end{align}\\]\nThis expression is valid for interior derivatives, but special cases are:\n\\[\n\\frac{\\partial f}{\\partial x_0} = -400x_0(x_1 - x_0^2) - 2(1 - x_0)\n\\]\n\\[\n\\frac{\\partial f}{\\partial x_{N-1}} = 200(x_{N-1} - x_{N-2}^2)\n\\]\nHere’s a Python function that computes this gradient:\n\ndef rosen_der(x):\n    xm = x[1:-1]\n    xm_m1 = x[:-2]\n    xm_p1 = x[2:]\n    der = np.zeros_like(x)\n    der[1:-1] = 200*(xm-xm_m1**2) - 400*(xm_p1 - xm**2)*xm - 2*(1-xm)\n    der[0] = -400*x[0]*(x[1]-x[0]**2) - 2*(1-x[0])\n    der[-1] = 200*(x[-1]-x[-2]**2)\n    return der\n\nYou can specify this gradient information in the minimize function using the jac parameter as illustrated below:\n\nres = minimize(rosen, x0, method='BFGS', jac=rosen_der,\n               options={'disp': True})\n\nprint(res.x)\n\nOptimization terminated successfully.\n         Current function value: 0.000000\n         Iterations: 25\n         Function evaluations: 30\n         Gradient evaluations: 30\n[1.00000004 1.0000001  1.00000021 1.00000044 1.00000092]\n\n\n\n\n\n3.2.2 Background and Basics for Gradient-based Optimization\n\n\n3.2.3 Gradient\nThe gradient \\(\\nabla f(J)\\) for a scalar function \\(f(J)\\) with \\(n\\) different variables is defined by its partial derivatives:\n\\[\n\\nabla f(J) = \\left[ \\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2}, \\ldots, \\frac{\\partial f}{\\partial x_n} \\right]\n\\]\n\n\n3.2.4 Jacobian Matrix\nThe Jacobian matrix \\(J(J)\\) for a vector-valued function \\(F(J) = [f_1(J), f_2(J), \\ldots, f_m(J)]\\) is defined as:\n\\(J(J) = \\begin{bmatrix} \\frac{\\partial f_1}{\\partial x_1} & \\frac{\\partial f_1}{\\partial x_2} & \\ldots & \\frac{\\partial f_1}{\\partial x_n} \\\\ \\frac{\\partial f_2}{\\partial x_1} & \\frac{\\partial f_2}{\\partial x_2} & \\ldots & \\frac{\\partial f_2}{\\partial x_n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\frac{\\partial f_m}{\\partial x_1} & \\frac{\\partial f_m}{\\partial x_2} & \\ldots & \\frac{\\partial f_m}{\\partial x_n} \\end{bmatrix}\\)\nIt consists of the first order partial derivatives and gives therefore an overview about the gradients of a vector valued function.\n\nExample 3.2 (acobian matrix) Consider a vector-valued function \\(f : \\mathbb{R}^2 \\rightarrow \\mathbb{R}^3\\) defined as follows: \\[f(J) = \\begin{bmatrix} x_1^2 + 2x_2 \\\\ 3x_1 - \\sin(x_2) \\\\ e^{x_1 + x_2} \\end{bmatrix}\\]\nLet’s compute the partial derivatives and construct the Jacobian matrix:\n\\(\\frac{\\partial f_1}{\\partial x_1} = 2x_1, \\quad \\frac{\\partial f_1}{\\partial x_2} = 2\\)\n\\(\\frac{\\partial f_2}{\\partial x_1} = 3, \\quad \\frac{\\partial f_2}{\\partial x_2} = -\\cos(x_2)\\)\n\\(\\frac{\\partial f_3}{\\partial x_1} = e^{x_1 + x_2}, \\quad \\frac{\\partial f_3}{\\partial x_2} = e^{x_1 + x_2}\\)\nSo, the Jacobian matrix is:\n\\[J(J) = \\begin{bmatrix} 2x_1 & 2 \\\\ 3 & -\\cos(x_2) \\\\ e^{x_1 + x_2} & e^{x_1 + x_2} \\end{bmatrix}\\]\nThis Jacobian matrix provides information about how small changes in the input variables \\(x_1\\) and \\(x_2\\) affect the corresponding changes in each component of the output vector.\n\n\n\n3.2.5 Hessian Matrix\nThe Hessian matrix \\(H(J)\\) for a scalar function \\(f(J)\\) is defined as:\n\\(H(J) = \\begin{bmatrix} \\frac{\\partial^2 f}{\\partial x_1^2} & \\frac{\\partial^2 f}{\\partial x_1 \\partial x_2} & \\ldots & \\frac{\\partial^2 f}{\\partial x_1 \\partial x_n} \\\\ \\frac{\\partial^2 f}{\\partial x_2 \\partial x_1} & \\frac{\\partial^2 f}{\\partial x_2^2} & \\ldots & \\frac{\\partial^2 f}{\\partial x_2 \\partial x_n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\frac{\\partial^2 f}{\\partial x_n \\partial x_1} & \\frac{\\partial^2 f}{\\partial x_n \\partial x_2} & \\ldots & \\frac{\\partial^2 f}{\\partial x_n^2} \\end{bmatrix}\\)\nSo, the Hessian matrix consists of the second order dervatives of the function. It provides information about the local curvature of the function with respect to changes in the input variables.\n\nExample 3.3 (Hessian matrix) Consider a scalar-valued function: \\[f(J) = x_1^2 + 2x_2^2 + \\sin(x_1   x_2)\\]\nThe Hessian matrix of this scalar-valued function is the matrix of its second-order partial derivatives with respect to the input variables: \\[H(J) = \\begin{bmatrix} \\frac{\\partial^2 f}{\\partial x_1^2} & \\frac{\\partial^2 f}{\\partial x_1 \\partial x_2} \\\\ \\frac{\\partial^2 f}{\\partial x_2 \\partial x_1} & \\frac{\\partial^2 f}{\\partial x_2^2} \\end{bmatrix}\\]\nLet’s compute the second-order partial derivatives and construct the Hessian matrix:\n\\[\\begin{align}\n\\frac{\\partial^2 f}{\\partial x_1^2} &= 2 + \\cos(x_1 x_2) x_2^2\\\\\n\\frac{\\partial^2 f}{\\partial x_1 \\partial x_2} &= 2x_1  x_2 \\cos(x_1 x_2) - \\sin(x_1  x_2)\\\\\n\\frac{\\partial^2 f}{\\partial x_2 \\partial x_1} &= 2x_1  x_2  \\cos(x_1  x_2) - \\sin(x_1  x_2)\\\\\n\\frac{\\partial^2 f}{\\partial x_2^2} &= 4x_2^2 + \\cos(x_1  x_2) x_1^2\n\\end{align}\\]\nSo, the Hessian matrix is:\n\\[H(J) = \\begin{bmatrix} 2 + \\cos(x_1   x_2)   x_2^2 & 2x_1   x_2   \\cos(x_1   x_2) - \\sin(x_1   x_2) \\\\ 2x_1   x_2   \\cos(x_1   x_2) - \\sin(x_1   x_2) & 4x_2^2 + \\cos(x_1   x_2)   x_1^2 \\end{bmatrix}\\]\n\n\n\n3.2.6 Gradient for Optimization\nIn optimization, the goal is to find the minimum or maximum of a function. Gradient-based optimization methods utilize information about the gradient (or derivative) of the function to guide the search for the optimal solution. This is particularly useful when dealing with complex, high-dimensional functions where an exhaustive search is impractical.\nThe gradient descent method can be divided in the following steps:\n\nInitialize: start with an initial guess for the parameters of the function to be optimized.\nCompute Gradient: Calculate the gradient (partial derivatives) of the function with respect to each parameter at the current point. The gradient indicates the direction of the steepest increase in the function.\nUpdate Parameters: Adjust the parameters in the opposite direction of the gradient, scaled by a learning rate. This step aims to move towards the minimum of the function:\n\n\\(x_{k+1} = x_k - \\alpha \\times \\nabla f(x_{k})\\)\n\\(x_{x}\\) is current parameter vector or point in the parameter space.\n\\(\\alpha\\) is the learning rate, a positive scalar that determines the step size in each iteration.\n\\(\\nabla f(x)\\) is the gradient of the objective function.\n\nIterate: Repeat the above steps until convergence or a predefined number of iterations. Convergence is typically determined when the change in the function value or parameters becomes negligible.\n\n\nExample 3.4 (Gradient Descent) We consider a simple quadratic function as an example: \\[\nf(x) = x^2 + 4x + y^2 + 2y + 4.\n\\]\nWe’ll use gradient descent to find the minimum of this function.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# Define the quadratic function\ndef quadratic_function(x, y):\n    return x**2 + 4*x + y**2 + 2*y + 4\n\n# Define the gradient of the quadratic function\ndef gradient_quadratic_function(x, y):\n    grad_x = 2*x + 4\n    grad_y = 2*y + 2\n    return np.array([grad_x, grad_y])\n\n# Gradient Descent for optimization in 2D\ndef gradient_descent(initial_point, learning_rate, num_iterations):\n    points = [np.array(initial_point)]\n    for _ in range(num_iterations):\n        current_point = points[-1]\n        gradient = gradient_quadratic_function(*current_point)\n        new_point = current_point - learning_rate * gradient\n        points.append(new_point)\n    return points\n\n# Visualization of optimization process with 3D surface and consistent arrow sizes\ndef plot_optimization_process_3d_consistent_arrows(points):\n    fig = plt.figure(figsize=(10, 8))\n    ax = fig.add_subplot(111, projection='3d')\n\n    x_vals = np.linspace(-10, 2, 100)\n    y_vals = np.linspace(-10, 2, 100)\n    X, Y = np.meshgrid(x_vals, y_vals)\n    Z = quadratic_function(X, Y)\n\n    ax.plot_surface(X, Y, Z, cmap='viridis', alpha=0.6)\n    ax.scatter(*zip(*points), [quadratic_function(*p) for p in points], c='red', label='Optimization Trajectory')\n\n    for i in range(len(points) - 1):  \n        x, y = points[i]\n        dx, dy = points[i + 1] - points[i]\n        dz = quadratic_function(*(points[i + 1])) - quadratic_function(*points[i])\n        gradient_length = 0.5\n\n        ax.quiver(x, y, quadratic_function(*points[i]), dx, dy, dz, color='blue', length=gradient_length, normalize=False, arrow_length_ratio=0.1)\n\n    ax.set_title('Gradient-Based Optimization with 2D Quadratic Function')\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    ax.set_zlabel('f(x, y)')\n    ax.legend()\n    plt.show()\n\n# Initial guess and parameters\ninitial_guess = [-9.0, -9.0]\nlearning_rate = 0.2\nnum_iterations = 10\n\n# Run gradient descent in 2D and visualize the optimization process with 3D surface and consistent arrow sizes\ntrajectory = gradient_descent(initial_guess, learning_rate, num_iterations)\nplot_optimization_process_3d_consistent_arrows(trajectory)\n\n\n\n\n\n\n\n\n\n\n\n3.2.7 Newton Method\nInitialization: Start with an initial guess for the optimal solution: \\(x_0\\).\nIteration: Repeat the following three steps until convergence or a predefined stopping criterion is met:\n\nCalculate the gradient (\\(\\nabla\\)) and the Hessian matrix (\\(\\nabla^2\\)) of the objective function at the current point: \\[\\nabla f(x_k) \\quad \\text{and} \\quad \\nabla^2 f(x_k)\\]\nUpdate the current solution using the Newton-Raphson update formula \\[x_{k+1} = x_k - [\\nabla^2 f(x_k)]^{-1} \\nabla f(x_k),\\] where\n* $\\nabla f(x_k)$ is the gradient (first derivative) of the objective function with respect to the variable $x$, evaluated at the current solution $x_k$.\n\n\\(\\nabla^2 f(x_k)\\): The Hessian matrix (second derivative) of the objective function with respect to \\(x\\), evaluated at the current solution \\(x_k\\).\n\\(x_k\\): The current solution or point in the optimization process.\n\\(\\nabla^2 f(x_k)]^{-1}\\): The inverse of the Hessian matrix at the current point, representing the approximation of the curvature of the objective function.\n\\(x_{k+1}\\): The updated solution or point after applying the Newton-Raphson update.\n\nCheck for convergence.\n\n\nExample 3.5 (Newton Method) We want to optimize the Rosenbrock function and use the Hessian and the Jacobian (which is equal to the gradient vector for scalar objective function) to the minimize function.\n\ndef rosenbrock(x):\n    return 100 * (x[1] - x[0]**2)**2 + (1 - x[0])**2\n\ndef rosenbrock_gradient(x):\n    dfdx0 = -400 * x[0] * (x[1] - x[0]**2) - 2 * (1 - x[0])\n    dfdx1 = 200 * (x[1] - x[0]**2)\n    return np.array([dfdx0, dfdx1])\n\ndef rosenbrock_hessian(x):\n    d2fdx0 = 1200 * x[0]**2 - 400 * x[1] + 2\n    d2fdx1 = -400 * x[0]\n    return np.array([[d2fdx0, d2fdx1], [d2fdx1, 200]])\n\ndef classical_newton_optimization_2d(initial_guess, tol=1e-6, max_iter=100):\n    x = initial_guess.copy()\n\n    for i in range(max_iter):\n        gradient = rosenbrock_gradient(x)\n        hessian = rosenbrock_hessian(x)\n\n        # Solve the linear system H * d = -g for d\n        d = np.linalg.solve(hessian, -gradient)\n\n        # Update x\n        x += d\n\n        # Check for convergence\n        if np.linalg.norm(gradient, ord=np.inf) &lt; tol:\n            break\n\n    return x\n\n# Initial guess\ninitial_guess_2d = np.array([0.0, 0.0])\n\n# Run classical Newton optimization for the 2D Rosenbrock function\nresult_2d = classical_newton_optimization_2d(initial_guess_2d)\n\n# Print the result\nprint(\"Optimal solution:\", result_2d)\nprint(\"Objective value:\", rosenbrock(result_2d))\n\nOptimal solution: [1. 1.]\nObjective value: 0.0\n\n\n\n\n\n3.2.8 BFGS-Algorithm\nBFGS is an optimization algorithm designed for unconstrained optimization problems. It belongs to the class of quasi-Newton methods and is known for its efficiency in finding the minimum of a smooth, unconstrained objective function.\n\n\n3.2.9 Procedure:\n\nInitialization:\n\nStart with an initial guess for the parameters of the objective function.\nInitialize an approximation of the Hessian matrix (inverse) denoted by \\(H\\).\n\n\nIterative Update:\n\nAt each iteration, compute the gradient vector at the current point.\nUpdate the parameters using the BFGS update formula, which involves the inverse Hessian matrix approximation, the gradient, and the difference in parameter vectors between successive iterations: \\[x_{k+1} = x_k - H_k^{-1} \\nabla f(x_k).\\]\nUpdate the inverse Hessian approximation using the BFGS update formula for the inverse Hessian. \\[H_{k+1} = H_k + \\frac{\\Delta x_k \\Delta x_k^T}{\\Delta x_k^T \\Delta g_k} - \\frac{H_k g_k g_k^T H_k}{g_k^T H_k g_k},\\] where:\n\\(x_k\\) and \\(x_{k+1}\\) are the parameter vectors at the current and updated iterations, respectively.\n\\(\\nabla f(x_k)\\) is the gradient vector at the current iteration.\n\\(\\Delta x_k = x_{k+1} - x_k\\) is the change in parameter vectors.\n\\(\\Delta g_k = \\nabla f(x_{k+1}) - \\nabla f(x_k)\\) is the change in gradient vectors.\n\nConvergence:\n\nRepeat the iterative update until the optimization converges. Convergence is typically determined by reaching a sufficiently low gradient or parameter change.\n\n\n\nExample 3.6 (BFGS for Rosenbrock)  \n\nimport numpy as np\nfrom scipy.optimize import minimize\n\n# Define the 2D Rosenbrock function\ndef rosenbrock(x):\n    return (1 - x[0])**2 + 100 * (x[1] - x[0]**2)**2\n\n# Initial guess\ninitial_guess = np.array([0.0, 0.0])\n\n# Minimize the Rosenbrock function using BFGS\nminimize(rosenbrock, initial_guess, method='BFGS')\n\n  message: Optimization terminated successfully.\n  success: True\n   status: 0\n      fun: 2.843987518235081e-11\n        x: [ 1.000e+00  1.000e+00]\n      nit: 19\n      jac: [ 3.987e-06 -2.844e-06]\n hess_inv: [[ 4.948e-01  9.896e-01]\n            [ 9.896e-01  1.984e+00]]\n     nfev: 72\n     njev: 24\n\n\n\n\n\n3.2.10 Visualization BFGS for Rosenbrock\nA visualization of the BFGS search process on Rosenbrock’s function can be found here: https://upload.wikimedia.org/wikipedia/de/f/ff/Rosenbrock-bfgs-animation.gif\n\n\n\n\n\n\n\nTasks\n\n\n\n\nIn which situations is it possible to use algorithms like BFGS, but not the classical Newton method?\nInvestigate the Newton-CG method\nUse an objective function of your choice and apply Newton-CG\nCompare the Newton-CG method with the BFGS. What are the similarities and differences between the two algorithms?",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to `scipy.optimize`</span>"
    ]
  },
  {
    "objectID": "003_scipy_optimize_intro.html#gradient--and-hessian-based-optimization-algorithms",
    "href": "003_scipy_optimize_intro.html#gradient--and-hessian-based-optimization-algorithms",
    "title": "3  Introduction to scipy.optimize",
    "section": "3.3 Gradient- and Hessian-based Optimization Algorithms",
    "text": "3.3 Gradient- and Hessian-based Optimization Algorithms\nSection 3.3.1 presents an optimization algorithm that uses gradient and Hessian information to find the minimum. Section 3.3.2 presents an optimization algorithm that uses gradient and Hessian information to find the minimum. Section 3.3.3 presents an optimization algorithm that uses gradient and Hessian information to find the minimum.\nThe methods Newton-CG, trust-ncg and trust-krylov are suitable for dealing with large-scale problems (problems with thousands of variables). That is because the conjugate gradient algorithm approximately solve the trust-region subproblem (or invert the Hessian) by iterations without the explicit Hessian factorization. Since only the product of the Hessian with an arbitrary vector is needed, the algorithm is specially suited for dealing with sparse Hessians, allowing low storage requirements and significant time savings for those sparse problems.\n\n3.3.1 Newton-Conjugate-Gradient Algorithm\nNewton-Conjugate Gradient algorithm is a modified Newton’s method and uses a conjugate gradient algorithm to (approximately) invert the local Hessian.\n\n\n3.3.2 Trust-Region Newton-Conjugate-Gradient Algorithm\n\n\n3.3.3 Trust-Region Truncated Generalized Lanczos / Conjugate Gradient Algorithm",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to `scipy.optimize`</span>"
    ]
  },
  {
    "objectID": "003_scipy_optimize_intro.html#global-optimization",
    "href": "003_scipy_optimize_intro.html#global-optimization",
    "title": "3  Introduction to scipy.optimize",
    "section": "3.4 Global Optimization",
    "text": "3.4 Global Optimization\nGlobal optimization aims to find the global minimum of a function within given bounds, in the presence of potentially many local minima. Typically, global minimizers efficiently search the parameter space, while using a local minimizer (e.g., minimize) under the hood.\n\n3.4.1 Local vs Global Optimization\n\n3.4.1.1 Local Optimizater:\n\nSeeks the optimum in a specific region of the search space\nTends to exploit the local environment, to find solutions in the immediate area\nHighly sensitive to initial conditions; may converge to different local optima based on the starting point\nOften computationally efficient for low-dimensional problems but may struggle with high-dimensional or complex search spaces\nCommonly used in situations where the objective is to refine and improve existing solutions\n\n\n\n3.4.1.2 Global Optimizer:\n\nExplores the entire search space to find the global optimum\nEmphasize exploration over exploitation, aiming to search broadly and avoid premature convergence to local optima\nAim to mitigate the risk of premature convergence to local optima by employing strategies for global exploration\nLess sensitive to initial conditions, designed to navigate diverse regions of the search space\nEquipped to handle high-dimensional and complex problems, though computational demands may vary depending on the specific algorithm\nPreferred for applications where a comprehensive search of the solution space is crucial, such as in parameter tuning, machine learning, and complex engineering design\n\n\n\n\n\n3.4.2 Global Optimizers in SciPy\nSciPy contains a number of good global optimizers. Here, we’ll use those on the same objective function, namely the (aptly named) eggholder function:\n\ndef eggholder(x):\n    return (-(x[1] + 47) * np.sin(np.sqrt(abs(x[0]/2 + (x[1]  + 47))))\n            -x[0] * np.sin(np.sqrt(abs(x[0] - (x[1]  + 47)))))\n\nbounds = [(-512, 512), (-512, 512)]\n\n\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\nx = np.arange(-512, 513)\ny = np.arange(-512, 513)\nxgrid, ygrid = np.meshgrid(x, y)\nxy = np.stack([xgrid, ygrid])\n\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.view_init(45, -45)\nax.plot_surface(xgrid, ygrid, eggholder(xy), cmap='terrain')\nax.set_xlabel('x')\nax.set_ylabel('y')\nax.set_zlabel('eggholder(x, y)')\nplt.show()\n\n\n\n\n\n\n\n\nWe now use the global optimizers to obtain the minimum and the function value at the minimum. We’ll store the results in a dictionary so we can compare different optimization results later.\n\nfrom scipy import optimize\nresults = dict()\nresults['shgo'] = optimize.shgo(eggholder, bounds)\nresults['shgo']\n\n message: Optimization terminated successfully.\n success: True\n     fun: -935.3379515605789\n    funl: [-9.353e+02]\n       x: [ 4.395e+02  4.540e+02]\n      xl: [[ 4.395e+02  4.540e+02]]\n     nit: 1\n    nfev: 45\n   nlfev: 40\n   nljev: 10\n   nlhev: 0\n\n\n\nresults['DA'] = optimize.dual_annealing(eggholder, bounds)\nresults['DA']\n\n message: ['Maximum number of iteration reached']\n success: True\n  status: 0\n     fun: -894.5789003890818\n       x: [-4.657e+02  3.857e+02]\n     nit: 1000\n    nfev: 4049\n    njev: 16\n    nhev: 0\n\n\nAll optimizers return an OptimizeResult, which in addition to the solution contains information on the number of function evaluations, whether the optimization was successful, and more. For brevity, we won’t show the full output of the other optimizers:\n\nresults['DE'] = optimize.differential_evolution(eggholder, bounds)\nresults['DE']\n\n             message: Optimization terminated successfully.\n             success: True\n                 fun: -894.5789003903757\n                   x: [-4.657e+02  3.857e+02]\n                 nit: 22\n                nfev: 708\n          population: [[-4.641e+02  3.857e+02]\n                       [-4.652e+02  3.820e+02]\n                       ...\n                       [-4.585e+02  3.876e+02]\n                       [-4.707e+02  3.882e+02]]\n population_energies: [-8.946e+02 -8.902e+02 ... -8.847e+02 -8.909e+02]\n                 jac: [-1.137e-05  0.000e+00]\n\n\nshgo has a second method, which returns all local minima rather than only what it thinks is the global minimum:\n\nresults['shgo_sobol'] = optimize.shgo(eggholder, bounds, n=200, iters=5,\n                                      sampling_method='sobol')\nresults['shgo_sobol']\n\n message: Optimization terminated successfully.\n success: True\n     fun: -959.640662720831\n    funl: [-9.596e+02 -9.353e+02 ... -6.591e+01 -6.387e+01]\n       x: [ 5.120e+02  4.042e+02]\n      xl: [[ 5.120e+02  4.042e+02]\n           [ 4.395e+02  4.540e+02]\n           ...\n           [ 3.165e+01 -8.523e+01]\n           [ 5.865e+01 -5.441e+01]]\n     nit: 5\n    nfev: 3529\n   nlfev: 2327\n   nljev: 634\n   nlhev: 0\n\n\nWe’ll now plot all found minima on a heatmap of the function:\n\nfig = plt.figure()\nax = fig.add_subplot(111)\nim = ax.imshow(eggholder(xy), interpolation='bilinear', origin='lower',\n               cmap='gray')\nax.set_xlabel('x')\nax.set_ylabel('y')\n\ndef plot_point(res, marker='o', color=None):\n    ax.plot(512+res.x[0], 512+res.x[1], marker=marker, color=color, ms=10)\n\nplot_point(results['DE'], color='c')  # differential_evolution - cyan\nplot_point(results['DA'], color='w')  # dual_annealing.        - white\n\n# SHGO produces multiple minima, plot them all (with a smaller marker size)\nplot_point(results['shgo'], color='r', marker='+')\nplot_point(results['shgo_sobol'], color='r', marker='x')\nfor i in range(results['shgo_sobol'].xl.shape[0]):\n    ax.plot(512 + results['shgo_sobol'].xl[i, 0],\n            512 + results['shgo_sobol'].xl[i, 1],\n            'ro', ms=2)\n\nax.set_xlim([-4, 514*2])\nax.set_ylim([-4, 514*2])\nplt.show()\n\n\n\n\n\n\n\n\n\n\n3.4.3 Dual Annealing Optimization\nThis function implements the Dual-Annealing optimization, which is a variant of the famous simulated annealing optimization.\nSimulated Annealing is a probabilistic optimization algorithm inspired by the annealing process in metallurgy. The algorithm is designed to find a good or optimal global solution to a problem by exploring the solution space in a controlled and adaptive manner.\n\n\n\n\n\n\nAnnealing in Metallurgy\n\n\n\nSimulated Annealing draws inspiration from the physical process of annealing in metallurgy. Just as metals are gradually cooled to achieve a more stable state, Simulated Annealing uses a similar approach to explore solution spaces in the digital world.\n\n\nHeating Phase: In metallurgy, a metal is initially heated to a high temperature. At this elevated temperature, the atoms or molecules in the material become more energetic and chaotic, allowing the material to overcome energy barriers and defects.\nAnalogy Simulated Annealing (Exploration Phase): In Simulated Annealing, the algorithm starts with a high “temperature,” which encourages exploration of the solution space. At this stage, the algorithm is more likely to accept solutions that are worse than the current one, allowing it to escape local optima and explore a broader region of the solution space.\nCooling Phase: The material is then gradually cooled at a controlled rate. As the temperature decreases, the atoms or molecules start to settle into more ordered and stable arrangements. The slow cooling rate is crucial to avoid the formation of defects and to ensure the material reaches a well-organized state.\nAnalogy Simulated Annealing (Exploitation Phase): As the algorithm progresses, the temperature is gradually reduced over time according to a cooling schedule. This reduction simulates the cooling process in metallurgy. With lower temperatures, the algorithm becomes more selective and tends to accept only better solutions, focusing on refining and exploiting the promising regions discovered during the exploration phase.\n\n3.4.3.1 Key Concepts\nTemperature: The temperature is a parameter that controls the likelihood of accepting worse solutions. We start with a high temperature, allowing the algorithm to explore the solution space braodly. The temperature decreases with the iterations of the algorithm.\nCooling Schedule: The temperature parameter is reduced according to this schedule. The analogy to the annealing of metals: a slower cooling rate allows the material to reach a more stable state.\nNeighborhood Exploration: At each iteration, the algorithm explores the neighborhood of the current solution. The neighborhood is defined by small perturbations or changes to the current solution.\nAcceptance Probability: The algorithm evaluates the objective function for the new solution in the neighborhood. If the new solution is better, it is accepted. If the new solution is worse, it may still be accepted with a certain probability. This probability is determined by both the difference in objective function values and the current temperature.\nFor minimization: If: \\[\nf(x_{t}) &gt; f(x_{t+1})\n\\] Then: \\[\nP(accept\\_new\\_point) = 1\n\\]\nIf: \\[\nf(x_{t}) &lt; f(x_{t+1})\n\\] Then: \\[\nP(accept\\_new\\_point) = e^{-(\\frac{f(x_{t+1}) - f(x_{t})}{Tt})}\n\\]\nTermination Criterion: The algorithm continues iterations until a termination condition is met. This could be a fixed number of iterations, reaching a specific temperature threshold, or achieving a satisfactory solution.\n\n\n3.4.3.2 Steps\n1. Initialization: Set an initial temperature (\\(T_{0}\\)) and an initial solution (\\(f(x_{0})\\)). The temperature is typically set high initially to encourage exploration.\n2. Generate a Neighbor: Perturb the current solution to generate a neighboring solution. The perturbation can be random or follow a specific strategy.\n3. Evaluate the Neighbor: Evaluate the objective function for the new solution in the neighborhood.\n4. Accept or Reject the Neighbor: + If the new solution is better (lower cost for minimization problems or higher for maximization problems), accept it as the new current solution. + If the new solution is worse, accept it with a probability determined by an acceptance probability function as mentioned above. The probability is influenced by the difference in objective function values and the current temperature.\n5. Cooling: Reduce the temperature according to a cooling schedule. The cooling schedule defines how fast the temperature decreases over time. Common cooling schedules include exponential or linear decay.\n6. Termination Criterion: Repeat the iterations (2-5) until a termination condition is met. This could be a fixed number of iterations, reaching a specific temperature threshold, or achieving a satisfactory solution.\n\n\n3.4.3.3 Scipy Implementation of the Dual Annealing Algorithm\nIn Scipy, we utilize the Dual Annealing optimizer, an extension of the simulated annealing algorithm that is versatile for both discrete and continuous problems.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import dual_annealing\n\ndef rastrigin_function(x):\n    return 20 + x[0]**2 - 10 * np.cos(2 * np.pi * x[0]) + x[1]**2 - 10 * np.cos(2 * np.pi * x[1])\n\n# Define the Rastrigin function for visualization\ndef rastrigin_visualization(x, y):\n    return 20 + x**2 - 10 * np.cos(2 * np.pi * x) + y**2 - 10 * np.cos(2 * np.pi * y)\n\n# Create a meshgrid for visualization\nx_vals = np.linspace(-10, 10, 100)\ny_vals = np.linspace(-10, 10, 100)\nx_mesh, y_mesh = np.meshgrid(x_vals, y_vals)\nz_mesh = rastrigin_visualization(x_mesh, y_mesh)\n\n# Visualize the Rastrigin function\nplt.figure(figsize=(10, 8))\ncontour = plt.contour(x_mesh, y_mesh, z_mesh, levels=50, cmap='viridis')\nplt.colorbar(contour, label='Rastrigin Function Value')\nplt.title('Visualization of the 2D Rastrigin Function')\n\n# Optimize the Rastrigin function using dual annealing\nresult = dual_annealing(func = rastrigin_function,\n                        x0=[5.0,3.0],                       #Initial Guess\n                        bounds= [(-10, 10), (-10, 10)],\n                        initial_temp = 5230,                #Intial Value for temperature\n                        restart_temp_ratio = 2e-05,         #Temperature schedule\n                        seed=42)\n\n# Plot the optimized point\noptimal_x, optimal_y = result.x\nplt.plot(optimal_x, optimal_y, 'ro', label='Optimal Point')\n\n# Set labels and legend\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.legend()\n\n# Show the plot\nplt.show()\n\n# Display the optimization result\nprint(\"Optimal parameters:\", result.x)\nprint(\"Minimum value of the Rastrigin function:\", result.fun)\n\n\n\n\n\n\n\n\nOptimal parameters: [-4.60133247e-09 -4.31928660e-09]\nMinimum value of the Rastrigin function: 7.105427357601002e-15\n\n\n\nresult\n\n message: ['Maximum number of iteration reached']\n success: True\n  status: 0\n     fun: 7.105427357601002e-15\n       x: [-4.601e-09 -4.319e-09]\n     nit: 1000\n    nfev: 4088\n    njev: 29\n    nhev: 0\n\n\n\n\n3.4.3.4 Example of Comparison Table:\n\n\n\n\n\n\n\n\n\n\n\n\n\nFunction\nAlgorithm\nBest Objective Function Value\nNumber of Iterations\nNumber of Evaluations\nLocal/Global Optimizer\nGradient-Based/Free Algorithm\nOther Comments\n\n\n\n\nRastrigin\nAlgorithm1\n1.23\n1000\n5000\nGlobal\nFree\n?\n\n\nRastrigin\nAlgorithm2\n0.95\n800\n4000\nLocal\nGradient-Based\n?\n\n\nRastrigin\nAlgorithm3\n1.45\n1200\n6000\nGlobal\nFree\n?\n\n\nRosenbrock\nAlgorithm1\n2.56\n1500\n7500\nLocal\nGradient-Based\n?\n\n\nRosenbrock\nAlgorithm2\n2.10\n1200\n6000\nGlobal\nFree\n?\n\n\nRosenbrock\nAlgorithm3\n2.75\n1800\n9000\nLocal\nGradient-Based\n?\n\n\n\n\n\n\n3.4.4 Differential Evolution\nDifferential Evolution is an algorithm used for finding the global minimum of multivariate functions. It is stochastic in nature (does not use gradient methods), and can search large areas of candidate space, but often requires larger numbers of function evaluations than conventional gradient based techniques.\nDifferential Evolution (DE) is a versatile and global optimization algorithm inspired by natural selection and evolutionary processes. Introduced by Storn and Price in 1997, DE mimics the survival-of-the-fittest principle by evolving a population of candidate solutions through iterative mutation, crossover, and selection operations. This nature-inspired approach enables DE to efficiently explore complex and non-linear solution spaces, making it a widely adopted optimization technique in diverse fields such as engineering, finance, and machine learning.\n\n\n3.4.5 Procedure\nThe procedure boils down to the following steps:\n\nInitialization:\n\nCreate a population of candidate solutions randomly within the specified search space.\n\nMutation:\n\nFor each individual in the population, select three distinct individuals (vectors) randomly.\nGenerate a mutant vector V by combining these three vectors with a scaling factor.\n\nCrossover:\n\nPerform the crossover operation between the target vector U and the mutant vector V. Information from both vectors is used to create a trial vector U´\n\n\n\n\n\n\n\n\nCross-Over Strategies in DE\n\n\n\n\nThere are several crossover strategies in the literature. Two examples are:\n\nBinominal Crossover:\nIn this strategy, each component of the trial vector is selected from the mutant vector with a probability equal to the crossover rate (\\(CR\\)). This means that each element of the trial vector has an independent probability of being replaced by the corresponding element of the mutant vector.\n\\[U'_i =\n      \\begin{cases}\n      V_i, & \\text{if a random number} \\ \\sim U(0, 1) \\leq CR \\ \\text{(Crossover Rate)} \\\\\n      U_i, & \\text{otherwise}\n      \\end{cases}\n\\]\nExponential Crossover:\nIn exponential crossover, the trial vector is constructed by selecting a random starting point and copying elements from the mutant vector with a certain probability. The probability decreases exponentially with the distance from the starting point. This strategy introduces a correlation between neighboring elements in the trial vector.\n\n\n\nSelection:\n\nEvaluate the fitness of the trial vector obtained from the crossover.\nReplace the target vector with the trial vector if its fitness is better.\n\nTermination:\n\nRepeat the mutation, crossover, and selection steps for a predefined number of generations or until convergence criteria are met.\n\nResult:\n\nThe algorithm returns the best-found solution after the specified number of iterations.\n\n\nThe key parameters in DE include the population size, crossover probability, and the scaling factor. Tweak these parameters based on the characteristics of the optimization problem for optimal performance.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import minimize\n\n# Define the Rastrigin function\ndef rastrigin(x):\n    A = 10\n    return A * len(x) + sum([(xi**2 - A * np.cos(2 * np.pi * xi)) for xi in x])\n\n# Create a grid for visualization\nx_vals = np.linspace(-5.12, 5.12, 100)\ny_vals = np.linspace(-5.12, 5.12, 100)\nX, Y = np.meshgrid(x_vals, y_vals)\nZ = rastrigin(np.vstack([X.ravel(), Y.ravel()]))\n\n# Reshape Z to match the shape of X and Y\nZ = Z.reshape(X.shape)\n\n# Plot the Rastrigin function\nplt.contour(X, Y, Z, levels=50, cmap='viridis', label='Rastrigin Function')\n\n# Initial guess (starting point for the optimization)\ninitial_guess = (4,3,4,2)\n\n# Define the bounds for each variable in the Rastrigin function\nbounds = [(-5.12, 5.12)] * 4  # 4D problem, each variable has bounds (-5.12, 5.12)\n\n# Run the minimize function\nresult = minimize(rastrigin, initial_guess, bounds=bounds, method='L-BFGS-B')\n\n# Extract the optimal solution\noptimal_solution = result.x\n\n# Plot the optimal solution\nplt.scatter(optimal_solution[0], optimal_solution[1], color='red', marker='x', label='Optimal Solution')\n\n# Add labels and legend\nplt.title('Optimization of Rastrigin Function with Minimize')\nplt.xlabel('Variable 1')\nplt.ylabel('Variable 2')\nplt.legend()\n\n# Show the plot\nplt.show()\n\n# Print the optimization result\nprint(\"Optimal Solution:\", optimal_solution)\nprint(\"Optimal Objective Value:\", result.fun)\n\n\n\n\n\n\n\n\nOptimal Solution: [-2.52869119e-08 -2.07795060e-08 -2.52869119e-08 -1.62721002e-08]\nOptimal Objective Value: 3.907985046680551e-13\n\n\n\n\n3.4.6 DIRECT\nDIviding RECTangles (DIRECT) is a deterministic global optimization algorithm capable of minimizing a black box function with its variables subject to lower and upper bound constraints by sampling potential solutions in the search space\n\n\n3.4.7 SHGO\nSHGO stands for “simplicial homology global optimization”. It is considered appropriate for solving general purpose NLP and blackbox optimization problems to global optimality (low-dimensional problems).\n\n\n3.4.8 Basin-hopping\nBasin-hopping is a two-phase method that combines a global stepping algorithm with local minimization at each step. Designed to mimic the natural process of energy minimization of clusters of atoms, it works well for similar problems with “funnel-like, but rugged” energy landscapes",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to `scipy.optimize`</span>"
    ]
  },
  {
    "objectID": "003_scipy_optimize_intro.html#project-one-mass-oscillator-optimization",
    "href": "003_scipy_optimize_intro.html#project-one-mass-oscillator-optimization",
    "title": "3  Introduction to scipy.optimize",
    "section": "3.5 Project: One-Mass Oscillator Optimization",
    "text": "3.5 Project: One-Mass Oscillator Optimization\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import minimize\n\n\n3.5.1 Introduction\nIn this project, you will apply various optimization algorithms to fit a one-mass oscillator model to real-world data. The objective is to minimize the sum of the squared residuals between the model predictions and the observed amplitudes of a one-mass oscillator system across different frequencies.\n\n\n3.5.2 One-Mass Oscillator Model\nThe one-mass oscillator is characterized by the following equation, representing the amplitudes of the system:\n\\[\nV(\\omega) = \\frac{F}{\\sqrt{(1 - \\nu^2)^2 + 4D^2\\nu^2}}\n\\]\nHere, \\(\\omega\\) represents the angular frequency of the system, \\(\\nu\\) is the ratio of the excitation frequency to the natural frequency, i.e., \\[\n\\nu = \\frac{\\omega_{\\text{err}}}{\\omega_{\\text{eig}}},\n\\] \\(D\\) is the damping ratio, and \\(F\\) is the force applied to the system.\nThe goal of the project is to determine the optimal values for the parameters \\(\\omega_{\\text{eig}}\\), \\(D\\), and \\(F\\) that result in the best fit of the one-mass oscillator model to the observed amplitudes.\n\n\n3.5.3 The Real-World Data\nThere are two different measurements. J represents the measured frequencies, and N represents the measured amplitudes.\n\ndf1 = pd.read_pickle(\"./data/Hcf.d/df1.pkl\")\ndf2 = pd.read_pickle(\"./data/Hcf.d/df2.pkl\")\ndf1.describe()\n\n\n\n\n\n\n\n\nJ\nN\n\n\n\n\ncount\n33.000000\n33.000000\n\n\nmean\n8148.750252\n10.430887\n\n\nstd\n6.870023\n2.846469\n\n\nmin\n8137.649210\n4.698761\n\n\n25%\n8143.799766\n8.319253\n\n\n50%\n8146.942295\n10.152119\n\n\n75%\n8153.934051\n13.407260\n\n\nmax\n8162.504002\n14.382749\n\n\n\n\n\n\n\n\ndf1.head()\n\n\n\n\n\n\n\n\nJ\nN\n\n\n\n\n14999\n8162.504002\n5.527511\n\n\n15011\n8156.384831\n7.359789\n\n\n15016\n8159.199238\n6.532958\n\n\n15020\n8159.200889\n5.895933\n\n\n15025\n8153.934051\n9.326749\n\n\n\n\n\n\n\n\n# plot the data, i.e., the measured amplitudes as a function of the measured frequencies\nplt.scatter(df1[\"J\"], df1[\"N\"], color=\"black\", label=\"Spektralpunkte\", zorder=5, s=10)\nplt.xlabel(\"Frequency [Hz]\")\nplt.ylabel(\"Amplitude\")\nplt.show()\n\n\n\n\n\n\n\n\nNote: Low amplitudes distort the fit and are negligible therefore we define a lower threshold for N.\n\nthreshold = 0.4\ndf1.sort_values(\"N\")\nmax_N = max(df1[\"N\"])\ndf1 = df1[df1[\"N\"]&gt;=threshold*max_N]\n\nWe extract the frequency value for maximum value of the amplitude. This serves as the initial value for one decision variable.\n\ndf_max=df1[df1[\"N\"]==max(df1[\"N\"])]\ninitial_Oeig = df_max[\"J\"].values[0]\nmax_N = df_max[\"N\"].values[0]\n\nWe also have to define the other two initial guesses for the damping ratio and the force, e.g.,\n\ninitial_D = 0.006\ninitial_F = 0.120\ninitial_values = [initial_Oeig, initial_D, initial_F]\n\nAdditionally, we define the bounds for the decision variables:\n\nmin_Oerr = min(df1[\"J\"])\nmax_Oerr = max(df1[\"J\"])\n\n\nbounds = [(min_Oerr, max_Oerr), (0, 0.03), (0, 1)]\n\n\n\n3.5.4 Objective Function\nThen we define the objective function:\n\ndef one_mass_oscillator(params, Oerr) -&gt; np.ndarray:\n    # returns amplitudes of the system\n    # Defines the model of a one mass oscilator \n    Oeig, D, F = params\n    nue = Oerr / Oeig\n    V = F / (np.sqrt((1 - nue**2) ** 2 + (4 * D**2 * nue**2)))\n    return V\n\n\ndef objective_function(params, Oerr, amplitudes) -&gt; np.ndarray:\n    # objective function to compare calculated and real amplitudes\n    return np.sum((amplitudes - one_mass_oscillator(params, Oerr)) ** 2)\n\nWe define the options for the optimzer and start the optimization process:\n\noptions = {\n    \"maxfun\": 100000,\n    \"ftol\": 1e-9,\n    \"xtol\": 1e-9,\n    \"stepmx\": 10,\n    \"eta\": 0.25,\n    \"gtol\": 1e-5}\n\n\nJ = np.array(df1[\"J\"]) # measured frequency\nN = np.array(df1[\"N\"]) # measured amplitude\n\n\nresult = minimize(\n    objective_function,\n    initial_values,\n    args=(J, N),\n    method='Nelder-Mead',\n    bounds=bounds,\n    options=options)\n\n\n\n3.5.5 Results\nWe can observe the results:\n\n# map optimized values to variables\nresonant_frequency = result.x[0]\nD = result.x[1]\nF = result.x[2]\n# predict the resonant amplitude with the fitted one mass oscillator.\nX_pred = np.linspace(min_Oerr, max_Oerr, 1000)\nypred_one_mass_oscillator = one_mass_oscillator(result.x, X_pred)\nresonant_amplitude = max(ypred_one_mass_oscillator)\nprint(f\"result: {result}\")\n\nresult:        message: Optimization terminated successfully.\n       success: True\n        status: 0\n           fun: 53.54144061205875\n             x: [ 8.148e+03  7.435e-04  2.153e-02]\n           nit: 93\n          nfev: 169\n final_simplex: (array([[ 8.148e+03,  7.435e-04,  2.153e-02],\n                       [ 8.148e+03,  7.435e-04,  2.153e-02],\n                       [ 8.148e+03,  7.435e-04,  2.153e-02],\n                       [ 8.148e+03,  7.435e-04,  2.153e-02]]), array([ 5.354e+01,  5.354e+01,  5.354e+01,  5.354e+01]))\n\n\nFinally, we can plot the optimized fit and the real values:\n\nplt.scatter(\n    df1[\"J\"],\n    df1[\"N\"],\n    color=\"black\",\n    label=\"Spektralpunkte filtered\",\n    zorder=5,\n    s=10,\n)\n# color the max amplitude point red\nplt.scatter(\n    initial_Oeig,\n    max_N,\n    color=\"red\",\n    label=\"Max Amplitude\",\n    zorder=5,\n    s=10,\n)\n\nplt.plot(\n        X_pred,\n        ypred_one_mass_oscillator,\n        label=\"Alpha\",\n        color=\"blue\",\n        linewidth=1,\n    )\nplt.scatter(\n    resonant_frequency,\n    resonant_amplitude,\n    color=\"blue\",\n    label=\"Max Curve Fit\",\n    zorder=10,\n    s=20,\n)\n\n\n\n\n\n\n\n\n\n\n3.5.6 Tasks\n\nInvestigate the trust region Conjugate Gradient method\nInvestigate the Differential Evolution Algorithm\nCompare all the methods we introduced for the Rosenbrock (4d) and Rastrigin (2d) function\n\n\n\n3.5.7 Task for the Project Work\n\n\n\n\n\n\nTask\n\n\n\n\nExperiment with various optimizers to identify the optimal parameter setup for the one-mass oscillator model and both data frames.\nPlease explain your thoughts and ideas, and subsequently compare the results obtained from different optimizers.",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to `scipy.optimize`</span>"
    ]
  },
  {
    "objectID": "003_scipy_optimize_intro.html#jupyter-notebook",
    "href": "003_scipy_optimize_intro.html#jupyter-notebook",
    "title": "3  Introduction to scipy.optimize",
    "section": "3.6 Jupyter Notebook",
    "text": "3.6 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to `scipy.optimize`</span>"
    ]
  },
  {
    "objectID": "004_spot_sklearn_optimization.html",
    "href": "004_spot_sklearn_optimization.html",
    "title": "4  Sequential Parameter Optimization: Using scipy Optimizers",
    "section": "",
    "text": "4.1 The Objective Function Branin\nThe spotpython package provides several classes of objective functions. We will use an analytical objective function, i.e., a function that can be described by a (closed) formula. Here we will use the Branin function. The 2-dim Branin function is \\[\ny = a  (x_2 - b  x_1^2 + c  x_1 - r) ^2 + s  (1 - t)  \\cos(x_1) + s,\n\\] where values of \\(a\\), \\(b\\), \\(c\\), \\(r\\), \\(s\\) and \\(t\\) are: \\(a = 1\\), \\(b = 5.1 / (4\\pi^2)\\), \\(c = 5 / \\pi\\), \\(r = 6\\), \\(s = 10\\) and \\(t = 1 / (8\\pi)\\).\nIt has three global minima: \\(f(x) = 0.397887\\) at \\((-\\pi, 12.275)\\), \\((\\pi, 2.275)\\), and \\((9.42478, 2.475)\\).\nInput Domain: This function is usually evaluated on the square \\(x_1 \\in  [-5, 10] \\times x_2 \\in  [0, 15]\\).\nfrom spotpython.fun.objectivefunctions import analytical\nlower = np.array([-5,-0])\nupper = np.array([10,15])\nfun = analytical(seed=123).fun_branin",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Sequential Parameter Optimization: Using `scipy` Optimizers</span>"
    ]
  },
  {
    "objectID": "004_spot_sklearn_optimization.html#sec-optimizer",
    "href": "004_spot_sklearn_optimization.html#sec-optimizer",
    "title": "4  Sequential Parameter Optimization: Using scipy Optimizers",
    "section": "4.2 The Optimizer",
    "text": "4.2 The Optimizer\nDifferential Evolution (DE) from the scikit.optimize package, see https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.differential_evolution.html#scipy.optimize.differential_evolution is the default optimizer for the search on the surrogate. Other optimiers that are available in spotpython, see https://docs.scipy.org/doc/scipy/reference/optimize.html#global-optimization.\n\ndual_annealing\ndirect\nshgo\nbasinhopping\n\nThese optimizers can be selected as follows:\n\nfrom scipy.optimize import differential_evolution\noptimizer = differential_evolution\n\nAs noted above, we will use differential_evolution. The optimizer can use 1000 evaluations. This value will be passed to the differential_evolution method, which has the argument maxiter (int). It defines the maximum number of generations over which the entire differential evolution population is evolved, see https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.differential_evolution.html#scipy.optimize.differential_evolution\n\n\n\n\n\n\nTensorBoard\n\n\n\nSimilar to the one-dimensional case, which is discussed in Section 7.5, we can use TensorBoard to monitor the progress of the optimization. We will use a similar code, only the prefix is different:\n\nfun_control=fun_control_init(\n                    lower = lower,\n                    upper = upper,\n                    fun_evals = 20,\n                    PREFIX = \"04_DE_\"\n                    )\nsurrogate_control=surrogate_control_init(\n                    n_theta=len(lower))\n\n\n\n\nspot_de = spot.Spot(fun=fun,\n                    fun_control=fun_control,\n                    surrogate_control=surrogate_control)\nspot_de.run()\n\nspotpython tuning: 3.8004550038787155 [######----] 55.00% \nspotpython tuning: 3.8004550038787155 [######----] 60.00% \nspotpython tuning: 3.1588579885698627 [######----] 65.00% \nspotpython tuning: 3.1342382932317037 [#######---] 70.00% \nspotpython tuning: 2.8956615907630585 [########--] 75.00% \nspotpython tuning: 0.42052429574482275 [########--] 80.00% \nspotpython tuning: 0.4013351867835322 [########--] 85.00% \nspotpython tuning: 0.399265616254338 [#########-] 90.00% \nspotpython tuning: 0.399265616254338 [##########] 95.00% \nspotpython tuning: 0.399265616254338 [##########] 100.00% Done...\n\n\n\n&lt;spotpython.spot.spot.Spot at 0x34d981520&gt;\n\n\n\n4.2.1 TensorBoard\nIf the prefix argument in fun_control_init()is not None (as above, where the prefix was set to 04_DE_) , we can start TensorBoard in the background with the following command:\ntensorboard --logdir=\"./runs\"\nWe can access the TensorBoard web server with the following URL:\nhttp://localhost:6006/\nThe TensorBoard plot illustrates how spotpython can be used as a microscope for the internal mechanisms of the surrogate-based optimization process. Here, one important parameter, the learning rate \\(\\theta\\) of the Kriging surrogate is plotted against the number of optimization steps.\n\n\n\nTensorBoard visualization of the spotpython optimization process and the surrogate model.",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Sequential Parameter Optimization: Using `scipy` Optimizers</span>"
    ]
  },
  {
    "objectID": "004_spot_sklearn_optimization.html#print-the-results",
    "href": "004_spot_sklearn_optimization.html#print-the-results",
    "title": "4  Sequential Parameter Optimization: Using scipy Optimizers",
    "section": "4.3 Print the Results",
    "text": "4.3 Print the Results\n\nspot_de.print_results()\n\nmin y: 0.399265616254338\nx0: 3.151170754781285\nx1: 2.2981660114765448\n\n\n[['x0', 3.151170754781285], ['x1', 2.2981660114765448]]",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Sequential Parameter Optimization: Using `scipy` Optimizers</span>"
    ]
  },
  {
    "objectID": "004_spot_sklearn_optimization.html#show-the-progress",
    "href": "004_spot_sklearn_optimization.html#show-the-progress",
    "title": "4  Sequential Parameter Optimization: Using scipy Optimizers",
    "section": "4.4 Show the Progress",
    "text": "4.4 Show the Progress\n\nspot_de.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\nspot_de.surrogate.plot()",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Sequential Parameter Optimization: Using `scipy` Optimizers</span>"
    ]
  },
  {
    "objectID": "004_spot_sklearn_optimization.html#exercises",
    "href": "004_spot_sklearn_optimization.html#exercises",
    "title": "4  Sequential Parameter Optimization: Using scipy Optimizers",
    "section": "4.5 Exercises",
    "text": "4.5 Exercises\n\n4.5.1 dual_annealing\n\nDescribe the optimization algorithm, see scipy.optimize.dual_annealing.\nUse the algorithm as an optimizer on the surrogate.\n\n\n\n\n\n\n\nTip: Selecting the Optimizer for the Surrogate\n\n\n\nWe can run spotpython with the dual_annealing optimizer as follows:\n\nspot_da = spot.Spot(fun=fun,\n                    fun_control=fun_control,\n                    optimizer=dual_annealing,\n                    surrogate_control=surrogate_control)\nspot_da.run()\nspot_da.print_results()\nspot_da.plot_progress(log_y=True)\nspot_da.surrogate.plot()\n\nspotpython tuning: 3.8004480172281534 [######----] 55.00% \nspotpython tuning: 3.8004480172281534 [######----] 60.00% \nspotpython tuning: 3.158996247273234 [######----] 65.00% \nspotpython tuning: 3.134218255713952 [#######---] 70.00% \nspotpython tuning: 2.8926591957342467 [########--] 75.00% \nspotpython tuning: 0.4189006494820333 [########--] 80.00% \nspotpython tuning: 0.4019392204560983 [########--] 85.00% \nspotpython tuning: 0.39922543271904765 [#########-] 90.00% \nspotpython tuning: 0.39922543271904765 [##########] 95.00% \nspotpython tuning: 0.39922543271904765 [##########] 100.00% Done...\n\nmin y: 0.39922543271904765\nx0: 3.1506699177492252\nx1: 2.298631597428197\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.5.2 direct\n\nDescribe the optimization algorithm\nUse the algorithm as an optimizer on the surrogate\n\n\n\n\n\n\n\nTip: Selecting the Optimizer for the Surrogate\n\n\n\nWe can run spotpython with the direct optimizer as follows:\n\nspot_di = spot.Spot(fun=fun,\n                    fun_control=fun_control,\n                    optimizer=direct,\n                    surrogate_control=surrogate_control)\nspot_di.run()\nspot_di.print_results()\nspot_di.plot_progress(log_y=True)\nspot_di.surrogate.plot()\n\nspotpython tuning: 3.812970247994418 [######----] 55.00% \nspotpython tuning: 3.812970247994418 [######----] 60.00% \nspotpython tuning: 3.162514679816068 [######----] 65.00% \nspotpython tuning: 3.1189615135325983 [#######---] 70.00% \nspotpython tuning: 2.6597698275013038 [########--] 75.00% \nspotpython tuning: 0.3984917773445744 [########--] 80.00% \nspotpython tuning: 0.3984917773445744 [########--] 85.00% \nspotpython tuning: 0.3984917773445744 [#########-] 90.00% \nspotpython tuning: 0.3984917773445744 [##########] 95.00% \nspotpython tuning: 0.3984917773445744 [##########] 100.00% Done...\n\nmin y: 0.3984917773445744\nx0: 3.137860082304525\nx1: 2.3010973936899863\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.5.3 shgo\n\nDescribe the optimization algorithm\nUse the algorithm as an optimizer on the surrogate\n\n\n\n\n\n\n\nTip: Selecting the Optimizer for the Surrogate\n\n\n\nWe can run spotpython with the direct optimizer as follows:\n\nspot_sh = spot.Spot(fun=fun,\n                    fun_control=fun_control,\n                    optimizer=shgo,\n                    surrogate_control=surrogate_control)\nspot_sh.run()\nspot_sh.print_results()\nspot_sh.plot_progress(log_y=True)\nspot_sh.surrogate.plot()\n\nspotpython tuning: 3.8004562736456844 [######----] 55.00% \nspotpython tuning: 3.8004562736456844 [######----] 60.00% \nspotpython tuning: 3.158996879015902 [######----] 65.00% \nspotpython tuning: 3.1341298968229996 [#######---] 70.00% \nspotpython tuning: 2.8919915800445954 [########--] 75.00% \nspotpython tuning: 0.4173165753511867 [########--] 80.00% \nspotpython tuning: 0.40097732409794773 [########--] 85.00% \nspotpython tuning: 0.3993020098909934 [#########-] 90.00% \nspotpython tuning: 0.3993020098909934 [##########] 95.00% \nspotpython tuning: 0.3993020098909934 [##########] 100.00% Done...\n\nmin y: 0.3993020098909934\nx0: 3.1510894339439672\nx1: 2.298936853041466\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.5.4 basinhopping\n\nDescribe the optimization algorithm\nUse the algorithm as an optimizer on the surrogate\n\n\n\n\n\n\n\nTip: Selecting the Optimizer for the Surrogate\n\n\n\nWe can run spotpython with the direct optimizer as follows:\n\nspot_bh = spot.Spot(fun=fun,\n                    fun_control=fun_control,\n                    optimizer=basinhopping,\n                    surrogate_control=surrogate_control)\nspot_bh.run()\nspot_bh.print_results()\nspot_bh.plot_progress(log_y=True)\nspot_bh.surrogate.plot()\n\nspotpython tuning: 3.800453600053931 [######----] 55.00% \nspotpython tuning: 3.800453600053931 [######----] 60.00% \nspotpython tuning: 3.1590141837294237 [######----] 65.00% \nspotpython tuning: 3.1341341806066314 [#######---] 70.00% \nspotpython tuning: 2.8914331943522242 [########--] 75.00% \nspotpython tuning: 0.41214245125719984 [########--] 80.00% \nspotpython tuning: 0.40113843843078634 [########--] 85.00% \nspotpython tuning: 0.3992327747775164 [#########-] 90.00% \nspotpython tuning: 0.3992327747775164 [##########] 95.00% \nspotpython tuning: 0.3992327747775164 [##########] 100.00% Done...\n\nmin y: 0.3992327747775164\nx0: 3.15016404734246\nx1: 2.2998320162156896\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.5.5 Performance Comparison\nCompare the performance and run time of the 5 different optimizers:\n\ndifferential_evolution\ndual_annealing\ndirect\nshgo\nbasinhopping.\n\nThe Branin function has three global minima:\n\n\\(f(x) = 0.397887\\) at\n\n\\((-\\pi, 12.275)\\),\n\\((\\pi, 2.275)\\), and\n\\((9.42478, 2.475)\\).\n\n\nWhich optima are found by the optimizers?\nDoes the seed argument in fun = analytical(seed=123).fun_branin change this behavior?",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Sequential Parameter Optimization: Using `scipy` Optimizers</span>"
    ]
  },
  {
    "objectID": "004_spot_sklearn_optimization.html#jupyter-notebook",
    "href": "004_spot_sklearn_optimization.html#jupyter-notebook",
    "title": "4  Sequential Parameter Optimization: Using scipy Optimizers",
    "section": "4.6 Jupyter Notebook",
    "text": "4.6 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this chapter is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Sequential Parameter Optimization: Using `scipy` Optimizers</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html",
    "href": "005_num_rsm.html",
    "title": "5  Introduction: Numerical Methods",
    "section": "",
    "text": "5.1 Response Surface Methods: What is RSM?\nResponse Surface Methods (RSM) refer to a collection of statistical and mathematical tools that are valuable for developing, improving, and optimizing processes. The overarching theme of RSM involves studying how input variables that control a product or process can potentially influence a response that measures performance or quality characteristics.\nThe advantages of RSM include a rich literature, well-established methods often used in manufacturing, the importance of careful experimental design combined with a well-understood model, and the potential to add significant value to scientific inquiry, process refinement, optimization, and more. However, there are also drawbacks to RSM, such as the use of simple and crude surrogates, the hands-on nature of the methods, and the limitation of local methods.\nRSM is related to various fields, including Design of Experiments (DoE), quality management, reliability, and productivity. Its applications are widespread in industry and manufacturing, focusing on designing, developing, and formulating new products and improving existing ones, as well as from laboratory research. RSM is commonly applied in domains such as materials science, manufacturing, applied chemistry, climate science, and many others.\nAn example of RSM involves studying the relationship between a response variable, such as yield (\\(y\\)) in a chemical process, and two process variables: reaction time (\\(\\xi_1\\)) and reaction temperature (\\(\\xi_2\\)). The provided code illustrates this scenario, following a variation of the so-called “banana function.”\nIn the context of visualization, RSM offers the choice between 3D plots and contour plots. In a 3D plot, the independent variables \\(\\xi_1\\) and \\(\\xi_2\\) are represented, with \\(y\\) as the dependent variable.\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef fun_rosen(x1, x2):\n    b = 10\n    return (x1-1)**2 + b*(x2-x1**2)**2\n\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nx = np.arange(-2.0, 2.0, 0.05)\ny = np.arange(-1.0, 3.0, 0.05)\nX, Y = np.meshgrid(x, y)\nzs = np.array(fun_rosen(np.ravel(X), np.ravel(Y)))\nZ = zs.reshape(X.shape)\n\nax.plot_surface(X, Y, Z)\n\nax.set_xlabel('X1')\nax.set_ylabel('X2')\nax.set_zlabel('Y')\n\nplt.show()\nimport numpy as np\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\n\ndelta = 0.025\nx1 = np.arange(-2.0, 2.0, delta)\nx2 = np.arange(-1.0, 3.0, delta)\nX1, X2 = np.meshgrid(x1, x2)\nY = fun_rosen(X1, X2)\nfig, ax = plt.subplots()\nCS = ax.contour(X1, X2, Y , 50)\nax.clabel(CS, inline=True, fontsize=10)\nax.set_title(\"Rosenbrock's Banana Function\")\n\nText(0.5, 1.0, \"Rosenbrock's Banana Function\")",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction: Numerical Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#response-surface-methods-what-is-rsm",
    "href": "005_num_rsm.html#response-surface-methods-what-is-rsm",
    "title": "5  Introduction: Numerical Methods",
    "section": "",
    "text": "contour plot example:\n\n\\(x_1\\) and \\(x_2\\) are the independent variables\n\\(y\\) is the dependent variable\n\n\n\n\nVisual inspection: yield is optimized near \\((\\xi_1. \\xi_2)\\)\n\n\n5.1.1 Visualization: Problems in Practice\n\nTrue response surface is unknown in practice\nWhen yield evaluation is not as simple as a toy banana function, but a process requiring care to monitor, reconfigure and run, it’s far too expensive to observe over a dense grid\nAnd, measuring yield may be a noisy/inexact process\nThat’s where stats (RSM) comes in\n\n\n\n5.1.2 RSM: Strategies\n\nRSMs consist of experimental strategies for\nexploring the space of the process (i.e., independent/input) variables (above \\(\\xi_1\\) and \\(\\xi2)\\)\nempirical statistical modeling targeted toward development of an appropriate approximating relationship between the response (yield) and process variables local to a study region of interest\noptimization methods for sequential refinement in search of the levels or values of process variables that produce desirable responses (e.g., that maximize yield or explain variation)\nRSM used for fitting an Empirical Model\nTrue response surface driven by an unknown physical mechanism\nObservations corrupted by noise\nHelpful: fit an empirical model to output collected under different process configurations\nConsider response \\(Y\\) that depends on controllable input variables \\(\\xi_1, \\xi_2, \\ldots, \\xi_m\\)\nRSM: Equations of the Empirical Model\n\n\\(Y=f(\\xi_1, \\xi_2, \\ldots, \\xi_m) + \\epsilon\\)\n\\(\\mathbb{E}\\{Y\\} = \\eta = f(\\xi1_1, \\xi_2, \\ldots, \\xi_m)\\)\n\\(\\epsilon\\) is treated as zero mean idiosyncratic noise possibly representing\n\ninherent variation, or\nthe effect of other systems or\nvariables not under our purview at this time\n\n\n\n\n\n5.1.3 RSM: Noise in the Empirical Model\n\nTypical simplifying assumption: \\(\\epsilon \\sim N(0,\\sigma^2)\\)\nWe seek estimates for \\(f\\) and \\(\\sigma^2\\) from noisy observations \\(Y\\) at inputs \\(\\xi\\)\n\n\n\n5.1.4 RSM: Natural and Coded Variables\n\nInputs \\(\\xi_1, \\xi_2, \\ldots, \\xi_m\\) called natural variables:\n\nexpressed in natural units of measurement, e.g., degrees Celsius, pounds per square inch (psi), etc.\n\nTransformed to coded variables \\(x_1, x_2, \\ldots, x_m\\):\n\nto mitigate hassles and confusion that can arise when working with a multitude of scales of measurement\n\nTypical Transformations offering dimensionless inputs \\(x_1, x_2, \\ldots, x_m\\)\n\nin the unit cube, or\nscaled to have a mean of zero and standard deviation of one, are common choices.\n\nEmpirical model becomes \\(\\eta = f(x_1, x_2, \\ldots, x_m)\\)\n\n\n\n5.1.5 RSM Low-order Polynomials\n\nLow-order polynomial make the following simplifying Assumptions\n\nLearning about \\(f\\) is lots easier if we make some simplifying approximations\nAppealing to Taylor’s theorem, a low-order polynomial in a small, localized region of the input (\\(x\\)) space is one way forward\nClassical RSM:\n\ndisciplined application of local analysis and\nsequential refinement of locality through conservative extrapolation\n\nInherently a hands-on process",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction: Numerical Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#first-order-models-main-effects-model",
    "href": "005_num_rsm.html#first-order-models-main-effects-model",
    "title": "5  Introduction: Numerical Methods",
    "section": "5.2 First-Order Models (Main Effects Model)",
    "text": "5.2 First-Order Models (Main Effects Model)\n\nFirst-order model (sometimes called main effects model) useful in parts of the input space where it’s believed that there’s little curvature in \\(f\\): \\[\\eta = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 \\]\nFor example: \\[\\eta = 50 + 8 x_1 + 3x_2\\]\nIn practice, such a surface would be obtained by fitting a model to the outcome of a designed experiment\nFirst-Order Model in python Evaluated on a Grid\nEvaluate model on a grid in a double-unit square centered at the origin\nCoded units are chosen arbitrarily, although one can imagine deploying this approximating function nearby \\(x^{(0)} = (0,0)\\)\n\n\ndef fun_1(x1,x2):\n    return 50 + 8*x1 + 3*x2\n\n\nimport numpy as np\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\n\ndelta = 0.025\nx1 = np.arange(-1.0, 1.0, delta)\nx2 = np.arange(-1.0, 1.0, delta)\nX1, X2 = np.meshgrid(x1, x2)\nY = fun_1(X1,X2)\nfig, ax = plt.subplots()\nCS = ax.contour(X1, X2, Y)\nax.clabel(CS, inline=True, fontsize=10)\nax.set_title('First Order Model: $50 + 8x_1 + 3x_2$')\n\nText(0.5, 1.0, 'First Order Model: $50 + 8x_1 + 3x_2$')\n\n\n\n\n\n\n\n\n\n\n5.2.1 First-Order Model Properties\n\nFirst-order model in 2d traces out a plane in \\(y \\times (x_1, x_2)\\) space\nOnly be appropriate for the most trivial of response surfaces, even when applied in a highly localized part of the input space\nAdding curvature is key to most applications:\n\nFirst-order model with interactions induces limited degree of curvature via different rates of change of \\(y\\) as \\(x_1\\) is varied for fixed \\(x_2\\), and vice versa: \\[\\eta = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_{12} x_{12} \\]\n\nFor example \\(\\eta = 50+8x_1+3x_2-4x_1x_2\\)\n\n\n\n5.2.2 First-order Model with Interactions in python\n\nCode below facilitates evaluations for pairs \\((x_1, x_2)\\)\nResponses may be observed over a mesh in the same double-unit square\n\n\ndef fun_11(x1,x2):\n    return 50 + 8 * x1 + 3 * x2 - 4 * x1 * x2\n\n\nimport numpy as np\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\n\ndelta = 0.025\nx1 = np.arange(-2.0, 2.0, delta)\nx2 = np.arange(-2.0, 2.0, delta)\nX1, X2 = np.meshgrid(x1, x2)\nY = fun_11(X1,X2)\nfig, ax = plt.subplots()\nCS = ax.contour(X1, X2, Y, 20)\nax.clabel(CS, inline=True, fontsize=10)\nax.set_title('First Order Model with Interactions')\n\nText(0.5, 1.0, 'First Order Model with Interactions')\n\n\n\n\n\n\n\n\n\n\n\n5.2.3 Observations: First-Order Model with Interactions\n\nMean response \\(\\eta\\) is increasing marginally in both \\(x_1\\) and \\(x_2\\), or conditional on a fixed value of the other until \\(x_1\\) is 0.75\nRate of increase slows as both coordinates grow simultaneously since the coefficient in front of the interaction term \\(x_1 x_2\\) is negative\nCompared to the first-order model (without interactions): surface is far more useful locally\nLeast squares regressions often flag up significant interactions when fit to data collected on a design far from local optima",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction: Numerical Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#second-order-models",
    "href": "005_num_rsm.html#second-order-models",
    "title": "5  Introduction: Numerical Methods",
    "section": "5.3 Second-Order Models",
    "text": "5.3 Second-Order Models\n\nSecond-order model may be appropriate near local optima where \\(f\\) would have substantial curvature: \\[\\eta = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2  + \\beta_{11}x_1^2 + \\beta_{22}x^2 + \\beta_{12} x_1 x_2\\]\nFor example \\[\\eta = 50 + 8 x_1 + 3x_2 - 7x_1^2 - 3 x_2^2 - 4x_1x_2\\]\nImplementation of the Second-Order Model as fun_2().\n\n\ndef fun_2(x1,x2):\n    return 50 + 8 * x1 + 3 * x2 - 7 * x1**2 - 3*x2**2 - 4 * x1 * x2\n\n\nimport numpy as np\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\n\ndelta = 0.025\nx1 = np.arange(-2.0, 2.0, delta)\nx2 = np.arange(-2.0, 2.0, delta)\nX1, X2 = np.meshgrid(x1, x2)\nY = fun_2(X1,X2)\nfig, ax = plt.subplots()\nCS = ax.contour(X1, X2, Y, 20)\nax.clabel(CS, inline=True, fontsize=10)\nax.set_title('Second Order Model with Interactions. Maximum near about $(0.6,0.2)$')\n\nText(0.5, 1.0, 'Second Order Model with Interactions. Maximum near about $(0.6,0.2)$')\n\n\n\n\n\n\n\n\n\n\n5.3.1 Second-Order Models: Properties\n\nNot all second-order models would have a single stationary point (in RSM jargon called “a simple maximum”)\nIn “yield maximizing” setting we’re presuming response surface is concave down from a global viewpoint\n\neven though local dynamics may be more nuanced\n\nExact criteria depend upon the eigenvalues of a certain matrix built from those coefficients\nBox and Draper (2007) provide a diagram categorizing all of the kinds of second-order surfaces in RSM analysis, where finding local maxima is the goal\n\n\n\n5.3.2 Example: Stationary Ridge\n\nExample set of coefficients describing what’s called a stationary ridge is provided by the code below\n\n\ndef fun_ridge(x1, x2):\n    return 80 + 4*x1 + 8*x2 - 3*x1**2 - 12*x2**2 - 12*x1*x2\n\n\nimport numpy as np\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\n\ndelta = 0.025\nx1 = np.arange(-2.0, 2.0, delta)\nx2 = np.arange(-2.0, 2.0, delta)\nX1, X2 = np.meshgrid(x1, x2)\nY = fun_ridge(X1,X2)\nfig, ax = plt.subplots()\nCS = ax.contour(X1, X2, Y, 20)\nax.clabel(CS, inline=True, fontsize=10)\nax.set_title('Example of a stationary ridge')\n\nText(0.5, 1.0, 'Example of a stationary ridge')\n\n\n\n\n\n\n\n\n\n\n\n5.3.3 Observations: Second-Order Model (Ridge)\n\nRidge: a whole line of stationary points corresponding to maxima\nSituation means that the practitioner has some flexibility when it comes to optimizing:\n\ncan choose the precise setting of \\((x_1, x_2)\\) either arbitrarily or (more commonly) by consulting some tertiary criteria\n\n\n\n\n5.3.4 Example: Rising Ridge\n\nAn example of a rising ridge is implemented by the code below.\n\n\ndef fun_ridge_rise(x1, x2):\n     return 80 - 4*x1 + 12*x2 - 3*x1**2 - 12*x2**2 - 12*x1*x2\n\n\nimport numpy as np\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\n\ndelta = 0.025\nx1 = np.arange(-2.0, 2.0, delta)\nx2 = np.arange(-2.0, 2.0, delta)\nX1, X2 = np.meshgrid(x1, x2)\nY = fun_ridge_rise(X1,X2)\nfig, ax = plt.subplots()\nCS = ax.contour(X1, X2, Y, 20)\nax.clabel(CS, inline=True, fontsize=10)\nax.set_title('Rising ridge: $\\\\eta = 80 + 4x_1 + 8x_2 - 3x_1^2 - 12x_2^2 - 12x_1x_2$')\n\nText(0.5, 1.0, 'Rising ridge: $\\\\eta = 80 + 4x_1 + 8x_2 - 3x_1^2 - 12x_2^2 - 12x_1x_2$')\n\n\n\n\n\n\n\n\n\n\n\n5.3.5 Summary: Rising Ridge\n\nThe stationary point is remote to the study region\nCcontinuum of (local) stationary points along any line going through the 2d space, excepting one that lies directly on the ridge\nAlthough estimated response will increase while moving along the axis of symmetry toward its stationary point, this situation indicates\n\neither a poor fit by the approximating second-order function, or\nthat the study region is not yet precisely in the vicinity of a local optima—often both.\n\n\n\n\n5.3.6 Falling Ridge\n\nInversion of a rising ridge is a falling ridge\nSimilarly indicating one is far from local optima, except that the response decreases as you move toward the stationary point\nFinding a falling ridge system can be a back-to-the-drawing-board affair.\n\n\n\n5.3.7 Saddle Point\n\nFinally, we can get what’s called a saddle or minimax system.\n\n\ndef fun_saddle(x1, x2):\n    return 80 + 4*x1 + 8*x2 - 2*x2**2 - 12*x1*x2 \n\n\nimport numpy as np\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\n\ndelta = 0.025\nx1 = np.arange(-2.0, 2.0, delta)\nx2 = np.arange(-2.0, 2.0, delta)\nX1, X2 = np.meshgrid(x1, x2)\nY = fun_saddle(X1,X2)\nfig, ax = plt.subplots()\nCS = ax.contour(X1, X2, Y, 20)\nax.clabel(CS, inline=True, fontsize=10)\nax.set_title('Saddle Point: $\\\\eta = 80 + 4x_1 + 8x_2 - 2x_2^2 - 12x_1x_2$')\n\nText(0.5, 1.0, 'Saddle Point: $\\\\eta = 80 + 4x_1 + 8x_2 - 2x_2^2 - 12x_1x_2$')\n\n\n\n\n\n\n\n\n\n\n\n5.3.8 Interpretation: Saddle Points\n\nLikely further data collection, and/or outside expertise, is needed before determining a course of action in this situation\n\n\n\n5.3.9 Summary: Ridge Analysis\n\nFinding a simple maximum, or stationary ridge, represents ideals in the spectrum of second-order approximating functions\nBut getting there can be a bit of a slog\nUsing models fitted from data means uncertainty due to noise, and therefore uncertainty in the type of fitted second-order model\nA ridge analysis attempts to offer a principled approach to navigating uncertainties when one is seeking local maxima\nThe two-dimensional setting exemplified above is convenient for visualization, but rare in practice\nComplications compound when studying the effect of more than two process variables",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction: Numerical Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#general-rsm-models",
    "href": "005_num_rsm.html#general-rsm-models",
    "title": "5  Introduction: Numerical Methods",
    "section": "5.4 General RSM Models",
    "text": "5.4 General RSM Models\n\nGeneral first-order model on \\(m\\) process variables \\(x_1, x_2, \\cdots, x_m\\) is \\[\\eta = \\beta_0 + \\beta_1x_1 + \\cdots + \\beta_m x_m\\]\nGeneral second-order model on \\(m\\) process variables \\[\n\\eta= \\beta_0 + \\sum_{j=1}^m + \\sum_{j=1}^m x_j^2 + \\sum_{j=2}^m \\sum_{k=1}^j \\beta_{kj}x_k x_j.\n\\]\n\n\n5.4.1 Ordinary Least Squares\n\nInference from data is carried out by ordinary least squares (OLS)\nFor an excellent review including R examples, see Sheather (2009)\nOLS and maximum likelihood estimators (MLEs) are in the typical Gaussian linear modeling setup basically equivalent",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction: Numerical Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#designs",
    "href": "005_num_rsm.html#designs",
    "title": "5  Introduction: Numerical Methods",
    "section": "5.5 Designs",
    "text": "5.5 Designs\n\nImportant: Organize the data collection phase of a response surface study carefully\nDesign: choice of \\(x\\)’s where we plan to observe \\(y\\)’s, for the purpose of approximating \\(f\\)\nAnalyses and designs need to be carefully matched\nWhen using a first-order model, some designs are preferred over others\nWhen using a second-order model to capture curvature, a different sort of design is appropriate\nDesign choices often contain features enabling modeling assumptions to be challenged\n\ne.g., to check if initial impressions are supported by the data ultimately collected\n\n\n\n5.5.1 Different Designs\n\nScreening desings: determine which variables matter so that subsequent experiments may be smaller and/or more focused\nThen there are designs tailored to the form of model (first- or second-order, say) in the screened variables\nAnd then there are more designs still",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction: Numerical Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#rsm-experimentation",
    "href": "005_num_rsm.html#rsm-experimentation",
    "title": "5  Introduction: Numerical Methods",
    "section": "5.6 RSM Experimentation",
    "text": "5.6 RSM Experimentation\n\n5.6.1 First Step\n\nRSM-based experimentation begins with a first-order model, possibly with interactions\nPresumption: current process operating far from optimal conditions\nCollect data and apply method of steepest ascent (gradient) on fitted surfaces to move to the optimum\n\n\n\n5.6.2 Second Step\n\nEventually, if all goes well after several such carefully iterated refinements, second-order models are used on appropriate designs in order to zero-in on ideal operating conditions\nCareful analysis of the fitted surface:\n\nRidge analysis with further refinement using gradients of, and\nstandard errors associated with, the fitted surfaces, and so on\n\n\n\n\n5.6.3 Third Step\n\nOnce the practitioner is satisfied with the full arc of\n\ndesign(s),\nfit(s), and\ndecision(s):\n\nA small experiment called confirmation test may be performed to check if the predicted optimal settings are realizable in practice",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction: Numerical Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#rsm-review-and-general-considerations",
    "href": "005_num_rsm.html#rsm-review-and-general-considerations",
    "title": "5  Introduction: Numerical Methods",
    "section": "5.7 RSM: Review and General Considerations",
    "text": "5.7 RSM: Review and General Considerations\n\nFirst Glimpse, RSM seems sensible, and pretty straightforward as quantitative statistics-based analysis goes\nBut: RSM can get complicated, especially when input dimensions are not very low\nDesign considerations are particularly nuanced, since the goal is to obtain reliable estimates of main effects, interaction, and curvature while minimizing sampling effort/expense\nRSM Downside: Inefficiency\n\nDespite intuitive appeal, several RSM downsides become apparent upon reflection\nProblems in practice\nStepwise nature of sequential decision making is inefficient:\n\nNot obvious how to re-use or update analysis from earlier phases, or couple with data from other sources/related experiments\n\n\nRSM Downside: Locality\n\nIn addition to being local in experiment-time (stepwise approach), it’s local in experiment-space\nBalance between\n\nexploration (maybe we’re barking up the wrong tree) and\nexploitation (let’s make things a little better) is modest at best\n\n\nRSM Downside: Expert Knowledge\n\nInterjection of expert knowledge is limited to hunches about relevant variables (i.e., the screening phase), where to initialize search, how to design the experiments\nYet at the same time classical RSMs rely heavily on constant examination throughout stages of modeling and design and on the instincts of seasoned practitioners\n\nRSM Downside: Replicability\n\nParallel analyses, conducted according to the same best intentions, rarely lead to the same designs, model fits and so on\nSometimes that means they lead to different conclusions, which can be cause for concern\n\n\n\n5.7.1 Historical Considerations about RSM\n\nIn spite of those criticisms, however, there was historically little impetus to revise the status quo\nClassical RSM was comfortable in its skin, consistently led to improvements or compelling evidence that none can reasonably be expected\nBut then in the late 20th century came an explosive expansion in computational capability, and with it a means of addressing many of those downsides\n\n\n\n5.7.2 Status Quo\n\nNowadays, field experiments and statistical models, designs and optimizations are coupled with with mathematical models\nSimple equations are not regarded as sufficient to describe real-world systems anymore\nPhysicists figured that out fifty years ago; industrial engineers followed, biologists, social scientists, climate scientists and weather forecasters, etc.\nSystems of equations are required, solved over meshes (e.g., finite elements), or stochastically interacting agents\nGoals for those simulation experiments are as diverse as their underlying dynamics\nOptimization of systems is common, e.g., to identify worst-case scenarios\n\n\n\n5.7.3 The Role of Statistics\n\nSolving systems of equations, or interacting agents, requires computing\nStatistics involved at various stages:\n\nchoosing the mathematical model\nsolving by stochastic simulation (Monte Carlo)\ndesigning the computer experiment\nsmoothing over idiosyncrasies or noise\nfinding optimal conditions, or\ncalibrating mathematical/computer models to data from field experiments\n\n\n\n\n5.7.4 New RSM is needed: DACE\n\nClassical RSMs are not well-suited to any of those tasks, because\n\nthey lack the fidelity required to model these data\ntheir intended application is too local\nthey’re also too hands-on.\n\nOnce computers are involved, a natural inclination is to automate—to remove humans from the loop and set the computer running on the analysis in order to maximize computing throughput, or minimize idle time\nDesign and Analysis of Computer Experiments as a modern extension of RSM\nExperimentation is changing due to advances in machine learning\nGaussian process (GP) regression is the canonical surrogate model\nOrigins in geostatistics (gold mining)\nWide applicability in contexts where prediction is king\nMachine learners exposed GPs as powerful predictors for all sorts of tasks:\nfrom regression to classification,\nactive learning/sequential design,\nreinforcement learning and optimization,\nlatent variable modeling, and so on",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction: Numerical Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#exercises",
    "href": "005_num_rsm.html#exercises",
    "title": "5  Introduction: Numerical Methods",
    "section": "5.8 Exercises",
    "text": "5.8 Exercises\n\nGenerate 3d Plots for the Contour Plots in this notebook.\nWrite a plot_3d function, that takes the objective function fun as an argument.\n\n\nIt should provide the following interface: plot_3d(fun).\n\n\nWrite a plot_contour function, that takes the objective function fun as an argument:\n\n\nIt should provide the following interface: plot_contour(fun).\n\n\nConsider further arguments that might be useful for both function, e.g., ranges, size, etc.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction: Numerical Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#jupyter-notebook",
    "href": "005_num_rsm.html#jupyter-notebook",
    "title": "5  Introduction: Numerical Methods",
    "section": "5.9 Jupyter Notebook",
    "text": "5.9 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Introduction: Numerical Methods</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html",
    "href": "006_num_gp.html",
    "title": "6  Kriging (Gaussian Process Regression)",
    "section": "",
    "text": "6.1 DACE and RSM\nMathematical models implemented in computer codes are used to circumvent the need for expensive field data collection. These models are particularly useful when dealing with highly nonlinear response surfaces, high signal-to-noise ratios (which often involve deterministic evaluations), and a global scope. As a result, a new approach is required in comparison to Response Surface Methodology (RSM).\nWith the improvement in computing power and simulation fidelity, researchers gain higher confidence and a better understanding of the dynamics in physical, biological, and social systems. However, the expansion of configuration spaces and increasing input dimensions necessitates more extensive designs. High-performance computing (HPC) allows for thousands of runs, whereas previously only tens were possible. This shift towards larger models and training data presents new computational challenges.\nResearch questions for DACE (Design and Analysis of Computer Experiments) include how to design computer experiments that make efficient use of computation and how to meta-model computer codes to save on simulation effort. The choice of surrogate model for computer codes significantly impacts the optimal experiment design, and the preferred model-design pairs can vary depending on the specific goal.\nThe combination of computer simulation, design, and modeling with field data from similar real-world experiments introduces a new category of computer model tuning problems. The ultimate goal is to automate these processes to the greatest extent possible, allowing for the deployment of HPC with minimal human intervention.\nOne of the remaining differences between RSM and DACE lies in how they handle noise. DACE employs replication, a technique that would not be used in a deterministic setting, to separate signal from noise. Traditional RSM is best suited for situations where a substantial proportion of the variability in the data is due to noise, and where the acquisition of data values can be severely limited. Consequently, RSM is better suited for a different class of problems, aligning with its intended purposes.\nTwo very good texts on computer experiments and surrogate modeling are Santner, Williams, and Notz (2003) and Forrester, Sóbester, and Keane (2008). The former is the canonical reference in the statistics literature and the latter is perhaps more popular in engineering.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html#background-expectation-mean-standard-deviation",
    "href": "006_num_gp.html#background-expectation-mean-standard-deviation",
    "title": "6  Kriging (Gaussian Process Regression)",
    "section": "6.2 Background: Expectation, Mean, Standard Deviation",
    "text": "6.2 Background: Expectation, Mean, Standard Deviation\nThe distribution of a random vector is characterized by some indexes. One of them is the expected value, which is defined as \\[\nE[X] = \\sum_{x \\in D_X} xp_X(x)  \\qquad \\text{if $X$ is discrete}\n\\] \\[\nE[X] = \\int\\limits_{x \\in D_X} xf_X(x)\\mathrm{d}x  \\quad  \\text{if $X$ is continuous.}\n\\]\nThe mean, \\(\\mu\\), of a probability distribution is a measure of its central tendency or location. That is, \\(E(X)\\) is defined as the average of all possible values of \\(X\\), weighted by their probabilities.\n\n\n\n\n\n\nExample: Expectation\n\n\n\nLet \\(X\\) denote the number produced by rolling a fair die. Then \\[\nE(X) = 1 \\times 1/6 + 2 \\times 1/6 + 3 \\times 1/6 + 4 \\times 1/6 + 5 \\times 1/6 + 6\\times 1/6 = 3.5.\n\\]\n\n\n\n6.2.1 Sample Mean\nThe sample mean is an important estimate of the population mean. The sample mean of a sample \\(\\{x_i\\}\\) (\\(i=1,2,\\ldots,n\\)) is defined as \\[\\overline{x}  = \\frac{1}{n} \\sum_i x_i.\\]\n\n\n6.2.2 Variance and Standard Deviation\nIf we are trying to predict the value of a random variable \\(X\\) by its mean \\(\\mu = E(X)\\), the error will be \\(X-\\mu\\). In many situations it is useful to have an idea how large this deviation or error is. Since \\(E(X-\\mu) = E(X) -\\mu = 0\\), it is necessary to use the absolute value or the square of (\\(X-\\mu\\)). The squared error is the first choice, because the derivatives are easier to calculate. These considerations motivate the definition of the variance:\nThe variance of a random variable \\(X\\) is the mean squared deviation of \\(X\\) from its expected value \\(\\mu = E(X)\\). \\[\\begin{equation}\nVar(X) = E[ (X-\\mu)^2].\n\\end{equation}\\]\n\n\n6.2.3 Standard Deviation\nTaking the square root of the variance to get back to the same scale of units as \\(X\\) gives the standard deviation. The standard deviation of \\(X\\) is the square root of the variance of \\(X\\). \\[\\begin{equation}\nsd(X) = \\sqrt{Var(X)}.\n\\end{equation}\\]\n\n\n6.2.4 Calculation of the Standard Deviation with Python\nThe function numpy.std returns the standard deviation, a measure of the spread of a distribution, of the array elements. The argument ddof specifies the Delta Degrees of Freedom. The divisor used in calculations is N - ddof, where N represents the number of elements. By default ddof is zero, i.e., std uses the formula \\[\\begin{equation}  \\sqrt{  \\frac{1}{N} \\sum_i \\left( x_i - \\bar{x} \\right)^2  } \\qquad \\text{with } \\quad \\bar{x} = \\sum_{i=1}^N x_i /N. \\end{equation}\\]\n\n\n\n\n\n\nExample: Standard Deviation with Python\n\n\n\nConsider the array \\([1,2,3]\\): Since \\(\\bar{x} = 2\\), the following value is computed: \\[ \\sqrt{1/3 \\times \\left( (1-2)^2 + (2-2)^2 + (3-2)^2  \\right)} = \\sqrt{2/3}.\\]\n\nimport numpy as np\na = np.array([[1, 2, 3]])\nnp.std(a)\n\n0.816496580927726\n\n\n\n\n\n\n6.2.5 The Empirical Standard Deviation\nThe empirical standard deviation (which uses \\(N-1\\)), \\(\\sqrt{1/2 \\times \\left( (1-2)^2 + (2-2)^2 + (3-2)^2  \\right)} = \\sqrt{2/2}\\), can be calculated as follows:\n\nnp.std(a, ddof=1)\n\n1.0\n\n\n\n\n6.2.6 The Argument “axis”\n\n\n\n\n\n\nAxes along which the standard deviation is computed\n\n\n\n\nWhen you compute np.std with axis=0, it calculates the standard deviation along the vertical axis, meaning it computes the standard deviation for each column of the array.\nOn the other hand, when you compute np.std with axis=1, it calculates the standard deviation along the horizontal axis, meaning it computes the standard deviation for each row of the array.\nIf the axis parameter is not specified, np.std computes the standard deviation of the flattened array.\n\n\n\n\nA = np.array([[1, 2], [3, 4]])\nA\n\narray([[1, 2],\n       [3, 4]])\n\n\n\nnp.std(A)\n\n1.118033988749895\n\n\n\nnp.std(A, axis=0)\n\narray([1., 1.])\n\n\n\nnp.std(A, axis=1)\n\narray([0.5, 0.5])",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html#data-types-and-precision-in-python",
    "href": "006_num_gp.html#data-types-and-precision-in-python",
    "title": "6  Kriging (Gaussian Process Regression)",
    "section": "6.3 Data Types and Precision in Python",
    "text": "6.3 Data Types and Precision in Python\nWe consider single versus double precision in Python. In single precision, std() can be inaccurate:\n\na = np.zeros((2, 4*4), dtype=np.float32)\na[0, :] = 1.0\na[1, :] = 0.1\na \n\narray([[1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. ,\n        1. , 1. , 1. ],\n       [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n        0.1, 0.1, 0.1]], dtype=float32)\n\n\n\nnp.std(a, axis=0)\n\narray([0.45, 0.45, 0.45, 0.45, 0.45, 0.45, 0.45, 0.45, 0.45, 0.45, 0.45,\n       0.45, 0.45, 0.45, 0.45, 0.45], dtype=float32)\n\n\n\nnp.std(a, axis=1)\n\narray([0., 0.], dtype=float32)\n\n\n\nabs(0.45 - np.std(a))\n\n1.7881393421514957e-08\n\n\n\n\n\n\n\n\nFloat data types\n\n\n\n\nfloat32 and float64 are data types in numpy that specify the precision of floating point numbers.\nfloat32 is a single-precision floating point number that occupies 32 bits of memory. It has a precision of about 7 decimal digits.\nfloat64 is a double-precision floating point number that occupies 64 bits of memory. It has a precision of about 15 decimal digits.\nThe main difference between float32 and float64 is the precision and memory usage. float64 provides a higher precision but uses more memory, while float32 uses less memory but has a lower precision.\n\n\n\nComputing the standard deviation in float64 is more accurate (result may vary), see https://numpy.org/devdocs/reference/generated/numpy.std.html.\n\nabs(0.45 - np.std(a, dtype=np.float64))\n\n7.450580707946131e-10\n\n\n\n\n\n\n\n\nExample: 32 versus 64 bit\n\n\n\n\nimport numpy as np\n\n# Define a number\nnum = 0.123456789123456789\n\n# Convert to float32 and float64\nnum_float32 = np.float32(num)\nnum_float64 = np.float64(num)\n\n# Print the number in both formats\nprint(\"float32: \", num_float32)\nprint(\"float64: \", num_float64)\n\nfloat32:  0.12345679\nfloat64:  0.12345678912345678\n\n\n\n\nThe float32 data type in numpy represents a single-precision floating point number. It uses 32 bits of memory, which gives it a precision of about 7 decimal digits. On the other hand, float64 represents a double-precision floating point number. It uses 64 bits of memory, which gives it a precision of about 15 decimal digits.\nThe reason float32 shows fewer digits is because it has less precision due to using less memory. The bits of memory are used to store the sign, exponent, and fraction parts of the floating point number, and with fewer bits, you can represent fewer digits accurately.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html#distributions-and-random-numbers-in-python",
    "href": "006_num_gp.html#distributions-and-random-numbers-in-python",
    "title": "6  Kriging (Gaussian Process Regression)",
    "section": "6.4 Distributions and Random Numbers in Python",
    "text": "6.4 Distributions and Random Numbers in Python\nResults from computers are deterministic, so it sounds like a contradiction in terms to generate random numbers on a computer. Standard computers generate pseudo-randomnumbers, i.e., numbers that behave as if they were drawn randomly.\n\n\n\n\n\n\nDeterministic Random Numbers\n\n\n\n\nIdea: Generate deterministically numbers that look (behave) as if they were drawn randomly.\n\n\n\n\n6.4.1 The Uniform Distribution\nThe probability density function of the uniform distribution is defined as: \\[\nf_X(x) = \\frac{1}{b-a} \\qquad \\text{for $x \\in [a,b]$}.\n\\]\nGenerate 10 random numbers from a uniform distribution between \\(a=0\\) and \\(b=1\\):\n\nimport numpy as np\n# Initialize the random number generator\nrng = np.random.default_rng(seed=123456789)\nn = 10\nx = rng.uniform(low=0.0, high=1.0, size=n)\nx\n\narray([0.02771274, 0.90670006, 0.88139355, 0.62489728, 0.79071481,\n       0.82590801, 0.84170584, 0.47172795, 0.95722878, 0.94659153])\n\n\nGenerate 10,000 random numbers from a uniform distribution between 0 and 10 and plot a histogram of the numbers:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Initialize the random number generator\nrng = np.random.default_rng(seed=123456789)\n\n# Generate random numbers from a uniform distribution\nx = rng.uniform(low=0, high=10, size=10000)\n\n# Plot a histogram of the numbers\nplt.hist(x, bins=50, density=True, edgecolor='black')\nplt.title('Uniform Distribution [0,10]')\nplt.xlabel('Value')\nplt.ylabel('Frequency')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n6.4.2 The Normal Distribution\nThe probability density function of the normal distribution is defined as: \\[\nf_X(x) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp\\left(-\\frac{1}{2} \\left(\\frac{x-\\mu}{\\sigma}\\right)^2\\right),\n\\tag{6.1}\\] where: \\(\\mu\\) is the mean; \\(\\sigma\\) is the standard deviation.\nTo generate ten random numbers from a normal distribution, the following command can be used.\n\n# generate 10 random numbers between from a normal distribution\nimport numpy as np\nrng = np.random.default_rng()\nn = 10\nmu, sigma = 2, 0.1\nx = rng.normal(mu, sigma, n)\nx\n\narray([1.73474447, 1.92537873, 1.8968753 , 2.27127547, 1.96531832,\n       2.05712517, 1.83147441, 2.03311044, 2.01184184, 1.96044855])\n\n\nVerify the mean:\n\nabs(mu - np.mean(x))\n\n0.03124073048711895\n\n\nNote: To verify the standard deviation, we use ddof = 1 (empirical standard deviation):\n\nabs(sigma - np.std(x, ddof=1))\n\n0.043782979215573864\n\n\nA normally distributed random variable is a random variable whose associated probability distribution is the normal (or Gaussian) distribution. The normal distribution is a continuous probability distribution characterized by a symmetric bell-shaped curve.\nThe distribution is defined by two parameters: the mean \\(\\mu\\) and the standard deviation \\(\\sigma\\). The mean indicates the center of the distribution, while the standard deviation measures the spread or dispersion of the distribution.\nThis distribution is widely used in statistics and the natural and social sciences as a simple model for random variables with unknown distributions.\n\nplot_normal_distribution(mu=0, sigma=1, num_samples=10000)\n\n\n\n\n\n\n\n\n\n\n6.4.3 Visualization of the Standard Deviation\nThe standard deviation of normal distributed can be visualized in terms of the histogram of \\(X\\):\n\nabout 68% of the values will lie in the interval within one standard deviation of the mean\n95% lie within two standard deviation of the mean\nand 99.9% lie within 3 standard deviations of the mean.\n\n\n\n\n\n\n\n\n\n\n\n\n6.4.4 Standardization of Random Variables\nTo compare statistical properties of random variables which use different units, it is a common practice to transform these random variables into standardized variables. If a random variable \\(X\\) has expectation \\(E(X) = \\mu\\) and standard deviation \\(sd(X) = \\sigma &gt;0\\), the random variable \\[\nX^{\\ast} = (X-\\mu)/\\sigma\n\\] is called \\(X\\) in standard units. It has \\(E(X^{\\ast}) = 0\\) and \\(sd(X^{\\ast}) =1\\).\n\n\n6.4.5 Realizations of a Normal Distribution\nRealizations of a normal distribution refers to the actual values that you get when you draw samples from a normal distribution. Each sample drawn from the distribution is a realization of that distribution.\nFor example, if you have a normal distribution with a mean of 0 and a standard deviation of 1, each number you draw from that distribution is a realization.\nHere’s a Python example:\n\nimport numpy as np\n\n# Define the parameters of the normal distribution\nmu = 0\nsigma = 1\n\n# Draw 10 samples (realizations) from the normal distribution\nrealizations = np.random.normal(mu, sigma, 10)\n\nprint(realizations)\n\n[ 0.48951662  0.23879586 -0.44811181 -0.610795   -2.02994507  0.60794659\n -0.35410888  0.15258149  0.50127485 -0.78640277]\n\n\nIn this code, np.random.normal generates 10 realizations of a normal distribution with a mean of 0 and a standard deviation of 1. The realizations array contains the actual values drawn from the distribution.\n\n\n6.4.6 The Multivariate Normal Distribution\nThe multivariate normal, multinormal, or Gaussian distribution serves as a generalization of the one-dimensional normal distribution to higher dimensions. We will consider \\(k\\)-dimensional random vectors \\(X = (X_1, X_2, \\ldots, X_k)\\). When drawing samples from this distribution, it results in a set of values represented as \\(\\{x_1, x_2, \\ldots, x_k\\}\\). To fully define this distribution, it is necessary to specify its mean \\(\\mu\\) and covariance matrix \\(\\Sigma\\). These parameters are analogous to the mean, which represents the central location, and the variance (squared standard deviation) of the one-dimensional normal distribution introduced in Equation 6.1.\nIn the context of the multivariate normal distribution, the mean takes the form of a coordinate within an \\(k\\)-dimensional space. This coordinate represents the location where samples are most likely to be generated, akin to the peak of the bell curve in a one-dimensional or univariate normal distribution.\n\n\n\n\n\n\nCovariance of two random variables\n\n\n\nFor two random variables \\(X\\) and \\(Y\\), the covariance is defined as the expected value (or mean) of the product of their deviations from their individual expected values: \\[\n\\operatorname{cov}(X, Y) = \\operatorname{E}{\\big[(X - \\operatorname{E}[X])(Y - \\operatorname{E}[Y])\\big]}\n\\]\nThe covariance within the multivariate normal distribution denotes the extent to which two variables vary together. The elements of the covariance matrix, such as \\(\\Sigma_{ij}\\), represent the covariances between the variables \\(x_i\\) and \\(x_j\\). These covariances describe how the different variables in the distribution are related to each other in terms of their variability.\nThe probability density function (PDF) of the multivariate normal distribution is defined as: \\[\nf_X(x) = \\frac{1}{\\sqrt{(2\\pi)^n \\det(\\Sigma)}} \\exp\\left(-\\frac{1}{2} (x-\\mu)^T\\Sigma^{-1} (x-\\mu)\\right),\n\\] where: \\(\\mu\\) is the \\(k \\times 1\\) mean vector; \\(\\Sigma\\) is the \\(k \\times k\\) covariance matrix. The covariance matrix \\(\\Sigma\\) is assumed to be positive definite, so that its determinant is strictly positive.\nFor discrete random variables, covariance can be written as: \\[\n\\operatorname{cov} (X,Y) = \\frac{1}{n}\\sum_{i=1}^n (x_i-E(X)) (y_i-E(Y)).\n\\]\n\n\nFigure 6.1 shows draws from a bivariate normal distribution with \\(\\mu = \\begin{pmatrix}0 \\\\ 0\\end{pmatrix}\\) and \\(\\Sigma=\\begin{pmatrix} 9 & 4 \\\\ 4 & 9 \\end{pmatrix}\\).\n\nimport numpy as np\nrng = np.random.default_rng()\nimport matplotlib.pyplot as plt\nmean = [0, 0]\ncov = [[9, 4], [4, 9]]  # diagonal covariance\nx, y = rng.multivariate_normal(mean, cov, 1000).T\n# Create a scatter plot of the numbers\nplt.scatter(x, y, s=2)\nplt.axis('equal')\nplt.grid()\nplt.title(f\"Bivariate Normal. Mean zero and positive covariance: {cov}\")\nplt.show()\n\n\n\n\n\n\n\nFigure 6.1: Bivariate Normal. Mean zero and covariance \\(\\Sigma=\\begin{pmatrix} 9 & 4 \\\\ 4 & 9\\end{pmatrix}\\)\n\n\n\n\n\nThe covariance matrix of a bivariate normal distribution determines the shape, orientation, and spread of the distribution in the two-dimensional space.\nThe diagonal elements of the covariance matrix (\\(\\sigma_1^2\\), \\(\\sigma_2^2\\)) are the variances of the individual variables. They determine the spread of the distribution along each axis. A larger variance corresponds to a greater spread along that axis.\nThe off-diagonal elements of the covariance matrix (\\(\\sigma_{12}, \\sigma_{21}\\)) are the covariances between the variables. They determine the orientation and shape of the distribution. If the covariance is positive, the distribution is stretched along the line \\(y=x\\), indicating that the variables tend to increase together. If the covariance is negative, the distribution is stretched along the line \\(y=-x\\), indicating that one variable tends to decrease as the other increases. If the covariance is zero, the variables are uncorrelated and the distribution is axis-aligned.\nIn Figure 6.1, the variances are identical and the variables are correlated (covariance is 4), so the distribution is stretched along the line \\(y=x\\).\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import multivariate_normal\n\n# Parameters\nmu = np.array([0, 0])\ncov = np.array([[9, 4], [4, 9]])\n\n# Create grid and multivariate normal\nx = np.linspace(-10,10,100)\ny = np.linspace(-10,10,100)\nX, Y = np.meshgrid(x,y)\npos = np.empty(X.shape + (2,))\npos[:, :, 0] = X; pos[:, :, 1] = Y\nrv = multivariate_normal(mu, cov)\n\nfig = plt.figure()\nax = plt.axes(projection='3d')  \nsurf=ax.plot_surface(X, Y, rv.pdf(pos),cmap='viridis',linewidth=0)\nax.set_xlabel('X axis')\nax.set_ylabel('Y axis')\nax.set_zlabel('Z axis')\nax.set_title('Bivariate Normal Distribution')\nfig.colorbar(surf, shrink=0.5, aspect=10)\nplt.show()\n\n\n\n\n\n\n\nFigure 6.2: Bivariate Normal. Mean zero and covariance \\(\\Sigma=\\begin{pmatrix} 9 & 4 \\\\ 4 & 9\\end{pmatrix}\\)\n\n\n\n\n\n\n\n6.4.7 The Bivariate Normal Distribution with Mean Zero and Zero Covariances \\(\\sigma_{12} = \\sigma_{21} = 0\\)\n\\(\\Sigma=\\begin{pmatrix} 9 & 0 \\\\ 0 & 9\\end{pmatrix}\\)\n\n\n\n\n\n\n\n\nFigure 6.3: Bivariate Normal. Mean zero and covariance \\(\\Sigma=\\begin{pmatrix} 9 & 0 \\\\ 0 & 9\\end{pmatrix}\\)\n\n\n\n\n\n\n\n6.4.8 The Bivariate Normal Distribution with Mean Zero and Negative Covariances \\(\\sigma_{12} = \\sigma_{21} = -4\\)\n\\(\\Sigma=\\begin{pmatrix} 9 & -4 \\\\ -4 & 9\\end{pmatrix}\\)\n\n\n\n\n\n\n\n\nFigure 6.4: Bivariate Normal. Mean zero and covariance \\(\\Sigma=\\begin{pmatrix} 9 & -4 \\\\ -4 & 9\\end{pmatrix}\\)",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html#cholesky-decomposition-and-positive-definite-matrices",
    "href": "006_num_gp.html#cholesky-decomposition-and-positive-definite-matrices",
    "title": "6  Kriging (Gaussian Process Regression)",
    "section": "6.5 Cholesky Decomposition and Positive Definite Matrices",
    "text": "6.5 Cholesky Decomposition and Positive Definite Matrices\nThe covariance matrix must be positive definite for a multivariate normal distribution for a couple of reasons:\n\nSemidefinite vs Definite: A covariance matrix is always symmetric and positive semidefinite. However, for a multivariate normal distribution, it must be positive definite, not just semidefinite. This is because a positive semidefinite matrix can have zero eigenvalues, which would imply that some dimensions in the distribution have zero variance, collapsing the distribution in those dimensions. A positive definite matrix has all positive eigenvalues, ensuring that the distribution has positive variance in all dimensions.\nInvertibility: The multivariate normal distribution’s probability density function involves the inverse of the covariance matrix. If the covariance matrix is not positive definite, it may not be invertible, and the density function would be undefined.\n\nIn summary, the covariance matrix being positive definite ensures that the multivariate normal distribution is well-defined and has positive variance in all dimensions.\n\nimport numpy as np\n\ndef is_positive_definite(matrix):\n    return np.all(np.linalg.eigvals(matrix) &gt; 0)\n\nmatrix = np.array([[9, 4], [4, 9]])\nprint(is_positive_definite(matrix))  # Outputs: True\n\nTrue\n\n\nMore effficent (and check if symmetric) is based on Cholesky decomposition.\n\nimport numpy as np\n\ndef is_pd(K):\n    try:\n        np.linalg.cholesky(K)\n        return True\n    except np.linalg.linalg.LinAlgError as err:\n        if 'Matrix is not positive definite' in err.message:\n            return False\n        else:\n            raise\nmatrix = np.array([[9, 4], [4, 9]])\nprint(is_pd(matrix))  # Outputs: True\n\nTrue\n\n\n\n\n\n\n\n\nExample: Cholesky decomposition.\n\n\n\nlinalg.cholesky computes the Cholesky decomposition of a matrix, i.e., it computes a lower triangular matrix \\(L\\) such that \\(LL^T = A\\). If the matrix is not positive definite, an error (LinAlgError) is raised.\n\nimport numpy as np\n\n# Define a Hermitian, positive-definite matrix\nA = np.array([[9, 4], [4, 9]]) \n\n# Compute the Cholesky decomposition\nL = np.linalg.cholesky(A)\n\nprint(\"L = \\n\", L)\nprint(\"L*LT = \\n\", np.dot(L, L.T))\n\nL = \n [[3.         0.        ]\n [1.33333333 2.68741925]]\nL*LT = \n [[9. 4.]\n [4. 9.]]",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html#maximum-likelihood-estimation-multivariate-normal-distribution",
    "href": "006_num_gp.html#maximum-likelihood-estimation-multivariate-normal-distribution",
    "title": "6  Kriging (Gaussian Process Regression)",
    "section": "6.6 Maximum Likelihood Estimation: Multivariate Normal Distribution",
    "text": "6.6 Maximum Likelihood Estimation: Multivariate Normal Distribution\nConsider the first \\(n\\) terms of an identically and independently distributed (i.i..d.) sequence \\({X^{(j)}}\\) of \\(k\\)-dimensional multivariate normal random vectors, i.e., \\(X^{(j)} \\sim N(\\mu, \\Sigma)\\), \\(j=1,2,\\ldots\\). The joint probability density function of the \\(j\\)-th term of the sequence is \\[\nf_X(x_j) = \\frac{1}{\\sqrt{(2\\pi)^k \\det(\\Sigma)}} \\exp\\left(-\\frac{1}{2} (x_j-\\mu)^T\\Sigma^{-1} (x_j-\\mu)\\right),\n\\]\nwhere: \\(\\mu\\) is the \\(k \\times 1\\) mean vector; \\(\\Sigma\\) is the \\(k \\times k\\) covariance matrix. The covariance matrix \\(\\Sigma\\) is assumed to be positive definite, so that its determinant is strictly positive. We use \\(x_1, \\ldots x_n\\), i.e., the realizations of the first \\(n\\) random vectors in the sequence, to estimate the two unknown parameters \\(\\mu\\) and \\(\\Sigma\\).\nThe likelihood function is defined as the joint probability density function of the observed data, viewed as a function of the unknown parameters. Since the terms in the sequence are independent, their joint density is equal to the product of their marginal densities. As a consequence, the likelihood function can be written as the product of the individual densities:\n\\[\nL(\\mu, \\Sigma) = \\prod_{j=1}^n f_X(x_j) = \\prod_{j=1}^n \\frac{1}{\\sqrt{(2\\pi)^k \\det(\\Sigma)}} \\exp\\left(-\\frac{1}{2} (x_j-\\mu)^T\\Sigma^{-1} (x_j-\\mu)\\right)\n\\] \\[\n= \\frac{1}{(2\\pi)^{nk/2} \\det(\\Sigma)^{n/2}} \\exp\\left(-\\frac{1}{2} \\sum_{j=1}^n (x_j-\\mu)^T\\Sigma^{-1} (x_j-\\mu)\\right).\n\\] The log-likelihood function is \\[\n\\ell(\\mu, \\Sigma) = -\\frac{nk}{2} \\ln(2\\pi) - \\frac{n}{2} \\ln(\\det(\\Sigma)) - \\frac{1}{2} \\sum_{j=1}^n (x_j-\\mu)^T\\Sigma^{-1} (x_j-\\mu).\n\\] The likelihood function is well-defined only if \\(\\det(\\Sigma)&gt;0\\).",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html#introduction-to-gaussian-processes",
    "href": "006_num_gp.html#introduction-to-gaussian-processes",
    "title": "6  Kriging (Gaussian Process Regression)",
    "section": "6.7 Introduction to Gaussian Processes",
    "text": "6.7 Introduction to Gaussian Processes\nThe concept of GP (Gaussian Process) regression can be understood as a simple extension of linear modeling. It is worth noting that this approach goes by various names and acronyms, including “kriging,” a term derived from geostatistics, as introduced by Matheron in 1963. Additionally, it is referred to as Gaussian spatial modeling or a Gaussian stochastic process, and machine learning (ML) researchers often use the term Gaussian process regression (GPR). In all of these instances, the central focus is on regression. This involves training on both inputs and outputs, with the ultimate objective of making predictions and quantifying uncertainty (referred to as uncertainty quantification or UQ).\nHowever, it’s important to emphasize that GPs are not a universal solution for every problem. Specialized tools may outperform GPs in specific, non-generic contexts, and GPs have their own set of limitations that need to be considered.\n\n6.7.1 Gaussian Process Prior\nIn the context of GP, any finite collection of realizations, which is represented by \\(n\\) observations, is modeled as having a multivariate normal (MVN) distribution. The characteristics of these realizations can be fully described by two key parameters:\n\nTheir mean, denoted as an \\(n\\)-vector \\(\\mu\\).\nThe covariance matrix, denoted as an \\(n \\times n\\) matrix \\(\\Sigma\\). This covariance matrix encapsulates the relationships and variability between the individual realizations within the collection.\n\n\n\n6.7.2 Covariance Function\nThe covariance function is defined by inverse exponentiated squared Euclidean distance: \\[\n\\Sigma(\\vec{x}, \\vec{x}') = \\exp\\{ - || \\vec{x} - \\vec{x}'||^2 \\},\n\\] where \\(\\vec{x}\\) and \\(\\vec{x}'\\) are two points in the \\(k\\)-dimensional input space and \\(\\| \\cdot \\|\\) denotes the Euclidean distance, i.e., \\[\n|| \\vec{x} - \\vec{x}'||^2 = \\sum_{i=1}^k (x_i - x_i')^2.\n\\]\nAn 1-d example is shown in Figure 6.5.\n\nvisualize_inverse_exp_squared_distance(5, 0.0, [0.5, 1, 2.0])\n\n\n\n\n\n\n\nFigure 6.5: One-dim inverse exponentiated squared Euclidean distance\n\n\n\n\n\nThe covariance function is also referred to as the kernel function. The Gaussian kernel uses an additional parameter, \\(\\sigma^2\\), to control the rate of decay. This parameter is referred to as the length scale or the characteristic length scale. The covariance function is then defined as\n\\[\n\\Sigma(\\vec{x}, \\vec{x}') = \\exp\\{ - || \\vec{x} - \\vec{x}'||^2 / (2 \\sigma^2) \\}.\n\\tag{6.2}\\]\nThe covariance decays exponentially fast as \\(\\vec{x}\\) and \\(\\vec{x}'\\) become farther apart. Observe that\n\\[\n\\Sigma(\\vec{x},\\vec{x}) = 1\n\\] and\n\\[\n\\Sigma(\\vec{x}, \\vec{x}') &lt; 1\n\\] for \\(\\vec{x} \\neq \\vec{x}'\\). The function \\(\\Sigma(\\vec{x},\\vec{x}')\\) must be positive definite.\n\n\n\n\n\n\nPositive Definiteness\n\n\n\nPositive definiteness in the context of the covariance matrix \\(\\Sigma_n\\) is a fundamental requirement. It is determined by evaluating \\(\\Sigma(x_i, x_j)\\) at pairs of \\(n\\) \\(\\vec{x}\\)-values, denoted as \\(\\vec{x}_1, \\vec{x}_2, \\ldots, \\vec{x}_n\\). The condition for positive definiteness is that for all \\(\\vec{x}\\) vectors that are not equal to zero, the expression \\(\\vec{x}^\\top \\Sigma_n \\vec{x}\\) must be greater than zero. This property is essential when intending to use \\(\\Sigma_n\\) as a covariance matrix in multivariate normal (MVN) analysis. It is analogous to the requirement in univariate Gaussian distributions where the variance parameter, \\(\\sigma^2\\), must be positive.\n\n\nGaussian Processes (GPs) can be effectively utilized to generate random data that follows a smooth functional relationship. The process involves the following steps:\n\nSelect a set of \\(\\vec{x}\\)-values, denoted as \\(\\vec{x}_1, \\vec{x}_2, \\ldots, \\vec{x}_n\\).\nDefine the covariance matrix \\(\\Sigma_n\\) by evaluating \\(\\Sigma_n^{ij} = \\Sigma(\\vec{x}_i, \\vec{x}_j)\\) for \\(i, j = 1, 2, \\ldots, n\\).\nGenerate an \\(n\\)-variate realization \\(Y\\) that follows a multivariate normal distribution with a mean of zero and a covariance matrix \\(\\Sigma_n\\), expressed as \\(Y \\sim \\mathcal{N}_n(0, \\Sigma_n)\\).\nVisualize the result by plotting it in the \\(x\\)-\\(y\\) plane.\n\n\n\n6.7.3 Construction of the Covariance Matrix\nHere is an one-dimensional example. The process begins by creating an input grid using \\(\\vec{x}\\)-values. This grid consists of 100 elements, providing the basis for further analysis and visualization.\n\nimport numpy as np\nn = 100\nX = np.linspace(0, 10, n, endpoint=False).reshape(-1,1)\n\nIn the context of this discussion, the construction of the covariance matrix, denoted as \\(\\Sigma_n\\), relies on the concept of inverse exponentiated squared Euclidean distances. However, it’s important to note that a modification is introduced later in the process. Specifically, the diagonal of the covariance matrix is augmented with a small value, represented as “eps” or \\(\\epsilon\\).\nThe reason for this augmentation is that while inverse exponentiated distances theoretically ensure the covariance matrix’s positive definiteness, in practical applications, the matrix can sometimes become numerically ill-conditioned. By adding a small value to the diagonal, such as \\(\\epsilon\\), this ill-conditioning issue is mitigated. In this context, \\(\\epsilon\\) is often referred to as “jitter.”\n\nimport numpy as np\nfrom numpy import array, zeros, power, ones, exp, multiply, eye, linspace, mat, spacing, sqrt, arange, append, ravel\nfrom numpy.linalg import cholesky, solve\nfrom numpy.random import multivariate_normal\ndef build_Sigma(X, sigma2):\n    n = X.shape[0]\n    k = X.shape[1]\n    D = zeros((k, n, n))\n    for l in range(k):\n        for i in range(n):\n            for j in range(i, n):\n                D[l, i, j] = 1/(2*sigma2[l])*(X[i,l] - X[j,l])**2\n    D = sum(D)\n    D = D + D.T\n    return exp(-D)  \n\n\nsigma2 = np.array([1.0])\nSigma = build_Sigma(X, sigma2)\nnp.round(Sigma[:3,:], 3)\n\narray([[1.   , 0.995, 0.98 , 0.956, 0.923, 0.882, 0.835, 0.783, 0.726,\n        0.667, 0.607, 0.546, 0.487, 0.43 , 0.375, 0.325, 0.278, 0.236,\n        0.198, 0.164, 0.135, 0.11 , 0.089, 0.071, 0.056, 0.044, 0.034,\n        0.026, 0.02 , 0.015, 0.011, 0.008, 0.006, 0.004, 0.003, 0.002,\n        0.002, 0.001, 0.001, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   ],\n       [0.995, 1.   , 0.995, 0.98 , 0.956, 0.923, 0.882, 0.835, 0.783,\n        0.726, 0.667, 0.607, 0.546, 0.487, 0.43 , 0.375, 0.325, 0.278,\n        0.236, 0.198, 0.164, 0.135, 0.11 , 0.089, 0.071, 0.056, 0.044,\n        0.034, 0.026, 0.02 , 0.015, 0.011, 0.008, 0.006, 0.004, 0.003,\n        0.002, 0.002, 0.001, 0.001, 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   ],\n       [0.98 , 0.995, 1.   , 0.995, 0.98 , 0.956, 0.923, 0.882, 0.835,\n        0.783, 0.726, 0.667, 0.607, 0.546, 0.487, 0.43 , 0.375, 0.325,\n        0.278, 0.236, 0.198, 0.164, 0.135, 0.11 , 0.089, 0.071, 0.056,\n        0.044, 0.034, 0.026, 0.02 , 0.015, 0.011, 0.008, 0.006, 0.004,\n        0.003, 0.002, 0.002, 0.001, 0.001, 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   ]])\n\n\n\nimport matplotlib.pyplot as plt\nplt.imshow(Sigma, cmap='hot', interpolation='nearest')\nplt.colorbar()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n6.7.4 Generation of Random Samples and Plotting the Realizations of the Random Function\nIn the context of the multivariate normal distribution, the next step is to utilize the previously constructed covariance matrix denoted as Sigma. It is used as an essential component in generating random samples from the multivariate normal distribution.\nThe function multivariate_normal is employed for this purpose. It serves as a random number generator specifically designed for the multivariate normal distribution. In this case, the mean of the distribution is set equal to mean, and the covariance matrix is provided as Psi. The argument size specifies the number of realizations, which, in this specific scenario, is set to one.\nBy default, the mean vector is initialized to zero. To match the number of samples, which is equivalent to the number of rows in the X and Sigma matrices, the argument zeros(n) is used, where n represents the number of samples (here taken from the size of the matrix, e.g.,: Sigma.shape[0]).\n\nrng = np.random.default_rng(seed=12345)\nY = rng.multivariate_normal(zeros(Sigma.shape[0]), Sigma, size = 1, check_valid=\"raise\").reshape(-1,1)\nY.shape\n\n(100, 1)\n\n\nNow we can plot the results, i.e., a finite realization of the random function \\(Y()\\) under a GP prior with a particular covariance structure. We will plot those X and Y pairs as connected points on an \\(x\\)-\\(y\\) plane.\n\nimport matplotlib.pyplot as plt\nplt.plot(X, Y)\nplt.title(\"Realization of Random Functions under a GP prior.\\n sigma2: {}\".format(sigma2[0]))\nplt.show()\n\n\n\n\n\n\n\nFigure 6.6: Realization of one random function under a GP prior. sigma2: 1.0\n\n\n\n\n\n\nrng = np.random.default_rng(seed=12345)\nY = rng.multivariate_normal(zeros(Sigma.shape[0]), Sigma, size = 3, check_valid=\"raise\")\nplt.plot(X, Y.T)\nplt.title(\"Realization of Three Random Functions under a GP prior.\\n sigma2: {}\".format(sigma2[0]))\nplt.show()\n\n\n\n\n\n\n\nFigure 6.7: Realization of three random functions under a GP prior. sigma2: 1.0\n\n\n\n\n\n\n\n6.7.5 Properties of the 1d Example\n\n6.7.5.1 Several Bumps:\nIn this analysis, we observe several bumps in the \\(x\\)-range of \\([0,10]\\). These bumps in the function occur because shorter distances exhibit high correlation, while longer distances tend to be essentially uncorrelated. This leads to variations in the function’s behavior:\n\nWhen \\(x\\) and \\(x'\\) are one \\(\\sigma\\) unit apart, the correlation is \\(\\exp\\left(-\\sigma^2 / (2\\sigma^2)\\right) = \\exp(-1/2) \\approx 0.61\\), i.e., a relative high correlation.\n\\(2\\sigma\\) apart means correlation \\(\\exp(− 2^2 /2) \\approx 0.14\\), i.e., only small correlation.\n\\(4\\sigma\\) apart means correlation \\(\\exp(− 4^2 /2) \\approx 0.0003\\), i.e., nearly no correlation—variables are considered independent for almost all practical application.\n\n\n\n6.7.5.2 Smoothness:\nThe function plotted in Figure 6.6 represents only a finite realization, which means that we have data for a limited number of pairs, specifically 100 points. These points appear smooth in a tactile sense because they are closely spaced, and the plot function connects the dots with lines to create the appearance of smoothness. The complete surface, which can be conceptually extended to an infinite realization over a compact domain, is exceptionally smooth in a calculus sense due to the covariance function’s property of being infinitely differentiable.\n\n\n6.7.5.3 Scale of Two:\nRegarding the scale of the \\(Y\\) values, they have a range of approximately \\([-2,2]\\), with a 95% probability of falling within this range. In standard statistical terms, 95% of the data points typically fall within two standard deviations of the mean, which is a common measure of the spread or range of data.\n\nimport numpy as np\nfrom numpy import array, zeros, power, ones, exp, multiply, eye, linspace, mat, spacing, sqrt, arange, append, ravel\nfrom numpy.random import multivariate_normal\n\ndef build_Sigma(X, sigma2):\n    n = X.shape[0]\n    k = X.shape[1]\n    D = zeros((k, n, n))\n    for l in range(k):\n        for i in range(n):\n            for j in range(i, n):\n                D[l, i, j] = 1/(2*sigma2[l])*(X[i,l] - X[j,l])**2\n    D = sum(D)\n    D = D + D.T\n    return exp(-D)\n\ndef plot_mvn( a=0, b=10, sigma2=1.0, size=1, n=100, show=True):    \n    X = np.linspace(a, b, n, endpoint=False).reshape(-1,1)\n    sigma2 = np.array([sigma2])\n    Sigma = build_Sigma(X, sigma2)\n    rng = np.random.default_rng(seed=12345)\n    Y = rng.multivariate_normal(zeros(Sigma.shape[0]), Sigma, size = size, check_valid=\"raise\")\n    plt.plot(X, Y.T)\n    plt.title(\"Realization of Random Functions under a GP prior.\\n sigma2: {}\".format(sigma2[0]))\n    if show:\n        plt.show()\n\n\nplot_mvn(a=0, b=10, sigma2=10.0, size=3, n=250)\n\n\n\n\n\n\n\nFigure 6.8: Realization of Random Functions under a GP prior. sigma2: 10\n\n\n\n\n\n\nplot_mvn(a=0, b=10, sigma2=0.1, size=3, n=250)\n\n\n\n\n\n\n\nFigure 6.9: Realization of Random Functions under a GP prior. sigma2: 0.1",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html#kriging-modeling-basics",
    "href": "006_num_gp.html#kriging-modeling-basics",
    "title": "6  Kriging (Gaussian Process Regression)",
    "section": "6.8 Kriging: Modeling Basics",
    "text": "6.8 Kriging: Modeling Basics\n\n6.8.1 The Kriging Idea in a Nutshell\nWe consider observed data of an unknown function \\(f\\) at \\(n\\) points \\(x_1, \\ldots, x_n\\), see Figure 6.10. These measurements a considered as realizations of MVN random variables \\(Y_1, \\ldots, Y_n\\) with mean \\(\\mu\\) and covariance matrix \\(\\Sigma_n\\) as shown in Figure 6.7, Figure 6.8 or Figure 6.9. In Kriging, a more general covariance matrix (or equivalently, a correlation matrix \\(\\Psi\\)) is used, see Equation 6.3. Using a maximum likelihood approach, we can estimate the unknown parameters \\(\\mu\\) and \\(\\Sigma_n\\) from the data so that the likelihood function is maximized.\n\n\n\n\n\n\n\n\nFigure 6.10: Eight measurements of an unknown function\n\n\n\n\n\n\n\n6.8.2 The Kriging Basis Function\n\\(k\\)-dimensional basis functions of the form \\[\n\\psi(\\vec{x}^{(i)}, \\vec{x}^{(j)}) = \\exp \\left( - \\sum_{l=1}^k \\theta_l | x_{l}^{(i)} - x_{l}^{(j)} | ^{p_l} \\right)\n\\tag{6.3}\\] are used in a method known as Kriging. Note, \\(\\vec{x}^{(i)}\\) denotes the \\(k\\)-dim vector \\(\\vec{x}^{(i)}= (x_1^{(i)}, \\ldots, x_k^{(i)})^T\\).\nThe Kriging basis function is related to the 1-dim Gaussian basis function (Equation 6.2), which is defined as \\[\n\\Sigma(\\vec{x}^{(i)}, \\vec{x}^{(j)}) = \\exp\\{ - || \\vec{x}^{(i)} - \\vec{x}^{(j)}||^2 / (2\\sigma^2) \\}.\n\\tag{6.4}\\]\nThere are some differences between Gaussian basis functions and Kriging basis functions:\n\nWhere the Gaussian basis function has \\(1/(2\\sigma^2)\\), the Kriging basis has a vector \\(\\theta = [\\theta_1, \\theta_2, \\ldots, \\theta_k]^T\\).\nThe \\(\\theta\\) vector allows the width of the basis function to vary from dimension to dimension.\nIn the Gaussian basis function, the exponent is fixed at 2, Kriging allows this exponent \\(p_l\\) to vary (typically from 1 to 2).\n\n\n\n6.8.3 The Correlation Coefficient\nIn a bivariate normal distribution, the covariance matrix and the correlation coefficient are closely related. The covariance matrix \\(\\Sigma\\) for a bivariate normal distribution is a \\(2\\times 2\\) matrix that looks like this:\n\\[\n\\Sigma =\n\\begin{pmatrix}\n\\sigma_1^2 & \\sigma_{12}\\\\\n\\sigma_{21} & \\sigma_2^2\n\\end{pmatrix},\n\\] where \\(\\sigma_1^2\\) and \\(\\sigma_2^2\\) are the variances of \\(X_1\\) and \\(X_2\\), and \\(\\sigma_{12} = \\sigma_{21}\\) is the covariance between \\(X_1\\) and \\(X_2\\).\nThe correlation coefficient, often denoted as \\(\\rho\\), is a normalized measure of the linear relationship between two variables. It is calculated from the covariance and the standard deviations \\(\\sigma_1\\) and \\(\\sigma_2\\) (or the square roots of the variances) of \\(X_1\\) and \\(X_2\\) as follows: \\[\n\\rho = \\sigma_{12} / (\\sqrt{\\sigma_1^2} \\times \\sqrt{\\sigma_2^2}) = \\sigma_{12} / (\\sigma_1 \\times \\sigma_2).\n\\]\nSo we can express the correlation coefficient \\(\\rho\\) in terms of the elements of the covariance matrix \\(\\Sigma\\). It can be interpreted as follows: The correlation coefficient ranges from -1 to 1. A value of 1 means that \\(X_1\\) and \\(X_2\\) are perfectly positively correlated, a value of -1 means they are perfectly negatively correlated, and a value of 0 means they are uncorrelated. This gives the same information as the covariance, but on a standardized scale that does not depend on the units of \\(X_1\\) and \\(X_2\\).\n\n\n6.8.4 Covariance Matrix and Correlation Matrix\n\n\n\n\n\n\nCovariance and Correlation (taken from Forrester, Sóbester, and Keane (2008))\n\n\n\nCovariance is a measure of the correlation between two or more sets of random variables.\n\\[\n\\text{Cov}(X,Y) = E[(X - E[X])(Y - E[Y])] = E[XY] - E[X]E[Y]\n\\]\nFrom the covariance, we can derive the correlation\n\\[\n\\text{Corr}(X,Y) = \\frac{\\text{Cov}(X,Y)}{\\sqrt{\\text{Var}(X)\\text{Var}(Y)}} = \\frac{\\text{Cov}(X,Y)}{\\sigma_X\\sigma_Y}.\n\\tag{6.5}\\]\nFor a vector of random variables\n\\[\nY =\n\\begin{pmatrix}\n(Y^{(l)}, \\ldots, Y^{(n)})\n\\end{pmatrix}^T\n\\]\nthe covariance matrix is a matrix of covariances between the random variables\n\\[\n\\Sigma =\n\\text{Cov}(Y, Y) =\n\\begin{pmatrix}\n\\text{Cov}(Y^{(1)}, Y^{(1)}) & \\ldots & \\text{Cov}(Y^{(1)}, Y^{(n)}) \\\\\n\\vdots & \\ddots & \\vdots \\\\\n\\text{Cov}(Y^{(n)}, Y^{(1)}) & \\ldots & \\text{Cov}(Y^{(n)}, Y^{(n)})\n\\end{pmatrix},\n\\]\nand from Equation 6.5\n\\[\n\\text{Cov}(Y, Y) = \\sigma_Y^2 \\text{Cor}(Y, Y).\n\\]\n\n\nYou can compute the correlation matrix \\(\\Psi\\) from a covariance matrix \\(\\Sigma\\) in Python using the numpy library. The correlation matrix is computed by dividing each element of the covariance matrix by the product of the standard deviations of the corresponding variables.\nThe function covariance_to_correlation first computes the standard deviations of the variables with np.sqrt(np.diag(cov)). It then computes the correlation matrix by dividing each element of the covariance matrix by the product of the standard deviations of the corresponding variables with cov / np.outer(std_devs, std_devs).\n\nimport numpy as np\n\ndef covariance_to_correlation(cov):\n    # Compute standard deviations\n    std_devs = np.sqrt(np.diag(cov))\n    \n    # Compute correlation matrix\n    corr = cov / np.outer(std_devs, std_devs)\n    \n    return corr\n\ncov = np.array([[9, -4], [-4, 9]])\nprint(covariance_to_correlation(cov))\n\n[[ 1.         -0.44444444]\n [-0.44444444  1.        ]]\n\n\n\n\n6.8.5 The Kriging Model\nConsider sample data \\(\\vec{X}\\) and \\(\\vec{y}\\) from \\(n\\) locations that are available in matrix form: \\(\\vec{X}\\) is a \\((n \\times k)\\) matrix, where \\(k\\) denotes the problem dimension and \\(\\vec{y}\\) is a \\((n\\times 1)\\) vector.\nThe observed responses \\(\\vec{y}\\) are considered as if they are from a stochastic process, which will be denoted as \\[\n\\begin{pmatrix}\n\\vec{Y}(\\vec{x}^{(1)})\\\\\n\\vdots\\\\\n\\vec{Y}(\\vec{x}^{(n)})\\\\\n\\end{pmatrix}.\n\\]\nThe set of random vectors (also referred to as a random field) has a mean of \\(\\vec{1} \\mu\\), which is a \\((n\\times 1)\\) vector.\n\n\n6.8.6 Correlations\nThe random vectors are correlated with each other using the basis function expression from Equation 6.3: \\[\n\\text{cor} \\left(\\vec{Y}(\\vec{x}^{(i)}),\\vec{Y}(\\vec{x}^{(l)}) \\right) = \\exp\\left\\{ - \\sum_{j=1}^k \\theta_j |x_j^{(i)} - x_j^{(l)} |^{p_j}\\right\\}.\n\\]\nThe \\((n \\times n)\\) correlation matrix of the observed sample data is\n\\[\n\\vec{\\Psi} = \\begin{pmatrix}\n\\text{cor}\\left(\n\\vec{Y}(\\vec{x}^{(i)}),\n\\vec{Y}(\\vec{x}^{(l)})\n\\right) & \\ldots &\n\\text{cor}\\left(\n\\vec{Y}(\\vec{x}^{(i)}),\n\\vec{Y}(\\vec{x}^{(l)})\n\\right)\\\\\n\\vdots  & \\vdots &  \\vdots\\\\\n\\text{cor}\\left(\n\\vec{Y}(\\vec{x}^{(i)}),\n\\vec{Y}(\\vec{x}^{(l)})\n\\right)&\n\\ldots &\n\\text{cor}\\left(\n\\vec{Y}(\\vec{x}^{(i)}),\n\\vec{Y}(\\vec{x}^{(l)})\n\\right)\n\\end{pmatrix}.\n\\]\nNote: correlations depend on the absolute distances between sample points \\(|x_j^{(n)} - x_j^{(n)}|\\) and the parameters \\(p_j\\) and \\(\\theta_j\\).\nCorrelation is intuitive, because when two points move close together, then \\(|x_l^{(i)} - x_l| \\to 0\\) and \\(\\exp(-|x_l^{(i)} - x_l| \\to 1\\), points show very close correlation and \\(Y(x_l^{(i)}) = Y(x_l)\\).\n\\(\\theta\\) can be seen as a width parameter:\n\nlow \\(\\theta_j\\) means that all points will have a high correlation, with \\(Y(x_j)\\) being similar across the sample.\nhigh \\(\\theta_j\\) means that there is a significant difference between the \\(Y(x_j)\\)’s.\n\\(\\theta_j\\) is a measure of how active the function we are approximating is.\nHigh \\(\\theta_j\\) indicate important parameters, see Figure 6.11.\n\n\nvisualize_inverse_exp_squared_distance(5, 0, theta_values=[0.5, 1, 2.0])\n\n\n\n\n\n\n\nFigure 6.11: Theta set to 1/2, 1, and 2\n\n\n\n\n\n\n\n\n\n\n\nExample: The Correlation Matrix (Detailed Computation)\n\n\n\nLet \\(n=4\\) and \\(k=3\\). The sample plan is represented by the following matrix \\(X\\): \\[\nX = \\begin{pmatrix} x_{11} & x_{12} & x_{13}\\\\\nx_{21} & x_{22} & x_{23}\\\\\nx_{31} & x_{32} & x_{33}\\\\\nx_{41} & x_{42} & x_{43}\\\\\n\\end{pmatrix}\n\\]\nTo compute the elements of the matrix \\(\\Psi\\), the following \\(k\\) (one for each of the \\(k\\) dimensions) \\((n,n)\\)-matrices have to be computed: \\[\nD_1 = \\begin{pmatrix} x_{11} - x_{11} & x_{11} - x_{21} & x_{11} -x_{31} & x_{11} - x_{41} \\\\  x_{21} - x_{11} & x_{21} - x_{21} & x_{21} -x_{31} & x_{21} - x_{41} \\\\ x_{31} - x_{11} & x_{31} - x_{21} & x_{31} -x_{31} & x_{31} - x_{41} \\\\ x_{41} - x_{11} & x_{41} - x_{21} & x_{41} -x_{31} & x_{41} - x_{41} \\\\\n\\end{pmatrix}\n\\]\n\\[\nD_2 = \\begin{pmatrix} x_{12} - x_{12} & x_{12} - x_{22} & x_{12} -x_{32} & x_{12} - x_{42} \\\\  x_{22} - x_{12} & x_{22} - x_{22} & x_{22} -x_{32} & x_{22} - x_{42} \\\\ x_{32} - x_{12} & x_{32} - x_{22} & x_{32} -x_{32} & x_{32} - x_{42} \\\\ x_{42} - x_{12} & x_{42} - x_{22} & x_{42} -x_{32} & x_{42} - x_{42} \\\\\n\\end{pmatrix}\n\\]\n\\[\nD_3 = \\begin{pmatrix} x_{13} - x_{13} & x_{13} - x_{23} & x_{13} -x_{33} & x_{13} - x_{43} \\\\  x_{23} - x_{13} & x_{23} - x_{23} & x_{23} -x_{33} & x_{23} - x_{43} \\\\ x_{33} - x_{13} & x_{33} - x_{23} & x_{33} -x_{33} & x_{33} - x_{43} \\\\ x_{43} - x_{13} & x_{43} - x_{23} & x_{43} -x_{33} & x_{43} - x_{43} \\\\\\end{pmatrix}\n\\]\nSince the matrices are symmetric and the main diagonals are zero, it is sufficient to compute the following matrices: \\[\nD_1 = \\begin{pmatrix} 0 & x_{11} - x_{21} & x_{11} -x_{31} & x_{11} - x_{41} \\\\  0 &  0 & x_{21} -x_{31} & x_{21} - x_{41} \\\\ 0 & 0 & 0 & x_{31} - x_{41} \\\\ 0 & 0 & 0 & 0 \\\\\\end{pmatrix}\n\\] \\[\nD_2 = \\begin{pmatrix} 0 & x_{12} - x_{22} & x_{12} -x_{32} & x_{12} - x_{42} \\\\  0 & 0 & x_{22} -x_{32} & x_{22} - x_{42} \\\\ 0 & 0 & 0 & x_{32} - x_{42} \\\\ 0 & 0 & 0 & 0 \\\\\n\\end{pmatrix}\n\\]\n\\[\nD_3 = \\begin{pmatrix} 0 & x_{13} - x_{23} & x_{13} -x_{33} & x_{13} - x_{43} \\\\  0 & 0 & x_{23} -x_{33} & x_{23} - x_{43} \\\\ 0 & 0 & 0 & x_{33} - x_{43} \\\\ 0 & 0 & 0 & 0 \\\\\\end{pmatrix}\n\\]\nWe will consider \\(p_l=2\\). The differences will be squared and multiplied by \\(\\theta_i\\), i.e.:\n\\[\nD_1 = \\theta_1 \\begin{pmatrix} 0 & (x_{11} - x_{21})^2 & (x_{11} -x_{31})^2 & (x_{11} - x_{41})^2 \\\\  0 &  0 & (x_{21} -x_{31})^2 & (x_{21} - x_{41})^2 \\\\ 0 & 0 & 0 & (x_{31} - x_{41})^2 \\\\ 0 & 0 & 0 & 0 \\\\\\end{pmatrix}\n\\]\n\\[\nD_2 = \\theta_2 \\begin{pmatrix} 0 & (x_{12} - x_{22})^2 & (x_{12} -x_{32})^2 & (x_{12} - x_{42})^2 \\\\  0 & 0 & (x_{22} -x_{32})^2 & (x_{22} - x_{42})^2 \\\\ 0 & 0 & 0 & (x_{32} - x_{42})^2 \\\\ 0 & 0 & 0 & 0 \\\\\\end{pmatrix}\n\\]\n\\[\nD_3 = \\theta_3 \\begin{pmatrix} 0 & (x_{13} - x_{23})^2 & (x_{13} -x_{33})^2 & (x_{13} - x_{43})^2 \\\\  0 & 0 & (x_{23} -x_{33})^2 & (x_{23} - x_{43})^2 \\\\ 0 & 0 & 0 & (x_{33} - x_{43})^2 \\\\ 0 & 0 & 0 & 0 \\\\\\end{pmatrix}\n\\]\nThe sum of the three matrices \\(D=D_1+ D_2 + D_3\\) will be calculated next:\n\\[\n\\begin{pmatrix} 0 &\n\\theta_1  (x_{11} - x_{21})^2 + \\theta_2 (x_{12} - x_{22})^2 + \\theta_3  (x_{13} - x_{23})^2  &\n\\theta_1 (x_{11} -x_{31})^2 + \\theta_2  (x_{12} -x_{32})^2 + \\theta_3  (x_{13} -x_{33})^2 &\n\\theta_1  (x_{11} - x_{41})^2 + \\theta_2  (x_{12} - x_{42})^2 + \\theta_3 (x_{13} - x_{43})^2\n\\\\  0 &  0 &\n\\theta_1  (x_{21} -x_{31})^2 + \\theta_2 (x_{22} -x_{32})^2 + \\theta_3  (x_{23} -x_{33})^2 &\n\\theta_1  x_{21} - x_{41})^2 + \\theta_2  (x_{22} - x_{42})^2 + \\theta_3 (x_{23} - x_{43})^2\n\\\\ 0 & 0 & 0 &\n\\theta_1 (x_{31} - x_{41})^2 + \\theta_2 (x_{32} - x_{42})^2 + \\theta_3 (x_{33} - x_{43})^2\n\\\\ 0 & 0 & 0 & 0 \\\\\\end{pmatrix}\n\\]\nFinally, \\[ \\Psi = \\exp(-D)\\] is computed.\nNext, we will demonstrate how this computation can be implemented in Python.\n\nfrom numpy import (array, zeros, power, ones, exp, multiply,\n                    eye, linspace, mat, spacing, sqrt, arange,\n                    append, ravel)\nfrom numpy.linalg import cholesky, solve\ntheta = np.array([1,2,3])\nX = np.array([ [1,0,0], [0,1,0], [100, 100, 100], [101, 100, 100]])\nX\n\narray([[  1,   0,   0],\n       [  0,   1,   0],\n       [100, 100, 100],\n       [101, 100, 100]])\n\n\n\ndef build_Psi(X, theta):\n    n = X.shape[0]\n    k = X.shape[1]\n    D = zeros((k, n, n))\n    for l in range(k):\n        for i in range(n):\n            for j in range(i, n):\n                D[l, i, j] = theta[l]*(X[i,l] - X[j,l])**2\n    D = sum(D)\n    D = D + D.T\n    return exp(-D)  \n\n\nPsi = build_Psi(X, theta)\nPsi\n\narray([[1.        , 0.04978707, 0.        , 0.        ],\n       [0.04978707, 1.        , 0.        , 0.        ],\n       [0.        , 0.        , 1.        , 0.36787944],\n       [0.        , 0.        , 0.36787944, 1.        ]])\n\n\n\n\n\n\n\n\n\n\nExample: The Correlation Matrix (Using Existing Functions)\n\n\n\nThe same result as computed in the previous example can be obtained with existing python functions, e.g., from the package scipy.\n\nfrom scipy.spatial.distance import squareform\nfrom scipy.spatial.distance import pdist\n\ndef build_Psi(X, theta, eps=sqrt(spacing(1))):\n    return exp(- squareform(pdist(X,\n                            metric='sqeuclidean',\n                            out=None,\n                            w=theta))) +  multiply(eye(X.shape[0]),\n                                                   eps)\n\nPsi = build_Psi(X, theta, eps=.0)\nPsi\n\narray([[1.        , 0.04978707, 0.        , 0.        ],\n       [0.04978707, 1.        , 0.        , 0.        ],\n       [0.        , 0.        , 1.        , 0.36787944],\n       [0.        , 0.        , 0.36787944, 1.        ]])\n\n\n\n\n\n\n6.8.7 The Condition Number\nA small value, eps, can be passed to the function build_Psi to improve the condition number. For example, eps=sqrt(spacing(1)) can be used. The numpy function spacing() returns the distance between a number and its nearest adjacent number.\nThe condition number of a matrix is a measure of its sensitivity to small changes in its elements. It is used to estimate how much the output of a function will change if the input is slightly altered.\nA matrix with a low condition number is well-conditioned, which means its behavior is relatively stable, while a matrix with a high condition number is ill-conditioned, meaning its behavior is unstable with respect to numerical precision.\n\nimport numpy as np\n\n# Define a well-conditioned matrix (low condition number)\nA = np.array([[1, 0.1], [0.1, 1]])\nprint(\"Condition number of A: \", np.linalg.cond(A))\n\n# Define an ill-conditioned matrix (high condition number)\nB = np.array([[1, 0.99999999], [0.99999999, 1]])\nprint(\"Condition number of B: \", np.linalg.cond(B))\n\nCondition number of A:  1.2222222222222225\nCondition number of B:  200000000.53159264\n\n\n\nnp.linalg.cond(Psi)\n\n2.163953413738652\n\n\n\n\n6.8.8 MLE to estimate \\(\\theta\\) and \\(p\\)\nWe know what the correlations mean, but how do we estimate the values of \\(\\theta_j\\) and where does our observed data \\(y\\) come in? To estimate the values of \\(\\vec{\\theta}\\) and \\(\\vec{p}\\), they are chosen to maximize the likelihood of \\(\\vec{y}\\), which can be expressed in terms of the sample data \\[L\\left(\\vec{Y}(\\vec{x}^{(1)}), \\ldots, \\vec{Y}(\\vec{x}^{(n)}) | \\mu, \\sigma \\right) = \\frac{1}{(2\\pi \\sigma)^{n/2} |\\vec{\\Psi}|^{1/2}} \\exp\\left\\{ \\frac{-(\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1}(\\vec{y} - \\vec{1}\\mu) }{2 \\sigma^2}\\right\\},\\] and formulated as the log-likelihood: \\[\\ln(L) = - \\frac{n}{2} \\ln(2\\pi \\sigma) - \\frac{1}{2} \\ln |\\vec{\\Psi}| \\frac{-(\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1}(\\vec{y} - \\vec{1}\\mu) }{2 \\sigma^2}.\\]\nOptimization of the log-likelihood by taking derivatives with respect to \\(\\mu\\) and \\(\\sigma\\) results in \\[\\hat{\\mu} = \\frac{\\vec{1}^T \\vec{\\Psi}^{-1} \\vec{y}^T}{\\vec{1}^T \\vec{\\Psi}^{-1} \\vec{1}^T}\\] and \\[\\hat{\\sigma} = \\frac{(\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1}(\\vec{y} - \\vec{1}\\mu)}{n}.\\]\nCombining the equations leads to the concentrated log-likelihood: \\[\\ln(L) = - \\frac{n}{2} \\ln(\\hat{\\sigma}) - \\frac{1}{2} \\ln |\\vec{\\Psi}|. \\tag{6.6}\\]\n\n\n\n\n\n\nNote: The Concentrated Log-Likelihood\n\n\n\n\nThe first term in Equation 6.6 requires information about the measured point (observations) \\(y_i\\).\nTo maximize \\(\\ln(L)\\), optimal values of \\(\\vec{\\theta}\\) and \\(\\vec{p}\\) are determined numerically, because the equation is not differentiable.\n\n\n\n\n\n6.8.9 Tuning \\(\\theta\\) and \\(p\\)\nOptimizers such as Nelder-Mead, Conjugate Gradient, or Simulated Annealing can be used to determine optimal values for \\(\\theta\\) and \\(p\\). After the optimization, the correlation matrix \\(\\Psi\\) is build with the optimized \\(\\theta\\) and \\(p\\) values. This is best (most likely) Kriging model for the given data \\(y\\).",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html#kriging-prediction",
    "href": "006_num_gp.html#kriging-prediction",
    "title": "6  Kriging (Gaussian Process Regression)",
    "section": "6.9 Kriging Prediction",
    "text": "6.9 Kriging Prediction\n\n6.9.1 The Augmented Correlation Matrix\nWe will use the Kriging correlation \\(\\Psi\\) to predict new values based on the observed data. The matrix algebra involved for calculating the likelihood is the most computationally intensive part of the Kriging process. Care must be taken that the computer code is as efficient as possible.\nBasic elements of the Kriging based surrogate optimization such as interpolation, expected improvement, and regression are presented. The presentation follows the approach described in Forrester, Sóbester, and Keane (2008) and Bartz et al. (2022).\nMain idea for prediction is that the new \\(Y(\\vec{x})\\) should be consistent with the old sample data \\(X\\). For a new prediction \\(\\hat{y}\\) at \\(\\vec{x}\\), the value of \\(\\hat{y}\\) is chosen so that it maximizes the likelihood of the sample data \\(\\vec{X}\\) and the prediction, given the (optimized) correlation parameter \\(\\vec{\\theta}\\) and \\(\\vec{p}\\) from above. The observed data \\(\\vec{y}\\) is augmented with the new prediction \\(\\hat{y}\\) which results in the augmented vector \\(\\vec{\\tilde{y}} = ( \\vec{y}^T, \\hat{y})^T\\). A vector of correlations between the observed data and the new prediction is defined as\n\\[ \\vec{\\psi} = \\begin{pmatrix}\n\\text{cor}\\left(\n\\vec{Y}(\\vec{x}^{(1)}),\n\\vec{Y}(\\vec{x})\n\\right) \\\\\n\\vdots  \\\\\n\\text{cor}\\left(\n\\vec{Y}(\\vec{x}^{(n)}),\n\\vec{Y}(\\vec{x})\n\\right)\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\vec{\\psi}^{(1)}\\\\\n\\vdots\\\\\n\\vec{\\psi}^{(n)}\n\\end{pmatrix}.\n\\] The augmented correlation matrix is constructed as \\[ \\tilde{\\vec{\\Psi}} =\n\\begin{pmatrix}\n\\vec{\\Psi} & \\vec{\\psi} \\\\\n\\vec{\\psi}^T & 1\n\\end{pmatrix}.\n\\]\nThe log-likelihood of the augmented data is \\[\n\\ln(L) = - \\frac{n}{2} \\ln(2\\pi) - \\frac{n}{2} \\ln(\\hat{\\sigma}^2) - \\frac{1}{2} \\ln |\\vec{\\hat{\\Psi}}| -  \\frac{(\\vec{\\tilde{y}} - \\vec{1}\\hat{\\mu})^T \\vec{\\tilde{\\Psi}}^{-1}(\\vec{\\tilde{y}} - \\vec{1}\\hat{\\mu})}{2 \\hat{\\sigma}^2}.\n\\]\nThe MLE for \\(\\hat{y}\\) can be calculated as \\[\n\\hat{y}(\\vec{x}) = \\hat{\\mu} + \\vec{\\psi}^T \\vec{\\tilde{\\Psi}}^{-1} (\\vec{y} - \\vec{1}\\hat{\\mu}).\n\\tag{6.7}\\]\n\n\n6.9.2 Properties of the Predictor\nEquation 6.7 reveals two important properties of the Kriging predictor:\n\nBasis functions: The basis function impacts the vector \\(\\vec{\\psi}\\), which contains the \\(n\\) correlations between the new point \\(\\vec{x}\\) and the observed locations. Values from the \\(n\\) basis functions are added to a mean base term \\(\\mu\\) with weightings \\(\\vec{w} = \\vec{\\tilde{\\Psi}}^{(-1)} (\\vec{y} - \\vec{1}\\hat{\\mu})\\).\nInterpolation: The predictions interpolate the sample data. When calculating the prediction at the \\(i\\)th sample point, \\(\\vec{x}^{(i)}\\), the \\(i\\)th column of \\(\\vec{\\Psi}^{-1}\\) is \\(\\vec{\\psi}\\), and \\(\\vec{\\psi}  \\vec{\\Psi}^{-1}\\) is the \\(i\\)th unit vector. Hence, \\(\\hat{y}(\\vec{x}^{(i)}) = y^{(i)}\\).",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html#kriging-example-sinusoid-function",
    "href": "006_num_gp.html#kriging-example-sinusoid-function",
    "title": "6  Kriging (Gaussian Process Regression)",
    "section": "6.10 Kriging Example: Sinusoid Function",
    "text": "6.10 Kriging Example: Sinusoid Function\nToy example in 1d where the response is a simple sinusoid measured at eight equally spaced \\(x\\)-locations in the span of a single period of oscillation.\n\n6.10.1 Calculating the Correlation Matrix \\(\\Psi\\)\nThe correlation matrix \\(\\Psi\\) is based on the pairwise squared distances between the input locations. Here we will use \\(n=8\\) sample locations and \\(\\theta\\) is set to 1.0.\n\nn = 8\nX = np.linspace(0, 2*np.pi, n, endpoint=False).reshape(-1,1)\n# theta should be an array (of one value, for the moment, will be changed later)\ntheta = np.array([1.0])\nPsi = build_Psi(X, theta)\n\nEvaluate at sample points\n\ny = np.sin(X)\n\n\nimport matplotlib.pyplot as plt\nplt.plot(X, y, \"bo\")\nplt.title(f\"Sin(x) evaluated at {n} points\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n6.10.2 Computing the \\(\\psi\\) Vector\nDistances between testing locations \\(x\\) and training data locations \\(X\\).\n\nfrom scipy.spatial.distance import cdist\n\ndef build_psi(X, x, theta, eps=sqrt(spacing(1))):\n    n = X.shape[0]\n    k = X.shape[1]\n    m = x.shape[0]\n    psi = zeros((n, m))\n    theta = theta * ones(k)\n    D = zeros((n, m))\n    D = cdist(x.reshape(-1, k),\n              X.reshape(-1, k),\n              metric='sqeuclidean',\n              out=None,\n              w=theta)\n    print(D.shape)\n    psi = exp(-D)\n    # return psi transpose to be consistent with the literature\n    return(psi.T)\n\n\n\n6.10.3 Predicting at New Locations\nWe would like to predict at \\(m = 100\\) new locations in the interval \\([0, 2\\pi]\\). The new locations are stored in the variable x.\n\nm = 100\nx = np.linspace(0, 2*np.pi, m, endpoint=False).reshape(-1,1)\npsi = build_psi(X, x, theta)\n\n(100, 8)\n\n\nComputation of the predictive equations.\n\nU = cholesky(Psi).T\none = np.ones(n).reshape(-1,1)\nmu = (one.T.dot(solve(U, solve(U.T, y)))) / one.T.dot(solve(U, solve(U.T, one)))\nf = mu * ones(m).reshape(-1,1) + psi.T.dot(solve(U, solve(U.T, y - one * mu)))\n\nTo compute \\(f\\), Equation 6.7 is used.\n\n\n6.10.4 Visualization\n\nimport matplotlib.pyplot as plt\nplt.plot(x, f, color = \"orange\", label=\"Fitted\")\nplt.plot(x, np.sin(x), color = \"grey\", label=\"Original\")\nplt.plot(X, y, \"bo\", label=\"Measurements\")\nplt.title(\"Kriging prediction of sin(x) with {} points.\\n theta: {}\".format(n, theta[0]))\nplt.legend(loc='upper right')\nplt.show()",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html#cholesky-example-with-two-points",
    "href": "006_num_gp.html#cholesky-example-with-two-points",
    "title": "6  Kriging (Gaussian Process Regression)",
    "section": "6.11 Cholesky Example With Two Points",
    "text": "6.11 Cholesky Example With Two Points\n\n6.11.1 Cholesky Decomposition\nWe consider \\(k=1\\) and \\(n=2\\) sample points. The sample points are located at \\(x_1=1\\) and \\(x_2=5\\). The response values are \\(y_1=2\\) and \\(y_2=10\\). The correlation parameter is \\(\\theta=1\\) and \\(p\\) is set to \\(1\\). Using Equation 6.3, we can compute the correlation matrix \\(\\Psi\\):\n\\[\n\\Psi = \\begin{pmatrix}\n1 & e^{-1}\\\\\ne^{-1} & 1\n\\end{pmatrix}.\n\\]\nTo determine MLE as in Equation 6.7, we need to compute \\(\\Psi^{-1}\\):\n\\[\n\\Psi^{-1} = \\frac{e}{e^2 -1} \\begin{pmatrix}\ne & -1\\\\\n-1 & e\n\\end{pmatrix}.\n\\]\nCholesky-decomposition of \\(\\Psi\\) is recommended to compute \\(\\Psi^{-1}\\). Cholesky decomposition is a decomposition of a positive definite symmetric matrix into the product of a lower triangular matrix \\(L\\), a diagonal matrix \\(D\\) and the transpose of \\(L\\), which is denoted as \\(L^T\\). Consider the following example:\n\\[\nLDL^T=\n\\begin{pmatrix}\n1 & 0 \\\\\nl_{21} & 1\n\\end{pmatrix}\n\\begin{pmatrix}\nd_{11} & 0 \\\\\n0 & d_{22}\n\\end{pmatrix}\n\\begin{pmatrix}\n1 & l_{21} \\\\\n0 & 1\n\\end{pmatrix}=\n\\]\n\\[\n\\begin{pmatrix}\nd_{11} & 0 \\\\\nd_{11} l_{21} & d_{22}\n\\end{pmatrix}\n\\begin{pmatrix}\n1 & l_{21} \\\\\n0 & 1\n\\end{pmatrix}\n=\n\\begin{pmatrix}\nd_{11} & d_{11} l_{21} \\\\\nd_{11} l_{21} & d_{11} l_{21}^2 + d_{22}\n\\end{pmatrix}.\n\\tag{6.8}\\]\nUsing Equation 6.8, we can compute the Cholesky decomposition of \\(\\Psi\\):\n\n\\(d_{11} = 1\\),\n\\(l_{21}d_{11} = e^{-1} \\Rightarrow l_{21} = e^{-1}\\), and\n\\(d_{11} l_{21}^2 + d_{22} = 1 \\Rightarrow d_{22} = 1 - e^{-2}\\).\n\nThe Cholesky decomposition of \\(\\Psi\\) is \\[\n\\Psi = \\begin{pmatrix}\n1 & 0\\\\\ne^{-1} & 1\\\\\n\\end{pmatrix}\n\\begin{pmatrix}\n1 & 0\\\\\n0 & 1 - e^{-2}\\\\\n\\end{pmatrix}\n\\begin{pmatrix}\n1 & e^{-1}\\\\\n0 & 1\\\\\n\\end{pmatrix}\n= LDL^T\\]\nSome programs use \\(U\\) instead of \\(L\\). The Cholesky decomposition of \\(\\Psi\\) is \\[\n\\Psi = LDL^T = U^TDU.\n\\]\nUsing \\[\n\\sqrt{D} =\\begin{pmatrix}\n1 & 0\\\\\n0 & \\sqrt{1 - e^{-2}}\\\\\n\\end{pmatrix},\n\\] we can write the Cholesky decomposition of \\(\\Psi\\) without a diagonal matrix \\(D\\) as \\[\n\\Psi = \\begin{pmatrix}\n1 & 0\\\\\ne^{-1} & \\sqrt{1 - e^{-2}}\\\\\n\\end{pmatrix}\n\\begin{pmatrix}\n1 & e^{-1}\\\\\n0 & \\sqrt{1 - e^{-2}}\\\\\n\\end{pmatrix}\n= U^TU.\n\\]\n\n\n6.11.2 Computation of the Inverse Matrix\nTo compute the inverse of a matrix using the Cholesky decomposition, you can follow these steps:\n\nDecompose the matrix \\(A\\) into \\(L\\) and \\(L^T\\), where \\(L\\) is a lower triangular matrix and \\(L^T\\) is the transpose of \\(L\\).\nCompute \\(L^{-1}\\), the inverse of \\(L\\).\nThe inverse of \\(A\\) is then \\((L^{-1})^T  L^-1\\).\n\nPlease note that this method only applies to symmetric, positive-definite matrices.\nThe inverse of the matrix \\(\\Psi\\) from above is:\n\\[\n\\Psi^{-1} = \\frac{e}{e^2 -1} \\begin{pmatrix}\ne & -1\\\\\n-1 & e\n\\end{pmatrix}.\n\\]\nHere’s an example of how to compute the inverse of a matrix using Cholesky decomposition in Python:\n\nimport numpy as np\nfrom scipy.linalg import cholesky, inv\nE = np.exp(1)\n\n# Psi is a symmetric, positive-definite matrix \nPsi = np.array([[1, 1/E], [1/E, 1]])\nL = cholesky(Psi, lower=True)\nL_inv = inv(L)\n# The inverse of A is (L^-1)^T * L^-1\nPsi_inv = np.dot(L_inv.T, L_inv)\n\nprint(\"Psi:\\n\", Psi)\nprint(\"Psi Inverse:\\n\", Psi_inv)\n\nPsi:\n [[1.         0.36787944]\n [0.36787944 1.        ]]\nPsi Inverse:\n [[ 1.15651764 -0.42545906]\n [-0.42545906  1.15651764]]",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html#jupyter-notebook",
    "href": "006_num_gp.html#jupyter-notebook",
    "title": "6  Kriging (Gaussian Process Regression)",
    "section": "6.12 Jupyter Notebook",
    "text": "6.12 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository\n\n\n\n\n\n\n\n\n\nBartz, Eva, Thomas Bartz-Beielstein, Martin Zaefferer, and Olaf Mersmann, eds. 2022. Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide. Springer.\n\n\nForrester, Alexander, András Sóbester, and Andy Keane. 2008. Engineering Design via Surrogate Modelling. Wiley.\n\n\nSantner, T J, B J Williams, and W I Notz. 2003. The Design and Analysis of Computer Experiments. Berlin, Heidelberg, New York: Springer.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "007_num_spot_intro.html",
    "href": "007_num_spot_intro.html",
    "title": "7  Introduction to spotpython",
    "section": "",
    "text": "7.1 Example: Spot and the Sphere Function\nimport numpy as np\nfrom math import inf\nfrom spotpython.fun.objectivefunctions import analytical\nfrom spotpython.utils.init import fun_control_init, design_control_init\nfrom spotpython.hyperparameters.values import set_control_key_value\nfrom spotpython.spot import spot\nimport matplotlib.pyplot as plt",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Introduction to spotpython</span>"
    ]
  },
  {
    "objectID": "007_num_spot_intro.html#example-spot-and-the-sphere-function",
    "href": "007_num_spot_intro.html#example-spot-and-the-sphere-function",
    "title": "7  Introduction to spotpython",
    "section": "",
    "text": "7.1.1 The Objective Function: Sphere\nThe spotpython package provides several classes of objective functions. We will use an analytical objective function, i.e., a function that can be described by a (closed) formula: \\[\nf(x) = x^2\n\\]\n\nfun = analytical().fun_sphere\n\nWe can apply the function fun to input values and plot the result:\n\nx = np.linspace(-1,1,100).reshape(-1,1)\ny = fun(x)\nplt.figure()\nplt.plot(x, y, \"k\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n7.1.2 The Spot Method as an Optimization Algorithm Using a Surrogate Model\nWe initialize the fun_control dictionary. The fun_control dictionary contains the parameters for the objective function. The fun_control dictionary is passed to the Spot method.\n\nfun_control=fun_control_init(lower = np.array([-1]),\n                     upper = np.array([1]))\nspot_0 = spot.Spot(fun=fun,\n                   fun_control=fun_control)\nspot_0.run()\n\nspotpython tuning: 4.959603317754042e-09 [#######---] 73.33% \nspotpython tuning: 4.959603317754042e-09 [########--] 80.00% \nspotpython tuning: 4.959603317754042e-09 [#########-] 86.67% \nspotpython tuning: 4.959603317754042e-09 [#########-] 93.33% \nspotpython tuning: 1.866838525968143e-10 [##########] 100.00% Done...\n\n\n\n&lt;spotpython.spot.spot.Spot at 0x3688ebf80&gt;\n\n\nThe method print_results() prints the results, i.e., the best objective function value (“min y”) and the corresponding input value (“x0”).\n\nspot_0.print_results()\n\nmin y: 1.866838525968143e-10\nx0: 1.3663229947447064e-05\n\n\n[['x0', 1.3663229947447064e-05]]\n\n\nTo plot the search progress, the method plot_progress() can be used. The parameter log_y is used to plot the objective function values on a logarithmic scale.\n\nspot_0.plot_progress(log_y=True)\n\n\n\n\n\n\n\nFigure 7.1: Visualization of the search progress of the Spot method. The black elements (points and line) represent the initial design, before the surrogate is build. The red elements represent the search on the surrogate.\n\n\n\n\n\nIf the dimension of the input space is one, the method plot_model() can be used to visualize the model and the underlying objective function values.\n\nspot_0.plot_model()\n\n\n\n\n\n\n\nFigure 7.2: Visualization of the model and the underlying objective function values.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Introduction to spotpython</span>"
    ]
  },
  {
    "objectID": "007_num_spot_intro.html#spot-parameters-fun_evals-init_size-and-show_models",
    "href": "007_num_spot_intro.html#spot-parameters-fun_evals-init_size-and-show_models",
    "title": "7  Introduction to spotpython",
    "section": "7.2 Spot Parameters: fun_evals, init_size and show_models",
    "text": "7.2 Spot Parameters: fun_evals, init_size and show_models\nWe will modify three parameters:\n\nThe number of function evaluations (fun_evals) will be set to 10 (instead of 15, which is the default value) in the fun_control dictionary.\nThe parameter show_models, which visualizes the search process for each single iteration for 1-dim functions, in the fun_control dictionary.\nThe size of the initial design (init_size) in the design_control dictionary.\n\nThe full list of the Spot parameters is shown in code reference on GitHub, see Spot.\n\nfun_control=fun_control_init(lower = np.array([-1]),\n                     upper = np.array([1]),\n                     fun_evals = 10,\n                     show_models = True)               \ndesign_control = design_control_init(init_size=9)\nspot_1 = spot.Spot(fun=fun,\n                   fun_control=fun_control,\n                   design_control=design_control)\nspot_1.run()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nspotpython tuning: 9.642507519254602e-09 [##########] 100.00% Done...",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Introduction to spotpython</span>"
    ]
  },
  {
    "objectID": "007_num_spot_intro.html#print-the-results",
    "href": "007_num_spot_intro.html#print-the-results",
    "title": "7  Introduction to spotpython",
    "section": "7.3 Print the Results",
    "text": "7.3 Print the Results\n\nspot_1.print_results()\n\nmin y: 9.642507519254602e-09\nx0: -9.819627039381181e-05\n\n\n[['x0', -9.819627039381181e-05]]",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Introduction to spotpython</span>"
    ]
  },
  {
    "objectID": "007_num_spot_intro.html#show-the-progress",
    "href": "007_num_spot_intro.html#show-the-progress",
    "title": "7  Introduction to spotpython",
    "section": "7.4 Show the Progress",
    "text": "7.4 Show the Progress\n\nspot_1.plot_progress()",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Introduction to spotpython</span>"
    ]
  },
  {
    "objectID": "007_num_spot_intro.html#sec-visualizing-tensorboard-01",
    "href": "007_num_spot_intro.html#sec-visualizing-tensorboard-01",
    "title": "7  Introduction to spotpython",
    "section": "7.5 Visualizing the Optimization and Hyperparameter Tuning Process with TensorBoard",
    "text": "7.5 Visualizing the Optimization and Hyperparameter Tuning Process with TensorBoard\nspotpython supports the visualization of the hyperparameter tuning process with TensorBoard. The following example shows how to use TensorBoard with spotpython.\nFirst, we define an “PREFIX” to identify the hyperparameter tuning process. The PREFIX is used to create a directory for the TensorBoard files.\n\nfun_control = fun_control_init(\n    PREFIX = \"01\",\n    lower = np.array([-1]),\n    upper = np.array([2]))\ndesign_control = design_control_init(init_size=5)\n\nSince the PREFIX is not None, spotpython will log the optimization process in the TensorBoard files.\n\nspot_tuner = spot.Spot(fun=fun,\n                   fun_control=fun_control,\n                   design_control=design_control)\nspot_tuner.run()\nspot_tuner.print_results()\n\nspotpython tuning: 2.4876122402648534e-05 [####------] 40.00% \nspotpython tuning: 8.406820960103693e-07 [#####-----] 46.67% \nspotpython tuning: 7.414780214595436e-07 [#####-----] 53.33% \nspotpython tuning: 3.807407090267134e-07 [######----] 60.00% \nspotpython tuning: 5.01557230424484e-09 [#######---] 66.67% \nspotpython tuning: 5.01557230424484e-09 [#######---] 73.33% \nspotpython tuning: 5.01557230424484e-09 [########--] 80.00% \nspotpython tuning: 5.01557230424484e-09 [#########-] 86.67% \nspotpython tuning: 5.01557230424484e-09 [#########-] 93.33% \nspotpython tuning: 5.01557230424484e-09 [##########] 100.00% Done...\n\nmin y: 5.01557230424484e-09\nx0: -7.082070533569148e-05\n\n\n[['x0', -7.082070533569148e-05]]\n\n\nNow we can start TensorBoard in the background. The TensorBoard process will read the TensorBoard files and visualize the hyperparameter tuning process. From the terminal, we can start TensorBoard with the following command:\ntensorboard --logdir=\"./runs\"\nlogdir is the directory where the TensorBoard files are stored. In our case, the TensorBoard files are stored in the directory ./runs.\nTensorBoard will start a web server on port 6006. We can access the TensorBoard web server with the following URL:\nhttp://localhost:6006/\nThe first TensorBoard visualization shows the objective function values plotted against the wall time. The wall time is the time that has passed since the start of the hyperparameter tuning process. The five initial design points are shown in the upper left region of the plot. The line visualizes the optimization process. \nThe second TensorBoard visualization shows the input values, i.e., \\(x_0\\), plotted against the wall time. \nThe third TensorBoard plot illustrates how spotpython can be used as a microscope for the internal mechanisms of the surrogate-based optimization process. Here, one important parameter, the learning rate \\(\\theta\\) of the Kriging surrogate is plotted against the number of optimization steps.\n\n\n\nTensorBoard visualization of the spotpython process.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Introduction to spotpython</span>"
    ]
  },
  {
    "objectID": "007_num_spot_intro.html#jupyter-notebook",
    "href": "007_num_spot_intro.html#jupyter-notebook",
    "title": "7  Introduction to spotpython",
    "section": "7.6 Jupyter Notebook",
    "text": "7.6 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Introduction to spotpython</span>"
    ]
  },
  {
    "objectID": "008_num_spot_multidim.html",
    "href": "008_num_spot_multidim.html",
    "title": "8  Multi-dimensional Functions",
    "section": "",
    "text": "8.1 Example: Spot and the 3-dim Sphere Function\nimport numpy as np\nfrom spotpython.fun.objectivefunctions import analytical\nfrom spotpython.utils.init import fun_control_init, surrogate_control_init\nfrom spotpython.spot import spot",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Multi-dimensional Functions</span>"
    ]
  },
  {
    "objectID": "008_num_spot_multidim.html#example-spot-and-the-3-dim-sphere-function",
    "href": "008_num_spot_multidim.html#example-spot-and-the-3-dim-sphere-function",
    "title": "8  Multi-dimensional Functions",
    "section": "",
    "text": "8.1.1 The Objective Function: 3-dim Sphere\nThe spotpython package provides several classes of objective functions. We will use an analytical objective function, i.e., a function that can be described by a (closed) formula: \\[\nf(x) = \\sum_i^k x_i^2.\n\\]\nIt is avaliable as fun_sphere in the analytical class [SOURCE].\n\nfun = analytical().fun_sphere\n\nHere we will use problem dimension \\(k=3\\), which can be specified by the lower bound arrays. The size of the lower bound array determines the problem dimension. If we select -1.0 * np.ones(3), a three-dimensional function is created. In contrast to the one-dimensional case (Section 7.5), where only one theta value was used, we will use three different theta values (one for each dimension), i.e., we set n_theta=3 in the surrogate_control. The prefix is set to \"03\" to distinguish the results from the one-dimensional case. Again, TensorBoard can be used to monitor the progress of the optimization.\nWe can also add interpreable labels to the dimensions, which will be used in the plots. Therefore, we set var_name=[\"Pressure\", \"Temp\", \"Lambda\"] instead of the default var_name=None, which would result in the labels x_0, x_1, and x_2.\n\nfun_control = fun_control_init(\n              PREFIX=\"03\",\n              lower = -1.0*np.ones(3),\n              upper = np.ones(3),\n              var_name=[\"Pressure\", \"Temp\", \"Lambda\"],\n              show_progress=True)\nsurrogate_control = surrogate_control_init(n_theta=3)\nspot_3 = spot.Spot(fun=fun,\n                  fun_control=fun_control,\n                  surrogate_control=surrogate_control)\nspot_3.run()\n\nspotpython tuning: 0.03443452603483929 [#######---] 73.33% \nspotpython tuning: 0.031343357117474185 [########--] 80.00% \nspotpython tuning: 0.0009629583911652714 [#########-] 86.67% \nspotpython tuning: 8.541680652934052e-05 [#########-] 93.33% \nspotpython tuning: 6.65563988471339e-05 [##########] 100.00% Done...\n\n\n\n&lt;spotpython.spot.spot.Spot at 0x34e4b9550&gt;\n\n\n\n\n\n\n\n\nNote\n\n\n\nNow we can start TensorBoard in the background with the following command:\ntensorboard --logdir=\"./runs\"\nand can access the TensorBoard web server with the following URL:\nhttp://localhost:6006/\n\n\n\n\n8.1.2 Results\n\n_ = spot_3.print_results()\n\nmin y: 6.65563988471339e-05\nPressure: 0.005332620051379623\nTemp: 0.001932437769368857\nLambda: 0.0058638934593215975\n\n\n\nspot_3.plot_progress()\n\n\n\n\n\n\n\n\n\n\n8.1.3 A Contour Plot\nWe can select two dimensions, say \\(i=0\\) and \\(j=1\\), and generate a contour plot as follows.\n\n\n\n\n\n\nNote:\n\n\n\nWe have specified identical min_z and max_z values to generate comparable plots.\n\n\n\nspot_3.plot_contour(i=0, j=1, min_z=0, max_z=2.25)\n\n\n\n\n\n\n\n\n\nIn a similar manner, we can plot dimension \\(i=0\\) and \\(j=2\\):\n\n\nspot_3.plot_contour(i=0, j=2, min_z=0, max_z=2.25)\n\n\n\n\n\n\n\n\n\nThe final combination is \\(i=1\\) and \\(j=2\\):\n\n\nspot_3.plot_contour(i=1, j=2, min_z=0, max_z=2.25)\n\n\n\n\n\n\n\n\n\nThe three plots look very similar, because the fun_sphere is symmetric.\nThis can also be seen from the variable importance:\n\n\n_ = spot_3.print_importance()\n\nPressure:  95.16050385357518\nTemp:  100.0\nLambda:  86.66610935794161\n\n\n\nspot_3.plot_importance()\n\n\n\n\n\n\n\n\n\n\n8.1.4 TensorBoard\n\n\n\nTensorBoard visualization of the spotpython process. Objective function values plotted against wall time.\n\n\nThe second TensorBoard visualization shows the input values, i.e., \\(x_0, \\ldots, x_2\\), plotted against the wall time. \nThe third TensorBoard plot illustrates how spotpython can be used as a microscope for the internal mechanisms of the surrogate-based optimization process. Here, one important parameter, the learning rate \\(\\theta\\) of the Kriging surrogate is plotted against the number of optimization steps.\n\n\n\nTensorBoard visualization of the spotpython surrogate model.\n\n\n\n\n8.1.5 Conclusion\nBased on this quick analysis, we can conclude that all three dimensions are equally important (as expected, because the analytical function is known).",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Multi-dimensional Functions</span>"
    ]
  },
  {
    "objectID": "008_num_spot_multidim.html#factorial-variables",
    "href": "008_num_spot_multidim.html#factorial-variables",
    "title": "8  Multi-dimensional Functions",
    "section": "8.2 Factorial Variables",
    "text": "8.2 Factorial Variables\nUntil now, we have considered continuous variables. However, in many applications, the variables are not continuous, but rather discrete or categorical. For example, the number of layers in a neural network, the number of trees in a random forest, or the type of kernel in a support vector machine are all discrete variables. In the following, we will consider a simple example with two numerical variables and one categorical variable.\n\nfrom spotpython.design.spacefilling import spacefilling\nfrom spotpython.build.kriging import Kriging\nfrom spotpython.fun.objectivefunctions import analytical\nimport numpy as np\n\nFirst, we generate the test data set for fitting the Kriging model. We use the spacefilling class to generate the first two diemnsion of \\(n=30\\) design points. The third dimension is a categorical variable, which can take the values \\(0\\), \\(1\\), or \\(2\\).\n\ngen = spacefilling(2)\nn = 30\nrng = np.random.RandomState(1)\nlower = np.array([-5,-0])\nupper = np.array([10,15])\nfun_orig = analytical().fun_branin\nfun = analytical().fun_branin_factor\n\nX0 = gen.scipy_lhd(n, lower=lower, upper = upper)\nX1 = np.random.randint(low=0, high=3, size=(n,))\nX = np.c_[X0, X1]\nprint(X[:5,:])\n\n[[-2.84117593  5.97308949  2.        ]\n [-3.61017994  6.90781409  1.        ]\n [ 9.91204705  5.09395275  2.        ]\n [-4.4616725   1.3617128   2.        ]\n [-2.40987728  8.05505365  0.        ]]\n\n\nThe objective function is the fun_branin_factor in the analytical class [SOURCE]. It calculates the Branin function of \\((x_1, x_2)\\) with an additional factor based on the value of \\(x_3\\). If \\(x_3 = 1\\), the value of the Branin function is increased by 10. If \\(x_3 = 2\\), the value of the Branin function is decreased by 10. Otherwise, the value of the Branin function is not changed.\n\ny = fun(X)\ny_orig = fun_orig(X0)\ndata = np.c_[X, y_orig, y]\nprint(data[:5,:])\n\n[[ -2.84117593   5.97308949   2.          32.09388125  22.09388125]\n [ -3.61017994   6.90781409   1.          43.965223    53.965223  ]\n [  9.91204705   5.09395275   2.           6.25588575  -3.74411425]\n [ -4.4616725    1.3617128    2.         212.41884106 202.41884106]\n [ -2.40987728   8.05505365   0.           9.25981051   9.25981051]]\n\n\nWe fit two Kriging models, one with three numerical variables and one with two numerical variables and one categorical variable. We then compare the predictions of the two models.\n\nS = Kriging(name='kriging',  seed=123, log_level=50, n_theta=3, noise=False, var_type=[\"num\", \"num\", \"num\"])\nS.fit(X, y)\nSf = Kriging(name='kriging',  seed=123, log_level=50, n_theta=3, noise=False, var_type=[\"num\", \"num\", \"factor\"])\nSf.fit(X, y)\n\nWe can now compare the predictions of the two models. We generate a new test data set and calculate the sum of the absolute differences between the predictions of the two models and the true values of the objective function. If the categorical variable is important, the sum of the absolute differences should be smaller than if the categorical variable is not important.\n\nn = 100\nk = 100\ny_true = np.zeros(n*k)\ny_pred= np.zeros(n*k)\ny_factor_pred= np.zeros(n*k)\nfor i in range(k):\n  X0 = gen.scipy_lhd(n, lower=lower, upper = upper)\n  X1 = np.random.randint(low=0, high=3, size=(n,))\n  X = np.c_[X0, X1]\n  a = i*n\n  b = (i+1)*n\n  y_true[a:b] = fun(X)\n  y_pred[a:b] = S.predict(X)\n  y_factor_pred[a:b] = Sf.predict(X)\n\n\nimport pandas as pd\ndf = pd.DataFrame({\"y\":y_true, \"Prediction\":y_pred, \"Prediction_factor\":y_factor_pred})\ndf.head()\n\n\n\n\n\n\n\n\ny\nPrediction\nPrediction_factor\n\n\n\n\n0\n6.684749\n17.660408\n8.981430\n\n\n1\n95.865258\n90.509501\n94.789595\n\n\n2\n49.811774\n31.120556\n50.354535\n\n\n3\n8.177150\n5.917583\n8.441051\n\n\n4\n10.968377\n14.164812\n4.820856\n\n\n\n\n\n\n\n\ndf.tail()\n\n\n\n\n\n\n\n\ny\nPrediction\nPrediction_factor\n\n\n\n\n9995\n73.620503\n82.887200\n73.604506\n\n\n9996\n76.187178\n92.365607\n76.894275\n\n\n9997\n29.494401\n27.820944\n29.928268\n\n\n9998\n15.390268\n15.671179\n3.957986\n\n\n9999\n26.261264\n13.626484\n25.011336\n\n\n\n\n\n\n\n\ns=np.sum(np.abs(y_pred - y_true))\nsf=np.sum(np.abs(y_factor_pred - y_true))\nres = (sf - s)\nprint(res)\n\n-93783.37196523952\n\n\n\nfrom spotpython.plot.validation import plot_actual_vs_predicted\nplot_actual_vs_predicted(y_test=df[\"y\"], y_pred=df[\"Prediction\"], title=\"Default\")\nplot_actual_vs_predicted(y_test=df[\"y\"], y_pred=df[\"Prediction_factor\"], title=\"Factor\")",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Multi-dimensional Functions</span>"
    ]
  },
  {
    "objectID": "008_num_spot_multidim.html#exercises",
    "href": "008_num_spot_multidim.html#exercises",
    "title": "8  Multi-dimensional Functions",
    "section": "8.3 Exercises",
    "text": "8.3 Exercises\n\n8.3.1 1. The Three Dimensional fun_cubed\n\nThe input dimension is 3. The search range is \\(-1 \\leq x \\leq 1\\) for all dimensions.\nGenerate contour plots\nCalculate the variable importance.\nDiscuss the variable importance:\n\nAre all variables equally important?\nIf not:\n\nWhich is the most important variable?\nWhich is the least important variable?\n\n\n\n\n\n8.3.2 2. The Ten Dimensional fun_wing_wt\n\nThe input dimension is 10. The search range is \\(0 \\leq x \\leq 1\\) for all dimensions.\nCalculate the variable importance.\nDiscuss the variable importance:\n\nAre all variables equally important?\nIf not:\n\nWhich is the most important variable?\nWhich is the least important variable?\n\nGenerate contour plots for the three most important variables. Do they confirm your selection?\n\n\n\n\n8.3.3 3. The Three Dimensional fun_runge\n\nThe input dimension is 3. The search range is \\(-5 \\leq x \\leq 5\\) for all dimensions.\nGenerate contour plots\nCalculate the variable importance.\nDiscuss the variable importance:\n\nAre all variables equally important?\nIf not:\n\nWhich is the most important variable?\nWhich is the least important variable?\n\n\n\n\n\n8.3.4 4. The Three Dimensional fun_linear\n\nThe input dimension is 3. The search range is \\(-5 \\leq x \\leq 5\\) for all dimensions.\nGenerate contour plots\nCalculate the variable importance.\nDiscuss the variable importance:\n\nAre all variables equally important?\nIf not:\n\nWhich is the most important variable?\nWhich is the least important variable?\n\n\n\n\n\n8.3.5 5. The Two Dimensional Rosenbrock Function fun_rosen\n\nThe input dimension is 2. The search range is \\(-5 \\leq x \\leq 10\\) for all dimensions.\nSee Rosenbrock function and Rosenbrock Function for details.\nGenerate contour plots\nCalculate the variable importance.\nDiscuss the variable importance:\n\nAre all variables equally important?\nIf not:\n\nWhich is the most important variable?\nWhich is the least important variable?",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Multi-dimensional Functions</span>"
    ]
  },
  {
    "objectID": "008_num_spot_multidim.html#selected-solutions",
    "href": "008_num_spot_multidim.html#selected-solutions",
    "title": "8  Multi-dimensional Functions",
    "section": "8.4 Selected Solutions",
    "text": "8.4 Selected Solutions\n\n8.4.1 Solution to Exercise Section 8.3.5: The Two-dimensional Rosenbrock Function fun_rosen\n\nimport numpy as np\nfrom spotpython.fun.objectivefunctions import analytical\nfrom spotpython.utils.init import fun_control_init, surrogate_control_init\nfrom spotpython.spot import spot\n\n\n8.4.1.1 The Objective Function: 2-dim fun_rosen\nThe spotpython package provides several classes of objective functions. We will use the fun_rosen in the analytical class [SOURCE].\n\nfun_rosen = analytical().fun_rosen\n\nHere we will use problem dimension \\(k=2\\), which can be specified by the lower bound arrays. The size of the lower bound array determines the problem dimension. If we select -5.0 * np.ones(2), a two-dimensional function is created. In contrast to the one-dimensional case, where only one theta value is used, we will use \\(k\\) different theta values (one for each dimension), i.e., we set n_theta=3 in the surrogate_control. The prefix is set to \"ROSEN\". Again, TensorBoard can be used to monitor the progress of the optimization.\n\nfun_control = fun_control_init(\n              PREFIX=\"ROSEN\",\n              lower = -5.0*np.ones(2),\n              upper = 10*np.ones(2),\n              show_progress=True,\n              fun_evals=25)\nsurrogate_control = surrogate_control_init(n_theta=2)\nspot_rosen = spot.Spot(fun=fun_rosen,\n                  fun_control=fun_control,\n                  surrogate_control=surrogate_control)\nspot_rosen.run()\n\nspotpython tuning: 90.78805160669465 [####------] 44.00% \nspotpython tuning: 1.0171930962259077 [#####-----] 48.00% \nspotpython tuning: 1.0171930962259077 [#####-----] 52.00% \nspotpython tuning: 1.0171930962259077 [######----] 56.00% \nspotpython tuning: 1.0171930962259077 [######----] 60.00% \nspotpython tuning: 1.0171930962259077 [######----] 64.00% \nspotpython tuning: 1.0171930962259077 [#######---] 68.00% \nspotpython tuning: 0.9722891367911908 [#######---] 72.00% \nspotpython tuning: 0.9722891367911908 [########--] 76.00% \nspotpython tuning: 0.9722891367911908 [########--] 80.00% \nspotpython tuning: 0.9722891367911908 [########--] 84.00% \nspotpython tuning: 0.8058112323775151 [#########-] 88.00% \nspotpython tuning: 0.8058112323775151 [#########-] 92.00% \nspotpython tuning: 0.8058112323775151 [##########] 96.00% \nspotpython tuning: 0.726650609991151 [##########] 100.00% Done...\n\n\n\n&lt;spotpython.spot.spot.Spot at 0x1060efbc0&gt;\n\n\n\n\n\n\n\n\nNote\n\n\n\nNow we can start TensorBoard in the background with the following command:\ntensorboard --logdir=\"./runs\"\nand can access the TensorBoard web server with the following URL:\nhttp://localhost:6006/\n\n\n\n\n8.4.1.2 Results\n\n_ = spot_rosen.print_results()\n\nmin y: 0.726650609991151\nx0: 0.17237438431069813\nx1: 0.09427797327939783\n\n\n\nspot_rosen.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\n\n8.4.1.3 A Contour Plot\nWe can select two dimensions, say \\(i=0\\) and \\(j=1\\), and generate a contour plot as follows.\n\n\n\n\n\n\nNote:\n\n\n\nFor higher dimensions, it might be useful to have identical min_z and max_z values to generate comparable plots. The default values are min_z=None and max_z=None, which will be replaced by the minimum and maximum values of the objective function.\n\n\n\nmin_z = None\nmax_z = None\nspot_rosen.plot_contour(i=0, j=1, min_z=min_z, max_z=max_z)\n\n\n\n\n\n\n\n\n\nThe variable importance can be calculated as follows:\n\n\n_ = spot_rosen.print_importance()\n\nx0:  99.99999999999999\nx1:  1.2430550048669098\n\n\n\nspot_rosen.plot_importance()\n\n\n\n\n\n\n\n\n\n\n8.4.1.4 TensorBoard\nTBD",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Multi-dimensional Functions</span>"
    ]
  },
  {
    "objectID": "008_num_spot_multidim.html#jupyter-notebook",
    "href": "008_num_spot_multidim.html#jupyter-notebook",
    "title": "8  Multi-dimensional Functions",
    "section": "8.5 Jupyter Notebook",
    "text": "8.5 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Multi-dimensional Functions</span>"
    ]
  },
  {
    "objectID": "009_num_spot_anisotropic.html",
    "href": "009_num_spot_anisotropic.html",
    "title": "9  Isotropic and Anisotropic Kriging",
    "section": "",
    "text": "9.1 Example: Isotropic Spot Surrogate and the 2-dim Sphere Function\nimport numpy as np\nfrom math import inf\nfrom spotpython.fun.objectivefunctions import analytical\nfrom spotpython.spot import spot\nfrom spotpython.utils.init import fun_control_init, surrogate_control_init\nPREFIX=\"003\"",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Isotropic and Anisotropic Kriging</span>"
    ]
  },
  {
    "objectID": "009_num_spot_anisotropic.html#sec-spot-2d-sphere-iso",
    "href": "009_num_spot_anisotropic.html#sec-spot-2d-sphere-iso",
    "title": "9  Isotropic and Anisotropic Kriging",
    "section": "",
    "text": "9.1.1 The Objective Function: 2-dim Sphere\nThe spotpython package provides several classes of objective functions. We will use an analytical objective function, i.e., a function that can be described by a (closed) formula:\n\\[\nf(x, y) = x^2 + y^2\n\\] The size of the lower bound vector determines the problem dimension. Here we will use np.array([-1, -1]), i.e., a two-dimensional function.\n\nfun = analytical().fun_sphere\nfun_control = fun_control_init(PREFIX=PREFIX,\n                               lower = np.array([-1, -1]),\n                               upper = np.array([1, 1]))\n\nAlthough the default spot surrogate model is an isotropic Kriging model, we will explicitly set the n_theta parameter to a value of 1, so that the same theta value is used for both dimensions. This is done to illustrate the difference between isotropic and anisotropic Kriging models.\n\nsurrogate_control=surrogate_control_init(n_theta=1)\n\n\nspot_2 = spot.Spot(fun=fun,\n                   fun_control=fun_control,\n                   surrogate_control=surrogate_control)\n\nspot_2.run()\n\nspotpython tuning: 2.217297132344163e-05 [#######---] 73.33% \nspotpython tuning: 2.217297132344163e-05 [########--] 80.00% \nspotpython tuning: 2.217297132344163e-05 [#########-] 86.67% \nspotpython tuning: 2.217297132344163e-05 [#########-] 93.33% \nspotpython tuning: 2.217297132344163e-05 [##########] 100.00% Done...\n\n\n\n&lt;spotpython.spot.spot.Spot at 0x1574936e0&gt;\n\n\n\n\n9.1.2 Results\n\nspot_2.print_results()\n\nmin y: 2.217297132344163e-05\nx0: 0.001637745619980198\nx1: 0.004414834154039912\n\n\n[['x0', 0.001637745619980198], ['x1', 0.004414834154039912]]\n\n\n\nspot_2.plot_progress(log_y=True)",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Isotropic and Anisotropic Kriging</span>"
    ]
  },
  {
    "objectID": "009_num_spot_anisotropic.html#example-with-anisotropic-kriging",
    "href": "009_num_spot_anisotropic.html#example-with-anisotropic-kriging",
    "title": "9  Isotropic and Anisotropic Kriging",
    "section": "9.2 Example With Anisotropic Kriging",
    "text": "9.2 Example With Anisotropic Kriging\nAs described in Section 9.1, the default parameter setting of spotpython’s Kriging surrogate uses the same theta value for every dimension. This is referred to as “using an isotropic kernel”. If different theta values are used for each dimension, then an anisotropic kernel is used. To enable anisotropic models in spotpython, the number of theta values should be larger than one. We can use surrogate_control=surrogate_control_init(n_theta=2) to enable this behavior (2 is the problem dimension).\n\nsurrogate_control = surrogate_control_init(n_theta=2)\nspot_2_anisotropic = spot.Spot(fun=fun,\n                    fun_control=fun_control,\n                    surrogate_control=surrogate_control)\nspot_2_anisotropic.run()\n\nspotpython tuning: 1.5904060546935205e-05 [#######---] 73.33% \nspotpython tuning: 1.5904060546935205e-05 [########--] 80.00% \nspotpython tuning: 1.5904060546935205e-05 [#########-] 86.67% \nspotpython tuning: 1.5904060546935205e-05 [#########-] 93.33% \nspotpython tuning: 1.4886245843852055e-05 [##########] 100.00% Done...\n\n\n\n&lt;spotpython.spot.spot.Spot at 0x37cd745f0&gt;\n\n\nThe search progress of the optimization with the anisotropic model can be visualized:\n\nspot_2_anisotropic.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\nspot_2_anisotropic.print_results()\n\nmin y: 1.4886245843852055e-05\nx0: -0.003850983818095356\nx1: -0.00023700100552480994\n\n\n[['x0', -0.003850983818095356], ['x1', -0.00023700100552480994]]\n\n\n\nspot_2_anisotropic.surrogate.plot()\n\n\n\n\n\n\n\n\n\n9.2.1 Taking a Look at the theta Values\n\n9.2.1.1 theta Values from the spot Model\nWe can check, whether one or several theta values were used. The theta values from the surrogate can be printed as follows:\n\nspot_2_anisotropic.surrogate.theta\n\narray([-0.32858908, -0.13977864])\n\n\n\nSince the surrogate from the isotropic setting was stored as spot_2, we can also take a look at the theta value from this model:\n\n\nspot_2.surrogate.theta\n\narray([-0.17881419])\n\n\n\n\n9.2.1.2 TensorBoard\nNow we can start TensorBoard in the background with the following command:\ntensorboard --logdir=\"./runs\"\nWe can access the TensorBoard web server with the following URL:\nhttp://localhost:6006/\nThe TensorBoard plot illustrates how spotpython can be used as a microscope for the internal mechanisms of the surrogate-based optimization process. Here, one important parameter, the learning rate \\(\\theta\\) of the Kriging surrogate is plotted against the number of optimization steps.\n\n\n\nTensorBoard visualization of the spotpython surrogate model.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Isotropic and Anisotropic Kriging</span>"
    ]
  },
  {
    "objectID": "009_num_spot_anisotropic.html#exercises",
    "href": "009_num_spot_anisotropic.html#exercises",
    "title": "9  Isotropic and Anisotropic Kriging",
    "section": "9.3 Exercises",
    "text": "9.3 Exercises\n\n9.3.1 1. The Branin Function fun_branin\n\nDescribe the function.\n\nThe input dimension is 2. The search range is \\(-5 \\leq x_1 \\leq 10\\) and \\(0 \\leq x_2 \\leq 15\\).\n\nCompare the results from spotpython run a) with isotropic and b) anisotropic surrogate models.\nModify the termination criterion: instead of the number of evaluations (which is specified via fun_evals), the time should be used as the termination criterion. This can be done as follows (max_time=1 specifies a run time of one minute):\n\n\nfrom math import inf\nfun_control = fun_control_init(\n              fun_evals=inf,\n              max_time=1)\n\n\n\n9.3.2 2. The Two-dimensional Sin-Cos Function fun_sin_cos\n\nDescribe the function.\n\nThe input dimension is 2. The search range is \\(-2\\pi \\leq x_1 \\leq 2\\pi\\) and \\(-2\\pi \\leq x_2 \\leq 2\\pi\\).\n\nCompare the results from spotpython run a) with isotropic and b) anisotropic surrogate models.\nModify the termination criterion (max_time instead of fun_evals) as described for fun_branin.\n\n\n\n9.3.3 3. The Two-dimensional Runge Function fun_runge\n\nDescribe the function.\n\nThe input dimension is 2. The search range is \\(-5 \\leq x_1 \\leq 5\\) and \\(-5 \\leq x_2 \\leq 5\\).\n\nCompare the results from spotpython run a) with isotropic and b) anisotropic surrogate models.\nModify the termination criterion (max_time instead of fun_evals) as described for fun_branin.\n\n\n\n9.3.4 4. The Ten-dimensional Wing-Weight Function fun_wingwt\n\nDescribe the function.\n\nThe input dimension is 10. The search ranges are between 0 and 1 (values are mapped internally to their natural bounds).\n\nCompare the results from spotpython run a) with isotropic and b) anisotropic surrogate models.\nModify the termination criterion (max_time instead of fun_evals) as described for fun_branin.\n\n\n\n9.3.5 5. The Two-dimensional Rosenbrock Function fun_rosen\n\nDescribe the function.\n\nThe input dimension is 2. The search ranges are between -5 and 10.\n\nCompare the results from spotpython run a) with isotropic and b) anisotropic surrogate models.\nModify the termination criterion (max_time instead of fun_evals) as described for fun_branin.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Isotropic and Anisotropic Kriging</span>"
    ]
  },
  {
    "objectID": "009_num_spot_anisotropic.html#selected-solutions",
    "href": "009_num_spot_anisotropic.html#selected-solutions",
    "title": "9  Isotropic and Anisotropic Kriging",
    "section": "9.4 Selected Solutions",
    "text": "9.4 Selected Solutions\n\n9.4.1 Solution to Exercise Section 9.3.5: The Two-dimensional Rosenbrock Function fun_rosen\n\n9.4.1.1 The Two Dimensional fun_rosen: The Isotropic Case\n\nimport numpy as np\nfrom spotpython.fun.objectivefunctions import analytical\nfrom spotpython.utils.init import fun_control_init, surrogate_control_init\nfrom spotpython.spot import spot\n\nThe spotpython package provides several classes of objective functions. We will use the fun_rosen in the analytical class [SOURCE].\n\nfun_rosen = analytical().fun_rosen\n\nHere we will use problem dimension \\(k=2\\), which can be specified by the lower bound arrays. The size of the lower bound array determines the problem dimension.\nThe prefix is set to \"ROSEN\" to distinguish the results from the one-dimensional case. Again, TensorBoard can be used to monitor the progress of the optimization.\n\nfun_control = fun_control_init(\n              PREFIX=\"ROSEN\",\n              lower = np.array([-5, -5]),\n              upper = np.array([10, 10]),\n              show_progress=True)\nsurrogate_control = surrogate_control_init(n_theta=1)\nspot_rosen = spot.Spot(fun=fun_rosen,\n                  fun_control=fun_control,\n                  surrogate_control=surrogate_control)\nspot_rosen.run()\n\nspotpython tuning: 52.876358299143206 [#######---] 73.33% \nspotpython tuning: 52.36204755139067 [########--] 80.00% \nspotpython tuning: 52.36204755139067 [#########-] 86.67% \nspotpython tuning: 43.44294819789333 [#########-] 93.33% \nspotpython tuning: 12.275982031887748 [##########] 100.00% Done...\n\n\n\n&lt;spotpython.spot.spot.Spot at 0x37cd96b40&gt;\n\n\n\n\n\n\n\n\nNote\n\n\n\nNow we can start TensorBoard in the background with the following command:\ntensorboard --logdir=\"./runs\"\nand can access the TensorBoard web server with the following URL:\nhttp://localhost:6006/\n\n\n\n9.4.1.1.1 Results\n\n_ = spot_rosen.print_results()\n\nmin y: 12.275982031887748\nx0: -2.3708319530278255\nx1: 5.923081469551754\n\n\n\nspot_rosen.plot_progress()\n\n\n\n\n\n\n\n\n\n\n9.4.1.1.2 A Contour Plot\nWe can select two dimensions, say \\(i=0\\) and \\(j=1\\), and generate a contour plot as follows.\n\nmin_z = None\nmax_z = None\nspot_rosen.plot_contour(i=0, j=1, min_z=min_z, max_z=max_z)\n\n\n\n\n\n\n\n\n\nThe variable importance cannot be calculated, because only one theta value was used.\n\n\n\n9.4.1.1.3 TensorBoard\nTBD\n\n\n\n9.4.1.2 The Two Dimensional fun_rosen: The Anisotropic Case\n\nimport numpy as np\nfrom spotpython.fun.objectivefunctions import analytical\nfrom spotpython.utils.init import fun_control_init, surrogate_control_init\nfrom spotpython.spot import spot\n\nThe spotpython package provides several classes of objective functions. We will use the fun_rosen in the analytical class [SOURCE].\n\nfun_rosen = analytical().fun_rosen\n\nHere we will use problem dimension \\(k=2\\), which can be specified by the lower bound arrays. The size of the lower bound array determines the problem dimension.\nWe can also add interpreable labels to the dimensions, which will be used in the plots.\n\nfun_control = fun_control_init(\n              PREFIX=\"ROSEN\",\n              lower = np.array([-5, -5]),\n              upper = np.array([10, 10]),\n              show_progress=True)\nsurrogate_control = surrogate_control_init(n_theta=2)\nspot_rosen = spot.Spot(fun=fun_rosen,\n                  fun_control=fun_control,\n                  surrogate_control=surrogate_control)\nspot_rosen.run()\n\nspotpython tuning: 90.78805160669465 [#######---] 73.33% \nspotpython tuning: 1.0171930962259077 [########--] 80.00% \nspotpython tuning: 1.0171930962259077 [#########-] 86.67% \nspotpython tuning: 1.0171930962259077 [#########-] 93.33% \nspotpython tuning: 1.0171930962259077 [##########] 100.00% Done...\n\n\n\n&lt;spotpython.spot.spot.Spot at 0x38825d370&gt;\n\n\n\n\n\n\n\n\nNote\n\n\n\nNow we can start TensorBoard in the background with the following command:\ntensorboard --logdir=\"./runs\"\nand can access the TensorBoard web server with the following URL:\nhttp://localhost:6006/\n\n\n\n9.4.1.2.1 Results\n\n_ = spot_rosen.print_results()\n\nmin y: 1.0171930962259077\nx0: 0.002781302621691875\nx1: -0.047687091984116046\n\n\n\nspot_rosen.plot_progress()\n\n\n\n\n\n\n\n\n\n\n9.4.1.2.2 A Contour Plot\nWe can select two dimensions, say \\(i=0\\) and \\(j=1\\), and generate a contour plot as follows.\n\nmin_z = None\nmax_z = None\nspot_rosen.plot_contour(i=0, j=1, min_z=min_z, max_z=max_z)\n\n\n\n\n\n\n\n\n\nThe variable importance can be calculated as follows:\n\n\n_ = spot_rosen.print_importance()\n\nx0:  100.0\nx1:  2.2275258776369804\n\n\n\nspot_rosen.plot_importance()\n\n\n\n\n\n\n\n\n\n\n9.4.1.2.3 TensorBoard\nTBD",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Isotropic and Anisotropic Kriging</span>"
    ]
  },
  {
    "objectID": "009_num_spot_anisotropic.html#jupyter-notebook",
    "href": "009_num_spot_anisotropic.html#jupyter-notebook",
    "title": "9  Isotropic and Anisotropic Kriging",
    "section": "9.5 Jupyter Notebook",
    "text": "9.5 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Isotropic and Anisotropic Kriging</span>"
    ]
  },
  {
    "objectID": "010_num_spot_sklearn_surrogate.html",
    "href": "010_num_spot_sklearn_surrogate.html",
    "title": "10  Using sklearn Surrogates in spotpython",
    "section": "",
    "text": "10.1 Example: Branin Function with spotpython’s Internal Kriging Surrogate",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Using `sklearn` Surrogates in `spotpython`</span>"
    ]
  },
  {
    "objectID": "010_num_spot_sklearn_surrogate.html#example-branin-function-with-spotpythons-internal-kriging-surrogate",
    "href": "010_num_spot_sklearn_surrogate.html#example-branin-function-with-spotpythons-internal-kriging-surrogate",
    "title": "10  Using sklearn Surrogates in spotpython",
    "section": "",
    "text": "10.1.1 The Objective Function Branin\n\nThe spotpython package provides several classes of objective functions.\nWe will use an analytical objective function, i.e., a function that can be described by a (closed) formula.\nHere we will use the Branin function:\n  y = a * (x2 - b * x1**2 + c * x1 - r) ** 2 + s * (1 - t) * np.cos(x1) + s,\n  where values of a, b, c, r, s and t are: a = 1, b = 5.1 / (4*pi**2),\n  c = 5 / pi, r = 6, s = 10 and t = 1 / (8*pi).\nIt has three global minima:\n  f(x) = 0.397887 at (-pi, 12.275), (pi, 2.275), and (9.42478, 2.475).\n\n\nfrom spotpython.fun.objectivefunctions import analytical\nfun = analytical().fun_branin\n\n\n\n\n\n\n\nTensorBoard\n\n\n\nSimilar to the one-dimensional case, which was introduced in Section Section 7.5, we can use TensorBoard to monitor the progress of the optimization. We will use the same code, only the prefix is different:\n\nfrom spotpython.utils.init import fun_control_init, design_control_init\nPREFIX = \"04\"\nfun_control = fun_control_init(\n    PREFIX=PREFIX,\n    lower = np.array([-5,-0]),\n    upper = np.array([10,15]),\n    fun_evals=20,\n    max_time=inf)\n\ndesign_control = design_control_init(\n    init_size=10)\n\n\n\n\n\n10.1.2 Running the surrogate model based optimizer Spot:\n\nspot_2 = spot.Spot(fun=fun,\n                   fun_control=fun_control,\n                   design_control=design_control)\n\n\nspot_2.run()\n\nspotpython tuning: 3.8004550038787155 [######----] 55.00% \nspotpython tuning: 3.8004550038787155 [######----] 60.00% \nspotpython tuning: 3.1588579885698627 [######----] 65.00% \nspotpython tuning: 3.1342382932317037 [#######---] 70.00% \nspotpython tuning: 2.8956615907630585 [########--] 75.00% \nspotpython tuning: 0.42052429574482275 [########--] 80.00% \nspotpython tuning: 0.4013351867835322 [########--] 85.00% \nspotpython tuning: 0.399265616254338 [#########-] 90.00% \nspotpython tuning: 0.399265616254338 [##########] 95.00% \nspotpython tuning: 0.399265616254338 [##########] 100.00% Done...\n\n\n\n&lt;spotpython.spot.spot.Spot at 0x155c010d0&gt;\n\n\n\n\n10.1.3 TensorBoard\nNow we can start TensorBoard in the background with the following command:\ntensorboard --logdir=\"./runs\"\nWe can access the TensorBoard web server with the following URL:\nhttp://localhost:6006/\nThe TensorBoard plot illustrates how spotpython can be used as a microscope for the internal mechanisms of the surrogate-based optimization process. Here, one important parameter, the learning rate \\(\\theta\\) of the Kriging surrogate is plotted against the number of optimization steps.\n\n\n\nTensorBoard visualization of the spotpython optimization process and the surrogate model.\n\n\n\n\n10.1.4 Print the Results\n\nspot_2.print_results()\n\nmin y: 0.399265616254338\nx0: 3.151170754781285\nx1: 2.2981660114765448\n\n\n[['x0', 3.151170754781285], ['x1', 2.2981660114765448]]\n\n\n\n\n10.1.5 Show the Progress and the Surrogate\n\nspot_2.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\nspot_2.surrogate.plot()",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Using `sklearn` Surrogates in `spotpython`</span>"
    ]
  },
  {
    "objectID": "010_num_spot_sklearn_surrogate.html#example-using-surrogates-from-scikit-learn",
    "href": "010_num_spot_sklearn_surrogate.html#example-using-surrogates-from-scikit-learn",
    "title": "10  Using sklearn Surrogates in spotpython",
    "section": "10.2 Example: Using Surrogates From scikit-learn",
    "text": "10.2 Example: Using Surrogates From scikit-learn\n\nDefault is the spotpython (i.e., the internal) kriging surrogate.\nIt can be called explicitely and passed to Spot.\n\n\nfrom spotpython.build.kriging import Kriging\nS_0 = Kriging(name='kriging', seed=123)\n\n\nAlternatively, models from scikit-learn can be selected, e.g., Gaussian Process, RBFs, Regression Trees, etc.\n\n\n# Needed for the sklearn surrogates:\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn import linear_model\nfrom sklearn import tree\nimport pandas as pd\n\n\nHere are some additional models that might be useful later:\n\n\nS_Tree = DecisionTreeRegressor(random_state=0)\nS_LM = linear_model.LinearRegression()\nS_Ridge = linear_model.Ridge()\nS_RF = RandomForestRegressor(max_depth=2, random_state=0)\n\n\n10.2.1 GaussianProcessRegressor as a Surrogate\n\nTo use a Gaussian Process model from sklearn, that is similar to spotpython’s Kriging, we can proceed as follows:\n\n\nkernel = 1 * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2))\nS_GP = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\n\n\nThe scikit-learn GP model S_GP is selected for Spot as follows:\nsurrogate = S_GP\nWe can check the kind of surogate model with the command isinstance:\n\n\nisinstance(S_GP, GaussianProcessRegressor) \n\nTrue\n\n\n\nisinstance(S_0, Kriging)\n\nTrue\n\n\n\nSimilar to the Spot run with the internal Kriging model, we can call the run with the scikit-learn surrogate:\n\n\nfun = analytical(seed=123).fun_branin\nspot_2_GP = spot.Spot(fun=fun,\n                     fun_control=fun_control,\n                     design_control=design_control,\n                     surrogate = S_GP)\nspot_2_GP.run()\n\nspotpython tuning: 18.865120626024897 [######----] 55.00% \nspotpython tuning: 4.067035571881624 [######----] 60.00% \nspotpython tuning: 3.4619135134152215 [######----] 65.00% \nspotpython tuning: 3.4619135134152215 [#######---] 70.00% \nspotpython tuning: 1.328248854169006 [########--] 75.00% \nspotpython tuning: 0.9548473238361144 [########--] 80.00% \nspotpython tuning: 0.9362788065438252 [########--] 85.00% \nspotpython tuning: 0.40009463636571496 [#########-] 90.00% \nspotpython tuning: 0.39824274152672423 [##########] 95.00% \n\n\nspotpython tuning: 0.39824274152672423 [##########] 100.00% Done...\n\n\n\n&lt;spotpython.spot.spot.Spot at 0x375c42b40&gt;\n\n\n\nspot_2_GP.plot_progress()\n\n\n\n\n\n\n\n\n\nspot_2_GP.print_results()\n\nmin y: 0.39824274152672423\nx0: 3.1501084171824973\nx1: 2.2710556115184426\n\n\n[['x0', 3.1501084171824973], ['x1', 2.2710556115184426]]",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Using `sklearn` Surrogates in `spotpython`</span>"
    ]
  },
  {
    "objectID": "010_num_spot_sklearn_surrogate.html#example-one-dimensional-sphere-function-with-spotpythons-kriging",
    "href": "010_num_spot_sklearn_surrogate.html#example-one-dimensional-sphere-function-with-spotpythons-kriging",
    "title": "10  Using sklearn Surrogates in spotpython",
    "section": "10.3 Example: One-dimensional Sphere Function With spotpython’s Kriging",
    "text": "10.3 Example: One-dimensional Sphere Function With spotpython’s Kriging\n\nIn this example, we will use an one-dimensional function, which allows us to visualize the optimization process.\n\nshow_models= True is added to the argument list.\n\n\n\nfrom spotpython.fun.objectivefunctions import analytical\nfun_control = fun_control_init(\n    lower = np.array([-1]),\n    upper = np.array([1]),\n    fun_evals=10,\n    max_time=inf,\n    show_models= True,\n    tolerance_x = np.sqrt(np.spacing(1)))\nfun = analytical(seed=123).fun_sphere\ndesign_control = design_control_init(\n    init_size=3)\n\n\nspot_1 = spot.Spot(fun=fun,\n                    fun_control=fun_control,\n                    design_control=design_control)\nspot_1.run()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.03475493366922229 [####------] 40.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.03475493366922229 [#####-----] 50.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.014772665252290174 [######----] 60.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.00020571435112063172 [#######---] 70.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 5.943319903709223e-08 [########--] 80.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 5.943319903709223e-08 [#########-] 90.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 5.943319903709223e-08 [##########] 100.00% Done...\n\n\n\n\n10.3.1 Results\n\nspot_1.print_results()\n\nmin y: 5.943319903709223e-08\nx0: -0.0002437892512747275\n\n\n[['x0', -0.0002437892512747275]]\n\n\n\nspot_1.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\nThe method plot_model plots the final surrogate:\n\n\nspot_1.plot_model()",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Using `sklearn` Surrogates in `spotpython`</span>"
    ]
  },
  {
    "objectID": "010_num_spot_sklearn_surrogate.html#example-sklearn-model-gaussianprocess",
    "href": "010_num_spot_sklearn_surrogate.html#example-sklearn-model-gaussianprocess",
    "title": "10  Using sklearn Surrogates in spotpython",
    "section": "10.4 Example: Sklearn Model GaussianProcess",
    "text": "10.4 Example: Sklearn Model GaussianProcess\n\nThis example visualizes the search process on the GaussianProcessRegression surrogate from sklearn.\nTherefore surrogate = S_GP is added to the argument list.\n\n\nfun = analytical(seed=123).fun_sphere\nspot_1_GP = spot.Spot(fun=fun,\n                      fun_control=fun_control,\n                      design_control=design_control,\n                      surrogate = S_GP)\nspot_1_GP.run()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.00492567138682192 [####------] 40.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.0026120626229886095 [#####-----] 50.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 3.1732324790463464e-07 [######----] 60.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 3.291512456526943e-08 [#######---] 70.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 1.8087882373554217e-08 [########--] 80.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 2.4792327258527864e-09 [#########-] 90.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 2.4792327258527864e-09 [##########] 100.00% Done...\n\n\n\n\nspot_1_GP.print_results()\n\nmin y: 2.4792327258527864e-09\nx0: 4.979189417819718e-05\n\n\n[['x0', 4.979189417819718e-05]]\n\n\n\nspot_1_GP.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\nspot_1_GP.plot_model()",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Using `sklearn` Surrogates in `spotpython`</span>"
    ]
  },
  {
    "objectID": "010_num_spot_sklearn_surrogate.html#exercises",
    "href": "010_num_spot_sklearn_surrogate.html#exercises",
    "title": "10  Using sklearn Surrogates in spotpython",
    "section": "10.5 Exercises",
    "text": "10.5 Exercises\n\n10.5.1 1. A decision tree regressor: DecisionTreeRegressor\n\nDescribe the surrogate model. Use the information from the scikit-learn documentation.\nUse the surrogate as the model for optimization.\n\n\n\n10.5.2 2. A random forest regressor: RandomForestRegressor\n\nDescribe the surrogate model. Use the information from the scikit-learn documentation.\nUse the surrogate as the model for optimization.\n\n\n\n10.5.3 3. Ordinary least squares Linear Regression: LinearRegression\n\nDescribe the surrogate model. Use the information from the scikit-learn documentation.\nUse the surrogate as the model for optimization.\n\n\n\n10.5.4 4. Linear least squares with l2 regularization: Ridge\n\nDescribe the surrogate model. Use the information from the scikit-learn documentation.\nUse the surrogate as the model for optimization.\n\n\n\n10.5.5 5. Gradient Boosting: HistGradientBoostingRegressor\n\nDescribe the surrogate model. Use the information from the scikit-learn documentation.\nUse the surrogate as the model for optimization.\n\n\n\n10.5.6 6. Comparison of Surrogates\n\nUse the following two objective functions\n\nthe 1-dim sphere function fun_sphere and\nthe two-dim Branin function fun_branin:\n\nfor a comparison of the performance of the five different surrogates:\n\nspotpython’s internal Kriging\nDecisionTreeRegressor\nRandomForestRegressor\nlinear_model.LinearRegression\nlinear_model.Ridge.\n\nGenerate a table with the results (number of function evaluations, best function value, and best parameter vector) for each surrogate and each function as shown in Table 10.1.\n\n\n\n\nTable 10.1: Result table\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsurrogate\nfun\nfun_evals\nmax_time\nx_0\nmin_y\nComments\n\n\n\n\nKriging\nfun_sphere\n10\ninf\n\n\n\n\n\nKriging\nfun_branin\n10\ninf\n\n\n\n\n\nDecisionTreeRegressor\nfun_sphere\n10\ninf\n\n\n\n\n\n…\n…\n…\n…\n\n\n\n\n\nRidge\nfun_branin\n10\ninf\n\n\n\n\n\n\n\n\n\n\nDiscuss the results. Which surrogate is the best for which function? Why?",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Using `sklearn` Surrogates in `spotpython`</span>"
    ]
  },
  {
    "objectID": "010_num_spot_sklearn_surrogate.html#selected-solutions",
    "href": "010_num_spot_sklearn_surrogate.html#selected-solutions",
    "title": "10  Using sklearn Surrogates in spotpython",
    "section": "10.6 Selected Solutions",
    "text": "10.6 Selected Solutions\n\n10.6.1 Solution to Exercise Section 10.5.5: Gradient Boosting\n\n10.6.1.1 Branin: Using SPOT\n\nimport numpy as np\nfrom math import inf\nfrom spotpython.fun.objectivefunctions import analytical\nfrom spotpython.utils.init import fun_control_init, design_control_init\nfrom spotpython.spot import spot\n\n\nThe Objective Function Branin\n\n\nfun = analytical().fun_branin\nPREFIX = \"BRANIN\"\nfun_control = fun_control_init(\n    PREFIX=PREFIX,\n    lower = np.array([-5,-0]),\n    upper = np.array([10,15]),\n    fun_evals=20,\n    max_time=inf)\n\ndesign_control = design_control_init(\n    init_size=10)\n\n\nRunning the surrogate model based optimizer Spot:\n\n\nspot_2 = spot.Spot(fun=fun,\n                   fun_control=fun_control,\n                   design_control=design_control)\nspot_2.run()\n\nspotpython tuning: 3.1468336273020228 [######----] 55.00% \nspotpython tuning: 3.1468336273020228 [######----] 60.00% \nspotpython tuning: 3.1468336273020228 [######----] 65.00% \nspotpython tuning: 3.1468336273020228 [#######---] 70.00% \nspotpython tuning: 1.1486878851267175 [########--] 75.00% \nspotpython tuning: 1.0238265839035492 [########--] 80.00% \nspotpython tuning: 0.42056072017865986 [########--] 85.00% \nspotpython tuning: 0.4019421180007683 [#########-] 90.00% \nspotpython tuning: 0.39920553705190365 [##########] 95.00% \nspotpython tuning: 0.39920553705190365 [##########] 100.00% Done...\n\n\n\n&lt;spotpython.spot.spot.Spot at 0x377cd2780&gt;\n\n\n\nPrint the results\n\n\nspot_2.print_results()\n\nmin y: 0.39920553705190365\nx0: 3.154894449957061\nx1: 2.286298891852929\n\n\n[['x0', 3.154894449957061], ['x1', 2.286298891852929]]\n\n\n\nShow the optimization progress:\n\n\nspot_2.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\nGenerate a surrogate model plot:\n\n\nspot_2.surrogate.plot()\n\n\n\n\n\n\n\n\n\n\n10.6.1.2 Branin: Using Surrogates From scikit-learn\n\nThe HistGradientBoostingRegressor model from scikit-learn is selected:\n\n\n# Needed for the sklearn surrogates:\nfrom sklearn.ensemble import HistGradientBoostingRegressor\nimport pandas as pd\nS_XGB = HistGradientBoostingRegressor()\n\n\nThe scikit-learn XGB model S_XGB is selected for Spot as follows: surrogate = S_XGB.\nSimilar to the Spot run with the internal Kriging model, we can call the run with the scikit-learn surrogate:\n\n\nfun = analytical(seed=123).fun_branin\nspot_2_XGB = spot.Spot(fun=fun,\n                     fun_control=fun_control,\n                     design_control=design_control,\n                     surrogate = S_XGB)\nspot_2_XGB.run()\n\nspotpython tuning: 30.69410528614059 [######----] 55.00% \nspotpython tuning: 30.69410528614059 [######----] 60.00% \nspotpython tuning: 30.69410528614059 [######----] 65.00% \nspotpython tuning: 30.69410528614059 [#######---] 70.00% \nspotpython tuning: 1.3263745845108854 [########--] 75.00% \nspotpython tuning: 1.3263745845108854 [########--] 80.00% \nspotpython tuning: 1.3263745845108854 [########--] 85.00% \nspotpython tuning: 1.3263745845108854 [#########-] 90.00% \nspotpython tuning: 1.3263745845108854 [##########] 95.00% \nspotpython tuning: 1.3263745845108854 [##########] 100.00% Done...\n\n\n\n&lt;spotpython.spot.spot.Spot at 0x3980e1dc0&gt;\n\n\n\nPrint the Results\n\n\nspot_2_XGB.print_results()\n\nmin y: 1.3263745845108854\nx0: -2.872730773493426\nx1: 10.874313833535739\n\n\n[['x0', -2.872730773493426], ['x1', 10.874313833535739]]\n\n\n\nShow the Progress\n\n\nspot_2_XGB.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\nSince the sklearn model does not provide a plot method, we cannot generate a surrogate model plot.\n\n\n\n10.6.1.3 One-dimensional Sphere Function With spotpython’s Kriging\n\nIn this example, we will use an one-dimensional function, which allows us to visualize the optimization process.\n\nshow_models= True is added to the argument list.\n\n\n\nfrom spotpython.fun.objectivefunctions import analytical\nfun_control = fun_control_init(\n    lower = np.array([-1]),\n    upper = np.array([1]),\n    fun_evals=10,\n    max_time=inf,\n    show_models= True,\n    tolerance_x = np.sqrt(np.spacing(1)))\nfun = analytical(seed=123).fun_sphere\ndesign_control = design_control_init(\n    init_size=3)\n\n\nspot_1 = spot.Spot(fun=fun,\n                    fun_control=fun_control,\n                    design_control=design_control)\nspot_1.run()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.03475493366922229 [####------] 40.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.03475493366922229 [#####-----] 50.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.014772665252290174 [######----] 60.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.00020571435112063172 [#######---] 70.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 5.943319903709223e-08 [########--] 80.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 5.943319903709223e-08 [#########-] 90.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 5.943319903709223e-08 [##########] 100.00% Done...\n\n\n\n\nPrint the Results\n\n\nspot_1.print_results()\n\nmin y: 5.943319903709223e-08\nx0: -0.0002437892512747275\n\n\n[['x0', -0.0002437892512747275]]\n\n\n\nShow the Progress\n\n\nspot_1.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\nThe method plot_model plots the final surrogate:\n\n\nspot_1.plot_model()\n\n\n\n\n\n\n\n\n\n\n10.6.1.4 One-dimensional Sphere Function With Sklearn Model HistGradientBoostingRegressor\n\nThis example visualizes the search process on the HistGradientBoostingRegressor surrogate from sklearn.\nTherefore surrogate = S_XGB is added to the argument list.\n\n\nfun_control = fun_control_init(\n    lower = np.array([-1]),\n    upper = np.array([1]),\n    fun_evals=10,\n    max_time=inf,\n    show_models= True,\n    tolerance_x = np.sqrt(np.spacing(1)))\nfun = analytical(seed=123).fun_sphere\ndesign_control = design_control_init(\n    init_size=3)\nspot_1_XGB = spot.Spot(fun=fun,\n                      fun_control=fun_control,\n                      design_control=design_control,\n                      surrogate = S_XGB)\nspot_1_XGB.run()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.03475493366922229 [####------] 40.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.03475493366922229 [#####-----] 50.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.03475493366922229 [######----] 60.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.03475493366922229 [#######---] 70.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.008730885505764131 [########--] 80.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.008730885505764131 [#########-] 90.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.008730885505764131 [##########] 100.00% Done...\n\n\n\n\nspot_1_XGB.print_results()\n\nmin y: 0.008730885505764131\nx0: 0.09343920754032609\n\n\n[['x0', 0.09343920754032609]]\n\n\n\nspot_1_XGB.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\nspot_1_XGB.plot_model()",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Using `sklearn` Surrogates in `spotpython`</span>"
    ]
  },
  {
    "objectID": "010_num_spot_sklearn_surrogate.html#jupyter-notebook",
    "href": "010_num_spot_sklearn_surrogate.html#jupyter-notebook",
    "title": "10  Using sklearn Surrogates in spotpython",
    "section": "10.7 Jupyter Notebook",
    "text": "10.7 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Using `sklearn` Surrogates in `spotpython`</span>"
    ]
  },
  {
    "objectID": "011_num_spot_sklearn_gaussian.html",
    "href": "011_num_spot_sklearn_gaussian.html",
    "title": "11  Sequential Parameter Optimization: Gaussian Process Models",
    "section": "",
    "text": "11.1 Gaussian Processes Regression: Basic Introductory scikit-learn Example",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Sequential Parameter Optimization:  Gaussian Process Models</span>"
    ]
  },
  {
    "objectID": "011_num_spot_sklearn_gaussian.html#gaussian-processes-regression-basic-introductory-scikit-learn-example",
    "href": "011_num_spot_sklearn_gaussian.html#gaussian-processes-regression-basic-introductory-scikit-learn-example",
    "title": "11  Sequential Parameter Optimization: Gaussian Process Models",
    "section": "",
    "text": "This is the example from scikit-learn: https://scikit-learn.org/stable/auto_examples/gaussian_process/plot_gpr_noisy_targets.html\nAfter fitting our model, we see that the hyperparameters of the kernel have been optimized.\nNow, we will use our kernel to compute the mean prediction of the full dataset and plot the 95% confidence interval.\n\n\n11.1.1 Train and Test Data\n\nX = np.linspace(start=0, stop=10, num=1_000).reshape(-1, 1)\ny = np.squeeze(X * np.sin(X))\nrng = np.random.RandomState(1)\ntraining_indices = rng.choice(np.arange(y.size), size=6, replace=False)\nX_train, y_train = X[training_indices], y[training_indices]\n\n\n\n11.1.2 Building the Surrogate With Sklearn\n\nThe model building with sklearn consisits of three steps:\n\nInstantiating the model, then\nfitting the model (using fit), and\nmaking predictions (using predict)\n\n\n\nkernel = 1 * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2))\ngaussian_process = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\ngaussian_process.fit(X_train, y_train)\nmean_prediction, std_prediction = gaussian_process.predict(X, return_std=True)\n\n\n\n11.1.3 Plotting the SklearnModel\n\nplt.plot(X, y, label=r\"$f(x) = x \\sin(x)$\", linestyle=\"dotted\")\nplt.scatter(X_train, y_train, label=\"Observations\")\nplt.plot(X, mean_prediction, label=\"Mean prediction\")\nplt.fill_between(\n    X.ravel(),\n    mean_prediction - 1.96 * std_prediction,\n    mean_prediction + 1.96 * std_prediction,\n    alpha=0.5,\n    label=r\"95% confidence interval\",\n)\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"sk-learn Version: Gaussian process regression on noise-free dataset\")\n\n\n\n\n\n\n\n\n\n\n11.1.4 The spotpython Version\n\nThe spotpython version is very similar:\n\nInstantiating the model, then\nfitting the model and\nmaking predictions (using predict).\n\n\n\nS = Kriging(name='kriging',  seed=123, log_level=50, cod_type=\"norm\")\nS.fit(X_train, y_train)\nS_mean_prediction, S_std_prediction, S_ei = S.predict(X, return_val=\"all\")\n\n\nplt.plot(X, y, label=r\"$f(x) = x \\sin(x)$\", linestyle=\"dotted\")\nplt.scatter(X_train, y_train, label=\"Observations\")\nplt.plot(X, S_mean_prediction, label=\"Mean prediction\")\nplt.fill_between(\n    X.ravel(),\n    S_mean_prediction - 1.96 * S_std_prediction,\n    S_mean_prediction + 1.96 * S_std_prediction,\n    alpha=0.5,\n    label=r\"95% confidence interval\",\n)\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"spotpython Version: Gaussian process regression on noise-free dataset\")\n\n\n\n\n\n\n\n\n\n\n11.1.5 Visualizing the Differences Between the spotpython and the sklearn Model Fits\n\nplt.plot(X, y, label=r\"$f(x) = x \\sin(x)$\", linestyle=\"dotted\")\nplt.scatter(X_train, y_train, label=\"Observations\")\nplt.plot(X, S_mean_prediction, label=\"spotpython Mean prediction\")\nplt.plot(X, mean_prediction, label=\"Sklearn Mean Prediction\")\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"Comparing Mean Predictions\")",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Sequential Parameter Optimization:  Gaussian Process Models</span>"
    ]
  },
  {
    "objectID": "011_num_spot_sklearn_gaussian.html#exercises",
    "href": "011_num_spot_sklearn_gaussian.html#exercises",
    "title": "11  Sequential Parameter Optimization: Gaussian Process Models",
    "section": "11.2 Exercises",
    "text": "11.2 Exercises\n\n11.2.1 Schonlau Example Function\n\nThe Schonlau Example Function is based on sample points only (there is no analytical function description available):\n\n\nX = np.linspace(start=0, stop=13, num=1_000).reshape(-1, 1)\nX_train = np.array([1., 2., 3., 4., 12.]).reshape(-1,1)\ny_train = np.array([0., -1.75, -2, -0.5, 5.])\n\n\nDescribe the function.\nCompare the two models that were build using the spotpython and the sklearn surrogate.\nNote: Since there is no analytical function available, you might be interested in adding some points and describe the effects.\n\n\n\n11.2.2 Forrester Example Function\n\nThe Forrester Example Function is defined as follows:\nf(x) = (6x- 2)^2 sin(12x-4) for x in [0,1].\nData points are generated as follows:\n\n\nfrom spotpython.utils.init import fun_control_init\nX = np.linspace(start=-0.5, stop=1.5, num=1_000).reshape(-1, 1)\nX_train = np.array([0.0, 0.175, 0.225, 0.3, 0.35, 0.375, 0.5,1]).reshape(-1,1)\nfun = analytical().fun_forrester\nfun_control = fun_control_init(sigma = 0.1)\ny = fun(X, fun_control=fun_control)\ny_train = fun(X_train, fun_control=fun_control)\n\n\nDescribe the function.\nCompare the two models that were build using the spotpython and the sklearn surrogate.\nNote: Modify the noise level (\"sigma\"), e.g., use a value of 0.2, and compare the two models.\n\n\nfun_control = fun_control_init(sigma = 0.2)\n\n\n\n11.2.3 fun_runge Function (1-dim)\n\nThe Runge function is defined as follows:\nf(x) = 1/ (1 + sum(x_i))^2\nData points are generated as follows:\n\n\ngen = spacefilling(1)\nrng = np.random.RandomState(1)\nlower = np.array([-10])\nupper = np.array([10])\nfun = analytical().fun_runge\nfun_control = fun_control_init(sigma = 0.025)\nX_train = gen.scipy_lhd(10, lower=lower, upper = upper).reshape(-1,1)\ny_train = fun(X, fun_control=fun_control)\nX = np.linspace(start=-13, stop=13, num=1000).reshape(-1, 1)\ny = fun(X, fun_control=fun_control)\n\n\nDescribe the function.\nCompare the two models that were build using the spotpython and the sklearn surrogate.\nNote: Modify the noise level (\"sigma\"), e.g., use a value of 0.05, and compare the two models.\n\n\nfun_control = fun_control_init(sigma = 0.5)\n\n\n\n11.2.4 fun_cubed (1-dim)\n\nThe Cubed function is defined as follows:\nnp.sum(X[i]** 3)\nData points are generated as follows:\n\n\ngen = spacefilling(1)\nrng = np.random.RandomState(1)\nfun_control = fun_control_init(sigma = 0.025,\n                lower = np.array([-10]),\n                upper = np.array([10]))\nfun = analytical().fun_cubed\nX_train = gen.scipy_lhd(10, lower=lower, upper = upper).reshape(-1,1)\ny_train = fun(X, fun_control=fun_control)\nX = np.linspace(start=-13, stop=13, num=1000).reshape(-1, 1)\ny = fun(X, fun_control=fun_control)\n\n\nDescribe the function.\nCompare the two models that were build using the spotpython and the sklearn surrogate.\nNote: Modify the noise level (\"sigma\"), e.g., use a value of 0.05, and compare the two models.\n\n\nfun_control = fun_control_init(sigma = 0.025)\n\n\n\n11.2.5 The Effect of Noise\nHow does the behavior of the spotpython fit changes when the argument noise is set to True, i.e.,\nS = Kriging(name='kriging',  seed=123, n_theta=1, noise=True)\nis used?",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Sequential Parameter Optimization:  Gaussian Process Models</span>"
    ]
  },
  {
    "objectID": "012_num_spot_ei.html",
    "href": "012_num_spot_ei.html",
    "title": "12  Expected Improvement",
    "section": "",
    "text": "12.1 Example: Spot and the 1-dim Sphere Function\nimport numpy as np\nfrom math import inf\nfrom spotpython.fun.objectivefunctions import analytical\nfrom spotpython.spot import spot\nfrom spotpython.utils.init import fun_control_init, surrogate_control_init, design_control_init\nimport matplotlib.pyplot as plt",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Expected Improvement</span>"
    ]
  },
  {
    "objectID": "012_num_spot_ei.html#example-spot-and-the-1-dim-sphere-function",
    "href": "012_num_spot_ei.html#example-spot-and-the-1-dim-sphere-function",
    "title": "12  Expected Improvement",
    "section": "",
    "text": "12.1.1 The Objective Function: 1-dim Sphere\n\nThe spotpython package provides several classes of objective functions.\nWe will use an analytical objective function, i.e., a function that can be described by a (closed) formula: \\[f(x) = x^2 \\]\n\n\nfun = analytical().fun_sphere\n\n\nThe size of the lower bound vector determines the problem dimension.\nHere we will use np.array([-1]), i.e., a one-dim function.\n\n\n\n\n\n\n\nTensorBoard\n\n\n\nSimilar to the one-dimensional case, which was introduced in Section Section 7.5, we can use TensorBoard to monitor the progress of the optimization. We will use the same code, only the prefix is different:\n\nfrom spotpython.utils.init import fun_control_init\nPREFIX = \"07_Y\"\nfun_control = fun_control_init(\n    PREFIX=PREFIX,\n    fun_evals = 25,\n    lower = np.array([-1]),\n    upper = np.array([1]),\n    tolerance_x = np.sqrt(np.spacing(1)),)\ndesign_control = design_control_init(init_size=10)\n\n\n\n\nspot_1 = spot.Spot(\n            fun=fun,\n            fun_control=fun_control,\n            design_control=design_control)\nspot_1.run()\n\nspotpython tuning: 4.959603317754042e-09 [####------] 44.00% \nspotpython tuning: 4.959603317754042e-09 [#####-----] 48.00% \nspotpython tuning: 4.959603317754042e-09 [#####-----] 52.00% \nspotpython tuning: 4.959603317754042e-09 [######----] 56.00% \nspotpython tuning: 1.7538785665210774e-10 [######----] 60.00% \nspotpython tuning: 5.299979470384224e-12 [######----] 64.00% \nspotpython tuning: 5.299979470384224e-12 [#######---] 68.00% \nspotpython tuning: 5.299979470384224e-12 [#######---] 72.00% \nspotpython tuning: 5.299979470384224e-12 [########--] 76.00% \nspotpython tuning: 5.299979470384224e-12 [########--] 80.00% \nspotpython tuning: 5.299979470384224e-12 [########--] 84.00% \nspotpython tuning: 5.299979470384224e-12 [#########-] 88.00% \nspotpython tuning: 5.299979470384224e-12 [#########-] 92.00% \nspotpython tuning: 5.299979470384224e-12 [##########] 96.00% \nspotpython tuning: 5.299979470384224e-12 [##########] 100.00% Done...\n\n\n\n&lt;spotpython.spot.spot.Spot at 0x362032b70&gt;\n\n\n\n\n12.1.2 Results\n\nspot_1.print_results()\n\nmin y: 5.299979470384224e-12\nx0: 2.302168427892326e-06\n\n\n[['x0', 2.302168427892326e-06]]\n\n\n\nspot_1.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\n\n\nTensorBoard visualization of the spotpython optimization process and the surrogate model.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Expected Improvement</span>"
    ]
  },
  {
    "objectID": "012_num_spot_ei.html#same-but-with-ei-as-infill_criterion",
    "href": "012_num_spot_ei.html#same-but-with-ei-as-infill_criterion",
    "title": "12  Expected Improvement",
    "section": "12.2 Same, but with EI as infill_criterion",
    "text": "12.2 Same, but with EI as infill_criterion\n\nPREFIX = \"07_EI_ISO\"\nfun_control = fun_control_init(\n    PREFIX=PREFIX,\n    lower = np.array([-1]),\n    upper = np.array([1]),\n    fun_evals = 25,\n    tolerance_x = np.sqrt(np.spacing(1)),\n    infill_criterion = \"ei\")\n\n\nspot_1_ei = spot.Spot(fun=fun,\n                     fun_control=fun_control)\nspot_1_ei.run()\n\nspotpython tuning: 7.188987729200596e-08 [####------] 44.00% \nspotpython tuning: 7.188987729200596e-08 [#####-----] 48.00% \nspotpython tuning: 7.188987729200596e-08 [#####-----] 52.00% \nspotpython tuning: 7.188987729200596e-08 [######----] 56.00% \nspotpython tuning: 5.939954122907979e-08 [######----] 60.00% \nspotpython tuning: 1.3947524785731501e-08 [######----] 64.00% \nspotpython tuning: 1.3947524785731501e-08 [#######---] 68.00% \nspotpython tuning: 1.3947524785731501e-08 [#######---] 72.00% \nspotpython tuning: 1.3947524785731501e-08 [########--] 76.00% \nspotpython tuning: 1.3947524785731501e-08 [########--] 80.00% \nspotpython tuning: 4.854409561808151e-10 [########--] 84.00% \nspotpython tuning: 4.854409561808151e-10 [#########-] 88.00% \nspotpython tuning: 2.611463411033466e-11 [#########-] 92.00% \nspotpython tuning: 2.611463411033466e-11 [##########] 96.00% \nspotpython tuning: 2.611463411033466e-11 [##########] 100.00% Done...\n\n\n\n&lt;spotpython.spot.spot.Spot at 0x3647ccc80&gt;\n\n\n\nspot_1_ei.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\nspot_1_ei.print_results()\n\nmin y: 2.611463411033466e-11\nx0: 5.110247949985857e-06\n\n\n[['x0', 5.110247949985857e-06]]\n\n\n\n\n\nTensorBoard visualization of the spotpython optimization process and the surrogate model. Expected improvement, isotropic Kriging.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Expected Improvement</span>"
    ]
  },
  {
    "objectID": "012_num_spot_ei.html#non-isotropic-kriging",
    "href": "012_num_spot_ei.html#non-isotropic-kriging",
    "title": "12  Expected Improvement",
    "section": "12.3 Non-isotropic Kriging",
    "text": "12.3 Non-isotropic Kriging\n\nPREFIX = \"07_EI_NONISO\"\nfun_control = fun_control_init(\n    PREFIX=PREFIX,\n    lower = np.array([-1, -1]),\n    upper = np.array([1, 1]),\n    fun_evals = 25,\n    tolerance_x = np.sqrt(np.spacing(1)),\n    infill_criterion = \"ei\")\nsurrogate_control = surrogate_control_init(\n    n_theta=2,\n    noise=False,\n    )\n\n\nspot_2_ei_noniso = spot.Spot(fun=fun,\n                   fun_control=fun_control,\n                   surrogate_control=surrogate_control)\nspot_2_ei_noniso.run()\n\nspotpython tuning: 1.8084153639415482e-05 [####------] 44.00% \nspotpython tuning: 1.8084153639415482e-05 [#####-----] 48.00% \nspotpython tuning: 1.8084153639415482e-05 [#####-----] 52.00% \nspotpython tuning: 1.8084153639415482e-05 [######----] 56.00% \nspotpython tuning: 1.8084153639415482e-05 [######----] 60.00% \nspotpython tuning: 1.8084153639415482e-05 [######----] 64.00% \nspotpython tuning: 1.8084153639415482e-05 [#######---] 68.00% \nspotpython tuning: 1.8084153639415482e-05 [#######---] 72.00% \nspotpython tuning: 1.8084153639415482e-05 [########--] 76.00% \nspotpython tuning: 1.7065306452997463e-05 [########--] 80.00% \nspotpython tuning: 1.7065306452997463e-05 [########--] 84.00% \nspotpython tuning: 7.056740725219606e-06 [#########-] 88.00% \nspotpython tuning: 7.056740725219606e-06 [#########-] 92.00% \nspotpython tuning: 7.056740725219606e-06 [##########] 96.00% \nspotpython tuning: 7.056740725219606e-06 [##########] 100.00% Done...\n\n\n\n&lt;spotpython.spot.spot.Spot at 0x364587c50&gt;\n\n\n\nspot_2_ei_noniso.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\nspot_2_ei_noniso.print_results()\n\nmin y: 7.056740725219606e-06\nx0: -0.0025062845492088196\nx1: -0.0008804989969425007\n\n\n[['x0', -0.0025062845492088196], ['x1', -0.0008804989969425007]]\n\n\n\nspot_2_ei_noniso.surrogate.plot()\n\n\n\n\n\n\n\n\n\n\n\nTensorBoard visualization of the spotpython optimization process and the surrogate model. Expected improvement, isotropic Kriging.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Expected Improvement</span>"
    ]
  },
  {
    "objectID": "012_num_spot_ei.html#using-sklearn-surrogates",
    "href": "012_num_spot_ei.html#using-sklearn-surrogates",
    "title": "12  Expected Improvement",
    "section": "12.4 Using sklearn Surrogates",
    "text": "12.4 Using sklearn Surrogates\n\n12.4.1 The spot Loop\nThe spot loop consists of the following steps:\n\nInit: Build initial design \\(X\\)\nEvaluate initial design on real objective \\(f\\): \\(y = f(X)\\)\nBuild surrogate: \\(S = S(X,y)\\)\nOptimize on surrogate: \\(X_0 =  \\text{optimize}(S)\\)\nEvaluate on real objective: \\(y_0 = f(X_0)\\)\nImpute (Infill) new points: \\(X = X \\cup X_0\\), \\(y = y \\cup y_0\\).\nGot 3.\n\nThe spot loop is implemented in R as follows:\n\n\n\nVisual representation of the model based search with SPOT. Taken from: Bartz-Beielstein, T., and Zaefferer, M. Hyperparameter tuning approaches. In Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide, E. Bartz, T. Bartz-Beielstein, M. Zaefferer, and O. Mersmann, Eds. Springer, 2022, ch. 4, pp. 67–114.\n\n\n\n\n12.4.2 spot: The Initial Model\n\n12.4.2.1 Example: Modifying the initial design size\nThis is the “Example: Modifying the initial design size” from Chapter 4.5.1 in [bart21i].\n\nspot_ei = spot.Spot(fun=fun,\n                fun_control=fun_control_init(\n                lower = np.array([-1,-1]),\n                upper= np.array([1,1])), \n                design_control = design_control_init(init_size=5))\nspot_ei.run()\n\nspotpython tuning: 0.13771720111978272 [####------] 40.00% \nspotpython tuning: 0.008762260544617942 [#####-----] 46.67% \nspotpython tuning: 0.0028383641218116835 [#####-----] 53.33% \nspotpython tuning: 0.0008109493206433335 [######----] 60.00% \nspotpython tuning: 0.0003652470205973824 [#######---] 66.67% \nspotpython tuning: 0.00036032551596159646 [#######---] 73.33% \nspotpython tuning: 0.00035888041070709844 [########--] 80.00% \nspotpython tuning: 0.00032677794812133767 [#########-] 86.67% \nspotpython tuning: 0.0002726988496483528 [#########-] 93.33% \nspotpython tuning: 0.00015304178060680248 [##########] 100.00% Done...\n\n\n\n&lt;spotpython.spot.spot.Spot at 0x367a6fda0&gt;\n\n\n\nspot_ei.plot_progress()\n\n\n\n\n\n\n\n\n\nnp.min(spot_1.y), np.min(spot_ei.y)\n\n(5.299979470384224e-12, 0.00015304178060680248)\n\n\n\n\n\n12.4.3 Init: Build Initial Design\n\nfrom spotpython.design.spacefilling import spacefilling\nfrom spotpython.build.kriging import Kriging\nfrom spotpython.fun.objectivefunctions import analytical\ngen = spacefilling(2)\nrng = np.random.RandomState(1)\nlower = np.array([-5,-0])\nupper = np.array([10,15])\nfun = analytical().fun_branin\n\nX = gen.scipy_lhd(10, lower=lower, upper = upper)\nprint(X)\ny = fun(X, fun_control=fun_control)\nprint(y)\n\n[[ 8.97647221 13.41926847]\n [ 0.66946019  1.22344228]\n [ 5.23614115 13.78185824]\n [ 5.6149825  11.5851384 ]\n [-1.72963184  1.66516096]\n [-4.26945568  7.1325531 ]\n [ 1.26363761 10.17935555]\n [ 2.88779942  8.05508969]\n [-3.39111089  4.15213772]\n [ 7.30131231  5.22275244]]\n[128.95676449  31.73474356 172.89678121 126.71295908  64.34349975\n  70.16178611  48.71407916  31.77322887  76.91788181  30.69410529]\n\n\n\nS = Kriging(name='kriging',  seed=123)\nS.fit(X, y)\nS.plot()\n\n\n\n\n\n\n\n\n\ngen = spacefilling(2, seed=123)\nX0 = gen.scipy_lhd(3)\ngen = spacefilling(2, seed=345)\nX1 = gen.scipy_lhd(3)\nX2 = gen.scipy_lhd(3)\ngen = spacefilling(2, seed=123)\nX3 = gen.scipy_lhd(3)\nX0, X1, X2, X3\n\n(array([[0.77254938, 0.31539299],\n        [0.59321338, 0.93854273],\n        [0.27469803, 0.3959685 ]]),\n array([[0.78373509, 0.86811887],\n        [0.06692621, 0.6058029 ],\n        [0.41374778, 0.00525456]]),\n array([[0.121357  , 0.69043832],\n        [0.41906219, 0.32838498],\n        [0.86742658, 0.52910374]]),\n array([[0.77254938, 0.31539299],\n        [0.59321338, 0.93854273],\n        [0.27469803, 0.3959685 ]]))\n\n\n\n\n12.4.4 Evaluate\n\n\n12.4.5 Build Surrogate\n\n\n12.4.6 A Simple Predictor\nThe code below shows how to use a simple model for prediction.\n\nAssume that only two (very costly) measurements are available:\n\nf(0) = 0.5\nf(2) = 2.5\n\nWe are interested in the value at \\(x_0 = 1\\), i.e., \\(f(x_0 = 1)\\), but cannot run an additional, third experiment.\n\n\nfrom sklearn import linear_model\nX = np.array([[0], [2]])\ny = np.array([0.5, 2.5])\nS_lm = linear_model.LinearRegression()\nS_lm = S_lm.fit(X, y)\nX0 = np.array([[1]])\ny0 = S_lm.predict(X0)\nprint(y0)\n\n[1.5]\n\n\n\nCentral Idea:\n\nEvaluation of the surrogate model S_lm is much cheaper (or / and much faster) than running the real-world experiment \\(f\\).",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Expected Improvement</span>"
    ]
  },
  {
    "objectID": "012_num_spot_ei.html#gaussian-processes-regression-basic-introductory-example",
    "href": "012_num_spot_ei.html#gaussian-processes-regression-basic-introductory-example",
    "title": "12  Expected Improvement",
    "section": "12.5 Gaussian Processes regression: basic introductory example",
    "text": "12.5 Gaussian Processes regression: basic introductory example\nThis example was taken from scikit-learn. After fitting our model, we see that the hyperparameters of the kernel have been optimized. Now, we will use our kernel to compute the mean prediction of the full dataset and plot the 95% confidence interval.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport math as m\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF\n\nX = np.linspace(start=0, stop=10, num=1_000).reshape(-1, 1)\ny = np.squeeze(X * np.sin(X))\nrng = np.random.RandomState(1)\ntraining_indices = rng.choice(np.arange(y.size), size=6, replace=False)\nX_train, y_train = X[training_indices], y[training_indices]\n\nkernel = 1 * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2))\ngaussian_process = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\ngaussian_process.fit(X_train, y_train)\ngaussian_process.kernel_\n\nmean_prediction, std_prediction = gaussian_process.predict(X, return_std=True)\n\nplt.plot(X, y, label=r\"$f(x) = x \\sin(x)$\", linestyle=\"dotted\")\nplt.scatter(X_train, y_train, label=\"Observations\")\nplt.plot(X, mean_prediction, label=\"Mean prediction\")\nplt.fill_between(\n    X.ravel(),\n    mean_prediction - 1.96 * std_prediction,\n    mean_prediction + 1.96 * std_prediction,\n    alpha=0.5,\n    label=r\"95% confidence interval\",\n)\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"sk-learn Version: Gaussian process regression on noise-free dataset\")\n\n\n\n\n\n\n\n\n\nfrom spotpython.build.kriging import Kriging\nimport numpy as np\nimport matplotlib.pyplot as plt\nrng = np.random.RandomState(1)\nX = np.linspace(start=0, stop=10, num=1_000).reshape(-1, 1)\ny = np.squeeze(X * np.sin(X))\ntraining_indices = rng.choice(np.arange(y.size), size=6, replace=False)\nX_train, y_train = X[training_indices], y[training_indices]\n\n\nS = Kriging(name='kriging',  seed=123, log_level=50, cod_type=\"norm\")\nS.fit(X_train, y_train)\n\nmean_prediction, std_prediction, ei = S.predict(X, return_val=\"all\")\n\nstd_prediction\n\nplt.plot(X, y, label=r\"$f(x) = x \\sin(x)$\", linestyle=\"dotted\")\nplt.scatter(X_train, y_train, label=\"Observations\")\nplt.plot(X, mean_prediction, label=\"Mean prediction\")\nplt.fill_between(\n    X.ravel(),\n    mean_prediction - 1.96 * std_prediction,\n    mean_prediction + 1.96 * std_prediction,\n    alpha=0.5,\n    label=r\"95% confidence interval\",\n)\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"spotpython Version: Gaussian process regression on noise-free dataset\")",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Expected Improvement</span>"
    ]
  },
  {
    "objectID": "012_num_spot_ei.html#the-surrogate-using-scikit-learn-models",
    "href": "012_num_spot_ei.html#the-surrogate-using-scikit-learn-models",
    "title": "12  Expected Improvement",
    "section": "12.6 The Surrogate: Using scikit-learn models",
    "text": "12.6 The Surrogate: Using scikit-learn models\nDefault is the internal kriging surrogate.\n\nS_0 = Kriging(name='kriging', seed=123)\n\nModels from scikit-learn can be selected, e.g., Gaussian Process:\n\n# Needed for the sklearn surrogates:\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn import linear_model\nfrom sklearn import tree\nimport pandas as pd\n\n\nkernel = 1 * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2))\nS_GP = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\n\n\nand many more:\n\n\nS_Tree = DecisionTreeRegressor(random_state=0)\nS_LM = linear_model.LinearRegression()\nS_Ridge = linear_model.Ridge()\nS_RF = RandomForestRegressor(max_depth=2, random_state=0) \n\n\nThe scikit-learn GP model S_GP is selected.\n\n\nS = S_GP\n\n\nisinstance(S, GaussianProcessRegressor)\n\nTrue\n\n\n\nfrom spotpython.fun.objectivefunctions import analytical\nfun = analytical().fun_branin\nfun_control = fun_control_init(\n    lower = np.array([-5,-0]),\n    upper = np.array([10,15]),\n    fun_evals = 15)    \ndesign_control = design_control_init(init_size=5)\nspot_GP = spot.Spot(fun=fun, \n                    fun_control=fun_control,\n                    surrogate=S, \n                    design_control=design_control)\nspot_GP.run()\n\nspotpython tuning: 24.51465459019188 [####------] 40.00% \nspotpython tuning: 11.003101704408273 [#####-----] 46.67% \nspotpython tuning: 11.003101704408273 [#####-----] 53.33% \nspotpython tuning: 7.281515308693262 [######----] 60.00% \nspotpython tuning: 7.281515308693262 [#######---] 66.67% \nspotpython tuning: 7.281515308693262 [#######---] 73.33% \nspotpython tuning: 2.9519942803779493 [########--] 80.00% \nspotpython tuning: 2.9519942803779493 [#########-] 86.67% \nspotpython tuning: 2.1049767654946914 [#########-] 93.33% \nspotpython tuning: 1.9431498675678949 [##########] 100.00% Done...\n\n\n\n&lt;spotpython.spot.spot.Spot at 0x39146ea80&gt;\n\n\n\nspot_GP.y\n\narray([ 69.32459936, 152.38491454, 107.92560483,  24.51465459,\n        76.73500031,  86.30429136,  11.0031017 ,  16.11757292,\n         7.28151531,  21.82295775,  10.96088904,   2.95199428,\n         3.0290972 ,   2.10497677,   1.94314987])\n\n\n\nspot_GP.plot_progress()\n\n\n\n\n\n\n\n\n\nspot_GP.print_results()\n\nmin y: 1.9431498675678949\nx0: 10.0\nx1: 2.9999226833344648\n\n\n[['x0', 10.0], ['x1', 2.9999226833344648]]",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Expected Improvement</span>"
    ]
  },
  {
    "objectID": "012_num_spot_ei.html#additional-examples",
    "href": "012_num_spot_ei.html#additional-examples",
    "title": "12  Expected Improvement",
    "section": "12.7 Additional Examples",
    "text": "12.7 Additional Examples\n\n# Needed for the sklearn surrogates:\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn import linear_model\nfrom sklearn import tree\nimport pandas as pd\n\n\nkernel = 1 * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2))\nS_GP = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\n\n\nfrom spotpython.build.kriging import Kriging\nimport numpy as np\nimport spotpython\nfrom spotpython.fun.objectivefunctions import analytical\nfrom spotpython.spot import spot\n\nS_K = Kriging(name='kriging',\n              seed=123,\n              log_level=50,\n              infill_criterion = \"y\",\n              n_theta=1,\n              noise=False,\n              cod_type=\"norm\")\nfun = analytical().fun_sphere\n\nfun_control = fun_control_init(\n    lower = np.array([-1,-1]),\n    upper = np.array([1,1]),\n    fun_evals = 25)\n\nspot_S_K = spot.Spot(fun=fun,\n                     fun_control=fun_control,\n                     surrogate=S_K,\n                     design_control=design_control,\n                     surrogate_control=surrogate_control)\nspot_S_K.run()\n\nspotpython tuning: 0.13771716844457255 [##--------] 24.00% \nspotpython tuning: 0.008763992988881779 [###-------] 28.00% \nspotpython tuning: 0.0028324931031249094 [###-------] 32.00% \nspotpython tuning: 0.0008161627041911008 [####------] 36.00% \nspotpython tuning: 0.00036337249944152984 [####------] 40.00% \nspotpython tuning: 0.0003620634598515755 [####------] 44.00% \nspotpython tuning: 0.00036019126988579237 [#####-----] 48.00% \nspotpython tuning: 0.0003310003348891555 [#####-----] 52.00% \nspotpython tuning: 0.0002796810486585005 [######----] 56.00% \nspotpython tuning: 0.00016668209586740844 [######----] 60.00% \nspotpython tuning: 2.105184213458755e-05 [######----] 64.00% \nspotpython tuning: 2.33449020805854e-06 [#######---] 68.00% \nspotpython tuning: 7.112087478830758e-07 [#######---] 72.00% \nspotpython tuning: 4.3581016990329405e-07 [########--] 76.00% \nspotpython tuning: 3.9965568597157324e-07 [########--] 80.00% \nspotpython tuning: 1.9740797347254742e-07 [########--] 84.00% \nspotpython tuning: 1.6627705746993065e-07 [#########-] 88.00% \nspotpython tuning: 1.6627705746993065e-07 [#########-] 92.00% \nspotpython tuning: 1.6627705746993065e-07 [##########] 96.00% \nspotpython tuning: 1.6627705746993065e-07 [##########] 100.00% Done...\n\n\n\n&lt;spotpython.spot.spot.Spot at 0x3913d9040&gt;\n\n\n\nspot_S_K.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\nspot_S_K.surrogate.plot()\n\n\n\n\n\n\n\n\n\nspot_S_K.print_results()\n\nmin y: 1.6627705746993065e-07\nx0: 0.0003245075243596407\nx1: 0.00024692493617273215\n\n\n[['x0', 0.0003245075243596407], ['x1', 0.00024692493617273215]]\n\n\n\n12.7.1 Optimize on Surrogate\n\n\n12.7.2 Evaluate on Real Objective\n\n\n12.7.3 Impute / Infill new Points",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Expected Improvement</span>"
    ]
  },
  {
    "objectID": "012_num_spot_ei.html#tests",
    "href": "012_num_spot_ei.html#tests",
    "title": "12  Expected Improvement",
    "section": "12.8 Tests",
    "text": "12.8 Tests\n\nimport numpy as np\nfrom spotpython.spot import spot\nfrom spotpython.fun.objectivefunctions import analytical\n\nfun_sphere = analytical().fun_sphere\n\nfun_control = fun_control_init(\n                    lower=np.array([-1, -1]),\n                    upper=np.array([1, 1]),\n                    n_points = 2)\nspot_1 = spot.Spot(\n    fun=fun_sphere,\n    fun_control=fun_control,\n)\n\n# (S-2) Initial Design:\nspot_1.X = spot_1.design.scipy_lhd(\n    spot_1.design_control[\"init_size\"], lower=spot_1.lower, upper=spot_1.upper\n)\nprint(spot_1.X)\n\n# (S-3): Eval initial design:\nspot_1.y = spot_1.fun(spot_1.X)\nprint(spot_1.y)\n\nspot_1.fit_surrogate()\nX0 = spot_1.suggest_new_X()\nprint(X0)\nassert X0.size == spot_1.n_points * spot_1.k\n\n[[ 0.86352963  0.7892358 ]\n [-0.24407197 -0.83687436]\n [ 0.36481882  0.8375811 ]\n [ 0.415331    0.54468512]\n [-0.56395091 -0.77797854]\n [-0.90259409 -0.04899292]\n [-0.16484832  0.35724741]\n [ 0.05170659  0.07401196]\n [-0.78548145 -0.44638164]\n [ 0.64017497 -0.30363301]]\n[1.36857656 0.75992983 0.83463487 0.46918172 0.92329124 0.8170764\n 0.15480068 0.00815134 0.81623768 0.502017  ]\n[[0.00163775 0.00441483]\n [0.00163816 0.00398502]]",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Expected Improvement</span>"
    ]
  },
  {
    "objectID": "012_num_spot_ei.html#ei-the-famous-schonlau-example",
    "href": "012_num_spot_ei.html#ei-the-famous-schonlau-example",
    "title": "12  Expected Improvement",
    "section": "12.9 EI: The Famous Schonlau Example",
    "text": "12.9 EI: The Famous Schonlau Example\n\nX_train0 = np.array([1, 2, 3, 4, 12]).reshape(-1,1)\nX_train = np.linspace(start=0, stop=10, num=5).reshape(-1, 1)\n\n\nfrom spotpython.build.kriging import Kriging\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nX_train = np.array([1., 2., 3., 4., 12.]).reshape(-1,1)\ny_train = np.array([0., -1.75, -2, -0.5, 5.])\n\nS = Kriging(name='kriging',  seed=123, log_level=50, n_theta=1, noise=False, cod_type=\"norm\")\nS.fit(X_train, y_train)\n\nX = np.linspace(start=0, stop=13, num=1000).reshape(-1, 1)\nmean_prediction, std_prediction, ei = S.predict(X, return_val=\"all\")\n\nplt.scatter(X_train, y_train, label=\"Observations\")\nplt.plot(X, mean_prediction, label=\"Mean prediction\")\nif True:\n    plt.fill_between(\n        X.ravel(),\n        mean_prediction - 2 * std_prediction,\n        mean_prediction + 2 * std_prediction,\n        alpha=0.5,\n        label=r\"95% confidence interval\",\n    )\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"Gaussian process regression on noise-free dataset\")\n\n\n\n\n\n\n\n\n\n#plt.plot(X, y, label=r\"$f(x) = x \\sin(x)$\", linestyle=\"dotted\")\n# plt.scatter(X_train, y_train, label=\"Observations\")\nplt.plot(X, -ei, label=\"Expected Improvement\")\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"Gaussian process regression on noise-free dataset\")\n\n\n\n\n\n\n\n\n\nS.log\n\n{'negLnLike': array([1.20788205]),\n 'theta': array([-0.99002505]),\n 'p': [],\n 'Lambda': []}",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Expected Improvement</span>"
    ]
  },
  {
    "objectID": "012_num_spot_ei.html#ei-the-forrester-example",
    "href": "012_num_spot_ei.html#ei-the-forrester-example",
    "title": "12  Expected Improvement",
    "section": "12.10 EI: The Forrester Example",
    "text": "12.10 EI: The Forrester Example\n\nfrom spotpython.build.kriging import Kriging\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport spotpython\nfrom spotpython.fun.objectivefunctions import analytical\nfrom spotpython.spot import spot\n\n# exact x locations are unknown:\nX_train = np.array([0.0, 0.175, 0.225, 0.3, 0.35, 0.375, 0.5,1]).reshape(-1,1)\n\nfun = analytical().fun_forrester\nfun_control = fun_control_init(\n    PREFIX=\"07_EI_FORRESTER\",\n    sigma=1.0,\n    seed=123,)\ny_train = fun(X_train, fun_control=fun_control)\n\nS = Kriging(name='kriging',  seed=123, log_level=50, n_theta=1, noise=False, cod_type=\"norm\")\nS.fit(X_train, y_train)\n\nX = np.linspace(start=0, stop=1, num=1000).reshape(-1, 1)\nmean_prediction, std_prediction, ei = S.predict(X, return_val=\"all\")\n\nplt.scatter(X_train, y_train, label=\"Observations\")\nplt.plot(X, mean_prediction, label=\"Mean prediction\")\nif True:\n    plt.fill_between(\n        X.ravel(),\n        mean_prediction - 2 * std_prediction,\n        mean_prediction + 2 * std_prediction,\n        alpha=0.5,\n        label=r\"95% confidence interval\",\n    )\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"Gaussian process regression on noise-free dataset\")\n\n\n\n\n\n\n\n\n\n#plt.plot(X, y, label=r\"$f(x) = x \\sin(x)$\", linestyle=\"dotted\")\n# plt.scatter(X_train, y_train, label=\"Observations\")\nplt.plot(X, -ei, label=\"Expected Improvement\")\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"Gaussian process regression on noise-free dataset\")",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Expected Improvement</span>"
    ]
  },
  {
    "objectID": "012_num_spot_ei.html#noise",
    "href": "012_num_spot_ei.html#noise",
    "title": "12  Expected Improvement",
    "section": "12.11 Noise",
    "text": "12.11 Noise\n\nimport numpy as np\nimport spotpython\nfrom spotpython.fun.objectivefunctions import analytical\nfrom spotpython.spot import spot\nfrom spotpython.design.spacefilling import spacefilling\nfrom spotpython.build.kriging import Kriging\nimport matplotlib.pyplot as plt\n\ngen = spacefilling(1)\nrng = np.random.RandomState(1)\nlower = np.array([-10])\nupper = np.array([10])\nfun = analytical().fun_sphere\nfun_control = fun_control_init(\n    PREFIX=\"07_Y\",\n    sigma=2.0,\n    seed=123,)\nX = gen.scipy_lhd(10, lower=lower, upper = upper)\nprint(X)\ny = fun(X, fun_control=fun_control)\nprint(y)\ny.shape\nX_train = X.reshape(-1,1)\ny_train = y\n\nS = Kriging(name='kriging',\n            seed=123,\n            log_level=50,\n            n_theta=1,\n            noise=False)\nS.fit(X_train, y_train)\n\nX_axis = np.linspace(start=-13, stop=13, num=1000).reshape(-1, 1)\nmean_prediction, std_prediction, ei = S.predict(X_axis, return_val=\"all\")\n\n#plt.plot(X, y, label=r\"$f(x) = x \\sin(x)$\", linestyle=\"dotted\")\nplt.scatter(X_train, y_train, label=\"Observations\")\n#plt.plot(X, ei, label=\"Expected Improvement\")\nplt.plot(X_axis, mean_prediction, label=\"mue\")\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"Sphere: Gaussian process regression on noisy dataset\")\n\n[[ 0.63529627]\n [-4.10764204]\n [-0.44071975]\n [ 9.63125638]\n [-8.3518118 ]\n [-3.62418901]\n [ 4.15331   ]\n [ 3.4468512 ]\n [ 6.36049088]\n [-7.77978539]]\n[-1.57464135 16.13714981  2.77008442 93.14904827 71.59322218 14.28895359\n 15.9770567  12.96468767 39.82265329 59.88028242]\n\n\n\n\n\n\n\n\n\n\nS.log\n\n{'negLnLike': array([26.18505386]),\n 'theta': array([-1.10547468]),\n 'p': [],\n 'Lambda': []}\n\n\n\nS = Kriging(name='kriging',\n            seed=123,\n            log_level=50,\n            n_theta=1,\n            noise=True)\nS.fit(X_train, y_train)\n\nX_axis = np.linspace(start=-13, stop=13, num=1000).reshape(-1, 1)\nmean_prediction, std_prediction, ei = S.predict(X_axis, return_val=\"all\")\n\n#plt.plot(X, y, label=r\"$f(x) = x \\sin(x)$\", linestyle=\"dotted\")\nplt.scatter(X_train, y_train, label=\"Observations\")\n#plt.plot(X, ei, label=\"Expected Improvement\")\nplt.plot(X_axis, mean_prediction, label=\"mue\")\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"Sphere: Gaussian process regression with nugget on noisy dataset\")\n\n\n\n\n\n\n\n\n\nS.log\n\n{'negLnLike': array([21.82276721]),\n 'theta': array([-2.94197609]),\n 'p': [],\n 'Lambda': array([4.89634048e-05])}",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Expected Improvement</span>"
    ]
  },
  {
    "objectID": "012_num_spot_ei.html#cubic-function",
    "href": "012_num_spot_ei.html#cubic-function",
    "title": "12  Expected Improvement",
    "section": "12.12 Cubic Function",
    "text": "12.12 Cubic Function\n\nimport numpy as np\nimport spotpython\nfrom spotpython.fun.objectivefunctions import analytical\nfrom spotpython.spot import spot\nfrom spotpython.design.spacefilling import spacefilling\nfrom spotpython.build.kriging import Kriging\nimport matplotlib.pyplot as plt\n\ngen = spacefilling(1)\nrng = np.random.RandomState(1)\nlower = np.array([-10])\nupper = np.array([10])\nfun = analytical().fun_cubed\nfun_control = fun_control_init(\n    PREFIX=\"07_Y\",\n    sigma=10.0,\n    seed=123,)\n\nX = gen.scipy_lhd(10, lower=lower, upper = upper)\nprint(X)\ny = fun(X, fun_control=fun_control)\nprint(y)\ny.shape\nX_train = X.reshape(-1,1)\ny_train = y\n\nS = Kriging(name='kriging',  seed=123, log_level=50, n_theta=1, noise=False)\nS.fit(X_train, y_train)\n\nX_axis = np.linspace(start=-13, stop=13, num=1000).reshape(-1, 1)\nmean_prediction, std_prediction, ei = S.predict(X_axis, return_val=\"all\")\n\nplt.scatter(X_train, y_train, label=\"Observations\")\n#plt.plot(X, ei, label=\"Expected Improvement\")\nplt.plot(X_axis, mean_prediction, label=\"mue\")\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"Cubed: Gaussian process regression on noisy dataset\")\n\n[[ 0.63529627]\n [-4.10764204]\n [-0.44071975]\n [ 9.63125638]\n [-8.3518118 ]\n [-3.62418901]\n [ 4.15331   ]\n [ 3.4468512 ]\n [ 6.36049088]\n [-7.77978539]]\n[ 2.56406437e-01 -6.93071067e+01 -8.56027124e-02  8.93405931e+02\n -5.82561927e+02 -4.76028022e+01  7.16445311e+01  4.09512920e+01\n  2.57319028e+02 -4.70871982e+02]\n\n\n\n\n\n\n\n\n\n\nS = Kriging(name='kriging',  seed=123, log_level=0, n_theta=1, noise=True)\nS.fit(X_train, y_train)\n\nX_axis = np.linspace(start=-13, stop=13, num=1000).reshape(-1, 1)\nmean_prediction, std_prediction, ei = S.predict(X_axis, return_val=\"all\")\n\nplt.scatter(X_train, y_train, label=\"Observations\")\n#plt.plot(X, ei, label=\"Expected Improvement\")\nplt.plot(X_axis, mean_prediction, label=\"mue\")\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"Cubed: Gaussian process with nugget regression on noisy dataset\")\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport spotpython\nfrom spotpython.fun.objectivefunctions import analytical\nfrom spotpython.spot import spot\nfrom spotpython.design.spacefilling import spacefilling\nfrom spotpython.build.kriging import Kriging\nimport matplotlib.pyplot as plt\n\ngen = spacefilling(1)\nrng = np.random.RandomState(1)\nlower = np.array([-10])\nupper = np.array([10])\nfun = analytical().fun_runge\nfun_control = fun_control_init(\n    PREFIX=\"07_Y\",\n    sigma=0.25,\n    seed=123,)\n\nX = gen.scipy_lhd(10, lower=lower, upper = upper)\nprint(X)\ny = fun(X, fun_control=fun_control)\nprint(y)\ny.shape\nX_train = X.reshape(-1,1)\ny_train = y\n\nS = Kriging(name='kriging',  seed=123, log_level=50, n_theta=1, noise=False)\nS.fit(X_train, y_train)\n\nX_axis = np.linspace(start=-13, stop=13, num=1000).reshape(-1, 1)\nmean_prediction, std_prediction, ei = S.predict(X_axis, return_val=\"all\")\n\nplt.scatter(X_train, y_train, label=\"Observations\")\n#plt.plot(X, ei, label=\"Expected Improvement\")\nplt.plot(X_axis, mean_prediction, label=\"mue\")\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"Gaussian process regression on noisy dataset\")\n\n[[ 0.63529627]\n [-4.10764204]\n [-0.44071975]\n [ 9.63125638]\n [-8.3518118 ]\n [-3.62418901]\n [ 4.15331   ]\n [ 3.4468512 ]\n [ 6.36049088]\n [-7.77978539]]\n[0.712453   0.05595118 0.83735691 0.0106654  0.01413372 0.07074765\n 0.05479457 0.07763503 0.02412205 0.01625354]\n\n\n\n\n\n\n\n\n\n\nS = Kriging(name='kriging',\n            seed=123,\n            log_level=50,\n            n_theta=1,\n            noise=True)\nS.fit(X_train, y_train)\n\nX_axis = np.linspace(start=-13, stop=13, num=1000).reshape(-1, 1)\nmean_prediction, std_prediction, ei = S.predict(X_axis, return_val=\"all\")\n\nplt.scatter(X_train, y_train, label=\"Observations\")\n#plt.plot(X, ei, label=\"Expected Improvement\")\nplt.plot(X_axis, mean_prediction, label=\"mue\")\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"Gaussian process regression with nugget on noisy dataset\")",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Expected Improvement</span>"
    ]
  },
  {
    "objectID": "012_num_spot_ei.html#modifying-lambda-search-space",
    "href": "012_num_spot_ei.html#modifying-lambda-search-space",
    "title": "12  Expected Improvement",
    "section": "12.13 Modifying Lambda Search Space",
    "text": "12.13 Modifying Lambda Search Space\n\nS = Kriging(name='kriging',\n            seed=123,\n            log_level=50,\n            n_theta=1,\n            noise=True,\n            min_Lambda=0.1,\n            max_Lambda=10)\nS.fit(X_train, y_train)\n\nprint(f\"Lambda: {S.Lambda}\")\n\nLambda: 0.1\n\n\n\nX_axis = np.linspace(start=-13, stop=13, num=1000).reshape(-1, 1)\nmean_prediction, std_prediction, ei = S.predict(X_axis, return_val=\"all\")\n\nplt.scatter(X_train, y_train, label=\"Observations\")\n#plt.plot(X, ei, label=\"Expected Improvement\")\nplt.plot(X_axis, mean_prediction, label=\"mue\")\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"Gaussian process regression with nugget on noisy dataset. Modified Lambda search space.\")",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Expected Improvement</span>"
    ]
  },
  {
    "objectID": "013_num_spot_noisy.html",
    "href": "013_num_spot_noisy.html",
    "title": "13  Handling Noise",
    "section": "",
    "text": "13.1 Example: Spot and the Noisy Sphere Function\nimport numpy as np\nfrom math import inf\nfrom spotpython.fun.objectivefunctions import analytical\nfrom spotpython.spot import spot\nimport matplotlib.pyplot as plt\nfrom spotpython.utils.init import fun_control_init, get_spot_tensorboard_path\nfrom spotpython.utils.init import fun_control_init, design_control_init, surrogate_control_init\n\nPREFIX = \"08\"",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Handling Noise</span>"
    ]
  },
  {
    "objectID": "013_num_spot_noisy.html#example-spot-and-the-noisy-sphere-function",
    "href": "013_num_spot_noisy.html#example-spot-and-the-noisy-sphere-function",
    "title": "13  Handling Noise",
    "section": "",
    "text": "13.1.1 The Objective Function: Noisy Sphere\nThe spotpython package provides several classes of objective functions, which return a one-dimensional output \\(y=f(x)\\) for a given input \\(x\\) (independent variable). Several objective functions allow one- or multidimensional input, some also combinations of real-valued and categorial input values.\nAn objective function is considered as “analytical” if it can be described by a closed mathematical formula, e.g., \\[\nf(x, y) = x^2 + y^2.\n\\]\nTo simulate measurement errors, adding artificial noise to the function value \\(y\\) is a common practice, e.g.,:\n\\[\nf(x, y) = x^2 + y^2 + \\epsilon.\n\\]\nUsually, noise is assumed to be normally distributed with mean \\(\\mu=0\\) and standard deviation \\(\\sigma\\). spotpython uses numpy’s scale parameter, which specifies the standard deviation (spread or “width”) of the distribution is used. This must be a non-negative value, see https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html.\n\n\n\n\n\n\nExample: The sphere function without noise\n\n\n\nThe default setting does not use any noise.\n\nfrom spotpython.fun.objectivefunctions import analytical\nfun = analytical().fun_sphere\nx = np.linspace(-1,1,100).reshape(-1,1)\ny = fun(x)\nplt.figure()\nplt.plot(x,y, \"k\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample: The sphere function with noise\n\n\n\nNoise can be added to the sphere function as follows:\n\nfrom spotpython.fun.objectivefunctions import analytical\nfun = analytical(seed=123, sigma=0.02).fun_sphere\nx = np.linspace(-1,1,100).reshape(-1,1)\ny = fun(x)\nplt.figure()\nplt.plot(x,y, \"k\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n13.1.2 Reproducibility: Noise Generation and Seed Handling\nspotpython provides two mechanisms for generating random noise:\n\nThe seed is initialized once, i.e., when the objective function is instantiated. This can be done using the following call: fun = analytical(sigma=0.02, seed=123).fun_sphere.\nThe seed is set every time the objective function is called. This can be done using the following call: y = fun(x, sigma=0.02, seed=123).\n\nThese two different ways lead to different results as explained in the following tables:\n\n\n\n\n\n\nExample: Noise added to the sphere function\n\n\n\nSince sigma is set to 0.02, noise is added to the function:\n\nfrom spotpython.fun.objectivefunctions import analytical\nfun = analytical(sigma=0.02, seed=123).fun_sphere\nx = np.array([1]).reshape(-1,1)\nfor i in range(3):\n    print(f\"{i}: {fun(x)}\")\n\n0: [0.98021757]\n1: [0.99264427]\n2: [1.02575851]\n\n\nThe seed is set once. Every call to fun() results in a different value. The whole experiment can be repeated, the initial seed is used to generate the same sequence as shown below:\n\n\n\n\n\n\n\n\nExample: Noise added to the sphere function\n\n\n\nSince sigma is set to 0.02, noise is added to the function:\n\nfrom spotpython.fun.objectivefunctions import analytical\nfun = analytical(sigma=0.02, seed=123).fun_sphere\nx = np.array([1]).reshape(-1,1)\nfor i in range(3):\n    print(f\"{i}: {fun(x)}\")\n\n0: [0.98021757]\n1: [0.99264427]\n2: [1.02575851]\n\n\n\n\nIf spotpython is used as a hyperparameter tuner, it is important that only one realization of the noise function is optimized. This behaviour can be accomplished by passing the same seed via the dictionary fun_control to every call of the objective function fun as shown below:\n\n\n\n\n\n\nExample: The same noise added to the sphere function\n\n\n\nSince sigma is set to 0.02, noise is added to the function:\n\nfrom spotpython.fun.objectivefunctions import analytical\nfun = analytical().fun_sphere\nfun_control = fun_control_init(\n    PREFIX=PREFIX,\n    sigma=0.02)\ny = fun(x, fun_control=fun_control)\nx = np.array([1]).reshape(-1,1)\nfor i in range(3):\n    print(f\"{i}: {fun(x)}\")\n\n0: [0.98021757]\n1: [0.98021757]\n2: [0.98021757]",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Handling Noise</span>"
    ]
  },
  {
    "objectID": "013_num_spot_noisy.html#spotpythons-noise-handling-approaches",
    "href": "013_num_spot_noisy.html#spotpythons-noise-handling-approaches",
    "title": "13  Handling Noise",
    "section": "13.2 spotpython’s Noise Handling Approaches",
    "text": "13.2 spotpython’s Noise Handling Approaches\nThe following setting will be used for the next steps:\n\nfun = analytical().fun_sphere\nfun_control = fun_control_init(\n    PREFIX=PREFIX,\n    sigma=0.02,\n)\n\nspotpython is adopted as follows to cope with noisy functions:\n\nfun_repeats is set to a value larger than 1 (here: 2)\nnoise is set to true. Therefore, a nugget (Lambda) term is added to the correlation matrix\ninit size (of the design_control dictionary) is set to a value larger than 1 (here: 3)\n\n\nspot_1_noisy = spot.Spot(fun=fun,\n                   fun_control=fun_control_init(\n                                    lower = np.array([-1]),\n                                    upper = np.array([1]),\n                                    fun_evals = 20,\n                                    fun_repeats = 2,\n                                    noise = True,\n                                    show_models=True),\n                   design_control=design_control_init(init_size=3, repeats=2),\n                   surrogate_control=surrogate_control_init(noise=True))\n\n\nspot_1_noisy.run()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.034752873669989026 [####------] 40.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.03230817945928789 [#####-----] 50.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.015578418800855254 [######----] 60.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.0009550994714026289 [#######---] 70.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 5.561590542963861e-05 [########--] 80.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 7.181090066713707e-07 [#########-] 90.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 4.5254143126895086e-07 [##########] 100.00% Done...",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Handling Noise</span>"
    ]
  },
  {
    "objectID": "013_num_spot_noisy.html#print-the-results",
    "href": "013_num_spot_noisy.html#print-the-results",
    "title": "13  Handling Noise",
    "section": "13.3 Print the Results",
    "text": "13.3 Print the Results\n\nspot_1_noisy.print_results()\n\nmin y: 4.5254143126895086e-07\nmin mean y: 4.5254143126895086e-07\nx0: 0.0006727119972684825\n\n\n[['x0', 0.0006727119972684825]]\n\n\n\nspot_1_noisy.plot_progress(log_y=False,\n    filename=\"./figures/\" + PREFIX + \"_progress.png\")\n\n\n\n\nProgress plot. Black dots denote results from the initial design. Red dots illustrate the improvement found by the surrogate model based optimization.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Handling Noise</span>"
    ]
  },
  {
    "objectID": "013_num_spot_noisy.html#noise-and-surrogates-the-nugget-effect",
    "href": "013_num_spot_noisy.html#noise-and-surrogates-the-nugget-effect",
    "title": "13  Handling Noise",
    "section": "13.4 Noise and Surrogates: The Nugget Effect",
    "text": "13.4 Noise and Surrogates: The Nugget Effect\n\n13.4.1 The Noisy Sphere\n\n13.4.1.1 The Data\n\nWe prepare some data first:\n\n\nimport numpy as np\nimport spotpython\nfrom spotpython.fun.objectivefunctions import analytical\nfrom spotpython.spot import spot\nfrom spotpython.design.spacefilling import spacefilling\nfrom spotpython.build.kriging import Kriging\nimport matplotlib.pyplot as plt\n\ngen = spacefilling(1)\nrng = np.random.RandomState(1)\nlower = np.array([-10])\nupper = np.array([10])\nfun = analytical().fun_sphere\nfun_control = fun_control_init(\n    PREFIX=PREFIX,\n    sigma=4)\nX = gen.scipy_lhd(10, lower=lower, upper = upper)\ny = fun(X, fun_control=fun_control)\nX_train = X.reshape(-1,1)\ny_train = y\n\n\nA surrogate without nugget is fitted to these data:\n\n\nS = Kriging(name='kriging',\n            n_theta=1,\n            noise=False)\nS.fit(X_train, y_train)\n\nX_axis = np.linspace(start=-13, stop=13, num=1000).reshape(-1, 1)\nmean_prediction, std_prediction, ei = S.predict(X_axis, return_val=\"all\")\n\nplt.scatter(X_train, y_train, label=\"Observations\")\nplt.plot(X_axis, mean_prediction, label=\"mue\")\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"Sphere: Gaussian process regression on noisy dataset\")\n\n\n\n\n\n\n\n\n\nIn comparison to the surrogate without nugget, we fit a surrogate with nugget to the data:\n\n\nS_nug = Kriging(name='kriging',\n            n_theta=1,\n            noise=True)\nS_nug.fit(X_train, y_train)\nX_axis = np.linspace(start=-13, stop=13, num=1000).reshape(-1, 1)\nmean_prediction, std_prediction, ei = S_nug.predict(X_axis, return_val=\"all\")\nplt.scatter(X_train, y_train, label=\"Observations\")\nplt.plot(X_axis, mean_prediction, label=\"mue\")\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"Sphere: Gaussian process regression with nugget on noisy dataset\")\n\n\n\n\n\n\n\n\n\nThe value of the nugget term can be extracted from the model as follows:\n\n\nS.Lambda\n\n\nS_nug.Lambda\n\n0.0005592051705322895\n\n\n\nWe see:\n\nthe first model S has no nugget,\nwhereas the second model has a nugget value (Lambda) larger than zero.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Handling Noise</span>"
    ]
  },
  {
    "objectID": "013_num_spot_noisy.html#exercises",
    "href": "013_num_spot_noisy.html#exercises",
    "title": "13  Handling Noise",
    "section": "13.5 Exercises",
    "text": "13.5 Exercises\n\n13.5.1 Noisy fun_cubed\n\nAnalyse the effect of noise on the fun_cubed function with the following settings:\n\n\nfun = analytical().fun_cubed\nfun_control = fun_control_init(\n    sigma=10)\nlower = np.array([-10])\nupper = np.array([10])\n\n\n\n13.5.2 fun_runge\n\nAnalyse the effect of noise on the fun_runge function with the following settings:\n\n\nlower = np.array([-10])\nupper = np.array([10])\nfun = analytical().fun_runge\nfun_control = fun_control_init(\n    sigma=0.25)\n\n\n\n13.5.3 fun_forrester\n\nAnalyse the effect of noise on the fun_forrester function with the following settings:\n\n\nlower = np.array([0])\nupper = np.array([1])\nfun = analytical().fun_forrester\nfun_control = fun_control_init(\n    sigma=5)\n\n\n\n13.5.4 fun_xsin\n\nAnalyse the effect of noise on the fun_xsin function with the following settings:\n\n\nlower = np.array([-1.])\nupper = np.array([1.])\nfun = analytical().fun_xsin\nfun_control = fun_control_init(    \n    sigma=0.5)",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Handling Noise</span>"
    ]
  },
  {
    "objectID": "014_num_spot_ocba.html",
    "href": "014_num_spot_ocba.html",
    "title": "14  Optimal Computational Budget Allocation in Spot",
    "section": "",
    "text": "14.1 Example: Spot, OCBA, and the Noisy Sphere Function\nimport numpy as np\nfrom math import inf\nfrom spotpython.fun.objectivefunctions import analytical\nfrom spotpython.spot import spot\nimport matplotlib.pyplot as plt\nfrom spotpython.utils.init import fun_control_init, get_spot_tensorboard_path\nfrom spotpython.utils.init import fun_control_init, design_control_init, surrogate_control_init\n\nPREFIX = \"09\"",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Optimal Computational Budget Allocation in `Spot`</span>"
    ]
  },
  {
    "objectID": "014_num_spot_ocba.html#example-spot-ocba-and-the-noisy-sphere-function",
    "href": "014_num_spot_ocba.html#example-spot-ocba-and-the-noisy-sphere-function",
    "title": "14  Optimal Computational Budget Allocation in Spot",
    "section": "",
    "text": "14.1.1 The Objective Function: Noisy Sphere\nThe spotpython package provides several classes of objective functions. We will use an analytical objective function with noise, i.e., a function that can be described by a (closed) formula: \\[f(x) = x^2 + \\epsilon\\]\nSince sigma is set to 0.1, noise is added to the function:\n\nfun = analytical().fun_sphere\nfun_control = fun_control_init(\n    PREFIX=PREFIX,\n    sigma=0.1)\n\nA plot illustrates the noise:\n\nx = np.linspace(-1,1,100).reshape(-1,1)\ny = fun(x, fun_control=fun_control)\nplt.figure()\nplt.plot(x,y, \"k\")\nplt.show()\n\n\n\n\n\n\n\n\nSpot is adopted as follows to cope with noisy functions:\n\nfun_repeats is set to a value larger than 1 (here: 2)\nnoise is set to true. Therefore, a nugget (Lambda) term is added to the correlation matrix\ninit size (of the design_control dictionary) is set to a value larger than 1 (here: 2)\n\n\nspot_1_noisy = spot.Spot(fun=fun,\n                   fun_control=fun_control_init( \n                   lower = np.array([-1]),\n                   upper = np.array([1]),\n                   fun_evals = 20,\n                   fun_repeats = 2,\n                   infill_criterion=\"ei\",\n                   noise = True,\n                   tolerance_x=0.0,\n                   ocba_delta = 1,                   \n                   show_models=True),\n                   design_control=design_control_init(init_size=3, repeats=2),\n                   surrogate_control=surrogate_control_init(noise=True))\n\n\nspot_1_noisy.run()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.00891934134603014 [####------] 40.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.00891934134603014 [#####-----] 50.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 6.820812967131544e-05 [######----] 60.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 3.692698488681066e-06 [#######---] 70.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 1.4235007051487162e-06 [########--] 80.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 1.4235007051487162e-06 [#########-] 90.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 1.4235007051487162e-06 [##########] 100.00% Done...",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Optimal Computational Budget Allocation in `Spot`</span>"
    ]
  },
  {
    "objectID": "014_num_spot_ocba.html#print-the-results",
    "href": "014_num_spot_ocba.html#print-the-results",
    "title": "14  Optimal Computational Budget Allocation in Spot",
    "section": "14.2 Print the Results",
    "text": "14.2 Print the Results\n\nspot_1_noisy.print_results()\n\nmin y: 1.4235007051487162e-06\nmin mean y: 1.4235007051487162e-06\nx0: -0.0011931054878545804\n\n\n[['x0', -0.0011931054878545804]]\n\n\n\nspot_1_noisy.plot_progress(log_y=False)",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Optimal Computational Budget Allocation in `Spot`</span>"
    ]
  },
  {
    "objectID": "014_num_spot_ocba.html#noise-and-surrogates-the-nugget-effect",
    "href": "014_num_spot_ocba.html#noise-and-surrogates-the-nugget-effect",
    "title": "14  Optimal Computational Budget Allocation in Spot",
    "section": "14.3 Noise and Surrogates: The Nugget Effect",
    "text": "14.3 Noise and Surrogates: The Nugget Effect\n\n14.3.1 The Noisy Sphere\n\n14.3.1.1 The Data\nWe prepare some data first:\n\nimport numpy as np\nimport spotpython\nfrom spotpython.fun.objectivefunctions import analytical\nfrom spotpython.spot import spot\nfrom spotpython.design.spacefilling import spacefilling\nfrom spotpython.build.kriging import Kriging\nimport matplotlib.pyplot as plt\n\ngen = spacefilling(1)\nrng = np.random.RandomState(1)\nlower = np.array([-10])\nupper = np.array([10])\nfun = analytical().fun_sphere\nfun_control = fun_control_init(    \n    sigma=2,\n    seed=125)\nX = gen.scipy_lhd(10, lower=lower, upper = upper)\ny = fun(X, fun_control=fun_control)\nX_train = X.reshape(-1,1)\ny_train = y\n\nA surrogate without nugget is fitted to these data:\n\nS = Kriging(name='kriging',\n            seed=123,\n            log_level=50,\n            n_theta=1,\n            noise=False)\nS.fit(X_train, y_train)\n\nX_axis = np.linspace(start=-13, stop=13, num=1000).reshape(-1, 1)\nmean_prediction, std_prediction, ei = S.predict(X_axis, return_val=\"all\")\n\nplt.scatter(X_train, y_train, label=\"Observations\")\nplt.plot(X_axis, mean_prediction, label=\"mue\")\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"Sphere: Gaussian process regression on noisy dataset\")\n\n\n\n\n\n\n\n\nIn comparison to the surrogate without nugget, we fit a surrogate with nugget to the data:\n\nS_nug = Kriging(name='kriging',\n            seed=123,\n            log_level=50,\n            n_theta=1,\n            noise=True)\nS_nug.fit(X_train, y_train)\nX_axis = np.linspace(start=-13, stop=13, num=1000).reshape(-1, 1)\nmean_prediction, std_prediction, ei = S_nug.predict(X_axis, return_val=\"all\")\nplt.scatter(X_train, y_train, label=\"Observations\")\nplt.plot(X_axis, mean_prediction, label=\"mue\")\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"Sphere: Gaussian process regression with nugget on noisy dataset\")\n\n\n\n\n\n\n\n\nThe value of the nugget term can be extracted from the model as follows:\n\nS.Lambda\n\n\nS_nug.Lambda\n\n9.867760027597887e-05\n\n\nWe see:\n\nthe first model S has no nugget,\nwhereas the second model has a nugget value (Lambda) larger than zero.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Optimal Computational Budget Allocation in `Spot`</span>"
    ]
  },
  {
    "objectID": "014_num_spot_ocba.html#exercises",
    "href": "014_num_spot_ocba.html#exercises",
    "title": "14  Optimal Computational Budget Allocation in Spot",
    "section": "14.4 Exercises",
    "text": "14.4 Exercises\n\n14.4.1 Noisy fun_cubed\nAnalyse the effect of noise on the fun_cubed function with the following settings:\n\nfun = analytical().fun_cubed\nfun_control = fun_control_init(    \n    sigma=10,\n    seed=123)\nlower = np.array([-10])\nupper = np.array([10])\n\n\n\n14.4.2 fun_runge\nAnalyse the effect of noise on the fun_runge function with the following settings:\n\nlower = np.array([-10])\nupper = np.array([10])\nfun = analytical().fun_runge\nfun_control = fun_control_init(    \n    sigma=0.25,\n    seed=123)\n\n\n\n14.4.3 fun_forrester\nAnalyse the effect of noise on the fun_forrester function with the following settings:\n\nlower = np.array([0])\nupper = np.array([1])\nfun = analytical().fun_forrester\nfun_control = {\"sigma\": 5,\n               \"seed\": 123}\n\n\n\n14.4.4 fun_xsin\nAnalyse the effect of noise on the fun_xsin function with the following settings:\n\nlower = np.array([-1.])\nupper = np.array([1.])\nfun = analytical().fun_xsin\nfun_control = fun_control_init(    \n    sigma=0.5,\n    seed=123)",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Optimal Computational Budget Allocation in `Spot`</span>"
    ]
  },
  {
    "objectID": "015_num_spot_correlation_p.html",
    "href": "015_num_spot_correlation_p.html",
    "title": "15  Kriging with Varying Correlation-p",
    "section": "",
    "text": "15.1 Example: Spot Surrogate and the 2-dim Sphere Function\nimport numpy as np\nfrom math import inf\nfrom spotpython.fun.objectivefunctions import analytical\nfrom spotpython.spot import spot\nfrom spotpython.utils.init import fun_control_init, surrogate_control_init\nPREFIX=\"015\"",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Kriging with Varying Correlation-p</span>"
    ]
  },
  {
    "objectID": "015_num_spot_correlation_p.html#example-spot-surrogate-and-the-2-dim-sphere-function",
    "href": "015_num_spot_correlation_p.html#example-spot-surrogate-and-the-2-dim-sphere-function",
    "title": "15  Kriging with Varying Correlation-p",
    "section": "",
    "text": "15.1.1 The Objective Function: 2-dim Sphere\n\nThe spotpython package provides several classes of objective functions.\nWe will use an analytical objective function, i.e., a function that can be described by a (closed) formula: \\[f(x, y) = x^2 + y^2\\]\nThe size of the lower bound vector determines the problem dimension.\nHere we will use np.array([-1, -1]), i.e., a two-dim function.\n\n\nfun = analytical().fun_sphere\nfun_control = fun_control_init(PREFIX=PREFIX,\n                               lower = np.array([-1, -1]),\n                               upper = np.array([1, 1]))\n\n\nAlthough the default spot surrogate model is an isotropic Kriging model, we will explicitly set the theta parameter to a value of 1 for both dimensions. This is done to illustrate the difference between isotropic and anisotropic Kriging models.\n\n\nsurrogate_control=surrogate_control_init(n_p=1,\n                                         p_val=2.0,)\n\n\nspot_2 = spot.Spot(fun=fun,\n                   fun_control=fun_control,\n                   surrogate_control=surrogate_control)\n\nspot_2.run()\n\nspotpython tuning: 1.5904060546935205e-05 [#######---] 73.33% \nspotpython tuning: 1.5904060546935205e-05 [########--] 80.00% \nspotpython tuning: 1.5904060546935205e-05 [#########-] 86.67% \nspotpython tuning: 1.5904060546935205e-05 [#########-] 93.33% \nspotpython tuning: 1.4886245843852055e-05 [##########] 100.00% Done...\n\n\n\n&lt;spotpython.spot.spot.Spot at 0x347c81130&gt;\n\n\n\n\n15.1.2 Results\n\nspot_2.print_results()\n\nmin y: 1.4886245843852055e-05\nx0: -0.003850983818095356\nx1: -0.00023700100552480994\n\n\n[['x0', -0.003850983818095356], ['x1', -0.00023700100552480994]]\n\n\n\nspot_2.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\nspot_2.surrogate.plot()",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Kriging with Varying Correlation-p</span>"
    ]
  },
  {
    "objectID": "015_num_spot_correlation_p.html#example-with-modified-p",
    "href": "015_num_spot_correlation_p.html#example-with-modified-p",
    "title": "15  Kriging with Varying Correlation-p",
    "section": "15.2 Example With Modified p",
    "text": "15.2 Example With Modified p\n\nWe can use set p to a value other than 2 to obtain a different Kriging model.\n\n\nsurrogate_control = surrogate_control_init(n_p=1,\n                                           p_val=1.0)\nspot_2_p1= spot.Spot(fun=fun,\n                    fun_control=fun_control,\n                    surrogate_control=surrogate_control)\nspot_2_p1.run()\n\nspotpython tuning: 1.5904060546935205e-05 [#######---] 73.33% \nspotpython tuning: 1.5904060546935205e-05 [########--] 80.00% \nspotpython tuning: 1.5904060546935205e-05 [#########-] 86.67% \nspotpython tuning: 1.5904060546935205e-05 [#########-] 93.33% \nspotpython tuning: 1.4886245843852055e-05 [##########] 100.00% Done...\n\n\n\n&lt;spotpython.spot.spot.Spot at 0x347d68f80&gt;\n\n\n\nThe search progress of the optimization with the anisotropic model can be visualized:\n\n\nspot_2_p1.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\nspot_2_p1.print_results()\n\nmin y: 1.4886245843852055e-05\nx0: -0.003850983818095356\nx1: -0.00023700100552480994\n\n\n[['x0', -0.003850983818095356], ['x1', -0.00023700100552480994]]\n\n\n\nspot_2_p1.surrogate.plot()\n\n\n\n\n\n\n\n\n\n15.2.1 Taking a Look at the p Values\n\n15.2.1.1 p Values from the spot Model\n\nWe can check, which p values the spot model has used:\nThe p values from the surrogate can be printed as follows:\n\n\nspot_2_p1.surrogate.p\n\narray([1.])\n\n\n\nSince the surrogate from the isotropic setting was stored as spot_2, we can also take a look at the theta value from this model:\n\n\nspot_2.surrogate.p\n\narray([2.])",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Kriging with Varying Correlation-p</span>"
    ]
  },
  {
    "objectID": "015_num_spot_correlation_p.html#optimization-of-the-p-values",
    "href": "015_num_spot_correlation_p.html#optimization-of-the-p-values",
    "title": "15  Kriging with Varying Correlation-p",
    "section": "15.3 Optimization of the p Values",
    "text": "15.3 Optimization of the p Values\n\nsurrogate_control = surrogate_control_init(n_p=1,\n                                           optim_p=True)\nspot_2_pm= spot.Spot(fun=fun,\n                    fun_control=fun_control,\n                    surrogate_control=surrogate_control)\nspot_2_pm.run()\n\nspotpython tuning: 2.0901803896651035e-05 [#######---] 73.33% \nspotpython tuning: 2.0901803896651035e-05 [########--] 80.00% \nspotpython tuning: 2.0901803896651035e-05 [#########-] 86.67% \nspotpython tuning: 2.0901803896651035e-05 [#########-] 93.33% \nspotpython tuning: 9.862120336177949e-06 [##########] 100.00% Done...\n\n\n\n&lt;spotpython.spot.spot.Spot at 0x34bbd1dc0&gt;\n\n\n\nspot_2_pm.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\nspot_2_pm.print_results()\n\nmin y: 9.862120336177949e-06\nx0: -0.002974641180991332\nx1: -0.0010067920244660482\n\n\n[['x0', -0.002974641180991332], ['x1', -0.0010067920244660482]]\n\n\n\nspot_2_pm.surrogate.plot()\n\n\n\n\n\n\n\n\n\nspot_2_pm.surrogate.p\n\narray([1.66198193])",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Kriging with Varying Correlation-p</span>"
    ]
  },
  {
    "objectID": "015_num_spot_correlation_p.html#optimization-of-multiple-p-values",
    "href": "015_num_spot_correlation_p.html#optimization-of-multiple-p-values",
    "title": "15  Kriging with Varying Correlation-p",
    "section": "15.4 Optimization of Multiple p Values",
    "text": "15.4 Optimization of Multiple p Values\n\nsurrogate_control = surrogate_control_init(n_p=2,\n                                           optim_p=True)\nspot_2_pmo= spot.Spot(fun=fun,\n                    fun_control=fun_control,\n                    surrogate_control=surrogate_control)\nspot_2_pmo.run()\n\nspotpython tuning: 1.90602728663205e-05 [#######---] 73.33% \nspotpython tuning: 1.90602728663205e-05 [########--] 80.00% \nspotpython tuning: 1.90602728663205e-05 [#########-] 86.67% \nspotpython tuning: 1.90602728663205e-05 [#########-] 93.33% \nspotpython tuning: 5.741913594811217e-06 [##########] 100.00% Done...\n\n\n\n&lt;spotpython.spot.spot.Spot at 0x34d71d7c0&gt;\n\n\n\nspot_2_pmo.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\nspot_2_pmo.print_results()\n\nmin y: 5.741913594811217e-06\nx0: -0.002070805151396577\nx1: -0.001205686368737997\n\n\n[['x0', -0.002070805151396577], ['x1', -0.001205686368737997]]\n\n\n\nspot_2_pmo.surrogate.plot()\n\n\n\n\n\n\n\n\n\nspot_2_pmo.surrogate.p\n\narray([1.35351306, 1.87234959])",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Kriging with Varying Correlation-p</span>"
    ]
  },
  {
    "objectID": "015_num_spot_correlation_p.html#exercises",
    "href": "015_num_spot_correlation_p.html#exercises",
    "title": "15  Kriging with Varying Correlation-p",
    "section": "15.5 Exercises",
    "text": "15.5 Exercises\n\n15.5.1 fun_branin\n\nDescribe the function.\n\nThe input dimension is 2. The search range is \\(-5 \\leq x_1 \\leq 10\\) and \\(0 \\leq x_2 \\leq 15\\).\n\nCompare the results from spotpython runs with different options for p.\nModify the termination criterion: instead of the number of evaluations (which is specified via fun_evals), the time should be used as the termination criterion. This can be done as follows (max_time=1 specifies a run time of one minute):\n\n\nfun_evals=inf,\nmax_time=1,\n\n\n\n15.5.2 fun_sin_cos\n\nDescribe the function.\n\nThe input dimension is 2. The search range is \\(-2\\pi \\leq x_1 \\leq 2\\pi\\) and \\(-2\\pi \\leq x_2 \\leq 2\\pi\\).\n\nCompare the results from spotpython run a) with isotropic and b) anisotropic surrogate models.\nModify the termination criterion (max_time instead of fun_evals) as described for fun_branin.\n\n\n\n15.5.3 fun_runge\n\nDescribe the function.\n\nThe input dimension is 2. The search range is \\(-5 \\leq x_1 \\leq 5\\) and \\(-5 \\leq x_2 \\leq 5\\).\n\nCompare the results from spotpython runs with different options for p.\nModify the termination criterion (max_time instead of fun_evals) as described for fun_branin.\n\n\n\n15.5.4 fun_wingwt\n\nDescribe the function.\n\nThe input dimension is 10. The search ranges are between 0 and 1 (values are mapped internally to their natural bounds).\n\nCompare the results from spotpython runs with different options for p.\nModify the termination criterion (max_time instead of fun_evals) as described for fun_branin.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Kriging with Varying Correlation-p</span>"
    ]
  },
  {
    "objectID": "015_num_spot_correlation_p.html#jupyter-notebook",
    "href": "015_num_spot_correlation_p.html#jupyter-notebook",
    "title": "15  Kriging with Varying Correlation-p",
    "section": "15.6 Jupyter Notebook",
    "text": "15.6 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Kriging with Varying Correlation-p</span>"
    ]
  },
  {
    "objectID": "100_ddmo.html",
    "href": "100_ddmo.html",
    "title": "16  Data-Driven Modeling and Optimization",
    "section": "",
    "text": "16.1 StatQuest Videos",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Data-Driven Modeling and Optimization</span>"
    ]
  },
  {
    "objectID": "100_ddmo.html#statquest-videos",
    "href": "100_ddmo.html#statquest-videos",
    "title": "16  Data-Driven Modeling and Optimization",
    "section": "",
    "text": "16.1.1 June, 11th 2024\n\n16.1.1.1 Histograms\n\nVideo: Histograms, Clearly Explained\n\n\nExercise 16.1 (Histograms) Problems with histograms?\n\n\n\n16.1.1.2 Probability Distributions\n\nVideo: The Main Ideas behind Probability Distributions\n\n\nExercise 16.2 (Smaller Bins) What happens when we use smaller bins in a histogram?\n\n\nExercise 16.3 (Density Curve) Why plot a curve to approximate a histogram?\n\n\n\n16.1.1.3 Normal Distribution\n\nVideo: The Normal Distribution, Clearly Explained!!!\n\n\nExercise 16.4 (TwoSDQuestion) How many samples are plus/minus two SD around the mean?\n\n\nExercise 16.5 (OneSDQuestion) How many samples are plus/minus one SD around the mean?\n\n\nExercise 16.6 (ThreeSDQuestion) How many samples are plus/minus three SD around the mean?\n\n\nExercise 16.7 (DataRangeQuestion) You have a mean at 100 and a SD of 10. Where are 95% of the data?\n\n\nExercise 16.8 (PeakHeightQuestion) If the peak is very high, is the SD low or high?\n\n\n\n16.1.1.4 The mean, the media, and the mode\n\n\n16.1.1.5 The exponential distribution\n\n\n16.1.1.6 Population and Estimated Parameters\n\nVideo: Population and Estimated Parameters, Clearly Explained\n\n\nExercise 16.9 (ProbabilityQuestion) If we have a certain curve and want to calculate the probability of values equal to 20 if the mean is 20.\n\n\n\n16.1.1.7 Mean, Variance, and Standard Deviation\n\nVideo: Calculating the Mean, Variance, and Standard Deviation\n\n\nExercise 16.10 (MeanDifferenceQuestion) The difference between \\(\\mu\\) and x-bar?\n\n\nExercise 16.11 (EstimateMeanQuestion) How do you calculate the sample mean?\n\n\nExercise 16.12 (SigmaSquaredQuestion) What is sigma squared?\n\n\nExercise 16.13 (EstimatedSDQuestion) What is the formula for the estimated standard deviation?\n\n\nExercise 16.14 (VarianceDifferenceQuestion) Difference between the variance and the estimated variance?\n\n\n\n\n16.1.2 Mathematical Models\n\nVideo: What is a mathematical model?\n\n\nExercise 16.15 (ModelBenefitsQuestion) What are the benefits of using models?\n\n\n16.1.2.1 Sampling from a Distribution\n\nVidoe: Sampling from a Distribution, Clearly Explained!!!\n\n\nExercise 16.16 (SampleDefinitionQuestion) What is a sample in statistics?\n\n\n\n\n16.1.3 Hypothesis Testing and the Null-Hypothesis\n\nExercise 16.17 (RejectHypothesisQuestion) What does it mean to reject a hypothesis?\n\n\nExercise 16.18 (NullHypothesisQuestion) What is a null hypothesis?\n\n\nExercise 16.19 (BetterDrugQuestion) How can you show that you have found a better drug?\n\n\n16.1.3.1 Alternative Hypotheses, Main Ideas\n\n\n16.1.3.2 p-values: What they are and how to interpret them\n\nExercise 16.20 (PValueIntroductionQuestion) What is the reason for introducing the p-value?\n\n\nExercise 16.21 (PValueRangeQuestion) Is there any range for p-values? Can it be negative?\n\n\nExercise 16.22 (PValueRangeQuestion) Is there any range for p-values? Can it be negative?\n\n\nExercise 16.23 (TypicalPValueQuestion) What are typical values of the p-value and what does it mean? 5%?\n\n\nExercise 16.24 (FalsePositiveQuestion) What is a false-positive?\n\n\n\n16.1.3.3 How to calculate p-values\n\nExercise 16.25 (CalculatePValueQuestion) How to calculate p-value?\n\n\nExercise 16.26 (SDCalculationQuestion) What is the SD if the mean is 155 and in the range from 142 - 169 there are 95% of the data?\n\n\nExercise 16.27 (SidedPValueQuestion) When do we need the two-sided p-value and when the one-sided?\n\n\nExercise 16.28 (CoinTestQuestion) Test a coin with Tail-Head-Head. What is the p-value?\n\n\nExercise 16.29 (BorderPValueQuestion) If you get exactly the 0.05 border value, can you reject?\n\n\nExercise 16.30 (OneSidedPValueCautionQuestion) Why should you be careful with a one-sided p-test?\n\n\nExercise 16.31 (BinomialDistributionQuestion) What is the binomial distribution?\n\n\n\n16.1.3.4 p-hacking: What it is and how to avoid it\n\nExercise 16.32 (PHackingWaysQuestion) Name two typical ways of p-hacking.\n\n\nExercise 16.33 (AvoidPHackingQuestion) How can p-hacking be avoided?\n\n\nExercise 16.34 (MultipleTestingProblemQuestion) What is the multiple testing problem?\n\n\n\n16.1.3.5 Covariance\n\nExercise 16.35 (CovarianceDefinitionQuestion) What is covariance?\n\n\nExercise 16.36 (CovarianceMeaningQuestion) What is the meaning of covariance?\n\n\nExercise 16.37 (CovarianceVarianceRelationshipQuestion) What is the relationship between covariance and variance?\n\n\nExercise 16.38 (HighCovarianceQuestion) If covariance is high, is there a strong relationship?\n\n\nExercise 16.39 (ZeroCovarianceQuestion) What if the covariance is zero?\n\n\nExercise 16.40 (NegativeCovarianceQuestion) Can covariance be negative?\n\n\nExercise 16.41 (NegativeVarianceQuestion) Can variance be negative?\n\n\n\n16.1.3.6 Pearson’s Correlation\nVideo: [Pearson’s Correlation, Clearly Explained]\n\nExercise 16.42 (CorrelationValueQuestion) What do you do if the correlation value is 10?\n\n\nExercise 16.43 (CorrelationRangeQuestion) What is the possible range of correlation values?\n\n\nExercise 16.44 (CorrelationFormulaQuestion) What is the formula for correlation?\n\n\n\n16.1.3.7 Boxplots\n\n\n\n16.1.4 June, 18th 2024\n\n16.1.4.1 Statistical Power\n\nVideo: Statistical Power, Clearly Explained\n\n\nExercise 16.45 (UnderstandingStatisticalPower) What is the definition of power in a statistical test?\n\n\nExercise 16.46 (DistributionEffectOnPower) What is the implication for power analysis if the samples come from the same distribution?\n\n\nExercise 16.47 (IncreasingPower) How can you increase the power if the distributions are very similar?\n\n\nExercise 16.48 (PreventingPHacking) What should be done to avoid p-hacking when the distributions are close to each other?\n\n\nExercise 16.49 (SampleSizeAndPower) If there is overlap and the sample size is small, will the power be high or low?\n\n\n\n16.1.4.2 Power Analysis\n\nVideo: Power Analysis, Clearly Explained!!!\n\n\nExercise 16.50 (FactorsAffectingPower) Which are the two main factors that affect power?\n\n\nExercise 16.51 (PurposeOfPowerAnalysis) What does power analysis tell us?\n\n\nExercise 16.52 (ExperimentRisks) What are the two risks faced when performing an experiment?\n\n\nExercise 16.53 (PerformingPowerAnalysis) How do you perform a power analysis?\n\n\n\n16.1.4.3 The Central Limit Theorem\n\nVideo: The Central Limit Theorem, Clearly Explained!!!\n\n\nExercise 16.54 (CentralLimitTheoremExplanation) What does the Central Limit Theorem state?\n\n\n\n16.1.4.4 Boxplots\n\nVideo: Boxplots are Awesome\n\n\nExercise 16.55 (MedianInBoxplot) What is represented by the middle line in a boxplot?\n\n\nExercise 16.56 (BoxContentInBoxplot) What does the box in a boxplot represent?\n\n\n\n16.1.4.5 R-squared\n\nVideo: R-squared, Clearly Explained\n\n\nExercise 16.57 (RSquaredDefinition) What is R-squared? Show the formula.\n\n\nExercise 16.58 (NegativeRSquared) Can the R-squared value be negative?\n\n\nExercise 16.59 (RSquaredCalculation) Perform a calculation involving R-squared.\n\n\n\n16.1.4.6 The main ideas of fitting a line to data (The main ideas of least squares and linear regression.)\n\nVideo: The main ideas of fitting a line to data (The main ideas of least squares and linear regression.)\n\n\nExercise 16.60 (LeastSquaresMeaning) What is the meaning of the least squares method?\n\n\n\n16.1.4.7 Linear Regression\n\nVideo: Linear Regression, Clearly Explained\n\n\n\n16.1.4.8 Multiple Regression\n\nVideo: Multiple Regression, Clearly Explained\n\n\n\n16.1.4.9 A Gentle Introduction to Machine Learning\n\nVideo: A Gentle Introduction to Machine Learning\n\n\nExercise 16.61 (RegressionVsClassification) What is the difference between regression and classification?\n\n\n\n16.1.4.10 Maximum Likelihood\n\nVideo: Maximum Likelihood, clearly explained!!!\n\n\nExercise 16.62 (LikelihoodConcept) What is the idea of likelihood?\n\n\nVideo: Probability is not Likelihood. Find out why!!!\n\n\nExercise 16.63 (ProbabilityVsLikelihood) What is the difference between probability and likelihood?\n\n\n\n16.1.4.11 Cross-Validation\n\nVideo: Machine Learning Fundamentals: Cross Validation\n\n\nExercise 16.64 (TrainVsTestData) What is the difference between training and testing data?\n\n\nExercise 16.65 (SingleValidationIssue) What is the problem if you validate the model only once?\n\n\nExercise 16.66 (FoldDefinition) What is a fold in cross-validation?\n\n\nExercise 16.67 (LeaveOneOutValidation) What is leave-one-out cross-validation?\n\n\n\n16.1.4.12 The Confusion Matrix\n\nVideo: Machine Learning Fundamentals: The Confusion Matrix\n\n\nExercise 16.68 (DrawingConfusionMatrix) Draw the confusion matrix.\n\n\n\n16.1.4.13 Sensitivity and Specificity\n\nVideo: Machine Learning Fundamentals: Sensitivity and Specificity\n\n\nExercise 16.69 (SensitivitySpecificityCalculation1) Calculate the sensitivity and specificity for a given confusion matrix.\n\n\nExercise 16.70 (SensitivitySpecificityCalculation2) Calculate the sensitivity and specificity for a given confusion matrix.\n\n\n\n16.1.4.14 Bias and Variance\n\nVideo: Machine Learning Fundamentals: Bias and Variance\n\n\nExercise 16.71 (BiasAndVariance) What are bias and variance?\n\n\n\n16.1.4.15 Mutual Information\n\nVideo: Mutual Information, Clearly Explained\n\n\nExercise 16.72 (MutualInformationExample) Provide an example and calculate if mutual information is high or low.\n\n\n\n\n16.1.5 June, 25th 2024\n\n16.1.5.1 Principal Component Analysis (PCA)\n\nVideo: Principal Component Analysis (PCA), Step-by-Step\n\n\nExercise 16.73 (WhatIsPCA) What is PCA?\n\n\nExercise 16.74 (ScreePlotExplanation) What is a scree plot?\n\n\nVidoe: PCA - Practical Tips\n\n\nExercise 16.75 (LeastSquaresInPCA) Does PCA use least squares?\n\n\nExercise 16.76 (PCASteps) Which steps are performed by PCA?\n\n\nExercise 16.77 (EigenvaluePC1) What is the eigenvalue of the first principal component?\n\n\nExercise 16.78 (DifferencesBetweenPoints) Are the differences between red and yellow the same as the differences between red and blue points?\n\n\nVideo: PCA in Python\n\n\nExercise 16.79 (ScalingInPCA) How to scale data in PCA?\n\n\nExercise 16.80 (DetermineNumberOfComponents) How to determine the number of principal components?\n\n\nExercise 16.81 (LimitingNumberOfComponents) How is the number of principal components limited?\n\n\n\n\n16.1.6 t-SNE\n\nVideo: t-SNE, Clearly Explained\n\n\nExercise 16.82 (WhyUseTSNE) Why use t-SNE?\n\n\nExercise 16.83 (MainIdeaOfTSNE) What is the main idea of t-SNE?\n\n\nExercise 16.84 (BasicConceptOfTSNE) What is the basic concept of t-SNE?\n\n\nExercise 16.85 (TSNESteps) What are the steps in t-SNE?\n\n\n\n16.1.7 K-means clustering\n\nVideo: K-means clustering\n\n\nExercise 16.86 (HowKMeansWorks) How does K-means clustering work?\n\n\nExercise 16.87 (QualityOfClusters) How can the quality of the resulting clusters be calculated?\n\n\nExercise 16.88 (IncreasingK) Why is it not a good idea to increase k too much?\n\n\n\n16.1.8 DBSCAN\n\nVideo: Clustering with DBSCAN, Clearly Explained!!!\n\n\nExercise 16.89 (CorePointInDBSCAN) What is a core point in DBSCAN?\n\n\nExercise 16.90 (AddingVsExtending) What is the difference between adding and extending in DBSCAN?\n\n\nExercise 16.91 (OutliersInDBSCAN) What are outliers in DBSCAN?\n\n\n\n16.1.9 K-nearest neighbors\n\nVideo: StatQuest: K-nearest neighbors, Clearly Explained\n\n\nExercise 16.92 (AdvantagesAndDisadvantagesOfK) What are the advantages and disadvantages of k = 1 and k = 100 in K-nearest neighbors?\n\n\n\n16.1.10 Naive Bayes\n\nVideo: Naive Bayes, Clearly Explained!!!\n\n\nExercise 16.93 (NaiveBayesFormula) What is the formula for Naive Bayes?\n\n\nExercise 16.94 (CalculateProbabilities) Calculate the probabilities for a given example using Naive Bayes.\n\n\n\n16.1.11 Gaussian Naive Bayes\n\nVideo: Gaussian Naive Bayes, Clearly Explained!!!\n\n\nExercise 16.95 (UnderflowProblem) Why is underflow a problem in Gaussian Naive Bayes?\n\n\n\n16.1.12 July, 2nd 2024\n\n16.1.12.1 Decision and Classification Trees, Clearly Explained\n\n\n16.1.12.2 StatQuest: Decision Trees, Part 2 - Feature Selection and Missing Data\n\n\n16.1.12.3 Regression Trees, Clearly Explained!!!\n\n\n16.1.12.4 How to Prune Regression Trees, Clearly Explained!!!\n\n\n16.1.12.5 Trees\n\nExercise 16.96 (Tree Usage) For what can we use trees?\n\n\n\n16.1.12.6 Decision Trees\n\nExercise 16.97 (Tree Usage) Based on a shown tree graph:\n\nHow can you use this tree?\nWhat is the root node?\nWhat are branches and internal nodes?\nWhat are the leafs?\nAre the leafs pure or impure?\nWhich of the leafs is more impure?\n\n\n\nExercise 16.98 (Tree Feature Importance) Is the most or least important feature on top?\n\n\nExercise 16.99 (Tree Feature Imputation) How can you fill a gap/missing data?\n\n\nSolution 16.1 (Tree Feature Imputation). \n\nMean\nMedian\nComparing to column with high correlation\n\n\n\n\n16.1.12.7 Regression Trees\n\nExercise 16.100 (Regression Tree Limitations) What are limitations?\n\n\nExercise 16.101 (Regression Tree Score) How is the tree score calculated?\n\n\nExercise 16.102 (Regression Tree Alpha Value Small) What can we say about the tree if the alpha value is small?\n\n\nExercise 16.103 (Regression Tree Increase Alpha Value) What happens if you increase alpha?\n\n\nExercise 16.104 (Regression Tree Pruning) What is the meaning of pruning?\n\n\n\n\n16.1.13 Additional Videos\n\nOdds and Log(Odds), Clearly Explained!!!\nOne-Hot, Label, Target and K-Fold Target Encoding, Clearly Explained!!!\nMaximum Likelihood for the Exponential Distribution, Clearly Explained!!!\nROC and AUC, Clearly Explained!\nEntropy (for data science) Clearly Explained!!!\nClassification Trees in Python from Start to Finish: Long live video!",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Data-Driven Modeling and Optimization</span>"
    ]
  },
  {
    "objectID": "100_ddmo.html#introduction-to-statistical-learning",
    "href": "100_ddmo.html#introduction-to-statistical-learning",
    "title": "16  Data-Driven Modeling and Optimization",
    "section": "16.2 Introduction to Statistical Learning",
    "text": "16.2 Introduction to Statistical Learning\n\n\n\n\n\n\nNote\n\n\n\nParts of this course are based on the book An Introduction to Statistical Learning, James et al. (2014). Some of the figures in this presentation are taken from An Introduction to Statistical Learning (Springer, 2013) with permission from the authors: G. James, D. Witten, T. Hastie and R. Tibshirani.\n\n\n\n16.2.1 Opening Remarks and Examples\n\nArtificial Intelligence (AI)\nMachine learning (ML)\nDeep Learning (DL)\n\n\n\n\nAI, ML, and DL. Taken fron Chollet and Allaire (2018)\n\n\n\n1980’s neural networks.\nStatistical learning.\nIBM Watson supercomputer.\n\nStatistical learning problems include:\n\nIdentification of prostate cancer through PSA and other measurements such as age, Gleason score, etc. Scatter plots help reveal the nature of the data and its correlations. Using transformed data (log scale) can highlight typos in the data; for example, a patient with a 449-gram prostate. Recommendation: Always examine the data before conducting any sophisticated analysis.\nClassification of phonemes, specifically between “aa” and “ao.”\nPrediction of heart attacks, which can be visualized through colored scatter plots.\nDetection of email spam, based on the frequency of words within the messages, using 57 features.\nIdentification of numbers in handwritten zip codes, which involves pattern recognition.\nClassification of tissue samples into cancer classes based on gene expression profiles, utilizing heat maps for visualization.\nEstablishing the relationship between salary and demographic variables like income (wage) versus age, year, and education level, employing regression models.\nClassification of pixels in LANDSAT images by their usage, using nearest neighbor methods.\n\n\n16.2.1.1 Supervised and Unsupervised Learning\nTwo important types: supervised and unsupervised learning. There is even more, e.g., semi-supervised learning.\n\n16.2.1.1.1 Starting point\n\nOutcome measurement \\(Y\\) (dependent variable, response, target).\nVector of \\(p\\) predictor measurements \\(X\\) (inputs, regressors, covariates, features, independent variables).\nTraining data \\((x_1, y1), \\ldots ,(x_N, y_N)\\). These are observations (examples, instances) of these measurements.\n\nIn the regression problem, \\(Y\\) is quantitative (e.g., price, blood pressure). In the classification problem, \\(Y\\) takes values in a finite, unordered set (e.g., survived/died, digit 0-9, cancer class of tissue sample).\n\n\n16.2.1.1.2 Philosophy\nIt is important to understand the ideas behind the various techniques, in order to know how and when to use them. One has to understand the simpler methods first, in order to grasp the more sophisticated ones. It is important to accurately assess the performance of a method, to know how well or how badly it is working (simpler methods often perform as well as fancier ones!) This is an exciting research area, having important applications in science, industry and finance. Statistical learning is a fundamental ingredient in the training of a modern data scientist.",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Data-Driven Modeling and Optimization</span>"
    ]
  },
  {
    "objectID": "100_ddmo.html#basics",
    "href": "100_ddmo.html#basics",
    "title": "16  Data-Driven Modeling and Optimization",
    "section": "16.3 Basics",
    "text": "16.3 Basics\n\n16.3.1 Histograms\nCreating a histogram and calculating the probabilities from a dataset can be approached with scientific precision\n\nData Collection: Obtain the dataset you wish to analyze. This dataset could represent any quantitative measure, such to examine its distribution.\nDecide on the Number of Bins: The number of bins influences the histogram’s granularity. There are several statistical rules to determine an optimal number of bins:\n\nSquare-root rule: suggests using the square root of the number of data points as the number of bins.\nSturges’ formula: \\(k = 1 + 3.322 \\log_{10}(n)\\), where \\(n\\) is the number of data points and \\(k\\) is the suggested number of bins.\nFreedman-Diaconis rule: uses the interquartile range (IQR) and the cube root of the number of data points \\(n\\) to calculate bin width as \\(2 \\dfrac{IQR}{n^{1/3}}\\).\n\nDetermine Range and Bin Width: Calculate the range of data by subtracting the minimum data point value from the maximum. Divide this range by the number of bins to determine the width of each bin.\nAllocate Data Points to Bins: Iterate through the data, sorting each data point into the appropriate bin based on its value.\nDraw the Histogram: Use a histogram to visualize the frequency or relative frequency (probability) of data points within each bin.\nCalculate Probabilities: The relative frequency of data within each bin represents the probability of a randomly selected data point falling within that bin’s range.\n\nBelow is a Python script that demonstrates how to generate a histogram and compute probabilities using the matplotlib library for visualization and numpy for data manipulation.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n\n# Sample data: Randomly generated for demonstration\ndata = np.random.normal(0, 1, 1000)  # 1000 data points with a normal distribution\n\n# Step 2: Decide on the number of bins\nnum_bins = int(np.ceil(1 + 3.322 * np.log10(len(data))))  # Sturges' formula\n\n# Step 3: Determine range and bin width -- handled internally by matplotlib\n\n# Steps 4 & 5: Sort data into bins and draw the histogram\nfig, ax = plt.subplots()\nn, bins, patches = ax.hist(data, bins=num_bins, density=True, alpha=0.75, edgecolor='black')\n\n# Calculate probabilities (relative frequencies) manually, if needed\nbin_width = np.diff(bins)  # np.diff finds the difference between adjacent bin boundaries\nprobabilities = n * bin_width  # n is already normalized to form a probability density if `density=True`\n\n# Adding labels and title for clarity\nax.set_xlabel('Data Value')\nax.set_ylabel('Probability Density')\nax.set_title('Histogram with Probability Density')\n\n\n\n\n\n\nText(0.5, 1.0, 'Histogram with Probability Density')\n\n\n(a) Histogram with Probability Density\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\nFigure 16.1\n\n\n\n\n\nfor i, prob in enumerate(probabilities):\n    print(f\"Bin {i+1} Probability: {prob:.4f}\")\n\n# Ensure probabilities sum to 1 (or very close, due to floating-point arithmetic)\nprint(f\"Sum of probabilities: {np.sum(probabilities)}\")\n\nBin 1 Probability: 0.0080\nBin 2 Probability: 0.0240\nBin 3 Probability: 0.0830\nBin 4 Probability: 0.1820\nBin 5 Probability: 0.2590\nBin 6 Probability: 0.2310\nBin 7 Probability: 0.1370\nBin 8 Probability: 0.0560\nBin 9 Probability: 0.0150\nBin 10 Probability: 0.0040\nBin 11 Probability: 0.0010\nSum of probabilities: 1.0\n\n\nThis code segment goes through the necessary steps to generate a histogram and calculate probabilities for a synthetic dataset. It demonstrates important scientific and computational practices including binning, visualization, and probability calculation in Python.\nKey Points: - The histogram represents the distribution of data, with the histogram’s bins outlining the data’s spread and density. - The option density=True in ax.hist() normalizes the histogram so that the total area under the histogram sums to 1, thereby converting frequencies to probability densities. - The choice of bin number and width has a significant influence on the histogram’s shape and the insights that can be drawn from it, highlighting the importance of selecting appropriate binning strategies based on the dataset’s characteristics and the analysis objectives.\n\n\n16.3.2 Probability Distributions\nWhat happens when we use smaller bins in a histogram? The histogram becomes more detailed, revealing the distribution of data points with greater precision. However, as the bin size decreases, the number of data points within each bin may decrease, leading to sparse or empty bins. This sparsity can make it challenging to estimate probabilities accurately, especially for data points that fall within these empty bins.\nAdvantages, when using a probability distribution, include:\n\nBlanks can be filled\nProbabilities can be calculated\nParameters are sufficiemnt to describe the distribution, e.g., mean and variance for the normal distribution\n\nProbability distributions offer a powerful solution to the challenges posed by limited data in estimating probabilities. When data is scarce, constructing a histogram to determine the probability of certain outcomes can lead to inaccurate or unreliable results due to the lack of detail in the dataset. However, collecting vast amounts of data to populate a histogram for more precise estimates can often be impractical, time-consuming, and expensive.\nA probability distribution is a mathematical function that provides the probabilities of occurrence of different possible outcomes for an experiment. It is a more efficient approach to understanding the likelihood of various outcomes than relying solely on extensive data collection. For continuous data, this is often represented graphically by a smooth curve.\n\n16.3.2.1 The Normal Distribution: A Common Example\nA commonly encountered probability distribution is the normal distribution, known for its characteristic bell-shaped curve. This curve represents how the values of a variable are distributed: most of the observations cluster around the mean (or center) of the distribution, with frequencies gradually decreasing as values move away from the mean.\nThe normal distribution is particularly useful because of its defined mathematical properties. It is determined entirely by its mean (mu, \\(\\mu\\)) and its standard deviation (sigma, \\(\\sigma\\)). The area under the curve represents probability, making it possible to calculate the likelihood of a random variable falling within a specific range.\n\n\n16.3.2.2 Practical Example: Estimating Probabilities\nConsider we are interested in the heights of adults in a population. Instead of measuring the height of every adult (which would be impractical), we can use the normal distribution to estimate the probability of adults’ heights falling within certain intervals, assuming we know the mean and standard deviation of the heights.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\nmu = 170  # e.g., mu height of adults in cm\nsd = 10  # e.g., standard deviation of heights in cm\nheights = np.linspace(mu - 3*sd, mu + 3*sd, 1000)\n# Calculate the probability density function for the normal distribution\npdf = norm.pdf(heights, mu, sd)\n# Plot the normal distribution curve\nplt.plot(heights, pdf, color='blue', linewidth=2)\nplt.fill_between(heights, pdf, where=(heights &gt;= mu - 2 * sd) & (heights &lt;= mu + 2*sd), color='grey', alpha=0.5)\nplt.xlabel('Height (cm)')\nplt.ylabel('Probability Density')\nplt.show()\n\n\n\n\n\n\n\nFigure 16.2: Normal Distribution Curve with Highlighted Probability Area. 95 percent of the data falls within two standard deviations of the mean.\n\n\n\n\n\nThis Python code snippet generates a plot of the normal distribution for adult heights, with a mean of 170 cm and a standard deviation of 10 cm. It visually approximates a histogram with a blue bell-shaped curve, and highlights (in grey) the area under the curve between \\(\\mu \\pm 2 \\times \\sigma\\). This area corresponds to the probability of randomly selecting an individual whose height falls within this range.\nBy using the area under the curve, we can efficiently estimate probabilities without needing to collect and analyze a vast amount of data. This method not only saves time and resources but also provides a clear and intuitive way to understand and communicate statistical probabilities.\n\n\n\n16.3.3 Discrete Distributions\nDiscrete probability distributions are essential tools in statistics, providing a mathematical foundation to model and analyze situations with discrete outcomes. Histograms, which can be seen as discrete distributions with data organized into bins, offer a way to visualize and estimate probabilities based on the collected data. However, they come with limitations, especially when data is scarce or when we encounter gaps in the data (blank spaces in histograms). These gaps can make it challenging to accurately estimate probabilities.\nA more efficient approach, especially for discrete data, is to use mathematical equations—particularly those defining discrete probability distributions—to calculate probabilities directly, thus bypassing the intricacies of data collection and histogram interpretation.\n\n16.3.3.1 Bernoulli Distribution\nThe Bernoulli distribution, named after Swiss scientist Jacob Bernoulli, is a discrete probability distribution, which takes value \\(1\\) with success probability \\(p\\) and value \\(0\\) with failure probability \\(q = 1-p\\). So if \\(X\\) is a random variable with this distribution, we have: \\[\nP(X=1) = 1-P(X=0) = p = 1-q.\n\\]\n\n\n16.3.3.2 Binomial Distribution\nThe Binomial Distribution is a prime example of a discrete probability distribution that is particularly useful for binary outcomes (e.g., success/failure, yes/no, pumpkin pie/blueberry pie). It leverages simple mathematical principles to calculate the probability of observing a specific number of successes (preferred outcomes) in a fixed number of trials, given the probability of success in each trial.\n\n\n16.3.3.3 An Illustrative Example: Pie Preference\nConsider a scenario from “StatLand” where 70% of people prefer pumpkin pie over blueberry pie. The question is: What is the probability that, out of three people asked, the first two prefer pumpkin pie and the third prefers blueberry pie?\nUsing the concept of the Binomial Distribution, the probability of such an outcome can be calculated without the need to layout every possible combination by hand. This process not only simplifies calculations but also provides a clear and precise method to determine probabilities in scenarios involving discrete choices. We will use Python to calculate the probability of observing exactly two out of three people prefer pumpkin pie, given the 70% preference rate:\n\nfrom scipy.stats import binom\nn = 3  # Number of trials (people asked)\np = 0.7  # Probability of success (preferring pumpkin pie)\nx = 2  # Number of successes (people preferring pumpkin pie)\n# Probability calculation using Binomial Distribution\nprob = binom.pmf(x, n, p)\nprint(f\"The probability that exactly 2 out of 3 people prefer pumpkin pie is: {prob:.3f}\")\n\nThe probability that exactly 2 out of 3 people prefer pumpkin pie is: 0.441\n\n\nThis code uses the binom.pmf() function from scipy.stats to calculate the probability mass function (PMF) of observing exactly x successes in n trials, where each trial has a success probability of p.\nA Binomial random variable is the sum of \\(n\\) independent, identically distributed Bernoulli random variables, each with probability \\(p\\) of success. We may indicate a random variable \\(X\\) with Bernoulli distribution using the notation \\(X \\sim \\mathrm{Bi}(1,\\theta)\\). Then, the notation for the Binomial is \\(X \\sim \\mathrm{Bi}(n,\\theta)\\). Its probability and distribution functions are, respectively, \\[\np_X(x) = {n\\choose x}\\theta^x(1-\\theta)^{n-x}, \\qquad F_X(x) = \\Pr\\{X \\le x\\} = \\sum_{i=0}^{x} {n\\choose i}\\theta^i(1-\\theta)^{n-i}.\n\\]\nThe mean of the binomial distribution is \\(\\text{E}[X] = n\\theta\\). The variance of the distribution is \\(\\text{Var}[X] = n\\theta(1-\\theta)\\) (see next section).\nA process consists of a sequence of \\(n\\) independent trials, i.e., the outcome of each trial does not depend on the outcome of previous trials. The outcome of each trial is either a success or a failure. The probability of success is denoted as \\(p\\), and \\(p\\) is constant for each trial. Coin tossing is a classical example for this setting.\nThe binomial distribution is a statistical distribution giving the probability of obtaining a specified number of successes in a binomial experiment; written Binomial(n, p), where \\(n\\) is the number of trials, and \\(p\\) the probability of success in each.\n\nDefinition 16.1 (Binomial Distribution) The binomial distribution with parameters \\(n\\) and \\(p\\), where \\(n\\) is the number of trials, and \\(p\\) the probability of success in each, is \\[\\begin{equation}\np(x) = { n \\choose k } p^x(1-p)^{n-x} \\qquad x = 0,1, \\ldots, n.\n\\end{equation}\\] The mean \\(\\mu\\) and the variance \\(\\sigma^2\\) of the binomial distribution are \\[\\begin{equation}\n\\mu = np\n\\end{equation}\\] and \\[\\begin{equation}\n\\sigma^2 = np(1-p).\n\\end{equation}\\]\n\nNote, the Bernoulli distribution is simply Binomial(1,p).",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Data-Driven Modeling and Optimization</span>"
    ]
  },
  {
    "objectID": "100_ddmo.html#continuous-distributions",
    "href": "100_ddmo.html#continuous-distributions",
    "title": "16  Data-Driven Modeling and Optimization",
    "section": "16.4 Continuous Distributions",
    "text": "16.4 Continuous Distributions\nOur considerations regarding probability distributions, expectations, and standard deviations will be extended from discrete distributions to continuous distributions. One simple example of a continuous distribution is the uniform distribution. Continuous distributions are defined by probability density functions.\n\n16.4.1 Distribution functions: PDFs and CDFs\nThe density for a continuous distribution is a measure of the relative probability of “getting a value close to \\(x\\).” Probability density functions \\(f\\) and cumulative distribution function \\(F\\) are related as follows. \\[\\begin{equation}\nf(x) = \\frac{d}{dx} F(x)\n\\end{equation}\\]\n\n\n16.4.2 Expectation (Continuous)\n\nDefinition 16.2 (Expectation (Continuous)) \\[\\begin{equation}\n  \\text{E}(X) = \\int_{-\\infty}^\\infty x f(x) \\, dx\n  \\end{equation}\\]\n\n\n\n16.4.3 Variance and Standard Deviation (Continuous)\n\nDefinition 16.3 (Variance (Continuous)) Variance can be calculated with \\(\\text{E}(X)\\) and \\[\\begin{equation}\n  \\text{E}(X^2) = \\int_{-\\infty}^\\infty x^2 f(x) \\, dx\n\\end{equation}\\] as \\[\\begin{equation*}\n  \\text{Var}(X) = \\text{E}(X^2) - [ E(X)]^2.\n  \\end{equation*}\\] \\(\\Box\\)\n\n\nDefinition 16.4 (Standard Deviation (Continuous)) Standard deviation can be calculated as \\[\\begin{equation*}\n  \\text{sd}(X) = \\sqrt{\\text{Var}(X)}.\n  \\end{equation*}\\] \\(\\Box\\)\n\n\n\n16.4.4 Uniform Distribution\nThis variable is defined in the interval \\([a,b]\\). We write it as \\(X \\sim U[a,b]\\). Its density and cumulative distribution functions are, respectively, \\[\nf_X(x) = \\frac{I_{[a,b]}(x)}{b-a},  \\quad\\quad F_X(x) = \\frac{1}{b-a}\\int\\limits_{-\\infty}\\limits^x I_{[a,b]}(t) \\mathrm{d}t = \\frac{x-a}{b-a},\n\\] where \\(I_{[a,b]}(\\cdot)\\) is the indicator function of the interval \\([a,b]\\). Note that, if we set \\(a=0\\) and \\(b=1\\), we obtain \\(F_X(x) = x\\), \\(x\\) \\(\\in\\) \\([0,1]\\).\nA typical example is the following: the cdf of a continuous r.v. is uniformly distributed in \\([0,1]\\). The proof of this statement is as follows: For \\(u\\) \\(\\in\\) \\([0,1]\\), we have \\[\\begin{eqnarray*}\n\\Pr\\{F_X(X) \\leq u\\} &=& \\Pr\\{F_X^{-1}(F_X(X)) \\leq F_X^{-1}(u)\\} = \\Pr\\{X \\leq F_X^{-1}(u)\\} \\\\\n                      &=& F_X(F_X^{-1}(u)) = u.     \n\\end{eqnarray*}\\] This means that, when \\(X\\) is continuous, there is a one-to-one relationship (given by the cdf) between \\(x\\) \\(\\in\\) \\(D_X\\) and \\(u\\) \\(\\in\\) \\([0,1]\\).\nThe has a constant density over a specified interval, say \\([a,b]\\). The uniform \\(U(a,b)\\) distribution has density \\[\\begin{equation}\nf(x) =\n\\left\\{\n  \\begin{array}{ll}\n  1/(b-a) & \\textrm{ if } a &lt; x &lt; b,\\\\\n  0 & \\textrm{ otherwise}\n  \\end{array}\n  \\right.\n  \\end{equation}\\]\n\n\n16.4.5 Normal Distribution\n\nDefinition 16.5 (Normal Distribution) This variable is defined on the support \\(D_X = \\mathbb{R}\\) and its density function is given by \\[\nf_X(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left \\{-\\frac{1}{2\\sigma^2}(x-\\mu)^2 \\right \\}.\n\\] The density function is identified by the pair of parameters \\((\\mu,\\sigma^2)\\), where \\(\\mu\\) \\(\\in\\) \\(\\mathbb{R}\\) is the mean (or location parameter) and \\(\\sigma^2 &gt; 0\\) is the variance (or dispersion parameter) of \\(X\\). \\(\\Box\\)\n\nThe density function is symmetric around \\(\\mu\\). The normal distribution belongs to the location-scale family distributions. This means that, if \\(Z \\sim N(0,1)\\) (read, \\(Z\\) has a standard normal distribution; i.e., with \\(\\mu=0\\) and \\(\\sigma^2=1\\)), and we consider the linear transformation \\(X = \\mu + \\sigma Z\\), then \\(X \\sim N(\\mu,\\sigma^2)\\) (read, \\(X\\) has a normal distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\)). This means that one can obtain the probability of any interval \\((-\\infty,x]\\), \\(x\\) \\(\\in\\) \\(R\\) for any normal distribution (i.e., for any pair of the parameters \\(\\mu\\) and \\(\\sigma\\)) once the quantiles of the standard normal distribution are known. Indeed \\[\\begin{eqnarray*}\nF_X(x) &=& \\Pr\\left\\{X \\leq x \\right\\} = \\Pr\\left\\{\\frac{X-\\mu}{\\sigma} \\leq \\frac{x-\\mu}{\\sigma} \\right\\} \\\\\n           &=& \\Pr\\left\\{Z \\leq \\frac{x-\\mu}{\\sigma}\\right\\}  = F_Z\\left(\\frac{x-\\mu}{\\sigma}\\right)    \\qquad x \\in \\mathbb{R}.\n\\end{eqnarray*}\\] The quantiles of the standard normal distribution are available in any statistical program. The density and cumulative distribution function of the standard normal r.v.~at point \\(x\\) are usually denoted by the symbols \\(\\phi(x)\\) and \\(\\Phi(x)\\).\nThe standard normal distribution is based on the \\[\n\\varphi(z) = \\frac{1}{\\sqrt{2\\pi}} \\exp \\left(- \\frac{z^2}{2} \\right).\n\\tag{16.1}\\]\nAn important application of the standardization introduced in Equation 16.1 reads as follows. In case the distribution of \\(X\\) is approximately normal, the distribution of X^{*} is approximately standard normal. That is \\[\\begin{equation*}\n  P(X\\leq b) = P( \\frac{X-\\mu}{\\sigma} \\leq \\frac{b-\\mu}{\\sigma}) = P(X^{*} \\leq \\frac{b-\\mu}{\\sigma})\n\\end{equation*}\\] The probability \\(P(X\\leq b)\\) can be approximated by \\(\\Phi(\\frac{b-\\mu}{\\sigma})\\), where \\(\\Phi\\) is the standard normal cumulative distribution function.\nIf \\(X\\) is a normal random variable with mean \\(\\mu\\) and variance \\(\\sigma^2\\), i.e., \\(X \\sim \\cal{N} (\\mu, \\sigma^2)\\), then \\[\\begin{equation}\n  X = \\mu + \\sigma Z \\textrm{ where } Z \\sim \\cal{N}(0,1).\n  \\end{equation}\\]\nIf \\(Z \\sim \\cal{N}(0,1)\\) and \\(X\\sim \\cal{N}(\\mu, \\sigma^2)\\), then \\[\\begin{equation*}\n  X = \\mu + \\sigma Z.\n\\end{equation*}\\]\nThe probability of getting a value in a particular interval is the area under the corresponding part of the curve. Consider the density function of the normal distribution. It can be plotted using the following commands. The result is shown in Figure 16.3.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\nx = np.arange(-4, 4, 0.1)\n# Calculating the normal distribution's density function values for each point in x\ny = norm.pdf(x, 0, 1)\nplt.plot(x, y, linestyle='-', linewidth=2)\nplt.title('Normal Distribution')\nplt.xlabel('X')\nplt.ylabel('Density')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\nFigure 16.3: Normal Distribution Density Function\n\n\n\n\n\nThe (CDF) describes the probability of “hitting” \\(x\\) or less in a given distribution. We consider the CDF function of the normal distribution. It can be plotted using the following commands. The result is shown in Figure 16.4.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Generating a sequence of numbers from -4 to 4 with 0.1 intervals\nx = np.arange(-4, 4, 0.1)\n\n# Calculating the cumulative distribution function value of the normal distribution for each point in x\ny = norm.cdf(x, 0, 1)  # mean=0, stddev=1\n\n# Plotting the results. The equivalent of 'type=\"l\"' in R (line plot) becomes the default plot type in matplotlib.\nplt.plot(x, y, linestyle='-', linewidth=2)\nplt.title('Normal Distribution CDF')\nplt.xlabel('X')\nplt.ylabel('Cumulative Probability')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\nFigure 16.4: Normal Distribution Cumulative Distribution Function\n\n\n\n\n\n\n\n16.4.6 The Mean, the Median, and the Mode\n\n\n16.4.7 The Exponential Distribution\nThe exponential distribution is a continuous probability distribution that describes the time between events in a Poisson process, where events occur continuously and independently at a constant average rate. It is characterized by a single parameter, the rate parameter \\(\\lambda\\), which represents the average number of events per unit time.\n\n\n16.4.8 Population and Estimated Parameters\n\n\n16.4.9 Calculating the Mean, Variance, and Standard Deviation\n\n\n16.4.10 What is a Mathematical Model?\n\n\n16.4.11 Sampling from a Distribution\n\n\n16.4.12 Hypothesis Testing and the Null Hypothesis\n\n\n16.4.13 Alternative Hypotheses\n\n\n16.4.14 p-values: What They Are and How to Interpret Them\n\n\n16.4.15 How to Calculate p-values\n\n\n16.4.16 p-hacking: What It Is and How to Avoid It\n\n\n16.4.17 Covariance\n\n\n16.4.18 Pearson’s Correlation\n\n\n16.4.19 Boxplots\n\n\n16.4.20 R-squared\n\n\n16.4.21 The Main Ideas of Fitting a Line to Data\n\n\n16.4.22 Linear Regression\n\n\n16.4.23 Multiple Regression",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Data-Driven Modeling and Optimization</span>"
    ]
  },
  {
    "objectID": "100_ddmo.html#supervised-learning",
    "href": "100_ddmo.html#supervised-learning",
    "title": "16  Data-Driven Modeling and Optimization",
    "section": "16.5 Supervised Learning",
    "text": "16.5 Supervised Learning\nObjectives of supervised learning: On the basis of the training data we would like to:\n\nAccurately predict unseen test cases.\nUnderstand which inputs affect the outcome, and how.\nAssess the quality of our predictions and inferences.\n\nNote: Supervised means \\(Y\\) is known.\n\nExercise 16.105  \n\nDo children learn supervised?\nWhen do you learn supervised?\nCan learning be unsupervised?\n\n\n\n16.5.0.0.1 Unsupervised Learning\nNo outcome variable, just a set of predictors (features) measured on a set of samples. The objective is more fuzzy—find groups of samples that behave similarly, find features that behave similarly, find linear combinations of features with the most variation. It is difficult to know how well your are doing. Unsupervised learning different from supervised learning, but can be useful as a pre-processing step for supervised learning. Clustering and principle component analysis are important techniques.\nUnsupervised: \\(Y\\) is unknown, there is no \\(Y\\), no trainer, no teacher, but: distances between the inputs values (features). A distance (or similarity) measure is necessary.\n\n\n16.5.0.0.2 Statistical Learning\nWe consider supervised learning first.\n\n\n\n\n\n\nFigure 16.5: Sales as a function of TV, radio and newspaper. Taken from James et al. (2014)\n\n\n\nSales figures from a marketing campaign, see Figure 16.5. Trend shown using regression. First seems to be stronger than the third.\nCan we predict \\(Y\\) = Sales using these three? Perhaps we can do better using a model \\[\nY = Sales \\approx  f(X_1 = TV,  X_2 = Radio, X_3= Newspaper)\n\\] modeling the joint relationsship.\nHere Sales is a response or target that we wish to predict. We generically refer to the response as \\(Y\\). TV is a feature, or input, or predictor; we name it \\(X_1\\). Likewise name Radio as \\(X_2\\), and so on. We can refer to the input vector collectively as \\[\nX =\n\\begin{pmatrix}\nX_1\\\\\nX_2\\\\\nX_3\n\\end{pmatrix}\n\\]\nNow we write our model as \\[\nY = f(X) + \\epsilon\n\\] where \\(\\epsilon\\) captures measurement errors and other discrepancies.\nWhat is \\(f\\) good for? With a good \\(f\\) we can make predictions of \\(Y\\) at new points \\(X = x\\). We can understand which components of \\(X = (X_1, X_2, \\ldots X_p)\\) are important in explaining \\(Y\\), and which are irrelevant.\nFor example, Seniority and Years of Education have a big impact on Income, but Marital Status typically does not. Depending on the complexity of \\(f\\), we may be able to understand how each component \\(X_j\\) of \\(X\\) affects \\(Y\\).\n\n\n16.5.1 Statistical Learning and Regression\n\n16.5.1.1 Regression Function\n\n\n\n\n\n\nFigure 16.6: Scatter plot of 2000 points (population). What is a good function \\(f\\)? There are many function values at \\(X=4\\). A function can return only one value. We can take the mean from these values as a return value. Taken from James et al. (2014)\n\n\n\nConsider Figure 16.6. Is there an ideal \\(f(X)\\)? In particular, what is a good value for \\(f(X)\\) at any selected value of \\(X\\), say \\(X = 4\\)? There can be many \\(Y\\) values at \\(X=4\\). A good value is \\[\nf(4) = E(Y |X = 4).\n\\]\n\\(E(Y |X = 4)\\) means expected value (average) of \\(Y\\) given \\(X = 4\\).\nThe ideal \\(f(x) = E(Y |X = x)\\) is called the regression function. Read: The regression function gives the conditional expectation of \\(Y\\) given \\(X\\).\nThe regression function \\(f(x)\\) is also defined for the vector \\(X\\); e.g., \\(f(x) = f(x_1, x_2, x_3) = E(Y | X_1 =x_1, X_2 =x_2, X_3 =x_3).\\)\n\n\n\n16.5.2 Optimal Predictor\nThe regression function is the ideal or optimal predictor of \\(Y\\) with regard to mean-squared prediction error: It means that \\(f(x) = E(Y | X = x)\\) is the function that minimizes \\[\nE[(Y - g(X))^2|X = x]\n\\] over all functions \\(g\\) at all points \\(X = x\\).\n\n\n16.5.2.1 Residuals, Reducible and Irreducible Error\nAt each point \\(X\\) we make mistakes: \\[\n\\epsilon = Y-f(x)\n\\] is the residual. Even if we knew \\(f(x)\\), we would still make errors in prediction, since at each \\(X=x\\) there is typically a distribution of possible \\(Y\\) values as is illustrated in Figure 16.6.\nFor any estimate \\(\\hat{f}(x)\\) of \\(f(x)\\), we have \\[\nE\\left[ ( Y - \\hat{f}(X))^2 | X = x\\right] = \\left[ f(x) - \\hat{f}(x) \\right]^2 + \\text{var}(\\epsilon),\n\\] and \\(\\left[ f(x) - \\hat{f}(x) \\right]^2\\) is the reducible error, because it depends on the model (changing the model \\(f\\) might reduce this error), and \\(\\text{var}(\\epsilon)\\) is the irreducible error.\n\n\n16.5.2.2 Local Regression (Smoothing)\nTypically we have few if any data points with \\(X = 4\\) exactly. So we cannot compute \\(E(Y |X = x)\\)! Idea: Relax the definition and let \\[\n\\hat{f}(x)=  Ave(Y|X \\in  \\cal{N}(x)),\n\\] where \\(\\cal{N} (x)\\) is some neighborhood of \\(x\\), see Figure 16.7.\n\n\n\n\n\n\nFigure 16.7: Relaxing the definition. There is no \\(Y\\) value at \\(X=4\\). Taken from James et al. (2014)\n\n\n\nNearest neighbor averaging can be pretty good for small \\(p\\), i.e., \\(p \\leq 4\\) and large-ish \\(N\\). We will discuss smoother versions, such as kernel and spline smoothing later in the course.\n\n\n16.5.3 Curse of Dimensionality and Parametric Models\n\n\n\n\n\n\nFigure 16.8: A 10% neighborhood in high dimensions need no longer be local. Left: Values of two variables \\(x_1\\) and \\(x_2\\), uniformly distributed. Form two 10% neighborhoods: (a) the first is just involving \\(x_1\\) ignoring \\(x_2\\). (b) is the neighborhood in two dimension. Notice that the radius of the circle is much larger than the lenght of the interval in one dimension. Right: radius plotted against fraction of the volume. In 10 dim, you have to break out the interval \\([-1;+1]\\) to get 10% of the data. Taken from James et al. (2014)\n\n\n\nLocal, e.g., nearest neighbor, methods can be lousy when \\(p\\) is large. Reason: the curse of dimensionality, i.e., nearest neighbors tend to be far away in high dimensions. We need to get a reasonable fraction of the \\(N\\) values of \\(y_i\\) to average to bring the variance down—e.g., 10%. A 10% neighborhood in high dimensions need no longer be local, so we lose the spirit of estimating \\(E(Y |X = x)\\) by local averaging, see Figure 16.8. If the curse of dimensionality does not exist, nearest neighbor models would be perfect prediction models.\nWe will use structured (parametric) models to deal with the curse of dimensionality. The linear model is an important example of a parametric model: \\[\nf_L(X) = \\beta_0 + \\beta_1 X_1 + \\ldots + \\beta_p X_p.\n\\] A linear model is specified in terms of \\(p + 1\\) parameters $ _1, _2, , _p$. We estimate the parameters by fitting the model to . Although it is almost never correct, a linear model often serves as a good and interpretable approximation to the unknown true function \\(f(X)\\).\nThe linear model is avoiding the curse of dimensionality, because it is not relying on any local properties. Linear models belong to the class of approaches: they replace the problem of estimating \\(f\\) with estimating a fixed set of coefficients \\(\\beta_i\\), with \\(i=1,2, \\ldots, p\\).\n\n\n\n\n\n\nFigure 16.9: A linear model \\(\\hat{f}_L\\) gives a reasonable fit. Taken from James et al. (2014)\n\n\n\n\n\n\n\n\n\nFigure 16.10: A quadratic model \\(\\hat{f}_Q\\) fits slightly better. Taken from James et al. (2014)\n\n\n\nA linear model \\[\n\\hat{f}_L(X) = \\hat{\\beta}_0 + \\hat{\\beta}_1 X\n\\] gives a reasonable fit, see Figure 16.9. A quadratic model \\[\n\\hat{f}_Q(X) = \\hat{\\beta}_0 + \\hat{\\beta}_1 X + \\hat{\\beta}_2 X^2\n\\] gives a slightly improved fit, see Figure 16.10.\nFigure 16.11 shows a simulated example. Red points are simulated values for income from the model \\[\nincome = f(education, seniority) + \\epsilon\n\\] \\(f\\) is the blue surface.\n\n\n\n\n\n\nFigure 16.11: The true model. Red points are simulated values for income from the model, \\(f\\) is the blue surface. Taken from James et al. (2014)\n\n\n\n\n\n\n\n\n\nFigure 16.12: Linear regression fit to the simulated data (red points). Taken from James et al. (2014)\n\n\n\nThe linear regression model \\[\n\\hat{f}(education, seniority) = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\times education +\n\\hat{\\beta}_2 \\times seniority\n\\] captures the important information. But it does not capture everything. More flexible regression model \\[\n\\hat{f}_S (education, seniority)\n\\] fit to the simulated data. Here we use a technique called a thin-plate spline to fit a flexible surface. Even more flexible spline regression model \\[\n\\hat{f}_S (education, seniority)\n\\] fit to the simulated data. Here the fitted model makes no errors on the training data! Also known as overfitting.\n\n\n\n\n\n\nFigure 16.13: Thin-plate spline models \\(\\hat{f}_S (education, seniority)\\) fitted to the model from Figure 16.11. Taken from James et al. (2014)\n\n\n\n\n\n\n\n\n\nFigure 16.14: Thin-plate spline models \\(\\hat{f}_S (education, seniority)\\) fitted to the model from Figure 16.11. The model makes no errors on the training data (overfitting). Taken from James et al. (2014)\n\n\n\n\n16.5.3.1 Trade-offs\n\nPrediction accuracy versus interpretability: Linear models are easy to interpret; thin-plate splines are not.\nGood fit versus over-fit or under-fit: How do we know when the fit is just right?\nParsimony (Occam’s razor) versus black-box: We often prefer a simpler model involving fewer variables over a black-box predictor involving them all.\n\nThe trad-offs are visualized in Figure 16.15.\n\n\n\n\n\n\nFigure 16.15: Interpretability versus flexibility. Flexibility corresponds with the number of model parameters. Taken from James et al. (2014)\n\n\n\n\n\n\n16.5.4 Assessing Model Accuracy and Bias-Variance Trade-off\n\n\n\n\n\n\nFigure 16.16: Black curve is truth. Red curve on right is \\(MSETe\\), grey curve is \\(MSETr\\). Orange, blue and green curves/squares correspond to fits of different flexibility. The dotted line represents the irreducible error, i.e., \\(var(\\epsilon)\\). Taken from James et al. (2014)\n\n\n\n\n\n\n\n\n\nFigure 16.17: Here, the truth is smoother. Black curve is truth. Red curve on right is \\(MSETe\\), grey curve is \\(MSETr\\). Orange, blue and green curves/squares correspond to fits of different flexibility. The dotted line represents the irreducible error, i.e., \\(var(\\epsilon)\\). Taken from James et al. (2014)\n\n\n\n\n\n\n\n\n\nFigure 16.18: Here the truth is wiggly and the noise is low, so the more flexible fits do the best. Black curve is truth. Red curve on right is \\(MSETe\\), grey curve is \\(MSETr\\). Orange, blue and green curves/squares correspond to fits of different flexibility. The dotted line represents the irreducible error, i.e., \\(var(\\epsilon)\\). Taken from James et al. (2014)\n\n\n\nSuppose we fit a model \\(f(x)\\) to some training data \\(Tr = \\{x_i, y_i \\}^N_1\\), and we wish to see how well it performs. We could compute the average squared prediction error over \\(Tr\\): \\[\nMSE_{Tr} = Ave_{i \\in Tr}[y_i - \\hat{f}(x_i)]^2.\n\\] This may be biased toward more overfit models. Instead we should, if possible, compute it using fresh test data \\(Te== \\{x_i, y_i \\}^N_1\\): \\[\nMSE_{Te} = Ave_{i \\in Te}[y_i - \\hat{f}(x_i)]^2.\n\\] The red curve, which illustrated the test error, can be estimated by holding out some data to get the test-data set.\n\n16.5.4.1 Bias-Variance Trade-off\nSuppose we have fit a model \\(f(x)\\) to some training data \\(Tr\\), and let \\((x_0, y_0)\\) be a test observation drawn from the population. If the true model is \\[\nY = f(X) + \\epsilon  \\qquad \\text{ with } f(x) = E(Y|X=x),\n\\] then \\[\nE \\left( y_0 - \\hat{f}(x_0) \\right)^2 = \\text{var} (\\hat{f}(x_0)) + [Bias(\\hat{f}(x_0))]^2 + \\text{var}(\\epsilon).\n\\tag{16.2}\\]\nHere, \\(\\text{var}(\\epsilon)\\) is the irreducible error. The reducible error consists of two components:\n\n\\(\\text{var} (\\hat{f}(x_0))\\) is the variance that comes from different training sets. Different training sets result in different functions \\(\\hat{f}\\).\n\\(Bias(\\hat{f}(x_0)) = E[\\hat{f}(x_0)] - f(x_0)\\).\n\nThe expectation averages over the variability of \\(y_0\\) as well as the variability in \\(Tr\\). Note that \\[\nBias(\\hat{f}(x_0)) = E[\\hat{f}(x_0)] - f(x_0).\n\\] Typically as the flexibility of \\(\\hat{f}\\) increases, its variance increases (because the fits differ from training set to trainig set), and its bias decreases. So choosing the flexibility based on average test error amounts to a bias-variance trade-off, see Figure 16.19.\n\n\n\n\n\n\nFigure 16.19: Bias-variance trade-off for the three examples. Taken from James et al. (2014)\n\n\n\nIf we add the two components (reducible and irreducible error), we get the MSE in Figure 16.19 as can be seen in Equation 16.2.\n\n\n\n16.5.5 Classification Problems and K-Nearest Neighbors\nIn classification we have a qualitative response variable.\n\n\n\n\n\n\nFigure 16.20: Classification. Taken from James et al. (2014)\n\n\n\nHere the response variable \\(Y\\) is qualitative, e.g., email is one of \\(\\cal{C} = (spam, ham)\\), where ham is good email, digit class is one of \\(\\cal{C} = \\{ 0, 1, \\ldots, 9 \\}\\). Our goals are to:\n\nBuild a classifier \\(C(X)\\) that assigns a class label from \\(\\cal{C}\\) to a future unlabeled observation \\(X\\).\nAssess the uncertainty in each classification\nUnderstand the roles of the different predictors among \\(X = (X_1,X_2, \\ldots, X_p)\\).\n\nSimulation example depicted in@fig-0218a. \\(Y\\) takes two values, zero and one, and \\(X\\) has only one value. Big sample: each single vertical bar indicates an occurrance of a zero (orange) or one (blue) as a function of the \\(X\\)s. Black curve generated the data: it is the probability of generating a one. For high values of \\(X\\), the probability of ones is increasing. What is an ideal classifier \\(C(X)\\)?\nSuppose the \\(K\\) elements in \\(\\cal{C}\\) are numbered \\(1,2,\\ldots, K\\). Let \\[\np_k(x) = Pr(Y = k|X = x), k = 1,2,\\ldots,K.\n\\]\nThese are the conditional class probabilities at \\(x\\); e.g. see little barplot at \\(x = 5\\). Then the Bayes optimal classifier at \\(x\\) is \\[\nC(x) = j \\qquad \\text{ if }  p_j(x) = \\max \\{p_1(x),p_2(x),\\ldots, p_K(x)\\}.\n\\] At \\(x=5\\) there is an 80% probability of one, and an 20% probability of a zero. So, we classify this point to the class with the highest probability, the majority class.\nNearest-neighbor averaging can be used as before. This is illustrated in Fig.~\\(\\ref{fig:0219a}\\). Here, we consider 100 points only. Nearest-neighbor averaging also breaks down as dimension grows. However, the impact on \\(\\hat{C}(x)\\) is less than on \\(\\hat{p}_k (x)\\), \\(k = 1, \\ldots, K\\).\n\n\n\n\n\n\nFigure 16.21: Classification. Taken from James et al. (2014)\n\n\n\n\n16.5.5.1 Classification: Some Details\nAverage number of errors made to measure the performance. Typically we measure the performance of \\(\\hat{C}(x)\\) using the misclassification error rate: \\[\nErr_{Te} = Ave_{i\\in Te} I[y_i \\neq \\hat{C} (x_i) ].\n\\] The Bayes classifier (using the true \\(p_k(x)\\)) has smallest error (in the population).\n\n\n\n16.5.6 k-Nearest Neighbor Classification\nConsider k-nearest neighbors in two dimensions. Orange and blue dots label the true class memberships of the underlying points in the 2-dim plane. Dotted line is the decision boundary, that is the contour with equal probability for both classes.\nNearest-neighbor averaging in 2-dim. At any given point we want to classify, we spread out a little neighborhood, say \\(K=10\\) points from the neighborhood and calulated the percentage of blue and orange. We assign the color with the highest probability to this point. If this is done for every point in the plane, we obtain the solid black curve as the esitmated decsion boundary.\nWe can use \\(K=1\\). This is the nearest-neighbor classifier. The decision boundary is piecewise linear. Islands occur. Approximation is rather noisy.\n\\(K=100\\) leads to a smooth decision boundary. But gets uninteresting.\n\n\n\n\n\n\nFigure 16.22: K-nearest neighbors in two dimensions. Taken from James et al. (2014)\n\n\n\n\n\n\n\n\n\nFigure 16.23: K-nearest neighbors in two dimensions. Taken from James et al. (2014)\n\n\n\n\n\n\n\n\n\nFigure 16.24: K-nearest neighbors in two dimensions. Taken from James et al. (2014)\n\n\n\n\\(K\\) large means higher bias, so \\(1/K\\) is chosen, because we go from low to high complexity on the \\(x\\)-error, see Figure 16.25. Horizontal dotted line is the base error.\n\n\n\n\n\n\nFigure 16.25: K-nearest neighbors classification error. Taken from James et al. (2014)\n\n\n\n\n\n16.5.7 Minkowski Distance\nThe Minkowski distance of order \\(p\\) (where \\(p\\) is an integer) between two points \\(X=(x_1,x_2,\\ldots,x_n)\\text{ and }Y=(y_1,y_2,\\ldots,y_n) \\in \\mathbb{R}^n\\) is defined as: \\[\nD \\left( X,Y \\right) = \\left( \\sum_{i=1}^n |x_i-y_i|^p \\right)^\\frac{1}{p}.\n\\]\n\n\n16.5.8 Unsuperivsed Learning: Classification\n\n16.5.8.1 k-Means Algorithm\nThe \\(k\\)-means algorithm is an unsupervised learning algorithm that has a loose relationship to the \\(k\\)-nearest neighbor classifier. The \\(k\\)-means algorithm works as follows:\n\nStep 1: Randomly choose \\(k\\) centers. Assign points to cluster.\nStep 2: Determine the distances of each data point to the centroids and re-assign each point to the closest cluster centroid based upon minimum distance\nStep 3: Calculate cluster centroids again\nStep 4: Repeat steps 2 and 3 until we reach global optima where no improvements are possible and no switching of data points from one cluster to other.\n\nThe basic principle of the \\(k\\)-means algorithm is illustrated in Figure 16.26, Figure 16.27, Figure 16.28, and Figure 16.29.\n\n\n\n\n\n\nFigure 16.26: k-means algorithm. Step 1. Randomly choose \\(k\\) centers. Assign points to cluster. \\(k\\) initial means(in this case \\(k=3\\)) are randomly generated within the data domain (shown in color). Attribution: I, Weston.pace, CC BY-SA 3.0 http://creativecommons.org/licenses/by-sa/3.0/, via Wikimedia Commons\n\n\n\n\n\n\n\n\n\nFigure 16.27: k-means algorithm. Step 2. \\(k\\) clusters are created by associating every observation with the nearest mean. The partitions here represent the Voronoi diagram generated by the means. Attribution: I, Weston.pace, CC BY-SA 3.0 http://creativecommons.org/licenses/by-sa/3.0/, via Wikimedia Commons\n\n\n\n\n\n\n\n\n\nFigure 16.28: k-means algorithm. Step 3. The centroid of each of the \\(k\\) clusters becomes the new mean. Attribution: I, Weston.pace, CC BY-SA 3.0 http://creativecommons.org/licenses/by-sa/3.0/, via Wikimedia Commons\n\n\n\n\n\n\n\n\n\nFigure 16.29: k-means algorithm. Step 4. Steps 2 and 3 are repeated until convergence has been reached. Attribution: I, Weston.pace, CC BY-SA 3.0 http://creativecommons.org/licenses/by-sa/3.0/, via Wikimedia Commons\n\n\n\n\n\n\n\nChollet, Francoise, and J. J. Allaire. 2018. Deep Learning with Python. Manning.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2014. An Introduction to Statistical Learning with Applications in R. 7th ed. Springer.",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Data-Driven Modeling and Optimization</span>"
    ]
  },
  {
    "objectID": "200_mlai.html",
    "href": "200_mlai.html",
    "title": "17  Machine Learning and Artificial Intelligence",
    "section": "",
    "text": "17.1 Jupyter Notebooks",
    "crumbs": [
      "Machine Learning and AI",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Machine Learning and Artificial Intelligence</span>"
    ]
  },
  {
    "objectID": "200_mlai.html#jupyter-notebooks",
    "href": "200_mlai.html#jupyter-notebooks",
    "title": "17  Machine Learning and Artificial Intelligence",
    "section": "",
    "text": "The Jupyter-Notebook version of this file can be found here: malai.ipynb",
    "crumbs": [
      "Machine Learning and AI",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Machine Learning and Artificial Intelligence</span>"
    ]
  },
  {
    "objectID": "200_mlai.html#videos",
    "href": "200_mlai.html#videos",
    "title": "17  Machine Learning and Artificial Intelligence",
    "section": "17.2 Videos",
    "text": "17.2 Videos\n\n17.2.1 June, 11th 2024\n\nHappy Halloween (Neural Networks Are Not Scary)\nThe Essential Main Ideas of Neural Networks\n\n\n\n17.2.2 June, 18th 2024\n\nThe Chain Rule\nGradient Descent, Step-by-Step\nNeural Networks Pt. 2: Backpropagation Main Ideas\n\n\n17.2.2.1 Gradient Descent\n\nExercise 17.1 (GradDescStepSize) How is the step size calculated?\n\n\nExercise 17.2 (GradDescIntercept) How to calculate the new intercept?\n\n\nExercise 17.3 (GradDescIntercept) When does the gradient descend stop?\n\n\n\n17.2.2.2 Backpropagation\n\nExercise 17.4 (ChainRuleAndGradientDescent) What are the key components involved in backpropagation?\n\n\nExercise 17.5 (BackpropagationNaming) Why is it called backpropagation?\n\n\n\n17.2.2.3 ReLU\n\nExercise 17.6 (Graph ReLU) Draw the graph of a ReLU function.\n\n\nBackpropagation Details Pt. 1: Optimizing 3 parameters simultaneously.\nBackpropagation Details Pt. 2: Going bonkers with The Chain Rule\nNeural Networks Pt. 3: ReLU In Action!!!\nNeural Networks Pt. 4: Multiple Inputs and Outputs\nNeural Networks Part 5: ArgMax and SoftMax\nTensors for Neural Networks, Clearly Explained!!!\nEssential Matrix Algebra for Neural Networks, Clearly Explained!!!\nThe StatQuest Introduction to PyTorch\n\n\n\n17.2.2.4 PyTorch Links\n\nStatQuest: Introduction to Coding Neural Networks with PyTorch\nML-AI Pytorch Introduction\n\n\n\n\n17.2.3 June, 25th 2024\n\n\n17.2.4 CNNs\n\n17.2.4.1 Neural Networks Part 8: Image Classification with Convolutional Neural Networks (CNNs)\n\nExercise 17.7 (CNNImageRecognition) Why are classical neural networks poor at image recognition?\n\n\nExercise 17.8 (CNNFiltersInitialization) How are the filter values in CNNs initialized and optimized?\n\n\nExercise 17.9 (CNNFilterInitialization) How are the filter values determined in Convolutional Neural Networks (CNNs)?\n\n\nExercise 17.10 (GenNNStockPrediction) What is a limitation of using classical neural networks for stock market prediction?\n\n\n\n\n17.2.5 RNN\n\n17.2.5.1 Recurrent Neural Networks (RNNs), Clearly Explained!!!\n\nExercise 17.11 (RNNUnrolling) How does the unrolling process work in Recurrent Neural Networks (RNNs)?\n\n\nExercise 17.12 (RNNReliability) Why do Recurrent Neural Networks (RNNs) sometimes fail to work reliably?\n\n\n\n\n17.2.6 LSTM\n\n17.2.6.1 Long Short-Term Memory (LSTM), Clearly Explained\n\nExercise 17.13 (LSTMSigmoidTanh) What are the differences between the sigmoid and tanh activation functions?\n\n\nExercise 17.14 (LSTMSigmoidTanh) What is the ?\n\n\nExercise 17.15 (LSTMGates) What are the gates in an LSTM network and their functions?\n\n\nExercise 17.16 (LSTMLongTermInfo) In which gate is long-term information used in an LSTM network?\n\n\nExercise 17.17 (LSTMUpdateGates) In which Gates is it updated in an LSTM?\n\n\n\n\n17.2.7 Pytorch/Lightning\n\n17.2.7.1 Introduction to Coding Neural Networks with PyTorch and Lightning\n\nExercise 17.18 (PyTorchRequiresGrad) What does requires_grad mean in PyTorch?\n\n\n\n\n17.2.8 July, 2nd 2024\n\nWord Embedding and Word2Vec, Clearly Explained!!!\nSequence-to-Sequence (seq2seq) Encoder-Decoder Neural Networks, Clearly Explained!!!\nAttention for Neural Networks, Clearly Explained!!!\n\n\n17.2.8.1 Embeddings\n\nExercise 17.19 (NN Strings) Can neural networks process strings?\n\n\nExercise 17.20 (Embedding Definition) What is the meaning of word embedding?\n\n\nExercise 17.21 (Embedding Dimensions) Why do we need high dimension in word embedding?\n\n\n\n17.2.8.2 Sequence to Sequence\n\nExercise 17.22 (LSTM) Why are LSTMs used?\n\n\nExercise 17.23 (Teacher Forcing) Why is teacher forcing used?\n\n\nExercise 17.24 (Attention) What is the idea of attention?\n\n\n\n\n17.2.9 Additional Lecture (July, 9th 2024)?\n\nTransformer Neural Networks, ChatGPT’s foundation, Clearly Explained!!!\nDecoder-Only Transformers, ChatGPTs specific Transformer, Clearly Explained!!!\nThe matrix math behind transformer neural networks, one step at a time!!!\nWord Embedding in PyTorch + Lightning\n\n\n17.2.9.1 Transformers\n\nExercise 17.25 (ChatGPT) What kind of transformer does ChatGPT use?\n\n\nExercise 17.26 (Translation) What kind of NN are used for translation?\n\n\nExercise 17.27 (Difference Encoder-Decoder and Decoder Only.) What is the encoder-decoder transformer and the decoder only transformer?\n\n\nExercise 17.28 (Weights) How are the weights initialized (a) and trained (b)?\n\n\nExercise 17.29 (Order of Words) How is the word order preserved?\n\n\nExercise 17.30 (Relationship Between Words) How is the relationship between words modeled?\n\n\nExercise 17.31 (Masked Self Attention) What is masked self-attention?\n\n\nExercise 17.32 (Softmax) Why is Softmax used to calculate percentage of similarities?\n\n\nExercise 17.33 (Softmax Output) How is the percentage output of softmax in Transformers used?\n\n\nExercise 17.34 (V´s) What is done with the scaled V´s that we get for each token so far (example: “is”,”what”)?\n\n\nExercise 17.35 (Residual Connections) What are residual connections?\n\n\nExercise 17.36 (Generate Known Word in Sequence) Why do we want to generate the word in the sequence that comes after “what” that we already know? (Example from video)\n\n\nExercise 17.37 (Masked-Self-Attention Values and Bypass) How do we use the two values (“masked-self-attention values + bypass”) which we have for each input? (Example from video: (“What”, ”is”, ”StatQuest”))\n\n\n\n\n17.2.10 Additional Videos\n\nThe SoftMax Derivative, Step-by-Step!!!\nNeural Networks Part 6: Cross Entropy\nNeural Networks Part 7: Cross Entropy Derivatives and Backpropagation\n\n\n\n17.2.11 All Videos in a Playlist\n\nFull Playlist ML-AI",
    "crumbs": [
      "Machine Learning and AI",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Machine Learning and Artificial Intelligence</span>"
    ]
  },
  {
    "objectID": "200_mlai.html#the-statquest-introduction-to-pytorch",
    "href": "200_mlai.html#the-statquest-introduction-to-pytorch",
    "title": "17  Machine Learning and Artificial Intelligence",
    "section": "17.3 The StatQuest Introduction to PyTorch",
    "text": "17.3 The StatQuest Introduction to PyTorch\nThe following code is taken from The StatQuest Introduction to PyTorch. Attribution goes to Josh Starmer, the creator of StatQuest, see Josh Starmer.\n\nimport torch # torch provides basic functions, from setting a random seed (for reproducability) to creating tensors.\nimport torch.nn as nn # torch.nn allows us to create a neural network.\nimport torch.nn.functional as F # nn.functional give us access to the activation and loss functions.\nfrom torch.optim import SGD # optim contains many optimizers. Here, we're using SGD, stochastic gradient descent.\n\nimport matplotlib.pyplot as plt ## matplotlib allows us to draw graphs.\nimport seaborn as sns ## seaborn makes it easier to draw nice-looking graphs.\n\n%matplotlib inline\n\nBuilding a neural network in PyTorch means creating a new class with two methods: init() and forward(). The init() method defines and initializes all of the parameters that we want to use, and the forward() method tells PyTorch what should happen during a forward pass through the neural network.\n\n17.3.1 Build a Simple Neural Network in PyTorch\n__init__() is the class constructor function, and we use it to initialize the weights and biases.\n\n## create a neural network class by creating a class that inherits from nn.Module.\nclass BasicNN(nn.Module):\n\n    def __init__(self): # __init__() is the class constructor function, and we use it to initialize the weights and biases.\n        \n        super().__init__() # initialize an instance of the parent class, nn.Model.\n        \n        ## Now create the weights and biases that we need for our neural network.\n        ## Each weight or bias is an nn.Parameter, which gives us the option to optimize the parameter by setting\n        ## requires_grad, which is short for \"requires gradient\", to True. Since we don't need to optimize any of these\n        ## parameters now, we set requires_grad=False.\n        ##\n        ## NOTE: Because our neural network is already fit to the data, we will input specific values\n        ## for each weight and bias. In contrast, if we had not already fit the neural network to the data,\n        ## we might start with a random initalization of the weights and biases.\n        self.w00 = nn.Parameter(torch.tensor(1.7), requires_grad=False)\n        self.b00 = nn.Parameter(torch.tensor(-0.85), requires_grad=False)\n        self.w01 = nn.Parameter(torch.tensor(-40.8), requires_grad=False)\n        \n        self.w10 = nn.Parameter(torch.tensor(12.6), requires_grad=False)\n        self.b10 = nn.Parameter(torch.tensor(0.0), requires_grad=False)\n        self.w11 = nn.Parameter(torch.tensor(2.7), requires_grad=False)\n\n        self.final_bias = nn.Parameter(torch.tensor(-16.), requires_grad=False)\n        \n        \n    def forward(self, input): ## forward() takes an input value and runs it though the neural network \n                              ## illustrated at the top of this notebook. \n        \n        ## the next three lines implement the top of the neural network (using the top node in the hidden layer).\n        input_to_top_relu = input * self.w00 + self.b00\n        top_relu_output = F.relu(input_to_top_relu)\n        scaled_top_relu_output = top_relu_output * self.w01\n        \n        ## the next three lines implement the bottom of the neural network (using the bottom node in the hidden layer).\n        input_to_bottom_relu = input * self.w10 + self.b10\n        bottom_relu_output = F.relu(input_to_bottom_relu)\n        scaled_bottom_relu_output = bottom_relu_output * self.w11\n        \n        ## here, we combine both the top and bottom nodes from the hidden layer with the final bias.\n        input_to_final_relu = scaled_top_relu_output + scaled_bottom_relu_output + self.final_bias\n        \n        output = F.relu(input_to_final_relu)\n    \n        return output # output is the predicted effectiveness for a drug dose.\n\nOnce we have created the class that defines the neural network, we can create an actual neural network and print out its parameters, just to make sure things are what we expect.\n\n## create the neural network. \nmodel = BasicNN()\n\n## print out the name and value for each parameter\nfor name, param in model.named_parameters():\n    print(name, param.data)\n\nw00 tensor(1.7000)\nb00 tensor(-0.8500)\nw01 tensor(-40.8000)\nw10 tensor(12.6000)\nb10 tensor(0.)\nw11 tensor(2.7000)\nfinal_bias tensor(-16.)\n\n\n\n\n17.3.2 Use the Neural Network and Graph the Output\nNow that we have a neural network, we can use it on a variety of doses to determine which will be effective. Then we can make a graph of these data, and this graph should match the green bent shape fit to the training data that’s shown at the top of this document. So, let’s start by making a sequence of input doses…\n\n## now create the different doses we want to run through the neural network.\n## torch.linspace() creates the sequence of numbers between, and including, 0 and 1.\ninput_doses = torch.linspace(start=0, end=1, steps=11)\n\n# now print out the doses to make sure they are what we expect...\ninput_doses\n\ntensor([0.0000, 0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000,\n        0.9000, 1.0000])\n\n\nNow that we have input_doses, let’s run them through the neural network and graph the output…\n\n## create the neural network. \nmodel = BasicNN() \n\n## now run the different doses through the neural network.\noutput_values = model(input_doses)\n\n## Now draw a graph that shows the effectiveness for each dose.\n##\n## First, set the style for seaborn so that the graph looks cool.\nsns.set(style=\"whitegrid\")\n\n## create the graph (you might not see it at this point, but you will after we save it as a PDF).\nsns.lineplot(x=input_doses, \n     y=output_values, \n     color='green', \n     linewidth=2.5)\n\n## now label the y- and x-axes.\nplt.ylabel('Effectiveness')\nplt.xlabel('Dose')\n\n## optionally, save the graph as a PDF.\n# plt.savefig('BasicNN.pdf')\n\nText(0.5, 0, 'Dose')\n\n\n\n\n\n\n\n\n\nThe graph shows that the neural network fits the training data. In other words, so far, we don’t have any bugs in our code.\n\n\n17.3.3 Optimize (Train) a Parameter in the Neural Network and Graph the Output\nNow that we know how to create and use a simple neural network, and we can graph the output relative to the input, let’s see how to train a neural network. The first thing we need to do is tell PyTorch which parameter (or parameters) we want to train, and we do that by setting requiresgrad=True. In this example, we’ll train finalbias.\nNow we create a neural network by creating a class that inherits from nn.Module.\nNOTE: This code is the same as before, except we changed the class name to BasicNN_train and we modified final_bias in two ways:\n1) we set the value of the tensor to 0, and\n2) we set \"requires_grad=True\".\nNow let’s graph the output of BasicNN_train, which is currently not optimized, and compare it to the graph we drew earlier of the optimized neural network.\n\nclass BasicNN_train(nn.Module):\n\n    def __init__(self): # __init__ is the class constructor function, and we use it to initialize the weights and biases.\n        \n        super().__init__() # initialize an instance of the parent class, nn.Module.\n        \n        self.w00 = nn.Parameter(torch.tensor(1.7), requires_grad=False)\n        self.b00 = nn.Parameter(torch.tensor(-0.85), requires_grad=False)\n        self.w01 = nn.Parameter(torch.tensor(-40.8), requires_grad=False)\n        \n        self.w10 = nn.Parameter(torch.tensor(12.6), requires_grad=False)\n        self.b10 = nn.Parameter(torch.tensor(0.0), requires_grad=False)\n        self.w11 = nn.Parameter(torch.tensor(2.7), requires_grad=False)\n\n        ## we want to modify final_bias to demonstrate how to optimize it with backpropagation.\n        ## The optimal value for final_bias is -16...\n#         self.final_bias = nn.Parameter(torch.tensor(-16.), requires_grad=False)\n        ## ...so we set it to 0 and tell Pytorch that it now needs to calculate the gradient for this parameter.\n        self.final_bias = nn.Parameter(torch.tensor(0.), requires_grad=True) \n        \n    def forward(self, input):\n        \n        input_to_top_relu = input * self.w00 + self.b00\n        top_relu_output = F.relu(input_to_top_relu)\n        scaled_top_relu_output = top_relu_output * self.w01\n        \n        input_to_bottom_relu = input * self.w10 + self.b10\n        bottom_relu_output = F.relu(input_to_bottom_relu)\n        scaled_bottom_relu_output = bottom_relu_output * self.w11\n    \n        input_to_final_relu = scaled_top_relu_output + scaled_bottom_relu_output + self.final_bias\n        \n        output = F.relu(input_to_final_relu)\n        \n        return output\n\n\n## create the neural network. \nmodel = BasicNN_train() \n\n## now run the different doses through the neural network.\noutput_values = model(input_doses)\n\n## Now draw a graph that shows the effectiveness for each dose.\n##\n## set the style for seaborn so that the graph looks cool.\nsns.set(style=\"whitegrid\")\n\n## create the graph (you might not see it at this point, but you will after we save it as a PDF).\nsns.lineplot(x=input_doses, \n             y=output_values.detach(), ## NOTE: because final_bias has a gradident, we call detach() \n                                       ## to return a new tensor that only has the value and not the gradient.\n             color='green', \n             linewidth=2.5)\n\n## now label the y- and x-axes.\nplt.ylabel('Effectiveness')\nplt.xlabel('Dose')\n\n## lastly, save the graph as a PDF.\n# plt.savefig('BasicNN_train.pdf')\n\nText(0.5, 0, 'Dose')\n\n\n\n\n\n\n\n\n\nThe graph shows that when the dose is 0.5, the output from the unoptimized neural network is 17, which is wrong, since the output value should be 1. So, now that we have a parameter we can optimize, let’s create some training data that we can use to optimize it.\n\n## create the training data for the neural network.\ninputs = torch.tensor([0., 0.5, 1.])\nlabels = torch.tensor([0., 1., 0.])\n\n..and now let’s use that training data to train (or optimize) final_bias.\n\n## create the neural network we want to train.\nmodel = BasicNN_train()\n\noptimizer = SGD(model.parameters(), lr=0.1) ## here we're creating an optimizer to train the neural network.\n                                            ## NOTE: There are a bunch of different ways to optimize a neural network.\n                                            ## In this example, we'll use Stochastic Gradient Descent (SGD). However,\n                                            ## another popular algortihm is Adam (which will be covered in a StatQuest).\n\nprint(\"Final bias, before optimization: \" + str(model.final_bias.data) + \"\\n\")\n\n## this is the optimization loop. Each time the optimizer sees all of the training data is called an \"epoch\".\nfor epoch in range(100):\n\n    ## we create and initialize total_loss for each epoch so that we can evaluate how well model fits the\n    ## training data. At first, when the model doesn't fit the training data very well, total_loss\n    ## will be large. However, as gradient descent improves the fit, total_loss will get smaller and smaller.\n    ## If total_loss gets really small, we can decide that the model fits the data well enough and stop\n    ## optimizing the fit. Otherwise, we can just keep optimizing until we reach the maximum number of epochs. \n    total_loss = 0\n\n    ## this internal loop is where the optimizer sees all of the training data and where we \n    ## calculate the total_loss for all of the training data.\n    for iteration in range(len(inputs)):\n\n        input_i = inputs[iteration] ## extract a single input value (a single dose)...\n        label_i = labels[iteration] ## ...and its corresponding label (the effectiveness for the dose).\n\n        output_i = model(input_i) ## calculate the neural network output for the input (the single dose).\n\n        loss = (output_i - label_i)**2 ## calculate the loss for the single value.\n                                       ## NOTE: Because output_i = model(input_i), \"loss\" has a connection to \"model\"\n                                       ## and the derivative (calculated in the next step) is kept and accumulated\n                                       ## in \"model\".\n\n        loss.backward() # backward() calculates the derivative for that single value and adds it to the previous one.\n\n        total_loss += float(loss) # accumulate the total loss for this epoch.\n\n\n    if (total_loss &lt; 0.0001):\n        print(\"Num steps: \" + str(epoch))\n        break\n\n    optimizer.step() ## take a step toward the optimal value.\n    optimizer.zero_grad() ## This zeroes out the gradient stored in \"model\". \n                          ## Remember, by default, gradients are added to the previous step (the gradients are accumulated),\n                          ## and we took advantage of this process to calculate the derivative one data point at a time.\n                          ## NOTE: \"optimizer\" has access to \"model\" because of how it was created with the call \n                          ## (made earlier): optimizer = SGD(model.parameters(), lr=0.1).\n                          ## ALSO NOTE: Alternatively, we can zero out the gradient with model.zero_grad().\n    if epoch % 10 == 0:\n        print(\"Step: \" + str(epoch) + \" Final Bias: \" + str(model.final_bias.data) + \"\\n\")\n    ## now go back to the start of the loop and go through another epoch.\n\nprint(\"Total loss: \" + str(total_loss))\nprint(\"Final bias, after optimization: \" + str(model.final_bias.data))\n\nFinal bias, before optimization: tensor(0.)\n\nStep: 0 Final Bias: tensor(-3.2020)\n\nStep: 10 Final Bias: tensor(-14.6348)\n\nStep: 20 Final Bias: tensor(-15.8623)\n\nStep: 30 Final Bias: tensor(-15.9941)\n\nNum steps: 34\nTotal loss: 6.58966600894928e-05\nFinal bias, after optimization: tensor(-16.0019)\n\n\nSo, if everything worked correctly, the optimizer should have converged on final_bias = 16.0019 after 34 steps, or epochs. BAM!\nLastly, let’s graph the output from the optimized neural network and see if it’s the same as what we started with. If so, then the optimization worked.\n\n## run the different doses through the neural network\noutput_values = model(input_doses)\n\n## set the style for seaborn so that the graph looks cool.\nsns.set(style=\"whitegrid\")\n\n## create the graph (you might not see it at this point, but you will after we save it as a PDF).\nsns.lineplot(x=input_doses, \n     y=output_values.detach(), ## NOTE: we call detach() because final_bias has a gradient\n     color='green', \n     linewidth=2.5)\n\n## now label the y- and x-axes.\nplt.ylabel('Effectiveness')\nplt.xlabel('Dose')\n\n## lastly, save the graph as a PDF.\n# plt.savefig('BascNN_optimized.pdf')\n\nText(0.5, 0, 'Dose')\n\n\n\n\n\n\n\n\n\nAnd we see that the optimized model results in the same graph that we started with, so the optimization worked as expected.",
    "crumbs": [
      "Machine Learning and AI",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Machine Learning and Artificial Intelligence</span>"
    ]
  },
  {
    "objectID": "200_mlai.html#build-a-long-short-term-memory-unit-by-hand-using-pytorch-lightning",
    "href": "200_mlai.html#build-a-long-short-term-memory-unit-by-hand-using-pytorch-lightning",
    "title": "17  Machine Learning and Artificial Intelligence",
    "section": "17.4 Build a Long Short-Term Memory unit by hand using PyTorch + Lightning",
    "text": "17.4 Build a Long Short-Term Memory unit by hand using PyTorch + Lightning\nThe following code is based on Long Short-Term Memory with PyTorch + Lightning and StatQuest: Long Short-Term Memory (LSTM) with PyTorch + Lightning!!!. Attribution goes to Josh Starmer, the creator of StatQuest, see Josh Starmer.\n\nimport torch # torch will allow us to create tensors.\nimport torch.nn as nn # torch.nn allows us to create a neural network.\nimport torch.nn.functional as F # nn.functional give us access to the activation and loss functions.\nfrom torch.optim import Adam # optim contains many optimizers. This time we're using Adam\n\nimport lightning as L # lightning has tons of cool tools that make neural networks easier\nfrom torch.utils.data import TensorDataset, DataLoader # these are needed for the training data\n\nA Long Short-Term Memory (LSTM) unit is a type of neural network, and that means we need to create a new class. To make it easy to train the LSTM, this class will inherit from LightningModule and we’ll create the following methods:\n\ninit() to initialize the Weights and Biases and keep track of a few other house keeping things.\nlstm_unit() to do the LSTM math. For example, to calculate the percentage of the long-term memory to remember.\nforward() to make a forward pass through the unrolled LSTM. In other words forward() calls lstm_unit() for each data point.\nconfigure_optimizers() to configure the opimimizer. In the past, we have use SGD (Stochastic Gradient Descent), however, in this tutorial we’ll change things up and use Adam, another popular algorithm for optimizing the Weights and Biases.\ntraining_step() to pass the training data to forward(), calculate the loss and to keep track of the loss values in a log file.\n\n\nclass LSTMbyHand(L.LightningModule):\n\n    def __init__(self):\n        super().__init__()\n        L.seed_everything(seed=42)\n\n        ## NOTE: nn.LSTM() uses random values from a uniform distribution to initialize the tensors\n        ## Here we can do it 2 different ways 1) Normal Distribution and 2) Uniform Distribution\n        ## We'll start with the Normal distribution.\n        mean = torch.tensor(0.0)\n        std = torch.tensor(1.0)\n\n        ## NOTE: In this case, I'm only using the normal distribution for the Weights.\n        ## All Biases are initialized to 0.\n        ##\n        ## These are the Weights and Biases in the first stage, which determines what percentage\n        ## of the long-term memory the LSTM unit will remember.\n        self.wlr1 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n        self.wlr2 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n        self.blr1 = nn.Parameter(torch.tensor(0.), requires_grad=True)\n\n        ## These are the Weights and Biases in the second stage, which determines the new\n        ## potential long-term memory and what percentage will be remembered.\n        self.wpr1 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n        self.wpr2 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n        self.bpr1 = nn.Parameter(torch.tensor(0.), requires_grad=True)\n\n        self.wp1 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n        self.wp2 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n        self.bp1 = nn.Parameter(torch.tensor(0.), requires_grad=True)\n\n        ## These are the Weights and Biases in the third stage, which determines the\n        ## new short-term memory and what percentage will be sent to the output.\n        self.wo1 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n        self.wo2 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n        self.bo1 = nn.Parameter(torch.tensor(0.), requires_grad=True)\n\n        ## We can also initialize all Weights and Biases using a uniform distribution. This is\n        ## how nn.LSTM() does it.\n#         self.wlr1 = nn.Parameter(torch.rand(1), requires_grad=True)\n#         self.wlr2 = nn.Parameter(torch.rand(1), requires_grad=True)\n#         self.blr1 = nn.Parameter(torch.rand(1), requires_grad=True)\n\n#         self.wpr1 = nn.Parameter(torch.rand(1), requires_grad=True)\n#         self.wpr2 = nn.Parameter(torch.rand(1), requires_grad=True)\n#         self.bpr1 = nn.Parameter(torch.rand(1), requires_grad=True)\n\n#         self.wp1 = nn.Parameter(torch.rand(1), requires_grad=True)\n#         self.wp2 = nn.Parameter(torch.rand(1), requires_grad=True)\n#         self.bp1 = nn.Parameter(torch.rand(1), requires_grad=True)\n\n#         self.wo1 = nn.Parameter(torch.rand(1), requires_grad=True)\n#         self.wo2 = nn.Parameter(torch.rand(1), requires_grad=True)\n#         self.bo1 = nn.Parameter(torch.rand(1), requires_grad=True)\n\n\n    def lstm_unit(self, input_value, long_memory, short_memory):\n        ## lstm_unit does the math for a single LSTM unit.\n\n        ## NOTES:\n        ## long term memory is also called \"cell state\"\n        ## short term memory is also called \"hidden state\"\n\n        ## 1) The first stage determines what percent of the current long-term memory\n        ##    should be remembered\n        long_remember_percent = torch.sigmoid((short_memory * self.wlr1) +\n                                              (input_value * self.wlr2) +\n                                              self.blr1)\n\n        ## 2) The second stage creates a new, potential long-term memory and determines what\n        ##    percentage of that to add to the current long-term memory\n        potential_remember_percent = torch.sigmoid((short_memory * self.wpr1) +\n                                                   (input_value * self.wpr2) +\n                                                   self.bpr1)\n        potential_memory = torch.tanh((short_memory * self.wp1) +\n                                      (input_value * self.wp2) +\n                                      self.bp1)\n\n        ## Once we have gone through the first two stages, we can update the long-term memory\n        updated_long_memory = ((long_memory * long_remember_percent) +\n                       (potential_remember_percent * potential_memory))\n\n        ## 3) The third stage creates a new, potential short-term memory and determines what\n        ##    percentage of that should be remembered and used as output.\n        output_percent = torch.sigmoid((short_memory * self.wo1) +\n                                       (input_value * self.wo2) +\n                                       self.bo1)\n        updated_short_memory = torch.tanh(updated_long_memory) * output_percent\n\n        ## Finally, we return the updated long and short-term memories\n        return([updated_long_memory, updated_short_memory])\n\n    def forward(self, input):\n        ## forward() unrolls the LSTM for the training data by calling lstm_unit() for each day of training data\n        ## that we have. forward() also keeps track of the long and short-term memories after each day and returns\n        ## the final short-term memory, which is the 'output' of the LSTM.\n\n        long_memory = 0 # long term memory is also called \"cell state\" and indexed with c0, c1, ..., cN\n        short_memory = 0 # short term memory is also called \"hidden state\" and indexed with h0, h1, ..., cN\n        day1 = input[0]\n        day2 = input[1]\n        day3 = input[2]\n        day4 = input[3]\n\n        ## Day 1\n        long_memory, short_memory = self.lstm_unit(day1, long_memory, short_memory)\n\n        ## Day 2\n        long_memory, short_memory = self.lstm_unit(day2, long_memory, short_memory)\n\n        ## Day 3\n        long_memory, short_memory = self.lstm_unit(day3, long_memory, short_memory)\n\n        ## Day 4\n        long_memory, short_memory = self.lstm_unit(day4, long_memory, short_memory)\n\n        ##### Now return short_memory, which is the 'output' of the LSTM.\n        return short_memory\n\n    def configure_optimizers(self): # this configures the optimizer we want to use for backpropagation.\n        # return Adam(self.parameters(), lr=0.1) # NOTE: Setting the learning rate to 0.1 trains way faster than\n                                                 # using the default learning rate, lr=0.001, which requires a lot more\n                                                 # training. However, if we use the default value, we get\n                                                 # the exact same Weights and Biases that I used in\n                                                 # the LSTM Clearly Explained StatQuest video. So we'll use the\n                                                 # default value.\n        return Adam(self.parameters())\n\n\n    def training_step(self, batch, batch_idx): # take a step during gradient descent.\n        input_i, label_i = batch # collect input\n        output_i = self.forward(input_i[0]) # run input through the neural network\n        loss = (output_i - label_i)**2 ## loss = sum of squared residual\n        # Logging the loss and the predicted values so we can evaluate the training:\n        self.log(\"train_loss\", loss)\n        ## NOTE: Our dataset consists of two sequences of values representing Company A and Company B\n        ## For Company A, the goal is to predict that the value on Day 5 = 0, and for Company B,\n        ## the goal is to predict that the value on Day 5 = 1. We use label_i, the value we want to\n        ## predict, to keep track of which company we just made a prediction for and\n        ## log that output value in a company specific file\n        if (label_i == 0):\n            self.log(\"out_0\", output_i)\n        else:\n            self.log(\"out_1\", output_i)\n        return loss\n\nOnce we have created the class that defines an LSTM, we can use it to create a model and print out the randomly initialized Weights and Biases. Then, just for fun, we’ll see what those random Weights and Biases predict for Company A and Company B. If they are good predictions, then we’re done! However, the chances of getting good predictions from random values is very small.\n\n## Create the model object, print out parameters and see how well\n## the untrained LSTM can make predictions...\nmodel = LSTMbyHand() \n\nprint(\"Before optimization, the parameters are...\")\nfor name, param in model.named_parameters():\n    print(name, param.data)\n\nprint(\"\\nNow let's compare the observed and predicted values...\")\n## NOTE: To make predictions, we pass in the first 4 days worth of stock values \n## in an array for each company. In this case, the only difference between the\n## input values for Company A and B occurs on the first day. Company A has 0 and\n## Company B has 1.\nprint(\"Company A: Observed = 0, Predicted =\", \n      model(torch.tensor([0., 0.5, 0.25, 1.])).detach())\nprint(\"Company B: Observed = 1, Predicted =\", \n      model(torch.tensor([1., 0.5, 0.25, 1.])).detach())\n\nBefore optimization, the parameters are...\nwlr1 tensor(0.3367)\nwlr2 tensor(0.1288)\nblr1 tensor(0.)\nwpr1 tensor(0.2345)\nwpr2 tensor(0.2303)\nbpr1 tensor(0.)\nwp1 tensor(-1.1229)\nwp2 tensor(-0.1863)\nbp1 tensor(0.)\nwo1 tensor(2.2082)\nwo2 tensor(-0.6380)\nbo1 tensor(0.)\n\nNow let's compare the observed and predicted values...\nCompany A: Observed = 0, Predicted = tensor(-0.0377)\nCompany B: Observed = 1, Predicted = tensor(-0.0383)\n\n\nWith the unoptimized paramters, the predicted value for Company A, -0.0377, isn’t terrible, since it is relatively close to the observed value, 0. However, the predicted value for Company B, -0.0383, is terrible, because it is relatively far from the observed value, 1. So, that means we need to train the LSTM.\n\n17.4.1 Train the LSTM unit and use Lightning and TensorBoard to evaluate: Part 1 - Getting Started\nSince we are using Lightning training, training the LSTM we created by hand is pretty easy. All we have to do is create the training data and put it into a DataLoader…\n\n## create the training data for the neural network.\ninputs = torch.tensor([[0., 0.5, 0.25, 1.], [1., 0.5, 0.25, 1.]])\nlabels = torch.tensor([0., 1.])\n\ndataset = TensorDataset(inputs, labels)\ndataloader = DataLoader(dataset)\n\n# show the training data\nfor i, (input_i, label_i) in enumerate(dataloader):\n    print(\"Training data: \", input_i, label_i)\n\nTraining data:  tensor([[0.0000, 0.5000, 0.2500, 1.0000]]) tensor([0.])\nTraining data:  tensor([[1.0000, 0.5000, 0.2500, 1.0000]]) tensor([1.])\n\n\n…and then create a Lightning Trainer, L.Trainer, and fit it to the training data. NOTE: We are starting with 2000 epochs. This may be enough to successfully optimize all of the parameters, but it might not. We’ll find out after we compare the predictions to the observed values.\n\ntrainer = L.Trainer(max_epochs=2000) # with default learning rate, 0.001 (this tiny learning rate makes learning slow)\ntrainer.fit(model, train_dataloaders=dataloader)\n\n\n\n\nNow that we’ve trained the model with 2000 epochs, we can see how good the predictions are…\n\nprint(\"\\nNow let's compare the observed and predicted values...\")\nprint(\"Company A: Observed = 0, Predicted =\", model(torch.tensor([0., 0.5, 0.25, 1.])).detach())\nprint(\"Company B: Observed = 1, Predicted =\", model(torch.tensor([1., 0.5, 0.25, 1.])).detach())\n\n\nNow let's compare the observed and predicted values...\nCompany A: Observed = 0, Predicted = tensor(0.4342)\nCompany B: Observed = 1, Predicted = tensor(0.6171)\n\n\nUnfortunately, these predictions are terrible. So it seems like we’ll have to do more training. However, it would be awesome if we could be confident that more training will actually improve the predictions. If not, we can spare ourselves a lot of time, and potentially money, and just give up. So, before we dive into more training, let’s look at the loss values and predictions that we saved in log files with TensorBoard. TensorBoard will graph everything that we logged during training, making it super easy to see if things are headed in the right direction or not.\nTo get TensorBoard working:\n\nFirst, check to see if the TensorBoard plugin is installed. If it’s not, install it with the following command: pip install tensorboard\nNext, run the following command: tensorboard --logdir lightning_logs\n\nNOTE: If your graphs look messed up and you see a bunch of different lines, instead of just one red line per graph, then check where this notebook is saved for a directory called lightning_logs. Delete lightning_logs and the re-run everything in this notebook. One source of problems with the graphs is that every time we train a model, a new batch of log files is created and stored in lightning_logs and TensorBoard, by default, will plot all of them. You can turn off unwanted log files in TensorBoard, and we’ll do this later on in this notebook, but for now, the easiest thing to do is to start with a clean slate.\nAnyway, if we look at the loss (trainloss), we see that it is going down, which is good, but it still has further to go. When we look at the predictions for Company A (out0), we see that they started out pretty good, close to 0, but then got really bad early on in training, shooting all the way up to 0.5, but are starting to get smaller. In contrast, when we look at the predictions for Company B (out_1), we see that they started out really bad, close to 0, but have been getting better ever since and look like they could continue to get better if we kept training.\nIn summary, the graphs seem to suggest that if we continued training our model, the predictions would improve. So let’s add more epochs to the training.\n\n\n17.4.2 Optimizing (Training) the Weights and Biases in the LSTM that we made by hand: Part 2 - Adding More Epochs without Starting Over\nThe good news is that because we’re using Lightning, we can pick up where we left off training without having to start over from scratch. This is because when we train with Lightning, it creates checkpoint files that keep track of the Weights and Biases as they change. As a result, all we have to do to pick up where we left off is tell the Trainer where the checkpoint files are located. This is awesome and will save us a lot of time since we don’t have to retrain the first 2000 epochs. So let’s add an additional 1000 epochs to the training.\n\n## First, find where the most recent checkpoint files are stored\npath_to_checkpoint = trainer.checkpoint_callback.best_model_path ## By default, \"best\" = \"most recent\"\nprint(\"The new trainer will start where the last left off, and the check point data is here: \" + \n      path_to_checkpoint + \"\\n\")\n\n## Then create a new Lightning Trainer\ntrainer = L.Trainer(max_epochs=3000) # Before, max_epochs=2000, so, by setting it to 3000, we're adding 1000 more.\n## And then call fit() using the path to the most recent checkpoint files\n## so that we can pick up where we left off.\ntrainer.fit(model, train_dataloaders=dataloader, ckpt_path=path_to_checkpoint)\n\nThe new trainer will start where the last left off, and the check point data is here: /Users/bartz/workspace/Hyperparameter-Tuning-Cookbook/lightning_logs/version_144/checkpoints/epoch=1999-step=4000.ckpt\n\n\n\n\n\n\nNow that we have added 1000 epochs to the training, let’s check the predictions…\n\nprint(\"\\nNow let's compare the observed and predicted values...\")\nprint(\"Company A: Observed = 0, Predicted =\", model(torch.tensor([0., 0.5, 0.25, 1.])).detach())\nprint(\"Company B: Observed = 1, Predicted =\", model(torch.tensor([1., 0.5, 0.25, 1.])).detach())\n\n\nNow let's compare the observed and predicted values...\nCompany A: Observed = 0, Predicted = tensor(0.2708)\nCompany B: Observed = 1, Predicted = tensor(0.7534)\n\n\nThe blue lines in each graph represents the values we logged during the extra 1000 epochs. The loss is getting smaller and the predictions for both companies are improving! Hooray!!! However, because it looks like there is even more room for improvement, let’s add 2000 more epochs to the training.\n\n## First, find where the most recent checkpoint files are stored\npath_to_checkpoint = trainer.checkpoint_callback.best_model_path ## By default, \"best\" = \"most recent\"\nprint(\"The new trainer will start where the last left off, and the check point data is here: \" + \n      path_to_checkpoint + \"\\n\")\n\n## Then create a new Lightning Trainer\ntrainer = L.Trainer(max_epochs=5000) # Before, max_epochs=3000, so, by setting it to 5000, we're adding 2000 more.\n## And then call fit() using the path to the most recent checkpoint files\n## so that we can pick up where we left off.\ntrainer.fit(model, train_dataloaders=dataloader, ckpt_path=path_to_checkpoint)\n\nThe new trainer will start where the last left off, and the check point data is here: /Users/bartz/workspace/Hyperparameter-Tuning-Cookbook/lightning_logs/version_145/checkpoints/epoch=2999-step=6000.ckpt\n\n\n\n\n\n\nNow that we have added 2000 more epochs to the training (for a total of 5000 epochs), let’s check the predictions.\n\nprint(\"\\nNow let's compare the observed and predicted values...\")\nprint(\"Company A: Observed = 0, Predicted =\", model(torch.tensor([0., 0.5, 0.25, 1.])).detach())\nprint(\"Company B: Observed = 1, Predicted =\", model(torch.tensor([1., 0.5, 0.25, 1.])).detach())\n\n\nNow let's compare the observed and predicted values...\nCompany A: Observed = 0, Predicted = tensor(0.0022)\nCompany B: Observed = 1, Predicted = tensor(0.9693)\n\n\nThe prediction for Company A is super close to 0, which is exactly what we want, and the prediction for Company B is close to 1, which is also what we want.\nThe dark red lines show how things changed when we added an additional 2000 epochs to the training, for a total of 5000 epochs. Now we see that the loss (train_loss) and the predictions for each company appear to be tapering off, suggesting that adding more epochs may not improve the predictions much, so we’re done!\nLastly, let’s print out the final estimates for the Weights and Biases. In theory, they should be the same (within rounding error) as what we used in the StatQuest on Long Short-Term Memory and seen in the diagram of the LSTM unit at the top of this Jupyter notebook.\n\nprint(\"After optimization, the parameters are...\")\nfor name, param in model.named_parameters():\n    print(name, param.data)\n\nAfter optimization, the parameters are...\nwlr1 tensor(2.7043)\nwlr2 tensor(1.6307)\nblr1 tensor(1.6234)\nwpr1 tensor(1.9983)\nwpr2 tensor(1.6525)\nbpr1 tensor(0.6204)\nwp1 tensor(1.4122)\nwp2 tensor(0.9393)\nbp1 tensor(-0.3217)\nwo1 tensor(4.3848)\nwo2 tensor(-0.1943)\nbo1 tensor(0.5935)",
    "crumbs": [
      "Machine Learning and AI",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Machine Learning and Artificial Intelligence</span>"
    ]
  },
  {
    "objectID": "200_mlai.html#using-and-optimzing-the-pytorch-lstm-nn.lstm",
    "href": "200_mlai.html#using-and-optimzing-the-pytorch-lstm-nn.lstm",
    "title": "17  Machine Learning and Artificial Intelligence",
    "section": "17.5 Using and optimzing the PyTorch LSTM, nn.LSTM()",
    "text": "17.5 Using and optimzing the PyTorch LSTM, nn.LSTM()\nNow that we know how to create an LSTM unit by hand, train it, and then use it to make good predictions, let’s learn how to take advantage of PyTorch’s nn.LSTM() function. For the most part, using nn.LSTM() allows us to simplify the init() function and the forward() function. The other big difference is that this time, we’re not going to try and recreate the parameter values we used in the StatQuest on Long Short-Term Memory, and that means we can set the learning rate for the Adam to 0.1. This will speed up training a lot. Everything else stays the same.\n\n## Instead of coding an LSTM by hand, let's see what we can do with PyTorch's nn.LSTM()\nclass LightningLSTM(L.LightningModule):\n\n    def __init__(self): # __init__() is the class constructor function, and we use it to initialize the Weights and Biases.\n\n        super().__init__() # initialize an instance of the parent class, LightningModule.\n\n        L.seed_everything(seed=42)\n\n        ## input_size = number of features (or variables) in the data. In our example\n        ##              we only have a single feature (value)\n        ## hidden_size = this determines the dimension of the output\n        ##               in other words, if we set hidden_size=1, then we have 1 output node\n        ##               if we set hidden_size=50, then we hve 50 output nodes (that can then be 50 input\n        ##               nodes to a subsequent fully connected neural network.\n        self.lstm = nn.LSTM(input_size=1, hidden_size=1)\n\n\n    def forward(self, input):\n        ## transpose the input vector\n        input_trans = input.view(len(input), 1)\n\n        lstm_out, temp = self.lstm(input_trans)\n\n        ## lstm_out has the short-term memories for all inputs. We make our prediction with the last one\n        prediction = lstm_out[-1]\n        return prediction\n\n\n    def configure_optimizers(self): # this configures the optimizer we want to use for backpropagation.\n        return Adam(self.parameters(), lr=0.1) ## we'll just go ahead and set the learning rate to 0.1\n\n\n    def training_step(self, batch, batch_idx): # take a step during gradient descent.\n        input_i, label_i = batch # collect input\n        output_i = self.forward(input_i[0]) # run input through the neural network\n        loss = (output_i - label_i)**2 ## loss = squared residual\n        self.log(\"train_loss\", loss)\n\n        if (label_i == 0):\n            self.log(\"out_0\", output_i)\n        else:\n            self.log(\"out_1\", output_i)\n\n        return loss\n\nNow let’s create the model and print out the initial Weights and Biases and predictions.\n\nmodel = LightningLSTM() # First, make model from the class\n\n## print out the name and value for each parameter\nprint(\"Before optimization, the parameters are...\")\nfor name, param in model.named_parameters():\n    print(name, param.data)\n\nprint(\"\\nNow let's compare the observed and predicted values...\")\nprint(\"Company A: Observed = 0, Predicted =\", model(torch.tensor([0., 0.5, 0.25, 1.])).detach())\nprint(\"Company B: Observed = 1, Predicted =\", model(torch.tensor([1., 0.5, 0.25, 1.])).detach())\n\nBefore optimization, the parameters are...\nlstm.weight_ih_l0 tensor([[ 0.7645],\n        [ 0.8300],\n        [-0.2343],\n        [ 0.9186]])\nlstm.weight_hh_l0 tensor([[-0.2191],\n        [ 0.2018],\n        [-0.4869],\n        [ 0.5873]])\nlstm.bias_ih_l0 tensor([ 0.8815, -0.7336,  0.8692,  0.1872])\nlstm.bias_hh_l0 tensor([ 0.7388,  0.1354,  0.4822, -0.1412])\n\nNow let's compare the observed and predicted values...\nCompany A: Observed = 0, Predicted = tensor([0.6675])\nCompany B: Observed = 1, Predicted = tensor([0.6665])\n\n\nAs expected, the predictions are bad, so we will train the model. However, because we’ve increased the learning rate to 0.1, we only need to train for 300 epochs.\n\n## NOTE: Because we have set Adam's learning rate to 0.1, we will train much, much faster.\n## Before, with the hand made LSTM and the default learning rate, 0.001, it took about 5000 epochs to fully train\n## the model. Now, with the learning rate set to 0.1, we only need 300 epochs. Now, because we are doing so few epochs,\n## we have to tell the trainer add stuff to the log files every 2 steps (or epoch, since we have to rows of training data)\n## because the default, updating the log files every 50 steps, will result in a terrible looking graphs. So\ntrainer = L.Trainer(max_epochs=300, log_every_n_steps=2)\n\ntrainer.fit(model, train_dataloaders=dataloader)\n\nprint(\"After optimization, the parameters are...\")\nfor name, param in model.named_parameters():\n    print(name, param.data)\n\n\n\n\nAfter optimization, the parameters are...\nlstm.weight_ih_l0 tensor([[3.5364],\n        [1.3869],\n        [1.5390],\n        [1.2488]])\nlstm.weight_hh_l0 tensor([[5.2070],\n        [2.9577],\n        [3.2652],\n        [2.0678]])\nlstm.bias_ih_l0 tensor([-0.9143,  0.3724, -0.1815,  0.6376])\nlstm.bias_hh_l0 tensor([-1.0570,  1.2414, -0.5685,  0.3092])\n\n\nNow that training is done, let’s print out the new predictions…\n\nprint(\"\\nNow let's compare the observed and predicted values...\")\nprint(\"Company A: Observed = 0, Predicted =\", model(torch.tensor([0., 0.5, 0.25, 1.])).detach())\nprint(\"Company B: Observed = 1, Predicted =\", model(torch.tensor([1., 0.5, 0.25, 1.])).detach())\n\n\nNow let's compare the observed and predicted values...\nCompany A: Observed = 0, Predicted = tensor([6.8527e-05])\nCompany B: Observed = 1, Predicted = tensor([0.9809])\n\n\n…and, as we can see, after just 300 epochs, the LSTM is making great predictions. The prediction for Company A is close to the observed value 0 and the prediction for Company B is close to the observed value 1.\nLastly, let’s go back to TensorBoard to see the latest graphs. NOTE: To make it easier to see what we just did, deselect version0, version1 and version2 and make sure version3 is checked on the left-hand side of the page, under where it says Runs. This allows us to just look at the log files from the most recent training, which only went for 300 epochs.\nIn all three graphs, the loss (trainloss) and the predictions for Company A (out0) and Company B (out_1) started to taper off after 500 steps, or just 250 epochs, suggesting that adding more epochs may not improve the predictions much, so we’re done!",
    "crumbs": [
      "Machine Learning and AI",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Machine Learning and Artificial Intelligence</span>"
    ]
  },
  {
    "objectID": "300_hpt_intro.html",
    "href": "300_hpt_intro.html",
    "title": "18  Hyperparameter Tuning",
    "section": "",
    "text": "18.1 Structure of the Hyperparameter Tuning Chapters\nThe first part is structured as follows:\nThe concept of the hyperparameter tuning is described in Section 18.2.\nHyperparameter tuning with sklearn in Python is described in Chapter 19.\nHyperparameter tuning with river in Python is described in Chapter 21.\nThis part of the book is concluded with a description of the most recent PyTorch hyperparameter tuning approach, which is the integration of spotpython into the PyTorch Lightning training workflow. Hyperparameter tuning with PyTorch Lightning in Python is described in ?sec-hpt-pytorch. This is considered as the most effective, efficient, and flexible way to integrate spotpython into the PyTorch training workflow.\nFigure 18.1 shows the graphical user interface of spotpython that is used in this book.",
    "crumbs": [
      "Introduction to Hyperparameter Tuning",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Hyperparameter Tuning</span>"
    ]
  },
  {
    "objectID": "300_hpt_intro.html#structure-of-the-hyperparameter-tuning-chapters",
    "href": "300_hpt_intro.html#structure-of-the-hyperparameter-tuning-chapters",
    "title": "18  Hyperparameter Tuning",
    "section": "",
    "text": "Figure 18.1: spot GUI",
    "crumbs": [
      "Introduction to Hyperparameter Tuning",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Hyperparameter Tuning</span>"
    ]
  },
  {
    "objectID": "300_hpt_intro.html#sec-hyperparameter-tuning-goals",
    "href": "300_hpt_intro.html#sec-hyperparameter-tuning-goals",
    "title": "18  Hyperparameter Tuning",
    "section": "18.2 Goals of Hyperparameter Tuning",
    "text": "18.2 Goals of Hyperparameter Tuning\nThe goal of hyperparameter tuning is to optimize the hyperparameters in a way that improves the performance of the machine learning or deep learning model. Hyperparameters are parameters that are not learned during the training process, but are set before the training process begins. Hyperparameter tuning is an important, but often difficult and computationally intensive task. Changing the architecture of a neural network or the learning rate of an optimizer can have a significant impact on the performance.\nHyperparameter tuning is referred to as “hyperparameter optimization” (HPO) in the literature. However, since we do not consider the optimization, but also the understanding of the hyperparameters, we use the term “hyperparameter tuning” in this book. See also the discussion in Chapter 2 of Bartz et al. (2022), which lays the groundwork and presents an introduction to the process of tuning Machine Learning and Deep Learning hyperparameters and the respective methodology. Since the key elements such as the hyperparameter tuning process and measures of tunability and performance are presented in Bartz et al. (2022), we refer to this chapter for details.\nThe simplest, but also most computationally expensive, hyperparameter tuning approach uses manual search (or trial-and-error (Meignan et al. 2015)). Commonly encountered is simple random search, i.e., random and repeated selection of hyperparameters for evaluation, and lattice search (“grid search”). In addition, methods that perform directed search and other model-free algorithms, i.e., algorithms that do not explicitly rely on a model, e.g., evolution strategies (Bartz-Beielstein et al. 2014) or pattern search (Lewis, Torczon, and Trosset 2000) play an important role. Also, “hyperband”, i.e., a multi-armed bandit strategy that dynamically allocates resources to a set of random configurations and uses successive bisections to stop configurations with poor performance (Li et al. 2016), is very common in hyperparameter tuning. The most sophisticated and efficient approaches are the Bayesian optimization and surrogate model based optimization methods, which are based on the optimization of cost functions determined by simulations or experiments.\nWe consider a surrogate optimization based hyperparameter tuning approach that uses the Python version of the SPOT (“Sequential Parameter Optimization Toolbox”) (Bartz-Beielstein, Lasarczyk, and Preuss 2005), which is suitable for situations where only limited resources are available. This may be due to limited availability and cost of hardware, or due to the fact that confidential data may only be processed locally, e.g., due to legal requirements. Furthermore, in our approach, the understanding of algorithms is seen as a key tool for enabling transparency and explainability. This can be enabled, for example, by quantifying the contribution of machine learning and deep learning components (nodes, layers, split decisions, activation functions, etc.). Understanding the importance of hyperparameters and the interactions between multiple hyperparameters plays a major role in the interpretability and explainability of machine learning models. SPOT provides statistical tools for understanding hyperparameters and their interactions. Last but not least, it should be noted that the SPOT software code is available in the open source spotpython package on github1, allowing replicability of the results. This tutorial describes the Python variant of SPOT, which is called spotpython. The R implementation is described in Bartz et al. (2022). SPOT is an established open source software that has been maintained for more than 15 years (Bartz-Beielstein, Lasarczyk, and Preuss 2005) (Bartz et al. 2022).\n\n\n\n\nBartz, Eva, Thomas Bartz-Beielstein, Martin Zaefferer, and Olaf Mersmann, eds. 2022. Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide. Springer.\n\n\nBartz-Beielstein, Thomas, Jürgen Branke, Jörn Mehnen, and Olaf Mersmann. 2014. “Evolutionary Algorithms.” Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery 4 (3): 178–95.\n\n\nBartz-Beielstein, Thomas, Christian Lasarczyk, and Mike Preuss. 2005. “Sequential Parameter Optimization.” In Proceedings 2005 Congress on Evolutionary Computation (CEC’05), Edinburgh, Scotland, edited by B McKay et al., 773–80. Piscataway NJ: IEEE Press.\n\n\nLewis, R M, V Torczon, and M W Trosset. 2000. “Direct search methods: Then and now.” Journal of Computational and Applied Mathematics 124 (1–2): 191–207.\n\n\nLi, Lisha, Kevin Jamieson, Giulia DeSalvo, Afshin Rostamizadeh, and Ameet Talwalkar. 2016. “Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization.” arXiv e-Prints, March, arXiv:1603.06560.\n\n\nMeignan, David, Sigrid Knust, Jean-Marc Frayet, Gilles Pesant, and Nicolas Gaud. 2015. “A Review and Taxonomy of Interactive Optimization Methods in Operations Research.” ACM Transactions on Interactive Intelligent Systems, September.",
    "crumbs": [
      "Introduction to Hyperparameter Tuning",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Hyperparameter Tuning</span>"
    ]
  },
  {
    "objectID": "300_hpt_intro.html#footnotes",
    "href": "300_hpt_intro.html#footnotes",
    "title": "18  Hyperparameter Tuning",
    "section": "",
    "text": "https://github.com/sequential-parameter-optimization↩︎",
    "crumbs": [
      "Introduction to Hyperparameter Tuning",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Hyperparameter Tuning</span>"
    ]
  },
  {
    "objectID": "400_spot_hpt_sklearn.html",
    "href": "400_spot_hpt_sklearn.html",
    "title": "19  HPT: sklearn",
    "section": "",
    "text": "19.1 Introduction to sklearn",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>HPT: sklearn</span>"
    ]
  },
  {
    "objectID": "401_spot_hpt_sklearn_classification.html",
    "href": "401_spot_hpt_sklearn_classification.html",
    "title": "20  HPT: sklearn SVC on Moons Data",
    "section": "",
    "text": "20.1 Step 1: Setup\nBefore we consider the detailed experimental setup, we select the parameters that affect run time, initial design size and the device that is used.\nMAX_TIME = 1\nINIT_SIZE = 10\nPREFIX = \"10\"",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>HPT: sklearn SVC on Moons Data</span>"
    ]
  },
  {
    "objectID": "401_spot_hpt_sklearn_classification.html#sec-setup-17",
    "href": "401_spot_hpt_sklearn_classification.html#sec-setup-17",
    "title": "20  HPT: sklearn SVC on Moons Data",
    "section": "",
    "text": "Caution: Run time and initial design size should be increased for real experiments\n\n\n\n\nMAX_TIME is set to one minute for demonstration purposes. For real experiments, this should be increased to at least 1 hour.\nINIT_SIZE is set to 5 for demonstration purposes. For real experiments, this should be increased to at least 10.",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>HPT: sklearn SVC on Moons Data</span>"
    ]
  },
  {
    "objectID": "401_spot_hpt_sklearn_classification.html#step-2-initialization-of-the-empty-fun_control-dictionary",
    "href": "401_spot_hpt_sklearn_classification.html#step-2-initialization-of-the-empty-fun_control-dictionary",
    "title": "20  HPT: sklearn SVC on Moons Data",
    "section": "20.2 Step 2: Initialization of the Empty fun_control Dictionary",
    "text": "20.2 Step 2: Initialization of the Empty fun_control Dictionary\nspotpython supports the visualization of the hyperparameter tuning process with TensorBoard. The following example shows how to use TensorBoard with spotpython. The fun_control dictionary is the central data structure that is used to control the optimization process. It is initialized as follows:\n\nfrom spotpython.utils.init import fun_control_init\nfrom spotpython.hyperparameters.values import set_control_key_value\nfrom spotpython.utils.eda import gen_design_table\nfun_control = fun_control_init(\n    PREFIX=PREFIX,\n    TENSORBOARD_CLEAN=True,\n    max_time=MAX_TIME,\n    fun_evals=inf,\n    tolerance_x = np.sqrt(np.spacing(1)))\n\nMoving TENSORBOARD_PATH: runs/ to TENSORBOARD_PATH_OLD: runs_OLD/runs_2024_10_12_11_59_29\n\n\n\n\n\n\n\n\nTip: TensorBoard\n\n\n\n\nSince the spot_tensorboard_path argument is not None, which is the default, spotpython will log the optimization process in the TensorBoard folder.\nThe TENSORBOARD_CLEAN argument is set to True to archive the TensorBoard folder if it already exists. This is useful if you want to start a hyperparameter tuning process from scratch. If you want to continue a hyperparameter tuning process, set TENSORBOARD_CLEAN to False. Then the TensorBoard folder will not be archived and the old and new TensorBoard files will shown in the TensorBoard dashboard.",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>HPT: sklearn SVC on Moons Data</span>"
    ]
  },
  {
    "objectID": "401_spot_hpt_sklearn_classification.html#sec-data-loading-17",
    "href": "401_spot_hpt_sklearn_classification.html#sec-data-loading-17",
    "title": "20  HPT: sklearn SVC on Moons Data",
    "section": "20.3 Step 3: SKlearn Load Data (Classification)",
    "text": "20.3 Step 3: SKlearn Load Data (Classification)\nRandomly generate classification data.\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import make_moons, make_circles, make_classification\nn_features = 2\nn_samples = 500\ntarget_column = \"y\"\nds =  make_moons(n_samples, noise=0.5, random_state=0)\nX, y = ds\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=42\n)\ntrain = pd.DataFrame(np.hstack((X_train, y_train.reshape(-1, 1))))\ntest = pd.DataFrame(np.hstack((X_test, y_test.reshape(-1, 1))))\ntrain.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\ntest.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\ntrain.head()\n\n\n\n\n\n\n\n\nx1\nx2\ny\n\n\n\n\n0\n1.960101\n0.383172\n0.0\n\n\n1\n2.354420\n-0.536942\n1.0\n\n\n2\n1.682186\n-0.332108\n0.0\n\n\n3\n1.856507\n0.687220\n1.0\n\n\n4\n1.925524\n0.427413\n1.0\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\n\nx_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\ny_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\ncm = plt.cm.RdBu\ncm_bright = ListedColormap([\"#FF0000\", \"#0000FF\"])\nax = plt.subplot(1, 1, 1)\nax.set_title(\"Input data\")\n# Plot the training points\nax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors=\"k\")\n# Plot the testing points\nax.scatter(\n    X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6, edgecolors=\"k\"\n)\nax.set_xlim(x_min, x_max)\nax.set_ylim(y_min, y_max)\nax.set_xticks(())\nax.set_yticks(())\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nn_samples = len(train)\n# add the dataset to the fun_control\nfun_control.update({\"data\": None, # dataset,\n               \"train\": train,\n               \"test\": test,\n               \"n_samples\": n_samples,\n               \"target_column\": target_column})",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>HPT: sklearn SVC on Moons Data</span>"
    ]
  },
  {
    "objectID": "401_spot_hpt_sklearn_classification.html#sec-specification-of-preprocessing-model-17",
    "href": "401_spot_hpt_sklearn_classification.html#sec-specification-of-preprocessing-model-17",
    "title": "20  HPT: sklearn SVC on Moons Data",
    "section": "20.4 Step 4: Specification of the Preprocessing Model",
    "text": "20.4 Step 4: Specification of the Preprocessing Model\nData preprocesssing can be very simple, e.g., you can ignore it. Then you would choose the prep_model “None”:\n\nprep_model = None\nfun_control.update({\"prep_model\": prep_model})\n\nA default approach for numerical data is the StandardScaler (mean 0, variance 1). This can be selected as follows:\n\nfrom sklearn.preprocessing import StandardScaler\nprep_model = StandardScaler\nfun_control.update({\"prep_model\": prep_model})\n\nEven more complicated pre-processing steps are possible, e.g., the follwing pipeline:\ncategorical_columns = []\none_hot_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\nprep_model = ColumnTransformer(\n         transformers=[\n             (\"categorical\", one_hot_encoder, categorical_columns),\n         ],\n         remainder=StandardScaler,\n     )",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>HPT: sklearn SVC on Moons Data</span>"
    ]
  },
  {
    "objectID": "401_spot_hpt_sklearn_classification.html#step-5-select-model-algorithm-and-core_model_hyper_dict",
    "href": "401_spot_hpt_sklearn_classification.html#step-5-select-model-algorithm-and-core_model_hyper_dict",
    "title": "20  HPT: sklearn SVC on Moons Data",
    "section": "20.5 Step 5: Select Model (algorithm) and core_model_hyper_dict",
    "text": "20.5 Step 5: Select Model (algorithm) and core_model_hyper_dict\nThe selection of the algorithm (ML model) that should be tuned is done by specifying the its name from the sklearn implementation. For example, the SVC support vector machine classifier is selected as follows:\n\nfrom spotpython.hyperparameters.values import add_core_model_to_fun_control\nfrom spotpython.hyperdict.sklearn_hyper_dict import SklearnHyperDict\nfrom sklearn.svm import SVC\nadd_core_model_to_fun_control(core_model=SVC,\n                              fun_control=fun_control,\n                              hyper_dict=SklearnHyperDict,\n                              filename=None)\n\nNow fun_control has the information from the JSON file. The corresponding entries for the core_model class are shown below.\n\nfun_control['core_model_hyper_dict']\n\n{'C': {'type': 'float',\n  'default': 1.0,\n  'transform': 'None',\n  'lower': 0.1,\n  'upper': 10.0},\n 'kernel': {'levels': ['linear', 'poly', 'rbf', 'sigmoid'],\n  'type': 'factor',\n  'default': 'rbf',\n  'transform': 'None',\n  'core_model_parameter_type': 'str',\n  'lower': 0,\n  'upper': 3},\n 'degree': {'type': 'int',\n  'default': 3,\n  'transform': 'None',\n  'lower': 3,\n  'upper': 3},\n 'gamma': {'levels': ['scale', 'auto'],\n  'type': 'factor',\n  'default': 'scale',\n  'transform': 'None',\n  'core_model_parameter_type': 'str',\n  'lower': 0,\n  'upper': 1},\n 'coef0': {'type': 'float',\n  'default': 0.0,\n  'transform': 'None',\n  'lower': 0.0,\n  'upper': 0.0},\n 'shrinking': {'levels': [0, 1],\n  'type': 'factor',\n  'default': 0,\n  'transform': 'None',\n  'core_model_parameter_type': 'bool',\n  'lower': 0,\n  'upper': 1},\n 'probability': {'levels': [0, 1],\n  'type': 'factor',\n  'default': 0,\n  'transform': 'None',\n  'core_model_parameter_type': 'bool',\n  'lower': 0,\n  'upper': 1},\n 'tol': {'type': 'float',\n  'default': 0.001,\n  'transform': 'None',\n  'lower': 0.0001,\n  'upper': 0.01},\n 'cache_size': {'type': 'float',\n  'default': 200,\n  'transform': 'None',\n  'lower': 100,\n  'upper': 400},\n 'break_ties': {'levels': [0, 1],\n  'type': 'factor',\n  'default': 0,\n  'transform': 'None',\n  'core_model_parameter_type': 'bool',\n  'lower': 0,\n  'upper': 1}}\n\n\n\n\n\n\n\n\nsklearn Model Selection\n\n\n\nThe following sklearn models are supported by default:\n\nRidgeCV\nRandomForestClassifier\nSVC\nLogisticRegression\nKNeighborsClassifier\nGradientBoostingClassifier\nGradientBoostingRegressor\nElasticNet\n\nThey can be imported as follows:\n\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.linear_model import ElasticNet",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>HPT: sklearn SVC on Moons Data</span>"
    ]
  },
  {
    "objectID": "401_spot_hpt_sklearn_classification.html#step-6-modify-hyper_dict-hyperparameters-for-the-selected-algorithm-aka-core_model",
    "href": "401_spot_hpt_sklearn_classification.html#step-6-modify-hyper_dict-hyperparameters-for-the-selected-algorithm-aka-core_model",
    "title": "20  HPT: sklearn SVC on Moons Data",
    "section": "20.6 Step 6: Modify hyper_dict Hyperparameters for the Selected Algorithm aka core_model",
    "text": "20.6 Step 6: Modify hyper_dict Hyperparameters for the Selected Algorithm aka core_model\nspotpython provides functions for modifying the hyperparameters, their bounds and factors as well as for activating and de-activating hyperparameters without re-compilation of the Python source code. These functions were described in Section D.15.1.\n\n20.6.1 Modify hyperparameter of type numeric and integer (boolean)\nNumeric and boolean values can be modified using the modify_hyper_parameter_bounds method.\n\n\n\n\n\n\nsklearn Model Hyperparameters\n\n\n\nThe hyperparameters of the sklearn SVC model are described in the sklearn documentation.\n\n\n\nFor example, to change the tol hyperparameter of the SVC model to the interval [1e-5, 1e-3], the following code can be used:\n\n\nfrom spotpython.hyperparameters.values import modify_hyper_parameter_bounds\nmodify_hyper_parameter_bounds(fun_control, \"tol\", bounds=[1e-5, 1e-3])\nmodify_hyper_parameter_bounds(fun_control, \"probability\", bounds=[0, 0])\nfun_control[\"core_model_hyper_dict\"][\"tol\"]\n\n{'type': 'float',\n 'default': 0.001,\n 'transform': 'None',\n 'lower': 1e-05,\n 'upper': 0.001}\n\n\n\n\n20.6.2 Modify hyperparameter of type factor\nFactors can be modified with the modify_hyper_parameter_levels function. For example, to exclude the sigmoid kernel from the tuning, the kernel hyperparameter of the SVC model can be modified as follows:\n\nfrom spotpython.hyperparameters.values import modify_hyper_parameter_levels\nmodify_hyper_parameter_levels(fun_control, \"kernel\", [\"poly\", \"rbf\"])\nfun_control[\"core_model_hyper_dict\"][\"kernel\"]\n\n{'levels': ['poly', 'rbf'],\n 'type': 'factor',\n 'default': 'rbf',\n 'transform': 'None',\n 'core_model_parameter_type': 'str',\n 'lower': 0,\n 'upper': 1}\n\n\n\n\n20.6.3 Optimizers\nOptimizers are described in Section 4.2.",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>HPT: sklearn SVC on Moons Data</span>"
    ]
  },
  {
    "objectID": "401_spot_hpt_sklearn_classification.html#step-7-selection-of-the-objective-loss-function",
    "href": "401_spot_hpt_sklearn_classification.html#step-7-selection-of-the-objective-loss-function",
    "title": "20  HPT: sklearn SVC on Moons Data",
    "section": "20.7 Step 7: Selection of the Objective (Loss) Function",
    "text": "20.7 Step 7: Selection of the Objective (Loss) Function\nThere are two metrics:\n\nmetric_river is used for the river based evaluation via eval_oml_iter_progressive.\nmetric_sklearn is used for the sklearn based evaluation.\n\n\nfrom sklearn.metrics import mean_absolute_error, accuracy_score, roc_curve, roc_auc_score, log_loss, mean_squared_error\nfun_control.update({\n               \"metric_sklearn\": log_loss,\n               \"weights\": 1.0,\n               })\n\n\n\n\n\n\n\nmetric_sklearn: Minimization and Maximization\n\n\n\n\nBecause the metric_sklearn is used for the sklearn based evaluation, it is important to know whether the metric should be minimized or maximized.\nThe weights parameter is used to indicate whether the metric should be minimized or maximized.\nIf weights is set to -1.0, the metric is maximized.\nIf weights is set to 1.0, the metric is minimized, e.g., weights = 1.0 for mean_absolute_error, or weights = -1.0 for roc_auc_score.\n\n\n\n\n20.7.1 Predict Classes or Class Probabilities\nIf the key \"predict_proba\" is set to True, the class probabilities are predicted. False is the default, i.e., the classes are predicted.\n\nfun_control.update({\n               \"predict_proba\": False,\n               })",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>HPT: sklearn SVC on Moons Data</span>"
    ]
  },
  {
    "objectID": "401_spot_hpt_sklearn_classification.html#step-8-calling-the-spot-function",
    "href": "401_spot_hpt_sklearn_classification.html#step-8-calling-the-spot-function",
    "title": "20  HPT: sklearn SVC on Moons Data",
    "section": "20.8 Step 8: Calling the SPOT Function",
    "text": "20.8 Step 8: Calling the SPOT Function\n\n20.8.1 The Objective Function\nThe objective function is selected next. It implements an interface from sklearn’s training, validation, and testing methods to spotpython.\n\nfrom spotpython.fun.hypersklearn import HyperSklearn\nfun = HyperSklearn().fun_sklearn\n\nThe following code snippet shows how to get the default hyperparameters as an array, so that they can be passed to the Spot function.\n\nfrom spotpython.hyperparameters.values import get_default_hyperparameters_as_array\nX_start = get_default_hyperparameters_as_array(fun_control)\n\n\n\n20.8.2 Run the Spot Optimizer\nThe class Spot [SOURCE] is the hyperparameter tuning workhorse. It is initialized with the following parameters:\n\nfun: the objective function\nfun_control: the dictionary with the control parameters for the objective function\ndesign: the experimental design\ndesign_control: the dictionary with the control parameters for the experimental design\nsurrogate: the surrogate model\nsurrogate_control: the dictionary with the control parameters for the surrogate model\noptimizer: the optimizer\noptimizer_control: the dictionary with the control parameters for the optimizer\n\n\n\n\n\n\n\nNote: Total run time\n\n\n\nThe total run time may exceed the specified max_time, because the initial design (here: init_size = INIT_SIZE as specified above) is always evaluated, even if this takes longer than max_time.\n\n\n\nfrom spotpython.utils.init import design_control_init, surrogate_control_init\ndesign_control = design_control_init()\nset_control_key_value(control_dict=design_control,\n                        key=\"init_size\",\n                        value=INIT_SIZE,\n                        replace=True)\n\nsurrogate_control = surrogate_control_init(noise=True,\n                                           n_theta=2)\nfrom spotpython.spot import spot\nspot_tuner = spot.Spot(fun=fun,\n                   fun_control=fun_control,\n                   design_control=design_control,\n                   surrogate_control=surrogate_control)\nspot_tuner.run(X_start=X_start)\n\nspotpython tuning: 6.436366676628063 [----------] 4.78% \nspotpython tuning: 6.436366676628063 [#---------] 7.17% \nspotpython tuning: 6.436366676628063 [#---------] 9.92% \nspotpython tuning: 6.436366676628063 [#---------] 13.29% \nspotpython tuning: 6.436366676628063 [##--------] 15.92% \nspotpython tuning: 6.436366676628063 [##--------] 18.42% \nspotpython tuning: 6.436366676628063 [##--------] 21.91% \nspotpython tuning: 6.436366676628063 [###-------] 26.69% \nspotpython tuning: 6.436366676628063 [###-------] 32.11% \nspotpython tuning: 6.436366676628063 [####------] 37.31% \nspotpython tuning: 6.436366676628063 [#####-----] 45.65% \nspotpython tuning: 6.436366676628063 [######----] 60.57% \nspotpython tuning: 6.436366676628063 [######----] 63.79% \nspotpython tuning: 6.436366676628063 [#######---] 72.38% \nspotpython tuning: 6.436366676628063 [########--] 75.06% \nspotpython tuning: 6.436366676628063 [########--] 82.04% \nspotpython tuning: 6.436366676628063 [##########] 100.00% Done...\n\n\n\n&lt;spotpython.spot.spot.Spot at 0x382bf2180&gt;\n\n\n\n\n20.8.3 TensorBoard\nNow we can start TensorBoard in the background with the following command, where ./runs is the default directory for the TensorBoard log files:\ntensorboard --logdir=\"./runs\"\n\n\n\n\n\n\nTip: TENSORBOARD_PATH\n\n\n\nThe TensorBoard path can be printed with the following command:\n\nfrom spotpython.utils.init import get_tensorboard_path\nget_tensorboard_path(fun_control)\n\n'runs/'\n\n\n\n\nWe can access the TensorBoard web server with the following URL:\nhttp://localhost:6006/\nThe TensorBoard plot illustrates how spotpython can be used as a microscope for the internal mechanisms of the surrogate-based optimization process. Here, one important parameter, the learning rate \\(\\theta\\) of the Kriging surrogate [SOURCE] is plotted against the number of optimization steps.\n\n\n\nTensorBoard visualization of the spotpython optimization process and the surrogate model.",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>HPT: sklearn SVC on Moons Data</span>"
    ]
  },
  {
    "objectID": "401_spot_hpt_sklearn_classification.html#sec-results-tuning-17",
    "href": "401_spot_hpt_sklearn_classification.html#sec-results-tuning-17",
    "title": "20  HPT: sklearn SVC on Moons Data",
    "section": "20.9 Step 9: Results",
    "text": "20.9 Step 9: Results\nAfter the hyperparameter tuning run is finished, the results can be saved and reloaded with the following commands:\n\nfrom spotpython.utils.file import save_pickle, load_pickle\nfrom spotpython.utils.init import get_experiment_name\nexperiment_name = get_experiment_name(PREFIX)\nSAVE_AND_LOAD = False\nif SAVE_AND_LOAD == True:\n    save_pickle(spot_tuner, experiment_name)\n    spot_tuner = load_pickle(experiment_name)\n\nAfter the hyperparameter tuning run is finished, the progress of the hyperparameter tuning can be visualized. The black points represent the performace values (score or metric) of hyperparameter configurations from the initial design, whereas the red points represents the hyperparameter configurations found by the surrogate model based optimization.\n\nspot_tuner.plot_progress(log_y=True, filename=\"./figures/\" + experiment_name+\"_progress.pdf\")\n\n\n\n\n\n\n\n\nResults can also be printed in tabular form.\n\nprint(gen_design_table(fun_control=fun_control, spot=spot_tuner))\n\n| name        | type   | default   |   lower |   upper | tuned                 | transform   |   importance | stars   |\n|-------------|--------|-----------|---------|---------|-----------------------|-------------|--------------|---------|\n| C           | float  | 1.0       |     0.1 |    10.0 | 1.3459476182876375    | None        |        43.22 | *       |\n| kernel      | factor | rbf       |     0.0 |     1.0 | rbf                   | None        |       100.00 | ***     |\n| degree      | int    | 3         |     3.0 |     3.0 | 3.0                   | None        |         0.00 |         |\n| gamma       | factor | scale     |     0.0 |     1.0 | scale                 | None        |         0.03 |         |\n| coef0       | float  | 0.0       |     0.0 |     0.0 | 0.0                   | None        |         0.00 |         |\n| shrinking   | factor | 0         |     0.0 |     1.0 | 1                     | None        |        24.82 | *       |\n| probability | factor | 0         |     0.0 |     0.0 | 0                     | None        |         0.00 |         |\n| tol         | float  | 0.001     |   1e-05 |   0.001 | 2.988661226661179e-05 | None        |         0.06 |         |\n| cache_size  | float  | 200.0     |   100.0 |   400.0 | 174.45504889441855    | None        |         0.03 |         |\n| break_ties  | factor | 0         |     0.0 |     1.0 | 0                     | None        |         0.04 |         |\n\n\nA histogram can be used to visualize the most important hyperparameters.\n\nspot_tuner.plot_importance(threshold=0.0025, filename=\"./figures/\" + experiment_name+\"_importance.pdf\")",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>HPT: sklearn SVC on Moons Data</span>"
    ]
  },
  {
    "objectID": "401_spot_hpt_sklearn_classification.html#get-default-hyperparameters",
    "href": "401_spot_hpt_sklearn_classification.html#get-default-hyperparameters",
    "title": "20  HPT: sklearn SVC on Moons Data",
    "section": "20.10 Get Default Hyperparameters",
    "text": "20.10 Get Default Hyperparameters\nThe default hyperparameters, whihc will be used for a comparion with the tuned hyperparameters, can be obtained with the following commands:\n\nfrom spotpython.hyperparameters.values import get_one_core_model_from_X\nfrom spotpython.hyperparameters.values import get_default_hyperparameters_as_array\nX_start = get_default_hyperparameters_as_array(fun_control)\nmodel_default = get_one_core_model_from_X(X_start, fun_control, default=True)\nmodel_default\n\nSVC(cache_size=200.0, shrinking=False)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  SVC?Documentation for SVCiNot fittedSVC(cache_size=200.0, shrinking=False)",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>HPT: sklearn SVC on Moons Data</span>"
    ]
  },
  {
    "objectID": "401_spot_hpt_sklearn_classification.html#get-spot-results",
    "href": "401_spot_hpt_sklearn_classification.html#get-spot-results",
    "title": "20  HPT: sklearn SVC on Moons Data",
    "section": "20.11 Get SPOT Results",
    "text": "20.11 Get SPOT Results\nIn a similar way, we can obtain the hyperparameters found by spotpython.\n\nfrom spotpython.hyperparameters.values import get_one_core_model_from_X\nX = spot_tuner.to_all_dim(spot_tuner.min_X.reshape(1,-1))\nmodel_spot = get_one_core_model_from_X(X, fun_control)\n\n\n20.11.1 Plot: Compare Predictions\n\nfrom spotpython.plot.validation import plot_roc\nplot_roc(model_list=[model_default, model_spot], fun_control= fun_control, model_names=[\"Default\", \"Spot\"])\n\n\n\n\n\n\n\n\n\nfrom spotpython.plot.validation import plot_confusion_matrix\nplot_confusion_matrix(model=model_default, fun_control=fun_control, title = \"Default\")\n\n\n\n\n\n\n\n\n\nplot_confusion_matrix(model=model_spot, fun_control=fun_control, title=\"SPOT\")\n\n\n\n\n\n\n\n\n\nmin(spot_tuner.y), max(spot_tuner.y)\n\n(6.436366676628063, 10.813096016735146)\n\n\n\n\n20.11.2 Detailed Hyperparameter Plots\n\nspot_tuner.plot_important_hyperparameter_contour(filename=None)\n\nC:  43.21937437869265\nkernel:  100.0\ngamma:  0.028895927097448246\nshrinking:  24.81890091438799\ntol:  0.06432027777032988\ncache_size:  0.029077677771141282\nbreak_ties:  0.03796473642110418\nimpo: [['C', 43.21937437869265], ['kernel', 100.0], ['gamma', 0.028895927097448246], ['shrinking', 24.81890091438799], ['tol', 0.06432027777032988], ['cache_size', 0.029077677771141282], ['break_ties', 0.03796473642110418]]\nindices: [1, 0, 3, 4, 6, 5, 2]\nindices after max_imp selection: [1, 0, 3, 4, 6, 5, 2]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n20.11.3 Parallel Coordinates Plot\n\nspot_tuner.parallel_plot()\n\n                                                \n\n\n\n\n20.11.4 Plot all Combinations of Hyperparameters\n\nWarning: this may take a while.\n\n\nPLOT_ALL = False\nif PLOT_ALL:\n    n = spot_tuner.k\n    for i in range(n-1):\n        for j in range(i+1, n):\n            spot_tuner.plot_contour(i=i, j=j, min_z=min_z, max_z = max_z)",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>HPT: sklearn SVC on Moons Data</span>"
    ]
  },
  {
    "objectID": "500_spot_hpt_river.html",
    "href": "500_spot_hpt_river.html",
    "title": "21  HPT: River",
    "section": "",
    "text": "21.1 Introduction to River",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>HPT: River</span>"
    ]
  },
  {
    "objectID": "501_spot_river_gui.html",
    "href": "501_spot_river_gui.html",
    "title": "22  Simplifying Hyperparameter Tuning in Online Machine Learning—The spotRiverGUI",
    "section": "",
    "text": "22.1 Introduction\nBatch Machine Learning (BML) often encounters limitations when processing substantial volumes of streaming data (Keller-McNulty 2004; Gaber, Zaslavsky, and Krishnaswamy 2005; Aggarwal 2007). These limitations become particularly evident in terms of available memory, managing drift in data streams (Bifet and Gavaldà 2007, 2009; Gama et al. 2004; Bartz-Beielstein 2024c), and processing novel, unclassified data (Bifet 2010), (Dredze, Oates, and Piatko 2010). As a solution, Online Machine Learning (OML) serves as an effective alternative to BML, adeptly addressing these constraints. OML’s ability to sequentially process data proves especially beneficial for handling data streams (Bifet et al. 2010a; Masud et al. 2011; Gama, Sebastião, and Rodrigues 2013; Putatunda 2021; Bartz-Beielstein and Hans 2024).\nThe Online Machine Learning (OML) methods provided by software packages such as river (Montiel et al. 2021) or MOA (Bifet et al. 2010b) require the specification of many hyperparameters. To give an example, Hoeffding trees (Hoeglinger and Pears 2007), which are very popular in OML, offer a variety of “splitters” to generate subtrees. There are also several methods to limit the tree size, ensuring time and memory requirements remain manageable. Given the multitude of parameters, manually searching for the optimal hyperparameter setting can be a daunting and often futile task due to the complexity of possible combinations. This article elucidates how automatic hyperparameter optimization, or “tuning”, can be achieved. Beyond optimizing the OML process, Hyperparameter Tuning (HPT) executed with the Sequential Parameter Optimization Toolbox (SPOT) enhances the explainability and interpretability of OML procedures. This can result in a more efficient, resource-conserving algorithm, contributing to the concept of “Green AI”.\nThis article describes the spotRiverGUI, which is a graphical user interface for the spotriver package. The GUI allows the user to select the task, the data set, the preprocessing model, the metric, and the online machine learning model. The user can specify the experiment duration, the initial design, and the evaluation options. The GUI provides information about the data set and allows the user to save and load experiments. It also starts and stops a tensorboard process to observe the tuning online and provides an analysis of the hyperparameter tuning process. The spotRiverGUI releases the user from the burden of manually searching for the optimal hyperparameter setting. After providing the data, users can compare different OML algorithms from the powerful river package in a convenient way and tune the selected algorithm very efficiently.\nThis article is structured as follows:\nSection 22.2 describes how to install the software. It also explains how the spotRiverGUI can be started. Section 22.3 describes the binary classification task and the options available in the spotRiverGUI. Section 22.4 provides information about the planned regression task. Section 22.5 describes how the data can be visualized in the spotRiverGUI. Section 22.6 provides information about saving and loading experiments. Section 22.7 describes how to start an experiment and how the associated tensorboard process can be started and stopped. Section 22.8 provides information about the analysis of the results from the hyperparameter tuning process. Section 22.9 concludes the article and provides an outlook.",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Simplifying Hyperparameter Tuning in Online Machine Learning---The spotRiverGUI</span>"
    ]
  },
  {
    "objectID": "501_spot_river_gui.html#introduction",
    "href": "501_spot_river_gui.html#introduction",
    "title": "22  Simplifying Hyperparameter Tuning in Online Machine Learning—The spotRiverGUI",
    "section": "",
    "text": "Note\n\n\n\nNote: This document refers to spotRiverGUI version 0.0.26 which was released on Feb 18, 2024 on GitHub, see: https://github.com/sequential-parameter-optimization/spotGUI/tree/main. The GUI is under active development and new features will be added soon.",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Simplifying Hyperparameter Tuning in Online Machine Learning---The spotRiverGUI</span>"
    ]
  },
  {
    "objectID": "501_spot_river_gui.html#sec-starting-gui",
    "href": "501_spot_river_gui.html#sec-starting-gui",
    "title": "22  Simplifying Hyperparameter Tuning in Online Machine Learning—The spotRiverGUI",
    "section": "22.2 Installation and Starting",
    "text": "22.2 Installation and Starting\n\n22.2.1 Installation\nWe strongly recommend using a virtual environment for the installation of the river, spotriver, build and spotRiverGUI packages.\nMiniforge, which holds the minimal installers for Conda, is a good starting point. Please follow the instructions on https://github.com/conda-forge/miniforge. Using Conda, the following commands can be used to create a virtual environment (Python 3.11 is recommended):\n&gt;&gt; conda create -n myenv python=3.11\n&gt;&gt; conda activate myenv\nNow the river and spotriver packages can be installed:\n&gt;&gt; (myenv) pip install river spotriver build\nAlthough the spotGUI package is available on PyPI, we recommend an installation from the GitHub repository https://github.com/sequential-parameter-optimization/spotGUI, because the spotGUI package is under active development and new features will be added soon. The installation from the GitHub repository is done by executing the following command:\n&gt;&gt; (myenv) git clone git@github.com:sequential-parameter-optimization/spotGUI.git\nBuilding the spotGUI package is done by executing the following command:\n&gt;&gt; (myenv) cd spotGUI\n&gt;&gt; (myenv) python -m build\nNow the spotRiverGUI package can be installed:\n&gt;&gt; (myenv) pip install dist/spotGUI-0.0.26.tar.gz\n\n\n22.2.2 Starting the GUI\nThe GUI can be started by executing the spotRiverGUI.py file in the spotGUI/spotRiverGUI directory. Change to the spotRiverGUI directory and start the GUI:\n&gt;&gt; (myenv) cd spotGUI/spotRiverGUI\n&gt;&gt; (myenv) python spotRiverGUI.py\nThe GUI window will open, as shown in Figure 22.1.\n\n\n\n\n\n\nFigure 22.1: spotriver GUI\n\n\n\nAfter the GUI window has opened, the user can select the task. Currently, Binary Classification is available. Further tasks like Regression will be available soon.\nDepending on the task, the user can select the data set, the preprocessing model, the metric, and the online machine learning model.",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Simplifying Hyperparameter Tuning in Online Machine Learning---The spotRiverGUI</span>"
    ]
  },
  {
    "objectID": "501_spot_river_gui.html#sec-binary-classification",
    "href": "501_spot_river_gui.html#sec-binary-classification",
    "title": "22  Simplifying Hyperparameter Tuning in Online Machine Learning—The spotRiverGUI",
    "section": "22.3 Binary Classification",
    "text": "22.3 Binary Classification\n\n22.3.1 Binary Classification Options\nIf the Binary Classification task is selected, the user can select pre-specified data sets from the Data drop-down menu.\n\n22.3.1.1 River Data Sets\nThe following data sets from the river package are available (the descriptions are taken from the river package):\n\nBananas: An artificial dataset where instances belongs to several clusters with a banana shape.There are two attributes that correspond to the x and y axis, respectively. More: https://riverml.xyz/dev/api/datasets/Bananas/.\nCreditCard: Credit card frauds. The datasets contains transactions made by credit cards in September 2013 by European cardholders. Feature ‘Class’ is the response variable and it takes value 1 in case of fraud and 0 otherwise. More: https://riverml.xyz/dev/api/datasets/CreditCard/.\nElec2: Electricity prices in New South Wales. This is a binary classification task, where the goal is to predict if the price of electricity will go up or down. This data was collected from the Australian New South Wales Electricity Market. In this market, prices are not fixed and are affected by demand and supply of the market. They are set every five minutes. Electricity transfers to/from the neighboring state of Victoria were done to alleviate fluctuations. More: https://riverml.xyz/dev/api/datasets/Elec2/.\nHiggs: The data has been produced using Monte Carlo simulations. The first 21 features (columns 2-22) are kinematic properties measured by the particle detectors in the accelerator. The last seven features are functions of the first 21 features; these are high-level features derived by physicists to help discriminate between the two classes. More: https://riverml.xyz/dev/api/datasets/Higgs/.\nHTTP: HTTP dataset of the KDD 1999 cup. The goal is to predict whether or not an HTTP connection is anomalous or not. The dataset only contains 2,211 (0.4%) positive labels. More: https://riverml.xyz/dev/api/datasets/HTTP/.\nPhishing: Phishing websites. This dataset contains features from web pages that are classified as phishing or not.https://riverml.xyz/dev/api/datasets/Phishing/\n\n\n\n22.3.1.2 User Data Sets\nBesides the river data sets described in Section 22.3.1.1, the user can also select a user-defined data set. Currently, comma-separated values (CSV) files are supported. Further formats will be supported soon. The user-defined CSV data set must be a binary classification task with the target variable in the last column. The first row must contain the column names. If the file is copied to the subdirectory userData, the user can select the data set from the Data drop-down menu.\nAs an example, we have provided a CSV-version of the Phishing data set. The file is located in the userData subdirectory and is called PhishingData.csv. It contains the columns empty_server_form_handler, popup_window, https, request_from_other_domain, anchor_from_other_domain, is_popular, long_url, age_of_domain, ip_in_url, and is_phishing. The first few lines of the file are shown below (modified due to formatting reasons):\nempty_server_form_handler,...,is_phishing\n0.0,0.0,0.0,0.0,0.0,0.5,1.0,1,1,1\n1.0,0.0,0.5,0.5,0.0,0.5,0.0,1,0,1\n0.0,0.0,1.0,0.0,0.5,0.5,0.0,1,0,1\n0.0,0.0,1.0,0.0,0.0,1.0,0.5,0,0,1\nBased on the required format, we can see that is_phishing is the target column, because it is the last column of the data set.\n\n\n22.3.1.3 Stream Data Sets\nForthcoming versions of the GUI will support stream data sets, e.g, the Friedman-Drift generator (Ikonomovska 2012) or the SEA-Drift generator (Street and Kim 2001). The Friedman-Drift generator was also used in the hyperparameter tuning study in Bartz-Beielstein (2024b).\n\n\n22.3.1.4 Data Set Options\nCurrently, the user can select the following parameters for the data sets:\n\nn_total: The total number of instances. Since some data sets are quite large, the user can select a subset of the data set by specifying the n_total value.\ntest_size: The size of the test set in percent (0.0 - 1.0). The training set will be 1.0 - test_size.\n\nThe target column should be the last column of the data set. Future versions of the GUI will support the selection of the target_column from the GUI. Currently, the value from the field target_column has not effect.\nTo compare different data scaling methods, the user can select the preprocessing model from the Preprocessing drop-down menu. Currently, the following preprocessing models are available:\n\nStandardScaler: Standardize features by removing the mean and scaling to unit variance.\nMinMaxScaler: Scale features to a range.\nNone: No scaling is performed.\n\nThe spotRiverGUI will not provide sophisticated data preprocessing methods. We assume that the data was preprocessed before it is copied into the userData subdirectory.\n\n\n\n22.3.2 Experiment Options\nCurrently, the user can select the following options for specifying the experiment duration:\n\nMAX_TIME: The maximum time in minutes for the experiment.\nFUN_EVALS: The number of function evaluations for the experiment. This is the number of OML-models that are built and evaluated.\n\nIf the MAX_TIME is reached or FUN_EVALS OML models are evaluated, the experiment will be stopped.\n\n\n\n\n\n\nInitial design is always evaluated\n\n\n\n\nThe initial design will always be evaluated before one of the stopping criteria is reached.\nIf the initial design is very large or the model evaluations are very time-consuming, the runtime will be larger than the MAX_TIME value.\n\n\n\nBased on the INIT_SIZE, the number of hyperparameter configurations for the initial design can be specified. The initial design is evaluated before the first surrogate model is built. A detailed description of the initial design and the surrogate model based hyperparameter tuning can be found in Bartz-Beielstein (2024a) and in Bartz-Beielstein and Zaefferer (2022). The spotpython package is used for the hyperparameter tuning process. It implements a robust surrogate model based optimization method (Forrester, Sóbester, and Keane 2008).\nThe PREFIX parameter can be used to specify the experiment name.\nThe spotpython hyperparameter tuning program allows the user to specify several options for the hyperparameter tuning process. The spotRiverGUI will support more options in future versions. Currently, the user can specify whether the outcome from the experiment is noisy or deterministic. The corresponding parameter is called NOISE. The reader is referred to Bartz-Beielstein (2024b) and to the chapter “Handling Noise” (https://sequential-parameter-optimization.github.io/Hyperparameter-Tuning-Cookbook/013_num_spot_noisy.html) for further information about the NOISE parameter.\n\n\n22.3.3 Evaluation Options\nThe user can select one of the following evaluation metrics for binary classification tasks from the metric drop-down menu:\n\naccuracy_score\ncohen_kappa_score\nf1_score\nhamming_loss\nhinge_loss\njaccard_score\nmatthews_corrcoef\nprecision_score\nrecall_score\nroc_auc_score\nzero_one_loss\n\nThese metrics are based on the scikit-learn module (Pedregosa et al. 2011), which implements several loss, score, and utility functions to measure classification performance, see https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics. spotRiverGUI supports metrics that are computed from the y_pred and the y_true values. The y_pred values are the predicted target values, and the y_true values are the true target values. The y_pred values are generated by the online machine learning model, and the y_true values are the true target values from the data set.\n\n\n\n\n\n\nEvaluation Metrics: Minimization and Maximization\n\n\n\n\nSome metrics are minimized, and some are maximized. The spotRiverGUI will support the user in selecting the correct metric based on the task. For example, the accuracy_score is maximized, and the hamming_loss is minimized. The user can select the metric and spotRiverGUI will automatically determine whether the metric is minimized or maximized.\n\n\n\nIn addition to the evaluation metric results, spotriver considers the time and memory consumption of the online machine learning model. The spotRiverGUI will support the user in selecting the time and memory consumption as additional evaluation metrics. By modifying the weight vector, which is shown in the weights: y, time, mem field, the user can specify the importance of the evaluation metrics. For example, the weight vector 1,0,0 specifies that only the y metric (e.g., accuracy) is considered. The weight vector 0,1,0 specifies that only the time metric is considered. The weight vector 0,0,1 specifies that only the memory metric is considered. The weight vector 1,1,1 specifies that all metrics are considered. Any real values (also negative ones) are allowed for the weights.\n\n\n\n\n\n\nThe weight vector\n\n\n\n\nThe specification of adequate weights is highly problem dependent.\nThere is no generic setting that fits to all problems.\n\n\n\nAs described in Bartz-Beielstein (2024a), a prediction horizon is used for the comparison of the online-machine learning algorithms. The horizon can be specified in the spotRiverGUI by the user and is highly problem dependent. The spotRiverGUI uses the eval_oml_horizon method from the spotriver package, which evaluates the online-machine learning model on a rolling horizon basis.\nIn addition to the horizon value, the user can specify the oml_grace_period value. During the oml_grace_period, the OML-model is trained on the (small) training data set. No predictions are made during this initial training phase, but the memory and computation time are measured. Then, the OML-model is evaluated on the test data set using a given (sklearn) evaluation metric. The default value of the oml_grace_period is horizon. For convenience, the value horizon is also selected when the user specifies the oml_grace_period value as None.\n\n\n\n\n\n\nThe oml_grace_period\n\n\n\n\nIf the oml_grace_period is set to the size of the training data set, the OML-model is trained on the entire training data set and then evaluated on the test data set using a given (sklearn) evaluation metric.\nThis setting might be “unfair” in some cases, because the OML-model should learn online and not on the entire training data set.\nTherefore, a small data set is recommended for the oml_grace_period setting and the prediction horizon is a recommended value for the oml_grace_period setting. The reader is referred to Bartz-Beielstein (2024a) for further information about the oml_grace_period setting.\n\n\n\n\n\n22.3.4 Online Machine Learning Model Options\nThe user can select one of the following online machine learning models from the coremodel drop-down menu:\n\nforest.AMFClassifier: Aggregated Mondrian Forest classifier for online learning (Mourtada, Gaiffas, and Scornet 2019). This implementation is truly online, in the sense that a single pass is performed, and that predictions can be produced anytime. More: https://riverml.xyz/dev/api/forest/AMFClassifier/.\ntree.ExtremelyFastDecisionTreeClassifier: Extremely Fast Decision Tree (EFDT) classifier (Manapragada, Webb, and Salehi 2018). Also referred to as the Hoeffding AnyTime Tree (HATT) classifier. In practice, despite the name, EFDTs are typically slower than a vanilla Hoeffding Tree to process data. More: https://riverml.xyz/dev/api/tree/ExtremelyFastDecisionTreeClassifier/.\ntree.HoeffdingTreeClassifier: Hoeffding Tree or Very Fast Decision Tree classifier (Bifet et al. 2010a; Domingos and Hulten 2000). More: https://riverml.xyz/dev/api/tree/HoeffdingTreeClassifier/.\ntree.HoeffdingAdaptiveTreeClassifier: Hoeffding Adaptive Tree classifier (Bifet and Gavaldà 2009). More: https://riverml.xyz/dev/api/tree/HoeffdingAdaptiveTreeClassifier/.\nlinear_model.LogisticRegression: Logistic regression classifier. More: hhttps://riverml.xyz/dev/api/linear-model/LogisticRegression/.\n\nThe spotRiverGUI automatically determines the hyperparameters for the selected online machine learning model and adapts the input fields to the model hyperparameters. The user can modify the hyperparameters in the GUI. Figure 22.2 shows the spotRiverGUI when the forest.AMFClassifier is selected and Figure 22.3 shows the spotRiverGUI when the tree.HoeffdingTreeClassifier is selected.\n\n\n\n\n\n\nFigure 22.2: spotRiverGUI when forest.AMFClassifier is selected\n\n\n\n\n\n\n\n\n\nFigure 22.3: spotRiverGUI when tree.HoeffdingAdaptiveTreeClassifier is selected\n\n\n\nNumerical and categorical hyperparameters are treated differently in the spotRiverGUI:\n\nThe user can modify the lower and upper bounds for the numerical hyperparameters.\nThere are no upper or lower bounds for categorical hyperparameters. Instead, hyperparameter values for the categorical hyperparameters are considered as sets of values, e.g., the set of ExhaustiveSplitter, HistogramSplitter, GaussianSplitter is provided for the splitter hyperparameter of the tree.HoeffdingAdaptiveTreeClassifier model as can be seen in Figure 22.3. The user can select the full set or any subset of the set of values for the categorical hyperparameters.\n\nIn addition to the lower and upper bounds (or the set of values for the categorical hyperparameters), the spotRiverGUI provides information about the Default values and the Transformation function. If the Transformation function is set to None, the values of the hyperparameters are passed to the spot tuner as they are. If the Transformation function is set to transform_power_2_int, the value \\(x\\) is transformed to \\(2^x\\) before it is passed to the spot tuner.\nModifications of the Default values and Transformation functions values in the spotRiverGUI have no effect on the hyperparameter tuning process. This is intensional. In future versions, the user will be able to add their own hyperparameter dictionaries to the spotRiverGUI, which allows the modification of Default values and Transformation functions values. Furthermore, the spotRiverGUI will support more online machine learning models in future versions.",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Simplifying Hyperparameter Tuning in Online Machine Learning---The spotRiverGUI</span>"
    ]
  },
  {
    "objectID": "501_spot_river_gui.html#sec-regression",
    "href": "501_spot_river_gui.html#sec-regression",
    "title": "22  Simplifying Hyperparameter Tuning in Online Machine Learning—The spotRiverGUI",
    "section": "22.4 Regression",
    "text": "22.4 Regression\nRegression tasks will be supported soon. The same workflow as for the binary classification task will be used, i.e., the user can select the data set, the preprocessing model, the metric, and the online machine learning model.",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Simplifying Hyperparameter Tuning in Online Machine Learning---The spotRiverGUI</span>"
    ]
  },
  {
    "objectID": "501_spot_river_gui.html#sec-showing-data",
    "href": "501_spot_river_gui.html#sec-showing-data",
    "title": "22  Simplifying Hyperparameter Tuning in Online Machine Learning—The spotRiverGUI",
    "section": "22.5 Showing the Data",
    "text": "22.5 Showing the Data\nThe spotRiverGUI provides the Show Data button, which opens a new window and shows information about the data set. The first figure (Figure 22.4) shows histograms of the target variables in the train and test data sets. The second figure (Figure 22.5) shows scatter plots of the features in the train data set. The third figure (Figure 22.6) shows the corresponding scatter plots of the features in the test data set.\n\n\n\n\n\n\nFigure 22.4: Output from the spotRiverGUI when Bananas data is selected for the Show Data option\n\n\n\n\n\n\n\n\n\nFigure 22.5: Visualization of the train data. Output from the spotRiverGUI when Bananas data is selected for the Show Data option\n\n\n\n\n\n\n\n\n\nFigure 22.6: Visualization of the test data. Output from the spotRiverGUI when Bananas data is selected for the Show Data option\n\n\n\n\n\n\n\n\n\nSize of the Displayed Data Sets\n\n\n\n\nSome data sets are quite large and the display of the data sets might take some time.\nTherefore, a random subset of 1000 instances of the data set is displayed if the data set is larger than 1000 instances.\n\n\n\nShowing the data is important, especially for the new / unknown data sets as can be seen in Figure 22.7, Figure 22.8, and Figure 22.9: The target variable is highly biased. The user can check whether the data set is correctly formatted and whether the target variable is correctly specified.\n\n\n\n\n\n\nFigure 22.7: Output from the spotRiverGUI when HTTP data is selected for the Show Data option. The target variable is biased.\n\n\n\n\n\n\n\n\n\nFigure 22.8: Output from the spotRiverGUI when HTTP data is selected for the Show Data option. A subset of 1000 randomly chosen data points is shown. Only a few positive events are in the data.\n\n\n\n\n\n\n\n\n\nFigure 22.9: Output from the spotRiverGUI when HTTP data is selected for the Show Data option. The test data set shows the same structure as the train data set.\n\n\n\nIn addition to the histograms and scatter plots, the spotRiverGUI provides textual information about the data set in the console window. e.g., for the Bananas data set, the following information is shown:\nTrain data summary:\n                 x1           x2            y\ncount  3710.000000  3710.000000  3710.000000\nmean     -0.016243     0.002430     0.451482\nstd       0.995490     1.001150     0.497708\nmin      -3.089839    -2.385937     0.000000\n25%      -0.764512    -0.914144     0.000000\n50%      -0.027259    -0.033754     0.000000\n75%       0.745066     0.836618     1.000000\nmax       2.754447     2.517112     1.000000\n\nTest data summary:\n                 x1           x2            y\ncount  1590.000000  1590.000000  1590.000000\nmean      0.037900    -0.005670     0.440881\nstd       1.009744     0.997603     0.496649\nmin      -2.980834    -2.199138     0.000000\n25%      -0.718710    -0.911151     0.000000\n50%       0.034858    -0.046502     0.000000\n75%       0.862049     0.806506     1.000000\nmax       2.813360     3.194302     1.000000",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Simplifying Hyperparameter Tuning in Online Machine Learning---The spotRiverGUI</span>"
    ]
  },
  {
    "objectID": "501_spot_river_gui.html#sec-saving-loading",
    "href": "501_spot_river_gui.html#sec-saving-loading",
    "title": "22  Simplifying Hyperparameter Tuning in Online Machine Learning—The spotRiverGUI",
    "section": "22.6 Saving and Loading",
    "text": "22.6 Saving and Loading\n\n22.6.1 Saving the Experiment\nIf the experiment should not be started immediately, the user can save the experiment by clicking on the Save Experiment button. The spotRiverGUI will save the experiment as a pickle file. The file name is generated based on the PREFIX parameter. The pickle file contains a set of dictionaries, which are used to start the experiment.\nspotRiverGUI shows a summary of the selected hyperparameters in the console window as can be seen in Table 22.1.\n\n\n\nTable 22.1: The hyperparameter values for the tree.HoeffdingAdaptiveTreeClassifier model.\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\ntype\ndefault\nlower\nupper\ntransform\n\n\n\n\ngrace_period\nint\n200\n10\n1000\nNone\n\n\nmax_depth\nint\n20\n2\n20\ntransform_power_2_int\n\n\ndelta\nfloat\n1e-07\n1e-08\n1e-06\nNone\n\n\ntau\nfloat\n0.05\n0.01\n0.1\nNone\n\n\nleaf_prediction\nfactor\nnba\n0\n2\nNone\n\n\nnb_threshold\nint\n0\n0\n10\nNone\n\n\nsplitter\nfactor\nGaussianSplitter\n0\n2\nNone\n\n\nbootstrap_sampling\nfactor\n0\n0\n1\nNone\n\n\ndrift_window_threshold\nint\n300\n100\n500\nNone\n\n\ndrift_detector\nfactor\nADWIN\n0\n0\nNone\n\n\nswitch_significance\nfloat\n0.05\n0.01\n0.1\nNone\n\n\nbinary_split\nfactor\n0\n0\n1\nNone\n\n\nmax_size\nfloat\n100.0\n100\n1000\nNone\n\n\nmemory_estimate_period\nint\n1000000\n100000\n1e+06\nNone\n\n\nstop_mem_management\nfactor\n0\n0\n1\nNone\n\n\nremove_poor_attrs\nfactor\n0\n0\n1\nNone\n\n\nmerit_preprune\nfactor\n0\n0\n1\nNone\n\n\n\n\n\n\n\n\n22.6.2 Loading an Experiment\nFuture versions of the spotRiverGUI will support the loading of experiments from the GUI. Currently, the user can load the experiment by executing the command load_experiment, see https://sequential-parameter-optimization.github.io/spotpython/reference/spotpython/utils/file/#spotpython.utils.file.load_experiment.",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Simplifying Hyperparameter Tuning in Online Machine Learning---The spotRiverGUI</span>"
    ]
  },
  {
    "objectID": "501_spot_river_gui.html#sec-running-experiment",
    "href": "501_spot_river_gui.html#sec-running-experiment",
    "title": "22  Simplifying Hyperparameter Tuning in Online Machine Learning—The spotRiverGUI",
    "section": "22.7 Running a New Experiment",
    "text": "22.7 Running a New Experiment\nAn experiment can be started by clicking on the Run Experiment button. The GUI calls run_spot_python_experiment from spotGUI.tuner.spotRun. Output will be shown in the console window from which the GUI was started.\n\n22.7.1 Starting and Stopping Tensorboard\nTensorboard (Abadi et al. 2016) is automatically started when an experiment is started. The tensorboard process can be observed in a browser by opening the http://localhost:6006 page. Tensorboard provides a visual representation of the hyperparameter tuning process. Figure 22.10 and Figure 22.11 show the tensorboard page when the spotRiverGUI is performing the tuning process.\n\n\n\n\n\n\nFigure 22.10: Tensorboard visualization of the hyperparameter tuning process\n\n\n\n\n\n\n\n\n\nFigure 22.11: Tensorboard. Parallel coordinates plot\n\n\n\nspotpython.utils.tensorboard provides the methods start_tensorboard and stop_tensorboard to start and stop tensorboard as a background process. After the experiment is finished, the tensorboard process is stopped automatically.",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Simplifying Hyperparameter Tuning in Online Machine Learning---The spotRiverGUI</span>"
    ]
  },
  {
    "objectID": "501_spot_river_gui.html#sec-analysis",
    "href": "501_spot_river_gui.html#sec-analysis",
    "title": "22  Simplifying Hyperparameter Tuning in Online Machine Learning—The spotRiverGUI",
    "section": "22.8 Performing the Analysis",
    "text": "22.8 Performing the Analysis\nIf the hyperparameter tuning process is finished, the user can analyze the results by clicking on the Analysis button. The following options are available:\n\nProgress plot\nCompare tuned versus default hyperparameters\nImportance of hyperparameters\nContour plot\nParallel coordinates plot\n\nFigure 22.12 shows the progress plot of the hyperparameter tuning process. Black dots denote results from the initial design. Red dots illustrate the improvement found by the surrogate model based optimization. For binary classification tasks, the roc_auc_score can be used as the evaluation metric. The confusion matrix is shown in Figure 22.13. The default versus tuned hyperparameters are shown in Figure 22.14. The surrogate plot is shown in Figure 22.15, Figure 22.16, and Figure 22.17.\n\n\n\n\n\n\nFigure 22.12: Progress plot of the hyperparameter tuning process\n\n\n\n\n\n\n\n\n\nFigure 22.13: Confusion matrix\n\n\n\n\n\n\n\n\n\nFigure 22.14: Default versus tuned hyperparameters\n\n\n\n\n\n\n\n\n\nFigure 22.15: Surrogate plot based on the Kriging model. x0 and x1 plotted against each other.\n\n\n\n\n\n\n\n\n\nFigure 22.16: Surrogate plot based on the Kriging model. x1 and x2 plotted against each other.\n\n\n\n\n\n\n\n\n\nFigure 22.17: Surrogate plot based an the Kriging model. x0 and x2 plotted against each other.\n\n\n\nFurthermore, the tuned hyperparameters are shown in the console window. A typical output is shown below (modified due to formatting reasons):\n|name    |type   |default |low | up |tuned |transf |importance|stars|\n|--------|-------|--------|----|----|------|-------|----------|-----|\n|n_estim |int    |    3.0 |2.0 |7.0 |  3.0 | pow_2 |      0.04|     |\n|step    |float  |    1.0 |0.1 |10.0|  5.12| None  |      0.21| .   |\n|use_agg |factor |    1.0 |0.0 |1.0 |  0.0 | None  |     10.17| *   |\n|dirichl |float  |    0.5 |0.1 |0.75|  0.37| None  |     13.64| *   |\n|split_p |factor |    0.0 |0.0 |1.0 |  0.0 | None  |    100.00| *** |\nIn addition to the tuned parameters that are shown in the column tuned, the columns importance and stars are shown. Both columns show the most important hyperparameters based on information from the surrogate model. The stars column shows the importance of the hyperparameters in a graphical way. It is important to note that the results are based on a demo of the hyperparameter tuning process. The plots are not based on a real hyperparameter tuning process. The reader is referred to Bartz-Beielstein (2024b) for further information about the analysis of the hyperparameter tuning process.",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Simplifying Hyperparameter Tuning in Online Machine Learning---The spotRiverGUI</span>"
    ]
  },
  {
    "objectID": "501_spot_river_gui.html#sec-summary",
    "href": "501_spot_river_gui.html#sec-summary",
    "title": "22  Simplifying Hyperparameter Tuning in Online Machine Learning—The spotRiverGUI",
    "section": "22.9 Summary and Outlook",
    "text": "22.9 Summary and Outlook\nThe spotRiverGUI provides a graphical user interface for the spotriver package. It releases the user from the burden of manually searching for the optimal hyperparameter setting. After copying a data set into the userData folder and starting spotRiverGUI, users can compare different OML algorithms from the powerful river package in a convenient way. Users can generate configurations on their local machines, which can be transferred to a remote machine for execution. Results from the remote machine can be copied back to the local machine for analysis.\n\n\n\n\n\n\nBenefits of the spotRiverGUI:\n\n\n\n\nVery easy to use (only the data must be provided in the correct format).\nReproducible results.\nState-of-the-art hyperparameter tuning methods.\nPowerful analysis tools, e.g., Bayesian optimization (Forrester, Sóbester, and Keane 2008; Gramacy 2020).\nVisual representation of the hyperparameter tuning process with tensorboard.\nMost advanced online machine learning models from the river package.\n\n\n\nThe river package (Montiel et al. 2021), which is very well documented, can be downloaded from https://riverml.xyz/latest/.\nThe spotRiverGUI is under active development and new features will be added soon. It can be downloaded from GitHub: https://github.com/sequential-parameter-optimization/spotGUI.\nInteractive Jupyter Notebooks and further material about OML are provided in the GitHub repository https://github.com/sn-code-inside/online-machine-learning. This material is part of the supplementary material of the book “Online Machine Learning - A Practical Guide with Examples in Python”, see https://link.springer.com/book/9789819970063 and the forthcoming book “Online Machine Learning - Eine praxisorientierte Einführung”, see https://link.springer.com/book/9783658425043.",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Simplifying Hyperparameter Tuning in Online Machine Learning---The spotRiverGUI</span>"
    ]
  },
  {
    "objectID": "501_spot_river_gui.html#sec-appendix",
    "href": "501_spot_river_gui.html#sec-appendix",
    "title": "22  Simplifying Hyperparameter Tuning in Online Machine Learning—The spotRiverGUI",
    "section": "22.10 Appendix",
    "text": "22.10 Appendix\n\n22.10.1 Adding new Tasks\nCurrently, three tasks are supported in the spotRiverGUI: Binary Classification, Regression, and Rules. Rules was added in ver 0.6.0. Here, we document how this task updated was implemented. Adding an additional task requires modifications in the following files:\n\nspotRun.py:\n\nThe riverclass rules must be imported, i.e., from river import forest, tree, linear_model, rules.\nThe method get_river_rules_core_model_names() must be modified.\nThe get_scenario_dict() method must be modified.\n\nCTk.py:\n\nThe task_frame must be extended.\nThe change_task_event() method must be modified.\n\n\nIn addition, the hyperparameter dictionary in spotriver must be updated. This is the only modification required in the spotriverpackage.\n\n\n\n\nAbadi, Martin, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, et al. 2016. “TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems.” arXiv e-Prints, March, arXiv:1603.04467.\n\n\nAggarwal, Charu, ed. 2007. Data Streams – Models and Algorithms. Springer-Verlag.\n\n\nBartz-Beielstein, Thomas. 2024a. “Evaluation and Performance Measurement.” In, edited by Eva Bartz and Thomas Bartz-Beielstein, 47–62. Singapore: Springer Nature Singapore.\n\n\n———. 2024b. “Hyperparameter Tuning.” In, edited by Eva Bartz and Thomas Bartz-Beielstein, 125–40. Singapore: Springer Nature Singapore.\n\n\n———. 2024c. “Introduction: From Batch to Online Machine Learning.” In Online Machine Learning: A Practical Guide with Examples in Python, edited by Eva Bartz and Thomas Bartz-Beielstein, 1–11. Singapore: Springer Nature Singapore. https://doi.org/10.1007/978-981-99-7007-0_1.\n\n\nBartz-Beielstein, Thomas, and Lukas Hans. 2024. “Drift Detection and Handling.” In Online Machine Learning: A Practical Guide with Examples in Python, edited by Eva Bartz and Thomas Bartz-Beielstein, 23–39. Singapore: Springer Nature Singapore. https://doi.org/10.1007/978-981-99-7007-0_3.\n\n\nBartz-Beielstein, Thomas, and Martin Zaefferer. 2022. “Hyperparameter Tuning Approaches.” In Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide, edited by Eva Bartz, Thomas Bartz-Beielstein, Martin Zaefferer, and Olaf Mersmann, 67–114. Springer.\n\n\nBifet, Albert. 2010. Adaptive Stream Mining: Pattern Learning and Mining from Evolving Data Streams. Vol. 207. Frontiers in Artificial Intelligence and Applications. IOS Press.\n\n\nBifet, Albert, and Ricard Gavaldà. 2007. “Learning from Time-Changing Data with Adaptive Windowing.” In Proceedings of the 2007 SIAM International Conference on Data Mining (SDM), 443–48.\n\n\n———. 2009. “Adaptive Learning from Evolving Data Streams.” In Proceedings of the 8th International Symposium on Intelligent Data Analysis: Advances in Intelligent Data Analysis VIII, 249–60. IDA ’09. Berlin, Heidelberg: Springer-Verlag.\n\n\nBifet, Albert, Geoff Holmes, Richard Kirkby, and Bernhard Pfahringer. 2010a. “MOA: Massive Online Analysis.” Journal of Machine Learning Research 99: 1601–4.\n\n\n———. 2010b. “MOA: Massive Online Analysis.” Journal of Machine Learning Research 11: 1601–4.\n\n\nDomingos, Pedro M., and Geoff Hulten. 2000. “Mining High-Speed Data Streams.” In Proceedings of the Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Boston, MA, USA, August 20-23, 2000, edited by Raghu Ramakrishnan, Salvatore J. Stolfo, Roberto J. Bayardo, and Ismail Parsa, 71–80. ACM.\n\n\nDredze, Mark, Tim Oates, and Christine Piatko. 2010. “We’re Not in Kansas Anymore: Detecting Domain Changes in Streams.” In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, 585–95.\n\n\nForrester, Alexander, András Sóbester, and Andy Keane. 2008. Engineering Design via Surrogate Modelling. Wiley.\n\n\nGaber, Mohamed Medhat, Arkady Zaslavsky, and Shonali Krishnaswamy. 2005. “Mining Data Streams: A Review.” SIGMOD Rec. 34: 18–26.\n\n\nGama, João, Pedro Medas, Gladys Castillo, and Pedro Rodrigues. 2004. “Learning with Drift Detection.” In Advances in Artificial Intelligence – SBIA 2004, edited by Ana L. C. Bazzan and Sofiane Labidi, 286–95. Berlin, Heidelberg: Springer Berlin Heidelberg.\n\n\nGama, João, Raquel Sebastião, and Pedro Pereira Rodrigues. 2013. “On Evaluating Stream Learning Algorithms.” Machine Learning 90 (3): 317–46.\n\n\nGramacy, Robert B. 2020. Surrogates. CRC press.\n\n\nHoeglinger, Stefan, and Russel Pears. 2007. “Use of Hoeffding Trees in Concept Based Data Stream Mining.” 2007 Third International Conference on Information and Automation for Sustainability, 57–62.\n\n\nIkonomovska, Elena. 2012. “Algorithms for Learning Regression Trees and Ensembles on Evolving Data Streams.” PhD thesis, Jozef Stefan International Postgraduate School.\n\n\nKeller-McNulty, Sallie, ed. 2004. Statistical Analysis of Massive Data Streams: Proceedings of a Workshop. Washington, DC: Committee on Applied; Theoretical Statistics, National Research Council; National Academies Press.\n\n\nManapragada, Chaitanya, Geoffrey I. Webb, and Mahsa Salehi. 2018. “Extremely Fast Decision Tree.” In KDD’ 2018 - Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, edited by Chih-Jen Lin and Hui Xiong, 1953–62. United States of America: Association for Computing Machinery (ACM). https://doi.org/10.1145/3219819.3220005.\n\n\nMasud, Mohammad, Jing Gao, Latifur Khan, Jiawei Han, and Bhavani M Thuraisingham. 2011. “Classification and Novel Class Detection in Concept-Drifting Data Streams Under Time Constraints.” IEEE Transactions on Knowledge and Data Engineering 23 (6): 859–74.\n\n\nMontiel, Jacob, Max Halford, Saulo Martiello Mastelini, Geoffrey Bolmier, Raphael Sourty, Robin Vaysse, Adil Zouitine, et al. 2021. “River: Machine Learning for Streaming Data in Python.”\n\n\nMourtada, Jaouad, Stephane Gaiffas, and Erwan Scornet. 2019. “AMF: Aggregated Mondrian Forests for Online Learning.” arXiv e-Prints, June, arXiv:1906.10529. https://doi.org/10.48550/arXiv.1906.10529.\n\n\nPedregosa, F., G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, et al. 2011. “Scikit-Learn: Machine Learning in Python.” Journal of Machine Learning Research 12: 2825–30.\n\n\nPutatunda, Sayan. 2021. Practical Machine Learning for Streaming Data with Python. Springer.\n\n\nStreet, W. Nick, and YongSeog Kim. 2001. “A Streaming Ensemble Algorithm (SEA) for Large-Scale Classification.” In Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 377–82. KDD ’01. New York, NY, USA: Association for Computing Machinery.",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Simplifying Hyperparameter Tuning in Online Machine Learning---The spotRiverGUI</span>"
    ]
  },
  {
    "objectID": "502_spot_hpt_river_friedman_htr.html",
    "href": "502_spot_hpt_river_friedman_htr.html",
    "title": "23  river Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data",
    "section": "",
    "text": "23.1 The Friedman Drift Data Set\nWe will use the Friedman synthetic dataset with concept drifts, which is described in detail in Section E.2. The following parameters are used to generate and handle the data set:\nWe will use spotriver’s convert_to_df function [SOURCE] to convert the river data set to a pandas data frame. Then we add column names x1 until x10 to the first 10 columns of the dataframe and the column name y to the last column of the dataframe.\nThis data generation is independently repeated for the training and test data sets, because the data sets are generated with concept drifts and the usual train-test split would not work.\nfrom river.datasets import synth\nimport pandas as pd\nimport numpy as np\nfrom spotriver.utils.data_conversion import convert_to_df\n\nn_train = 6_000\nn_test = 4_000\nn_samples = n_train + n_test\ntarget_column = \"y\"\n\ndataset = synth.FriedmanDrift(\n   drift_type='gra',\n   position=(n_train/4, n_train/2),\n   seed=123\n)\n\ntrain = convert_to_df(dataset, n_total=n_train)\ntrain.columns = [f\"x{i}\" for i in range(1, 11)] + [target_column]\ndataset = synth.FriedmanDrift(\n   drift_type='gra',\n   position=(n_test/4, n_test/2),\n   seed=123\n)\ntest = convert_to_df(dataset, n_total=n_test)\ntest.columns = [f\"x{i}\" for i in range(1, 11)] + [target_column]\nWe combine the train and test data sets and save them to a csv file.\ndf = pd.concat([train, test])\ndf.to_csv(\"./userData/friedman.csv\", index=False)\nThe Friedman Drift data set described in this section is avaialble as a csv data file and can be downloaded from github: friedman.csv.",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>`river` Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data</span>"
    ]
  },
  {
    "objectID": "502_spot_hpt_river_friedman_htr.html#sec-the-friedman-drift-data-set-24",
    "href": "502_spot_hpt_river_friedman_htr.html#sec-the-friedman-drift-data-set-24",
    "title": "23  river Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data",
    "section": "",
    "text": "position: The positions of the concept drifts.\nn_train: The number of samples used for training.\nn_test: The number of samples used for testing.\nseed: The seed for the random number generator.\ntarget_column: The name of the target column.\ndrift_type: The type of the concept drift.\n\n\n\n\n\n\n\n\n\n\n\nThe Data Set\n\n\n\nData sets that are available as pandas dataframes can easily be passed to the spot hyperparameter tuner. spotpython requires a train and a test data set, where the column names must be identical.",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>`river` Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data</span>"
    ]
  },
  {
    "objectID": "502_spot_hpt_river_friedman_htr.html#sec-setup-24",
    "href": "502_spot_hpt_river_friedman_htr.html#sec-setup-24",
    "title": "23  river Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data",
    "section": "23.2 Setup",
    "text": "23.2 Setup\n\n23.2.1 General Experiment Setup\nTo keep track of the different experiments, we use a PREFIX for the experiment name. The PREFIX is used to create a unique experiment name. The PREFIX is also used to create a unique TensorBoard folder, which is used to store the TensorBoard log files.\nspotpython allows the specification of two different types of stopping criteria: first, the number of function evaluations (fun_evals), and second, the maximum run time in seconds (max_time). Here, we will set the number of function evaluations to infinity and the maximum run time to one minute.\nFurthermore, we set the initial design size (init_size) to 10. The initial design is used to train the surrogate model. The surrogate model is used to predict the performance of the hyperparameter configurations. The initial design is also used to train the first model. Since the init_size belongs to the experimental design, it is set in the design_control dictionary, see [SOURCE].\nmax_time is set to one minute for demonstration purposes and init_size is set to 10 for demonstration purposes. For real experiments, these values should be increased. Note, the total run time may exceed the specified max_time, because the initial design is always evaluated, even if this takes longer than max_time.\n\n\n\n\n\n\nSummary: General Experiment Setup\n\n\n\nThe following parameters are used to specify the general experiment setup:\n\nPREFIX = \"024\"\nfun_evals = inf\nmax_time = 1\ninit_size = 10\n\n\n\n\n\n23.2.2 Data Setup\nWe use the StandardScaler [SOURCE] from river as the data-preprocessing model. The StandardScaler is used to standardize the data set, i.e., it has zero mean and unit variance.\nThe names of the training and test data sets are train and test, respectively. They are available as pandas dataframes. Both must use the same column names. The column names were set to x1 to x10 for the features and y for the target column during the data set generation in Section 23.1. Therefore, the target_column is set to y (as above).\n\n\n\n\n\n\nSummary: Data Setup\n\n\n\nThe following parameters are used to specify the data setup:\n\nprep_model_name = \"StandardScaler\"\ntest = test\ntrain = train\ntarget_column = \"y\"\n\n\n\n\n\n23.2.3 Evaluation Setup\nHere we use the mean_absolute_error [SOURCE] as the evaluation metric. Internally, this metric is passed to the objective (or loss) function fun_oml_horizon [SOURCE] and further to the evaluation function eval_oml_horizon [SOURCE].\nspotriver also supports additional metrics. For example, the metric_river is used for the river based evaluation via eval_oml_iter_progressive [SOURCE]. The metric_river is implemented to simulate the behaviour of the “original” river metrics.\n\n\n\n\n\n\nSummary: Evaluation Setup\n\n\n\nThe following parameter are used to select the evaluation metric:\n\nmetric_sklearn_name = \"mean_absolute_error\"\n\n\n\n\n\n23.2.4 River-Specific Setup\nIn the online-machine-learning (OML) setup, the model is trained on a fixed number of observations and then evaluated on a fixed number of observations. The horizon defines the number of observations that are used for the evaluation. Here, a horizon of 7*24 is used, which corresponds to one week of data.\nThe oml_grace_period defines the number of observations that are used for the initial training of the model. This value is relatively small, since the online-machine-learning is trained on the incoming data and the model is updated continuously. However, it needs a certain number of observations to start the training process. Therefore, this short training period aka oml_grace_period is set to the horizon, i.e., the number of observations that are used for the evaluation. In this case, we use a horizon of 7*24.\nThe weights provide a flexible way to define specific requirements, e.g., if the memory is more important than the time, the weight for the memory can be increased. spotriver stores information about the model’ s score (metric), memory, and time. The hyperparamter tuner requires a single objective. Therefore, a weighted sum of the metric, memory, and time is computed. The weights are defined in the weights array. The weights provide a flexible way to define specific requirements, e.g., if the memory is more important than the time, the weight for the memory can be increased.\nThe weight_coeff defines a multiplier for the results: results are multiplied by (step/n_steps)**weight_coeff, where n_steps is the total number of iterations. Results from the beginning have a lower weight than results from the end if weight_coeff &gt; 1. If weight_coeff == 0, all results have equal weight. Note, that the weight_coeff is only used internally for the tuner and does not affect the results that are used for the evaluation or comparisons.\n\n\n\n\n\n\nSummary: River-Specific Setup\n\n\n\nThe following parameters are used:\n\nhorizon = 7*24\noml_grace_period = 7*24\nweights = np.array([1, 0.01, 0.01])\nweight_coeff = 0.0\n\n\n\n\n\n23.2.5 Model Setup\nBy using core_model_name = \"tree.HoeffdingTreeRegressor\", the river model class HoeffdingTreeRegressor [SOURCE] from the tree module is selected. For a given core_model_name, the corresponding hyperparameters are automatically loaded from the associated dictionary, which is stored as a JSON file. The JSON file contains hyperparameter type information, names, and bounds. For river models, the hyperparameters are stored in the RiverHyperDict, see [SOURCE]\nAlternatively, you can load a local hyper_dict. Simply set river_hyper_dict.json as the filename. If filenameis set to None, which is the default, the hyper_dict [SOURCE] is loaded from the spotriver package.\nHow hyperparameter levels can be modified is described in Section D.15.1.\n\n\n\n\n\n\nSummary: Model Setup\n\n\n\nThe following parameters are used for the model setup:\n\nfrom spotriver.fun.hyperriver import HyperRiver\nfrom spotriver.hyperdict.river_hyper_dict import RiverHyperDict\ncore_model_name = \"tree.HoeffdingTreeRegressor\"\nhyperdict = RiverHyperDict\n\n\n\n\n\n23.2.6 Objective Function Setup\nThe loss function (metric) values are passed to the objective function fun_oml_horizon [SOURCE], which combines information about the loss, required memory and time as described in Section 23.2.4.\n\n\n\n\n\n\nSummary: Objective Function Setup\n\n\n\nThe following parameters are used:\n\nfun = HyperRiver().fun_oml_horizon\n\n\n23.2.7 Surrogate Model Setup\nThe default surrogate model is the Kriging model, see [SOURCE]. We specify noise as True to include noise in the model. An anisotropic kernel is used, which allows different length scales for each dimension, by setting n_theta = 2. Furthermore, the interval for the Lambda value is set to [1e-3, 1e2].\nThese parameters are set in the surrogate_control dictionary and therefore passed to the surrogate_control_init function [SOURCE].\n\nnoise = True\nn_theta = 2\nmin_Lambda = 1e-3\nmax_Lambda = 10\n\n\n\n\n\n\n23.2.8 Summary: Setting up the Experiment\nAt this stage, all required information is available to set up the dictionaries for the hyperparameter tuning. Altogether, the fun_control, design_control, surrogate_control, and optimize_control dictionaries are initialized as follows:\n\nfrom spotpython.utils.init import fun_control_init, design_control_init, surrogate_control_init, optimizer_control_init\n\nfun = HyperRiver().fun_oml_horizon\n\nfun_control = fun_control_init(\n    PREFIX=\"024\",\n    fun_evals=inf,\n    max_time=1,\n\n    prep_model_name=\"StandardScaler\",\n    test=test,\n    train=train,\n    target_column=target_column,\n\n    metric_sklearn_name=\"mean_absolute_error\",\n    horizon=7*24,\n    oml_grace_period=7*24,\n    weight_coeff=0.0,\n    weights=np.array([1, 0.01, 0.01]),\n\n    core_model_name=\"tree.HoeffdingTreeRegressor\",\n    hyperdict=RiverHyperDict,\n   )\n\n\ndesign_control = design_control_init(\n    init_size=10,\n)\n\nsurrogate_control = surrogate_control_init(\n    noise=True,\n    n_theta=2,\n    min_Lambda=1e-3,\n    max_Lambda=10,\n)\n\noptimizer_control = optimizer_control_init()\n\n\n\n23.2.9 Run the Spot Optimizer\nThe class Spot [SOURCE] is the hyperparameter tuning workhorse. It is initialized with the following parameters, which were specified above.\n\nfun: the objective function\nfun_control: the dictionary with the control parameters for the objective function\ndesign_control: the dictionary with the control parameters for the experimental design\nsurrogate_control: the dictionary with the control parameters for the surrogate model\noptimizer_control: the dictionary with the control parameters for the optimizer\n\nspotpython allows maximum flexibility in the definition of the hyperparameter tuning setup. Alternative surrogate models, optimizers, and experimental designs can be used. Thus, interfaces for the surrogate model, experimental design, and optimizer are provided. The default surrogate model is the kriging model, the default optimizer is the differential evolution, and default experimental design is the Latin hypercube design.\n\n\n\n\n\n\nSummary: Spot Setup\n\n\n\nThe following parameters are used for the Spot setup. These were specified above:\n\nfun = fun\nfun_control = fun_control\ndesign_control = design_control\nsurrogate_control = surrogate_control\noptimizer_control = optimizer_control\n\n\n\n\nfrom spotpython.spot import spot\nspot_tuner = spot.Spot(\n    fun=fun,\n    fun_control=fun_control,\n    design_control=design_control,\n    surrogate_control=surrogate_control,\n    optimizer_control=optimizer_control,\n)\nres = spot_tuner.run()\n\nspotpython tuning: 3.197669208422809 [----------] 1.96% \nspotpython tuning: 3.197669208422809 [----------] 3.46% \nspotpython tuning: 3.197669208422809 [#---------] 6.61% \nspotpython tuning: 3.197669208422809 [#---------] 8.09% \nspotpython tuning: 3.197669208422809 [#---------] 12.35% \nspotpython tuning: 3.197669208422809 [#---------] 13.93% \nspotpython tuning: 3.197669208422809 [##--------] 15.58% \nspotpython tuning: 2.1532812886809225 [##--------] 19.12% \nspotpython tuning: 2.1532812886809225 [###-------] 25.75% \nspotpython tuning: 2.1532812886809225 [####------] 40.72% \nspotpython tuning: 2.1532812886809225 [######----] 57.06% \nspotpython tuning: 2.1532812886809225 [#######---] 74.70% \nspotpython tuning: 2.1532812886809225 [##########] 97.31% \nspotpython tuning: 2.1532812886809225 [##########] 100.00% Done...",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>`river` Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data</span>"
    ]
  },
  {
    "objectID": "502_spot_hpt_river_friedman_htr.html#using-the-spotgui",
    "href": "502_spot_hpt_river_friedman_htr.html#using-the-spotgui",
    "title": "23  river Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data",
    "section": "23.3 Using the spotgui",
    "text": "23.3 Using the spotgui\nThe spotgui [github] provides a convenient way to interact with the hyperparameter tuning process. To obtain the settings from Section 23.2.8, the spotgui can be started as shown in Figure 26.1.\n\n\n\n\n\n\nFigure 23.1: spotgui",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>`river` Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data</span>"
    ]
  },
  {
    "objectID": "502_spot_hpt_river_friedman_htr.html#results",
    "href": "502_spot_hpt_river_friedman_htr.html#results",
    "title": "23  river Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data",
    "section": "23.4 Results",
    "text": "23.4 Results\nAfter the hyperparameter tuning run is finished, the progress of the hyperparameter tuning can be visualized with spotpython’s method plot_progress. The black points represent the performace values (score or metric) of hyperparameter configurations from the initial design, whereas the red points represents the hyperparameter configurations found by the surrogate model based optimization.\n\nspot_tuner.plot_progress(log_y=True, filename=None)\n\n\n\n\n\n\n\n\nResults can be printed in tabular form.\n\nfrom spotpython.utils.eda import gen_design_table\nprint(gen_design_table(fun_control=fun_control, spot=spot_tuner))\n\n| name                   | type   | default          |   lower |   upper | tuned                | transform              |   importance | stars   |\n|------------------------|--------|------------------|---------|---------|----------------------|------------------------|--------------|---------|\n| grace_period           | int    | 200              |    10.0 |  1000.0 | 525.0                | None                   |         0.00 |         |\n| max_depth              | int    | 20               |     2.0 |    20.0 | 9.0                  | transform_power_2_int  |         0.00 |         |\n| delta                  | float  | 1e-07            |   1e-08 |   1e-06 | 1e-08                | None                   |         0.12 | .       |\n| tau                    | float  | 0.05             |    0.01 |     0.1 | 0.018396269490502385 | None                   |         0.00 |         |\n| leaf_prediction        | factor | mean             |     0.0 |     2.0 | model                | None                   |         0.00 |         |\n| leaf_model             | factor | LinearRegression |     0.0 |     2.0 | LinearRegression     | None                   |        31.21 | *       |\n| model_selector_decay   | float  | 0.95             |     0.9 |    0.99 | 0.99                 | None                   |         0.02 |         |\n| splitter               | factor | EBSTSplitter     |     0.0 |     2.0 | TEBSTSplitter        | None                   |         0.00 |         |\n| min_samples_split      | int    | 5                |     2.0 |    10.0 | 4.0                  | None                   |         0.00 |         |\n| binary_split           | factor | 0                |     0.0 |     1.0 | 0                    | None                   |        85.81 | **      |\n| max_size               | float  | 500.0            |   100.0 |  1000.0 | 421.3969981171623    | None                   |         0.00 |         |\n| memory_estimate_period | int    | 6                |     3.0 |     8.0 | 6.0                  | transform_power_10_int |         0.00 |         |\n| stop_mem_management    | factor | 0                |     0.0 |     1.0 | 0                    | None                   |         0.00 |         |\n| remove_poor_attrs      | factor | 0                |     0.0 |     1.0 | 1                    | None                   |         0.00 |         |\n| merit_preprune         | factor | 1                |     0.0 |     1.0 | 1                    | None                   |       100.00 | ***     |\n\n\nA histogram can be used to visualize the most important hyperparameters.\n\nspot_tuner.plot_importance(threshold=10.0)",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>`river` Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data</span>"
    ]
  },
  {
    "objectID": "502_spot_hpt_river_friedman_htr.html#performance-of-the-model-with-default-hyperparameters",
    "href": "502_spot_hpt_river_friedman_htr.html#performance-of-the-model-with-default-hyperparameters",
    "title": "23  river Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data",
    "section": "23.5 Performance of the Model with Default Hyperparameters",
    "text": "23.5 Performance of the Model with Default Hyperparameters\n\n23.5.1 Get Default Hyperparameters and Fit the Model\nThe default hyperparameters, which will be used for a comparion with the tuned hyperparameters, can be obtained with the following commands:\n\nfrom spotpython.hyperparameters.values import get_default_hyperparameters_as_array\nX_start = get_default_hyperparameters_as_array(fun_control)\n\nspotpython tunes numpy arrays, i.e., the hyperparameters are stored in a numpy array.\n\nfrom spotpython.hyperparameters.values import get_one_core_model_from_X\nmodel_default = get_one_core_model_from_X(X_start, fun_control, default=True)\n\n\n\n23.5.2 Evaluate the Model with Default Hyperparameters\nThe model with the default hyperparameters can be trained and evaluated. The evaluation function eval_oml_horizon [SOURCE] is the same function that was used for the hyperparameter tuning. During the hyperparameter tuning, the evaluation function was called from the objective (or loss) function fun_oml_horizon [SOURCE].\n\nfrom spotriver.evaluation.eval_bml import eval_oml_horizon\n\ndf_eval_default, df_true_default = eval_oml_horizon(\n                    model=model_default,\n                    train=fun_control[\"train\"],\n                    test=fun_control[\"test\"],\n                    target_column=fun_control[\"target_column\"],\n                    horizon=fun_control[\"horizon\"],\n                    oml_grace_period=fun_control[\"oml_grace_period\"],\n                    metric=fun_control[\"metric_sklearn\"],\n                )\n\nThe three performance criteria, i.e., score (metric), runtime, and memory consumption, can be visualized with the following commands:\n\nfrom spotriver.evaluation.eval_bml import plot_bml_oml_horizon_metrics, plot_bml_oml_horizon_predictions\ndf_labels=[\"default\"]\nplot_bml_oml_horizon_metrics(df_eval = [df_eval_default], log_y=False, df_labels=df_labels, metric=fun_control[\"metric_sklearn\"])\n\n\n\n\n\n\n\n\n\n\n23.5.3 Show Predictions of the Model with Default Hyperparameters\n\nSelect a subset of the data set for the visualization of the predictions:\n\nWe use the mean, \\(m\\), of the data set as the center of the visualization.\nWe use 100 data points, i.e., \\(m \\pm 50\\) as the visualization window.\n\n\n\nm = fun_control[\"test\"].shape[0]\na = int(m/2)-50\nb = int(m/2)+50\nplot_bml_oml_horizon_predictions(df_true = [df_true_default[a:b]], target_column=target_column,  df_labels=df_labels)",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>`river` Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data</span>"
    ]
  },
  {
    "objectID": "502_spot_hpt_river_friedman_htr.html#get-spot-results",
    "href": "502_spot_hpt_river_friedman_htr.html#get-spot-results",
    "title": "23  river Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data",
    "section": "23.6 Get SPOT Results",
    "text": "23.6 Get SPOT Results\nIn a similar way, we can obtain the hyperparameters found by spotpython.\n\nfrom spotpython.hyperparameters.values import get_one_core_model_from_X\nX = spot_tuner.to_all_dim(spot_tuner.min_X.reshape(1,-1))\nmodel_spot = get_one_core_model_from_X(X, fun_control)\n\n\ndf_eval_spot, df_true_spot = eval_oml_horizon(\n                    model=model_spot,\n                    train=fun_control[\"train\"],\n                    test=fun_control[\"test\"],\n                    target_column=fun_control[\"target_column\"],\n                    horizon=fun_control[\"horizon\"],\n                    oml_grace_period=fun_control[\"oml_grace_period\"],\n                    metric=fun_control[\"metric_sklearn\"],\n                )\n\n\ndf_labels=[\"default\", \"spot\"]\nplot_bml_oml_horizon_metrics(df_eval = [df_eval_default, df_eval_spot], log_y=False, df_labels=df_labels, metric=fun_control[\"metric_sklearn\"])\n\n\n\n\n\n\n\n\n\nplot_bml_oml_horizon_predictions(df_true = [df_true_default[a:b], df_true_spot[a:b]], target_column=target_column,  df_labels=df_labels)\n\n\n\n\n\n\n\n\n\nfrom spotpython.plot.validation import plot_actual_vs_predicted\nplot_actual_vs_predicted(y_test=df_true_default[target_column], y_pred=df_true_default[\"Prediction\"], title=\"Default\")\nplot_actual_vs_predicted(y_test=df_true_spot[target_column], y_pred=df_true_spot[\"Prediction\"], title=\"SPOT\")",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>`river` Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data</span>"
    ]
  },
  {
    "objectID": "502_spot_hpt_river_friedman_htr.html#visualize-regression-trees",
    "href": "502_spot_hpt_river_friedman_htr.html#visualize-regression-trees",
    "title": "23  river Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data",
    "section": "23.7 Visualize Regression Trees",
    "text": "23.7 Visualize Regression Trees\n\ndataset_f = dataset.take(n_samples)\nprint(f\"n_samples: {n_samples}\")\nfor x, y in dataset_f:\n    model_default.learn_one(x, y)\n\nn_samples: 10000\n\n\n\n\n\n\n\n\nCaution: Large Trees\n\n\n\n\nSince the trees are large, the visualization is suppressed by default.\nTo visualize the trees, uncomment the following line.\n\n\n\n\n# model_default.draw()\n\n\nmodel_default.summary\n\n{'n_nodes': 23,\n 'n_branches': 11,\n 'n_leaves': 12,\n 'n_active_leaves': 12,\n 'n_inactive_leaves': 0,\n 'height': 7,\n 'total_observed_weight': 14168.0}\n\n\n\n23.7.1 Spot Model\n\nprint(f\"n_samples: {n_samples}\")\ndataset_f = dataset.take(n_samples)\nfor x, y in dataset_f:\n    model_spot.learn_one(x, y)\n\nn_samples: 10000\n\n\n\n\n\n\n\n\nCaution: Large Trees\n\n\n\n\nSince the trees are large, the visualization is suppressed by default.\nTo visualize the trees, uncomment the following line.\n\n\n\n\n# model_spot.draw()\n\n\nmodel_spot.summary\n\n{'n_nodes': 11,\n 'n_branches': 5,\n 'n_leaves': 6,\n 'n_active_leaves': 6,\n 'n_inactive_leaves': 0,\n 'height': 4,\n 'total_observed_weight': 14168.0}\n\n\n\nfrom spotpython.utils.eda import compare_two_tree_models\nprint(compare_two_tree_models(model_default, model_spot))\n\n| Parameter             |   Default |   Spot |\n|-----------------------|-----------|--------|\n| n_nodes               |        23 |     11 |\n| n_branches            |        11 |      5 |\n| n_leaves              |        12 |      6 |\n| n_active_leaves       |        12 |      6 |\n| n_inactive_leaves     |         0 |      0 |\n| height                |         7 |      4 |\n| total_observed_weight |     14168 |  14168 |",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>`river` Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data</span>"
    ]
  },
  {
    "objectID": "502_spot_hpt_river_friedman_htr.html#detailed-hyperparameter-plots",
    "href": "502_spot_hpt_river_friedman_htr.html#detailed-hyperparameter-plots",
    "title": "23  river Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data",
    "section": "23.8 Detailed Hyperparameter Plots",
    "text": "23.8 Detailed Hyperparameter Plots\n\nspot_tuner.plot_important_hyperparameter_contour(max_imp=3)\n\ngrace_period:  0.0015024268683762165\nmax_depth:  0.0015024268683762165\ndelta:  0.11806586417733643\ntau:  0.001502427239817596\nleaf_prediction:  0.0015024268683762165\nleaf_model:  31.210604375922564\nmodel_selector_decay:  0.02224349432937083\nsplitter:  0.0015024268683762165\nmin_samples_split:  0.0015024268683762165\nbinary_split:  85.81129793777532\nmax_size:  0.0015024268683762165\nmemory_estimate_period:  0.0015024268683762165\nstop_mem_management:  0.0015024268683762165\nremove_poor_attrs:  0.0015024268683762165\nmerit_preprune:  100.0\nimpo: [['grace_period', 0.0015024268683762165], ['max_depth', 0.0015024268683762165], ['delta', 0.11806586417733643], ['tau', 0.001502427239817596], ['leaf_prediction', 0.0015024268683762165], ['leaf_model', 31.210604375922564], ['model_selector_decay', 0.02224349432937083], ['splitter', 0.0015024268683762165], ['min_samples_split', 0.0015024268683762165], ['binary_split', 85.81129793777532], ['max_size', 0.0015024268683762165], ['memory_estimate_period', 0.0015024268683762165], ['stop_mem_management', 0.0015024268683762165], ['remove_poor_attrs', 0.0015024268683762165], ['merit_preprune', 100.0]]\nindices: [14, 9, 5, 2, 6, 3, 0, 1, 4, 7, 8, 10, 11, 12, 13]\nindices after max_imp selection: [14, 9, 5]",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>`river` Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data</span>"
    ]
  },
  {
    "objectID": "502_spot_hpt_river_friedman_htr.html#parallel-coordinates-plots",
    "href": "502_spot_hpt_river_friedman_htr.html#parallel-coordinates-plots",
    "title": "23  river Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data",
    "section": "23.9 Parallel Coordinates Plots",
    "text": "23.9 Parallel Coordinates Plots\n\nspot_tuner.parallel_plot()",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>`river` Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data</span>"
    ]
  },
  {
    "objectID": "503_spot_hpt_river_friedman_amfr.html",
    "href": "503_spot_hpt_river_friedman_amfr.html",
    "title": "24  The Friedman Drift Data Set",
    "section": "",
    "text": "24.1 Setup\nWe will use a general experiment, data, evaluation, river-specific, objective-function, and surrogate setup similar to the setup from Section 23.2. Only the model setup differs from the setup in Section 23.2. Here we use the Mondrian Tree Regressor from river.\nfrom spotriver.hyperdict.river_hyper_dict import RiverHyperDict\ncore_model_name = \"forest.AMFRegressor\"\nhyperdict = RiverHyperDict\nhyperdict\n\nspotriver.hyperdict.river_hyper_dict.RiverHyperDict",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>The Friedman Drift Data Set</span>"
    ]
  },
  {
    "objectID": "503_spot_hpt_river_friedman_amfr.html#setup",
    "href": "503_spot_hpt_river_friedman_amfr.html#setup",
    "title": "24  The Friedman Drift Data Set",
    "section": "",
    "text": "24.1.1 Select a User Hyperdictionary\nAlternatively, you can load a local hyper_dict from the “userModel” folder. Here, we have selected a copy of the JSON MondrianHyperDict hyperdictionary from [SOURCE] and the MondrianHyperDict class from [SOURCE]. The hyperparameters of the Mondrian Tree Regressor are defined in the MondrianHyperDict class, i.e., there is an key “AMFRegressor” in the hyperdict “mondrian_hyper_dict.json” file.\n\nimport sys\nsys.path.insert(0, './userModel')\nimport mondrian_hyper_dict\nhyperdict = mondrian_hyper_dict.MondrianHyperDict\nhyperdict\n\nmondrian_hyper_dict.MondrianHyperDict\n\n\n\nfrom spotpython.utils.init import fun_control_init, design_control_init, surrogate_control_init, optimizer_control_init\nfrom spotriver.fun.hyperriver import HyperRiver\n\nfun = HyperRiver().fun_oml_horizon\n\nfun_control = fun_control_init(\n    PREFIX=\"503\",\n    fun_evals=inf,\n    max_time=1,\n\n    prep_model_name=\"StandardScaler\",\n    test=test,\n    train=train,\n    target_column=target_column,\n\n    metric_sklearn_name=\"mean_absolute_error\",\n    horizon=7*24,\n    oml_grace_period=7*24,\n    weight_coeff=0.0,\n    weights=np.array([1, 0.01, 0.01]),\n\n    core_model_name=\"forest.AMFRegressor\",\n    hyperdict=hyperdict,\n   )\n\n\ndesign_control = design_control_init(\n    init_size=5,\n)\n\nsurrogate_control = surrogate_control_init(\n    noise=True,\n    n_theta=2,\n    min_Lambda=1e-3,\n    max_Lambda=10,\n)\n\noptimizer_control = optimizer_control_init()",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>The Friedman Drift Data Set</span>"
    ]
  },
  {
    "objectID": "503_spot_hpt_river_friedman_amfr.html#modify-hyper_dict-hyperparameters-for-the-selected-algorithm-aka-core_model",
    "href": "503_spot_hpt_river_friedman_amfr.html#modify-hyper_dict-hyperparameters-for-the-selected-algorithm-aka-core_model",
    "title": "24  The Friedman Drift Data Set",
    "section": "24.2 Modify hyper_dict Hyperparameters for the Selected Algorithm aka core_model",
    "text": "24.2 Modify hyper_dict Hyperparameters for the Selected Algorithm aka core_model\nAfter the core_model and the hyperdict are added to the fun_control dictionary, the hyperparameter tuning can be started. However, in some settings, the user wants to modify the hyperparameters. This can be done with the set_int_hyperparameter_values, set_float_hyperparameter_values, set_boolean_hyperparameter_values, and set_factor_hyperparameter_values functions, which can be imported from from spotpython.hyperparameters.values [SOURCE].\nThe following code shows how hyperparameter of type float and integer can be modified. Additional examples can be found in Section D.15.1.\n\nfrom spotpython.utils.eda import gen_design_table\nprint(gen_design_table(fun_control))\n\n| name            | type   |   default |   lower |   upper | transform             |\n|-----------------|--------|-----------|---------|---------|-----------------------|\n| n_estimators    | int    |         3 |     2   |      10 | transform_power_2_int |\n| step            | float  |         1 |     0.1 |      10 | None                  |\n| use_aggregation | factor |         1 |     0   |       1 | None                  |\n\n\n\nfrom spotpython.hyperparameters.values import set_int_hyperparameter_values, set_float_hyperparameter_values, set_factor_hyperparameter_values\nset_int_hyperparameter_values(fun_control, \"n_estimators\", 2, 7)\nset_float_hyperparameter_values(fun_control, \"step\", 0.1, 15)\nprint(gen_design_table(fun_control))\n\nSetting hyperparameter n_estimators to value [2, 7].\nVariable type is int.\nCore type is None.\nCalling modify_hyper_parameter_bounds().\nSetting hyperparameter step to value [0.1, 15].\nVariable type is float.\nCore type is None.\nCalling modify_hyper_parameter_bounds().\n| name            | type   |   default |   lower |   upper | transform             |\n|-----------------|--------|-----------|---------|---------|-----------------------|\n| n_estimators    | int    |         3 |     2   |       7 | transform_power_2_int |\n| step            | float  |         1 |     0.1 |      15 | None                  |\n| use_aggregation | factor |         1 |     0   |       1 | None                  |\n\n\n\n\n\n\n\n\nNote: Active and Inactive Hyperparameters\n\n\n\nHyperparameters can be excluded from the tuning procedure by selecting identical values for the lower and upper bounds.\n\n\n\n24.2.1 Run the Spot Optimizer\n\nfrom spotpython.spot import spot\nspot_tuner = spot.Spot(\n    fun=fun,\n    fun_control=fun_control,\n    design_control=design_control,\n    surrogate_control=surrogate_control,\n    optimizer_control=optimizer_control,\n)\nres = spot_tuner.run()\n\nspotpython tuning: 2.7978052210288 [#########-] 85.60% \nspotpython tuning: 2.7978052210288 [##########] 100.00% Done...\n\n\n\nWe can start TensorBoard in the background with the following command, where ./runs is the default directory for the TensorBoard log files:\ntensorboard --logdir=\"./runs\"We can access the TensorBoard web server with the following URL:\nhttp://localhost:6006/",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>The Friedman Drift Data Set</span>"
    ]
  },
  {
    "objectID": "503_spot_hpt_river_friedman_amfr.html#results",
    "href": "503_spot_hpt_river_friedman_amfr.html#results",
    "title": "24  The Friedman Drift Data Set",
    "section": "24.3 Results",
    "text": "24.3 Results\nAfter the hyperparameter tuning run is finished, the progress of the hyperparameter tuning can be visualized with spotpython’s method plot_progress. The black points represent the performace values (score or metric) of hyperparameter configurations from the initial design, whereas the red points represents the hyperparameter configurations found by the surrogate model based optimization.\n\nspot_tuner.plot_progress()\n\n\n\n\n\n\n\n\nResults can be printed in tabular form.\n\nfrom spotpython.utils.eda import gen_design_table\nprint(gen_design_table(fun_control=fun_control, spot=spot_tuner))\n\n| name            | type   |   default |   lower |   upper |             tuned | transform             |   importance | stars   |\n|-----------------|--------|-----------|---------|---------|-------------------|-----------------------|--------------|---------|\n| n_estimators    | int    |       3.0 |     2.0 |       7 |               5.0 | transform_power_2_int |       100.00 | ***     |\n| step            | float  |       1.0 |     0.1 |      15 | 5.535800414766609 | None                  |         0.01 |         |\n| use_aggregation | factor |       1.0 |     0.0 |       1 |               1.0 | None                  |         0.40 | .       |\n\n\nA histogram can be used to visualize the most important hyperparameters.\n\nspot_tuner.plot_importance(threshold=10.0)",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>The Friedman Drift Data Set</span>"
    ]
  },
  {
    "objectID": "503_spot_hpt_river_friedman_amfr.html#performance-of-the-model-with-default-hyperparameters",
    "href": "503_spot_hpt_river_friedman_amfr.html#performance-of-the-model-with-default-hyperparameters",
    "title": "24  The Friedman Drift Data Set",
    "section": "24.4 Performance of the Model with Default Hyperparameters",
    "text": "24.4 Performance of the Model with Default Hyperparameters\n\n24.4.1 Get Default Hyperparameters and Fit the Model\nThe default hyperparameters, which will be used for a comparion with the tuned hyperparameters, can be obtained with the following commands:\n\nfrom spotpython.hyperparameters.values import get_default_hyperparameters_as_array\nX_start = get_default_hyperparameters_as_array(fun_control)\n\nspotpython tunes numpy arrays, i.e., the hyperparameters are stored in a numpy array.\n\nfrom spotpython.hyperparameters.values import get_one_core_model_from_X\nmodel_default = get_one_core_model_from_X(X_start, fun_control, default=True)\n\n\n\n24.4.2 Evaluate the Model with Default Hyperparameters\nThe model with the default hyperparameters can be trained and evaluated. The evaluation function eval_oml_horizon [SOURCE] is the same function that was used for the hyperparameter tuning. During the hyperparameter tuning, the evaluation function was called from the objective (or loss) function fun_oml_horizon [SOURCE].\n\nfrom spotriver.evaluation.eval_bml import eval_oml_horizon\n\ndf_eval_default, df_true_default = eval_oml_horizon(\n                    model=model_default,\n                    train=fun_control[\"train\"],\n                    test=fun_control[\"test\"],\n                    target_column=fun_control[\"target_column\"],\n                    horizon=fun_control[\"horizon\"],\n                    oml_grace_period=fun_control[\"oml_grace_period\"],\n                    metric=fun_control[\"metric_sklearn\"],\n                )\n\nThe three performance criteria, i.e., score (metric), runtime, and memory consumption, can be visualized with the following commands:\n\nfrom spotriver.evaluation.eval_bml import plot_bml_oml_horizon_metrics, plot_bml_oml_horizon_predictions\ndf_labels=[\"default\"]\nplot_bml_oml_horizon_metrics(df_eval = [df_eval_default], log_y=False, df_labels=df_labels, metric=fun_control[\"metric_sklearn\"])\n\n\n\n\n\n\n\n\n\n\n24.4.3 Show Predictions of the Model with Default Hyperparameters\n\nSelect a subset of the data set for the visualization of the predictions:\n\nWe use the mean, \\(m\\), of the data set as the center of the visualization.\nWe use 100 data points, i.e., \\(m \\pm 50\\) as the visualization window.\n\n\n\nm = fun_control[\"test\"].shape[0]\na = int(m/2)-50\nb = int(m/2)+50\nplot_bml_oml_horizon_predictions(df_true = [df_true_default[a:b]], target_column=target_column,  df_labels=df_labels)",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>The Friedman Drift Data Set</span>"
    ]
  },
  {
    "objectID": "503_spot_hpt_river_friedman_amfr.html#get-spot-results",
    "href": "503_spot_hpt_river_friedman_amfr.html#get-spot-results",
    "title": "24  The Friedman Drift Data Set",
    "section": "24.5 Get SPOT Results",
    "text": "24.5 Get SPOT Results\nIn a similar way, we can obtain the hyperparameters found by spotpython.\n\nfrom spotpython.hyperparameters.values import get_one_core_model_from_X\nX = spot_tuner.to_all_dim(spot_tuner.min_X.reshape(1,-1))\nmodel_spot = get_one_core_model_from_X(X, fun_control)\n\n\ndf_eval_spot, df_true_spot = eval_oml_horizon(\n                    model=model_spot,\n                    train=fun_control[\"train\"],\n                    test=fun_control[\"test\"],\n                    target_column=fun_control[\"target_column\"],\n                    horizon=fun_control[\"horizon\"],\n                    oml_grace_period=fun_control[\"oml_grace_period\"],\n                    metric=fun_control[\"metric_sklearn\"],\n                )\n\n\ndf_labels=[\"default\", \"spot\"]\nplot_bml_oml_horizon_metrics(df_eval = [df_eval_default, df_eval_spot], log_y=False, df_labels=df_labels, metric=fun_control[\"metric_sklearn\"])\n\n\n\n\n\n\n\n\n\nplot_bml_oml_horizon_predictions(df_true = [df_true_default[a:b], df_true_spot[a:b]], target_column=target_column,  df_labels=df_labels)\n\n\n\n\n\n\n\n\n\nfrom spotpython.plot.validation import plot_actual_vs_predicted\nplot_actual_vs_predicted(y_test=df_true_default[target_column], y_pred=df_true_default[\"Prediction\"], title=\"Default\")\nplot_actual_vs_predicted(y_test=df_true_spot[target_column], y_pred=df_true_spot[\"Prediction\"], title=\"SPOT\")",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>The Friedman Drift Data Set</span>"
    ]
  },
  {
    "objectID": "503_spot_hpt_river_friedman_amfr.html#detailed-hyperparameter-plots",
    "href": "503_spot_hpt_river_friedman_amfr.html#detailed-hyperparameter-plots",
    "title": "24  The Friedman Drift Data Set",
    "section": "24.6 Detailed Hyperparameter Plots",
    "text": "24.6 Detailed Hyperparameter Plots\n\nspot_tuner.plot_important_hyperparameter_contour(max_imp=3)\n\nn_estimators:  99.99999999999999\nstep:  0.00793379815741246\nuse_aggregation:  0.40041848176170436\nimpo: [['n_estimators', 99.99999999999999], ['step', 0.00793379815741246], ['use_aggregation', 0.40041848176170436]]\nindices: [0, 2, 1]\nindices after max_imp selection: [0, 2, 1]",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>The Friedman Drift Data Set</span>"
    ]
  },
  {
    "objectID": "503_spot_hpt_river_friedman_amfr.html#parallel-coordinates-plots",
    "href": "503_spot_hpt_river_friedman_amfr.html#parallel-coordinates-plots",
    "title": "24  The Friedman Drift Data Set",
    "section": "24.7 Parallel Coordinates Plots",
    "text": "24.7 Parallel Coordinates Plots\n\nspot_tuner.parallel_plot()",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>The Friedman Drift Data Set</span>"
    ]
  },
  {
    "objectID": "600_spot_lightning_data.html",
    "href": "600_spot_lightning_data.html",
    "title": "25  HPT PyTorch Lightning: Data",
    "section": "",
    "text": "25.1 Setup\nimport torch\nfrom spotpython.utils.device import getDevice\nfrom math import inf\nWORKERS = 0\nPREFIX=\"030\"\nDEVICE = getDevice()\nDEVICES = 1\nTEST_SIZE = 0.4",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>HPT PyTorch Lightning: Data</span>"
    ]
  },
  {
    "objectID": "600_spot_lightning_data.html#sec-setup-30",
    "href": "600_spot_lightning_data.html#sec-setup-30",
    "title": "25  HPT PyTorch Lightning: Data",
    "section": "",
    "text": "Before we consider the detailed experimental setup, we select the parameters that affect run time, initial design size, etc.\nThe parameter WORKERS specifies the number of workers.\nThe prefix PREFIX is used for the experiment name and the name of the log file.\nThe parameter DEVICE specifies the device to use for training.\n\n\n\n\n\n\n\n\nNote: Device selection\n\n\n\n\nAlthough there are no .cuda() or .to(device) calls required, because Lightning does these for you, see LIGHTNINGMODULE, we would like to know which device is used. Threrefore, we imitate the LightningModule behaviour which selects the highest device.\nThe method spotpython.utils.device.getDevice() returns the device that is used by Lightning.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>HPT PyTorch Lightning: Data</span>"
    ]
  },
  {
    "objectID": "600_spot_lightning_data.html#initialization-of-the-fun_control-dictionary",
    "href": "600_spot_lightning_data.html#initialization-of-the-fun_control-dictionary",
    "title": "25  HPT PyTorch Lightning: Data",
    "section": "25.2 Initialization of the fun_control Dictionary",
    "text": "25.2 Initialization of the fun_control Dictionary\nspotpython uses a Python dictionary for storing the information required for the hyperparameter tuning process.\n\nfrom spotpython.utils.init import fun_control_init\nimport numpy as np\nfun_control = fun_control_init(\n    _L_in=10,\n    _L_out=1,\n    _torchmetric=\"mean_squared_error\",\n    PREFIX=PREFIX,\n    device=DEVICE,\n    enable_progress_bar=False,\n    num_workers=WORKERS,\n    show_progress=True,\n    test_size=TEST_SIZE,\n    )",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>HPT PyTorch Lightning: Data</span>"
    ]
  },
  {
    "objectID": "600_spot_lightning_data.html#loading-the-diabetes-data-set",
    "href": "600_spot_lightning_data.html#loading-the-diabetes-data-set",
    "title": "25  HPT PyTorch Lightning: Data",
    "section": "25.3 Loading the Diabetes Data Set",
    "text": "25.3 Loading the Diabetes Data Set\nHere, we load the Diabetes data set from spotpython’s data module.\n\nfrom spotpython.data.diabetes import Diabetes\ndataset = Diabetes(target_type=torch.float)\nprint(len(dataset))\n\n442\n\n\n\n25.3.1 Data Set and Data Loader\nAs shown below, a DataLoader from torch.utils.data can be used to check the data.\n\n# Set batch size for DataLoader\nbatch_size = 5\n# Create DataLoader\nfrom torch.utils.data import DataLoader\ndataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n\n# Iterate over the data in the DataLoader\nfor batch in dataloader:\n    inputs, targets = batch\n    print(f\"Batch Size: {inputs.size(0)}\")\n    print(f\"Inputs Shape: {inputs.shape}\")\n    print(f\"Targets Shape: {targets.shape}\")\n    print(\"---------------\")\n    print(f\"Inputs: {inputs}\")\n    print(f\"Targets: {targets}\")\n    break\n\nBatch Size: 5\nInputs Shape: torch.Size([5, 10])\nTargets Shape: torch.Size([5])\n---------------\nInputs: tensor([[ 0.0381,  0.0507,  0.0617,  0.0219, -0.0442, -0.0348, -0.0434, -0.0026,\n          0.0199, -0.0176],\n        [-0.0019, -0.0446, -0.0515, -0.0263, -0.0084, -0.0192,  0.0744, -0.0395,\n         -0.0683, -0.0922],\n        [ 0.0853,  0.0507,  0.0445, -0.0057, -0.0456, -0.0342, -0.0324, -0.0026,\n          0.0029, -0.0259],\n        [-0.0891, -0.0446, -0.0116, -0.0367,  0.0122,  0.0250, -0.0360,  0.0343,\n          0.0227, -0.0094],\n        [ 0.0054, -0.0446, -0.0364,  0.0219,  0.0039,  0.0156,  0.0081, -0.0026,\n         -0.0320, -0.0466]])\nTargets: tensor([151.,  75., 141., 206., 135.])\n\n\n\n\n25.3.2 Preparing Training, Validation, and Test Data\nThe following code shows how to split the data into training, validation, and test sets. Then a Lightning Trainer is used to train (fit) the model, validate it, and test it.\n\nfrom torch.utils.data import DataLoader\nfrom spotpython.data.diabetes import Diabetes\nfrom spotpython.light.regression.netlightregression import NetLightRegression\nfrom torch import nn\nimport lightning as L\nimport torch\nBATCH_SIZE = 8\ndataset = Diabetes(target_type=torch.float)\ntrain1_set, test_set = torch.utils.data.random_split(dataset, [0.6, 0.4])\ntrain_set, val_set = torch.utils.data.random_split(train1_set, [0.6, 0.4])\ntrain_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, pin_memory=True)\ntest_loader = DataLoader(test_set, batch_size=BATCH_SIZE)\nval_loader = DataLoader(val_set, batch_size=BATCH_SIZE)\nbatch_x, batch_y = next(iter(train_loader))\nprint(f\"batch_x.shape: {batch_x.shape}\")\nprint(f\"batch_y.shape: {batch_y.shape}\")\nnet_light_base = NetLightRegression(l1=128,\n                                    epochs=10,\n                                    batch_size=BATCH_SIZE,\n                                    initialization='Default',\n                                    act_fn=nn.ReLU(),\n                                    optimizer='Adam',\n                                    dropout_prob=0.1,\n                                    lr_mult=0.1,\n                                    patience=5,\n                                    _L_in=10,\n                                    _L_out=1,\n                                    _torchmetric=\"mean_squared_error\")\ntrainer = L.Trainer(max_epochs=10,  enable_progress_bar=False)\ntrainer.fit(net_light_base, train_loader)\ntrainer.validate(net_light_base, val_loader)\ntrainer.test(net_light_base, test_loader)\n\nbatch_x.shape: torch.Size([8, 10])\nbatch_y.shape: torch.Size([8])\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃      Validate metric      ┃       DataLoader 0        ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│         hp_metric         │      32421.490234375      │\n│         val_loss          │      32421.490234375      │\n└───────────────────────────┴───────────────────────────┘\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃        Test metric        ┃       DataLoader 0        ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│         hp_metric         │       25781.0234375       │\n│         val_loss          │       25781.0234375       │\n└───────────────────────────┴───────────────────────────┘\n\n\n\n[{'val_loss': 25781.0234375, 'hp_metric': 25781.0234375}]\n\n\n\n\n25.3.3 Dataset for spotpython\nspotpython handles the data set, which is added to the fun_control dictionary with the key data_set as follows:\n\nfrom spotpython.hyperparameters.values import set_control_key_value\nfrom spotpython.data.diabetes import Diabetes\ndataset = Diabetes(target_type=torch.float)\nset_control_key_value(control_dict=fun_control,\n                        key=\"data_set\",\n                        value=dataset,\n                        replace=True)\nprint(len(dataset))\n\n442\n\n\nIf the data set is in the fun_control dictionary, it is used to create a LightDataModule object. This object is used to create the data loaders for the training, validation, and test sets. Therefore, the following information must be provided in the fun_control dictionary:\n\ndata_set: the data set\nbatch_size: the batch size\nnum_workers: the number of workers\ntest_size: the size of the test set\ntest_seed: the seed for the test set\n\n\nfrom spotpython.utils.init import fun_control_init\nimport numpy as np\nfun_control = fun_control_init(\n    data_set=dataset,\n    device=\"cpu\",\n    enable_progress_bar=False,\n    num_workers=0,\n    show_progress=True,\n    test_size=0.4,\n    test_seed=42,    \n    )\n\n\nfrom spotpython.data.lightdatamodule import LightDataModule\ndm = LightDataModule(\n    dataset=fun_control[\"data_set\"],\n    batch_size=8,\n    num_workers=fun_control[\"num_workers\"],\n    test_size=fun_control[\"test_size\"],\n    test_seed=fun_control[\"test_seed\"],\n)\ndm.setup()\nprint(f\"train_model(): Test set size: {len(dm.data_test)}\")\nprint(f\"train_model(): Train set size: {len(dm.data_train)}\")\n\ntrain_model(): Test set size: 177\ntrain_model(): Train set size: 160",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>HPT PyTorch Lightning: Data</span>"
    ]
  },
  {
    "objectID": "600_spot_lightning_data.html#the-lightdatamodule",
    "href": "600_spot_lightning_data.html#the-lightdatamodule",
    "title": "25  HPT PyTorch Lightning: Data",
    "section": "25.4 The LightDataModule",
    "text": "25.4 The LightDataModule\nThe steps described above are handled by the LightDataModule class. This class is used to create the data loaders for the training, validation, and test sets. The LightDataModule class is part of the spotpython package. The LightDataModule class provides the following methods:\n\nprepare_data(): This method is used to prepare the data set.\nsetup(): This method is used to create the data loaders for the training, validation, and test sets.\ntrain_dataloader(): This method is used to return the data loader for the training set.\nval_dataloader(): This method is used to return the data loader for the validation set.\ntest_dataloader(): This method is used to return the data loader for the test set.\npredict_dataloader(): This method is used to return the data loader for the prediction set.\n\n\n25.4.1 The prepare_data() Method\nThe prepare_data() method is used to prepare the data set. This method is called only once and on a single process. It can be used to download the data set. In our case, the data set is already available, so this method uses a simple pass statement.\n\n\n25.4.2 The setup() Method\nSplits the data for use in training, validation, and testing. It uses torch.utils.data.random_split() to split the data. Splitting is based on the test_size and test_seed. The test_size can be a float or an int.\n\n25.4.2.1 Determine the Sizes of the Data Sets\n\nfrom torch.utils.data import random_split\ndata_full = dataset\ntest_size = fun_control[\"test_size\"]\ntest_seed=fun_control[\"test_seed\"]\n# if test_size is float, then train_size is 1 - test_size\nif isinstance(test_size, float):\n    full_train_size = round(1.0 - test_size, 2)\n    val_size = round(full_train_size * test_size, 2)\n    train_size = round(full_train_size - val_size, 2)\nelse:\n    # if test_size is int, then train_size is len(data_full) - test_size\n    full_train_size = len(data_full) - test_size\n    val_size = int(full_train_size * test_size / len(data_full))\n    train_size = full_train_size - val_size\n\nprint(f\"LightDataModule setup(): full_train_size: {full_train_size}\")\nprint(f\"LightDataModule setup(): val_size: {val_size}\")\nprint(f\"LightDataModule setup(): train_size: {train_size}\")\nprint(f\"LightDataModule setup(): test_size: {test_size}\")\n\nLightDataModule setup(): full_train_size: 0.6\nLightDataModule setup(): val_size: 0.24\nLightDataModule setup(): train_size: 0.36\nLightDataModule setup(): test_size: 0.4\n\n\nstage is used to define the data set to be returned. The stage can be None, fit, test, or predict. If stage is None, the method returns the training (fit), testing (test) and prediction (predict) data sets.\n\n\n25.4.2.2 Stage “fit”\n\nstage = \"fit\"\nif stage == \"fit\" or stage is None:\n    generator_fit = torch.Generator().manual_seed(test_seed)\n    data_train, data_val, _ = random_split(data_full, [train_size, val_size, test_size], generator=generator_fit)\nprint(f\"LightDataModule setup(): Train set size: {len(data_train)}\")\nprint(f\"LightDataModule setup(): Validation set size: {len(data_val)}\")\n\nLightDataModule setup(): Train set size: 160\nLightDataModule setup(): Validation set size: 106\n\n\n\n\n25.4.2.3 Stage “test”\n\nstage = \"test\"\nif stage == \"test\" or stage is None:\n    generator_test = torch.Generator().manual_seed(test_seed)\n    data_test, _ = random_split(data_full, [test_size, full_train_size], generator=generator_test)\nprint(f\"LightDataModule setup(): Test set size: {len(data_test)}\")\n# Set batch size for DataLoader\nbatch_size = 5\n# Create DataLoader\nfrom torch.utils.data import DataLoader\ndataloader = DataLoader(data_test, batch_size=batch_size, shuffle=False)\n# Iterate over the data in the DataLoader\nfor batch in dataloader:\n    inputs, targets = batch\n    print(f\"Batch Size: {inputs.size(0)}\")\n    print(f\"Inputs Shape: {inputs.shape}\")\n    print(f\"Targets Shape: {targets.shape}\")\n    print(\"---------------\")\n    print(f\"Inputs: {inputs}\")\n    print(f\"Targets: {targets}\")\n    break\n\nLightDataModule setup(): Test set size: 177\nBatch Size: 5\nInputs Shape: torch.Size([5, 10])\nTargets Shape: torch.Size([5])\n---------------\nInputs: tensor([[ 0.0562, -0.0446, -0.0579, -0.0080,  0.0521,  0.0491,  0.0560, -0.0214,\n         -0.0283,  0.0445],\n        [ 0.0018, -0.0446, -0.0709, -0.0229, -0.0016, -0.0010,  0.0266, -0.0395,\n         -0.0225,  0.0072],\n        [-0.0527, -0.0446,  0.0542, -0.0263, -0.0552, -0.0339, -0.0139, -0.0395,\n         -0.0741, -0.0591],\n        [ 0.0054, -0.0446, -0.0482, -0.0126,  0.0012, -0.0066,  0.0634, -0.0395,\n         -0.0514, -0.0591],\n        [-0.0527, -0.0446, -0.0094, -0.0057,  0.0397,  0.0447,  0.0266, -0.0026,\n         -0.0181, -0.0135]])\nTargets: tensor([158.,  49., 142.,  96.,  59.])\n\n\n\n\n25.4.2.4 Stage “predict”\nPrediction and testing use the same data set.\n\nstage = \"predict\"\nif stage == \"predict\" or stage is None:\n    generator_predict = torch.Generator().manual_seed(test_seed)\n    data_predict, _ = random_split(\n        data_full, [test_size, full_train_size], generator=generator_predict\n    )\nprint(f\"LightDataModule setup(): Predict set size: {len(data_predict)}\")\n# Set batch size for DataLoader\nbatch_size = 5\n# Create DataLoader\nfrom torch.utils.data import DataLoader\ndataloader = DataLoader(data_predict, batch_size=batch_size, shuffle=False)\n# Iterate over the data in the DataLoader\nfor batch in dataloader:\n    inputs, targets = batch\n    print(f\"Batch Size: {inputs.size(0)}\")\n    print(f\"Inputs Shape: {inputs.shape}\")\n    print(f\"Targets Shape: {targets.shape}\")\n    print(\"---------------\")\n    print(f\"Inputs: {inputs}\")\n    print(f\"Targets: {targets}\")\n    break\n\nLightDataModule setup(): Predict set size: 177\nBatch Size: 5\nInputs Shape: torch.Size([5, 10])\nTargets Shape: torch.Size([5])\n---------------\nInputs: tensor([[ 0.0562, -0.0446, -0.0579, -0.0080,  0.0521,  0.0491,  0.0560, -0.0214,\n         -0.0283,  0.0445],\n        [ 0.0018, -0.0446, -0.0709, -0.0229, -0.0016, -0.0010,  0.0266, -0.0395,\n         -0.0225,  0.0072],\n        [-0.0527, -0.0446,  0.0542, -0.0263, -0.0552, -0.0339, -0.0139, -0.0395,\n         -0.0741, -0.0591],\n        [ 0.0054, -0.0446, -0.0482, -0.0126,  0.0012, -0.0066,  0.0634, -0.0395,\n         -0.0514, -0.0591],\n        [-0.0527, -0.0446, -0.0094, -0.0057,  0.0397,  0.0447,  0.0266, -0.0026,\n         -0.0181, -0.0135]])\nTargets: tensor([158.,  49., 142.,  96.,  59.])\n\n\n\n\n\n25.4.3 The train_dataloader() Method\nReturns the training dataloader, i.e., a Pytorch DataLoader instance using the training dataset. It simply returns a DataLoader with the data_train set that was created in the setup() method as described in Section 25.4.2.2.\n\ndef train_dataloader(self) -&gt; DataLoader:\n    return DataLoader(self.data_train, batch_size=self.batch_size, num_workers=self.num_workers)\n\nThe train_dataloader() method can be used as follows:\n\nfrom spotpython.data.lightdatamodule import LightDataModule\nfrom spotpython.data.diabetes import Diabetes\ndataset = Diabetes(target_type=torch.float)\ndata_module = LightDataModule(dataset=dataset, batch_size=5, test_size=0.4)\ndata_module.setup()\nprint(f\"Training set size: {len(data_module.data_train)}\")\ndl = data_module.train_dataloader()\n# Iterate over the data in the DataLoader\nfor batch in dl:\n    inputs, targets = batch\n    print(f\"Batch Size: {inputs.size(0)}\")\n    print(f\"Inputs Shape: {inputs.shape}\")\n    print(f\"Targets Shape: {targets.shape}\")\n    print(\"---------------\")\n    print(f\"Inputs: {inputs}\")\n    print(f\"Targets: {targets}\")\n    break\n\nTraining set size: 160\nBatch Size: 5\nInputs Shape: torch.Size([5, 10])\nTargets Shape: torch.Size([5])\n---------------\nInputs: tensor([[ 0.0562, -0.0446, -0.0579, -0.0080,  0.0521,  0.0491,  0.0560, -0.0214,\n         -0.0283,  0.0445],\n        [ 0.0018, -0.0446, -0.0709, -0.0229, -0.0016, -0.0010,  0.0266, -0.0395,\n         -0.0225,  0.0072],\n        [-0.0527, -0.0446,  0.0542, -0.0263, -0.0552, -0.0339, -0.0139, -0.0395,\n         -0.0741, -0.0591],\n        [ 0.0054, -0.0446, -0.0482, -0.0126,  0.0012, -0.0066,  0.0634, -0.0395,\n         -0.0514, -0.0591],\n        [-0.0527, -0.0446, -0.0094, -0.0057,  0.0397,  0.0447,  0.0266, -0.0026,\n         -0.0181, -0.0135]])\nTargets: tensor([158.,  49., 142.,  96.,  59.])\n\n\n\n\n25.4.4 The val_dataloader() Method\nReturns the validation dataloader, i.e., a Pytorch DataLoader instance using the validation dataset. It simply returns a DataLoader with the data_val set that was created in the setup() method as desccribed in Section 25.4.2.2.\n\ndef val_dataloader(self) -&gt; DataLoader:\n    return DataLoader(self.data_val, batch_size=self.batch_size, num_workers=self.num_workers)\n\nThe val_dataloader() method can be used as follows:\n\nfrom spotpython.data.lightdatamodule import LightDataModule\nfrom spotpython.data.diabetes import Diabetes\ndataset = Diabetes(target_type=torch.float)\ndata_module = LightDataModule(dataset=dataset, batch_size=5, test_size=0.4)\ndata_module.setup()\nprint(f\"Validation set size: {len(data_module.data_val)}\")\ndl = data_module.val_dataloader()\n# Iterate over the data in the DataLoader\nfor batch in dl:\n    inputs, targets = batch\n    print(f\"Batch Size: {inputs.size(0)}\")\n    print(f\"Inputs Shape: {inputs.shape}\")\n    print(f\"Targets Shape: {targets.shape}\")\n    print(\"---------------\")\n    print(f\"Inputs: {inputs}\")\n    print(f\"Targets: {targets}\")\n    break\n\nValidation set size: 106\nBatch Size: 5\nInputs Shape: torch.Size([5, 10])\nTargets Shape: torch.Size([5])\n---------------\nInputs: tensor([[ 0.0163, -0.0446,  0.0736, -0.0412, -0.0043, -0.0135, -0.0139, -0.0011,\n          0.0429,  0.0445],\n        [ 0.0453, -0.0446,  0.0714,  0.0012, -0.0098, -0.0010,  0.0155, -0.0395,\n         -0.0412, -0.0715],\n        [ 0.0308,  0.0507,  0.0326,  0.0494, -0.0401, -0.0436, -0.0692,  0.0343,\n          0.0630,  0.0031],\n        [ 0.0235,  0.0507, -0.0396, -0.0057, -0.0484, -0.0333,  0.0118, -0.0395,\n         -0.1016, -0.0674],\n        [-0.0091,  0.0507,  0.0013, -0.0022,  0.0796,  0.0701,  0.0339, -0.0026,\n          0.0267,  0.0818]])\nTargets: tensor([275., 141., 208.,  78., 142.])\n\n\n\n\n25.4.5 The test_dataloader() Method\nReturns the test dataloader, i.e., a Pytorch DataLoader instance using the test dataset. It simply returns a DataLoader with the data_test set that was created in the setup() method as described in Section 25.4.2.3.\n\ndef test_dataloader(self) -&gt; DataLoader:\n    return DataLoader(self.data_test, batch_size=self.batch_size, num_workers=self.num_workers)\n\nThe test_dataloader() method can be used as follows:\n\nfrom spotpython.data.lightdatamodule import LightDataModule\nfrom spotpython.data.diabetes import Diabetes\ndataset = Diabetes(target_type=torch.float)\ndata_module = LightDataModule(dataset=dataset, batch_size=5, test_size=0.4)\ndata_module.setup()\nprint(f\"Test set size: {len(data_module.data_test)}\")\ndl = data_module.test_dataloader()\n# Iterate over the data in the DataLoader\nfor batch in dl:\n    inputs, targets = batch\n    print(f\"Batch Size: {inputs.size(0)}\")\n    print(f\"Inputs Shape: {inputs.shape}\")\n    print(f\"Targets Shape: {targets.shape}\")\n    print(\"---------------\")\n    print(f\"Inputs: {inputs}\")\n    print(f\"Targets: {targets}\")\n    break\n\nTest set size: 177\nBatch Size: 5\nInputs Shape: torch.Size([5, 10])\nTargets Shape: torch.Size([5])\n---------------\nInputs: tensor([[ 0.0562, -0.0446, -0.0579, -0.0080,  0.0521,  0.0491,  0.0560, -0.0214,\n         -0.0283,  0.0445],\n        [ 0.0018, -0.0446, -0.0709, -0.0229, -0.0016, -0.0010,  0.0266, -0.0395,\n         -0.0225,  0.0072],\n        [-0.0527, -0.0446,  0.0542, -0.0263, -0.0552, -0.0339, -0.0139, -0.0395,\n         -0.0741, -0.0591],\n        [ 0.0054, -0.0446, -0.0482, -0.0126,  0.0012, -0.0066,  0.0634, -0.0395,\n         -0.0514, -0.0591],\n        [-0.0527, -0.0446, -0.0094, -0.0057,  0.0397,  0.0447,  0.0266, -0.0026,\n         -0.0181, -0.0135]])\nTargets: tensor([158.,  49., 142.,  96.,  59.])\n\n\n\n\n25.4.6 The predict_dataloader() Method\nReturns the prediction dataloader, i.e., a Pytorch DataLoader instance using the prediction dataset. It simply returns a DataLoader with the data_predict set that was created in the setup() method as described in Section 25.4.2.4.\n\n\n\n\n\n\nWarning\n\n\n\nThe batch_size is set to the length of the data_predict set.\n\n\n\ndef predict_dataloader(self) -&gt; DataLoader:\n    return DataLoader(self.data_predict, batch_size=len(self.data_predict), num_workers=self.num_workers)\n\nThe predict_dataloader() method can be used as follows:\n\nfrom spotpython.data.lightdatamodule import LightDataModule\nfrom spotpython.data.diabetes import Diabetes\ndataset = Diabetes(target_type=torch.float)\ndata_module = LightDataModule(dataset=dataset, batch_size=5, test_size=0.4)\ndata_module.setup()\nprint(f\"Test set size: {len(data_module.data_predict)}\")\ndl = data_module.predict_dataloader()\n# Iterate over the data in the DataLoader\nfor batch in dl:\n    inputs, targets = batch\n    print(f\"Batch Size: {inputs.size(0)}\")\n    print(f\"Inputs Shape: {inputs.shape}\")\n    print(f\"Targets Shape: {targets.shape}\")\n    print(\"---------------\")\n    print(f\"Inputs: {inputs}\")\n    print(f\"Targets: {targets}\")\n    break\n\nTest set size: 177\nBatch Size: 177\nInputs Shape: torch.Size([177, 10])\nTargets Shape: torch.Size([177])\n---------------\nInputs: tensor([[ 0.0562, -0.0446, -0.0579,  ..., -0.0214, -0.0283,  0.0445],\n        [ 0.0018, -0.0446, -0.0709,  ..., -0.0395, -0.0225,  0.0072],\n        [-0.0527, -0.0446,  0.0542,  ..., -0.0395, -0.0741, -0.0591],\n        ...,\n        [ 0.0090, -0.0446, -0.0321,  ..., -0.0764, -0.0119, -0.0384],\n        [-0.0273, -0.0446, -0.0666,  ..., -0.0395, -0.0358, -0.0094],\n        [ 0.0817,  0.0507,  0.0067,  ...,  0.0919,  0.0547,  0.0072]])\nTargets: tensor([158.,  49., 142.,  96.,  59.,  74., 137., 136.,  39.,  66., 310., 198.,\n        235., 116.,  55., 177.,  59., 246.,  53., 135.,  88., 198., 186., 217.,\n         51., 118., 153., 180.,  51., 229.,  84.,  72., 237., 142., 185.,  91.,\n         88., 148., 179., 144.,  25.,  89.,  42.,  60., 124., 170., 215., 263.,\n        178., 245., 202.,  97., 321.,  71., 123., 220., 132., 243.,  61., 102.,\n        187.,  70., 242., 134.,  63.,  72.,  88., 219., 127., 146., 122., 143.,\n        220., 293.,  59., 317.,  60., 140.,  65., 277.,  90.,  96., 109., 190.,\n         90.,  52., 160., 233., 230., 175.,  68., 272., 144.,  70.,  68., 163.,\n         71.,  93., 263., 118., 220.,  90., 232., 120., 163.,  88.,  85.,  52.,\n        181., 232., 212., 332.,  81., 214., 145., 268., 115.,  93.,  64., 156.,\n        128., 200., 281., 103., 220.,  66.,  48., 246.,  42., 150., 125., 109.,\n        129.,  97., 265.,  97., 173., 216., 237., 121.,  42., 151.,  31.,  68.,\n        137., 221., 283., 124., 243., 150.,  69., 306., 182., 252., 132., 258.,\n        121., 110., 292., 101., 275., 141., 208.,  78., 142., 185., 167., 258.,\n        144.,  89., 225., 140., 303., 236.,  87.,  77., 131.])",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>HPT PyTorch Lightning: Data</span>"
    ]
  },
  {
    "objectID": "600_spot_lightning_data.html#using-the-lightdatamodule-in-the-train_model-method",
    "href": "600_spot_lightning_data.html#using-the-lightdatamodule-in-the-train_model-method",
    "title": "25  HPT PyTorch Lightning: Data",
    "section": "25.5 Using the LightDataModule in the train_model() Method",
    "text": "25.5 Using the LightDataModule in the train_model() Method\nFirst, a LightDataModule object is created and the setup() method is called.\n\ndm = LightDataModule(\n    dataset=fun_control[\"data_set\"],\n    batch_size=config[\"batch_size\"],\n    num_workers=fun_control[\"num_workers\"],\n    test_size=fun_control[\"test_size\"],\n    test_seed=fun_control[\"test_seed\"],\n)\ndm.setup()\n\nThen, the Trainer is initialized.\n\n# Init trainer\ntrainer = L.Trainer(\n    default_root_dir=os.path.join(fun_control[\"CHECKPOINT_PATH\"], config_id),\n    max_epochs=model.hparams.epochs,\n    accelerator=fun_control[\"accelerator\"],\n    devices=fun_control[\"devices\"],\n    logger=TensorBoardLogger(\n        save_dir=fun_control[\"TENSORBOARD_PATH\"],\n        version=config_id,\n        default_hp_metric=True,\n        log_graph=fun_control[\"log_graph\"],\n    ),\n    callbacks=[\n        EarlyStopping(monitor=\"val_loss\", patience=config[\"patience\"], mode=\"min\", strict=False, verbose=False)\n    ],\n    enable_progress_bar=enable_progress_bar,\n)\n\nNext, the fit() method is called to train the model.\n\n# Pass the datamodule as arg to trainer.fit to override model hooks :)\ntrainer.fit(model=model, datamodule=dm)\n\nFinally, the validate() method is called to validate the model. The validate() method returns the validation loss.\n\n# Test best model on validation and test set\n# result = trainer.validate(model=model, datamodule=dm, ckpt_path=\"last\")\nresult = trainer.validate(model=model, datamodule=dm)\n# unlist the result (from a list of one dict)\nresult = result[0]\nreturn result[\"val_loss\"]",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>HPT PyTorch Lightning: Data</span>"
    ]
  },
  {
    "objectID": "600_spot_lightning_data.html#further-information",
    "href": "600_spot_lightning_data.html#further-information",
    "title": "25  HPT PyTorch Lightning: Data",
    "section": "25.6 Further Information",
    "text": "25.6 Further Information\n\n25.6.1 Preprocessing\nPreprocessing is handled by Lightning and PyTorch. It is described in the LIGHTNINGDATAMODULE documentation. Here you can find information about the transforms methods.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>HPT PyTorch Lightning: Data</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_diabetes.html",
    "href": "601_spot_hpt_light_diabetes.html",
    "title": "26  Hyperparameter Tuning with spotpython and PyTorch Lightning for the Diabetes Data Set",
    "section": "",
    "text": "26.1 Looking at the Results",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Hyperparameter Tuning with `spotpython` and `PyTorch` Lightning for the Diabetes Data Set</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_diabetes.html#looking-at-the-results",
    "href": "601_spot_hpt_light_diabetes.html#looking-at-the-results",
    "title": "26  Hyperparameter Tuning with spotpython and PyTorch Lightning for the Diabetes Data Set",
    "section": "",
    "text": "26.1.1 Tuning Progress\nAfter the hyperparameter tuning run is finished, the progress of the hyperparameter tuning can be visualized with spotpython’s method plot_progress. The black points represent the performace values (score or metric) of hyperparameter configurations from the initial design, whereas the red points represents the hyperparameter configurations found by the surrogate model based optimization.\n\nspot_tuner.plot_progress()\n\n\n\n26.1.2 Tuned Hyperparameters and Their Importance\nResults can be printed in tabular form.\n\nfrom spotpython.utils.eda import gen_design_table\nprint(gen_design_table(fun_control=fun_control, spot=spot_tuner))\n\nA histogram can be used to visualize the most important hyperparameters.\n\nspot_tuner.plot_importance(threshold=1.0)\n\n\nspot_tuner.plot_important_hyperparameter_contour(max_imp=3)\n\n\n\n26.1.3 Get the Tuned Architecture\n\nimport pprint\nfrom spotpython.hyperparameters.values import get_tuned_architecture\nconfig = get_tuned_architecture(spot_tuner, fun_control)\npprint.pprint(config)\n\n\nTest on the full data set\n\n\n# set the value of the key \"TENSORBOARD_CLEAN\" to True in the fun_control dictionary and use the update() method to update the fun_control dictionary\nfun_control.update({\"TENSORBOARD_CLEAN\": True})\nfun_control.update({\"tensorboard_log\": True})\n\n\nimport os\nimport pickle\n\ndef chk_pickle(s):\n    # Construct the filename\n    filename = s + '.pickle'\n\n    # Check if the file exists\n    return os.path.isfile(filename)\n\n\nfrom spotpython.light.testmodel import test_model\nfrom spotpython.light.loadmodel import load_light_from_checkpoint\nfrom spotpython.utils.init import get_feature_names\n\n\nif chk_pickle(\"model_loaded_\" + PREFIX):\n    with open(\"model_loaded_\" + PREFIX + \".pickle\", \"rb\") as f:\n        model_loaded = pickle.load(f)\nelse:\n    test_model(config, fun_control)\n    model_loaded = load_light_from_checkpoint(config, fun_control)\n    # save model_loaded to pickle file\n    with open(\"model_loaded_\" + PREFIX + \".pickle\", \"wb\") as f:\n        pickle.dump(model_loaded, f)\n\nget_feature_names(fun_control)",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Hyperparameter Tuning with `spotpython` and `PyTorch` Lightning for the Diabetes Data Set</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_diabetes.html#cross-validation-with-lightning",
    "href": "601_spot_hpt_light_diabetes.html#cross-validation-with-lightning",
    "title": "26  Hyperparameter Tuning with spotpython and PyTorch Lightning for the Diabetes Data Set",
    "section": "26.2 Cross Validation With Lightning",
    "text": "26.2 Cross Validation With Lightning\n\nThe KFold class from sklearn.model_selection is used to generate the folds for cross-validation.\nThese mechanism is used to generate the folds for the final evaluation of the model.\nThe CrossValidationDataModule class [SOURCE] is used to generate the folds for the hyperparameter tuning process.\nIt is called from the cv_model function [SOURCE].\n\n\nconfig\n\n\nfrom spotpython.light.cvmodel import cv_model\nfrom spotpython.hyperparameters.values import set_control_key_value\nset_control_key_value(control_dict=fun_control,\n                        key=\"k_folds\",\n                        value=2,\n                        replace=True)\nset_control_key_value(control_dict=fun_control,\n                        key=\"test_size\",\n                        value=0.6,\n                        replace=True)\ncv_model(config, fun_control)",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Hyperparameter Tuning with `spotpython` and `PyTorch` Lightning for the Diabetes Data Set</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_diabetes.html#extending-the-basic-setup",
    "href": "601_spot_hpt_light_diabetes.html#extending-the-basic-setup",
    "title": "26  Hyperparameter Tuning with spotpython and PyTorch Lightning for the Diabetes Data Set",
    "section": "26.3 Extending the Basic Setup",
    "text": "26.3 Extending the Basic Setup\nThis basic setup can be adapted to user-specific needs in many ways. For example, the user can specify a custom data set, a custom model, or a custom loss function. The following sections provide more details on how to customize the hyperparameter tuning process. Before we proceed, we will provide an overview of the basic settings of the hyperparameter tuning process and explain the parameters used so far.\n\n26.3.1 General Experiment Setup\nTo keep track of the different experiments, we use a PREFIX for the experiment name. The PREFIX is used to create a unique experiment name. The PREFIX is also used to create a unique TensorBoard folder, which is used to store the TensorBoard log files.\nspotpython allows the specification of two different types of stopping criteria: first, the number of function evaluations (fun_evals), and second, the maximum run time in seconds (max_time). Here, we will set the number of function evaluations to infinity and the maximum run time to one minute.\nmax_time is set to one minute for demonstration purposes. For real experiments, this value should be increased. Note, the total run time may exceed the specified max_time, because the initial design is always evaluated, even if this takes longer than max_time.\n\n\n26.3.2 Data Setup\nHere, we have provided the Diabetes data set class, which is a subclass of torch.utils.data.Dataset. Data preprocessing is handled by Lightning and PyTorch. It is described in the LIGHTNINGDATAMODULE documentation.\nThe data splitting, i.e., the generation of training, validation, and testing data, is handled by Lightning.\n\n\n26.3.3 Objective Function fun\nThe objective function fun from the class HyperLight [SOURCE] is selected next. It implements an interface from PyTorch’s training, validation, and testing methods to spotpython.\n\n\n26.3.4 Core-Model Setup\nBy using core_model_name = \"light.regression.NNLinearRegressor\", the spotpython model class NetLightRegression [SOURCE] from the light.regression module is selected.\n\n\n26.3.5 Hyperdict Setup\nFor a given core_model_name, the corresponding hyperparameters are automatically loaded from the associated dictionary, which is stored as a JSON file. The JSON file contains hyperparameter type information, names, and bounds. For spotpython models, the hyperparameters are stored in the LightHyperDict, see [SOURCE] Alternatively, you can load a local hyper_dict. The hyperdict uses the default hyperparameter settings. These can be modified as described in Section D.15.1.\n\n\n26.3.6 Other Settings\nThere are several additional parameters that can be specified, e.g., since we did not specify a loss function, mean_squared_error is used, which is the default loss function. These will be explained in more detail in the following sections.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Hyperparameter Tuning with `spotpython` and `PyTorch` Lightning for the Diabetes Data Set</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_diabetes.html#sec-tensorboard-601",
    "href": "601_spot_hpt_light_diabetes.html#sec-tensorboard-601",
    "title": "26  Hyperparameter Tuning with spotpython and PyTorch Lightning for the Diabetes Data Set",
    "section": "26.4 Tensorboard",
    "text": "26.4 Tensorboard\nThe textual output shown in the console (or code cell) can be visualized with Tensorboard, if the argument tensorboard_log to fun_control_init() is set to True. The Tensorboard log files are stored in the runs folder. To start Tensorboard, run the following command in the terminal:\ntensorboard --logdir=\"runs/\"\nFurther information can be found in the PyTorch Lightning documentation for Tensorboard.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Hyperparameter Tuning with `spotpython` and `PyTorch` Lightning for the Diabetes Data Set</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_diabetes.html#loading-the-saved-experiment-and-getting-the-hyperparameters-of-the-tuned-model",
    "href": "601_spot_hpt_light_diabetes.html#loading-the-saved-experiment-and-getting-the-hyperparameters-of-the-tuned-model",
    "title": "26  Hyperparameter Tuning with spotpython and PyTorch Lightning for the Diabetes Data Set",
    "section": "26.5 Loading the Saved Experiment and Getting the Hyperparameters of the Tuned Model",
    "text": "26.5 Loading the Saved Experiment and Getting the Hyperparameters of the Tuned Model\nTo get the tuned hyperparameters as a dictionary, the get_experiment_from_PREFIX function can be used.\n\nfrom spotpython.utils.file import get_experiment_from_PREFIX\nconfig = get_experiment_from_PREFIX(\"601\")[\"config\"]\nconfig",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Hyperparameter Tuning with `spotpython` and `PyTorch` Lightning for the Diabetes Data Set</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_diabetes.html#using-the-spotgui",
    "href": "601_spot_hpt_light_diabetes.html#using-the-spotgui",
    "title": "26  Hyperparameter Tuning with spotpython and PyTorch Lightning for the Diabetes Data Set",
    "section": "26.6 Using the spotgui",
    "text": "26.6 Using the spotgui\nThe spotgui [github] provides a convenient way to interact with the hyperparameter tuning process. To obtain the settings from ?sec-summary-setting-up-the-experiment-601, the spotgui can be started as shown in Figure 26.1.\n\n\n\n\n\n\nFigure 26.1: spotgui",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Hyperparameter Tuning with `spotpython` and `PyTorch` Lightning for the Diabetes Data Set</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_diabetes.html#summary",
    "href": "601_spot_hpt_light_diabetes.html#summary",
    "title": "26  Hyperparameter Tuning with spotpython and PyTorch Lightning for the Diabetes Data Set",
    "section": "26.7 Summary",
    "text": "26.7 Summary\nThis section presented an introduction to the basic setup of hyperparameter tuning with spotpython and PyTorch Lightning.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Hyperparameter Tuning with `spotpython` and `PyTorch` Lightning for the Diabetes Data Set</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_user_data.html",
    "href": "601_spot_hpt_light_user_data.html",
    "title": "27  Hyperparameter Tuning with PyTorch Lightning and User Data Sets",
    "section": "",
    "text": "27.1 Loading a User Specified Data Set\nUsing a user-specified data set is straightforward.\nThe user simply needs to provide a data set and loads is as a spotpython CVSDataset() class by specifying the path, filename, and target column.\nConsider the following example, where the user has a data set stored in the userData directory. The data set is stored in a file named data.csv. The target column is named target. To show the data, it is loaded as a pandas data frame and the first 5 rows are displayed. This step is not necessary for the hyperparameter tuning process, but it is useful for understanding the data.\n# load the csv data set as a pandas dataframe and dislay the first 5 rows\nimport pandas as pd\ndata = pd.read_csv(\"./userData/data.csv\")\nprint(data.head())\n\n        age       sex       bmi        bp        s1        s2        s3  \\\n0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n2  0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n\n         s4        s5        s6  target  \n0 -0.002592  0.019907 -0.017646   151.0  \n1 -0.039493 -0.068332 -0.092204    75.0  \n2 -0.002592  0.002861 -0.025930   141.0  \n3  0.034309  0.022688 -0.009362   206.0  \n4 -0.002592 -0.031988 -0.046641   135.0\nNext, the data set is loaded as a spotpython CSVDataset() class. This step is necessary for the hyperparameter tuning process.\nfrom spotpython.data.csvdataset import CSVDataset\nimport torch\ndata_set = CSVDataset(directory=\"./userData/\",\n                     filename=\"data.csv\",\n                     target_column=\"target\",\n                     feature_type=torch.float32,\n                     target_type=torch.float32,\n                     rmNA=True)\nprint(len(data_set))\n\n442\nThe following step is not necessary for the hyperparameter tuning process, but it is useful for understanding the data. The data set is loaded as a DataLoader from torch.utils.data to check the data.\n# Set batch size for DataLoader\nbatch_size = 5\n# Create DataLoader\nfrom torch.utils.data import DataLoader\ndataloader = DataLoader(data_set, batch_size=batch_size, shuffle=False)\n\n# Iterate over the data in the DataLoader\nfor batch in dataloader:\n    inputs, targets = batch\n    print(f\"Batch Size: {inputs.size(0)}\")\n    print(f\"Inputs Shape: {inputs.shape}\")\n    print(f\"Targets Shape: {targets.shape}\")\n    print(\"---------------\")\n    print(f\"Inputs: {inputs}\")\n    print(f\"Targets: {targets}\")\n    break\n\nBatch Size: 5\nInputs Shape: torch.Size([5, 10])\nTargets Shape: torch.Size([5])\n---------------\nInputs: tensor([[ 0.0381,  0.0507,  0.0617,  0.0219, -0.0442, -0.0348, -0.0434, -0.0026,\n          0.0199, -0.0176],\n        [-0.0019, -0.0446, -0.0515, -0.0263, -0.0084, -0.0192,  0.0744, -0.0395,\n         -0.0683, -0.0922],\n        [ 0.0853,  0.0507,  0.0445, -0.0057, -0.0456, -0.0342, -0.0324, -0.0026,\n          0.0029, -0.0259],\n        [-0.0891, -0.0446, -0.0116, -0.0367,  0.0122,  0.0250, -0.0360,  0.0343,\n          0.0227, -0.0094],\n        [ 0.0054, -0.0446, -0.0364,  0.0219,  0.0039,  0.0156,  0.0081, -0.0026,\n         -0.0320, -0.0466]])\nTargets: tensor([151.,  75., 141., 206., 135.])\nSimilar to the setting from ?sec-basic-setup-601, the hyperparameter tuning setup is defined. Instead of using the Diabetes data set, the user data set is used. The data_set parameter is set to the user data set. The fun_control dictionary is set up via the fun_control_init function.\nNote, that we have modified the fun_evals parameter to 12 and the init_size to 7 to reduce the computational time for this example.\nfrom spotpython.hyperdict.light_hyper_dict import LightHyperDict\nfrom spotpython.fun.hyperlight import HyperLight\nfrom spotpython.utils.init import (fun_control_init, surrogate_control_init, design_control_init)\nfrom spotpython.utils.eda import gen_design_table\nfrom spotpython.hyperparameters.values import set_hyperparameter\nfrom spotpython.spot import spot\n\nfun_control = fun_control_init(\n    PREFIX=\"601\",\n    fun_evals=12,\n    max_time=1,\n    data_set = data_set,\n    core_model_name=\"light.regression.NNLinearRegressor\",\n    hyperdict=LightHyperDict,\n    _L_in=10,\n    _L_out=1)\n\ndesign_control = design_control_init(init_size=7)\n\nset_hyperparameter(fun_control, \"initialization\", [\"Default\"])\n\nfun = HyperLight().fun\n\nspot_tuner = spot.Spot(fun=fun,fun_control=fun_control, design_control=design_control)\n\nmodule_name: light\nsubmodule_name: regression\nmodel_name: NNLinearRegressor\nres = spot_tuner.run()\nprint(gen_design_table(fun_control=fun_control, spot=spot_tuner))\nspot_tuner.plot_important_hyperparameter_contour(max_imp=3)\n\nMilestones: [128, 256, 384]\n\n\nMilestones: [16, 32, 48]\n\n\ntrain_model result: {'val_loss': nan, 'hp_metric': nan}\nMilestones: [32, 64, 96]\n\n\ntrain_model result: {'val_loss': 12256.3876953125, 'hp_metric': 12256.3876953125}\nMilestones: [64, 128, 192]\n\n\ntrain_model result: {'val_loss': 23173.634765625, 'hp_metric': 23173.634765625}\nMilestones: [8, 16, 24]\n\n\ntrain_model result: {'val_loss': nan, 'hp_metric': nan}\nMilestones: [32, 64, 96]\n\n\ntrain_model result: {'val_loss': nan, 'hp_metric': nan}\nMilestones: [4, 8, 12]\n\n\ntrain_model result: {'val_loss': 23810.33203125, 'hp_metric': 23810.33203125}\n\n\nMilestones: [32, 64, 96]\ntrain_model result: {'val_loss': 13219.3115234375, 'hp_metric': 13219.3115234375}\nspotpython tuning: 12256.3876953125 [###-------] 33.33% \n\n\nMilestones: [32, 64, 96]\n\n\ntrain_model result: {'val_loss': 10988.732421875, 'hp_metric': 10988.732421875}\nspotpython tuning: 10988.732421875 [####------] 41.67% \n\n\nMilestones: [32, 64, 96]\ntrain_model result: {'val_loss': 10807.1953125, 'hp_metric': 10807.1953125}\nspotpython tuning: 10807.1953125 [#####-----] 50.00% \n| name           | type   | default   |   lower |   upper | tuned               | transform             |   importance | stars   |\n|----------------|--------|-----------|---------|---------|---------------------|-----------------------|--------------|---------|\n| l1             | int    | 3         |     3.0 |     8.0 | 4.0                 | transform_power_2_int |         0.34 | .       |\n| epochs         | int    | 4         |     4.0 |     9.0 | 7.0                 | transform_power_2_int |       100.00 | ***     |\n| batch_size     | int    | 4         |     1.0 |     4.0 | 2.0                 | transform_power_2_int |         0.34 | .       |\n| act_fn         | factor | ReLU      |     0.0 |     5.0 | Swish               | None                  |         0.02 |         |\n| optimizer      | factor | SGD       |     0.0 |    11.0 | Adagrad             | None                  |        83.45 | **      |\n| dropout_prob   | float  | 0.01      |     0.0 |    0.25 | 0.08638404150780843 | None                  |         0.21 | .       |\n| lr_mult        | float  | 1.0       |     0.1 |    10.0 | 5.9782734862852775  | None                  |         3.54 | *       |\n| patience       | int    | 2         |     2.0 |     6.0 | 3.0                 | transform_power_2_int |         0.03 |         |\n| batch_norm     | factor | 0         |     0.0 |     1.0 | 1                   | None                  |         0.01 |         |\n| initialization | factor | Default   |     0.0 |     0.0 | Default             | None                  |         0.00 |         |\nl1:  0.3405546044830082\nepochs:  100.0\nbatch_size:  0.3403411651664836\nact_fn:  0.015686587527038564\noptimizer:  83.45110370294486\ndropout_prob:  0.21040471019463378\nlr_mult:  3.5368197185142463\npatience:  0.028632058307146952\nbatch_norm:  0.013408853458270809\nimpo: [['l1', 0.3405546044830082], ['epochs', 100.0], ['batch_size', 0.3403411651664836], ['act_fn', 0.015686587527038564], ['optimizer', 83.45110370294486], ['dropout_prob', 0.21040471019463378], ['lr_mult', 3.5368197185142463], ['patience', 0.028632058307146952], ['batch_norm', 0.013408853458270809]]\nindices: [1, 4, 6, 0, 2, 5, 7, 3, 8]\nindices after max_imp selection: [1, 4, 6]",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Hyperparameter Tuning with PyTorch Lightning and User Data Sets</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_user_data.html#summary",
    "href": "601_spot_hpt_light_user_data.html#summary",
    "title": "27  Hyperparameter Tuning with PyTorch Lightning and User Data Sets",
    "section": "27.2 Summary",
    "text": "27.2 Summary\nThis section showed how to use user-specified data sets for the hyperparameter tuning process with spotpython. The user needs to provide the data set and load it as a spotpython CSVDataset() class.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Hyperparameter Tuning with PyTorch Lightning and User Data Sets</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_user_model.html",
    "href": "601_spot_hpt_light_user_model.html",
    "title": "28  Hyperparameter Tuning with PyTorch Lightning and User Models",
    "section": "",
    "text": "28.1 Using a User Specified Model\nAs templates, we provide the following three files that allow the user to specify a model in the /userModel directory:\nThe my_regressor.py file contains the model class, which is a subclass of nn.Module. The my_hyperdict.json file contains the hyperparameter settings as a dictionary, which are loaded via the my_hyperdict.py file.\nNote, that we have to add the path to the userModel directory to the sys.path list as shown below.\nimport sys\nsys.path.insert(0, './userModel')\nimport my_regressor\nimport my_hyper_dict\nfrom spotpython.hyperparameters.values import add_core_model_to_fun_control\n\nfrom spotpython.data.diabetes import Diabetes\nfrom spotpython.hyperdict.light_hyper_dict import LightHyperDict\nfrom spotpython.fun.hyperlight import HyperLight\nfrom spotpython.utils.init import (fun_control_init, design_control_init)\nfrom spotpython.utils.eda import gen_design_table\nfrom spotpython.hyperparameters.values import set_hyperparameter\nfrom spotpython.spot import spot\n\nfun_control = fun_control_init(\n    PREFIX=\"601-user-model\",\n    fun_evals=inf,\n    max_time=1,\n    data_set = Diabetes(),\n    _L_in=10,\n    _L_out=1)\n\nadd_core_model_to_fun_control(fun_control=fun_control,\n                              core_model=my_regressor.MyRegressor,\n                              hyper_dict=my_hyper_dict.MyHyperDict)\n\ndesign_control = design_control_init(init_size=7)\n\nfun = HyperLight().fun\n\nspot_tuner = spot.Spot(fun=fun,fun_control=fun_control, design_control=design_control)\nres = spot_tuner.run()\nprint(gen_design_table(fun_control=fun_control, spot=spot_tuner))\nspot_tuner.plot_important_hyperparameter_contour(max_imp=3)\n\ntrain_model result: {'val_loss': nan, 'hp_metric': nan}\n\n\ntrain_model result: {'val_loss': 4795.224609375, 'hp_metric': 4795.224609375}\n\n\ntrain_model result: {'val_loss': 19881.609375, 'hp_metric': 19881.609375}\n\n\ntrain_model result: {'val_loss': nan, 'hp_metric': nan}\n\n\ntrain_model result: {'val_loss': 22673.50390625, 'hp_metric': 22673.50390625}\n\n\ntrain_model result: {'val_loss': 23567.240234375, 'hp_metric': 23567.240234375}\n\n\ntrain_model result: {'val_loss': 4667.7060546875, 'hp_metric': 4667.7060546875}\nspotpython tuning: 4667.7060546875 [#---------] 11.02% \n\n\ntrain_model result: {'val_loss': 8564.896484375, 'hp_metric': 8564.896484375}\nspotpython tuning: 4667.7060546875 [#######---] 72.08% \n\n\ntrain_model result: {'val_loss': 4786.97119140625, 'hp_metric': 4786.97119140625}\nspotpython tuning: 4667.7060546875 [########--] 82.51% \n\n\ntrain_model result: {'val_loss': 4959.9033203125, 'hp_metric': 4959.9033203125}\nspotpython tuning: 4667.7060546875 [##########] 100.00% Done...\n\n| name           | type   | default   |   lower |   upper | tuned              | transform             |   importance | stars   |\n|----------------|--------|-----------|---------|---------|--------------------|-----------------------|--------------|---------|\n| l1             | int    | 3         |     3.0 |     8.0 | 4.0                | transform_power_2_int |         0.77 | .       |\n| epochs         | int    | 4         |     4.0 |     9.0 | 7.0                | transform_power_2_int |         0.77 | .       |\n| batch_size     | int    | 4         |     1.0 |     4.0 | 2.0                | transform_power_2_int |        92.25 | **      |\n| act_fn         | factor | ReLU      |     0.0 |     5.0 | Swish              | None                  |        24.94 | *       |\n| optimizer      | factor | SGD       |     0.0 |    11.0 | Adagrad            | None                  |         0.77 | .       |\n| dropout_prob   | float  | 0.01      |     0.0 |    0.25 | 0.0859555065832669 | None                  |         0.77 | .       |\n| lr_mult        | float  | 1.0       |     0.1 |    10.0 | 5.442942114443714  | None                  |       100.00 | ***     |\n| patience       | int    | 2         |     2.0 |     6.0 | 3.0                | transform_power_2_int |         0.77 | .       |\n| initialization | factor | Default   |     0.0 |     2.0 | Kaiming            | None                  |         0.77 | .       |\nl1:  0.7704984104186962\nepochs:  0.7704984104186962\nbatch_size:  92.24549821912215\nact_fn:  24.93612753081475\noptimizer:  0.7704984104186962\ndropout_prob:  0.7704984104186962\nlr_mult:  100.0\npatience:  0.7704984104186962\ninitialization:  0.7704984104186962\nimpo: [['l1', 0.7704984104186962], ['epochs', 0.7704984104186962], ['batch_size', 92.24549821912215], ['act_fn', 24.93612753081475], ['optimizer', 0.7704984104186962], ['dropout_prob', 0.7704984104186962], ['lr_mult', 100.0], ['patience', 0.7704984104186962], ['initialization', 0.7704984104186962]]\nindices: [6, 2, 3, 0, 1, 4, 5, 7, 8]\nindices after max_imp selection: [6, 2, 3]",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Hyperparameter Tuning with PyTorch Lightning and User Models</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_user_model.html#using-a-user-specified-model",
    "href": "601_spot_hpt_light_user_model.html#using-a-user-specified-model",
    "title": "28  Hyperparameter Tuning with PyTorch Lightning and User Models",
    "section": "",
    "text": "my_regressor.py, see Section 28.2.4\nmy_hyperdict.json, see Section 28.2.3\nmy_hyperdict.py, see Section 28.2.2.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Hyperparameter Tuning with PyTorch Lightning and User Models</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_user_model.html#details",
    "href": "601_spot_hpt_light_user_model.html#details",
    "title": "28  Hyperparameter Tuning with PyTorch Lightning and User Models",
    "section": "28.2 Details",
    "text": "28.2 Details\n\n28.2.1 Model Setup\nBy using core_model_name = \"my_regressor.MyRegressor\", the user specified model class MyRegressor [SOURCE] is selected. For this given core_model_name, the local hyper_dict is loaded using the my_hyper_dict.py file as shown below.\n\n\n28.2.2 The my_hyper_dict.py File\nThe my_hyper_dict.py file must be placed in the /userModel directory. It provides a convenience function to load the hyperparameters from user specified the my_hyper_dict.json file, see Section 28.2.2. The user does not need to modify this file, if the JSON file is stored as my_hyper_dict.json. Alternative filenames can be specified via the filename argument (which is default set to \"my_hyper_dict.json\").\n\n\n28.2.3 The my_hyper_dict.json File\nThe my_hyper_dict.json file contains the hyperparameter settings as a dictionary, which are loaded via the my_hyper_dict.py file. The example below shows the content of the my_hyper_dict.json file.\n{\n    \"MyRegressor\": {\n        \"l1\": {\n            \"type\": \"int\",\n            \"default\": 3,\n            \"transform\": \"transform_power_2_int\",\n            \"lower\": 3,\n            \"upper\": 8\n        },\n        \"epochs\": {\n            \"type\": \"int\",\n            \"default\": 4,\n            \"transform\": \"transform_power_2_int\",\n            \"lower\": 4,\n            \"upper\": 9\n        },\n        \"batch_size\": {\n            \"type\": \"int\",\n            \"default\": 4,\n            \"transform\": \"transform_power_2_int\",\n            \"lower\": 1,\n            \"upper\": 4\n        },\n        \"act_fn\": {\n            \"levels\": [\n                \"Sigmoid\",\n                \"Tanh\",\n                \"ReLU\",\n                \"LeakyReLU\",\n                \"ELU\",\n                \"Swish\"\n            ],\n            \"type\": \"factor\",\n            \"default\": \"ReLU\",\n            \"transform\": \"None\",\n            \"class_name\": \"spotpython.torch.activation\",\n            \"core_model_parameter_type\": \"instance()\",\n            \"lower\": 0,\n            \"upper\": 5\n        },\n        \"optimizer\": {\n            \"levels\": [\n                \"Adadelta\",\n                \"Adagrad\",\n                \"Adam\",\n                \"AdamW\",\n                \"SparseAdam\",\n                \"Adamax\",\n                \"ASGD\",\n                \"NAdam\",\n                \"RAdam\",\n                \"RMSprop\",\n                \"Rprop\",\n                \"SGD\"\n            ],\n            \"type\": \"factor\",\n            \"default\": \"SGD\",\n            \"transform\": \"None\",\n            \"class_name\": \"torch.optim\",\n            \"core_model_parameter_type\": \"str\",\n            \"lower\": 0,\n            \"upper\": 11\n        },\n        \"dropout_prob\": {\n            \"type\": \"float\",\n            \"default\": 0.01,\n            \"transform\": \"None\",\n            \"lower\": 0.0,\n            \"upper\": 0.25\n        },\n        \"lr_mult\": {\n            \"type\": \"float\",\n            \"default\": 1.0,\n            \"transform\": \"None\",\n            \"lower\": 0.1,\n            \"upper\": 10.0\n        },\n        \"patience\": {\n            \"type\": \"int\",\n            \"default\": 2,\n            \"transform\": \"transform_power_2_int\",\n            \"lower\": 2,\n            \"upper\": 6\n        },\n        \"initialization\": {\n            \"levels\": [\n                \"Default\",\n                \"Kaiming\",\n                \"Xavier\"\n            ],\n            \"type\": \"factor\",\n            \"default\": \"Default\",\n            \"transform\": \"None\",\n            \"core_model_parameter_type\": \"str\",\n            \"lower\": 0,\n            \"upper\": 2\n        }\n    }\n}\n\n\n28.2.4 The my_regressor.py File\nThe my_regressor.py file contains [SOURCE] the model class, which is a subclass of nn.Module. It must implement the following methods:\n\n__init__(self, **kwargs): The constructor of the model class. The hyperparameters are passed as keyword arguments.\nforward(self, x: torch.Tensor) -&gt; torch.Tensor: The forward pass of the model. The input x is passed through the model and the output is returned.\ntraining_step(self, batch, batch_idx) -&gt; torch.Tensor: The training step of the model. It takes a batch of data and the batch index as input and returns the loss.\nvalidation_step(self, batch, batch_idx) -&gt; torch.Tensor: The validation step of the model. It takes a batch of data and the batch index as input and returns the loss.\ntest_step(self, batch, batch_idx) -&gt; torch.Tensor: The test step of the model. It takes a batch of data and the batch index as input and returns the loss.\npredict(self, x: torch.Tensor) -&gt; torch.Tensor: The prediction method of the model. It takes an input x and returns the prediction.\nconfigure_optimizers(self) -&gt; torch.optim.Optimizer: The method to configure the optimizer of the model. It returns the optimizer.\n\nThe file my_regressor.py must be placed in the /userModel directory. The user can modify the model class to implement a custom model architecture.\nWe will take a closer look at the methods defined in the my_regressor.py file in the next subsections.\n\n28.2.4.1 The __init__ Method\n__init__() initializes the MyRegressor object. It takes the following arguments:\n\nl1 (int): The number of neurons in the first hidden layer.\nepochs (int): The number of epochs to train the model for.\nbatch_size (int): The batch size to use during training.\ninitialization (str): The initialization method to use for the weights.\nact_fn (nn.Module): The activation function to use in the hidden layers.\noptimizer (str): The optimizer to use during training.\ndropout_prob (float): The probability of dropping out a neuron during training.\nlr_mult (float): The learning rate multiplier for the optimizer.\npatience (int): The number of epochs to wait before early stopping.\n_L_in (int): The number of input features. Not a hyperparameter, but needed to create the network.\n_L_out (int): The number of output classes. Not a hyperparameter, but needed to create the network.\n_torchmetric (str): The metric to use for the loss function. If None, then “mean_squared_error” is used.\n\nIt is implemented as follows:\n\nclass MyRegressor(L.LightningModule):\n        def __init__(\n        self,\n        l1: int,\n        epochs: int,\n        batch_size: int,\n        initialization: str,\n        act_fn: nn.Module,\n        optimizer: str,\n        dropout_prob: float,\n        lr_mult: float,\n        patience: int,\n        _L_in: int,\n        _L_out: int,\n        _torchmetric: str,\n    ):\n        super().__init__()\n        self._L_in = _L_in\n        self._L_out = _L_out\n        if _torchmetric is None:\n            _torchmetric = \"mean_squared_error\"\n        self._torchmetric = _torchmetric\n        self.metric = getattr(torchmetrics.functional.regression, _torchmetric)\n        # _L_in and _L_out are not hyperparameters, but are needed to create the network\n        # _torchmetric is not a hyperparameter, but is needed to calculate the loss\n        self.save_hyperparameters(ignore=[\"_L_in\", \"_L_out\", \"_torchmetric\"])\n        # set dummy input array for Tensorboard Graphs\n        # set log_graph=True in Trainer to see the graph (in traintest.py)\n        self.example_input_array = torch.zeros((batch_size, self._L_in))\n        if self.hparams.l1 &lt; 4:\n            raise ValueError(\"l1 must be at least 4\")\n        hidden_sizes = self._get_hidden_sizes()\n        # Create the network based on the specified hidden sizes\n        layers = []\n        layer_sizes = [self._L_in] + hidden_sizes\n        layer_size_last = layer_sizes[0]\n        for layer_size in layer_sizes[1:]:\n            layers += [\n                nn.Linear(layer_size_last, layer_size),\n                self.hparams.act_fn,\n                nn.Dropout(self.hparams.dropout_prob),\n            ]\n            layer_size_last = layer_size\n        layers += [nn.Linear(layer_sizes[-1], self._L_out)]\n        # nn.Sequential summarizes a list of modules into a single module,\n        # applying them in sequence\n        self.layers = nn.Sequential(*layers)\n\n\n\n28.2.4.2 The _get_hidden_sizes Method\n__init__() uses the helper method _get_hidden_sizes() to calculate the hidden layer sizes based on the number of neurons in the first hidden layer l1. The hidden layer sizes are calculated as follows:\n\ndef _get_hidden_sizes(self):\n    # Calculate the hidden layer sizes based on the number of neurons in the first hidden layer\n    hidden_sizes = [self.hparams.l1]\n    while hidden_sizes[-1] &gt; 2:\n        hidden_sizes.append(hidden_sizes[-1] // 2)\n    return hidden_sizes\n\n\n\n28.2.4.3 The forward Method\nThe forward() method defines the forward pass of the model. It takes an input tensor x and passes it through the network layers to produce an output tensor. It is implemented as follows:\n\ndef forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    return self.layers(x)\n\n\n\n28.2.4.4 The _calculate_loss Method\nThe _calculate_loss() method calculates the loss based on the predicted output and the target values. It uses the specified metric to calculate the loss. It takes the following arguments:\n\nbatch (tuple): A tuple containing a batch of input data and labels.\n\nIt is implemented as follows:\n\ndef _calculate_loss(self, batch):\n    x, y = batch\n    y = y.view(len(y), 1)\n    y_hat = self(x)\n    loss = self.metric(y_hat, y)\n    return loss\n\n\n\n28.2.4.5 The training_step Method\nThe training_step() method defines the training step of the model. It takes a batch of data and returns the loss. It is implemented as follows:\n\ndef training_step(self, batch: tuple) -&gt; torch.Tensor:\n    val_loss = self._calculate_loss(batch)\n    return val_loss\n\n\n\n28.2.4.6 The validation_step Method\nThe validation_step() method defines the validation step of the model. It takes a batch of data and returns the loss. It is implemented as follows:\n\ndef validation_step(self, batch: tuple) -&gt; torch.Tensor:\n    val_loss = self._calculate_loss(batch)\n    return val_loss\n\n\n\n28.2.4.7 The test_step Method\nThe test_step() method defines the test step of the model. It takes a batch of data and returns the loss. It is implemented as follows:\n\ndef test_step(self, batch: tuple) -&gt; torch.Tensor:\n    val_loss = self._calculate_loss(batch)\n    return val_loss\n\n\n\n28.2.4.8 The predict Method\nThe predict() method defines the prediction method of the model. It takes an input tensor x and returns a tuple with the input tensor x, the target tensor y, and the predicted tensor y_hat.\nIt is implemented as follows:\n\ndef predict(self, x: torch.Tensor) -&gt; torch.Tensor:\n    x, y = batch\n    yhat = self(x)\n    y = y.view(len(y), 1)\n    yhat = yhat.view(len(yhat), 1)\n    return (x, y, yhat)\n\n\n\n28.2.4.9 The configure_optimizers Method\nThe configure_optimizers() method defines the optimizer to use during training. It uses the optimizer_handler from spotpython.hyperparameter.optimizer to create the optimizer based on the specified optimizer name, parameters, and learning rate multiplier. It is implemented as follows:\n\ndef configure_optimizers(self) -&gt; torch.optim.Optimizer:\n    optimizer = optimizer_handler(\n        optimizer_name=self.hparams.optimizer, params=self.parameters(), lr_mult=self.hparams.lr_mult\n    )\n    return optimizer\n\nNote, the default Lightning way is to define an optimizer as optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate). spotpython uses an optimizer handler to create the optimizer, which adapts the learning rate according to the lr_mult hyperparameter as well as other hyperparameters. See spotpython.hyperparameters.optimizer.py [SOURCE] for details.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Hyperparameter Tuning with PyTorch Lightning and User Models</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_user_model.html#connection-with-the-lightdatamodule",
    "href": "601_spot_hpt_light_user_model.html#connection-with-the-lightdatamodule",
    "title": "28  Hyperparameter Tuning with PyTorch Lightning and User Models",
    "section": "28.3 Connection with the LightDataModule",
    "text": "28.3 Connection with the LightDataModule\nThe steps described in Section 28.2.4 are connected to the LightDataModule class [DOC]. This class is used to create the data loaders for the training, validation, and test sets. The LightDataModule class is part of the spotpython package and class provides the following methods [SOURCE]:\n\nprepare_data(): This method is used to prepare the data set.\nsetup(): This method is used to create the data loaders for the training, validation, and test sets.\ntrain_dataloader(): This method is used to return the data loader for the training set.\nval_dataloader(): This method is used to return the data loader for the validation set.\ntest_dataloader(): This method is used to return the data loader for the test set.\npredict_dataloader(): This method is used to return the data loader for the prediction set.\n\n\n28.3.1 The prepare_data() Method\nThe prepare_data() method is used to prepare the data set. This method is called only once and on a single process. It can be used to download the data set. In our case, the data set is already available, so this method uses a simple pass statement.\n\n\n28.3.2 The setup() Method\nThe stage is used to define the data set to be returned. It can be None, fit, test, or predict. If stage is None, the method returns the training (fit), testing (test), and prediction (predict) data sets.\nThe setup methods splits the data based on the stage setting for use in training, validation, and testing. It uses torch.utils.data.random_split() to split the data.\nSplitting is based on the test_size and test_seed. The test_size can be a float or an int.\nFirst, the data set sizes are determined as described in Section 28.3.2.1. Then, the data sets are split based on the stage setting. spotpython’s LightDataModule class uses the following sizes:\n\nfull_train_size: The size of the full training data set. This data set is splitted into the final training data set and a validation data set.\nval_size: The size of the validation data set. The validation data set is used to validate the model during training.\ntrain_size: The size of the training data set. The training data set is used to train the model.\ntest_size: The size of the test data set. The test data set is used to evaluate the model after training. It is not used during training (“hyperparameter tuning”). Only after everything is finished, the model is evaluated on the test data set.\n\n\n28.3.2.1 Determine the Sizes of the Data Sets\n\nimport torch\nfrom torch.utils.data import random_split\ndata_full = Diabetes()\ntest_size = fun_control[\"test_size\"]\ntest_seed=fun_control[\"test_seed\"]\n# if test_size is float, then train_size is 1 - test_size\nif isinstance(test_size, float):\n    full_train_size = round(1.0 - test_size, 2)\n    val_size = round(full_train_size * test_size, 2)\n    train_size = round(full_train_size - val_size, 2)\nelse:\n    # if test_size is int, then train_size is len(data_full) - test_size\n    full_train_size = len(data_full) - test_size\n    val_size = int(full_train_size * test_size / len(data_full))\n    train_size = full_train_size - val_size\n\nprint(f\"LightDataModule setup(): full_train_size: {full_train_size}\")\nprint(f\"LightDataModule setup(): val_size: {val_size}\")\nprint(f\"LightDataModule setup(): train_size: {train_size}\")\nprint(f\"LightDataModule setup(): test_size: {test_size}\")\n\nLightDataModule setup(): full_train_size: 0.6\nLightDataModule setup(): val_size: 0.24\nLightDataModule setup(): train_size: 0.36\nLightDataModule setup(): test_size: 0.4\n\n\n\n\n28.3.2.2 The “setup” Method: Stage “fit”\nHere, train_size and val_size are used to split the data into training and validation sets.\n\nstage = \"fit\"\nscaler = None\n# Assign train/val datasets for use in dataloaders\nif stage == \"fit\" or stage is None:\n    print(f\"train_size: {train_size}, val_size: {val_size} used for train & val data.\")\n    generator_fit = torch.Generator().manual_seed(test_seed)\n    data_train, data_val, _ = random_split(\n        data_full, [train_size, val_size, test_size], generator=generator_fit\n    )\n    if scaler is not None:\n        # Fit the scaler on training data and transform both train and val data\n        scaler_train_data = torch.stack([data_train[i][0] for i in range(len(data_train))]).squeeze(1)\n        # train_val_data = data_train[:,0]\n        print(scaler_train_data.shape)\n        scaler.fit(scaler_train_data)\n        data_train = [(scaler.transform(data), target) for data, target in data_train]\n        data_tensors_train = [data.clone().detach() for data, target in data_train]\n        target_tensors_train = [target.clone().detach() for data, target in data_train]\n        data_train = TensorDataset(\n            torch.stack(data_tensors_train).squeeze(1), torch.stack(target_tensors_train)\n        )\n        # print(data_train)\n        data_val = [(scaler.transform(data), target) for data, target in data_val]\n        data_tensors_val = [data.clone().detach() for data, target in data_val]\n        target_tensors_val = [target.clone().detach() for data, target in data_val]\n        data_val = TensorDataset(torch.stack(data_tensors_val).squeeze(1), torch.stack(target_tensors_val))\n\ntrain_size: 0.36, val_size: 0.24 used for train & val data.\n\n\nThe data_train and data_val data sets are further used to create the training and validation data loaders as described in Section 28.3.3 and Section 28.3.4, respectively.\n\n\n28.3.2.3 The “setup” Method: Stage “test”\nHere, the test data set, which is based on the test_size, is created.\n\nstage = \"test\"\n# Assign test dataset for use in dataloader(s)\nif stage == \"test\" or stage is None:\n    print(f\"test_size: {test_size} used for test dataset.\")\n    # get test data set as test_abs percent of the full dataset\n    generator_test = torch.Generator().manual_seed(test_seed)\n    data_test, _ = random_split(data_full, [test_size, full_train_size], generator=generator_test)\n    if scaler is not None:\n        data_test = [(scaler.transform(data), target) for data, target in data_test]\n        data_tensors_test = [data.clone().detach() for data, target in data_test]\n        target_tensors_test = [target.clone().detach() for data, target in data_test]\n        data_test = TensorDataset(\n            torch.stack(data_tensors_test).squeeze(1), torch.stack(target_tensors_test)\n        )\nprint(f\"LightDataModule setup(): Test set size: {len(data_test)}\")\n# Set batch size for DataLoader\nbatch_size = 5\n# Create DataLoader\nfrom torch.utils.data import DataLoader\ndataloader = DataLoader(data_test, batch_size=batch_size, shuffle=False)\n# Iterate over the data in the DataLoader\nfor batch in dataloader:\n    inputs, targets = batch\n    print(f\"Batch Size: {inputs.size(0)}\")\n    print(f\"Inputs Shape: {inputs.shape}\")\n    print(f\"Targets Shape: {targets.shape}\")\n    print(\"---------------\")\n    print(f\"Inputs: {inputs}\")\n    print(f\"Targets: {targets}\")\n    break\n\ntest_size: 0.4 used for test dataset.\nLightDataModule setup(): Test set size: 177\nBatch Size: 5\nInputs Shape: torch.Size([5, 10])\nTargets Shape: torch.Size([5])\n---------------\nInputs: tensor([[ 0.0490, -0.0446, -0.0418,  0.1045,  0.0356, -0.0257,  0.1775, -0.0764,\n         -0.0129,  0.0155],\n        [-0.0273,  0.0507, -0.0159, -0.0298,  0.0039, -0.0007,  0.0413, -0.0395,\n         -0.0236,  0.0113],\n        [ 0.0708,  0.0507, -0.0170,  0.0219,  0.0438,  0.0563,  0.0376, -0.0026,\n         -0.0702, -0.0176],\n        [-0.0382,  0.0507,  0.0714, -0.0573,  0.1539,  0.1559,  0.0008,  0.0719,\n          0.0503,  0.0693],\n        [ 0.0453, -0.0446,  0.0391,  0.0460,  0.0067, -0.0242,  0.0081, -0.0126,\n          0.0643,  0.0569]])\nTargets: tensor([103.,  53.,  80., 220., 246.])\n\n\n\n\n28.3.2.4 The “setup” Method: Stage “predict”\nPrediction and testing use the same data set. The prediction data set is created based on the test_size.\n\nstage = \"predict\"\nif stage == \"predict\" or stage is None:\n    print(f\"test_size: {test_size} used for predict dataset.\")\n    # get test data set as test_abs percent of the full dataset\n    generator_predict = torch.Generator().manual_seed(test_seed)\n    data_predict, _ = random_split(\n        data_full, [test_size, full_train_size], generator=generator_predict\n    )\n    if scaler is not None:\n        data_predict = [(scaler.transform(data), target) for data, target in data_predict]\n        data_tensors_predict = [data.clone().detach() for data, target in data_predict]\n        target_tensors_predict = [target.clone().detach() for data, target in data_predict]\n        data_predict = TensorDataset(\n            torch.stack(data_tensors_predict).squeeze(1), torch.stack(target_tensors_predict)\n        )\nprint(f\"LightDataModule setup(): Predict set size: {len(data_predict)}\")\n# Set batch size for DataLoader\nbatch_size = 5\n# Create DataLoader\nfrom torch.utils.data import DataLoader\ndataloader = DataLoader(data_predict, batch_size=batch_size, shuffle=False)\n# Iterate over the data in the DataLoader\nfor batch in dataloader:\n    inputs, targets = batch\n    print(f\"Batch Size: {inputs.size(0)}\")\n    print(f\"Inputs Shape: {inputs.shape}\")\n    print(f\"Targets Shape: {targets.shape}\")\n    print(\"---------------\")\n    print(f\"Inputs: {inputs}\")\n    print(f\"Targets: {targets}\")\n    break\n\ntest_size: 0.4 used for predict dataset.\nLightDataModule setup(): Predict set size: 177\nBatch Size: 5\nInputs Shape: torch.Size([5, 10])\nTargets Shape: torch.Size([5])\n---------------\nInputs: tensor([[ 0.0490, -0.0446, -0.0418,  0.1045,  0.0356, -0.0257,  0.1775, -0.0764,\n         -0.0129,  0.0155],\n        [-0.0273,  0.0507, -0.0159, -0.0298,  0.0039, -0.0007,  0.0413, -0.0395,\n         -0.0236,  0.0113],\n        [ 0.0708,  0.0507, -0.0170,  0.0219,  0.0438,  0.0563,  0.0376, -0.0026,\n         -0.0702, -0.0176],\n        [-0.0382,  0.0507,  0.0714, -0.0573,  0.1539,  0.1559,  0.0008,  0.0719,\n          0.0503,  0.0693],\n        [ 0.0453, -0.0446,  0.0391,  0.0460,  0.0067, -0.0242,  0.0081, -0.0126,\n          0.0643,  0.0569]])\nTargets: tensor([103.,  53.,  80., 220., 246.])\n\n\n\n\n\n28.3.3 The train_dataloader() Method\nThe method `train_dataloader returns the training dataloader, i.e., a Pytorch DataLoader instance using the training dataset. It simply returns a DataLoader with the data_train set that was created in the setup() method as described in Section 28.3.2.2.\n\ndef train_dataloader(self) -&gt; DataLoader:\n    return DataLoader(data_train, batch_size=batch_size, num_workers=num_workers)\n\n\n\n\n\n\n\nUsing the train_dataloader() Method\n\n\n\nThe train_dataloader() method can be used as follows:\n\nfrom spotpython.data.lightdatamodule import LightDataModule\nfrom spotpython.data.diabetes import Diabetes\ndataset = Diabetes(target_type=torch.float)\ndata_module = LightDataModule(dataset=dataset, batch_size=5, test_size=0.4)\ndata_module.setup()\nprint(f\"Training set size: {len(data_module.data_train)}\")\ndl = data_module.train_dataloader()\n# Iterate over the data in the DataLoader\nfor batch in dl:\n    inputs, targets = batch\n    print(f\"Batch Size: {inputs.size(0)}\")\n    print(f\"Inputs Shape: {inputs.shape}\")\n    print(f\"Targets Shape: {targets.shape}\")\n    print(\"---------------\")\n    print(f\"Inputs: {inputs}\")\n    print(f\"Targets: {targets}\")\n    break\n\nTraining set size: 160\nBatch Size: 5\nInputs Shape: torch.Size([5, 10])\nTargets Shape: torch.Size([5])\n---------------\nInputs: tensor([[ 0.0562, -0.0446, -0.0579, -0.0080,  0.0521,  0.0491,  0.0560, -0.0214,\n         -0.0283,  0.0445],\n        [ 0.0018, -0.0446, -0.0709, -0.0229, -0.0016, -0.0010,  0.0266, -0.0395,\n         -0.0225,  0.0072],\n        [-0.0527, -0.0446,  0.0542, -0.0263, -0.0552, -0.0339, -0.0139, -0.0395,\n         -0.0741, -0.0591],\n        [ 0.0054, -0.0446, -0.0482, -0.0126,  0.0012, -0.0066,  0.0634, -0.0395,\n         -0.0514, -0.0591],\n        [-0.0527, -0.0446, -0.0094, -0.0057,  0.0397,  0.0447,  0.0266, -0.0026,\n         -0.0181, -0.0135]])\nTargets: tensor([158.,  49., 142.,  96.,  59.])\n\n\n\n\n\n\n28.3.4 The val_dataloader() Method\nReturns the validation dataloader, i.e., a Pytorch DataLoader instance using the validation dataset. It simply returns a DataLoader with the data_val set that was created in the setup() method as desccribed in Section 28.3.2.2.\n\ndef val_dataloader(self) -&gt; DataLoader:\n    return DataLoader(data_val, batch_size=batch_size, num_workers=num_workers)\n\n\n\n\n\n\n\nUsing the val_dataloader() Method\n\n\n\nThe val_dataloader() method can be used as follows:\n\nfrom spotpython.data.lightdatamodule import LightDataModule\nfrom spotpython.data.diabetes import Diabetes\ndataset = Diabetes(target_type=torch.float)\ndata_module = LightDataModule(dataset=dataset, batch_size=5, test_size=0.4)\ndata_module.setup()\nprint(f\"Validation set size: {len(data_module.data_val)}\")\ndl = data_module.val_dataloader()\n# Iterate over the data in the DataLoader\nfor batch in dl:\n    inputs, targets = batch\n    print(f\"Batch Size: {inputs.size(0)}\")\n    print(f\"Inputs Shape: {inputs.shape}\")\n    print(f\"Targets Shape: {targets.shape}\")\n    print(\"---------------\")\n    print(f\"Inputs: {inputs}\")\n    print(f\"Targets: {targets}\")\n    break\n\nValidation set size: 106\nBatch Size: 5\nInputs Shape: torch.Size([5, 10])\nTargets Shape: torch.Size([5])\n---------------\nInputs: tensor([[ 0.0163, -0.0446,  0.0736, -0.0412, -0.0043, -0.0135, -0.0139, -0.0011,\n          0.0429,  0.0445],\n        [ 0.0453, -0.0446,  0.0714,  0.0012, -0.0098, -0.0010,  0.0155, -0.0395,\n         -0.0412, -0.0715],\n        [ 0.0308,  0.0507,  0.0326,  0.0494, -0.0401, -0.0436, -0.0692,  0.0343,\n          0.0630,  0.0031],\n        [ 0.0235,  0.0507, -0.0396, -0.0057, -0.0484, -0.0333,  0.0118, -0.0395,\n         -0.1016, -0.0674],\n        [-0.0091,  0.0507,  0.0013, -0.0022,  0.0796,  0.0701,  0.0339, -0.0026,\n          0.0267,  0.0818]])\nTargets: tensor([275., 141., 208.,  78., 142.])\n\n\n\n\n\n\n28.3.5 The test_dataloader() Method\nReturns the test dataloader, i.e., a Pytorch DataLoader instance using the test dataset. It simply returns a DataLoader with the data_test set that was created in the setup() method as described in Section 25.4.2.3.\n\ndef test_dataloader(self) -&gt; DataLoader:\n    return DataLoader(data_test, batch_size=batch_size, num_workers=num_workers)\n\n\n\n\n\n\n\nUsing the test_dataloader() Method\n\n\n\nThe test_dataloader() method can be used as follows:\n\nfrom spotpython.data.lightdatamodule import LightDataModule\nfrom spotpython.data.diabetes import Diabetes\ndataset = Diabetes(target_type=torch.float)\ndata_module = LightDataModule(dataset=dataset, batch_size=5, test_size=0.4)\ndata_module.setup()\nprint(f\"Test set size: {len(data_module.data_test)}\")\ndl = data_module.test_dataloader()\n# Iterate over the data in the DataLoader\nfor batch in dl:\n    inputs, targets = batch\n    print(f\"Batch Size: {inputs.size(0)}\")\n    print(f\"Inputs Shape: {inputs.shape}\")\n    print(f\"Targets Shape: {targets.shape}\")\n    print(\"---------------\")\n    print(f\"Inputs: {inputs}\")\n    print(f\"Targets: {targets}\")\n    break\n\nTest set size: 177\nBatch Size: 5\nInputs Shape: torch.Size([5, 10])\nTargets Shape: torch.Size([5])\n---------------\nInputs: tensor([[ 0.0562, -0.0446, -0.0579, -0.0080,  0.0521,  0.0491,  0.0560, -0.0214,\n         -0.0283,  0.0445],\n        [ 0.0018, -0.0446, -0.0709, -0.0229, -0.0016, -0.0010,  0.0266, -0.0395,\n         -0.0225,  0.0072],\n        [-0.0527, -0.0446,  0.0542, -0.0263, -0.0552, -0.0339, -0.0139, -0.0395,\n         -0.0741, -0.0591],\n        [ 0.0054, -0.0446, -0.0482, -0.0126,  0.0012, -0.0066,  0.0634, -0.0395,\n         -0.0514, -0.0591],\n        [-0.0527, -0.0446, -0.0094, -0.0057,  0.0397,  0.0447,  0.0266, -0.0026,\n         -0.0181, -0.0135]])\nTargets: tensor([158.,  49., 142.,  96.,  59.])\n\n\n\n\n\n\n28.3.6 The predict_dataloader() Method\nReturns the prediction dataloader, i.e., a Pytorch DataLoader instance using the prediction dataset. It simply returns a DataLoader with the data_predict set that was created in the setup() method as described in Section 25.4.2.4.\n\n\n\n\n\n\nWarning\n\n\n\nThe batch_size is set to the length of the data_predict set.\n\n\n\ndef predict_dataloader(self) -&gt; DataLoader:\n    return DataLoader(data_predict, batch_size=len(data_predict), num_workers=num_workers)\n\n\n\n\n\n\n\nUsing the predict_dataloader() Method\n\n\n\nThe predict_dataloader() method can be used as follows:\n\nfrom spotpython.data.lightdatamodule import LightDataModule\nfrom spotpython.data.diabetes import Diabetes\ndataset = Diabetes(target_type=torch.float)\ndata_module = LightDataModule(dataset=dataset, batch_size=5, test_size=0.4)\ndata_module.setup()\nprint(f\"Test set size: {len(data_module.data_predict)}\")\ndl = data_module.predict_dataloader()\n# Iterate over the data in the DataLoader\nfor batch in dl:\n    inputs, targets = batch\n    print(f\"Batch Size: {inputs.size(0)}\")\n    print(f\"Inputs Shape: {inputs.shape}\")\n    print(f\"Targets Shape: {targets.shape}\")\n    print(\"---------------\")\n    print(f\"Inputs: {inputs}\")\n    print(f\"Targets: {targets}\")\n    break\n\nTest set size: 177\nBatch Size: 177\nInputs Shape: torch.Size([177, 10])\nTargets Shape: torch.Size([177])\n---------------\nInputs: tensor([[ 0.0562, -0.0446, -0.0579,  ..., -0.0214, -0.0283,  0.0445],\n        [ 0.0018, -0.0446, -0.0709,  ..., -0.0395, -0.0225,  0.0072],\n        [-0.0527, -0.0446,  0.0542,  ..., -0.0395, -0.0741, -0.0591],\n        ...,\n        [ 0.0090, -0.0446, -0.0321,  ..., -0.0764, -0.0119, -0.0384],\n        [-0.0273, -0.0446, -0.0666,  ..., -0.0395, -0.0358, -0.0094],\n        [ 0.0817,  0.0507,  0.0067,  ...,  0.0919,  0.0547,  0.0072]])\nTargets: tensor([158.,  49., 142.,  96.,  59.,  74., 137., 136.,  39.,  66., 310., 198.,\n        235., 116.,  55., 177.,  59., 246.,  53., 135.,  88., 198., 186., 217.,\n         51., 118., 153., 180.,  51., 229.,  84.,  72., 237., 142., 185.,  91.,\n         88., 148., 179., 144.,  25.,  89.,  42.,  60., 124., 170., 215., 263.,\n        178., 245., 202.,  97., 321.,  71., 123., 220., 132., 243.,  61., 102.,\n        187.,  70., 242., 134.,  63.,  72.,  88., 219., 127., 146., 122., 143.,\n        220., 293.,  59., 317.,  60., 140.,  65., 277.,  90.,  96., 109., 190.,\n         90.,  52., 160., 233., 230., 175.,  68., 272., 144.,  70.,  68., 163.,\n         71.,  93., 263., 118., 220.,  90., 232., 120., 163.,  88.,  85.,  52.,\n        181., 232., 212., 332.,  81., 214., 145., 268., 115.,  93.,  64., 156.,\n        128., 200., 281., 103., 220.,  66.,  48., 246.,  42., 150., 125., 109.,\n        129.,  97., 265.,  97., 173., 216., 237., 121.,  42., 151.,  31.,  68.,\n        137., 221., 283., 124., 243., 150.,  69., 306., 182., 252., 132., 258.,\n        121., 110., 292., 101., 275., 141., 208.,  78., 142., 185., 167., 258.,\n        144.,  89., 225., 140., 303., 236.,  87.,  77., 131.])",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Hyperparameter Tuning with PyTorch Lightning and User Models</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_user_model.html#using-the-lightdatamodule-in-the-train_model-method",
    "href": "601_spot_hpt_light_user_model.html#using-the-lightdatamodule-in-the-train_model-method",
    "title": "28  Hyperparameter Tuning with PyTorch Lightning and User Models",
    "section": "28.4 Using the LightDataModule in the train_model() Method",
    "text": "28.4 Using the LightDataModule in the train_model() Method\nThe methods discussed so far are used in spotpython’s train_model() method [DOC] to train the model. It is implemented as follows [SOURCE].\nFirst, a LightDataModule object is created and the setup() method is called.\n\ndm = LightDataModule(\n    dataset=fun_control[\"data_set\"],\n    batch_size=config[\"batch_size\"],\n    num_workers=fun_control[\"num_workers\"],\n    test_size=fun_control[\"test_size\"],\n    test_seed=fun_control[\"test_seed\"],\n)\ndm.setup()\n\nThen, the Trainer is initialized.\n\n# Init trainer\ntrainer = L.Trainer(\n    default_root_dir=os.path.join(fun_control[\"CHECKPOINT_PATH\"], config_id),\n    max_epochs=model.hparams.epochs,\n    accelerator=fun_control[\"accelerator\"],\n    devices=fun_control[\"devices\"],\n    logger=TensorBoardLogger(\n        save_dir=fun_control[\"TENSORBOARD_PATH\"],\n        version=config_id,\n        default_hp_metric=True,\n        log_graph=fun_control[\"log_graph\"],\n    ),\n    callbacks=[\n        EarlyStopping(monitor=\"val_loss\", patience=config[\"patience\"], mode=\"min\", strict=False, verbose=False)\n    ],\n    enable_progress_bar=enable_progress_bar,\n)\n\nNext, the fit() method is called to train the model.\n\n# Pass the datamodule as arg to trainer.fit to override model hooks :)\ntrainer.fit(model=model, datamodule=dm)\n\nFinally, the validate() method is called to validate the model. The validate() method returns the validation loss.\n\n# Test best model on validation and test set\nresult = trainer.validate(model=model, datamodule=dm)\n# unlist the result (from a list of one dict)\nresult = result[0]\nreturn result[\"val_loss\"]",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Hyperparameter Tuning with PyTorch Lightning and User Models</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_user_model.html#the-last-connection-the-hyperlight-class",
    "href": "601_spot_hpt_light_user_model.html#the-last-connection-the-hyperlight-class",
    "title": "28  Hyperparameter Tuning with PyTorch Lightning and User Models",
    "section": "28.5 The Last Connection: The HyperLight Class",
    "text": "28.5 The Last Connection: The HyperLight Class\nThe method train_model() is part of the HyperLight class [DOC]. It is called from spotpython as an objective function to train the model and return the validation loss.\nThe HyperLight class is implemented as follows [SOURCE].\n\nclass HyperLight:\n    def fun(self, X: np.ndarray, fun_control: dict = None) -&gt; np.ndarray:\n        z_res = np.array([], dtype=float)\n        self.check_X_shape(X=X, fun_control=fun_control)\n        var_dict = assign_values(X, get_var_name(fun_control))\n        for config in generate_one_config_from_var_dict(var_dict, fun_control):\n            df_eval = train_model(config, fun_control)\n            z_val = fun_control[\"weights\"] * df_eval\n            z_res = np.append(z_res, z_val)\n        return z_res",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Hyperparameter Tuning with PyTorch Lightning and User Models</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_user_model.html#further-information",
    "href": "601_spot_hpt_light_user_model.html#further-information",
    "title": "28  Hyperparameter Tuning with PyTorch Lightning and User Models",
    "section": "28.6 Further Information",
    "text": "28.6 Further Information\n\n28.6.1 Preprocessing\nPreprocessing is handled by Lightning and PyTorch. It is described in the LIGHTNINGDATAMODULE documentation. Here you can find information about the transforms methods.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Hyperparameter Tuning with PyTorch Lightning and User Models</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_pinn_model.html",
    "href": "601_spot_hpt_light_pinn_model.html",
    "title": "29  Hyperparameter Tuning with PyTorch Lightning: Physics Informed Neural Networks",
    "section": "",
    "text": "29.1 The Ground Truth Model\nDefinition of the (unknown) differential equation:\nimport torch\nimport numpy as np\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data as thdat\nimport functools\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# boundaries for the frequency range\na = 0\nb = 500\n\ndef ode(frequency, loc, sigma, R):\n    \"\"\"Computes the amplitude. Defining equation, used\n    to generate data and train models.\n    The equation itself is not known to the model.\n\n    Args:\n        frequency: (N,) array-like\n        loc: float\n        sigma: float\n        R: float\n    \n    Returns:\n        (N,) array-like\n    \n    Examples:\n        &gt;&gt;&gt; ode(0, 25, 100, 0.005)\n        100.0\n    \"\"\"\n    A = np.exp(-R * (frequency - loc)**2/sigma**2)\n    return A\nSetting the parameters for the ode\nnp.random.seed(10)\nloc = 250\nsigma = 100\nR = 0.5\nfrequencies = np.linspace(a, b, 1000)\neq = functools.partial(ode, loc=loc, sigma=sigma, R=R)\namplitudes = eq(frequencies)\ndf = pd.DataFrame({'Frequency': frequencies[:10], 'Amplitude': amplitudes[:10]})\nprint(df)\n\n   Frequency  Amplitude\n0   0.000000   0.043937\n1   0.500501   0.044490\n2   1.001001   0.045048\n3   1.501502   0.045612\n4   2.002002   0.046183\n5   2.502503   0.046759\n6   3.003003   0.047341\n7   3.503504   0.047929\n8   4.004004   0.048524\n9   4.504505   0.049124\n# Make training data\nt = np.linspace(a, 2*b/3, 10)\nA = eq(t) +  0.2 * np.random.randn(10)\nplt.plot(frequencies, amplitudes)\nplt.plot(t, A, 'o')\nplt.legend(['Equation (ground truth)', 'Training data'])\nplt.ylabel('Amplitude')\nplt.xlabel('Frequency')\n\nText(0.5, 0, 'Frequency')",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Hyperparameter Tuning with PyTorch Lightning: Physics Informed Neural Networks</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_pinn_model.html#the-ground-truth-model",
    "href": "601_spot_hpt_light_pinn_model.html#the-ground-truth-model",
    "title": "29  Hyperparameter Tuning with PyTorch Lightning: Physics Informed Neural Networks",
    "section": "",
    "text": "Generating the data\n\n\n\nNow we have the ground truth for the full frequency range and can take a look at the first 10 values:\n\n\n\nWe generate the training data as a subset of the full frequency range and add some noise:\n\n\n\nPlot of the training data and the ground truth:",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Hyperparameter Tuning with PyTorch Lightning: Physics Informed Neural Networks</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_pinn_model.html#required-files",
    "href": "601_spot_hpt_light_pinn_model.html#required-files",
    "title": "29  Hyperparameter Tuning with PyTorch Lightning: Physics Informed Neural Networks",
    "section": "29.2 Required Files",
    "text": "29.2 Required Files\nWe use the files from the /userModel directory as templates. They are renamed as follows:\n\nmy_regressor.py \\(\\Rightarrow\\) pinn_regressor.py, see Section 29.2.2\nmy_hyperdict.json \\(\\Rightarrow\\) pinn_hyperdict.py, see Section 29.2.3\nmy_hyperdict.py \\(\\Rightarrow\\) pinn_hyperdict.py, see ?sec-pinn-hyper-dict.\n\n\n29.2.1 The New pinn_hyperdict.py File\nModifying the pin_hyperdict.py file is very easy. We simply have to change the classname MyHyperDict to PINNHyperDict and the filename from \"my_hyper_dict.json\" to \"pinn_hyper_dict.json\". The file is shown below.\n\nimport json\nfrom spotpython.data import base\nimport pathlib\n\nclass PINNHyperDict(base.FileConfig):\n    def __init__(\n        self,\n        filename: str = \"pinn_hyper_dict.json\",\n        directory: None = None,\n    ) -&gt; None:\n        super().__init__(filename=filename, directory=directory)\n        self.filename = filename\n        self.directory = directory\n        self.hyper_dict = self.load()\n\n    @property\n    def path(self):\n        if self.directory:\n            return pathlib.Path(self.directory).joinpath(self.filename)\n        return pathlib.Path(__file__).parent.joinpath(self.filename)\n\n    def load(self) -&gt; dict:\n        with open(self.path, \"r\") as f:\n            d = json.load(f)\n        return d\n\n\n\n29.2.2 The New pinn_regressor.py File\n\n\n\n\n\n\nWarning\n\n\n\nThe document is not complete. The code below is a template and needs to be modified to work with the PINN model.\n\n\n\nimport lightning as L\nimport torch\nfrom torch import nn\nfrom spotpython.hyperparameters.optimizer import optimizer_handler\nimport torchmetrics.functional.regression\n\nclass PINNRegressor(L.LightningModule):\n    \"\"\"\n    A LightningModule class for a regression neural network model.\n\n    Attributes:\n        l1 (int):\n            The number of neurons in the first hidden layer.\n        epochs (int):\n            The number of epochs to train the model for.\n        batch_size (int):\n            The batch size to use during training.\n        initialization (str):\n            The initialization method to use for the weights.\n        act_fn (nn.Module):\n            The activation function to use in the hidden layers.\n        optimizer (str):\n            The optimizer to use during training.\n        dropout_prob (float):\n            The probability of dropping out a neuron during training.\n        lr_mult (float):\n            The learning rate multiplier for the optimizer.\n        patience (int):\n            The number of epochs to wait before early stopping.\n        _L_in (int):\n            The number of input features.\n        _L_out (int):\n            The number of output classes.\n        _torchmetric (str):\n            The metric to use for the loss function. If `None`,\n            then \"mean_squared_error\" is used.\n        layers (nn.Sequential):\n            The neural network model.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        l1: int,\n        epochs: int,\n        batch_size: int,\n        initialization: str,\n        act_fn: nn.Module,\n        optimizer: str,\n        dropout_prob: float,\n        lr_mult: float,\n        patience: int,\n        _L_in: int,\n        _L_out: int,\n        _torchmetric: str,\n    ):\n        \"\"\"\n        Initializes the MyRegressor object.\n\n        Args:\n            l1 (int):\n                The number of neurons in the first hidden layer.\n            epochs (int):\n                The number of epochs to train the model for.\n            batch_size (int):\n                The batch size to use during training.\n            initialization (str):\n                The initialization method to use for the weights.\n            act_fn (nn.Module):\n                The activation function to use in the hidden layers.\n            optimizer (str):\n                The optimizer to use during training.\n            dropout_prob (float):\n                The probability of dropping out a neuron during training.\n            lr_mult (float):\n                The learning rate multiplier for the optimizer.\n            patience (int):\n                The number of epochs to wait before early stopping.\n            _L_in (int):\n                The number of input features. Not a hyperparameter, but needed to create the network.\n            _L_out (int):\n                The number of output classes. Not a hyperparameter, but needed to create the network.\n            _torchmetric (str):\n                The metric to use for the loss function. If `None`,\n                then \"mean_squared_error\" is used.\n\n        Returns:\n            (NoneType): None\n\n        Raises:\n            ValueError: If l1 is less than 4.\n\n        \"\"\"\n        super().__init__()\n        # Attribute 'act_fn' is an instance of `nn.Module` and is already saved during\n        # checkpointing. It is recommended to ignore them\n        # using `self.save_hyperparameters(ignore=['act_fn'])`\n        # self.save_hyperparameters(ignore=[\"act_fn\"])\n        #\n        self._L_in = _L_in\n        self._L_out = _L_out\n        if _torchmetric is None:\n            _torchmetric = \"mean_squared_error\"\n        self._torchmetric = _torchmetric\n        self.metric = getattr(torchmetrics.functional.regression, _torchmetric)\n        # _L_in and _L_out are not hyperparameters, but are needed to create the network\n        # _torchmetric is not a hyperparameter, but is needed to calculate the loss\n        self.save_hyperparameters(ignore=[\"_L_in\", \"_L_out\", \"_torchmetric\"])\n        # set dummy input array for Tensorboard Graphs\n        # set log_graph=True in Trainer to see the graph (in traintest.py)\n        self.example_input_array = torch.zeros((batch_size, self._L_in))\n        if self.hparams.l1 &lt; 4:\n            raise ValueError(\"l1 must be at least 4\")\n        hidden_sizes = self._get_hidden_sizes()\n        # Create the network based on the specified hidden sizes\n        layers = []\n        layer_sizes = [self._L_in] + hidden_sizes\n        layer_size_last = layer_sizes[0]\n        for layer_size in layer_sizes[1:]:\n            layers += [\n                nn.Linear(layer_size_last, layer_size),\n                self.hparams.act_fn,\n                nn.Dropout(self.hparams.dropout_prob),\n            ]\n            layer_size_last = layer_size\n        layers += [nn.Linear(layer_sizes[-1], self._L_out)]\n        # nn.Sequential summarizes a list of modules into a single module, applying them in sequence\n        self.layers = nn.Sequential(*layers)\n\n    def _generate_div2_list(self, n, n_min) -&gt; list:\n        \"\"\"\n        Generate a list of numbers from n to n_min (inclusive) by dividing n by 2\n        until the result is less than n_min.\n        This function starts with n and keeps dividing it by 2 until n_min is reached.\n        The number of times each value is added to the list is determined by n // current.\n        No more than 4 repeats of the same value (`max_repeats` below) are added to the list.\n\n        Args:\n            n (int): The number to start with.\n            n_min (int): The minimum number to stop at.\n\n        Returns:\n            list: A list of numbers from n to n_min (inclusive).\n\n        Examples:\n            _generate_div2_list(10, 1)\n            [10, 5, 5, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n            _ generate_div2_list(10, 2)\n            [10, 5, 5, 2, 2, 2, 2, 2]\n        \"\"\"\n        result = []\n        current = n\n        repeats = 1\n        max_repeats = 4\n        while current &gt;= n_min:\n            result.extend([current] * min(repeats, max_repeats))\n            current = current // 2\n            repeats = repeats + 1\n        return result\n\n    def _get_hidden_sizes(self):\n        \"\"\"\n        Generate the hidden layer sizes for the network.\n\n        Returns:\n            list: A list of hidden layer sizes.\n\n        \"\"\"\n        n_low = self._L_in // 4\n        n_high = max(self.hparams.l1, 2 * n_low)\n        hidden_sizes = self._generate_div2_list(n_high, n_low)\n        return hidden_sizes\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Performs a forward pass through the model.\n\n        Args:\n            x (torch.Tensor): A tensor containing a batch of input data.\n\n        Returns:\n            torch.Tensor: A tensor containing the output of the model.\n\n        \"\"\"\n        x = self.layers(x)\n        return x\n\n    def _calculate_loss(self, batch):\n        \"\"\"\n        Calculate the loss for the given batch.\n\n        Args:\n            batch (tuple): A tuple containing a batch of input data and labels.\n\n        Returns:\n            torch.Tensor: A tensor containing the loss for this batch.\n\n        \"\"\"\n        x, y = batch\n        y = y.view(len(y), 1)\n        y_hat = self(x)\n        loss = self.metric(y_hat, y)\n        return loss\n\n    def training_step(self, batch: tuple) -&gt; torch.Tensor:\n        \"\"\"\n        Performs a single training step.\n\n        Args:\n            batch (tuple): A tuple containing a batch of input data and labels.\n\n        Returns:\n            torch.Tensor: A tensor containing the loss for this batch.\n\n        \"\"\"\n        val_loss = self._calculate_loss(batch)\n        # self.log(\"train_loss\", val_loss, on_step=True, on_epoch=True, prog_bar=True)\n        # self.log(\"train_mae_loss\", mae_loss, on_step=True, on_epoch=True, prog_bar=True)\n        return val_loss\n\n    def validation_step(self, batch: tuple, batch_idx: int, prog_bar: bool = False) -&gt; torch.Tensor:\n        \"\"\"\n        Performs a single validation step.\n\n        Args:\n            batch (tuple): A tuple containing a batch of input data and labels.\n            batch_idx (int): The index of the current batch.\n            prog_bar (bool, optional): Whether to display the progress bar. Defaults to False.\n\n        Returns:\n            torch.Tensor: A tensor containing the loss for this batch.\n\n        \"\"\"\n        val_loss = self._calculate_loss(batch)\n        # self.log(\"val_loss\", val_loss, on_step=False, on_epoch=True, prog_bar=prog_bar)\n        self.log(\"val_loss\", val_loss, prog_bar=prog_bar)\n        self.log(\"hp_metric\", val_loss, prog_bar=prog_bar)\n        return val_loss\n\n    def test_step(self, batch: tuple, batch_idx: int, prog_bar: bool = False) -&gt; torch.Tensor:\n        \"\"\"\n        Performs a single test step.\n\n        Args:\n            batch (tuple): A tuple containing a batch of input data and labels.\n            batch_idx (int): The index of the current batch.\n            prog_bar (bool, optional): Whether to display the progress bar. Defaults to False.\n\n        Returns:\n            torch.Tensor: A tensor containing the loss for this batch.\n        \"\"\"\n        val_loss = self._calculate_loss(batch)\n        self.log(\"val_loss\", val_loss, prog_bar=prog_bar)\n        self.log(\"hp_metric\", val_loss, prog_bar=prog_bar)\n        return val_loss\n\n    def predict_step(self, batch: tuple, batch_idx: int, prog_bar: bool = False) -&gt; torch.Tensor:\n        \"\"\"\n        Performs a single prediction step.\n\n        Args:\n            batch (tuple): A tuple containing a batch of input data and labels.\n            batch_idx (int): The index of the current batch.\n            prog_bar (bool, optional): Whether to display the progress bar. Defaults to False.\n\n        Returns:\n            A tuple containing the input data, the true labels, and the predicted values.\n        \"\"\"\n        x, y = batch\n        yhat = self(x)\n        y = y.view(len(y), 1)\n        yhat = yhat.view(len(yhat), 1)\n        print(f\"Predict step x: {x}\")\n        print(f\"Predict step y: {y}\")\n        print(f\"Predict step y_hat: {yhat}\")\n        # pred_loss = F.mse_loss(y_hat, y)\n        # pred loss not registered\n        # self.log(\"pred_loss\", pred_loss, prog_bar=prog_bar)\n        # self.log(\"hp_metric\", pred_loss, prog_bar=prog_bar)\n        # MisconfigurationException: You are trying to `self.log()`\n        # but the loop's result collection is not registered yet.\n        # This is most likely because you are trying to log in a `predict` hook, but it doesn't support logging.\n        # If you want to manually log, please consider using `self.log_dict({'pred_loss': pred_loss})` instead.\n        return (x, y, yhat)\n\n    def configure_optimizers(self) -&gt; torch.optim.Optimizer:\n        \"\"\"\n        Configures the optimizer for the model.\n\n        Notes:\n            The default Lightning way is to define an optimizer as\n            `optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)`.\n            spotpython uses an optimizer handler to create the optimizer, which\n            adapts the learning rate according to the lr_mult hyperparameter as\n            well as other hyperparameters. See `spotpython.hyperparameters.optimizer.py` for details.\n\n        Returns:\n            torch.optim.Optimizer: The optimizer to use during training.\n\n        \"\"\"\n        # optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n        optimizer = optimizer_handler(\n            optimizer_name=self.hparams.optimizer, params=self.parameters(), lr_mult=self.hparams.lr_mult\n        )\n        return optimizer\n\n\n\n29.2.3 The New pinn_hyperdict.json File",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Hyperparameter Tuning with PyTorch Lightning: Physics Informed Neural Networks</span>"
    ]
  },
  {
    "objectID": "602_spot_lightning_xai.html",
    "href": "602_spot_lightning_xai.html",
    "title": "30  Explainable AI with SpotPython and Pytorch",
    "section": "",
    "text": "from torch.utils.data import DataLoader\nfrom spotpython.utils.init import fun_control_init\nfrom spotpython.hyperparameters.values import set_control_key_value\nfrom spotpython.data.diabetes import Diabetes\nfrom spotpython.light.regression.netlightregression import NetLightRegression\nfrom spotpython.hyperdict.light_hyper_dict import LightHyperDict\nfrom spotpython.hyperparameters.values import add_core_model_to_fun_control\nfrom spotpython.hyperparameters.values import (\n        get_default_hyperparameters_as_array, get_one_config_from_X)\nfrom spotpython.hyperparameters.values import set_control_key_value\nfrom spotpython.plot.xai import (get_activations, get_gradients, get_weights, plot_nn_values_hist, plot_nn_values_scatter, visualize_weights, visualize_gradients, visualize_activations, visualize_gradient_distributions, visualize_weights_distributions)\nfun_control = fun_control_init(\n    _L_in=10, # 10: diabetes\n    _L_out=1,\n    _torchmetric=\"mean_squared_error\",\n    )\ndataset = Diabetes()\nset_control_key_value(control_dict=fun_control,\n                        key=\"data_set\",\n                        value=dataset,\n                        replace=True)\nadd_core_model_to_fun_control(fun_control=fun_control,\n                              core_model=NetLightRegression,\n                              hyper_dict=LightHyperDict)\nX = get_default_hyperparameters_as_array(fun_control)\nconfig = get_one_config_from_X(X, fun_control)\n_L_in = fun_control[\"_L_in\"]\n_L_out = fun_control[\"_L_out\"]\n_torchmetric = fun_control[\"_torchmetric\"]\nmodel = fun_control[\"core_model\"](**config, _L_in=_L_in, _L_out=_L_out, _torchmetric=_torchmetric)\nbatch_size= config[\"batch_size\"]\ndataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n\n\nget_activations(model, fun_control=fun_control, batch_size=batch_size, device = \"cpu\")\n\nnet: NetLightRegression(\n  (layers): Sequential(\n    (0): Linear(in_features=10, out_features=8, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.01, inplace=False)\n    (3): Linear(in_features=8, out_features=4, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.01, inplace=False)\n    (6): Linear(in_features=4, out_features=4, bias=True)\n    (7): ReLU()\n    (8): Dropout(p=0.01, inplace=False)\n    (9): Linear(in_features=4, out_features=2, bias=True)\n    (10): ReLU()\n    (11): Dropout(p=0.01, inplace=False)\n    (12): Linear(in_features=2, out_features=1, bias=True)\n  )\n)\n\n\n{0: array([ 1.43207282e-01,  6.29712082e-03,  1.04200497e-01, -3.79188173e-03,\n        -1.74976081e-01, -7.97475874e-02, -2.00860098e-01,  2.48444736e-01,\n         1.42530382e-01, -2.86847632e-03,  3.61538231e-02, -5.21567538e-02,\n        -2.15294853e-01, -1.26742452e-01, -1.79230243e-01,  2.73077697e-01,\n         1.36738747e-01,  8.57900176e-03,  1.01677164e-01,  3.27536091e-03,\n        -1.92429125e-01, -7.95854479e-02, -1.84092522e-01,  2.72164375e-01,\n         1.51459932e-01,  3.70034538e-02,  4.94864434e-02, -6.36564642e-02,\n        -1.63678646e-01, -1.26617596e-01, -2.05547154e-01,  2.25242063e-01,\n         1.54910132e-01,  4.92912624e-03,  6.90693632e-02, -3.28048877e-02,\n        -1.77523270e-01, -1.17699921e-01, -1.95609123e-01,  2.50784487e-01,\n         1.66618377e-01,  1.22015951e-02,  2.58807316e-02, -8.16192776e-02,\n        -2.00623482e-01, -1.17052853e-01, -1.86843857e-01,  2.40996510e-01,\n         1.80479109e-01,  3.72159854e-02,  3.55244167e-02, -3.60636115e-02,\n        -2.09616780e-01, -1.19843856e-01, -1.44335642e-01,  2.73970902e-01,\n         1.46006003e-01, -1.83095373e-02,  8.83664042e-02,  2.28608586e-02,\n        -1.77115664e-01, -1.37761638e-01, -1.90622538e-01,  2.85049856e-01,\n         1.44436464e-01,  1.36893094e-02,  6.65568933e-02, -2.01083720e-04,\n        -1.99043870e-01, -1.11171007e-01, -1.76820531e-01,  2.78549373e-01,\n         1.31597325e-01,  1.31126186e-02,  5.92438355e-02, -6.50760308e-02,\n        -1.55642599e-01, -1.12090096e-01, -2.32182071e-01,  2.25448400e-01,\n         2.09733546e-01,  4.48576249e-02,  1.76887661e-02, -7.26176351e-02,\n        -1.81560591e-01, -1.18118793e-01, -1.55840069e-01,  2.45131850e-01,\n         1.57539800e-01,  4.57477495e-02,  8.64019692e-02,  1.06538832e-02,\n        -2.25713193e-01, -8.36062431e-02, -1.51326194e-01,  2.42097050e-01,\n         1.46130219e-01, -6.08363096e-03,  4.69235368e-02, -4.06553932e-02,\n        -1.90215483e-01, -1.30105391e-01, -1.91207454e-01,  2.75829703e-01,\n         1.37035578e-01,  1.32784406e-02,  8.11730623e-02, -2.83420049e-02,\n        -1.72134370e-01, -1.05717532e-01, -1.93411276e-01,  2.68321246e-01,\n         1.24822736e-01, -2.49985531e-02,  5.46513572e-02, -3.76938097e-02,\n        -2.02080101e-01, -1.29510283e-01, -1.99880868e-01,  2.84415126e-01,\n         1.36025175e-01,  2.10405551e-02,  1.25923336e-01, -1.76883545e-02,\n        -1.46617338e-01, -1.00234658e-01, -2.21794963e-01,  2.05139250e-01],\n       dtype=float32),\n 3: array([-0.09106569,  0.15831017,  0.29874575, -0.05709065, -0.07168067,\n         0.13238071,  0.29310873, -0.04537551, -0.08868651,  0.15093939,\n         0.29576218, -0.0508837 , -0.07256822,  0.15756649,  0.29804155,\n        -0.06024086, -0.07925774,  0.15159754,  0.29655144, -0.05204485,\n        -0.06510481,  0.14707124,  0.2955585 , -0.05045141, -0.05945833,\n         0.15397519,  0.28643152, -0.03937227, -0.0780265 ,  0.1443048 ,\n         0.2993904 , -0.04338943, -0.07745007,  0.1438258 ,  0.29152495,\n        -0.04569358, -0.08201659,  0.14775375,  0.3020632 , -0.06361471,\n        -0.05014775,  0.16657498,  0.28808075, -0.04191205, -0.07614301,\n         0.16806594,  0.29809946, -0.05615523, -0.07369395,  0.13612927,\n         0.2925982 , -0.04455032, -0.08367015,  0.14735378,  0.29441217,\n        -0.05101945, -0.07929114,  0.12925598,  0.29300398, -0.04631315,\n        -0.09977546,  0.1741175 ,  0.30642375, -0.07330882], dtype=float32),\n 6: array([ 0.02894721, -0.15329668,  0.0478624 ,  0.5073338 ,  0.03414171,\n        -0.1624101 ,  0.0582981 ,  0.5058923 ,  0.0301194 , -0.15560818,\n         0.05099656,  0.5068564 ,  0.02897662, -0.15344843,  0.04822758,\n         0.5072659 ,  0.03012998, -0.15550745,  0.05065323,  0.5069246 ,\n         0.03103478, -0.1570965 ,  0.05247599,  0.50667256,  0.02730933,\n        -0.15252227,  0.0509877 ,  0.5065358 ,  0.03256607, -0.15896471,\n         0.05305116,  0.5067359 ,  0.03095146, -0.15756464,  0.05418621,\n         0.5063291 ,  0.03229896, -0.1581411 ,  0.05142961,  0.50702184,\n         0.02454497, -0.14787357,  0.04604906,  0.50718296,  0.02638294,\n        -0.14930864,  0.04427201,  0.5077407 ,  0.03309863, -0.16082475,\n         0.05695035,  0.50603575,  0.03071198, -0.15675312,  0.05250891,\n         0.5066291 ,  0.03489432, -0.16362445,  0.05948593,  0.50574666,\n         0.02671532, -0.14859803,  0.04098557,  0.5084204 ], dtype=float32),\n 9: array([0.04397329, 0.23183572, 0.04112439, 0.22675759, 0.0430866 ,\n        0.23046201, 0.04386139, 0.2317175 , 0.04319487, 0.23055825,\n        0.04269706, 0.22967225, 0.04286424, 0.23156166, 0.04263979,\n        0.2289063 , 0.0421553 , 0.2292049 , 0.04312573, 0.22948454,\n        0.04418794, 0.23408437, 0.04489119, 0.23388621, 0.0414625 ,\n        0.22755873, 0.0426609 , 0.22978865, 0.04081305, 0.22611658,\n        0.04594607, 0.23471704], dtype=float32),\n 12: array([-0.30635476, -0.30988604, -0.3073418 , -0.30644947, -0.30726004,\n        -0.30787635, -0.306807  , -0.308307  , -0.3082779 , -0.3078606 ,\n        -0.30507785, -0.3049926 , -0.30935943, -0.30782318, -0.3103186 ,\n        -0.30425358], dtype=float32)}\n\n\n\nget_gradients(model, fun_control=fun_control, batch_size=batch_size, device = \"cpu\")\n\n{'layers.0.weight': array([ 0.10417589, -0.04161514,  0.10597268,  0.02180895,  0.12001497,\n         0.0289035 ,  0.01146171,  0.08183315,  0.2495192 ,  0.5108763 ,\n         0.14668097, -0.07902835,  0.00912531,  0.02640062,  0.14108549,\n         0.06816658,  0.14256881, -0.00347908,  0.07373644,  0.23171763,\n         0.08313344, -0.0332093 ,  0.08456729,  0.01740377,  0.09577318,\n         0.0230653 ,  0.00914656,  0.0653037 ,  0.1991189 ,  0.4076846 ,\n         0.04405227,  0.03805925,  0.015035  ,  0.0069457 ,  0.0094994 ,\n         0.03021198, -0.01876849,  0.02160799, -0.03238906, -0.02050959,\n         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        -0.05415884,  0.02163483, -0.05509295, -0.01133801, -0.06239325,\n        -0.01502632, -0.0059587 , -0.04254333, -0.12971975, -0.2655938 ],\n       dtype=float32),\n 'layers.3.weight': array([ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n        -5.8896484e+00, -6.3058013e-01, -2.5641673e+00, -8.9936234e-02,\n         0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -1.0009734e+01,\n         5.1539743e-01,  5.5181440e-02,  2.2438775e-01,  7.8702327e-03,\n         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  8.7594193e-01,\n         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n       dtype=float32),\n 'layers.6.weight': array([ 0.       ,  7.6445217, 15.007772 ,  0.       ,  0.       ,\n         0.       ,  0.       ,  0.       ,  0.       , 11.027901 ,\n        21.650045 ,  0.       ,  0.       ,  3.458755 ,  6.7902493,\n         0.       ], dtype=float32),\n 'layers.9.weight': array([ -2.3285942,   0.       ,  -3.9471323, -39.11015  ,  -4.6057286,\n          0.       ,  -7.8070364, -77.35598  ], dtype=float32),\n 'layers.12.weight': array([-12.126856, -64.91129 ], dtype=float32)}\n\n\n\nget_weights(model)\n\n{'Layer 0': array([-0.12895013,  0.01047491, -0.15705723,  0.11925378, -0.26944348,\n         0.23180884, -0.22984707, -0.25141433, -0.19982024,  0.1432175 ,\n        -0.11684369,  0.11833665, -0.2683918 , -0.19186287, -0.11611126,\n        -0.06214499, -0.24123858,  0.20706302, -0.07457636,  0.10150522,\n         0.22361842,  0.05891513,  0.08647271,  0.3052416 , -0.1426217 ,\n         0.10016554, -0.14069483,  0.22599207,  0.25255734, -0.29155323,\n         0.26994652,  0.1510033 ,  0.13780165,  0.13018303,  0.26287985,\n        -0.04175457, -0.26743335, -0.09074122, -0.2227112 ,  0.02090477,\n        -0.05904209, -0.16961981, -0.02875187,  0.2995954 , -0.0249426 ,\n         0.01004026, -0.04931906,  0.04971322,  0.28176296,  0.19337103,\n         0.11224869,  0.06871963,  0.07456426,  0.12216929, -0.04086405,\n        -0.29390487, -0.19555901,  0.2699275 ,  0.01890202, -0.25616774,\n         0.04987781,  0.26129004, -0.29883513, -0.21289697, -0.12594265,\n         0.0126926 , -0.07375361, -0.03475064, -0.30828732,  0.14808287,\n         0.2775668 ,  0.19329055, -0.22393112, -0.25491226,  0.13131432,\n         0.00710202,  0.12963155, -0.3090024 , -0.01885445,  0.22301763],\n       dtype=float32),\n 'Layer 3': array([ 0.19455571,  0.12364562, -0.2711233 ,  0.2728095 ,  0.11085409,\n         0.24458633, -0.13908438,  0.07495222,  0.34520328,  0.23782092,\n         0.28354865, -0.07424083,  0.26936427, -0.2769144 ,  0.03057847,\n        -0.19906998, -0.08245403, -0.09054411,  0.02645254,  0.32178298,\n         0.17503859, -0.00149773,  0.2509683 , -0.1811804 ,  0.18221132,\n        -0.03278595, -0.06152213,  0.0413917 , -0.27085608,  0.04085568,\n         0.11887809,  0.302264  ], dtype=float32),\n 'Layer 6': array([ 0.4752962 , -0.24824601,  0.22039747,  0.19587505,  0.13966405,\n         0.39540154, -0.20208222,  0.13140953,  0.00280607, -0.3760708 ,\n        -0.12140697, -0.33391154,  0.22107768,  0.04494798,  0.04898232,\n        -0.15168536], dtype=float32),\n 'Layer 9': array([ 0.07573527, -0.22145915, -0.30541402,  0.03821951, -0.3709231 ,\n        -0.3758251 , -0.3254385 , -0.1698224 ], dtype=float32),\n 'Layer 12': array([0.2738903, 0.5417278], dtype=float32)}\n\n\n\nvisualize_activations(model, fun_control=fun_control, batch_size=batch_size, device = \"cpu\", cmap=\"BlueWhiteRed\", absolute=False)\n\nnet: NetLightRegression(\n  (layers): Sequential(\n    (0): Linear(in_features=10, out_features=8, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.01, inplace=False)\n    (3): Linear(in_features=8, out_features=4, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.01, inplace=False)\n    (6): Linear(in_features=4, out_features=4, bias=True)\n    (7): ReLU()\n    (8): Dropout(p=0.01, inplace=False)\n    (9): Linear(in_features=4, out_features=2, bias=True)\n    (10): ReLU()\n    (11): Dropout(p=0.01, inplace=False)\n    (12): Linear(in_features=2, out_features=1, bias=True)\n  )\n)\n128 values in Layer 0.\n16 padding values added.\n144 values now in Layer 0.\n\n\n\n\n\n\n\n\n\n64 values in Layer 3.\n64 values now in Layer 3.\n\n\n\n\n\n\n\n\n\n64 values in Layer 6.\n64 values now in Layer 6.\n\n\n\n\n\n\n\n\n\n32 values in Layer 9.\n4 padding values added.\n36 values now in Layer 9.\n\n\n\n\n\n\n\n\n\n16 values in Layer 12.\n16 values now in Layer 12.\n\n\n\n\n\n\n\n\n\n\nvisualize_weights_distributions(model, color=f\"C{0}\")\n\nn:5\n\n\n\n\n\n\n\n\n\n\nvisualize_gradient_distributions(model, fun_control, batch_size=batch_size, color=f\"C{0}\")\n\nn:5\n\n\n\n\n\n\n\n\n\n\nvisualize_weights(model, absolute=True, cmap=\"gray\", figsize=(6, 6))\n\n80 values in Layer Layer 0.\n1 padding values added.\n81 values now in Layer Layer 0.\n\n\n\n\n\n\n\n\n\n32 values in Layer Layer 3.\n4 padding values added.\n36 values now in Layer Layer 3.\n\n\n\n\n\n\n\n\n\n16 values in Layer Layer 6.\n16 values now in Layer Layer 6.\n\n\n\n\n\n\n\n\n\n8 values in Layer Layer 9.\n1 padding values added.\n9 values now in Layer Layer 9.\n\n\n\n\n\n\n\n\n\n2 values in Layer Layer 12.\n2 padding values added.\n4 values now in Layer Layer 12.\n\n\n\n\n\n\n\n\n\n\nvisualize_gradients(model, fun_control, batch_size, absolute=True, cmap=\"BlueWhiteRed\", figsize=(6, 6))\n\n80 values in Layer layers.0.weight.\n1 padding values added.\n81 values now in Layer layers.0.weight.\n\n\n\n\n\n\n\n\n\n32 values in Layer layers.3.weight.\n4 padding values added.\n36 values now in Layer layers.3.weight.\n\n\n\n\n\n\n\n\n\n16 values in Layer layers.6.weight.\n16 values now in Layer layers.6.weight.\n\n\n\n\n\n\n\n\n\n8 values in Layer layers.9.weight.\n1 padding values added.\n9 values now in Layer layers.9.weight.\n\n\n\n\n\n\n\n\n\n2 values in Layer layers.12.weight.\n2 padding values added.\n4 values now in Layer layers.12.weight.\n\n\n\n\n\n\n\n\n\n\nvisualize_activations(model, fun_control=fun_control, batch_size=batch_size, device = \"cpu\")\n\nnet: NetLightRegression(\n  (layers): Sequential(\n    (0): Linear(in_features=10, out_features=8, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.01, inplace=False)\n    (3): Linear(in_features=8, out_features=4, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.01, inplace=False)\n    (6): Linear(in_features=4, out_features=4, bias=True)\n    (7): ReLU()\n    (8): Dropout(p=0.01, inplace=False)\n    (9): Linear(in_features=4, out_features=2, bias=True)\n    (10): ReLU()\n    (11): Dropout(p=0.01, inplace=False)\n    (12): Linear(in_features=2, out_features=1, bias=True)\n  )\n)\n128 values in Layer 0.\n16 padding values added.\n144 values now in Layer 0.\n\n\n\n\n\n\n\n\n\n64 values in Layer 3.\n64 values now in Layer 3.\n\n\n\n\n\n\n\n\n\n64 values in Layer 6.\n64 values now in Layer 6.\n\n\n\n\n\n\n\n\n\n32 values in Layer 9.\n4 padding values added.\n36 values now in Layer 9.\n\n\n\n\n\n\n\n\n\n16 values in Layer 12.\n16 values now in Layer 12.\n\n\n\n\n\n\n\n\n\n\nvisualize_activations(model, fun_control=fun_control, batch_size=batch_size, device = \"cpu\")\n\nnet: NetLightRegression(\n  (layers): Sequential(\n    (0): Linear(in_features=10, out_features=8, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.01, inplace=False)\n    (3): Linear(in_features=8, out_features=4, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.01, inplace=False)\n    (6): Linear(in_features=4, out_features=4, bias=True)\n    (7): ReLU()\n    (8): Dropout(p=0.01, inplace=False)\n    (9): Linear(in_features=4, out_features=2, bias=True)\n    (10): ReLU()\n    (11): Dropout(p=0.01, inplace=False)\n    (12): Linear(in_features=2, out_features=1, bias=True)\n  )\n)\n128 values in Layer 0.\n16 padding values added.\n144 values now in Layer 0.\n\n\n\n\n\n\n\n\n\n64 values in Layer 3.\n64 values now in Layer 3.\n\n\n\n\n\n\n\n\n\n64 values in Layer 6.\n64 values now in Layer 6.\n\n\n\n\n\n\n\n\n\n32 values in Layer 9.\n4 padding values added.\n36 values now in Layer 9.\n\n\n\n\n\n\n\n\n\n16 values in Layer 12.\n16 values now in Layer 12.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Explainable AI with SpotPython and Pytorch</span>"
    ]
  },
  {
    "objectID": "603_spot_lightning_transformer_introduction.html",
    "href": "603_spot_lightning_transformer_introduction.html",
    "title": "31  HPT PyTorch Lightning Transformer: Introduction",
    "section": "",
    "text": "31.1 Transformer Basics",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>HPT PyTorch Lightning Transformer: Introduction</span>"
    ]
  },
  {
    "objectID": "603_spot_lightning_transformer_introduction.html#sec-transformer-basics",
    "href": "603_spot_lightning_transformer_introduction.html#sec-transformer-basics",
    "title": "31  HPT PyTorch Lightning Transformer: Introduction",
    "section": "",
    "text": "31.1.1 Embedding\nWord embedding is a technique where words or phrases (so-called tokens) from the vocabulary are mapped to vectors of real numbers. These vectors capture the semantic properties of the words. Words that are similar in meaning are mapped to vectors that are close to each other in the vector space, and words that are dissimilar are mapped to vectors that are far apart. Word embeddings are needed for transformers for several reasons:\n\nDimensionality Reduction: Word embeddings reduce the dimensionality of the data. Instead of dealing with high-dimensional sparse vectors (like one-hot encoded vectors), we deal with dense vectors of much lower dimensionality.\nCapturing Semantic Similarities: Word embeddings capture semantic similarities between words. This is crucial for tasks like text classification, sentiment analysis, etc., where the meaning of the words is important.\nHandling Unknown Words: If a word is not present in the training data but appears in the test data, one-hot encoding cannot handle it. But word embeddings can handle such situations by mapping the unknown word to a vector that is similar to known words.\nInput to Neural Networks: Transformers, like other neural networks, work with numerical data. Word embeddings provide a way to convert text data into numerical form that can be fed into these networks.\n\nIn the context of transformers, word embeddings are used as the initial input representation. The transformer then learns more complex representations by considering the context in which each token appears.\n\n31.1.1.1 Neural Network for Embeddings\nIdea for word embeddings: use a relatively simple NN that has one input for every token (word, symbol) in the vocabulary. The output of the NN is a vector of a fixed size, which is the word embedding. The network that is used in this chapter is visualized in Figure 31.1. For simplicity, a 2-dimensional output vector is used in this visualization. The weights of the NN are randomly initialized, and are learned during training.\n\n\n\n\n\n\nFigure 31.1: Transformer. Computation of the self attention. In this example, we consider two inputs, i.e., (1,0) and (0,1). For each input, there are two values, which results in a \\(2 \\times 2\\) matrix. In general, when there are \\(T\\) inputs, a \\(T \\times T\\) matrix will be generated. Figure credits: Starmer, Josh: Decoder-Only Transformers, ChatGPTs specific Transformer, Clearly Explained.\n\n\n\nAll tokens are embedded in this way. For each token there are two numerical values, the embedding vector. The same network is used for embedding all tokens. If a longer input is added, it can be embedded with the same net.\n\n\n31.1.1.2 Positional Encoding for the Embeddings\nPositional encoding is added to the input embeddings to give the model some information about the relative or absolute position of the tokens in the sequence. The positional encodings have the same dimension as the embeddings so that the two can be summed.\nIf a token occurs several times, it is embedded several times and receives different embedding vectors, as the position is taken into account by the positional encoding.\n\n\n\n31.1.2 Attention\nAttention describes how similar is each token to itself and to all other tokens in the input, e.g., in a sentence. The attention mechanism can be implemented as a set of layers in neural networks. There are a lot of different possible definitions of “attention” in the literature, but the one we will use here is the following: the attention mechanism describes a weighted average of (sequence) elements with the weights dynamically computed based on an input query and elements’ keys (Lippe 2022).\nThe goal is to take an average over the features of multiple elements. However, instead of weighting each element equally, we want to weight them depending on their actual values. In other words, we want to dynamically decide on which inputs we want to “attend” more than others.\nCalculation of the self-attention:\n\nQueries: Calculate two new values from the (two) values of the embedding vector using an NN, which are referred to as query values.\nKeys: Calculate two new values, called key values, from the (two) values of the embedding vector using an NN.\nDot product: Calculate the dot product of the query values and the key values. This is a measure of the similarity of the query and key values.\nSoftmax: Apply the softmax function to the outputs from the dot product. This is a measure of the attention that a token pays to other tokens.\nValues: Calculate two new values from the (two) values of the embedding vector using an NN, which are referred to as value values.\nThe values are multiplied (weighted) by the values of the softmax function.\nThe weighted values are summed. Now we have the self attention value for the token.\n\n\n\n31.1.3 Self-Attention\nMost attention mechanisms differ in terms of what queries they use, how the key and value vectors are defined, and what score function is used. The attention applied inside the Transformer architecture is called “self-attention”. In self-attention, each sequence element provides a key, value, and query. For each element, we perform an attention layer where based on its query, we check the similarity of the all sequence elements’ keys, and returned a different, averaged value vector for each element.\n\n\n31.1.4 Masked Self-Attention\nMasked self-attention is a variant of the self-attention method described in Section 31.1.3. It asks the question: How similar is each token to itself and to all preceding tokens in the input (sentence)? Masked self-attention is an autoregressive mechanism, which means that the attention mechanism is only allowed to look at the tokens that have already been processed. Calculation of the mask self-attention is identical to the self-attention, but the attention is only calculated for the tokens that have already been processed. If the masked self-attention method is applied to the first token, the masked self-attention value is exactly the value of the first token, as it only takes itself into account. For the other tokens, the masked self-attention value is a weighted sum of the values of the previous tokens. The weighting is determined by the similarity of the query values and the key values (dot product and softmax).\n\n\n31.1.5 Generation of Outputs\nTo calculate the output, we use a residual connector that adds the output of the neural network and the output of the masked self-attention method. We thus obtain the residual connection values. The residual connector is used to facilitate training.\nTo generate the next token, we use another neural network that calculates the output from the (two) residual connection values. The input layer of the neural network has the size of the residual connection values, the output layer has the number of tokens in the vocabulary as a dimension.\nIf we now enter the residual connection value of the first token, we receive the token (or the probabilities using Softmax) that is to come next as the output of the neural network. This makes sense even if we already know the second token (as with the first token): We can use it to calculate the error of the neural network and train the network. In addition, the decoder-transformer uses the masked self-attention method to calculate the output, i.e. the encoding and generation of new tokens is done with exactly the same elements of the network.\nNote: ChatGPT does not use a new neural network, but the same network that was already used to calculate the embedding. The network is therefore used for embedding, masked self-attention and calculating the output. In the last calculation, the network is inverted, i.e. it is run in the opposite direction to obtain the tokens and not the embeddings as in the original run.\n\n\n31.1.6 End-Of-Sequence-Token\nThe end-of-sequence token is used to signal the end of the input and also to start generating new tokens after the input. The EOS token recognizes all other tokens, as it comes after all tokens. When generating tokens, it is important to consider the relationships between the input tokens and the generation of new tokens.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>HPT PyTorch Lightning Transformer: Introduction</span>"
    ]
  },
  {
    "objectID": "603_spot_lightning_transformer_introduction.html#sec-details-implementation",
    "href": "603_spot_lightning_transformer_introduction.html#sec-details-implementation",
    "title": "31  HPT PyTorch Lightning Transformer: Introduction",
    "section": "31.2 Details of the Implementation",
    "text": "31.2 Details of the Implementation\nWe will now go into a bit more detail by first looking at the specific implementation of the attention mechanism which is in the Transformer case the (scaled) dot product attention. The variables shown in Table 31.1 are used in the Transformer architecture.\n\n\n\nTable 31.1: Variables used in the Transformer architecture.\n\n\n\n\n\n\n\n\n\n\nSymbol\nVariable\nDescription\n\n\n\n\n\\(Q\\)\nquery\nThe query vectors.\n\n\n\\(K\\)\nkey\nThe key vectors.\n\n\n\\(V\\)\nvalue\nThe value vectors.\n\n\n\\(d_{\\text{model}}\\)\nd_model\nThe dimensionality of the input and output features of the Transformer.\n\n\n\\(d_k\\)\nd_k\nThe hidden dimensionality of the key and query vectors.\n\n\n\\(d_v\\)\nd_v\nThe hidden dimensionality of the value vectors.\n\n\n\\(h\\)\nnum_heads\nThe number of heads in the Multi-Head Attention layer.\n\n\n\\(B\\)\nbatch_size\nThe batch size.\n\n\n\\(T\\)\nseq_length\nThe sequence length.\n\n\n\\(X\\)\nx\nThe input features (input elements in the sequence).\n\n\n\\(W^{Q}\\)\nqkv_proj\nThe weight matrix to transform the input to the query vectors.\n\n\n\\(W^{K}\\)\nqkv_proj\nThe weight matrix to transform the input to the key vectors.\n\n\n\\(W^{V}\\)\nqkv_proj\nThe weight matrix to transform the input to the value vectors.\n\n\n\\(W^{O}\\)\no_proj\nThe weight matrix to transform the concatenated output of the Multi-Head Attention layer to the final output.\n\n\n\\(N\\)\nnum_layers\nThe number of layers in the Transformer.\n\n\n\\(PE_{(pos,i)}\\)\npositional_encoding\nThe positional encoding for position \\(pos\\) and hidden dimensionality \\(i\\).\n\n\n\n\n\n\nSummarizing the ideas from Section 31.1, an attention mechanism has usually four parts we need to specify (Lippe 2022):\n\nQuery: The query is a feature vector that describes what we are looking for in the sequence, i.e., what would we maybe want to pay attention to.\nKeys: For each input element, we have a key which is again a feature vector. This feature vector roughly describes what the element is “offering”, or when it might be important. The keys should be designed such that we can identify the elements we want to pay attention to based on the query.\nScore function: To rate which elements we want to pay attention to, we need to specify a score function \\(f_{attn}\\). The score function takes the query and a key as input, and output the score/attention weight of the query-key pair. It is usually implemented by simple similarity metrics like a dot product, or a small MLP.\nValues: For each input element, we also have a value vector. This feature vector is the one we want to average over.\n\nThe weights of the average are calculated by a softmax over all score function outputs. Hence, we assign those value vectors a higher weight whose corresponding key is most similar to the query. If we try to describe it with pseudo-math, we can write:\n\\[\n\\alpha_i = \\frac{\\exp\\left(f_{attn}\\left(\\text{key}_i, \\text{query}\\right)\\right)}{\\sum_j \\exp\\left(f_{attn}\\left(\\text{key}_j, \\text{query}\\right)\\right)}, \\hspace{5mm} \\text{out} = \\sum_i \\alpha_i \\cdot \\text{value}_i\n\\]\nVisually, we can show the attention over a sequence of words as follows:\n\n\n\nAttention over a sequence of words. For every word, we have one key and one value vector. The query is compared to all keys with a score function (in this case the dot product) to determine the weights. The softmax is not visualized for simplicity. Finally, the value vectors of all words are averaged using the attention weights. Figure taken from Lippe (2022)\n\n\n\n31.2.1 Dot Product Attention\nOur goal is to have an attention mechanism with which any element in a sequence can attend to any other while still being efficient to compute. The dot product attention takes as input a set of queries \\(Q\\in\\mathbb{R}^{T\\times d_k}\\), keys \\(K\\in\\mathbb{R}^{T\\times d_k}\\) and values \\(V\\in\\mathbb{R}^{T\\times d_v}\\) where \\(T\\) is the sequence length, and \\(d_k\\) and \\(d_v\\) are the hidden dimensionality for queries/keys and values respectively. For simplicity, we neglect the batch dimension for now. The attention value from element \\(i\\) to \\(j\\) is based on its similarity of the query \\(Q_i\\) and key \\(K_j\\), using the dot product as the similarity metric (in Figure 31.1, we considered \\(Q_2\\) and \\(K_1\\) as well as \\(Q_2\\) and \\(K_2\\)). The dot product attention is calculated as follows:\n\\[\n\\text{Attention}(Q,K,V)=\\text{softmax}\\left(QK^T\\right) V\n\\tag{31.1}\\]\nThe matrix multiplication \\(QK^T\\) performs the dot product for every possible pair of queries and keys, resulting in a matrix of the shape \\(T\\times T\\). Each row represents the attention logits for a specific element \\(i\\) to all other elements in the sequence. On these, we apply a softmax and multiply with the value vector to obtain a weighted mean (the weights being determined by the attention).\n\n\n31.2.2 Scaled Dot Product Attention\nAn additional aspect is the scaling of the dot product using a scaling factor of \\(1/\\sqrt{d_k}\\). This scaling factor is crucial to maintain an appropriate variance of attention values after initialization. We initialize our layers with the intention of having equal variance throughout the model, and hence, \\(Q\\) and \\(K\\) might also have a variance close to \\(1\\). However, performing a dot product over two vectors with a variance \\(\\sigma^2\\) results in a scalar having \\(d_k\\)-times higher variance:\n\\[\nq_i \\sim \\mathcal{N}(0,\\sigma^2), k_i \\sim \\mathcal{N}(0,\\sigma^2) \\to \\text{Var}\\left(\\sum_{i=1}^{d_k} q_i\\cdot k_i\\right) = \\sigma^4\\cdot d_k\n\\]\nIf we do not scale down the variance back to \\(\\sim\\sigma^2\\), the softmax over the logits will already saturate to \\(1\\) for one random element and \\(0\\) for all others. The gradients through the softmax will be close to zero so that we can’t learn the parameters appropriately. Note that the extra factor of \\(\\sigma^2\\), i.e., having \\(\\sigma^4\\) instead of \\(\\sigma^2\\), is usually not an issue, since we keep the original variance \\(\\sigma^2\\) close to \\(1\\) anyways. Equation 31.1 can be modified as follows to calculate the dot product attention:\n\\[\n\\text{Attention}(Q,K,V)=\\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right) V.\n\\]\nAnother perspective on this scaled dot product attention mechanism offers the computation graph which is visualized in Figure 31.2.\n\n\n\n\n\n\nFigure 31.2: Scaled dot product attention. Figure credit Vaswani et al. (2017)\n\n\n\nThe block Mask (opt.) in the diagram above represents the optional masking of specific entries in the attention matrix. This is for instance used if we stack multiple sequences with different lengths into a batch. To still benefit from parallelization in PyTorch, we pad the sentences to the same length and mask out the padding tokens during the calculation of the attention values. This is usually done by setting the respective attention logits to a very low value.\nAfter we have discussed the details of the scaled dot product attention block, we can write a function below which computes the output features given the triple of queries, keys, and values:",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>HPT PyTorch Lightning Transformer: Introduction</span>"
    ]
  },
  {
    "objectID": "603_spot_lightning_transformer_introduction.html#sec-transformer-in-lightning",
    "href": "603_spot_lightning_transformer_introduction.html#sec-transformer-in-lightning",
    "title": "31  HPT PyTorch Lightning Transformer: Introduction",
    "section": "31.3 Example: Transformer in Lightning",
    "text": "31.3 Example: Transformer in Lightning\nThe following code is based on https://github.com/phlippe/uvadlc_notebooks/tree/master (Author: Phillip Lippe)\nFirst, we import the necessary libraries and download the pretrained models.\n\nimport os\nimport numpy as np\nimport random\nimport math\nimport json\nfrom functools import partial\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import to_rgb\nimport matplotlib\nimport seaborn as sns\n\n## tqdm for loading bars\nfrom tqdm.notebook import tqdm\n\n## PyTorch\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data as data\nimport torch.optim as optim\n\n# PyTorch Lightning\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n\n\n# Path to the folder where the pretrained models are saved\nCHECKPOINT_PATH = \"../saved_models/tutorial6\"\n\n# Ensure that all operations are deterministic on GPU (if used) for reproducibility\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\n\nfrom spotpython.utils.device import getDevice\ndevice = getDevice()\nprint(\"Device:\", device)\n\nDevice: mps\n\n\n\n# Setting the seed\npl.seed_everything(42)\n\n42\n\n\nTwo pre-trained models are downloaded below. Make sure to have adjusted your CHECKPOINT_PATH before running this code if not already done.\n\nimport urllib.request\nfrom urllib.error import HTTPError\n# Github URL where saved models are stored for this tutorial\nbase_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial6/\"\n# Files to download\npretrained_files = [\"ReverseTask.ckpt\", \"SetAnomalyTask.ckpt\"]\n\n# Create checkpoint path if it doesn't exist yet\nos.makedirs(CHECKPOINT_PATH, exist_ok=True)\n\n\n31.3.1 Downloading the Pretrained Models\n\n# For each file, check whether it already exists. If not, try downloading it.\nfor file_name in pretrained_files:\n    file_path = os.path.join(CHECKPOINT_PATH, file_name)\n    if \"/\" in file_name:\n        os.makedirs(file_path.rsplit(\"/\",1)[0], exist_ok=True)\n    if not os.path.isfile(file_path):\n        file_url = base_url + file_name\n        print(f\"Downloading {file_url}...\")\n        try:\n            urllib.request.urlretrieve(file_url, file_path)\n        except HTTPError as e:\n            print(\"Error:\\n\", e)\n\n\n\n31.3.2 The Transformer Architecture\nWe will implement the Transformer architecture by hand. As the architecture is so popular, there already exists a Pytorch module nn.Transformer (documentation) and a tutorial on how to use it for next token prediction. However, we will implement it here ourselves, to get through to the smallest details.\n\n\n31.3.3 Attention Mechanism\n\ndef scaled_dot_product(q, k, v, mask=None):\n    \"\"\"\n    Compute scaled dot product attention.\n    Args:\n        q: Queries\n        k: Keys\n        v: Values\n        mask: Mask to apply to the attention logits\n\n    Returns:\n        Tuple of (Values, Attention weights)\n\n    Examples:\n    &gt;&gt;&gt; seq_len, d_k = 1, 2\n        pl.seed_everything(42)\n        q = torch.randn(seq_len, d_k)\n        k = torch.randn(seq_len, d_k)\n        v = torch.randn(seq_len, d_k)\n        values, attention = scaled_dot_product(q, k, v)\n        print(\"Q\\n\", q)\n        print(\"K\\n\", k)\n        print(\"V\\n\", v)\n        print(\"Values\\n\", values)\n        print(\"Attention\\n\", attention)\n    \"\"\"\n    d_k = q.size()[-1]\n    attn_logits = torch.matmul(q, k.transpose(-2, -1))\n    attn_logits = attn_logits / math.sqrt(d_k)\n    if mask is not None:\n        attn_logits = attn_logits.masked_fill(mask == 0, -9e15)\n    attention = F.softmax(attn_logits, dim=-1)\n    values = torch.matmul(attention, v)\n    return values, attention\n\nNote that our code above supports any additional dimensionality in front of the sequence length so that we can also use it for batches. However, for a better understanding, let’s generate a few random queries, keys, and value vectors, and calculate the attention outputs:\n\nseq_len, d_k = 1, 2\npl.seed_everything(42)\nq = torch.randn(seq_len, d_k)\nk = torch.randn(seq_len, d_k)\nv = torch.randn(seq_len, d_k)\nvalues, attention = scaled_dot_product(q, k, v)\nprint(\"Q\\n\", q)\nprint(\"K\\n\", k)\nprint(\"V\\n\", v)\nprint(\"Values\\n\", values)\nprint(\"Attention\\n\", attention)\n\nQ\n tensor([[0.3367, 0.1288]])\nK\n tensor([[0.2345, 0.2303]])\nV\n tensor([[-1.1229, -0.1863]])\nValues\n tensor([[-1.1229, -0.1863]])\nAttention\n tensor([[1.]])\n\n\n\n\n31.3.4 Multi-Head Attention\nThe scaled dot product attention allows a network to attend over a sequence. However, often there are multiple different aspects a sequence element wants to attend to, and a single weighted average is not a good option for it. This is why we extend the attention mechanisms to multiple heads, i.e. multiple different query-key-value triplets on the same features. Specifically, given a query, key, and value matrix, we transform those into \\(h\\) sub-queries, sub-keys, and sub-values, which we pass through the scaled dot product attention independently. Afterward, we concatenate the heads and combine them with a final weight matrix. Mathematically, we can express this operation as:\n\\[\n\\begin{split}\n    \\text{Multihead}(Q,K,V) & = \\text{Concat}(\\text{head}_1,...,\\text{head}_h)W^{O}\\\\\n    \\text{where } \\text{head}_i & = \\text{Attention}(QW_i^Q,KW_i^K, VW_i^V)\n\\end{split}\n\\]\nWe refer to this as Multi-Head Attention layer with the learnable parameters \\(W_{1...h}^{Q}\\in\\mathbb{R}^{D\\times d_k}\\), \\(W_{1...h}^{K}\\in\\mathbb{R}^{D\\times d_k}\\), \\(W_{1...h}^{V}\\in\\mathbb{R}^{D\\times d_v}\\), and \\(W^{O}\\in\\mathbb{R}^{h\\cdot d_v\\times d_{out}}\\) (\\(D\\) being the input dimensionality). Expressed in a computational graph, we can visualize it as in Figure 31.3.\n\n\n\n\n\n\nFigure 31.3: Multi-Head Attention. Figure taken from Vaswani et al. (2017)\n\n\n\nHow are we applying a Multi-Head Attention layer in a neural network, where we do not have an arbitrary query, key, and value vector as input? Looking at the computation graph in Figure 31.3, a simple but effective implementation is to set the current feature map in a NN, \\(X\\in\\mathbb{R}^{B\\times T\\times d_{\\text{model}}}\\), as \\(Q\\), \\(K\\) and \\(V\\) (\\(B\\) being the batch size, \\(T\\) the sequence length, \\(d_{\\text{model}}\\) the hidden dimensionality of \\(X\\)). The consecutive weight matrices \\(W^{Q}\\), \\(W^{K}\\), and \\(W^{V}\\) can transform \\(X\\) to the corresponding feature vectors that represent the queries, keys, and values of the input. Using this approach, we can implement the Multi-Head Attention module below.\nAs a consequence, if the embedding dimension is 4, then 1, 2 or 4 heads can be used, but not 3. If 4 heads are used, then the dimension of the query, key and value vectors is 1. If 2 heads are used, then the dimension of the query, key and value vectors is \\(D=2\\). If 1 head is used, then the dimension of the query, key and value vectors is \\(D=4\\). The number of heads is a hyperparameter that can be adjusted. The number of heads is usually 8 or 16.\n\n# Helper function to support different mask shapes.\n# Output shape supports (batch_size, number of heads, seq length, seq length)\n# If 2D: broadcasted over batch size and number of heads\n# If 3D: broadcasted over number of heads\n# If 4D: leave as is\ndef expand_mask(mask):\n    assert mask.ndim &gt;= 2, \"Mask must be &gt;= 2-dim. with seq_length x seq_length\"\n    if mask.ndim == 3:\n        mask = mask.unsqueeze(1)\n    while mask.ndim &lt; 4:\n        mask = mask.unsqueeze(0)\n    return mask\n\n\nclass MultiheadAttention(nn.Module):\n    \n    def __init__(self, input_dim, embed_dim, num_heads):\n        super().__init__()\n        assert embed_dim % num_heads == 0, \"Embedding dim. must be 0 modulo number of heads.\"\n        \n        self.embed_dim = embed_dim\n        self.num_heads = num_heads\n        self.head_dim = embed_dim // num_heads\n        \n        # Stack all weight matrices 1...h together for efficiency\n        # Note that in many implementations you see \"bias=False\" which is optional\n        self.qkv_proj = nn.Linear(input_dim, 3*embed_dim)\n        self.o_proj = nn.Linear(embed_dim, embed_dim)\n        \n        self._reset_parameters()\n\n    def _reset_parameters(self):\n        # Original Transformer initialization, see PyTorch documentation\n        nn.init.xavier_uniform_(self.qkv_proj.weight)\n        self.qkv_proj.bias.data.fill_(0)\n        nn.init.xavier_uniform_(self.o_proj.weight)\n        self.o_proj.bias.data.fill_(0)\n\n    def forward(self, x, mask=None, return_attention=False):\n        batch_size, seq_length, _ = x.size()\n        if mask is not None:\n            mask = expand_mask(mask)\n        qkv = self.qkv_proj(x)\n        \n        # Separate Q, K, V from linear output\n        qkv = qkv.reshape(batch_size, seq_length, self.num_heads, 3*self.head_dim)\n        qkv = qkv.permute(0, 2, 1, 3) # [Batch, Head, SeqLen, Dims]\n        q, k, v = qkv.chunk(3, dim=-1)\n        \n        # Determine value outputs\n        values, attention = scaled_dot_product(q, k, v, mask=mask)\n        values = values.permute(0, 2, 1, 3) # [Batch, SeqLen, Head, Dims]\n        values = values.reshape(batch_size, seq_length, self.embed_dim)\n        o = self.o_proj(values)\n        \n        if return_attention:\n            return o, attention\n        else:\n            return o\n\n\n\n31.3.5 Permutation Equivariance\nOne crucial characteristic of the multi-head attention is that it is permutation-equivariant with respect to its inputs. This means that if we switch two input elements in the sequence, e.g. \\(X_1\\leftrightarrow X_2\\) (neglecting the batch dimension for now), the output is exactly the same besides the elements 1 and 2 switched. Hence, the multi-head attention is actually looking at the input not as a sequence, but as a set of elements. This property makes the multi-head attention block and the Transformer architecture so powerful and widely applicable! But what if the order of the input is actually important for solving the task, like language modeling? The answer is to encode the position in the input features, which we will take a closer look in Section 31.3.8.\n\n\n31.3.6 Transformer Encoder\nNext, we will look at how to apply the multi-head attention block inside the Transformer architecture. Originally, the Transformer model was designed for machine translation. Hence, it got an encoder-decoder structure where the encoder takes as input the sentence in the original language and generates an attention-based representation. On the other hand, the decoder attends over the encoded information and generates the translated sentence in an autoregressive manner, as in a standard RNN. While this structure is extremely useful for Sequence-to-Sequence tasks with the necessity of autoregressive decoding, we will focus here on the encoder part. Many advances in NLP have been made using pure encoder-based Transformer models (if interested, models include the BERT-family (Devlin et al. 2018), the Vision Transformer (Dosovitskiy et al. 2020), and more). We will also mainly focus on the encoder part. If you have understood the encoder architecture, the decoder is a very small step to implement as well. The full Transformer architecture looks as shown in Figure 31.4.\n\n\n\n\n\n\nFigure 31.4: Transformer architecture. Figure credit: Vaswani et al. (2017)\n\n\n\nThe encoder consists of \\(N\\) identical blocks that are applied in sequence. Taking as input \\(x\\), it is first passed through a Multi-Head Attention block as we have implemented above. The output is added to the original input using a residual connection, and we apply a consecutive Layer Normalization on the sum. Overall, it calculates \\[\n\\text{LayerNorm}(x+\\text{Multihead}(x,x,x))\n\\] (\\(x\\) being \\(Q\\), \\(K\\) and \\(V\\) input to the attention layer). The residual connection is crucial in the Transformer architecture for two reasons:\n\nSimilar to ResNets, Transformers are designed to be very deep. Some models contain more than 24 blocks in the encoder. Hence, the residual connections are crucial for enabling a smooth gradient flow through the model.\nWithout the residual connection, the information about the original sequence is lost. Remember that the Multi-Head Attention layer ignores the position of elements in a sequence, and can only learn it based on the input features. Removing the residual connections would mean that this information is lost after the first attention layer (after initialization), and with a randomly initialized query and key vector, the output vectors for position \\(i\\) has no relation to its original input. All outputs of the attention are likely to represent similar/same information, and there is no chance for the model to distinguish which information came from which input element. An alternative option to residual connection would be to fix at least one head to focus on its original input, but this is very inefficient and does not have the benefit of the improved gradient flow.\n\n\n\n31.3.7 Layer Normalization and Feed-Forward Network\nThe Layer Normalization also plays an important role in the Transformer architecture as it enables faster training and provides small regularization. Additionally, it ensures that the features are in a similar magnitude among the elements in the sequence.\nWe are not using Batch Normalization because it depends on the batch size which is often small with Transformers (they require a lot of GPU memory), and BatchNorm has shown to perform particularly bad in language as the features of words tend to have a much higher variance (there are many, very rare words which need to be considered for a good distribution estimate).\nAdditionally to the Multi-Head Attention, a small fully connected feed-forward network is added to the model, which is applied to each position separately and identically. Specifically, the model uses a Linear\\(\\to\\)ReLU\\(\\to\\)Linear MLP. The full transformation including the residual connection can be expressed as:\n\\[\n\\begin{split}\n    \\text{FFN}(x) & = \\max(0, xW_1+b_1)W_2 + b_2\\\\\n    x & = \\text{LayerNorm}(x + \\text{FFN}(x))\n\\end{split}\n\\]\nThis MLP adds extra complexity to the model and allows transformations on each sequence element separately. You can imagine as this allows the model to “post-process” the new information added by the previous Multi-Head Attention, and prepare it for the next attention block. Usually, the inner dimensionality of the MLP is 2-8\\(\\times\\) larger than \\(d_{\\text{model}}\\), i.e. the dimensionality of the original input \\(x\\). The general advantage of a wider layer instead of a narrow, multi-layer MLP is the faster, parallelizable execution.\nFinally, after looking at all parts of the encoder architecture, we can start implementing it below. We first start by implementing a single encoder block. Additionally to the layers described above, we will add dropout layers in the MLP and on the output of the MLP and Multi-Head Attention for regularization.\n\nclass EncoderBlock(nn.Module):\n    \n    def __init__(self, input_dim, num_heads, dim_feedforward, dropout=0.0):\n        \"\"\"\n        Inputs:\n            input_dim - Dimensionality of the input\n            num_heads - Number of heads to use in the attention block\n            dim_feedforward - Dimensionality of the hidden layer in the MLP\n            dropout - Dropout probability to use in the dropout layers\n        \"\"\"\n        super().__init__()\n        \n        # Attention layer\n        self.self_attn = MultiheadAttention(input_dim, input_dim, num_heads)\n        \n        # Two-layer MLP\n        self.linear_net = nn.Sequential(\n            nn.Linear(input_dim, dim_feedforward),\n            nn.Dropout(dropout),\n            nn.ReLU(inplace=True),\n            nn.Linear(dim_feedforward, input_dim)\n        )\n        \n        # Layers to apply in between the main layers\n        self.norm1 = nn.LayerNorm(input_dim)\n        self.norm2 = nn.LayerNorm(input_dim)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x, mask=None):\n        # Attention part\n        attn_out = self.self_attn(x, mask=mask)\n        x = x + self.dropout(attn_out)\n        x = self.norm1(x)\n        \n        # MLP part\n        linear_out = self.linear_net(x)\n        x = x + self.dropout(linear_out)\n        x = self.norm2(x)\n        \n        return x\n\nBased on this block, we can implement a module for the full Transformer encoder. Additionally to a forward function that iterates through the sequence of encoder blocks, we also provide a function called get_attention_maps. The idea of this function is to return the attention probabilities for all Multi-Head Attention blocks in the encoder. This helps us in understanding, and in a sense, explaining the model. However, the attention probabilities should be interpreted with a grain of salt as it does not necessarily reflect the true interpretation of the model (there is a series of papers about this, including Jain and Wallace (2019) and Wiegreffe and Pinter (2019)).\n\nclass TransformerEncoder(nn.Module):\n    \n    def __init__(self, num_layers, **block_args):\n        super().__init__()\n        self.layers = nn.ModuleList(\n            [EncoderBlock(**block_args) for _ in range(num_layers)])\n\n    def forward(self, x, mask=None):\n        for l in self.layers:\n            x = l(x, mask=mask)\n        return x\n\n    def get_attention_maps(self, x, mask=None):\n        attention_maps = []\n        for l in self.layers:\n            _, attn_map = l.self_attn(x, mask=mask, return_attention=True)\n            attention_maps.append(attn_map)\n            x = l(x)\n        return attention_maps\n\n\n\n31.3.8 Positional Encoding\nWe have discussed before that the Multi-Head Attention block is permutation-equivariant, and cannot distinguish whether an input comes before another one in the sequence or not. In tasks like language understanding, however, the position is important for interpreting the input words. The position information can therefore be added via the input features. We could learn a embedding for every possible position, but this would not generalize to a dynamical input sequence length. Hence, the better option is to use feature patterns that the network can identify from the features and potentially generalize to larger sequences. The specific pattern chosen by Vaswani et al. (2017) are sine and cosine functions of different frequencies, as follows:\n\\[\nPE_{(pos,i)} = \\begin{cases}\n    \\sin\\left(\\frac{pos}{10000^{i/d_{\\text{model}}}}\\right) & \\text{if}\\hspace{3mm} i \\text{ mod } 2=0\\\\\n    \\cos\\left(\\frac{pos}{10000^{(i-1)/d_{\\text{model}}}}\\right) & \\text{otherwise}\\\\\n\\end{cases}\n\\]\n\\(PE_{(pos,i)}\\) represents the position encoding at position \\(pos\\) in the sequence, and hidden dimensionality \\(i\\). These values, concatenated for all hidden dimensions, are added to the original input features (in the Transformer visualization above, see “Positional encoding”), and constitute the position information. We distinguish between even (\\(i \\text{ mod } 2=0\\)) and uneven (\\(i \\text{ mod } 2=1\\)) hidden dimensionalities where we apply a sine/cosine respectively. The intuition behind this encoding is that you can represent \\(PE_{(pos+k,:)}\\) as a linear function of \\(PE_{(pos,:)}\\), which might allow the model to easily attend to relative positions. The wavelengths in different dimensions range from \\(2\\pi\\) to \\(10000\\cdot 2\\pi\\).\nThe positional encoding is implemented below. The code is taken from the PyTorch tutorial https://pytorch.org/tutorials/beginner/transformer_tutorial.html#define-the-model about Transformers on NLP and adjusted for our purposes.\n\nclass PositionalEncoding(nn.Module):\n\n    def __init__(self, d_model, max_len=5000):\n        \"\"\"\n        Inputs\n            d_model - Hidden dimensionality of the input.\n            max_len - Maximum length of a sequence to expect.\n        \"\"\"\n        super().__init__()\n\n        # Create matrix of [SeqLen, HiddenDim] representing \n        # the positional encoding for max_len inputs\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0)\n        \n        # register_buffer =&gt; Tensor which is not a parameter,\n        # but should be part of the modules state.\n        # Used for tensors that need to be on the same device as the module.\n        # persistent=False tells PyTorch to not add the buffer to the \n        # state dict (e.g. when we save the model) \n        self.register_buffer('pe', pe, persistent=False)\n\n    def forward(self, x):\n        x = x + self.pe[:, :x.size(1)]\n        return x\n\nTo understand the positional encoding, we can visualize it below. We will generate an image of the positional encoding over hidden dimensionality and position in a sequence. Each pixel, therefore, represents the change of the input feature we perform to encode the specific position. Let’s do it below.\n\nmatplotlib.rcParams['lines.linewidth'] = 2.0\nplt.set_cmap('cividis')\nencod_block = PositionalEncoding(d_model=48, max_len=96)\npe = encod_block.pe.squeeze().T.cpu().numpy()\n\nfig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8,3))\npos = ax.imshow(pe, cmap=\"RdGy\", extent=(1,pe.shape[1]+1,pe.shape[0]+1,1))\nfig.colorbar(pos, ax=ax)\nax.set_xlabel(\"Position in sequence\")\nax.set_ylabel(\"Hidden dimension\")\nax.set_title(\"Positional encoding over hidden dimensions\")\nax.set_xticks([1]+[i*10 for i in range(1,1+pe.shape[1]//10)])\nax.set_yticks([1]+[i*10 for i in range(1,1+pe.shape[0]//10)])\nplt.show()\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\nYou can clearly see the sine and cosine waves with different wavelengths that encode the position in the hidden dimensions. Specifically, we can look at the sine/cosine wave for each hidden dimension separately, to get a better intuition of the pattern. Below we visualize the positional encoding for the hidden dimensions \\(1\\), \\(2\\), \\(3\\) and \\(4\\).\n\nsns.set_theme()\nfig, ax = plt.subplots(2, 2, figsize=(12,4))\nax = [a for a_list in ax for a in a_list]\nfor i in range(len(ax)):\n    ax[i].plot(np.arange(1,17), pe[i,:16], color=f'C{i}', marker=\"o\",\n                markersize=6, markeredgecolor=\"black\")\n    ax[i].set_title(f\"Encoding in hidden dimension {i+1}\")\n    ax[i].set_xlabel(\"Position in sequence\", fontsize=10)\n    ax[i].set_ylabel(\"Positional encoding\", fontsize=10)\n    ax[i].set_xticks(np.arange(1,17))\n    ax[i].tick_params(axis='both', which='major', labelsize=10)\n    ax[i].tick_params(axis='both', which='minor', labelsize=8)\n    ax[i].set_ylim(-1.2, 1.2)\nfig.subplots_adjust(hspace=0.8)\nsns.reset_orig()\nplt.show()\n\n\n\n\n\n\n\n\nAs we can see, the patterns between the hidden dimension \\(1\\) and \\(2\\) only differ in the starting angle. The wavelength is \\(2\\pi\\), hence the repetition after position \\(6\\). The hidden dimensions \\(2\\) and \\(3\\) have about twice the wavelength.\n\n\n31.3.9 Learning Rate Warm-up\nOne commonly used technique for training a Transformer is learning rate warm-up. This means that we gradually increase the learning rate from 0 on to our originally specified learning rate in the first few iterations. Thus, we slowly start learning instead of taking very large steps from the beginning. In fact, training a deep Transformer without learning rate warm-up can make the model diverge and achieve a much worse performance on training and testing. Take for instance the following plot by Liu et al. (2019) comparing Adam-vanilla (i.e. Adam without warm-up) vs Adam with a warm-up:\n\n\n\nWarm-up comparison. Figure taken from Liu et al. (2019)\n\n\nClearly, the warm-up is a crucial hyperparameter in the Transformer architecture. Why is it so important? There are currently two common explanations. Firstly, Adam uses the bias correction factors which however can lead to a higher variance in the adaptive learning rate during the first iterations. Improved optimizers like RAdam have been shown to overcome this issue, not requiring warm-up for training Transformers. Secondly, the iteratively applied Layer Normalization across layers can lead to very high gradients during the first iterations, which can be solved by using Pre-Layer Normalization (similar to Pre-Activation ResNet), or replacing Layer Normalization by other techniques (Adaptive Normalization, Power Normalization).\nNevertheless, many applications and papers still use the original Transformer architecture with Adam, because warm-up is a simple, yet effective way of solving the gradient problem in the first iterations. There are many different schedulers we could use. For instance, the original Transformer paper used an exponential decay scheduler with a warm-up. However, the currently most popular scheduler is the cosine warm-up scheduler, which combines warm-up with a cosine-shaped learning rate decay. We can implement it below, and visualize the learning rate factor over epochs.\n\nclass CosineWarmupScheduler(optim.lr_scheduler._LRScheduler):\n    \n    def __init__(self, optimizer, warmup, max_iters):\n        self.warmup = warmup\n        self.max_num_iters = max_iters\n        super().__init__(optimizer)\n        \n    def get_lr(self):\n        lr_factor = self.get_lr_factor(epoch=self.last_epoch)\n        return [base_lr * lr_factor for base_lr in self.base_lrs]\n    \n    def get_lr_factor(self, epoch):\n        lr_factor = 0.5 * (1 + np.cos(np.pi * epoch / self.max_num_iters))\n        if epoch &lt;= self.warmup:\n            lr_factor *= epoch * 1.0 / self.warmup\n        return lr_factor\n\n\n# Needed for initializing the lr scheduler\np = nn.Parameter(torch.empty(4,4))\noptimizer = optim.Adam([p], lr=1e-3)\nlr_scheduler = CosineWarmupScheduler(optimizer=optimizer, warmup=100, max_iters=2000)\n\n# Plotting\nepochs = list(range(2000))\nsns.set()\nplt.figure(figsize=(8,3))\nplt.plot(epochs, [lr_scheduler.get_lr_factor(e) for e in epochs])\nplt.ylabel(\"Learning rate factor\")\nplt.xlabel(\"Iterations (in batches)\")\nplt.title(\"Cosine Warm-up Learning Rate Scheduler\")\nplt.show()\nsns.reset_orig()\n\n\n\n\n\n\n\n\nIn the first 100 iterations, we increase the learning rate factor from 0 to 1, whereas for all later iterations, we decay it using the cosine wave. Pre-implementations of this scheduler can be found in the popular NLP Transformer library huggingface.\n\n\n31.3.10 PyTorch Lightning Module\nFinally, we can embed the Transformer architecture into a PyTorch lightning module. PyTorch Lightning simplifies our training and test code, as well as structures the code nicely in separate functions. We will implement a template for a classifier based on the Transformer encoder. Thereby, we have a prediction output per sequence element. If we would need a classifier over the whole sequence, the common approach is to add an additional [CLS] token to the sequence (CLS stands for classification, i.e., the first token of every sequence is always a special classification token, CLS). However, here we focus on tasks where we have an output per element.\nAdditionally to the Transformer architecture, we add a small input network (maps input dimensions to model dimensions), the positional encoding, and an output network (transforms output encodings to predictions). We also add the learning rate scheduler, which takes a step each iteration instead of once per epoch. This is needed for the warmup and the smooth cosine decay. The training, validation, and test step is left empty for now and will be filled for our task-specific models.\n\nclass TransformerPredictor(pl.LightningModule):\n\n    def __init__(self, input_dim, model_dim, num_classes, num_heads, num_layers, lr, warmup, max_iters, dropout=0.0, input_dropout=0.0):\n        \"\"\"\n        Inputs:\n            input_dim - Hidden dimensionality of the input\n            model_dim - Hidden dimensionality to use inside the Transformer\n            num_classes - Number of classes to predict per sequence element\n            num_heads - Number of heads to use in the Multi-Head Attention blocks\n            num_layers - Number of encoder blocks to use.\n            lr - Learning rate in the optimizer\n            warmup - Number of warmup steps. Usually between 50 and 500\n            max_iters - Number of maximum iterations the model is trained for. This is needed for the CosineWarmup scheduler\n            dropout - Dropout to apply inside the model\n            input_dropout - Dropout to apply on the input features\n        \"\"\"\n        super().__init__()\n        self.save_hyperparameters()\n        self._create_model()\n\n    def _create_model(self):\n        # Input dim -&gt; Model dim\n        self.input_net = nn.Sequential(\n            nn.Dropout(self.hparams.input_dropout),\n            nn.Linear(self.hparams.input_dim, self.hparams.model_dim)\n        )\n        # Positional encoding for sequences\n        self.positional_encoding = PositionalEncoding(d_model=self.hparams.model_dim)\n        # Transformer\n        self.transformer = TransformerEncoder(num_layers=self.hparams.num_layers,\n                                              input_dim=self.hparams.model_dim,\n                                              dim_feedforward=2*self.hparams.model_dim,\n                                              num_heads=self.hparams.num_heads,\n                                              dropout=self.hparams.dropout)\n        # Output classifier per sequence lement\n        self.output_net = nn.Sequential(\n            nn.Linear(self.hparams.model_dim, self.hparams.model_dim),\n            nn.LayerNorm(self.hparams.model_dim),\n            nn.ReLU(inplace=True),\n            nn.Dropout(self.hparams.dropout),\n            nn.Linear(self.hparams.model_dim, self.hparams.num_classes)\n        ) \n\n    def forward(self, x, mask=None, add_positional_encoding=True):\n        \"\"\"\n        Inputs:\n            x - Input features of shape [Batch, SeqLen, input_dim]\n            mask - Mask to apply on the attention outputs (optional)\n            add_positional_encoding - If True, we add the positional encoding to the input.\n                                      Might not be desired for some tasks.\n        \"\"\"\n        x = self.input_net(x)\n        if add_positional_encoding:\n            x = self.positional_encoding(x)\n        x = self.transformer(x, mask=mask)\n        x = self.output_net(x)\n        return x\n\n    @torch.no_grad()\n    def get_attention_maps(self, x, mask=None, add_positional_encoding=True):\n        \"\"\"\n        Function for extracting the attention matrices of the whole Transformer for a single batch.\n        Input arguments same as the forward pass.\n        \"\"\"\n        x = self.input_net(x)\n        if add_positional_encoding:\n            x = self.positional_encoding(x)\n        attention_maps = self.transformer.get_attention_maps(x, mask=mask)\n        return attention_maps\n\n    def configure_optimizers(self):\n        optimizer = optim.Adam(self.parameters(), lr=self.hparams.lr)\n        \n        # Apply lr scheduler per step\n        lr_scheduler = CosineWarmupScheduler(optimizer, \n                                             warmup=self.hparams.warmup, \n                                             max_iters=self.hparams.max_iters)\n        return [optimizer], [{'scheduler': lr_scheduler, 'interval': 'step'}]\n\n    def training_step(self, batch, batch_idx):\n        raise NotImplementedError\n\n    def validation_step(self, batch, batch_idx):\n        raise NotImplementedError    \n\n    def test_step(self, batch, batch_idx):\n        raise NotImplementedError",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>HPT PyTorch Lightning Transformer: Introduction</span>"
    ]
  },
  {
    "objectID": "603_spot_lightning_transformer_introduction.html#experiment-sequence-to-sequence",
    "href": "603_spot_lightning_transformer_introduction.html#experiment-sequence-to-sequence",
    "title": "31  HPT PyTorch Lightning Transformer: Introduction",
    "section": "31.4 Experiment: Sequence to Sequence",
    "text": "31.4 Experiment: Sequence to Sequence\nAfter having finished the implementation of the Transformer architecture, we can start experimenting and apply it to various tasks. We will focus on parallel Sequence-to-Sequence.\nA Sequence-to-Sequence task represents a task where the input and the output is a sequence, not necessarily of the same length. Popular tasks in this domain include machine translation and summarization. For this, we usually have a Transformer encoder for interpreting the input sequence, and a decoder for generating the output in an autoregressive manner. Here, however, we will go back to a much simpler example task and use only the encoder. Given a sequence of \\(N\\) numbers between \\(0\\) and \\(M\\), the task is to reverse the input sequence. In Numpy notation, if our input is \\(x\\), the output should be \\(x\\)[::-1]. Although this task sounds very simple, RNNs can have issues with such because the task requires long-term dependencies. Transformers are built to support such, and hence, we expect it to perform very well.\n\n31.4.1 Dataset and Data Loaders\nFirst, let’s create a dataset class below.\n\nclass ReverseDataset(data.Dataset):\n\n    def __init__(self, num_categories, seq_len, size):\n        super().__init__()\n        self.num_categories = num_categories\n        self.seq_len = seq_len\n        self.size = size\n        \n        self.data = torch.randint(self.num_categories, size=(self.size, self.seq_len))\n  \n    def __len__(self):\n        return self.size\n\n    def __getitem__(self, idx):\n        inp_data = self.data[idx]\n        labels = torch.flip(inp_data, dims=(0,))\n        return inp_data, labels\n\nWe create an arbitrary number of random sequences of numbers between 0 and num_categories-1. The label is simply the tensor flipped over the sequence dimension. We can create the corresponding data loaders below.\n\ndataset = partial(ReverseDataset, 10, 16)\ntrain_loader = data.DataLoader(dataset(50000),\n                                batch_size=128,\n                                shuffle=True,\n                                drop_last=True,\n                                pin_memory=True)\nval_loader   = data.DataLoader(dataset(1000), batch_size=128)\ntest_loader  = data.DataLoader(dataset(10000), batch_size=128)\n\n\ninp_data, labels = train_loader.dataset[0]\nprint(\"Input data:\", inp_data)\nprint(\"Labels:    \", labels)\n\nInput data: tensor([0, 4, 1, 2, 5, 5, 7, 6, 9, 6, 3, 1, 9, 3, 1, 9])\nLabels:     tensor([9, 1, 3, 9, 1, 3, 6, 9, 6, 7, 5, 5, 2, 1, 4, 0])\n\n\nDuring training, we pass the input sequence through the Transformer encoder and predict the output for each input token. We use the standard Cross-Entropy loss to perform this. Every number is represented as a one-hot vector. Remember that representing the categories as single scalars decreases the expressiveness of the model extremely as \\(0\\) and \\(1\\) are not closer related than \\(0\\) and \\(9\\) in our example. An alternative to a one-hot vector is using a learned embedding vector as it is provided by the PyTorch module nn.Embedding. However, using a one-hot vector with an additional linear layer as in our case has the same effect as an embedding layer (self.input_net maps one-hot vector to a dense vector, where each row of the weight matrix represents the embedding for a specific category).\n\n\n31.4.2 The Reverse Predictor Class\nTo implement the training dynamic, we create a new class inheriting from TransformerPredictor and overwriting the training, validation and test step functions, which were left empty in the base class. We also add a _calculate_loss function to calculate the loss and accuracy for a batch.\n\nclass ReversePredictor(TransformerPredictor):\n    \n    def _calculate_loss(self, batch, mode=\"train\"):\n        # Fetch data and transform categories to one-hot vectors\n        inp_data, labels = batch\n        inp_data = F.one_hot(inp_data, num_classes=self.hparams.num_classes).float()\n        \n        # Perform prediction and calculate loss and accuracy\n        preds = self.forward(inp_data, add_positional_encoding=True)\n        loss = F.cross_entropy(preds.view(-1,preds.size(-1)), labels.view(-1))\n        acc = (preds.argmax(dim=-1) == labels).float().mean()\n        \n        # Logging\n        self.log(f\"{mode}_loss\", loss)\n        self.log(f\"{mode}_acc\", acc)\n        return loss, acc\n        \n    def training_step(self, batch, batch_idx):\n        loss, _ = self._calculate_loss(batch, mode=\"train\")\n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        _ = self._calculate_loss(batch, mode=\"val\")\n    \n    def test_step(self, batch, batch_idx):\n        _ = self._calculate_loss(batch, mode=\"test\")\n\nFinally, we can create a training function. We create a pl.Trainer object, running for \\(N\\) epochs, logging in TensorBoard, and saving our best model based on the validation. Afterward, we test our models on the test set.\n\n\n31.4.3 Gradient Clipping\nAn additional parameter we pass to the trainer here is gradient_clip_val. This clips the norm of the gradients for all parameters before taking an optimizer step and prevents the model from diverging if we obtain very high gradients at, for instance, sharp loss surfaces (see many good blog posts on gradient clipping, like DeepAI glossary). For Transformers, gradient clipping can help to further stabilize the training during the first few iterations, and also afterward. In plain PyTorch, you can apply gradient clipping via torch.nn.utils.clip_grad_norm_(...) (see documentation). The clip value is usually between 0.5 and 10, depending on how harsh you want to clip large gradients.\n\n\n31.4.4 Implementation of the Lightning Trainer\nThe Lightning trainer can be implemented as follows:\n\ndef train_reverse(**kwargs):\n    # Create a PyTorch Lightning trainer with the generation callback\n    root_dir = os.path.join(CHECKPOINT_PATH, \"ReverseTask\")\n    os.makedirs(root_dir, exist_ok=True)\n    trainer = pl.Trainer(default_root_dir=root_dir, \n                         callbacks=[ModelCheckpoint(save_weights_only=True,\n                                    mode=\"max\", monitor=\"val_acc\")],\n                         accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n                         devices=1,\n                         max_epochs=10,\n                         gradient_clip_val=5)\n    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n    \n    # Check whether pretrained model exists. If yes, load it and skip training\n    pretrained_filename = os.path.join(CHECKPOINT_PATH, \"ReverseTask.ckpt\")\n    if os.path.isfile(pretrained_filename):\n        print(\"Found pretrained model, loading...\")\n        model = ReversePredictor.load_from_checkpoint(pretrained_filename)\n    else:\n        model = ReversePredictor(max_iters=trainer.max_epochs*len(train_loader), **kwargs)\n        trainer.fit(model, train_loader, val_loader)\n        \n    # Test best model on validation and test set\n    val_result = trainer.test(model, val_loader, verbose=False)\n    test_result = trainer.test(model, test_loader, verbose=False)\n    result = {\"test_acc\": test_result[0][\"test_acc\"], \"val_acc\": val_result[0][\"test_acc\"]}\n    \n    model = model.to(device)\n    return model, result\n\n\n\n31.4.5 Training the Model\nFinally, we can train the model. In this setup, we will use a single encoder block and a single head in the Multi-Head Attention. This is chosen because of the simplicity of the task, and in this case, the attention can actually be interpreted as an “explanation” of the predictions (compared to the other papers above dealing with deep Transformers).\n\nreverse_model, reverse_result = train_reverse(input_dim=train_loader.dataset.num_categories,\n                                              model_dim=32,\n                                              num_heads=1,\n                                              num_classes=train_loader.dataset.num_categories,\n                                              num_layers=1,\n                                              dropout=0.0,\n                                              lr=5e-4,\n                                              warmup=50)\n\nFound pretrained model, loading...\n\n\n\n\n\n\n\n\nThe warning of PyTorch Lightning regarding the number of workers can be ignored for now. As the data set is so simple and the __getitem__ finishes a neglectable time, we don’t need subprocesses to provide us the data (in fact, more workers can slow down the training as we have communication overhead among processes/threads). First, let’s print the results:\n\nprint(f\"Val accuracy:  {(100.0 * reverse_result['val_acc']):4.2f}%\")\nprint(f\"Test accuracy: {(100.0 * reverse_result['test_acc']):4.2f}%\")\n\nVal accuracy:  100.00%\nTest accuracy: 100.00%\n\n\nAs we would have expected, the Transformer can correctly solve the task.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>HPT PyTorch Lightning Transformer: Introduction</span>"
    ]
  },
  {
    "objectID": "603_spot_lightning_transformer_introduction.html#visualizing-attention-maps",
    "href": "603_spot_lightning_transformer_introduction.html#visualizing-attention-maps",
    "title": "31  HPT PyTorch Lightning Transformer: Introduction",
    "section": "31.5 Visualizing Attention Maps",
    "text": "31.5 Visualizing Attention Maps\nHow does the attention in the Multi-Head Attention block looks like for an arbitrary input? Let’s try to visualize it below.\n\ndata_input, labels = next(iter(val_loader))\ninp_data = F.one_hot(data_input, num_classes=reverse_model.hparams.num_classes).float()\ninp_data = inp_data.to(device)\nattention_maps = reverse_model.get_attention_maps(inp_data)\n\nThe object attention_maps is a list of length \\(N\\) where \\(N\\) is the number of layers. Each element is a tensor of shape [Batch, Heads, SeqLen, SeqLen], which we can verify below.\n\nattention_maps[0].shape\n\ntorch.Size([128, 1, 16, 16])\n\n\nNext, we will write a plotting function that takes as input the sequences, attention maps, and an index indicating for which batch element we want to visualize the attention map. We will create a plot where over rows, we have different layers, while over columns, we show the different heads. Remember that the softmax has been applied for each row separately.\n\ndef plot_attention_maps(input_data, attn_maps, idx=0):\n    if input_data is not None:\n        input_data = input_data[idx].detach().cpu().numpy()\n    else:\n        input_data = np.arange(attn_maps[0][idx].shape[-1])\n    attn_maps = [m[idx].detach().cpu().numpy() for m in attn_maps]\n    \n    num_heads = attn_maps[0].shape[0]\n    num_layers = len(attn_maps)\n    seq_len = input_data.shape[0]\n    fig_size = 4 if num_heads == 1 else 3\n    fig, ax = plt.subplots(num_layers, num_heads, figsize=(num_heads*fig_size, num_layers*fig_size))\n    if num_layers == 1:\n        ax = [ax]\n    if num_heads == 1:\n        ax = [[a] for a in ax]\n    for row in range(num_layers):\n        for column in range(num_heads):\n            ax[row][column].imshow(attn_maps[row][column], origin='lower', vmin=0)\n            ax[row][column].set_xticks(list(range(seq_len)))\n            ax[row][column].set_xticklabels(input_data.tolist())\n            ax[row][column].set_yticks(list(range(seq_len)))\n            ax[row][column].set_yticklabels(input_data.tolist())\n            ax[row][column].set_title(f\"Layer {row+1}, Head {column+1}\")\n    fig.subplots_adjust(hspace=0.5)\n    cax = fig.add_axes([0.95, 0.15, 0.01, 0.7])\n    cbar = fig.colorbar(ax[0][0].imshow(attn_maps[0][0], origin='lower', vmin=0), cax=cax)\n    cbar.set_label('Attention')\n    plt.show()\n\nFinally, we can plot the attention map of our trained Transformer on the reverse task:\n\nplot_attention_maps(data_input, attention_maps, idx=0)\n\n\n\n\n\n\n\n\nThe model has learned to attend to the token that is on the flipped index of itself. Hence, it actually does what we intended it to do. We see that it however also pays some attention to values close to the flipped index. This is because the model doesn’t need the perfect, hard attention to solve this problem, but is fine with this approximate, noisy attention map. The close-by indices are caused by the similarity of the positional encoding, which we also intended with the positional encoding.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>HPT PyTorch Lightning Transformer: Introduction</span>"
    ]
  },
  {
    "objectID": "603_spot_lightning_transformer_introduction.html#conclusion",
    "href": "603_spot_lightning_transformer_introduction.html#conclusion",
    "title": "31  HPT PyTorch Lightning Transformer: Introduction",
    "section": "31.6 Conclusion",
    "text": "31.6 Conclusion\nIn this chapter, we took a closer look at the Multi-Head Attention layer which uses a scaled dot product between queries and keys to find correlations and similarities between input elements. The Transformer architecture is based on the Multi-Head Attention layer and applies multiple of them in a ResNet-like block. The Transformer is a very important, recent architecture that can be applied to many tasks and datasets. Although it is best known for its success in NLP, there is so much more to it. We have seen its application on sequence-to-sequence tasks. Its property of being permutation-equivariant if we do not provide any positional encodings, allows it to generalize to many settings. Hence, it is important to know the architecture, but also its possible issues such as the gradient problem during the first iterations solved by learning rate warm-up. If you are interested in continuing with the study of the Transformer architecture, please have a look at the blog posts listed in the “Further Reading” section below.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>HPT PyTorch Lightning Transformer: Introduction</span>"
    ]
  },
  {
    "objectID": "603_spot_lightning_transformer_introduction.html#additional-considerations",
    "href": "603_spot_lightning_transformer_introduction.html#additional-considerations",
    "title": "31  HPT PyTorch Lightning Transformer: Introduction",
    "section": "31.7 Additional Considerations",
    "text": "31.7 Additional Considerations\n\n31.7.1 Complexity and Path Length\nWe can compare the self-attention operation with our other common layer competitors for sequence data: convolutions and recurrent neural networks. In Figure 31.5 you can find a table by Vaswani et al. (2017) on the complexity per layer, the number of sequential operations, and maximum path length. The complexity is measured by the upper bound of the number of operations to perform, while the maximum path length represents the maximum number of steps a forward or backward signal has to traverse to reach any other position. The lower this length, the better gradient signals can backpropagate for long-range dependencies. Let’s take a look at the table in Figure 31.5.\n\n\n\n\n\n\nFigure 31.5: Comparison of complexity and path length of different sequence layers. Table taken from Lippe (2022)\n\n\n\n\\(n\\) is the sequence length, \\(d\\) is the representation dimension and \\(k\\) is the kernel size of convolutions. In contrast to recurrent networks, the self-attention layer can parallelize all its operations making it much faster to execute for smaller sequence lengths. However, when the sequence length exceeds the hidden dimensionality, self-attention becomes more expensive than RNNs. One way of reducing the computational cost for long sequences is by restricting the self-attention to a neighborhood of inputs to attend over, denoted by \\(r\\). Nevertheless, there has been recently a lot of work on more efficient Transformer architectures that still allow long dependencies, of which you can find an overview in the paper by Tay et al. (2020) if interested.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>HPT PyTorch Lightning Transformer: Introduction</span>"
    ]
  },
  {
    "objectID": "603_spot_lightning_transformer_introduction.html#further-reading",
    "href": "603_spot_lightning_transformer_introduction.html#further-reading",
    "title": "31  HPT PyTorch Lightning Transformer: Introduction",
    "section": "31.8 Further Reading",
    "text": "31.8 Further Reading\nThere are of course many more tutorials out there about attention and Transformers. Below, we list a few that are worth exploring if you are interested in the topic and might want yet another perspective on the topic after this one:\n\nTransformer: A Novel Neural Network Architecture for Language Understanding (Jakob Uszkoreit, 2017) - The original Google blog post about the Transformer paper, focusing on the application in machine translation.\nThe Illustrated Transformer (Jay Alammar, 2018) - A very popular and great blog post intuitively explaining the Transformer architecture with many nice visualizations. The focus is on NLP.\nAttention? Attention! (Lilian Weng, 2018) - A nice blog post summarizing attention mechanisms in many domains including vision.\nIllustrated: Self-Attention (Raimi Karim, 2019) - A nice visualization of the steps of self-attention. Recommended going through if the explanation below is too abstract for you.\nThe Transformer family (Lilian Weng, 2020) - A very detailed blog post reviewing more variants of Transformers besides the original one.\n\n\n\n\n\nDevlin, Jacob, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.” arXiv e-Prints, October, arXiv:1810.04805.\n\n\nDosovitskiy, Alexey, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, et al. 2020. “An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale.” arXiv e-Prints, October, arXiv:2010.11929.\n\n\nJain, Sarthak, and Byron C. Wallace. 2019. “Attention is not Explanation.” arXiv e-Prints, February, arXiv:1902.10186.\n\n\nLippe, Phillip. 2022. “UvA Deep Learning Tutorials.”\n\n\nLiu, Liyuan, Haoming Jiang, Pengcheng He, Weizhu Chen, Xiaodong Liu, Jianfeng Gao, and Jiawei Han. 2019. “On the Variance of the Adaptive Learning Rate and Beyond.” arXiv e-Prints, August, arXiv:1908.03265.\n\n\nTay, Yi, Mostafa Dehghani, Dara Bahri, and Donald Metzler. 2020. “Efficient Transformers: A Survey.” arXiv e-Prints, September, arXiv:2009.06732.\n\n\nVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. “Attention Is All You Need.” arXiv e-Prints, June, 1–15.\n\n\nWiegreffe, Sarah, and Yuval Pinter. 2019. “Attention is not not Explanation.” arXiv e-Prints, August, arXiv:1908.04626.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>HPT PyTorch Lightning Transformer: Introduction</span>"
    ]
  },
  {
    "objectID": "603_spot_lightning_transformer_hpt.html",
    "href": "603_spot_lightning_transformer_hpt.html",
    "title": "32  Hyperparameter Tuning of a Transformer Network with PyTorch Lightning",
    "section": "",
    "text": "32.1 Basic Setup\nThis section provides an overview of the hyperparameter tuning process using spotpython and PyTorch Lightning. It uses the Diabetes data set (see Section E.1) for a regression task.\nIn this section, we will show how spotpython can be integrated into the PyTorch Lightning training workflow for a regression task. It demonstrates how easy it is to use spotpython to tune hyperparameters for a PyTorch Lightning model.\nAfter importing the necessary libraries, the fun_control dictionary is set up via the fun_control_init function. The fun_control dictionary contains\nThe method set_hyperparameter allows the user to modify default hyperparameter settings. Here we set the initialization method to [\"Default\"]. No other initializations are used in this experiment. The HyperLight class is used to define the objective function fun. It connects the PyTorch and the spotpython methods and is provided by spotpython. Finally, a Spot object is created.\nfrom spotpython.data.diabetes import Diabetes\nfrom spotpython.hyperdict.light_hyper_dict import LightHyperDict\nfrom spotpython.fun.hyperlight import HyperLight\nfrom spotpython.utils.init import (fun_control_init, surrogate_control_init, design_control_init)\nfrom spotpython.utils.eda import gen_design_table\nfrom spotpython.hyperparameters.values import set_hyperparameter\nfrom spotpython.spot import spot\nfrom spotpython.utils.file import get_experiment_filename\nfrom spotpython.utils.scaler import TorchStandardScaler\n\nfun_control = fun_control_init(\n    PREFIX=\"603\",\n    TENSORBOARD_CLEAN=True,\n    tensorboard_log=True,\n    fun_evals=inf,\n    max_time=1,\n    data_set = Diabetes(),\n    scaler=TorchStandardScaler(),\n    core_model_name=\"light.regression.NNTransformerRegressor\",\n    hyperdict=LightHyperDict,\n    _L_in=10,\n    _L_out=1)\n\nset_hyperparameter(fun_control, \"optimizer\", [\n                \"Adadelta\",\n                \"Adagrad\",\n                \"Adam\",\n                \"AdamW\",\n                \"Adamax\",\n            ])\nset_hyperparameter(fun_control, \"epochs\", [5, 7])\nset_hyperparameter(fun_control, \"nhead\", [1, 2])\nset_hyperparameter(fun_control, \"dim_feedforward_mult\", [1, 1])\n\ndesign_control = design_control_init(init_size=5)\nsurrogate_control = surrogate_control_init(\n    noise=True,\n    min_Lambda=1e-3,\n    max_Lambda=10,\n)\n\nfun = HyperLight().fun\n\nspot_tuner = spot.Spot(fun=fun,fun_control=fun_control, design_control=design_control, surrogate_control=surrogate_control)\n\nMoving TENSORBOARD_PATH: runs/ to TENSORBOARD_PATH_OLD: runs_OLD/runs_2024_10_12_12_31_40\nCreated spot_tensorboard_path: runs/spot_logs/603_maans14_2024-10-12_12-31-40 for SummaryWriter()\nmodule_name: light\nsubmodule_name: regression\nmodel_name: NNTransformerRegressor\nWe can take a look at the design table to see the initial design.\nprint(gen_design_table(fun_control))\n\n| name                 | type   | default        |   lower |   upper | transform             |\n|----------------------|--------|----------------|---------|---------|-----------------------|\n| d_model_mult         | int    | 4              |    1    |     5   | transform_power_2_int |\n| nhead                | int    | 3              |    1    |     2   | transform_power_2_int |\n| num_encoder_layers   | int    | 1              |    1    |     4   | transform_power_2_int |\n| dim_feedforward_mult | int    | 1              |    1    |     1   | transform_power_2_int |\n| epochs               | int    | 7              |    5    |     7   | transform_power_2_int |\n| batch_size           | int    | 5              |    5    |     8   | transform_power_2_int |\n| optimizer            | factor | Adam           |    0    |     4   | None                  |\n| dropout              | float  | 0.1            |    0.01 |     0.1 | None                  |\n| lr_mult              | float  | 0.1            |    0.01 |     0.3 | None                  |\n| patience             | int    | 5              |    4    |     7   | transform_power_2_int |\n| initialization       | factor | xavier_uniform |    0    |     3   | None                  |\nIf we want to run the hyperparameter tuning process on a remote server, we can save the setting as a pickle file and load it on the remote server.\nfilename = get_experiment_filename(fun_control[\"PREFIX\"])\n# if userExperimnents directory does not exist, create it\nif not os.path.exists(\"userExperiment\"):\n    os.makedirs(\"userExperiment\")\nfilename = os.path.join(\"userExperiment\", filename)\nif spot_tuner.spot_writer is not None:\n    spot_tuner.spot_writer.close()\n# remove attribute spot_writer from spot_tuner object\nif hasattr(spot_tuner, \"spot_writer\"):\n    delattr(spot_tuner, \"spot_writer\")\nspot_tuner.save_experiment(filename=filename)\n\nExperiment saved to userExperiment/spot_603_experiment.pickle\nCalling the method run() starts the hyperparameter tuning process on the local machine.\nres = spot_tuner.run()\n\nd_model: 8, dim_feedforward: 16\nMilestones: [16, 32, 48]\n\n\ntrain_model result: {'val_loss': 23954.24609375, 'hp_metric': 23954.24609375}\nd_model: 128, dim_feedforward: 256\nMilestones: [32, 64, 96]\n\n\ntrain_model result: {'val_loss': 20689.533203125, 'hp_metric': 20689.533203125}\nd_model: 32, dim_feedforward: 64\nMilestones: [8, 16, 24]\n\n\ntrain_model result: {'val_loss': 23385.4296875, 'hp_metric': 23385.4296875}\nd_model: 16, dim_feedforward: 32\nMilestones: [8, 16, 24]\n\n\ntrain_model result: {'val_loss': 23920.986328125, 'hp_metric': 23920.986328125}\nd_model: 8, dim_feedforward: 16\nMilestones: [16, 32, 48]\n\n\ntrain_model result: {'val_loss': 23945.990234375, 'hp_metric': 23945.990234375}\nd_model: 128, dim_feedforward: 256\n\n\nMilestones: [32, 64, 96]\n\n\ntrain_model result: {'val_loss': 19936.63671875, 'hp_metric': 19936.63671875}\nspotpython tuning: 19936.63671875 [#---------] 14.31% \nd_model: 128, dim_feedforward: 256\n\n\n\nMilestones: [32, 64, 96]\n\n\ntrain_model result: {'val_loss': 19263.798828125, 'hp_metric': 19263.798828125}\nspotpython tuning: 19263.798828125 [###-------] 29.03% \n\n\nd_model: 128, dim_feedforward: 256\nMilestones: [32, 64, 96]\n\n\ntrain_model result: {'val_loss': 18752.330078125, 'hp_metric': 18752.330078125}\nspotpython tuning: 18752.330078125 [#####-----] 46.61% \n\n\nd_model: 128, dim_feedforward: 256\nMilestones: [32, 64, 96]\n\n\ntrain_model result: {'val_loss': 19413.541015625, 'hp_metric': 19413.541015625}\nspotpython tuning: 18752.330078125 [#######---] 72.36% \n\n\nd_model: 128, dim_feedforward: 256\nMilestones: [16, 32, 48]\n\n\ntrain_model result: {'val_loss': 20917.896484375, 'hp_metric': 20917.896484375}\nspotpython tuning: 18752.330078125 [########--] 82.25% \n\n\nd_model: 128, dim_feedforward: 256\nMilestones: [32, 64, 96]\n\n\ntrain_model result: {'val_loss': 20649.611328125, 'hp_metric': 20649.611328125}\nspotpython tuning: 18752.330078125 [##########] 95.89% \n\n\nd_model: 32, dim_feedforward: 64\nMilestones: [32, 64, 96]\n\n\ntrain_model result: {'val_loss': 22397.33203125, 'hp_metric': 22397.33203125}\nspotpython tuning: 18752.330078125 [##########] 100.00% Done...\nNote that we have enabled Tensorboard-Logging, so we can visualize the results with Tensorboard. Execute the following command in the terminal to start Tensorboard.\ntensorboard --logdir=\"runs/\"",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Hyperparameter Tuning of a Transformer Network with PyTorch Lightning</span>"
    ]
  },
  {
    "objectID": "603_spot_lightning_transformer_hpt.html#sec-basic-setup-603",
    "href": "603_spot_lightning_transformer_hpt.html#sec-basic-setup-603",
    "title": "32  Hyperparameter Tuning of a Transformer Network with PyTorch Lightning",
    "section": "",
    "text": "PREFIX: a unique identifier for the experiment\nfun_evals: the number of function evaluations\nmax_time: the maximum run time in minutes\ndata_set: the data set. Here we use the Diabetes data set that is provided by spotpython.\ncore_model_name: the class name of the neural network model. This neural network model is provided by spotpython.\nhyperdict: the hyperparameter dictionary. This dictionary is used to define the hyperparameters of the neural network model. It is also provided by spotpython.\n_L_in: the number of input features. Since the Diabetes data set has 10 features, _L_in is set to 10.\n_L_out: the number of output features. Since we want to predict a single value, _L_out is set to 1.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Hyperparameter Tuning of a Transformer Network with PyTorch Lightning</span>"
    ]
  },
  {
    "objectID": "603_spot_lightning_transformer_hpt.html#looking-at-the-results",
    "href": "603_spot_lightning_transformer_hpt.html#looking-at-the-results",
    "title": "32  Hyperparameter Tuning of a Transformer Network with PyTorch Lightning",
    "section": "32.2 Looking at the Results",
    "text": "32.2 Looking at the Results\n\n32.2.1 Tuning Progress\nAfter the hyperparameter tuning run is finished, the progress of the hyperparameter tuning can be visualized with spotpython’s method plot_progress. The black points represent the performace values (score or metric) of hyperparameter configurations from the initial design, whereas the red points represents the hyperparameter configurations found by the surrogate model based optimization.\n\nspot_tuner.plot_progress(log_y=True, filename=None)\n\n\n\n\n\n\n\n\n\n\n32.2.2 Tuned Hyperparameters and Their Importance\nResults can be printed in tabular form.\n\nfrom spotpython.utils.eda import gen_design_table\nprint(gen_design_table(fun_control=fun_control, spot=spot_tuner))\n\n| name                 | type   | default        |   lower |   upper | tuned           | transform             |   importance | stars   |\n|----------------------|--------|----------------|---------|---------|-----------------|-----------------------|--------------|---------|\n| d_model_mult         | int    | 4              |     1.0 |     5.0 | 5.0             | transform_power_2_int |         0.11 | .       |\n| nhead                | int    | 3              |     1.0 |     2.0 | 2.0             | transform_power_2_int |        14.73 | *       |\n| num_encoder_layers   | int    | 1              |     1.0 |     4.0 | 1.0             | transform_power_2_int |         0.02 |         |\n| dim_feedforward_mult | int    | 1              |     1.0 |     1.0 | 1.0             | transform_power_2_int |         0.00 |         |\n| epochs               | int    | 7              |     5.0 |     7.0 | 7.0             | transform_power_2_int |         2.02 | *       |\n| batch_size           | int    | 5              |     5.0 |     8.0 | 5.0             | transform_power_2_int |         0.02 |         |\n| optimizer            | factor | Adam           |     0.0 |     4.0 | Adamax          | None                  |         0.85 | .       |\n| dropout              | float  | 0.1            |    0.01 |     0.1 | 0.1             | None                  |         0.02 |         |\n| lr_mult              | float  | 0.1            |    0.01 |     0.3 | 0.3             | None                  |       100.00 | ***     |\n| patience             | int    | 5              |     4.0 |     7.0 | 4.0             | transform_power_2_int |         0.99 | .       |\n| initialization       | factor | xavier_uniform |     0.0 |     3.0 | kaiming_uniform | None                  |         0.02 |         |",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Hyperparameter Tuning of a Transformer Network with PyTorch Lightning</span>"
    ]
  },
  {
    "objectID": "603_spot_lightning_transformer_hpt.html#hyperparameter-considerations",
    "href": "603_spot_lightning_transformer_hpt.html#hyperparameter-considerations",
    "title": "32  Hyperparameter Tuning of a Transformer Network with PyTorch Lightning",
    "section": "32.3 Hyperparameter Considerations",
    "text": "32.3 Hyperparameter Considerations\n\nd_model (or d_embedding):\n\nThis is the dimension of the embedding space or the number of expected features in the input.\nAll input features are projected into this dimensional space before entering the transformer encoder.\nThis dimension must be divisible by nhead since each head in the multi-head attention mechanism will process a subset of d_model/nhead features.\n\nnhead:\n\nThis is the number of attention heads in the multi-head attention mechanism.\nIt allows the transformer to jointly attend to information from different representation subspaces.\nIt’s important that d_model % nhead == 0 to ensure the dimensions are evenly split among the heads.\n\nnum_encoder_layers:\n\nThis specifies the number of transformer encoder layers stacked together.\nEach layer contains a multi-head attention mechanism followed by position-wise feedforward layers.\n\ndim_feedforward:\n\nThis is the dimension of the feedforward network model within the transformer encoder layer.\nTypically, this dimension is larger than d_model (e.g., 2048 for a Transformer model with d_model=512).\n\n\n\n32.3.1 Important: Constraints and Interconnections:\n\nd_model and nhead:\n\nAs mentioned, d_model must be divisible by nhead. This is critical because each attention head operates simultaneously on a part of the embedding, so d_model/nhead should be an integer.\n\nnum_encoder_layers and dim_feedforward**:\n\nThese parameters are more flexible and can be chosen independently of d_model and nhead.\nHowever, the choice of dim_feedforward does influence the computational cost and model capacity, as larger dimensions allow learning more complex representations.\n\nOne hyperparameter does not strictly need to be a multiple of others except for ensuring d_model % nhead == 0.\n\n\n\n32.3.2 Practical Considerations:\n\nSetting d_model:\n\nCommon choices for d_model are powers of 2 (e.g., 256, 512, 1024).\nEnsure that it matches the size of the input data after the linear projection layer.\n\nSetting nhead:\n\nTypically, values are 1, 2, 4, 8, etc., depending on the d_model value.\nEach head works on a subset of features, so d_model / nhead should be large enough to be meaningful.\n\nSetting num_encoder_layers:\n\nPractical values range from 1 to 12 or more depending on the depth desired.\nDeeper models can capture more complex patterns but are also more computationally intensive.\n\nSetting dim_feedforward:\n\nOften set to a multiple of d_model, such as 2048 when d_model is 512.\nEnsures sufficient capacity in the intermediate layers for complex feature transformations.\n\n\n\n\n\n\n\n\nNote: d_model Calculation\n\n\n\nSince d_model % nhead == 0 is a critical constraint to ensure that the multi-head attention mechanism can operate effectively, spotpython computes the value of d_model based on the nhead value provided by the user. This ensures that the hyperparameter configuration is valid. So, the final value of d_model is a multiple of nhead. spotpython uses the hyperparameter d_model_mult to determine the multiple of nhead to use for d_model, i.e., d_model = nhead * d_model_mult.\n\n\n\n\n\n\n\n\nNote: dim_feedforward Calculation\n\n\n\nSince this dimension is typically larger than d_model (e.g., 2048 for a Transformer model with d_model=512), spotpython uses the hyperparameter dim_feedforward_mult to determine the multiple of d_model to use for dim_feedforward, i.e., dim_feedforward = d_model * dim_feedforward_mult.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Hyperparameter Tuning of a Transformer Network with PyTorch Lightning</span>"
    ]
  },
  {
    "objectID": "603_spot_lightning_transformer_hpt.html#summary",
    "href": "603_spot_lightning_transformer_hpt.html#summary",
    "title": "32  Hyperparameter Tuning of a Transformer Network with PyTorch Lightning",
    "section": "32.4 Summary",
    "text": "32.4 Summary\nThis section presented an introduction to the basic setup of hyperparameter tuning of a transformer with spotpython and PyTorch Lightning.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Hyperparameter Tuning of a Transformer Network with PyTorch Lightning</span>"
    ]
  },
  {
    "objectID": "604_spot_lightning_save_load_models.html",
    "href": "604_spot_lightning_save_load_models.html",
    "title": "33  Saving and Loading",
    "section": "",
    "text": "33.1 spotpython: Saving and Loading Optimization Experiments\nIn this section, we will show how results from spotpython can be saved and reloaded. Here, spotpython can be used as an optimizer.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Saving and Loading</span>"
    ]
  },
  {
    "objectID": "604_spot_lightning_save_load_models.html#sec-spotpython-saving-and-loading",
    "href": "604_spot_lightning_save_load_models.html#sec-spotpython-saving-and-loading",
    "title": "33  Saving and Loading",
    "section": "",
    "text": "33.1.1 spotpython as an Optimizer\nIf spotpython is used as an optimizer, no dictionary of hyperparameters has be specified. The fun_control dictionary is sufficient.\n\nimport os\nimport pprint\nfrom spotpython.utils.file import load_experiment\nfrom spotpython.utils.file import get_experiment_filename\nimport numpy as np\nfrom math import inf\nfrom spotpython.spot import spot\nfrom spotpython.utils.init import (\n    fun_control_init,\n    design_control_init,\n    surrogate_control_init,\n    optimizer_control_init)\nfrom spotpython.fun.objectivefunctions import analytical\nfun = analytical().fun_branin\nfun_control = fun_control_init(\n            PREFIX=\"branin\",            \n            lower = np.array([0, 0]),\n            upper = np.array([10, 10]),\n            fun_evals=8,\n            fun_repeats=1,\n            max_time=inf,\n            noise=False,\n            tolerance_x=0,\n            ocba_delta=0,\n            var_type=[\"num\", \"num\"],\n            infill_criterion=\"ei\",\n            n_points=1,\n            seed=123,\n            log_level=20,\n            show_models=False,\n            show_progress=True)\ndesign_control = design_control_init(\n            init_size=5,\n            repeats=1)\nsurrogate_control = surrogate_control_init(\n            model_fun_evals=10000,\n            min_theta=-3,\n            max_theta=3,\n            n_theta=2,\n            theta_init_zero=True,\n            n_p=1,\n            optim_p=False,\n            var_type=[\"num\", \"num\"],\n            seed=124)\noptimizer_control = optimizer_control_init(\n            max_iter=1000,\n            seed=125)\nspot_tuner = spot.Spot(fun=fun,\n            fun_control=fun_control,\n            design_control=design_control,\n            surrogate_control=surrogate_control,\n            optimizer_control=optimizer_control)\nspot_tuner.run()\nPREFIX = fun_control[\"PREFIX\"]\nfilename = get_experiment_filename(PREFIX)\nspot_tuner.save_experiment(filename=filename)\nprint(f\"filename: {filename}\")\n\nspotpython tuning: 4.7932399644479124 [########--] 75.00% \nspotpython tuning: 2.0379524815147736 [#########-] 87.50% \nspotpython tuning: 1.9863250753932071 [##########] 100.00% Done...\n\nExperiment saved to spot_branin_experiment.pickle\nfilename: spot_branin_experiment.pickle\n\n\n\n(spot_tuner_1, fun_control_1, design_control_1,\n    surrogate_control_1, optimizer_control_1) = load_experiment(filename)\n\nThe progress of the original experiment is shown in Figure 33.1 and the reloaded experiment in Figure 33.2.\n\nspot_tuner.plot_progress(log_y=True)\n\n\n\n\n\n\n\nFigure 33.1: Progress of the original experiment\n\n\n\n\n\n\nspot_tuner_1.plot_progress(log_y=True)\n\n\n\n\n\n\n\nFigure 33.2: Progress of the reloaded experiment\n\n\n\n\n\nThe results from the original experiment are shown in Table 33.1 and the reloaded experiment in Table 33.2.\n\nspot_tuner.print_results()\n\nmin y: 1.9863250753932071\nx0: 10.0\nx1: 3.2107652010539627\n\n\n\n\nTable 33.1\n\n\n\n[['x0', 10.0], ['x1', 3.2107652010539627]]\n\n\n\n\n\n\nspot_tuner_1.print_results()\n\nmin y: 1.9863250753932071\nx0: 10.0\nx1: 3.2107652010539627\n\n\n\n\nTable 33.2\n\n\n\n[['x0', 10.0], ['x1', 3.2107652010539627]]\n\n\n\n\n\n\n33.1.1.1 Getting the Tuned Hyperparameters\nThe tuned hyperparameters can be obtained as a dictionary with the following code.\n\nfrom spotpython.hyperparameters.values import get_tuned_hyperparameters\nget_tuned_hyperparameters(spot_tuner=spot_tuner)\n\n{'x0': 10.0, 'x1': 3.2107652010539627}\n\n\n\n\n\n\n\n\nSummary: Saving and Loading Optimization Experiments\n\n\n\n\nIf spotpython is used as an optimizer (without an hyperparameter dictionary), experiments can be saved and reloaded with the save_experiment and load_experiment functions.\nThe tuned hyperparameters can be obtained with the get_tuned_hyperparameters function.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Saving and Loading</span>"
    ]
  },
  {
    "objectID": "604_spot_lightning_save_load_models.html#sec-spotpython-as-a-hyperparameter-tuner-37",
    "href": "604_spot_lightning_save_load_models.html#sec-spotpython-as-a-hyperparameter-tuner-37",
    "title": "33  Saving and Loading",
    "section": "33.2 spotpython as a Hyperparameter Tuner",
    "text": "33.2 spotpython as a Hyperparameter Tuner\nIf spotpython is used as a hyperparameter tuner, in addition to the fun_control dictionary a core_model dictionary have to be specified. This will be explained in Section 33.2.2.\nFurthermore, a data set has to be selected and added to the fun_control dictionary. Here, we will use the Diabetes data set.\n\n33.2.1 The Diabetes Data Set\nThe hyperparameter tuning of a PyTorch Lightning network on the Diabetes data set is used as an example. The Diabetes data set is a PyTorch Dataset for regression, which originates from the scikit-learn package, see https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes.\nTen baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements were obtained for each of n = 442 diabetes patients, as well as the response of interest, a quantitative measure of disease progression one year after baseline. The Diabetes data set is described in Table 33.3.\n\n\n\nTable 33.3: The Diabetes data set\n\n\n\n\n\nDescription\nValue\n\n\n\n\nSamples total\n442\n\n\nDimensionality\n10\n\n\nFeatures\nreal, -.2 &lt; x &lt; .2\n\n\nTargets\ninteger 25 - 346\n\n\n\n\n\n\n\nfrom spotpython.utils.device import getDevice\nfrom math import inf\nfrom spotpython.utils.init import fun_control_init\nimport numpy as np\nfrom spotpython.hyperparameters.values import set_control_key_value\nfrom spotpython.data.diabetes import Diabetes\n\nMAX_TIME = inf\nFUN_EVALS = 8\nINIT_SIZE = 5\nWORKERS = 0\nPREFIX=\"037\"\nDEVICE = getDevice()\nDEVICES = 1\nTEST_SIZE = 0.4\nTORCH_METRIC = \"mean_squared_error\"\ndataset = Diabetes()\n\nfun_control = fun_control_init(\n    _L_in=10,\n    _L_out=1,\n    _torchmetric=TORCH_METRIC,\n    PREFIX=PREFIX,\n    TENSORBOARD_CLEAN=True,\n    data_set=dataset,\n    device=DEVICE,\n    enable_progress_bar=False,\n    fun_evals=FUN_EVALS,\n    log_level=10,\n    max_time=MAX_TIME,\n    num_workers=WORKERS,\n    show_progress=True,\n    test_size=TEST_SIZE,\n    tolerance_x=np.sqrt(np.spacing(1)),\n    )\n\nMoving TENSORBOARD_PATH: runs/ to TENSORBOARD_PATH_OLD: runs_OLD/runs_2024_10_12_12_35_23\n\n\n\n\n33.2.2 Adding a core_model to the fun_control Dictionary\nspotpython includes the NetLightRegression class [SOURCE] for configurable neural networks. The class is imported here. It inherits from the class Lightning.LightningModule, which is the base class for all models in Lightning. Lightning.LightningModule is a subclass of torch.nn.Module and provides additional functionality for the training and testing of neural networks. The class Lightning.LightningModule is described in the Lightning documentation.\nThe hyperparameters of the model are specified in the core_model_hyper_dict dictionary [SOURCE].\nThe core_model dictionary contains the hyperparameters of the model to be tuned. These hyperparameters can be specified and modified with as shown in the following code.\n\nfrom spotpython.light.regression.netlightregression import NetLightRegression\nfrom spotpython.hyperdict.light_hyper_dict import LightHyperDict\nfrom spotpython.hyperparameters.values import add_core_model_to_fun_control\nadd_core_model_to_fun_control(fun_control=fun_control,\n                              core_model=NetLightRegression,\n                              hyper_dict=LightHyperDict)\nfrom spotpython.hyperparameters.values import set_control_hyperparameter_value\n\nset_control_hyperparameter_value(fun_control, \"epochs\", [4, 5])\nset_control_hyperparameter_value(fun_control, \"batch_size\", [4, 5])\nset_control_hyperparameter_value(fun_control, \"optimizer\", [\n                \"Adam\",\n                \"RAdam\",\n            ])\nset_control_hyperparameter_value(fun_control, \"dropout_prob\", [0.01, 0.1])\nset_control_hyperparameter_value(fun_control, \"lr_mult\", [0.05, 1.0])\nset_control_hyperparameter_value(fun_control, \"patience\", [2, 3])\nset_control_hyperparameter_value(fun_control, \"act_fn\",[\n                \"ReLU\",\n                \"LeakyReLU\"\n            ] )\n\nSetting hyperparameter epochs to value [4, 5].\nVariable type is int.\nCore type is None.\nCalling modify_hyper_parameter_bounds().\nSetting hyperparameter batch_size to value [4, 5].\nVariable type is int.\nCore type is None.\nCalling modify_hyper_parameter_bounds().\nSetting hyperparameter optimizer to value ['Adam', 'RAdam'].\nVariable type is factor.\nCore type is str.\nCalling modify_hyper_parameter_levels().\nSetting hyperparameter dropout_prob to value [0.01, 0.1].\nVariable type is float.\nCore type is None.\nCalling modify_hyper_parameter_bounds().\nSetting hyperparameter lr_mult to value [0.05, 1.0].\nVariable type is float.\nCore type is None.\nCalling modify_hyper_parameter_bounds().\nSetting hyperparameter patience to value [2, 3].\nVariable type is int.\nCore type is None.\nCalling modify_hyper_parameter_bounds().\nSetting hyperparameter act_fn to value ['ReLU', 'LeakyReLU'].\nVariable type is factor.\nCore type is instance().\nCalling modify_hyper_parameter_levels().\n\n\n\nimport pprint as pp\nfrom spotpython.hyperparameters.values import set_factor_hyperparameter_values\nset_factor_hyperparameter_values(fun_control, \"initialization\", [\"Default\"])\npp.pprint(fun_control)\n\n{'CHECKPOINT_PATH': 'runs/saved_models/',\n 'DATASET_PATH': 'data/',\n 'PREFIX': '037',\n 'RESULTS_PATH': 'results/',\n 'TENSORBOARD_CLEAN': True,\n 'TENSORBOARD_PATH': 'runs/',\n '_L_in': 10,\n '_L_out': 1,\n '_torchmetric': 'mean_squared_error',\n 'accelerator': 'auto',\n 'converters': None,\n 'core_model': &lt;class 'spotpython.light.regression.netlightregression.NetLightRegression'&gt;,\n 'core_model_hyper_dict': {'act_fn': {'class_name': 'spotpython.torch.activation',\n                                      'core_model_parameter_type': 'instance()',\n                                      'default': 'ReLU',\n                                      'levels': ['ReLU', 'LeakyReLU'],\n                                      'lower': 0,\n                                      'transform': 'None',\n                                      'type': 'factor',\n                                      'upper': 1},\n                           'batch_size': {'default': 4,\n                                          'lower': 4,\n                                          'transform': 'transform_power_2_int',\n                                          'type': 'int',\n                                          'upper': 5},\n                           'dropout_prob': {'default': 0.01,\n                                            'lower': 0.01,\n                                            'transform': 'None',\n                                            'type': 'float',\n                                            'upper': 0.1},\n                           'epochs': {'default': 4,\n                                      'lower': 4,\n                                      'transform': 'transform_power_2_int',\n                                      'type': 'int',\n                                      'upper': 5},\n                           'initialization': {'core_model_parameter_type': 'str',\n                                              'default': 'Default',\n                                              'levels': ['Default'],\n                                              'lower': 0,\n                                              'transform': 'None',\n                                              'type': 'factor',\n                                              'upper': 0},\n                           'l1': {'default': 3,\n                                  'lower': 3,\n                                  'transform': 'transform_power_2_int',\n                                  'type': 'int',\n                                  'upper': 8},\n                           'lr_mult': {'default': 1.0,\n                                       'lower': 0.05,\n                                       'transform': 'None',\n                                       'type': 'float',\n                                       'upper': 1.0},\n                           'optimizer': {'class_name': 'torch.optim',\n                                         'core_model_parameter_type': 'str',\n                                         'default': 'SGD',\n                                         'levels': ['Adam', 'RAdam'],\n                                         'lower': 0,\n                                         'transform': 'None',\n                                         'type': 'factor',\n                                         'upper': 1},\n                           'patience': {'default': 2,\n                                        'lower': 2,\n                                        'transform': 'transform_power_2_int',\n                                        'type': 'int',\n                                        'upper': 3}},\n 'core_model_hyper_dict_default': {'act_fn': {'class_name': 'spotpython.torch.activation',\n                                              'core_model_parameter_type': 'instance()',\n                                              'default': 'ReLU',\n                                              'levels': ['Sigmoid',\n                                                         'Tanh',\n                                                         'ReLU',\n                                                         'LeakyReLU',\n                                                         'ELU',\n                                                         'Swish'],\n                                              'lower': 0,\n                                              'transform': 'None',\n                                              'type': 'factor',\n                                              'upper': 5},\n                                   'batch_size': {'default': 4,\n                                                  'lower': 1,\n                                                  'transform': 'transform_power_2_int',\n                                                  'type': 'int',\n                                                  'upper': 4},\n                                   'dropout_prob': {'default': 0.01,\n                                                    'lower': 0.0,\n                                                    'transform': 'None',\n                                                    'type': 'float',\n                                                    'upper': 0.25},\n                                   'epochs': {'default': 4,\n                                              'lower': 4,\n                                              'transform': 'transform_power_2_int',\n                                              'type': 'int',\n                                              'upper': 9},\n                                   'initialization': {'core_model_parameter_type': 'str',\n                                                      'default': 'Default',\n                                                      'levels': ['Default',\n                                                                 'Kaiming',\n                                                                 'Xavier'],\n                                                      'lower': 0,\n                                                      'transform': 'None',\n                                                      'type': 'factor',\n                                                      'upper': 2},\n                                   'l1': {'default': 3,\n                                          'lower': 3,\n                                          'transform': 'transform_power_2_int',\n                                          'type': 'int',\n                                          'upper': 8},\n                                   'lr_mult': {'default': 1.0,\n                                               'lower': 0.1,\n                                               'transform': 'None',\n                                               'type': 'float',\n                                               'upper': 10.0},\n                                   'optimizer': {'class_name': 'torch.optim',\n                                                 'core_model_parameter_type': 'str',\n                                                 'default': 'SGD',\n                                                 'levels': ['Adadelta',\n                                                            'Adagrad',\n                                                            'Adam',\n                                                            'AdamW',\n                                                            'SparseAdam',\n                                                            'Adamax',\n                                                            'ASGD',\n                                                            'NAdam',\n                                                            'RAdam',\n                                                            'RMSprop',\n                                                            'Rprop',\n                                                            'SGD'],\n                                                 'lower': 0,\n                                                 'transform': 'None',\n                                                 'type': 'factor',\n                                                 'upper': 11},\n                                   'patience': {'default': 2,\n                                                'lower': 2,\n                                                'transform': 'transform_power_2_int',\n                                                'type': 'int',\n                                                'upper': 6}},\n 'core_model_name': None,\n 'counter': 0,\n 'data': None,\n 'data_dir': './data',\n 'data_module': None,\n 'data_set': &lt;spotpython.data.diabetes.Diabetes object at 0x33efd0f20&gt;,\n 'data_set_name': None,\n 'db_dict_name': None,\n 'design': None,\n 'device': 'mps',\n 'devices': 1,\n 'enable_progress_bar': False,\n 'eval': None,\n 'fun_evals': 8,\n 'fun_repeats': 1,\n 'horizon': None,\n 'hyperdict': None,\n 'infill_criterion': 'y',\n 'k_folds': 3,\n 'log_graph': False,\n 'log_level': 10,\n 'loss_function': None,\n 'lower': array([3. , 4. , 1. , 0. , 0. , 0. , 0.1, 2. , 0. ]),\n 'max_surrogate_points': 30,\n 'max_time': inf,\n 'metric_params': {},\n 'metric_river': None,\n 'metric_sklearn': None,\n 'metric_sklearn_name': None,\n 'metric_torch': None,\n 'model_dict': {},\n 'n_points': 1,\n 'n_samples': None,\n 'n_total': None,\n 'noise': False,\n 'num_workers': 0,\n 'ocba_delta': 0,\n 'oml_grace_period': None,\n 'optimizer': None,\n 'path': None,\n 'prep_model': None,\n 'prep_model_name': None,\n 'progress_file': None,\n 'save_experiment': False,\n 'save_model': False,\n 'scaler': None,\n 'scaler_name': None,\n 'scenario': None,\n 'seed': 123,\n 'show_batch_interval': 1000000,\n 'show_models': False,\n 'show_progress': True,\n 'shuffle': None,\n 'sigma': 0.0,\n 'spot_tensorboard_path': None,\n 'target_column': None,\n 'target_type': None,\n 'task': None,\n 'tensorboard_log': False,\n 'tensorboard_start': False,\n 'tensorboard_stop': False,\n 'test': None,\n 'test_seed': 1234,\n 'test_size': 0.4,\n 'tkagg': False,\n 'tolerance_x': 1.4901161193847656e-08,\n 'train': None,\n 'upper': array([ 8.  ,  9.  ,  4.  ,  5.  , 11.  ,  0.25, 10.  ,  6.  ,  2.  ]),\n 'var_name': ['l1',\n              'epochs',\n              'batch_size',\n              'act_fn',\n              'optimizer',\n              'dropout_prob',\n              'lr_mult',\n              'patience',\n              'initialization'],\n 'var_type': ['int',\n              'int',\n              'int',\n              'factor',\n              'factor',\n              'float',\n              'float',\n              'int',\n              'factor'],\n 'verbosity': 0,\n 'weight_coeff': 0.0,\n 'weights': 1.0,\n 'weights_entry': None}\n\n\n\n\n33.2.3 design_control, surrogate_control Dictionaries and the Objective Function\nAfter specifying the design_control and surrogate_control dictionaries, the objective function fun from the class HyperLight [SOURCE] is selected. It implements an interface from PyTorch’s training, validation, and testing methods to spotpython.\nThen, the hyperparameter tuning can be started.\n\nfrom spotpython.utils.init import design_control_init, surrogate_control_init\ndesign_control = design_control_init(init_size=INIT_SIZE)\n\nsurrogate_control = surrogate_control_init(noise=True,\n                                            n_theta=2)\nfrom spotpython.fun.hyperlight import HyperLight\nfun = HyperLight(log_level=10).fun\nfrom spotpython.spot import spot\nspot_tuner = spot.Spot(fun=fun,\n                       fun_control=fun_control,\n                       design_control=design_control,\n                       surrogate_control=surrogate_control)\nspot_tuner.run()\n\ntrain_model result: {'val_loss': 4179.72705078125, 'hp_metric': 4179.72705078125}\n\n\ntrain_model result: {'val_loss': 23407.560546875, 'hp_metric': 23407.560546875}\n\n\ntrain_model result: {'val_loss': 4221.5048828125, 'hp_metric': 4221.5048828125}\n\n\ntrain_model result: {'val_loss': 24088.78125, 'hp_metric': 24088.78125}\n\n\ntrain_model result: {'val_loss': 23975.578125, 'hp_metric': 23975.578125}\n\n\ntrain_model result: {'val_loss': 4102.8740234375, 'hp_metric': 4102.8740234375}\nspotpython tuning: 4102.8740234375 [########--] 75.00% \n\n\ntrain_model result: {'val_loss': 23990.4765625, 'hp_metric': 23990.4765625}\nspotpython tuning: 4102.8740234375 [#########-] 87.50% \n\n\ntrain_model result: {'val_loss': 4287.24365234375, 'hp_metric': 4287.24365234375}\nspotpython tuning: 4102.8740234375 [##########] 100.00% Done...\n\n\n\n&lt;spotpython.spot.spot.Spot at 0x340f370e0&gt;\n\n\nThe tuned hyperparameters can be obtained as a dictionary with the following code.\n\nfrom spotpython.hyperparameters.values import get_tuned_hyperparameters\nget_tuned_hyperparameters(spot_tuner)\n\n{'l1': 6.0,\n 'epochs': 5.0,\n 'batch_size': 4.0,\n 'act_fn': 1.0,\n 'optimizer': 0.0,\n 'dropout_prob': 0.02090868894352122,\n 'lr_mult': 0.3710391909139262,\n 'patience': 3.0,\n 'initialization': 0.0}\n\n\nHere , the numerical levels of the hyperparameters are used as keys in the dictionary. If the fun_control dictionary is used, the names of the hyperparameters are used as keys in the dictionary.\n\nget_tuned_hyperparameters(spot_tuner, fun_control)\n\n{'l1': 6.0,\n 'epochs': 5.0,\n 'batch_size': 4.0,\n 'act_fn': 'LeakyReLU',\n 'optimizer': 'Adam',\n 'dropout_prob': 0.02090868894352122,\n 'lr_mult': 0.3710391909139262,\n 'patience': 3.0,\n 'initialization': 'Default'}\n\n\n\nPREFIX = fun_control[\"PREFIX\"]\nfilename = get_experiment_filename(PREFIX)\nspot_tuner.save_experiment(filename=filename)\nprint(f\"filename: {filename}\")\n\nExperiment saved to spot_037_experiment.pickle\nfilename: spot_037_experiment.pickle\n\n\nThe results from the experiment are stored in the pickle file spot_037_experiment.pickle. The experiment can be reloaded with the following code.\n\n(spot_tuner_1, fun_control_1, design_control_1,\n    surrogate_control_1, optimizer_control_1) = load_experiment(filename)\n\nPlot the progress of the original experiment are identical to the reloaded experiment.\n\nspot_tuner.plot_progress(log_y=True)\nspot_tuner_1.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinally, the tuned hyperparameters can be obtained as a dictionary from the reloaded experiment with the following code.\n\nget_tuned_hyperparameters(spot_tuner_1, fun_control_1)\n\n{'l1': 6.0,\n 'epochs': 5.0,\n 'batch_size': 4.0,\n 'act_fn': 'LeakyReLU',\n 'optimizer': 'Adam',\n 'dropout_prob': 0.02090868894352122,\n 'lr_mult': 0.3710391909139262,\n 'patience': 3.0,\n 'initialization': 'Default'}\n\n\n\n\n\n\n\n\nSummary: Saving and Loading Hyperparameter-Tuning Experiments\n\n\n\n\nIf spotpython is used as an hyperparameter tuner (with an hyperparameter dictionary), experiments can be saved and reloaded with the save_experiment and load_experiment functions.\nThe tuned hyperparameters can be obtained with the get_tuned_hyperparameters function.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Saving and Loading</span>"
    ]
  },
  {
    "objectID": "604_spot_lightning_save_load_models.html#sec-saving-and-loading-pytorch-lightning-models-37",
    "href": "604_spot_lightning_save_load_models.html#sec-saving-and-loading-pytorch-lightning-models-37",
    "title": "33  Saving and Loading",
    "section": "33.3 Saving and Loading PyTorch Lightning Models",
    "text": "33.3 Saving and Loading PyTorch Lightning Models\nSection 33.1 and Section 33.2 explained how to save and load optimization and hyperparameter tuning experiments and how to get the tuned hyperparameters as a dictionary. This section shows how to save and load PyTorch Lightning models.\n\n33.3.1 Get the Tuned Architecture\nIn contrast to the function get_tuned_hyperparameters, the function get_tuned_architecture returns the tuned architecture of the model as a dictionary. Here, the transformations are already applied to the numerical levels of the hyperparameters and the encoding (and types) are the original types of the hyperparameters used by the model. The config dictionary can be passed to the model without any modifications.\n\nfrom spotpython.hyperparameters.values import get_tuned_architecture\nconfig = get_tuned_architecture(spot_tuner, fun_control)\npprint.pprint(config)\n\n{'act_fn': LeakyReLU(),\n 'batch_size': 16,\n 'dropout_prob': 0.02090868894352122,\n 'epochs': 32,\n 'initialization': 'Default',\n 'l1': 64,\n 'lr_mult': 0.3710391909139262,\n 'optimizer': 'Adam',\n 'patience': 8}\n\n\nAfter getting the tuned architecture, the model can be created and tested with the following code.\n\nfrom spotpython.light.testmodel import test_model\ntest_model(config, fun_control)\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃        Test metric        ┃       DataLoader 0        ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│         hp_metric         │     5133.49169921875      │\n│         val_loss          │     5133.49169921875      │\n└───────────────────────────┴───────────────────────────┘\n\n\n\ntest_model result: {'val_loss': 5133.49169921875, 'hp_metric': 5133.49169921875}\n\n\n(5133.49169921875, 5133.49169921875)\n\n\n\n\n33.3.2 Load a Model from Checkpoint\n\nfrom spotpython.light.loadmodel import load_light_from_checkpoint\nmodel_loaded = load_light_from_checkpoint(config, fun_control)\n\nconfig: {'l1': 64, 'epochs': 32, 'batch_size': 16, 'act_fn': LeakyReLU(), 'optimizer': 'Adam', 'dropout_prob': 0.02090868894352122, 'lr_mult': 0.3710391909139262, 'patience': 8, 'initialization': 'Default'}\nLoading model with 64_32_16_LeakyReLU_Adam_0.0209_0.371_8_Default_TEST from runs/saved_models/64_32_16_LeakyReLU_Adam_0.0209_0.371_8_Default_TEST/last.ckpt\nModel: NetLightRegression(\n  (layers): Sequential(\n    (0): Linear(in_features=10, out_features=64, bias=True)\n    (1): LeakyReLU()\n    (2): Dropout(p=0.02090868894352122, inplace=False)\n    (3): Linear(in_features=64, out_features=32, bias=True)\n    (4): LeakyReLU()\n    (5): Dropout(p=0.02090868894352122, inplace=False)\n    (6): Linear(in_features=32, out_features=32, bias=True)\n    (7): LeakyReLU()\n    (8): Dropout(p=0.02090868894352122, inplace=False)\n    (9): Linear(in_features=32, out_features=16, bias=True)\n    (10): LeakyReLU()\n    (11): Dropout(p=0.02090868894352122, inplace=False)\n    (12): Linear(in_features=16, out_features=1, bias=True)\n  )\n)\n\n\n\nvars(model_loaded)\n\n{'training': False,\n '_parameters': OrderedDict(),\n '_buffers': OrderedDict(),\n '_non_persistent_buffers_set': set(),\n '_backward_pre_hooks': OrderedDict(),\n '_backward_hooks': OrderedDict(),\n '_is_full_backward_hook': None,\n '_forward_hooks': OrderedDict(),\n '_forward_hooks_with_kwargs': OrderedDict(),\n '_forward_hooks_always_called': OrderedDict(),\n '_forward_pre_hooks': OrderedDict(),\n '_forward_pre_hooks_with_kwargs': OrderedDict(),\n '_state_dict_hooks': OrderedDict(),\n '_state_dict_pre_hooks': OrderedDict(),\n '_load_state_dict_pre_hooks': OrderedDict(),\n '_load_state_dict_post_hooks': OrderedDict(),\n '_modules': OrderedDict([('layers',\n               Sequential(\n                 (0): Linear(in_features=10, out_features=64, bias=True)\n                 (1): LeakyReLU()\n                 (2): Dropout(p=0.02090868894352122, inplace=False)\n                 (3): Linear(in_features=64, out_features=32, bias=True)\n                 (4): LeakyReLU()\n                 (5): Dropout(p=0.02090868894352122, inplace=False)\n                 (6): Linear(in_features=32, out_features=32, bias=True)\n                 (7): LeakyReLU()\n                 (8): Dropout(p=0.02090868894352122, inplace=False)\n                 (9): Linear(in_features=32, out_features=16, bias=True)\n                 (10): LeakyReLU()\n                 (11): Dropout(p=0.02090868894352122, inplace=False)\n                 (12): Linear(in_features=16, out_features=1, bias=True)\n               ))]),\n 'prepare_data_per_node': True,\n 'allow_zero_length_dataloader_with_multiple_devices': False,\n '_log_hyperparams': True,\n '_dtype': torch.float32,\n '_device': device(type='mps', index=0),\n '_trainer': None,\n '_example_input_array': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n '_automatic_optimization': True,\n '_strict_loading': None,\n '_current_fx_name': None,\n '_param_requires_grad_state': {},\n '_metric_attributes': None,\n '_compiler_ctx': None,\n '_fabric': None,\n '_fabric_optimizers': [],\n '_device_mesh': None,\n '_L_in': 10,\n '_L_out': 1,\n '_torchmetric': 'mean_squared_error',\n 'metric': &lt;function torchmetrics.functional.regression.mse.mean_squared_error(preds: torch.Tensor, target: torch.Tensor, squared: bool = True, num_outputs: int = 1) -&gt; torch.Tensor&gt;,\n '_hparams_name': 'kwargs',\n '_hparams': \"act_fn\":         LeakyReLU()\n \"batch_size\":     16\n \"dropout_prob\":   0.02090868894352122\n \"epochs\":         32\n \"initialization\": Default\n \"l1\":             64\n \"lr_mult\":        0.3710391909139262\n \"optimizer\":      Adam\n \"patience\":       8,\n '_hparams_initial': \"act_fn\":         LeakyReLU()\n \"batch_size\":     16\n \"dropout_prob\":   0.02090868894352122\n \"epochs\":         32\n \"initialization\": Default\n \"l1\":             64\n \"lr_mult\":        0.3710391909139262\n \"optimizer\":      Adam\n \"patience\":       8}\n\n\n\nimport torch\ntorch.save(model_loaded, \"model.pt\")\n\n\nmymodel = torch.load(\"model.pt\")\n\n\n# show all attributes of the model\nvars(mymodel)\n\n{'training': False,\n '_parameters': OrderedDict(),\n '_buffers': OrderedDict(),\n '_non_persistent_buffers_set': set(),\n '_backward_pre_hooks': OrderedDict(),\n '_backward_hooks': OrderedDict(),\n '_is_full_backward_hook': None,\n '_forward_hooks': OrderedDict(),\n '_forward_hooks_with_kwargs': OrderedDict(),\n '_forward_hooks_always_called': OrderedDict(),\n '_forward_pre_hooks': OrderedDict(),\n '_forward_pre_hooks_with_kwargs': OrderedDict(),\n '_state_dict_hooks': OrderedDict(),\n '_state_dict_pre_hooks': OrderedDict(),\n '_load_state_dict_pre_hooks': OrderedDict(),\n '_load_state_dict_post_hooks': OrderedDict(),\n '_modules': OrderedDict([('layers',\n               Sequential(\n                 (0): Linear(in_features=10, out_features=64, bias=True)\n                 (1): LeakyReLU()\n                 (2): Dropout(p=0.02090868894352122, inplace=False)\n                 (3): Linear(in_features=64, out_features=32, bias=True)\n                 (4): LeakyReLU()\n                 (5): Dropout(p=0.02090868894352122, inplace=False)\n                 (6): Linear(in_features=32, out_features=32, bias=True)\n                 (7): LeakyReLU()\n                 (8): Dropout(p=0.02090868894352122, inplace=False)\n                 (9): Linear(in_features=32, out_features=16, bias=True)\n                 (10): LeakyReLU()\n                 (11): Dropout(p=0.02090868894352122, inplace=False)\n                 (12): Linear(in_features=16, out_features=1, bias=True)\n               ))]),\n 'prepare_data_per_node': True,\n 'allow_zero_length_dataloader_with_multiple_devices': False,\n '_log_hyperparams': True,\n '_dtype': torch.float32,\n '_device': device(type='mps', index=0),\n '_trainer': None,\n '_example_input_array': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n '_automatic_optimization': True,\n '_strict_loading': None,\n '_current_fx_name': None,\n '_param_requires_grad_state': {},\n '_metric_attributes': None,\n '_compiler_ctx': None,\n '_fabric': None,\n '_fabric_optimizers': [],\n '_device_mesh': None,\n '_L_in': 10,\n '_L_out': 1,\n '_torchmetric': 'mean_squared_error',\n 'metric': &lt;function torchmetrics.functional.regression.mse.mean_squared_error(preds: torch.Tensor, target: torch.Tensor, squared: bool = True, num_outputs: int = 1) -&gt; torch.Tensor&gt;,\n '_hparams_name': 'kwargs',\n '_hparams': \"act_fn\":         LeakyReLU()\n \"batch_size\":     16\n \"dropout_prob\":   0.02090868894352122\n \"epochs\":         32\n \"initialization\": Default\n \"l1\":             64\n \"lr_mult\":        0.3710391909139262\n \"optimizer\":      Adam\n \"patience\":       8,\n '_hparams_initial': \"act_fn\":         LeakyReLU()\n \"batch_size\":     16\n \"dropout_prob\":   0.02090868894352122\n \"epochs\":         32\n \"initialization\": Default\n \"l1\":             64\n \"lr_mult\":        0.3710391909139262\n \"optimizer\":      Adam\n \"patience\":       8}",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Saving and Loading</span>"
    ]
  },
  {
    "objectID": "604_spot_lightning_save_load_models.html#sec-converting-a-lightning-model-to-a-plain-torch-model-37",
    "href": "604_spot_lightning_save_load_models.html#sec-converting-a-lightning-model-to-a-plain-torch-model-37",
    "title": "33  Saving and Loading",
    "section": "33.4 Converting a Lightning Model to a Plain Torch Model",
    "text": "33.4 Converting a Lightning Model to a Plain Torch Model\n\n33.4.1 The Function get_removed_attributes_and_base_net\nspotpython provides a function to covert a PyTorch Lightning model to a plain PyTorch model. The function get_removed_attributes_and_base_net returns a tuple with the removed attributes and the base net. The base net is a plain PyTorch model. The removed attributes are the attributes of the PyTorch Lightning model that are not part of the base net.\nThis conversion can be reverted.\n\nimport numpy as np\nimport torch\nfrom spotpython.utils.device import getDevice\nfrom torch.utils.data import random_split\nfrom spotpython.utils.classes import get_removed_attributes_and_base_net\nfrom spotpython.hyperparameters.optimizer import optimizer_handler\nremoved_attributes, torch_net = get_removed_attributes_and_base_net(net=mymodel)\n\n\nprint(removed_attributes)\n\n{'metric': &lt;function mean_squared_error at 0x33bc38680&gt;, '_hparams_initial': \"act_fn\":         LeakyReLU()\n\"batch_size\":     16\n\"dropout_prob\":   0.02090868894352122\n\"epochs\":         32\n\"initialization\": Default\n\"l1\":             64\n\"lr_mult\":        0.3710391909139262\n\"optimizer\":      Adam\n\"patience\":       8, '_hparams_name': 'kwargs', '_hparams': \"act_fn\":         LeakyReLU()\n\"batch_size\":     16\n\"dropout_prob\":   0.02090868894352122\n\"epochs\":         32\n\"initialization\": Default\n\"l1\":             64\n\"lr_mult\":        0.3710391909139262\n\"optimizer\":      Adam\n\"patience\":       8, '_trainer': None, '_torchmetric': 'mean_squared_error', '_metric_attributes': None, '_dtype': torch.float32, '_param_requires_grad_state': {}, 'allow_zero_length_dataloader_with_multiple_devices': False, '_fabric_optimizers': [], '_current_fx_name': None, '_strict_loading': None, '_device_mesh': None, 'prepare_data_per_node': True, '_log_hyperparams': True, '_automatic_optimization': True, '_example_input_array': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), '_fabric': None, '_device': device(type='mps', index=0), '_L_in': 10, '_compiler_ctx': None, '_L_out': 1}\n\n\n\nprint(torch_net)\n\nNetLightRegression(\n  (layers): Sequential(\n    (0): Linear(in_features=10, out_features=64, bias=True)\n    (1): LeakyReLU()\n    (2): Dropout(p=0.02090868894352122, inplace=False)\n    (3): Linear(in_features=64, out_features=32, bias=True)\n    (4): LeakyReLU()\n    (5): Dropout(p=0.02090868894352122, inplace=False)\n    (6): Linear(in_features=32, out_features=32, bias=True)\n    (7): LeakyReLU()\n    (8): Dropout(p=0.02090868894352122, inplace=False)\n    (9): Linear(in_features=32, out_features=16, bias=True)\n    (10): LeakyReLU()\n    (11): Dropout(p=0.02090868894352122, inplace=False)\n    (12): Linear(in_features=16, out_features=1, bias=True)\n  )\n)\n\n\n\n\n33.4.2 An Example how to use the Plain Torch Net\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.datasets import load_diabetes\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\n# Load the Diabetes dataset from sklearn\ndiabetes = load_diabetes()\nX = diabetes.data\ny = diabetes.target\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Scale the features\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Convert the data to PyTorch tensors\nX_train_tensor = torch.tensor(X_train, dtype=torch.float32)\ny_train_tensor = torch.tensor(y_train, dtype=torch.float32)\nX_test_tensor = torch.tensor(X_test, dtype=torch.float32)\ny_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n\n# Create a PyTorch dataset\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\ntest_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n\n# Create a PyTorch dataloader\nbatch_size = 32\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n\ntorch_net.to(getDevice(\"cpu\"))\n\n# train the net\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(torch_net.parameters(), lr=0.01)\nn_epochs = 100\nlosses = []\nfor epoch in range(n_epochs):\n    for inputs, targets in train_dataloader:\n        targets = targets.view(-1, 1)\n        optimizer.zero_grad()\n        outputs = torch_net(inputs)\n        loss = criterion(outputs, targets)\n        losses.append(loss.item())\n        loss.backward()\n        optimizer.step()\n# visualize the network training\nplt.plot(losses)\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.show()",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Saving and Loading</span>"
    ]
  },
  {
    "objectID": "a_01_intro_to_notebooks.html",
    "href": "a_01_intro_to_notebooks.html",
    "title": "Appendix A — Introduction to Jupyter Notebook",
    "section": "",
    "text": "A.1 Different Notebook cells\nThere are different cells that the notebook is currently supporting:\nAs a default, every cells in jupyter is set to “code”",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Introduction to Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "a_01_intro_to_notebooks.html#different-notebook-cells",
    "href": "a_01_intro_to_notebooks.html#different-notebook-cells",
    "title": "Appendix A — Introduction to Jupyter Notebook",
    "section": "",
    "text": "code cells\nmarkdown cells\nraw cells\n\n\n\nA.1.1 Code cells\nThe code cells are used to execute the code. They are following the logic of the choosen kernel. Therefore, it is important to keep in mind which programming language is currently used. Otherwise one might yield an error because of the wrong syntax.\nThe code cells are executed my be ▶ Run button (can be found in the header of the notebook).\n\n\nA.1.2 Markdown cells\nThe markdown cells are a usefull tool to comment the written code. Especially with the help of headers can the code be brought in a more readable format. If you are not familiar with the markdown syntax, you can find a usefull cheat sheet here: Markdown Cheat Sheeet\n\n\nA.1.3 Raw cells\nThe “Raw NBConvert” cell type can be used to render different code formats into HTML or LaTeX by Sphinx. This information is stored in the notebook metadata and converted appropriately.\n\nA.1.3.1 Usage\nTo select a desired format from within Jupyter, select the cell containing your special code and choose options from the following dropdown menus:\n\nSelect “Raw NBConvert”\nSwitch the Cell Toolbar to “Raw Cell Format” (The cell toolbar can be found under View)\nChose the appropriate “Raw NBConvert Format” within the cell\n\nData Science is fun",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Introduction to Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "a_01_intro_to_notebooks.html#install-packages",
    "href": "a_01_intro_to_notebooks.html#install-packages",
    "title": "Appendix A — Introduction to Jupyter Notebook",
    "section": "A.2 Install Packages",
    "text": "A.2 Install Packages\nBecause python is a heavily used programming language, there are many different packags that can make your life easier. Sadly, there are only a few standard packages that are already included in your python enviroment. If you have the need to install a new package in your enviroment, you can simply do that by exectuing the following code snippet in a code cell\n!pip install numpy\n\nThe ! is used to run the cell as a shell command\npip is package manager for python packages.\nnumpy is the the package you want to install\n\nHint: It is often usefull to restart the kernel after installing a package, otherwise loading the package could lead to an error.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Introduction to Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "a_01_intro_to_notebooks.html#load-packages",
    "href": "a_01_intro_to_notebooks.html#load-packages",
    "title": "Appendix A — Introduction to Jupyter Notebook",
    "section": "A.3 Load Packages",
    "text": "A.3 Load Packages\nAfter successfully installing the package it is necessary to import them before you can work with them. The import of the packages is done in the following way:\nimport numpy as np\nThe imported packages are often abbreviated. This is because you need to specify where the function is coming from.\nThe most common abbreviations for data science packages are:\n\nAbbreviations for data science packages\n\n\nAbbreviation\nPackage\nImport\n\n\n\n\nnp\nnumpy\nimport numpy as np\n\n\npd\npandas\nimport pandas as pd\n\n\nplt\nmatplotlib\nimport matplotlib.pyplot as plt\n\n\npx\nplotly\nimport plotly.exprss as px\n\n\ntf\ntensorflow\nimport tensorflow as tf\n\n\nsns\nseaborn\nimport seaborn as sns\n\n\ndt\ndatetime\nimport datetime as dt\n\n\npkl\npickle\nimport pickle as pkl",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Introduction to Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "a_01_intro_to_notebooks.html#functions-in-python",
    "href": "a_01_intro_to_notebooks.html#functions-in-python",
    "title": "Appendix A — Introduction to Jupyter Notebook",
    "section": "A.4 Functions in Python",
    "text": "A.4 Functions in Python\nBecause python is not using Semicolon’s it is import to keep track of indentation in your code. The indentation works as a placeholder for the semicolons. This is especially important if your are defining loops, functions, etc. …\nExample: We are defining a function that calculates the squared sum of its input parameters\n\ndef squared_sum(x,y): \n    z = x**2 + y**2\n    return z\n\nIf you are working with something that needs indentation, it will be already done by the notebook.\nHint: Keep in mind that is good practice to use the return parameter. If you are not using return and a function has multiple paramaters that you would like to return, it will only return the last one defined.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Introduction to Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "a_01_intro_to_notebooks.html#list-of-useful-jupyter-notebook-shortcuts",
    "href": "a_01_intro_to_notebooks.html#list-of-useful-jupyter-notebook-shortcuts",
    "title": "Appendix A — Introduction to Jupyter Notebook",
    "section": "A.5 List of Useful Jupyter Notebook Shortcuts",
    "text": "A.5 List of Useful Jupyter Notebook Shortcuts\n\nList of useful Jupyter Notebook Shortcuts\n\n\n\n\n\n\n\nFunction\nKeyboard Shortcut\nMenu Tools\n\n\n\n\nSave notebook\nEsc + s\nFile → Save and Checkpoint\n\n\nCreate new Cell\nEsc + a (above),  Esc + b (below)\nInsert → Cell above; Insert → Cell below\n\n\nRun Cell\nCtrl + enter\nCell → Run Cell\n\n\nCopy Cell\nc\nCopy Key\n\n\nPaste Cell\nv\nPaste Key\n\n\nInterrupt Kernel\nEsc + i i\nKernel → Interrupt\n\n\nRestart Kernel\nEsc + 0 0\nKernel → Restart\n\n\n\nIf you combine everything you can create beautiful graphics\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Generate 100 random data points along 3 dimensions\nx, y, scale = np.random.randn(3, 100)\nfig, ax = plt.subplots()\n\n# Map each onto a scatterplot we'll create with Matplotlib\nax.scatter(x=x, y=y, c=scale, s=np.abs(scale)*500)\nax.set(title=\"Some random data, created with the Jupyter Notebook!\")\nplt.show()",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Introduction to Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "a_02_git_intro_en.html",
    "href": "a_02_git_intro_en.html",
    "title": "Appendix B — Git Introduction",
    "section": "",
    "text": "B.1 Learning Objectives\nIn this learning unit, you will learn how to set up Git as a version control system for a project. The most important Git commands will be explained. You will learn how to track and manage changes to your projects with Git. Specifically:",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Git Introduction</span>"
    ]
  },
  {
    "objectID": "a_02_git_intro_en.html#learning-objectives",
    "href": "a_02_git_intro_en.html#learning-objectives",
    "title": "Appendix B — Git Introduction",
    "section": "",
    "text": "Initializing a repository: git init\nIgnoring files: .gitignore\nAdding files to the staging area: git add\nChecking status changes: git status\nReviewing history: git log\nCreating a new branch: git branch\nSwitching to the current branch: git switch and git checkout\nMerging two branches: git merge\nResolving conflicts\nReverting changes: git revert\nUploading changes to GitLab: git push\nDownloading changes from GitLab: git pull\nAdvanced: git rebase",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Git Introduction</span>"
    ]
  },
  {
    "objectID": "a_02_git_intro_en.html#basics-of-git",
    "href": "a_02_git_intro_en.html#basics-of-git",
    "title": "Appendix B — Git Introduction",
    "section": "B.2 Basics of Git",
    "text": "B.2 Basics of Git\n\nB.2.1 Initializing a Repository: git init\nTo set up Git as a version control system for your project, you need to initialize a new Git repository at the top-level folder, which is the working directory of your project. This is done using the git init command.\nAll files in this folder and its subfolders will automatically become part of the repository. Creating a Git repository is similar to adding an all-powerful passive observer of all things to your project. Git sits there, observes, and takes note of even the smallest changes, such as a single character in a file within a repository with hundreds of files. And it will tell you where these changes occurred if you forget. Once Git is initialized, it monitors all changes made within the working directory, and it tracks the history of events from that point forward. For this purpose, a historical timeline is created for your project, referred to as a “branch,” and the initial branch is named main. So, when someone says they are on the main branch or working on the main branch, it means they are in the historical main timeline of the project. The Git repository, often abbreviated as repo, is a virtual representation of your project, including its history and branches, a book, if you will, where you can look up and retrieve the entire history of the project: you work in your working directory, and the Git repository tracks and stores your work.\n\n\nB.2.2 Ignoring Files: .gitignore\nIt’s useful that Git watches and keeps an eye on everything in your project. However, in most projects, there are files and folders that you don’t need or want to keep an eye on. These may include system files, local project settings, libraries with dependencies, and so on.\nYou can exclude any file or folder from your Git repository by including them in the .gitignore file. In the .gitignore file, you create a list of file names, folder names, and other items that Git should not track, and Git will ignore these items. Hence the name “gitignore.” Do you want to track a file that you previously ignored? Simply remove the mention of the file in the gitignore file, and Git will start tracking it again.\n\n\nB.2.3 Adding Changes to the Staging Area: git add\nThe interesting thing about Git as an all-powerful, passive observer of all things is that it’s very passive. As long as you don’t tell Git what to remember, it will passively observe the changes in the project folder but do nothing.\nWhen you make a change to your project that you want Git to include in the project’s history to take a snapshot of so you can refer back to it later, your personal checkpoint, if you will, you need to first stage the changes in the staging area. What is the staging area? The staging area is where you collect changes to files that you want to include in the project’s history.\nThis is done using the git add command. You can specify which files you want to add by naming them, or you can add all of them using -A. By doing this, you’re telling Git that you’ve made changes and want it to remember these particular changes so you can recall them later if needed. This is important because you can choose which changes you want to stage, and those are the changes that will eventually be transferred to the history.\nNote: When you run git add, the changes are not transferred to the project’s history. They are only transferred to the staging area.\n\nExample B.1 (Example of git add from the beginning)  \n# Create a new directory for your\n# repository and navigate to that directory:\n\nmkdir my-repo\ncd my-repo\n\n# Initialize the repository with git init:\n\ngit init\n\n# Create a .gitignore file for Python code.\n# You can use a template from GitHub:\n\ncurl https://raw.githubusercontent.com/github/gitignore/master/Python.gitignore -o .gitignore\n\n# Add your files to the repository using git add:\n\ngit add .\nThis adds all files in the current directory to the repository, except for the files listed in the .gitignore file.\n\n\n\nB.2.4 Transferring Changes to Memory: git commit\nThe power of Git becomes evident when you start transferring changes to the project history. This is done using the git commit command. When you run git commit, you inform Git that the changes in the staging area should be added to the history of the project so that they can be referenced or retrieved later.\nAdditionally, you can add a commit message with the -m option to explain what changes were made. So when you look back at the project history, you can see that you added a new feature.\ngit commit creates a snapshot, an image of the current state of your project at that specific time, and adds it to the branch you are currently working on.\nAs you work on your project and transfer more snapshots, the branch grows and forms a timeline of events. This means you can now look back at every transfer in the branch and see what your code looked like at that time.\nYou can compare any phase of your code with any other phase of your code to find errors, restore deleted code, or do things that would otherwise not be possible, such as resetting the project to a previous state or creating a new timeline from any point.\nSo how often should you add these commits? My rule of thumb is not to commit too often. It’s better to have a Git repository with too many commits than one with too few commits.\n\nExample B.2 (Continuing the example from above:) After adding your files with git add, you can create a commit to save your changes. Use the git commit command with the -m option to specify your commit message:\ngit commit -m \"My first commit message\"\nThis creates a new commit with the added files and the specified commit message.\n\n\n\nB.2.5 Check the Status of Your Repository: git status\nIf you’re wondering what you’ve changed in your project since the last commit snapshot, you can always check the Git status. Git will list every modified file and the current status of each file.\nThis status can be either:\n\nUnchanged (unmodified), meaning nothing has changed since you last transferred it, or\nIt’s been changed (changed) but not staged (staged) to be transferred into the history, or\nSomething has been added to staging (staged) and is ready to be transferred into the history.\n\nWhen you run git status, you get an overview of the current state of your project.\n\nExample B.3 (Continuing the example from above:) The git status command displays the status of your working directory and the staging area. It shows you which files have been modified, which files are staged for commit, and which files are not yet being tracked:\ngit status\ngit status is a useful tool to keep track of your changes and ensure that you have added all the desired files for commit.\n\n\n\nB.2.6 Review Your Repository’s History: git log\n\nExample B.4 (Continuing the example from above:) You can view the history of your commits with the git log command. This command displays a list of all the commits in the current branch, along with information such as the author, date, and commit message:\ngit log\nThere are many options to customize the output of git log. For example, you can use the --pretty option to change the format of the output:\ngit log --pretty=oneline\nThis displays each commit in a single line.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Git Introduction</span>"
    ]
  },
  {
    "objectID": "a_02_git_intro_en.html#branches-timelines",
    "href": "a_02_git_intro_en.html#branches-timelines",
    "title": "Appendix B — Git Introduction",
    "section": "B.3 Branches (Timelines)",
    "text": "B.3 Branches (Timelines)\n\nB.3.1 Creating an Alternative Timeline: git branch\nIn the course of developing a project, you often reach a point where you want to add a new feature, but doing so might require changing the existing code in a way that could be challenging to undo later.\nOr maybe you just want to experiment and be able to discard your work if the experiment fails. In such cases, Git allows you to create an alternative timeline called a branch to work in.\nThis new branch has its own name and exists in parallel with the main branch and all other branches in your project.\nDuring development, you can switch between branches and work on different versions of your code concurrently. This way, you can have a stable codebase in the main branch while developing an experimental feature in a separate branch. When you switch from one branch to another, the code you’re working on is automatically reset to the latest commit of the branch you’re currently in.\nIf you’re working in a team, different team members can work on their own branches, creating an entire universe of alternative timelines for your project. When features are completed, they can be seamlessly merged back into the main branch.\n\nExample B.5 (Continuing the example from above:) To create a new branch, you can use the git branch command with the name of the new branch as an argument:\ngit branch my-tests\n\n\n\nB.3.2 The Pointer to the Current Branch: HEAD\nHow does Git know where you are on the timeline, and how can you keep track of your position?\nYou’re always working at the tip (HEAD) of the currently active branch. The HEAD pointer points there quite literally. In a new project archive with just a single main branch and only new commits being added, HEAD always points to the latest commit in the main branch. That’s where you are.\nHowever, if you’re in a repository with multiple branches, meaning multiple alternative timelines, HEAD will point to the latest commit in the branch you’re currently working on.\n\n\nB.3.3 Switching to an Alternative Timeline: git switch\nAs your project grows, and you have multiple branches, you need to be able to switch between these branches. This is where the switch command comes into play.\nAt any time, you can use the git switch command with the name of the branch you want to switch to, and HEAD moves from your current branch to the one you specified.\nIf you’ve made changes to your code before switching, Git will attempt to carry those changes over to the branch you’re switching to. However, if these changes conflict with the target branch, the switch will be canceled.\nTo resolve this issue without losing your changes, return to the original branch, add and commit your recent changes, and then perform the switch.\n\n\nB.3.4 Switching to an Alternative Timeline and Making Changes: git checkout\nTo switch between branches, you can also use the git checkout command. It works similarly to git switch for this purpose: you pass the name of the branch you want to switch to, and HEAD moves to the beginning of that branch.\nBut checkout can do more than just switch to another timeline. With git checkout, you can also move to any commit point in any timeline. In other words, you can travel back in time and work on code from the past.\nTo do this, use git checkout and provide the commit ID. This is an automatically generated, random combination of letters and numbers that identifies each commit. You can retrieve the commit ID using git log. When you run git log, you get a list of all the commits in your repository, starting with the most recent ones.\nWhen you use git checkout with an older commit ID, you check out a commit in the middle of a branch. This disrupts the timeline, as you’re actively attempting to change history. Git doesn’t want you to do that because, much like in a science fiction movie, altering the past might also alter the future. In our case, it would break the version control branch’s coherence.\nTo prevent you from accidentally disrupting time and altering history, checking out an earlier commit in any branch results in the warning “Detached Head,” which sounds rather ominous. The “Detached Head” warning is appropriate because it accurately describes what’s happening. Git literally detaches the head from the branch and sets it aside.\nNow, you’re working outside of time in a space unbound to any timeline, which again sounds rather threatening but is perfectly fine in reality.\nTo continue working on this past code, all you need to do is reattach it to the timeline. You can use git branch to create a new branch, and the detached head will automatically attach to this new branch.\nInstead of breaking the history, you’ve now created a new alternative timeline that starts in the past, allowing you to work safely. You can continue working on the branch as usual.\n\nExample B.6 (Continuing the example from above:) To switch to a new branch, you can use the git checkout command:\ngit checkout meine-tests\nNow you’re using the new branch and can make changes independently from the original branch.\n\n\n\nB.3.5 The Difference Between checkout and switch\nWhat is the difference between git switch and git checkout? git switch and git checkout are two different commands that both serve the purpose of switching between branches. You can use both to switch between branches, but they have an important distinction. git switch is a new command introduced with Git 2.23. git checkout is an older command that has existed since Git 1.6.0. So, git switch and git checkout have different origins. git switch was introduced to separate the purposes of git checkout. git checkout has two different purposes: 1. It can be used to switch between branches, and 2. It can be used to reset files to the state of the last commit.\nHere’s an example: In my project, I made a change since the last commit, but I haven’t staged it yet. Then, I realized that I actually don’t want this change. I want to reset the file to the state before the last commit. As long as I haven’t committed my changes, I can do this with git checkout by targeting the specific file. So, if that file is named main.js, I can say: git checkout main.js. And the file will be reset to the state of the last commit, which makes sense. I’m checking out the file from the last commit.\nBut that’s quite different from switching between the beginning of one branch to another. git switch and git restore were introduced to separate these two operations. git switch is for switching between branches, and git restore is for resetting the specified file to the state of the last commit. If you try to restore a file with git switch, it simply won’t work. It’s not intended for that. As I mentioned earlier, it’s about separating concerns.\n\nExample B.7 (Difference between git switch and git checkout) Here’s an example demonstrating how to initialize a repository and switch between branches:\n# Create a new directory for your repository\n# and navigate to that directory:\nmkdir my-repo\ncd my-repo\n\n# Initialize the repository with git init:\ngit init\n\n# Create a new branch with git branch:\ngit branch my-new-branch\n\n# Switch to the new branch using git switch:\ngit switch my-new-branch\n\n# Alternatively, you can also use git checkout\n# to switch to the new branch:\n\ngit checkout my-new-branch\nBoth commands lead to the same result: You are now on the new branch.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Git Introduction</span>"
    ]
  },
  {
    "objectID": "a_02_git_intro_en.html#merging-branches-and-resolving-conflicts",
    "href": "a_02_git_intro_en.html#merging-branches-and-resolving-conflicts",
    "title": "Appendix B — Git Introduction",
    "section": "B.4 Merging Branches and Resolving Conflicts",
    "text": "B.4 Merging Branches and Resolving Conflicts\n\nB.4.1 git merge: Merging Two Timelines\nGit allows you to split your development work into as many branches or alternative timelines as you like, enabling you to work on many different versions of your code simultaneously without losing or overwriting any of your work.\nThis is all well and good, but at some point, you need to bring those various versions of your code back together into one branch. That’s where git merge comes in.\nConsider an example where you have two branches, a main branch and an experimental branch called experimental-branch. In the experimental branch, there is a new feature. To merge these two branches, you set HEAD to the branch where you want to incorporate the code and execute git merge followed by the name of the branch you want to merge. HEAD is a special pointer that points to the current branch. When you run git merge, it combines the code from the branch associated with HEAD with the code from the branch specified by the branch name you provide.\n# Initialize the repository\ngit init\n\n# Create a new branch called \"experimental-branch\"\ngit branch experimental-branch\n\n# Switch to the \"experimental-branch\"\ngit checkout experimental-branch\n\n# Add the new feature here and\n# make a commit\n# ...\n\n# Switch back to the \"main\" branch\ngit checkout main\n\n# Perform the merge\ngit merge experimental-branch\nDuring the merge, matching pieces of code in the branches overlap, and any new code from the branch being merged is added to the project. So now, the main branch also contains the code from the experimental branch, and the events of the two separate timelines have been merged into a single one. What’s interesting is that even though the experimental branch was merged with the main branch, the last commit of the experimental branch remains intact, allowing you to continue working on the experimental branch separately if you wish.\n\n\nB.4.2 Resolving Conflicts When Merging\nMerging branches where there are no code changes at the same place in both branches is a straightforward process. It’s also a rare process. In most cases, there will be some form of conflict between the branches – the same code or the same code area has been modified differently in the different branches. Merging two branches with such conflicts will not work, at least not automatically.\nIn this case, Git doesn’t know how to merge this code. So, when such a situation occurs, it’s marked as a conflict, and the merging process is halted. This might sound more dramatic than it is. When you get a conflict warning, Git is saying there are two different versions here, and Git needs to know which one you want to keep. To help you figure out the conflict, Git combines all the code into a single file and automatically marks the conflicting code as the current change, which is the original code from the branch you’re working on, or as the incoming change, which is the code from the file you’re trying to merge.\nTo resolve this conflict, you’ll edit the file to literally resolve the code conflict. This might mean accepting either the current or incoming change and discarding the other. It could mean combining both changes or something else entirely. It’s up to you. So, you edit the code to resolve the conflict. Once you’ve resolved the conflict by editing the code, you add the new conflict-free version to the staging area with git add and then commit the merged code with git commit. That’s how the conflict is resolved.\nA merge conflict occurs when Git struggles to automatically merge changes from two different branches. This usually happens when changes were made to the same line in the same file in both branches. To resolve a merge conflict, you must manually edit the affected files and choose the desired changes. Git marks the conflict areas in the file with special markings like &lt;&lt;&lt;&lt;&lt;&lt;&lt;, =======, and &gt;&gt;&gt;&gt;&gt;&gt;&gt;. You can search for these markings and manually select the desired changes. After resolving the conflicts, you can add the changes with git add and create a new commit with git commit to complete the merge.\n\nExample B.8  \n# Perform the merge (this will cause a conflict)\ngit merge experimenteller-branch\n\n# Open the affected file in an editor and manually resolve the conflicts\n# ...\n\n# Add the modified file\ngit add &lt;filename&gt;\n\n# Create a new commit\ngit commit -m \"Resolved conflicts\"\n\n\n\nB.4.3 git revert: Undoing Something\nOne of the most powerful features of any software tool is the “Undo” button. Make a mistake, press “Undo,” and it’s as if it never happened. However, that’s not quite as simple when an all-powerful, passive observer is watching and recording your project’s history. How do you undo something that you’ve added to the history without rewriting the history?\nThe answer is that you can overwrite the history with the git reset command, but that’s quite risky and not a good practice.\nA better solution is to work with the historical timeline and simply place an older version of your code at the top of the branch. This is done with git revert. To make this work, you need to know the commit ID of the commit you want to go back to.\nThe commit ID is a machine-generated set of random numbers and letters, also known as a hash. To get a list of all the commits in the repository, including the commit ID and commit message, you can run git log.\n# Show the list of all operations in the repository\ngit log\nBy the way, it’s a good idea to leave clear and informative commit messages for this reason. This way, you know what happened in your previous commits. Once you’ve found the commit you want to revert to, call that commit ID with git revert, and then the ID. This will create a new commit at the top of the branch with the code from the reference commit. To transfer the code to the branch, add a commit message and save it. Now, the last commit in your branch matches the commit you’re reverting to, and your project’s history remains intact.\n\nExample B.9 (An example with git revert)  \n# Initialize a new repository\ngit init\n\n# Create a new file\necho \"Hello, World\" &gt; file.txt\n\n# Add the file to the repository\ngit add file.txt\n\n# Create a new commit\ngit commit -m \"First commit\"\n\n# Modify the file\necho \"Goodbye, World\" &gt; file.txt\n\n# Add the modified file\ngit add file.txt\n\n# Create a new commit\ngit commit -m \"Second commit\"\n\n# Use git log to find the commit ID of the second commit\ngit log\n\n# Use git revert to undo the changes from the second commit\ngit revert &lt;commit-id&gt;\n\nTo download the students branch from the repository git@git-ce.rwth-aachen.de:spotseven-lab/numerische-mathematik-sommersemester2023.git to your local machine, add a file, and upload the changes, you can follow these steps:\n\nExample B.10 (An example with git clone, git checkout, git add, git commit, git push)  \n# Clone the repository to your local machine:\ngit clone git@git-ce.rwth-aachen.de:spotseven-lab/numerische-mathematik-sommersemester2023.git\n\n# Change to the cloned repository:\ncd numerische-mathematik-sommersemester2023\n\n# Switch to the students branch:\ngit checkout students\n\n# Create the Test folder if it doesn't exist:\nmkdir Test\n\n# Create the Testdatei.txt file in the Test folder:\ntouch Test/Testdatei.txt\n\n# Add the file with git add:\ngit add Test/Testdatei.txt\n\n# Commit the changes with git commit:\ngit commit -m \"Added Testdatei.txt\"\n\n# Push the changes with git push:\ngit push origin students\nThis will upload the changes to the server and update the students branch in the repository.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Git Introduction</span>"
    ]
  },
  {
    "objectID": "a_02_git_intro_en.html#downloading-from-gitlab",
    "href": "a_02_git_intro_en.html#downloading-from-gitlab",
    "title": "Appendix B — Git Introduction",
    "section": "B.5 Downloading from GitLab",
    "text": "B.5 Downloading from GitLab\nTo download changes from a GitLab repository to your local machine, you can use the git pull command. This command downloads the latest changes from the specified remote repository and merges them with your local repository.\nHere is an example:\n\nExample B.11 (An example with git pull)  \n\n# Navigate to the local repository\n# linked to the GitHub repository:\ncd my-local-repository\n\n# Make sure you are in the correct branch:\ngit checkout main\n\n# Download the latest changes from GitHub:\ngit pull origin main\nThis downloads the latest changes from the main branch of the remote repository named “origin” and merges them with your local repository.\n\nIf there are conflicts between the downloaded changes and your local changes, you will need to resolve them manually before proceeding.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Git Introduction</span>"
    ]
  },
  {
    "objectID": "a_02_git_intro_en.html#advanced",
    "href": "a_02_git_intro_en.html#advanced",
    "title": "Appendix B — Git Introduction",
    "section": "B.6 Advanced",
    "text": "B.6 Advanced\n\nB.6.1 git rebase: Moving the Base of a Branch\nIn some cases, you may need to “rewrite history.” A common scenario is that you’ve been working on a new feature in a feature branch, and you realize that the work should have actually happened in the main branch.\nTo resolve this issue and make it appear as if the work occurred in the main branch, you can reset the experimental branch. “Rebase” literally means detaching the base of the experimental branch and moving it to the beginning of another branch, giving the branch a new base, thus “rebasing.”\nThis operation is performed from the branch you want to “rebase.” You use git rebase and specify the branch you want to use as the new base. If there are no conflicts between the experimental branch and the branch you want to rebase onto, this process happens automatically.\nIf there are conflicts, Git will guide you through the conflict resolution process for each commit from the rebase branch.\nThis may sound like a lot, but there’s a good reason for it. You are literally rewriting history by transferring commits from one branch to another. To maintain the coherence of the new version history, there should be no conflicts within the commits. So, you need to resolve them one by one until the history is clean. It goes without saying that this can be a fairly labor-intensive process. Therefore, you should not use git rebase frequently.\n\nExample B.12 (An example with git rebase) git rebase is a command used to change the base of a branch. This means that commits from the branch are applied to a new base, which is usually another branch. It can be used to clean up the repository history and avoid merge conflicts.\nHere is an example showing how to use git rebase:\n\nIn this example, we initialize a new Git repository and create a new file. We add the file to the repository and make an initial commit. Then, we create a new branch called “feature” and switch to that branch. We make changes to the file in the feature branch and create a new commit.\nThen, we switch back to the main branch and make changes to the file again. We add the modified file and make another commit.\nTo rebase the feature branch onto the main branch, we first switch to the feature branch and then use the git rebase command with the name of the main branch as an argument. This applies the commits from the feature branch to the main branch and changes the base of the feature branch.\n\n# Initialize a new repository\ngit init\n# Create a new file\necho \"Hello World\" &gt; file.txt\n# Add the file to the repository\ngit add file.txt\n# Create an initial commit\ngit commit -m \"Initial commit\"\n# Create a new branch called \"feature\"\ngit branch feature\n# Switch to the \"feature\" branch\ngit checkout feature\n# Make changes to the file in the \"feature\" branch\necho \"Hello Feature World\" &gt; file.txt\n# Add the modified file\ngit add file.txt\n# Create a new commit in the \"feature\" branch\ngit commit -m \"Feature commit\"\n# Switch back to the \"main\" branch\ngit checkout main\n# Make changes to the file in the \"main\" branch\necho \"Hello Main World\" &gt; file.txt\n# Add the modified file\ngit add file.txt\n# Create a new commit in the \"main\" branch\ngit commit -m \"Main commit\"\n# Use git rebase to rebase the \"feature\" branch\n# onto the \"main\" branch\ngit checkout feature\ngit rebase main",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Git Introduction</span>"
    ]
  },
  {
    "objectID": "a_02_git_intro_en.html#exercises",
    "href": "a_02_git_intro_en.html#exercises",
    "title": "Appendix B — Git Introduction",
    "section": "B.7 Exercises",
    "text": "B.7 Exercises\nIn order to be able to carry out this exercise, we provide you with a functional working environment. This can be accessed here. You can log in using your GMID. If you do not have one, you can generate one here. Once you have successfully logged in to the server, you must open a terminal instance. You are now in a position to carry out the exercise.\nAlternatively, you can also carry out the exercise locally on your computer, but then you will need to install git.\n\nB.7.1 Create project folder\nFirst create the test-repo folder via the command line and then navigate to this folder using the corresponding command.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Git Introduction</span>"
    ]
  },
  {
    "objectID": "a_02_git_intro_en.html#initialize-repo",
    "href": "a_02_git_intro_en.html#initialize-repo",
    "title": "Appendix B — Git Introduction",
    "section": "B.8 Initialize repo",
    "text": "B.8 Initialize repo\nNow initialize the repository so that the future project, which will be saved in the test-repo folder, and all associated files are versioned.\n\nB.8.1 Do not upload / ignore certain file types\nIn order to carry out this exercise, you must first download a file which you then have git ignore. To do this, download the current examination regulations for the Bachelor’s degree program in Electrical Engineering using the following command curl -o pruefungsordnung.pdf https://www.th-koeln.de/mam/downloads/deutsch/studium/studiengaenge/f07/ordnungen_plaene/f07_bpo_ba_ekb_2021_01_04.pdf.\nThe PDF file has been stored in the root directory of your repo and you must now exclude it from being uploaded so that no changes to this file are tracked. Please note that not only this one PDF file should be ignored, but all PDF files in the repo.\n\n\nB.8.2 Create file and stage it\nIn order to be able to commit a change later and thus make it traceable, it must first be staged. However, as we only have a PDF file so far, which is to be ignored by git, we cannot stage anything. Therefore, in this task, a file test.txt with some string as content is to be created and then staged.\n\n\nB.8.3 Create another file and check status\nTo understand the status function, you should create the file test2.txt and then call the status function of git.\n\n\nB.8.4 Commit changes\nAfter the changes to the test.txt file have been staged and these are now to be transferred to the project process, they must be committed. Therefore, in this step you should perform a corresponding commit in the current branch with the message test-commit. Finally, you should also display the history of the commits.\n\n\nB.8.5 Create a new branch and switch to it\nIn this task, you are to create a new branch with the name change-text in which you will later make changes. You should then switch to this branch.\n\n\nB.8.6 Commit changes in the new branch\nTo be able to merge the new branch into the main branch later, you must first make changes to the test.txt file. To do this, open the file and simply change the character string in this file before saving the changes and closing the file. Before you now commit the file, you should reset the file to the status of the last commit for practice purposes and thus undo the change. After you have done this, open the file test.txt again and change the character string again before saving and closing the file. This time you should commit the file test.txt and then commit it with the message test-commit2.\n\n\nB.8.7 Merge branch into main\nAfter you have committed the change to the test.txt file, you should merge the change-text branch including the change into the main branch so that it is also available there.\n\n\nB.8.8 Resolve merge conflict\nTo simulate a merge conflict, you must first change the content of the test.txt file before you commit the change. Then switch to the branch change-text and change the file test.txt there as well before you commit the change. Now you should try to merge the branch change-text into the main branch and solve the problems that occur in order to be able to perform the merge successfully.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Git Introduction</span>"
    ]
  },
  {
    "objectID": "a_03_python_intro_en.html",
    "href": "a_03_python_intro_en.html",
    "title": "Appendix C — Python Introduction",
    "section": "",
    "text": "C.1 Recommendations\nBeginner’s Guide to Python",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Python Introduction</span>"
    ]
  },
  {
    "objectID": "a_04_spot_doc.html",
    "href": "a_04_spot_doc.html",
    "title": "Appendix D — Documentation of the Sequential Parameter Optimization",
    "section": "",
    "text": "D.1 An Initial Example\nThe spotpython package provides several classes of objective functions. We will use an analytical objective function, i.e., a function that can be described by a (closed) formula: \\[\nf(x) = x^2.\n\\]\nfun = analytical().fun_sphere\nx = np.linspace(-1,1,100).reshape(-1,1)\ny = fun(x)\nplt.figure()\nplt.plot(x,y, \"k\")\nplt.show()\nfrom spotpython.utils.init import fun_control_init, design_control_init, surrogate_control_init, optimizer_control_init\nspot_1 = spot.Spot(fun=fun,\n                   fun_control=fun_control_init(\n                        lower = np.array([-10]),\n                        upper = np.array([100]),\n                        fun_evals = 7,\n                        fun_repeats = 1,\n                        max_time = inf,\n                        noise = False,\n                        tolerance_x = np.sqrt(np.spacing(1)),\n                        var_type=[\"num\"],\n                        infill_criterion = \"y\",\n                        n_points = 1,\n                        seed=123,\n                        log_level = 50),\n                   design_control=design_control_init(\n                        init_size=5,\n                        repeats=1),\n                   surrogate_control=surrogate_control_init(\n                        noise=False,\n                        min_theta=-4,\n                        max_theta=3,\n                        n_theta=1,\n                        model_optimizer=differential_evolution,\n                        model_fun_evals=10000))\nspot_1.run()\n\nspotpython tuning: 2.0030463147492306 [#########-] 85.71% \nspotpython tuning: 0.010360622165042565 [##########] 100.00% Done...\n\n\n\n&lt;spotpython.spot.spot.Spot at 0x32e972810&gt;",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Documentation of the Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "a_04_spot_doc.html#organization",
    "href": "a_04_spot_doc.html#organization",
    "title": "Appendix D — Documentation of the Sequential Parameter Optimization",
    "section": "D.2 Organization",
    "text": "D.2 Organization\nSpot organizes the surrogate based optimization process in four steps:\n\nSelection of the objective function: fun.\nSelection of the initial design: design.\nSelection of the optimization algorithm: optimizer.\nSelection of the surrogate model: surrogate.\n\nFor each of these steps, the user can specify an object:\n\nfrom spotpython.fun.objectivefunctions import analytical\nfun = analytical().fun_sphere\nfrom spotpython.design.spacefilling import spacefilling\ndesign = spacefilling(2)\nfrom scipy.optimize import differential_evolution\noptimizer = differential_evolution\nfrom spotpython.build.kriging import Kriging\nsurrogate = Kriging()\n\nFor each of these steps, the user can specify a dictionary of control parameters.\n\nfun_control\ndesign_control\noptimizer_control\nsurrogate_control\n\nEach of these dictionaries has an initialzaion method, e.g., fun_control_init(). The initialization methods set the default values for the control parameters.\n\n\n\n\n\n\nImportant:\n\n\n\n\nThe specification of an lower bound in fun_control is mandatory.\n\n\n\n\nfrom spotpython.utils.init import fun_control_init, design_control_init, optimizer_control_init, surrogate_control_init\nfun_control=fun_control_init(lower=np.array([-1, -1]),\n                            upper=np.array([1, 1]))\ndesign_control=design_control_init()\noptimizer_control=optimizer_control_init()\nsurrogate_control=surrogate_control_init()",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Documentation of the Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "a_04_spot_doc.html#the-spot-object",
    "href": "a_04_spot_doc.html#the-spot-object",
    "title": "Appendix D — Documentation of the Sequential Parameter Optimization",
    "section": "D.3 The Spot Object",
    "text": "D.3 The Spot Object\nBased on the definition of the fun, design, optimizer, and surrogate objects, and their corresponding control parameter dictionaries, fun_control, design_control, optimizer_control, and surrogate_control, the spot object can be build as follows:\n\nfrom spotpython.spot import spot\nspot_tuner = spot.Spot(fun=fun,\n                       fun_control=fun_control,\n                       design_control=design_control,\n                       optimizer_control=optimizer_control,\n                       surrogate_control=surrogate_control)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Documentation of the Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "a_04_spot_doc.html#run",
    "href": "a_04_spot_doc.html#run",
    "title": "Appendix D — Documentation of the Sequential Parameter Optimization",
    "section": "D.4 Run",
    "text": "D.4 Run\n\nspot_tuner.run()\n\nspotpython tuning: 1.5904060546935205e-05 [#######---] 73.33% \nspotpython tuning: 1.5904060546935205e-05 [########--] 80.00% \nspotpython tuning: 1.5904060546935205e-05 [#########-] 86.67% \nspotpython tuning: 1.5904060546935205e-05 [#########-] 93.33% \nspotpython tuning: 1.4886245843852055e-05 [##########] 100.00% Done...\n\n\n\n&lt;spotpython.spot.spot.Spot at 0x32ed15040&gt;",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Documentation of the Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "a_04_spot_doc.html#print-the-results",
    "href": "a_04_spot_doc.html#print-the-results",
    "title": "Appendix D — Documentation of the Sequential Parameter Optimization",
    "section": "D.5 Print the Results",
    "text": "D.5 Print the Results\n\nspot_tuner.print_results()\n\nmin y: 1.4886245843852055e-05\nx0: -0.003850983818095356\nx1: -0.00023700100552480994\n\n\n[['x0', -0.003850983818095356], ['x1', -0.00023700100552480994]]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Documentation of the Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "a_04_spot_doc.html#show-the-progress",
    "href": "a_04_spot_doc.html#show-the-progress",
    "title": "Appendix D — Documentation of the Sequential Parameter Optimization",
    "section": "D.6 Show the Progress",
    "text": "D.6 Show the Progress\n\nspot_tuner.plot_progress()",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Documentation of the Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "a_04_spot_doc.html#visualize-the-surrogate",
    "href": "a_04_spot_doc.html#visualize-the-surrogate",
    "title": "Appendix D — Documentation of the Sequential Parameter Optimization",
    "section": "D.7 Visualize the Surrogate",
    "text": "D.7 Visualize the Surrogate\n\nThe plot method of the kriging surrogate is used.\nNote: the plot uses the interval defined by the ranges of the natural variables.\n\n\nspot_tuner.surrogate.plot()",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Documentation of the Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "a_04_spot_doc.html#run-with-a-specific-start-design",
    "href": "a_04_spot_doc.html#run-with-a-specific-start-design",
    "title": "Appendix D — Documentation of the Sequential Parameter Optimization",
    "section": "D.8 Run With a Specific Start Design",
    "text": "D.8 Run With a Specific Start Design\nTo pass a specific start design, use the X_start argument of the run method.\n\nspot_x0 = spot.Spot(fun=fun,\n                    fun_control=fun_control_init(\n                        lower = np.array([-10]),\n                        upper = np.array([100]),\n                        fun_evals = 7,\n                        fun_repeats = 1,\n                        max_time = inf,\n                        noise = False,\n                        tolerance_x = np.sqrt(np.spacing(1)),\n                        var_type=[\"num\"],\n                        infill_criterion = \"y\",\n                        n_points = 1,\n                        seed=123,\n                        log_level = 50),\n                    design_control=design_control_init(\n                        init_size=5,\n                        repeats=1),\n                    surrogate_control=surrogate_control_init(\n                        noise=False,\n                        min_theta=-4,\n                        max_theta=3,\n                        n_theta=1,\n                        model_optimizer=differential_evolution,\n                        model_fun_evals=10000))\nspot_x0.run(X_start=np.array([0.5, -0.5]))\nspot_x0.plot_progress()\n\nspotpython tuning: 2.0030463147492306 [#########-] 85.71% \nspotpython tuning: 0.010360622165042565 [##########] 100.00% Done...",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Documentation of the Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "a_04_spot_doc.html#init-build-initial-design",
    "href": "a_04_spot_doc.html#init-build-initial-design",
    "title": "Appendix D — Documentation of the Sequential Parameter Optimization",
    "section": "D.9 Init: Build Initial Design",
    "text": "D.9 Init: Build Initial Design\n\nfrom spotpython.design.spacefilling import spacefilling\nfrom spotpython.build.kriging import Kriging\nfrom spotpython.fun.objectivefunctions import analytical\nfrom spotpython.utils.init import fun_control_init\ngen = spacefilling(2)\nrng = np.random.RandomState(1)\nlower = np.array([-5,-0])\nupper = np.array([10,15])\nfun = analytical().fun_branin\n\nfun_control = fun_control_init(sigma=0)\n\nX = gen.scipy_lhd(10, lower=lower, upper = upper)\nprint(X)\ny = fun(X, fun_control=fun_control)\nprint(y)\n\n[[ 8.97647221 13.41926847]\n [ 0.66946019  1.22344228]\n [ 5.23614115 13.78185824]\n [ 5.6149825  11.5851384 ]\n [-1.72963184  1.66516096]\n [-4.26945568  7.1325531 ]\n [ 1.26363761 10.17935555]\n [ 2.88779942  8.05508969]\n [-3.39111089  4.15213772]\n [ 7.30131231  5.22275244]]\n[128.95676449  31.73474356 172.89678121 126.71295908  64.34349975\n  70.16178611  48.71407916  31.77322887  76.91788181  30.69410529]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Documentation of the Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "a_04_spot_doc.html#replicability",
    "href": "a_04_spot_doc.html#replicability",
    "title": "Appendix D — Documentation of the Sequential Parameter Optimization",
    "section": "D.10 Replicability",
    "text": "D.10 Replicability\nSeed\n\ngen = spacefilling(2, seed=123)\nX0 = gen.scipy_lhd(3)\ngen = spacefilling(2, seed=345)\nX1 = gen.scipy_lhd(3)\nX2 = gen.scipy_lhd(3)\ngen = spacefilling(2, seed=123)\nX3 = gen.scipy_lhd(3)\nX0, X1, X2, X3\n\n(array([[0.77254938, 0.31539299],\n        [0.59321338, 0.93854273],\n        [0.27469803, 0.3959685 ]]),\n array([[0.78373509, 0.86811887],\n        [0.06692621, 0.6058029 ],\n        [0.41374778, 0.00525456]]),\n array([[0.121357  , 0.69043832],\n        [0.41906219, 0.32838498],\n        [0.86742658, 0.52910374]]),\n array([[0.77254938, 0.31539299],\n        [0.59321338, 0.93854273],\n        [0.27469803, 0.3959685 ]]))",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Documentation of the Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "a_04_spot_doc.html#surrogates",
    "href": "a_04_spot_doc.html#surrogates",
    "title": "Appendix D — Documentation of the Sequential Parameter Optimization",
    "section": "D.11 Surrogates",
    "text": "D.11 Surrogates\n\nD.11.1 A Simple Predictor\nThe code below shows how to use a simple model for prediction. Assume that only two (very costly) measurements are available:\n\nf(0) = 0.5\nf(2) = 2.5\n\nWe are interested in the value at \\(x_0 = 1\\), i.e., \\(f(x_0 = 1)\\), but cannot run an additional, third experiment.\n\nfrom sklearn import linear_model\nX = np.array([[0], [2]])\ny = np.array([0.5, 2.5])\nS_lm = linear_model.LinearRegression()\nS_lm = S_lm.fit(X, y)\nX0 = np.array([[1]])\ny0 = S_lm.predict(X0)\nprint(y0)\n\n[1.5]\n\n\nCentral Idea: Evaluation of the surrogate model S_lm is much cheaper (or / and much faster) than running the real-world experiment \\(f\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Documentation of the Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "a_04_spot_doc.html#tensorboard-setup",
    "href": "a_04_spot_doc.html#tensorboard-setup",
    "title": "Appendix D — Documentation of the Sequential Parameter Optimization",
    "section": "D.12 Tensorboard Setup",
    "text": "D.12 Tensorboard Setup\n\nD.12.1 Tensorboard Configuration\nThe TENSORBOARD_CLEAN argument can be set to True in the fun_control dictionary to archive the TensorBoard folder if it already exists. This is useful if you want to start a hyperparameter tuning process from scratch. If you want to continue a hyperparameter tuning process, set TENSORBOARD_CLEAN to False. Then the TensorBoard folder will not be archived and the old and new TensorBoard files will shown in the TensorBoard dashboard.\n\n\nD.12.2 Starting TensorBoard\nTensorBoard can be started as a background process with the following command, where ./runs is the default directory for the TensorBoard log files:\ntensorboard --logdir=\"./runs\"\n\n\n\n\n\n\nTENSORBOARD_PATH\n\n\n\nThe TensorBoard path can be printed with the following command (after a fun_control object has been created):\n\nfrom spotpython.utils.init import get_tensorboard_path\nget_tensorboard_path(fun_control)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Documentation of the Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "a_04_spot_doc.html#demotest-objective-function-fails",
    "href": "a_04_spot_doc.html#demotest-objective-function-fails",
    "title": "Appendix D — Documentation of the Sequential Parameter Optimization",
    "section": "D.13 Demo/Test: Objective Function Fails",
    "text": "D.13 Demo/Test: Objective Function Fails\nSPOT expects np.nan values from failed objective function values. These are handled. Note: SPOT’s counter considers only successful executions of the objective function.\n\nimport numpy as np\nfrom spotpython.fun.objectivefunctions import analytical\nfrom spotpython.spot import spot\nimport numpy as np\nfrom math import inf\n# number of initial points:\nni = 20\n# number of points\nn = 30\n\nfun = analytical().fun_random_error\nfun_control=fun_control_init(\n    lower = np.array([-1]),\n    upper= np.array([1]),\n    fun_evals = n,\n    show_progress=False)\ndesign_control=design_control_init(init_size=ni)\n\nspot_1 = spot.Spot(fun=fun,\n                     fun_control=fun_control,\n                     design_control=design_control)\n\n# assert value error from the run method\ntry:\n    spot_1.run()\nexcept ValueError as e:\n    print(e)\n\n[        nan         nan -0.02203599 -0.21843718  0.78240941         nan\n -0.3923345   0.67234256  0.31802454 -0.68898927 -0.75129705  0.97550354\n  0.41757584         nan  0.82585329         nan -0.49274073         nan\n -0.17991251  0.1481835 ]\n[-1.]\n[nan]\n[-0.57084122]\n[0.166475]\n[nan]\n[-0.24270361]\n[-0.47259301]\n[0.95541987]\n[0.17335968]\n[-0.58552368]\n[-0.20126111]\n[-0.60100809]\n[-0.97897336]\n[-0.2748985]\n[0.8359486]\n[0.99035591]\n[0.01641232]\n[0.5629346]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Documentation of the Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "a_04_spot_doc.html#handling-results-printing-saving-and-loading",
    "href": "a_04_spot_doc.html#handling-results-printing-saving-and-loading",
    "title": "Appendix D — Documentation of the Sequential Parameter Optimization",
    "section": "D.14 Handling Results: Printing, Saving, and Loading",
    "text": "D.14 Handling Results: Printing, Saving, and Loading\nThe results can be printed with the following command:\n\nspot_tuner.print_results(print_screen=False)\n\nThe tuned hyperparameters can be obtained as a dictionary with the following command:\n\nfrom spotpython.hyperparameters.values import get_tuned_hyperparameters\nget_tuned_hyperparameters(spot_tuner, fun_control)\n\nThe results can be saved and reloaded with the following commands:\n\nfrom spotpython.utils.file import save_pickle, load_pickle\nfrom spotpython.utils.init import get_experiment_name\nexperiment_name = get_experiment_name(\"024\")\nSAVE_AND_LOAD = False\nif SAVE_AND_LOAD == True:\n    save_pickle(spot_tuner, experiment_name)\n    spot_tuner = load_pickle(experiment_name)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Documentation of the Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "a_04_spot_doc.html#spotpython-as-a-hyperparameter-tuner",
    "href": "a_04_spot_doc.html#spotpython-as-a-hyperparameter-tuner",
    "title": "Appendix D — Documentation of the Sequential Parameter Optimization",
    "section": "D.15 spotpython as a Hyperparameter Tuner",
    "text": "D.15 spotpython as a Hyperparameter Tuner\n\nD.15.1 Modifying Hyperparameter Levels\nspotpython distinguishes between different types of hyperparameters. The following types are supported:\n\nint (integer)\nfloat (floating point number)\nboolean (boolean)\nfactor (categorical)\n\n\nD.15.1.1 Integer Hyperparameters\nInteger hyperparameters can be modified with the set_int_hyperparameter_values() [SOURCE] function. The following code snippet shows how to modify the n_estimators hyperparameter of a random forest model:\n\nfrom spotriver.hyperdict.river_hyper_dict import RiverHyperDict\nfrom spotpython.utils.init import fun_control_init\nfrom spotpython.hyperparameters.values import set_int_hyperparameter_values\nfrom spotpython.utils.eda import gen_design_table\nfun_control = fun_control_init(\n    core_model_name=\"forest.AMFRegressor\",\n    hyperdict=RiverHyperDict,\n)\nprint(\"Before modification:\")\nprint(gen_design_table(fun_control))\nset_int_hyperparameter_values(fun_control, \"n_estimators\", 2, 5)\nprint(\"After modification:\")\nprint(gen_design_table(fun_control))\n\nBefore modification:\n| name            | type   |   default |   lower |   upper | transform             |\n|-----------------|--------|-----------|---------|---------|-----------------------|\n| n_estimators    | int    |         3 |     2   |       5 | transform_power_2_int |\n| step            | float  |         1 |     0.1 |      10 | None                  |\n| use_aggregation | factor |         1 |     0   |       1 | None                  |\nSetting hyperparameter n_estimators to value [2, 5].\nVariable type is int.\nCore type is None.\nCalling modify_hyper_parameter_bounds().\nAfter modification:\n| name            | type   |   default |   lower |   upper | transform             |\n|-----------------|--------|-----------|---------|---------|-----------------------|\n| n_estimators    | int    |         3 |     2   |       5 | transform_power_2_int |\n| step            | float  |         1 |     0.1 |      10 | None                  |\n| use_aggregation | factor |         1 |     0   |       1 | None                  |\n\n\n\n\nD.15.1.2 Float Hyperparameters\nFloat hyperparameters can be modified with the set_float_hyperparameter_values() [SOURCE] function. The following code snippet shows how to modify the step hyperparameter of a hyperparameter of a Mondrian Regression Tree model:\n\nfrom spotriver.hyperdict.river_hyper_dict import RiverHyperDict\nfrom spotpython.utils.init import fun_control_init\nfrom spotpython.hyperparameters.values import set_float_hyperparameter_values\nfrom spotpython.utils.eda import gen_design_table\nfun_control = fun_control_init(\n    core_model_name=\"forest.AMFRegressor\",\n    hyperdict=RiverHyperDict,\n)\nprint(\"Before modification:\")\nprint(gen_design_table(fun_control))\nset_float_hyperparameter_values(fun_control, \"step\", 0.2, 5)\nprint(\"After modification:\")\nprint(gen_design_table(fun_control))\n\nBefore modification:\n| name            | type   |   default |   lower |   upper | transform             |\n|-----------------|--------|-----------|---------|---------|-----------------------|\n| n_estimators    | int    |         3 |     2   |       5 | transform_power_2_int |\n| step            | float  |         1 |     0.1 |      10 | None                  |\n| use_aggregation | factor |         1 |     0   |       1 | None                  |\nSetting hyperparameter step to value [0.2, 5].\nVariable type is float.\nCore type is None.\nCalling modify_hyper_parameter_bounds().\nAfter modification:\n| name            | type   |   default |   lower |   upper | transform             |\n|-----------------|--------|-----------|---------|---------|-----------------------|\n| n_estimators    | int    |         3 |     2   |       5 | transform_power_2_int |\n| step            | float  |         1 |     0.2 |       5 | None                  |\n| use_aggregation | factor |         1 |     0   |       1 | None                  |\n\n\n\n\nD.15.1.3 Boolean Hyperparameters\nBoolean hyperparameters can be modified with the set_boolean_hyperparameter_values() [SOURCE] function. The following code snippet shows how to modify the use_aggregation hyperparameter of a Mondrian Regression Tree model:\n\nfrom spotriver.hyperdict.river_hyper_dict import RiverHyperDict\nfrom spotpython.utils.init import fun_control_init\nfrom spotpython.hyperparameters.values import set_boolean_hyperparameter_values\nfrom spotpython.utils.eda import gen_design_table\nfun_control = fun_control_init(\n    core_model_name=\"forest.AMFRegressor\",\n    hyperdict=RiverHyperDict,\n)\nprint(\"Before modification:\")\nprint(gen_design_table(fun_control))\nset_boolean_hyperparameter_values(fun_control, \"use_aggregation\", 0, 0)\nprint(\"After modification:\")\nprint(gen_design_table(fun_control))\n\nBefore modification:\n| name            | type   |   default |   lower |   upper | transform             |\n|-----------------|--------|-----------|---------|---------|-----------------------|\n| n_estimators    | int    |         3 |     2   |       5 | transform_power_2_int |\n| step            | float  |         1 |     0.1 |      10 | None                  |\n| use_aggregation | factor |         1 |     0   |       1 | None                  |\nSetting hyperparameter use_aggregation to value [0, 0].\nVariable type is factor.\nCore type is bool.\nCalling modify_boolean_hyper_parameter_levels().\nAfter modification:\n| name            | type   |   default |   lower |   upper | transform             |\n|-----------------|--------|-----------|---------|---------|-----------------------|\n| n_estimators    | int    |         3 |     2   |       5 | transform_power_2_int |\n| step            | float  |         1 |     0.1 |      10 | None                  |\n| use_aggregation | factor |         1 |     0   |       0 | None                  |\n\n\n\n\nD.15.1.4 Factor Hyperparameters\nFactor hyperparameters can be modified with the set_factor_hyperparameter_values() [SOURCE] function. The following code snippet shows how to modify the leaf_model hyperparameter of a Hoeffding Tree Regressor model:\n\nfrom spotriver.hyperdict.river_hyper_dict import RiverHyperDict\nfrom spotpython.utils.init import fun_control_init\nfrom spotpython.hyperparameters.values import set_factor_hyperparameter_values\nfrom spotpython.utils.eda import gen_design_table\nfun_control = fun_control_init(\n    core_model_name=\"tree.HoeffdingTreeRegressor\",\n    hyperdict=RiverHyperDict,\n)\nprint(\"Before modification:\")\nprint(gen_design_table(fun_control))\nset_factor_hyperparameter_values(fun_control, \"leaf_model\", ['LinearRegression',\n                                                    'Perceptron'])\nprint(\"After modification:\")\n\nBefore modification:\n| name                   | type   | default          |   lower |    upper | transform              |\n|------------------------|--------|------------------|---------|----------|------------------------|\n| grace_period           | int    | 200              |  10     | 1000     | None                   |\n| max_depth              | int    | 20               |   2     |   20     | transform_power_2_int  |\n| delta                  | float  | 1e-07            |   1e-08 |    1e-06 | None                   |\n| tau                    | float  | 0.05             |   0.01  |    0.1   | None                   |\n| leaf_prediction        | factor | mean             |   0     |    2     | None                   |\n| leaf_model             | factor | LinearRegression |   0     |    2     | None                   |\n| model_selector_decay   | float  | 0.95             |   0.9   |    0.99  | None                   |\n| splitter               | factor | EBSTSplitter     |   0     |    2     | None                   |\n| min_samples_split      | int    | 5                |   2     |   10     | None                   |\n| binary_split           | factor | 0                |   0     |    1     | None                   |\n| max_size               | float  | 500.0            | 100     | 1000     | None                   |\n| memory_estimate_period | int    | 6                |   3     |    8     | transform_power_10_int |\n| stop_mem_management    | factor | 0                |   0     |    1     | None                   |\n| remove_poor_attrs      | factor | 0                |   0     |    1     | None                   |\n| merit_preprune         | factor | 1                |   0     |    1     | None                   |\nAfter modification:",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Documentation of the Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "a_05_datasets.html",
    "href": "a_05_datasets.html",
    "title": "Appendix E — Datasets",
    "section": "",
    "text": "E.1 The Diabetes Data Set\nThis section describes the Diabetes data set. This is a PyTorch Dataset for regression, which is derived from the Diabetes data set from scikit-learn (sklearn). Ten baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements were obtained for each of n = 442 diabetes patients, as well as the response of interest, a quantitative measure of disease progression one year after baseline.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Datasets</span>"
    ]
  },
  {
    "objectID": "a_05_datasets.html#sec-a-05-diabetes-data-set",
    "href": "a_05_datasets.html#sec-a-05-diabetes-data-set",
    "title": "Appendix E — Datasets",
    "section": "",
    "text": "E.1.1 Data Exploration of the sklearn Diabetes Data Set\n\nfrom sklearn.datasets import load_diabetes\nfrom spotpython.plot.xy import plot_y_vs_X\ndata = load_diabetes()\nX, y = data.data, data.target\nplot_y_vs_X(X, y, nrows=5, ncols=2, figsize=(20, 15))\n\n\n\n\n\n\n\n\n\nEach of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of n_samples (i.e., the sum of squares of each column totals 1).\ns3_hdl shows a different behavior than the other features. It has a negative slope. HDL (high-density lipoprotein) cholesterol, sometimes called “good” cholesterol, absorbs cholesterol in the blood and carries it back to the liver. The liver then flushes it from the body. High levels of HDL cholesterol can lower your risk for heart disease and stroke.\n\n\n\nE.1.2 Generating the PyTorch Data Set\nspotpython provides a Diabetes class to load the diabetes data set. The Diabetes class is a subclass of torch.utils.data.Dataset. It loads the diabetes data set from sklearn and returns the data set as a torch.utils.data.Dataset object, so that features and targets can be accessed as torch.tensors. [CODE REFERENCE].\n\nfrom spotpython.data.diabetes import Diabetes\ndata_set = Diabetes()\nprint(len(data_set))\nprint(data_set.names)\n\n442\n['age', 'sex', 'bmi', 'bp', 's1_tc', 's2_ldl', 's3_hdl', 's4_tch', 's5_ltg', 's6_glu']",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Datasets</span>"
    ]
  },
  {
    "objectID": "a_05_datasets.html#sec-a-05-friedman",
    "href": "a_05_datasets.html#sec-a-05-friedman",
    "title": "Appendix E — Datasets",
    "section": "E.2 The Friedman Drift Dataset",
    "text": "E.2 The Friedman Drift Dataset\n\nE.2.1 The Friedman Drift Dataset as Implemented in river\nWe will describe the Friedman synthetic dataset with concept drifts [SOURCE], see also Friedman (1991) and Ikonomovska, Gama, and Džeroski (2011). Each observation is composed of ten features. Each feature value is sampled uniformly in [0, 1]. Only the first five features are relevant. The target is defined by different functions depending on the type of the drift. Global Recurring Abrupt drift will be used, i.e., the concept drift appears over the whole instance space.\nThe target is defined by the following function: \\[\ny = 10 \\sin(\\pi x_0 x_1) + 20 (x_2 - 0.5)^2 + 10 x_3 + 5 x_4 + \\epsilon,\n\\] where \\(\\epsilon \\sim \\mathcal{N}(0, 1)\\) is normally distributed noise.\nIf the Global Recurring Abrupt drift variant of the Friedman Drift dataset is used, the target function changes at two points in time, namely \\(p_1\\) and \\(p_2\\). At the first point, the concept changes to: \\[\ny = 10 \\sin(\\pi x_3 x_5) + 20 (x_1 - 0.5)^2 + 10 x_0 + 5 x_2 + \\epsilon,\n\\] At the second point of drift the old concept reoccurs. This can be implemented as follows, see https://riverml.xyz/latest/api/datasets/synth/FriedmanDrift/:\ndef __iter__(self):\n    rng = random.Random(self.seed)\n\n    i = 0\n    while True:\n        x = {i: rng.uniform(a=0, b=1) for i in range(10)}\n        y = self._global_recurring_abrupt_gen(x, i) + rng.gauss(mu=0, sigma=1)\n\n        yield x, y\n        i += 1\ndef _global_recurring_abrupt_gen(self, x, index: int):\n    if index &lt; self._change_point1 or index &gt;= self._change_point2:\n        # The initial concept is recurring\n        return (\n            10 * math.sin(math.pi * x[0] * x[1]) + 20 * (x[2] - 0.5) ** 2 + 10 * x[3] + 5 * x[4]\n        )\n    else:\n        # Drift: the positions of the features are swapped\n        return (\n            10 * math.sin(math.pi * x[3] * x[5]) + 20 * (x[1] - 0.5) ** 2 + 10 * x[0] + 5 * x[2]\n        )\nspotpython requires the specification of a train and test data set. These data sets can be generated as follows:\n\nfrom river.datasets import synth\nimport pandas as pd\nimport numpy as np\nfrom spotriver.utils.data_conversion import convert_to_df\n\nseed = 123\nshuffle = True\nn_train = 6_000\nn_test = 4_000\nn_samples = n_train + n_test\ntarget_column = \"y\"\n\ndataset = synth.FriedmanDrift(\n   drift_type='gra',\n   position=(n_train/4, n_train/2),\n   seed=123\n)\n\ntrain = convert_to_df(dataset, n_total=n_train)\ntrain.columns = [f\"x{i}\" for i in range(1, 11)] + [target_column]\n\n\ndataset = synth.FriedmanDrift(\n   drift_type='gra',\n   position=(n_test/4, n_test/2),\n   seed=123\n)\ntest = convert_to_df(dataset, n_total=n_test)\ntest.columns = [f\"x{i}\" for i in range(1, 11)] + [target_column]\n\n\ndef plot_data_with_drift_points(data, target_column, n_train, title=\"\"):\n    indices = range(len(data))\n    y_values = data[target_column]\n\n    plt.figure(figsize=(10, 6))\n    plt.plot(indices, y_values, label=\"y Value\", color='blue')\n\n    drift_points = [n_train / 4, n_train / 2]\n    for dp in drift_points:\n        plt.axvline(x=dp, color='red', linestyle='--', label=f'Drift Point at {int(dp)}')\n\n    handles, labels = plt.gca().get_legend_handles_labels()\n    by_label = dict(zip(labels, handles))\n    plt.legend(by_label.values(), by_label.keys())\n\n    plt.xlabel('Index')\n    plt.ylabel('Target Value (y)')\n    plt.title(title)\n    plt.grid(True)\n    plt.show()\n\n\nplot_data_with_drift_points(train, target_column, n_train, title=\"Training Data with Drift Points\")\n\n\n\n\n\n\n\n\n\nplot_data_with_drift_points(test, target_column, n_train, title=\"Testing Data with Drift Points\")\n\n\n\n\n\n\n\n\n\n\nE.2.2 The Friedman Drift Data Set from spotpython\nA data generator for the Friedman Drift dataset is implemented in the spotpython package, see friedman.py. The spotpython version is a simplified version of the river implementation. The spotPyton version allows the generation of constant input values for the features. This is useful for visualizing the concept drifts. For the productive use the river version should be used.\nPlotting the first 100 samples of the Friedman Drift dataset, we can not see the concept drifts at \\(p_1\\) and \\(p_2\\). Drift can be visualized by plotting the target values over time for constant features, e,g, if \\(x_0\\) is set to \\(1\\) and all other features are set to \\(0\\). This is illustrated in the following plot.\n\nfrom spotpython.data.friedman import FriedmanDriftDataset\n\ndef plot_friedman_drift_data(n_samples, seed, change_point1, change_point2, constant=True):\n    data_generator = FriedmanDriftDataset(n_samples=n_samples, seed=seed, change_point1=change_point1, change_point2=change_point2, constant=constant)\n    data = [data for data in data_generator]\n    indices = [i for _, _, i in data]\n    values = {f\"x{i}\": [] for i in range(5)}\n    values[\"y\"] = []\n    for x, y, _ in data:\n        for i in range(5):\n            values[f\"x{i}\"].append(x[i])\n        values[\"y\"].append(y)\n\n    plt.figure(figsize=(10, 6))\n    for label, series in values.items():\n        plt.plot(indices, series, label=label)\n    plt.xlabel('Index')\n    plt.ylabel('Value')\n    plt.axvline(x=change_point1, color='k', linestyle='--', label='Drift Point 1')\n    plt.axvline(x=change_point2, color='r', linestyle='--', label='Drift Point 2')\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\nplot_friedman_drift_data(n_samples=100, seed=42, change_point1=50, change_point2=75, constant=False)\nplot_friedman_drift_data(n_samples=100, seed=42, change_point1=50, change_point2=75, constant=True)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFriedman, Jerome H. 1991. “Multivariate Adaptive Regression Splines.” The Annals of Statistics 19 (1): 1–67.\n\n\nIkonomovska, Elena, João Gama, and Sašo Džeroski. 2011. “Learning Model Trees from Evolving Data Streams.” Data Mining and Knowledge Discovery 23 (1): 128–68.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Datasets</span>"
    ]
  },
  {
    "objectID": "a_06_slurm.html",
    "href": "a_06_slurm.html",
    "title": "Appendix F — Using Slurm",
    "section": "",
    "text": "F.1 Introduction\nThis chapter describes how to generate a spotpython configuration on a local machine and run the spotpython code on a remote machine using Slurm.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Using Slurm</span>"
    ]
  },
  {
    "objectID": "a_06_slurm.html#prepare-the-slurm-scripts-on-the-remote-machine",
    "href": "a_06_slurm.html#prepare-the-slurm-scripts-on-the-remote-machine",
    "title": "Appendix F — Using Slurm",
    "section": "F.2 Prepare the Slurm Scripts on the Remote Machine",
    "text": "F.2 Prepare the Slurm Scripts on the Remote Machine\nTwo scripts are required to run the spotpython code on the remote machine:\n\nstartSlurm.sh and\nstartPython.py.\n\nThey should be saved in the same directory as the configuration (pickle) file. These two scripts must be generated only once and can be reused for different configurations.\nThe startSlurm.sh script is a shell script that contains the following code:\n\n#!/bin/python\n \n### Vergabe von Ressourcen\n#SBATCH --job-name=CH10_Test\n#SBATCH --ntasks-per-node=64\n#SBATCH --gres=gpu:1\n#SBATCH --time=24:00:00\n#SBATCH --error=job.%J.err\n#SBATCH --output=job.%J.out\n#----\n#SBATCH --partition=gpu\n\nif [ -z \"$1\" ]; then\n    echo \"Usage: $0 &lt;path_to_spot.pkl&gt;\"\n    exit 1\nfi\n\nSPOT_PKL=$1\n\nmodule load conda\n\nconda activate spot312\n\nsrun python startPython.py \"$SPOT_PKL\"\n\nSave the code in a file named startSlurm.sh and copy the file to the remote machine via scp, i.e.,\n\nscp startSlurm.sh user@144.33.22.1:\n\nThe startPython.py script is a Python script that contains the following code:\n\nimport argparse\nimport pickle\nfrom spotpython.utils.file import load_and_run_spot_python_experiment\n\ndef main(pickle_file):\n    spot_tuner = load_and_run_spot_python_experiment(pickle_file)\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description='Process a pickle file.')\n    parser.add_argument('pickle_file', type=str, help='The path to the pickle file to be processed.')\n\n    args = parser.parse_args()\n    main(args.pickle_file)\n\nSave the code in a file named startPython.py and copy the file to the remote machine via scp, i.e.,\n\nscp startPython.py user@144.33.22.1:",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Using Slurm</span>"
    ]
  },
  {
    "objectID": "a_06_slurm.html#generate-a-spotpython-configuration",
    "href": "a_06_slurm.html#generate-a-spotpython-configuration",
    "title": "Appendix F — Using Slurm",
    "section": "F.3 Generate a spotpython Configuration",
    "text": "F.3 Generate a spotpython Configuration\nThe configuration can be generated on a local machine using the following command:\n\nimport os\nfrom math import inf\nfrom spotpython.hyperdict.light_hyper_dict import LightHyperDict\nfrom spotpython.fun.hyperlight import HyperLight\nfrom spotpython.utils.init import (fun_control_init, design_control_init, surrogate_control_init)\nfrom spotpython.utils.eda import gen_design_table\nfrom spotpython.hyperparameters.values import set_hyperparameter\nfrom spotpython.spot import spot\nfrom spotpython.utils.scaler import TorchStandardScaler\nfrom spotpython.utils.device import getDevice\nfrom spotpython.utils.file import get_experiment_filename\n\n# load data (adapt this to your needs)\nfrom pyhcf.utils.io import load_hcf_df, hcf_df2tensor\nfrom pyhcf.utils.names import load_all_features_N_regression_list\ndf = load_hcf_df(A=True, H=True, param_list=load_all_features_N_regression_list(), target='N', rmNA=True, rmMF=True, rmV=4, min_freq=1000, incl_drossel=False)\ndata_set = hcf_df2tensor(df, target='N', return_X_y=False)\n\nfun_control = fun_control_init(\n    PREFIX=\"01\",\n    TENSORBOARD_CLEAN=False,\n    tensorboard_log=False,\n    fun_evals=inf,\n    max_time=600,\n    data_set=data_set,\n    scaler=TorchStandardScaler(),\n    device=getDevice(),\n    max_surrogate_points=30,\n    core_model_name=\"light.regression.NNLinearRegressor\",\n    hyperdict=LightHyperDict,\n    _L_in=86,\n    _L_out=1)\n\n# The following \"set_hyperparameter\"-block is optional.\n# You can adapt the hyperparameters to your needs as follows:\nset_hyperparameter(fun_control, \"optimizer\", [\n                \"Adadelta\",\n                \"Adagrad\",\n                \"Adam\",\n                \"AdamW\",\n                \"Adamax\",\n            ])\nset_hyperparameter(fun_control, \"l1\", [3,9])\nset_hyperparameter(fun_control, \"epochs\", [10,12])\nset_hyperparameter(fun_control, \"batch_size\", [4,8])\nset_hyperparameter(fun_control, \"dropout_prob\", [0.0, 0.1])\nset_hyperparameter(fun_control, \"lr_mult\", [0.1, 20.0])\nset_hyperparameter(fun_control, \"patience\", [6,9])\n\n# Modify the design control (optional)\ndesign_control = design_control_init(init_size=20)\n# Modify the surrogate control (optional)\nsurrogate_control = surrogate_control_init(\n    noise=True,\n    n_theta=2,\n    min_Lambda=1e-3,\n    max_Lambda=10,\n)\n\n# Check the design table\nprint(gen_design_table(fun_control))\n\n# The remaining part is mandatory:\nfun = HyperLight().fun\nspot_tuner = spot.Spot(fun=fun,fun_control=fun_control, design_control=design_control, surrogate_control=surrogate_control)\nfilename = get_experiment_filename(fun_control[\"PREFIX\"])\n# remove attribute spot_writer from spot_tuner object\nif hasattr(spot_tuner, \"spot_writer\"):\n    delattr(spot_tuner, \"spot_writer\")\nspot_tuner.save_experiment(filename=filename)\n\nThe configuration is saved as a pickle-file that contains the full information. In our example, the filename is spot_01_experiment.pickle.\n\n\n\n\n\n\nData\n\n\n\nThe data is loaded from the pyhcf package. You can adapt the data loading to your needs. To generate dummy data, you can use the following code:\n\nnum_samples = 1000\ninput_dim = 86\nX = torch.randn(num_samples, input_dim)  # random data for example\nY = torch.randn(num_samples, 1)  # random target for example\ndata_set = TensorDataset(X, Y)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Using Slurm</span>"
    ]
  },
  {
    "objectID": "a_06_slurm.html#copy-the-configuration-to-the-remote-machine",
    "href": "a_06_slurm.html#copy-the-configuration-to-the-remote-machine",
    "title": "Appendix F — Using Slurm",
    "section": "F.4 Copy the Configuration to the Remote Machine",
    "text": "F.4 Copy the Configuration to the Remote Machine\nYou can copy the configuration to the remote machine using the scp command. The following command copies the configuration to the remote machine 144.33.22.1:\n\nscp spot_01_experiment.pickle user@144.33.22.1:",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Using Slurm</span>"
    ]
  },
  {
    "objectID": "a_06_slurm.html#run-the-spotpython-code-on-the-remote-machine",
    "href": "a_06_slurm.html#run-the-spotpython-code-on-the-remote-machine",
    "title": "Appendix F — Using Slurm",
    "section": "F.5 Run the spotpython Code on the Remote Machine",
    "text": "F.5 Run the spotpython Code on the Remote Machine\nLogin on the remote machine and run the following command to start the spotpython code:\n\nssh user@144.33.22.1\ncd /path/to/remote/directory\nsh -x ./startSlurm.sh spot_01_experiment.pickle",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Using Slurm</span>"
    ]
  },
  {
    "objectID": "a_06_slurm.html#copy-the-results-to-the-local-machine",
    "href": "a_06_slurm.html#copy-the-results-to-the-local-machine",
    "title": "Appendix F — Using Slurm",
    "section": "F.6 Copy the Results to the Local Machine",
    "text": "F.6 Copy the Results to the Local Machine\nAfter the spotpython code has finished, you can copy the results back to the local machine using the scp command. The following command copies the results to the local machine:\n\nscp user@144.33.22.1:spot_01_experiment.pickle .",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Using Slurm</span>"
    ]
  },
  {
    "objectID": "a_06_slurm.html#analyze-the-results-on-the-local-machine",
    "href": "a_06_slurm.html#analyze-the-results-on-the-local-machine",
    "title": "Appendix F — Using Slurm",
    "section": "F.7 Analyze the Results on the Local Machine",
    "text": "F.7 Analyze the Results on the Local Machine\nThe file spot_01_experiment.pickle contains the results of the spotpython code. You can analyze the results on the local machine using the following code.\n\nfrom spotpython.utils.file import load_experiment\nspot_tuner, fun_control, design_control, surrogate_control, optimizer_control = load_experiment(\"spot_01_experiment.pickle\")\n\n\nF.7.1 Visualizing the Tuning Progress\nNow the spot_tuner object is loaded and you can analyze the results interactively.\n\nspot_tuner.plot_progress(log_y=True, filename=None)\n\n\n\nF.7.2 Design Table with Default and Tuned Hyperparameters\n\nfrom spotpython.utils.eda import gen_design_table\nprint(gen_design_table(fun_control=fun_control, spot=spot_tuner))\n\n\n\nF.7.3 Plotting Important Hyperparameters\n\nspot_tuner.plot_important_hyperparameter_contour(max_imp=3)\n\n\n\n\n\n\n\nspotgui\n\n\n\nThe spotgui can be used to analyze the results interactively.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Using Slurm</span>"
    ]
  },
  {
    "objectID": "a_99_solutions.html",
    "href": "a_99_solutions.html",
    "title": "Appendix G — Solutions to Selected Exercises",
    "section": "",
    "text": "G.1 Data-Driven Modeling and Optimization",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Solutions to Selected Exercises</span>"
    ]
  },
  {
    "objectID": "a_99_solutions.html#data-driven-modeling-and-optimization",
    "href": "a_99_solutions.html#data-driven-modeling-and-optimization",
    "title": "Appendix G — Solutions to Selected Exercises",
    "section": "",
    "text": "G.1.1 Histograms\n\nSolution G.1 (Density Curve). \n\nWe can calculate propabilities.\nWe only need two parameters (the mean and the sd) to form the curve -&gt; Store data more efficently\nBlanks can be filled\n\n\n\n\nG.1.2 The Normal Distribution\n\nSolution G.2 (TwoSDAnswer). 95%\n\n\nSolution G.3 (OneSDAnswer). 68%\n\n\nSolution G.4 (ThreeSDAnswer). 99,7%\n\n\nSolution G.5 (DataRangeAnswer). 80 - 120\n\n\nSolution G.6 (PeakHeightAnswer). low\n\n\n\nG.1.3 The mean, the media, and the mode\n\n\nG.1.4 The exponential distribution\n\n\nG.1.5 Population and Estimated Parameters\n\nSolution G.7 (ProbabilityAnswer). 50%\n\n\n\nG.1.6 Calculating the Mean, Variance and Standard Deviation\n\nSolution G.8 (MeanDifferenceAnswer). If we have all the data, \\(\\mu\\) is the population mean and x-bar is the sample mean. We don’t have the full information.\n\n\nSolution G.9 (EstimateMeanAnswer). Sum of the values divided by n.\n\n\nSolution G.10 (SigmaSquaredAnswer). Variance\n\n\nSolution G.11 (EstimatedSDAnswer). The same as the normal standard deviation, but using n-1.\n\n\nSolution G.12 (VarianceDifferenceAnswer). \\(n\\) and \\(n-1\\)\n\n\nSolution G.13 (ModelBenefitsAnswer). \n\nApproximation\nPrediction\nUnderstanding\n\n\n\nSolution G.14 (SampleDefinitionAnswer). It’s a subset of the data.\n\n\n\nG.1.7 Hypothesis Testing and the Null-Hypothesis\n\nSolution G.15 (RejectHypothesisAnswer). It means the evidence supports the alternative hypothesis, indicating that the null hypothesis is unlikely to be true.\n\n\nSolution G.16 (NullHypothesisAnswer). It’s a statement that there is no effect or no difference, and it serves as the default or starting assumption in hypothesis testing.\n\n\nSolution G.17 (BetterDrugAnswer). By conducting experiments and statistical tests to compare the new drug’s effectiveness against the current standard and demonstrating a significant improvement.\n\n\n\nG.1.8 Alternative Hypotheses, Main Ideas\n\n\nG.1.9 p-values: What they are and how to interpret them\n\nSolution G.18 (PValueIntroductionAnswer). We can reject the null hypothesis. We can make a decision.\n\n\nSolution G.19 (PValueRangeAnswer). It can only be between 0 and 1.\n\n\nSolution G.20 (PValueRangeAnswer). It can only be between 0 and 1.\n\n\nSolution G.21 (TypicalPValueAnswer). The chance that we wrongly reject the null hypothesis.\n\n\nSolution G.22 (FalsePositiveAnswer). If we have a false-positive, we succeed in rejecting the null hypothesis. But in fact/reality, this is false -&gt; False positive.\n\n\n\nG.1.10 How to calculate p-values\n\nSolution G.23 (CalculatePValueAnswer). Probability of specific result, probability of outcome with the same probability, and probability of events with smaller probability.\n\n\nSolution G.24 (SDCalculationAnswer). 7 is the SD.\n\n\nSolution G.25 (SidedPValueAnswer). If we are not interested in the direction of the change, we use the two-sided. If we want to know about the direction, the one-sided.\n\n\nSolution G.26 (CoinTestAnswer). TBD\n\n\nSolution G.27 (BorderPValueAnswer). TBD\n\n\nSolution G.28 (OneSidedPValueCautionAnswer). If you look in the wrong direction, there is no change.\n\n\nSolution G.29 (BinomialDistributionAnswer). TBD\n\n\n\nG.1.11 p-hacking: What it is and how to avoid it\n\nSolution G.30 (PHackingWaysAnswer). \n\nPerforming repeats until you find one result with a small p-value -&gt; false positive result.\nIncreasing the sample size within one experiment when it is close to the threshold.\n\n\n\nSolution G.31 (AvoidPHackingAnswer). Specify the number of repeats and the sample sizes at the beginning.\n\n\nSolution G.32 (MultipleTestingProblemAnswer). TBD\n\n\n\nG.1.12 Covariance\n\nSolution G.33 (CovarianceDefinitionAnswer). Formula\n\n\nSolution G.34 (CovarianceMeaningAnswer). Large values in the first variable result in large values in the second variable.\n\n\nSolution G.35 (CovarianceVarianceRelationshipAnswer). Formula\n\n\nSolution G.36 (HighCovarianceAnswer). No, size doesn’t matter.\n\n\nSolution G.37 (ZeroCovarianceAnswer). No relationship\n\n\nSolution G.38 (NegativeCovarianceAnswer). Yes\n\n\nSolution G.39 (NegativeVarianceAnswer). No\n\n\n\nG.1.13 Pearson’s Correlation\n\nSolution G.40 (CorrelationValueAnswer). Recalculate\n\n\nSolution G.41 (CorrelationRangeAnswer). From -1 to 1\n\n\nSolution G.42 (CorrelationFormulaAnswer). Formula\n\n\n\nG.1.14 Boxplots\n\nSolution G.43 (UnderstandingStatisticalPower). It is the probability of correctly rejecting the null hypothesis.\n\n\nSolution G.44 (DistributionEffectOnPower). Power analysis is not applicable.\n\n\nSolution G.45 (IncreasingPower). By taking more samples.\n\n\nSolution G.46 (PreventingPHacking). TBD\n\n\nSolution G.47 (SampleSizeAndPower). The power will be low.\n\n\n\nG.1.15 Power Analysis\n\nSolution G.48 (MainFactorsAffectingPower). The overlap (distance of the two means) and sample sizes.\n\n\nSolution G.49 (PowerAnalysisOutcome). The sample size needed.\n\n\nSolution G.50 (RisksInExperiments). Few experiments lead to very low power, and many experiments might result in p-hacking.\n\n\nSolution G.51 (StepsToPerformPowerAnalysis). \n\nSelect power\nSelect threshold for significance (alpha)\nEstimate the overlap (done by the effect size)\n\n\n\n\nG.1.16 The Central Limit Theorem\n\nSolution G.52 (CentralLimitTheoremAnswer). TBD\n\n\n\nG.1.17 Boxplots\n\nSolution G.53 (MedianAnswer). The median.\n\n\nSolution G.54 (BoxContentAnswer). 50% of the data.\n\n\n\nG.1.18 R-squared\n\nSolution G.55 (RSquaredFormulaAnswer). TBD\n\n\nSolution G.56 (NegativeRSquaredAnswer). If you fit a line, no, but there are cases where it could be negative. However, these are usually considered useless.\n\n\nSolution G.57 (RSquaredCalculationAnswer). TBD\n\n\nG.1.18.1 The main ideas of fitting a line to data (The main ideas of least squares and linear regression.)\n\nSolution G.58 (LeastSquaresAnswer). It is the calculation of the smallest sum of residuals when you fit a model to data.\n\n\n\n\nG.1.19 Linear Regression\n\n\nG.1.20 Multiple Regression\n\n\nG.1.21 A Gentle Introduction to Machine Learning\n\nSolution G.59 (RegressionVsClassificationAnswer). Regression involves predicting continuous values (e.g., temperature, size), while classification involves predicting discrete values (e.g., categories like cat, dog).\n\n\n\nG.1.22 Maximum Likelihood\n\nSolution G.60 (LikelihoodConceptAnswer). The distribution that fits the data best.\n\n\n\nG.1.23 Probability is not Likelihood\n\nSolution G.61 (ProbabilityVsLikelihoodAnswer). Likelihood: Finding the curve that best fits the data. Probability: Calculating the probability of an event given a specific curve.\n\n\n\nG.1.24 Cross Validation\n\nSolution G.62 (TrainVsTestDataAnswer). Training data is used to fit the model, while testing data is used to evaluate how well the model fits.\n\n\nSolution G.63 (SingleValidationIssueAnswer). The performance might not be representative because the data may not be equally distributed between training and testing sets.\n\n\nSolution G.64 (FoldDefinitionAnswer). TBD\n\n\nSolution G.65 (LeaveOneOutValidationAnswer). Only one data point is used as the test set, and the rest are used as the training set.\n\n\n\nG.1.25 The Confusion Matrix\n\nSolution G.66 (ConfusionMatrixAnswer). TBD\n\n\n\nG.1.26 Sensitivity and Specificity\n\nSolution G.67 (SensitivitySpecificityAnswer1). TBD\n\n\nSolution G.68 (SensitivitySpecificityAnswer2). TBD\n\n\n\nG.1.27 Bias and Variance\n\nSolution G.69 (BiasAndVarianceAnswer). TBD\n\n\n\nG.1.28 Mutual Information\n\nSolution G.70 (MutualInformationExampleAnswer). TBD\n\n\n\nG.1.29 Principal Component Analysis (PCA)\n\nSolution G.71 (WhatIsPCAAnswer). A dimension reduction technique that helps discover important variables.\n\n\nSolution G.72 (screePlotAnswer). It shows how much variation is defined by the data.\n\n\nSolution G.73 (LeastSquaresInPCAAnswer). No, in the first step it tries to maximize distances.\n\n\nSolution G.74 (PCAStepsAnswer). \n\nCalculate mean\nShift the data to the center of the coordinate system\nFit a line by maximizing the distances\nCalculate the sum of squared distances\nCalculate the slope\nRotate\n\n\n\nSolution G.75 (EigenvaluePC1Answer). Formula (to be specified).\n\n\nSolution G.76 (DifferencesBetweenPointsAnswer). No, because the first difference is measured on the PC1 scale and it is more important.\n\n\nSolution G.77 (ScalingInPCAAnswer). Scaling by dividing by the standard deviation (SD).\n\n\nSolution G.78 (DetermineNumberOfComponentsAnswer). TBD\n\n\nSolution G.79 (LimitingNumberOfComponentsAnswer). \n\nThe dimension of the problem\nNumber of samples\n\n\n\n\nG.1.30 t-SNE\n\nSolution G.80 (WhyUseTSNEAnswer). For dimension reduction and picking out the relevant clusters.\n\n\nSolution G.81 (MainIdeaOfTSNEAnswer). To reduce the dimensions of the data by reconstructing the relationships in a lower-dimensional space.\n\n\nSolution G.82 (BasicConceptOfTSNEAnswer). \n\nFirst, randomly arrange the points in a lower dimension\nDecide whether to move points left or right, depending on distances in the original dimension\nFinally, arrange points in the lower dimension similarly to the original dimension\n\n\n\nSolution G.83 (TSNEStepsAnswer). \n\nProject data to get random points\nSet up a matrix of distances\nCalculate the inner variances of the clusters and the Gaussian distribution\nDo the same with the projected points\nMove projected points so the second matrix gets more similar to the first matrix\n\n\n\n\nG.1.31 K-means clustering\n\nSolution G.84 (HowKMeansWorksAnswer). \n\nSelect the number of clusters\nRandomly select distinct data points as initial cluster centers\nMeasure the distance between each point and the cluster centers\nAssign each point to the nearest cluster\nRepeat the process\n\n\n\nSolution G.85 (QualityOfClustersAnswer). Calculate the within-cluster variation.\n\n\nSolution G.86 (IncreasingKAnswer). If k is too high, each point would be its own cluster. If k is too low, you cannot see the structures.\n\n\n\nG.1.32 DBSCAN\n\nSolution G.87 (CorePointInDBSCANAnswer). A point that is close to at least k other points.\n\n\nSolution G.88 (AddingVsExtendingAnswer). Adding means we add a point and then stop. Extending means we add a point and then look for other neighbors from that point.\n\n\nSolution G.89 (OutliersInDBSCANAnswer). Points that are not core points and do not belong to existing clusters.\n\n\n\nG.1.33 K-nearest neighbors\n\nSolution G.90 (AdvantagesAndDisadvantagesOfKAnswer). \n\nk = 1: Noise can disturb the process because of possibly incorrect measurements of points.\nk = 100: The majority can be wrong for some groups. It is smoother, but there is less chance to discover the structure of the data.\n\n\n\n\nG.1.34 Naive Bayes\n\nSolution G.91 (NaiveBayesFormulaAnswer). TBD\n\n\nSolution G.92 (CalculateProbabilitiesAnswer). TBD\n\n\n\nG.1.35 Gaussian Naive Bayes\n\nSolution G.93 (UnderflowProblemAnswer). Small values multiplied together can become smaller than the limits of computer memory, resulting in zero. Using logarithms (e.g., log(1/2) -&gt; -1, log(1/4) -&gt; -2) helps prevent underflow.\n\n\n\nG.1.36 Trees\n\nSolution G.94 (Tree Usage). Classication, Regression, Clustering\n\n\nSolution G.95 (Tree Usage). TBD\n\n\nSolution G.96 (Tree Feature Importance). The most important feature.\n\n\nSolution G.97 (Regression Tree Limitations). High dimensions\n\n\nSolution G.98 (Regression Tree Score). SSR + alpha * T\n\n\nSolution G.99 (Regression Tree Alpha Value Small). The tree is more complex.\n\n\nSolution G.100 (Regression Tree Increase Alpha Value). We get smaller trees\n\n\nSolution G.101 (Regression Tree Pruning). Decreases the complexity of the tree to enhance performance and reduce overfitting",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Solutions to Selected Exercises</span>"
    ]
  },
  {
    "objectID": "a_99_solutions.html#machine-learning-and-artificial-intelligence",
    "href": "a_99_solutions.html#machine-learning-and-artificial-intelligence",
    "title": "Appendix G — Solutions to Selected Exercises",
    "section": "G.2 Machine Learning and Artificial Intelligence",
    "text": "G.2 Machine Learning and Artificial Intelligence\n\nG.2.1 Backpropagation\n\nSolution G.102 (ChainRuleAndGradientDescentAnswer). Combination of the chain rule and gradient descent.\n\n\nSolution G.103 (BackpropagationNamingAnswer). Because you start at the end and go backwards.\n\n\n\nG.2.2 Gradient Descent\n\nSolution G.104 (GradDescStepSize). learning rate x slope\n\n\nSolution G.105 (GradDescIntercept). Old intercept - step size\n\n\nSolution G.106 (GradDescIntercept). When the step size is small or after a certain number of steps\n\n\n\nG.2.3 ReLU\n\nSolution G.107 (Graph ReLU). Graph of ReLU function: f(x) = max(0, x)\n\n\n\nG.2.4 CNNs\n\nSolution G.108 (CNNImageRecognitionAnswer). \n\ntoo many features for input layer -&gt; high memory consumption\nalways shift in data\nit learns local informations and local correlations\n\n\n\nSolution G.109 (CNNFiltersInitializationAnswer). The filter values in CNNs are randomly initialized and then trained and optimized through the process of backpropagation.\n\n\nSolution G.110 (CNNFilterInitializationAnswer). The filter values in CNNs are initially set by random initialization. These filters undergo training via backpropagation, where gradients are computed and used to adjust the filter values to optimize performance.\n\n\nSolution G.111 (GenNNStockPredictionAnswer). A limitation of using classical neural networks for stock market prediction is their reliance on fixed inputs. Stock market data is dynamic and requires models that can adapt to changing conditions over time.\n\n\n\nG.2.5 RNN\n\nSolution G.112 (RNNUnrollingAnswer). In the unrolling process of RNNs, the network is copied and the output from the inner loop is fed into the second layer of the copied network.\n\n\nSolution G.113 (RNNReliabilityAnswer). RNNs sometimes fail to work reliably due to the vanishing gradient problem (where gradients are less than 1) and the exploding gradient problem (where gradients are greater than 1). Additionally, reliability issues arise because the network and the weights are copied during the unrolling process.\n\n\n\nG.2.6 LSTM\n\nSolution G.114 (LSTMSigmoidTanhAnswer). The sigmoid activation function outputs values between 0 and 1, making it suitable for probability determination, whereas the tanh activation function outputs values between -1 and 1.\n\n\nSolution G.115 (LSTMSigmoidTanhAnswer). State how much of the long term memory should be used.\n\n\nSolution G.116 (LSTMGatesAnswer). An LSTM network has three types of gates: the forget gate, the input gate, and the output gate. The forget gate decides what information to discard from the cell state, the input gate updates the cell state with new information, and the output gate determines what part of the cell state should be output.\n\n\nSolution G.117 (LSTMLongTermInfoAnswer). Long-term information is used in the output gate of an LSTM network.\n\n\nSolution G.118 (LSTMUpdateGatesAnswer). In the input and forget gates.\n\n\n\nG.2.7 Pytorch/Lightning\n\nSolution G.119 (PyTorchRequiresGradAnswer). In PyTorch, requires_grad indicates whether a tensor should be trained. If set to False, the tensor will not be trained.\n\n\n\nG.2.8 Embeddings\n\nSolution G.120 (NN STrings). No, they process numerical values.\n\n\nSolution G.121 (Embedding Definition). Representation of a word as a vector.\n\n\nSolution G.122 (Embedding Dimensions). We can model similarities.\n\n\n\nG.2.9 Sequence to Sequence Models\n\nSolution G.123 (LSTM). Because they are able to consider “far away” information.\n\n\nSolution G.124 (Teacher Forcing). We need to force the correct words for the training.\n\n\nSolution G.125 (Attention). Attention scores compute similarities for one input to the others.\n\n\n\nG.2.10 Transformers\n\nSolution G.126 (ChatGPT). Decoder only.\n\n\nSolution G.127 (Translation). Encoder-Decoder structure.\n\n\nSolution G.128 (Difference Encoder-Decoder and Decoder Only.). \n\nEncoder-Decoder: self-attention.\nDecoder only: masked self-attention.\n\n\n\nSolution G.129 (Weights). \n\na: Randomly\nb: Backpropagation\n\n\n\nSolution G.130 (Order of Words). Positional Encoding\n\n\nSolution G.131 (Relationship Between Words). Masked self-attention which looks at the previous tokens.\n\n\nSolution G.132 (Masked Self Attention). It works by investigating how similar each word is to itself and all of the proceeding words in the sentence.\n\n\nSolution G.133 (Softmax). Transformation to values between 0 and 1.\n\n\nSolution G.134 (Softmax Output). We create two new numbers: Values – like K and Q with different weights. We scale these values by the percentage. -&gt; we get the scaled V´s\n\n\nSolution G.135 (V´s). Lastly, we sum these values together, which combine separate encodings for both words relative to their similarities to “is”, are the masked-self-attention values for “is”.\n\n\nSolution G.136 (Residual Connections). They are bypasses, which combine the position encoded values with masked-self-attention values.\n\n\nSolution G.137 (Generate Known Word in Sequence). \n\nTraining\nBecause it is a Decoder-Only transformer used for prediction and the calculations that you need.\n\n\n\n\nSolution G.138 (Masked-Self-Attention Values and Bypass). We use a simple neural network with two inputs and five outputs for the vocabulary.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Solutions to Selected Exercises</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Abadi, Martin, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen,\nCraig Citro, Greg S. Corrado, et al. 2016. “TensorFlow: Large-Scale Machine Learning on Heterogeneous\nDistributed Systems.” arXiv e-Prints, March,\narXiv:1603.04467.\n\n\nAggarwal, Charu, ed. 2007. Data Streams – Models and\nAlgorithms. Springer-Verlag.\n\n\nBartz, Eva, Thomas Bartz-Beielstein, Martin Zaefferer, and Olaf\nMersmann, eds. 2022. Hyperparameter Tuning for\nMachine and Deep Learning with R - A Practical Guide.\nSpringer.\n\n\nBartz-Beielstein, Thomas. 2023. “PyTorch\nHyperparameter Tuning with SPOT: Comparison with Ray\nTuner and Default Hyperparameters on\nCIFAR10.” https://github.com/sequential-parameter-optimization/spotpython/blob/main/notebooks/14_spot_ray_hpt_torch_cifar10.ipynb.\n\n\n———. 2024a. “Evaluation and Performance Measurement.” In,\nedited by Eva Bartz and Thomas Bartz-Beielstein, 47–62. Singapore:\nSpringer Nature Singapore.\n\n\n———. 2024b. “Hyperparameter Tuning.” In, edited by Eva\nBartz and Thomas Bartz-Beielstein, 125–40. Singapore: Springer Nature\nSingapore.\n\n\n———. 2024c. “Introduction: From Batch to Online Machine\nLearning.” In Online Machine Learning: A Practical Guide with\nExamples in Python, edited by Eva Bartz and Thomas\nBartz-Beielstein, 1–11. Singapore: Springer Nature Singapore. https://doi.org/10.1007/978-981-99-7007-0_1.\n\n\nBartz-Beielstein, Thomas, Jürgen Branke, Jörn Mehnen, and Olaf Mersmann.\n2014. “Evolutionary Algorithms.” Wiley\nInterdisciplinary Reviews: Data Mining and Knowledge Discovery 4\n(3): 178–95.\n\n\nBartz-Beielstein, Thomas, and Lukas Hans. 2024. “Drift Detection\nand Handling.” In Online Machine Learning: A Practical Guide\nwith Examples in Python, edited by Eva Bartz and Thomas\nBartz-Beielstein, 23–39. Singapore: Springer Nature Singapore. https://doi.org/10.1007/978-981-99-7007-0_3.\n\n\nBartz-Beielstein, Thomas, Christian Lasarczyk, and Mike Preuss. 2005.\n“Sequential Parameter Optimization.” In\nProceedings 2005 Congress on Evolutionary\nComputation (CEC’05), Edinburgh, Scotland, edited by B McKay\net al., 773–80. Piscataway NJ: IEEE Press.\n\n\nBartz-Beielstein, Thomas, and Martin Zaefferer. 2022.\n“Hyperparameter Tuning Approaches.” In Hyperparameter Tuning for Machine and Deep Learning with\nR - A Practical Guide, edited by Eva Bartz, Thomas\nBartz-Beielstein, Martin Zaefferer, and Olaf Mersmann, 67–114. Springer.\n\n\nBifet, Albert. 2010. Adaptive Stream Mining: Pattern Learning and\nMining from Evolving Data Streams. Vol. 207. Frontiers in\nArtificial Intelligence and Applications. IOS Press.\n\n\nBifet, Albert, and Ricard Gavaldà. 2007. “Learning from\nTime-Changing Data with Adaptive Windowing.” In Proceedings\nof the 2007 SIAM International Conference on Data Mining (SDM),\n443–48.\n\n\n———. 2009. “Adaptive Learning from Evolving Data Streams.”\nIn Proceedings of the 8th International Symposium on Intelligent\nData Analysis: Advances in Intelligent Data Analysis VIII, 249–60.\nIDA ’09. Berlin, Heidelberg: Springer-Verlag.\n\n\nBifet, Albert, Geoff Holmes, Richard Kirkby, and Bernhard Pfahringer.\n2010a. “MOA: Massive Online\nAnalysis.” Journal of Machine Learning Research 99:\n1601–4.\n\n\n———. 2010b. “MOA: Massive Online Analysis.” Journal of\nMachine Learning Research 11: 1601–4.\n\n\nChollet, Francoise, and J. J. Allaire. 2018. Deep Learning with\nPython. Manning.\n\n\nDevlin, Jacob, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018.\n“BERT: Pre-training of Deep Bidirectional\nTransformers for Language Understanding.” arXiv\ne-Prints, October, arXiv:1810.04805.\n\n\nDomingos, Pedro M., and Geoff Hulten. 2000. “Mining High-Speed\nData Streams.” In Proceedings of the Sixth ACM\nSIGKDD International Conference on Knowledge Discovery and\nData Mining, Boston, MA, USA, August 20-23, 2000, edited by Raghu\nRamakrishnan, Salvatore J. Stolfo, Roberto J. Bayardo, and Ismail Parsa,\n71–80. ACM.\n\n\nDosovitskiy, Alexey, Lucas Beyer, Alexander Kolesnikov, Dirk\nWeissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, et al.\n2020. “An Image is Worth 16x16 Words:\nTransformers for Image Recognition at Scale.” arXiv\ne-Prints, October, arXiv:2010.11929.\n\n\nDredze, Mark, Tim Oates, and Christine Piatko. 2010. “We’re Not in\nKansas Anymore: Detecting Domain Changes in Streams.” In\nProceedings of the 2010 Conference on Empirical Methods in Natural\nLanguage Processing, 585–95.\n\n\nForrester, Alexander, András Sóbester, and Andy Keane. 2008. Engineering Design via Surrogate Modelling.\nWiley.\n\n\nFriedman, Jerome H. 1991. “Multivariate Adaptive Regression\nSplines.” The Annals of Statistics 19 (1): 1–67.\n\n\nGaber, Mohamed Medhat, Arkady Zaslavsky, and Shonali Krishnaswamy. 2005.\n“Mining Data Streams: A Review.” SIGMOD\nRec. 34: 18–26.\n\n\nGama, João, Pedro Medas, Gladys Castillo, and Pedro Rodrigues. 2004.\n“Learning with Drift Detection.” In Advances in\nArtificial Intelligence – SBIA 2004, edited by Ana L. C. Bazzan and\nSofiane Labidi, 286–95. Berlin, Heidelberg: Springer Berlin Heidelberg.\n\n\nGama, João, Raquel Sebastião, and Pedro Pereira Rodrigues. 2013.\n“On Evaluating Stream Learning Algorithms.” Machine\nLearning 90 (3): 317–46.\n\n\nGramacy, Robert B. 2020. Surrogates. CRC press.\n\n\nHoeglinger, Stefan, and Russel Pears. 2007. “Use of Hoeffding\nTrees in Concept Based Data Stream Mining.” 2007 Third\nInternational Conference on Information and Automation for\nSustainability, 57–62.\n\n\nIkonomovska, Elena. 2012. “Algorithms for Learning Regression\nTrees and Ensembles on Evolving Data Streams.” PhD thesis, Jozef\nStefan International Postgraduate School.\n\n\nIkonomovska, Elena, João Gama, and Sašo Džeroski. 2011. “Learning\nModel Trees from Evolving Data Streams.” Data Mining and\nKnowledge Discovery 23 (1): 128–68.\n\n\nJain, Sarthak, and Byron C. Wallace. 2019. “Attention is not Explanation.” arXiv\ne-Prints, February, arXiv:1902.10186.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani.\n2014. An Introduction to Statistical Learning\nwith Applications in R. 7th ed. Springer.\n\n\nKeller-McNulty, Sallie, ed. 2004. Statistical Analysis of Massive\nData Streams: Proceedings of a Workshop. Washington,\nDC: Committee on Applied; Theoretical Statistics, National Research\nCouncil; National Academies Press.\n\n\nLewis, R M, V Torczon, and M W Trosset. 2000. “Direct search methods: Then and now.”\nJournal of Computational and Applied Mathematics 124 (1–2):\n191–207.\n\n\nLi, Lisha, Kevin Jamieson, Giulia DeSalvo, Afshin Rostamizadeh, and\nAmeet Talwalkar. 2016. “Hyperband: A Novel\nBandit-Based Approach to Hyperparameter Optimization.”\narXiv e-Prints, March, arXiv:1603.06560.\n\n\nLippe, Phillip. 2022. “UvA Deep Learning\nTutorials.”\n\n\nLiu, Liyuan, Haoming Jiang, Pengcheng He, Weizhu Chen, Xiaodong Liu,\nJianfeng Gao, and Jiawei Han. 2019. “On the\nVariance of the Adaptive Learning Rate and Beyond.”\narXiv e-Prints, August, arXiv:1908.03265.\n\n\nManapragada, Chaitanya, Geoffrey I. Webb, and Mahsa Salehi. 2018.\n“Extremely Fast Decision Tree.” In KDD’ 2018 -\nProceedings of the 24th ACM SIGKDD International Conference on Knowledge\nDiscovery and Data Mining, edited by Chih-Jen Lin and Hui Xiong,\n1953–62. United States of America: Association for Computing Machinery\n(ACM). https://doi.org/10.1145/3219819.3220005.\n\n\nMasud, Mohammad, Jing Gao, Latifur Khan, Jiawei Han, and Bhavani M\nThuraisingham. 2011. “Classification and Novel Class Detection in\nConcept-Drifting Data Streams Under Time Constraints.” IEEE\nTransactions on Knowledge and Data Engineering 23 (6): 859–74.\n\n\nMeignan, David, Sigrid Knust, Jean-Marc Frayet, Gilles Pesant, and\nNicolas Gaud. 2015. “A Review and Taxonomy of\nInteractive Optimization Methods in Operations Research.”\nACM Transactions on Interactive Intelligent Systems, September.\n\n\nMontiel, Jacob, Max Halford, Saulo Martiello Mastelini, Geoffrey\nBolmier, Raphael Sourty, Robin Vaysse, Adil Zouitine, et al. 2021.\n“River: Machine Learning for Streaming Data in Python.”\n\n\nMourtada, Jaouad, Stephane Gaiffas, and Erwan Scornet. 2019.\n“AMF: Aggregated Mondrian Forests for Online\nLearning.” arXiv e-Prints, June,\narXiv:1906.10529. https://doi.org/10.48550/arXiv.1906.10529.\n\n\nPedregosa, F., G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O.\nGrisel, M. Blondel, et al. 2011. “Scikit-Learn: Machine Learning\nin Python.” Journal of Machine Learning\nResearch 12: 2825–30.\n\n\nPutatunda, Sayan. 2021. Practical Machine Learning for Streaming\nData with Python. Springer.\n\n\nSantner, T J, B J Williams, and W I Notz. 2003. The Design and Analysis of Computer\nExperiments. Berlin, Heidelberg, New York: Springer.\n\n\nStreet, W. Nick, and YongSeog Kim. 2001. “A Streaming Ensemble\nAlgorithm (SEA) for Large-Scale Classification.” In\nProceedings of the Seventh ACM SIGKDD International Conference on\nKnowledge Discovery and Data Mining, 377–82. KDD ’01. New York, NY,\nUSA: Association for Computing Machinery.\n\n\nTay, Yi, Mostafa Dehghani, Dara Bahri, and Donald Metzler. 2020.\n“Efficient Transformers: A Survey.” arXiv\ne-Prints, September, arXiv:2009.06732.\n\n\nVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion\nJones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017.\n“Attention Is All You Need.” arXiv\ne-Prints, June, 1–15.\n\n\nWiegreffe, Sarah, and Yuval Pinter. 2019. “Attention is not not Explanation.”\narXiv e-Prints, August, arXiv:1908.04626.",
    "crumbs": [
      "Appendices",
      "References"
    ]
  }
]