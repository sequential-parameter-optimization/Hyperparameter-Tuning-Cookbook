[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hyperparameter Tuning Cookbook",
    "section": "",
    "text": "Preface",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#book-structure",
    "href": "index.html#book-structure",
    "title": "Hyperparameter Tuning Cookbook",
    "section": "Book Structure",
    "text": "Book Structure\nThis document is structured in three parts. The first part presents an introduction to optimization. The second part describes numerical methods, and the third part presents hyperparameter tuning.\n\n\n\n\n\n\nHyperparameter Tuning Reference\n\n\n\n\nThe open access book Bartz et al. (2022) provides a comprehensive overview of hyperparameter tuning. It can be downloaded from https://link.springer.com/book/10.1007/978-981-19-5170-1.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe .ipynb notebook (Bartz-Beielstein 2023) is updated regularly and reflects updates and changes in the spotpython package. It can be downloaded from https://github.com/sequential-parameter-optimization/spotpython/blob/main/notebooks/14_spot_ray_hpt_torch_cifar10.ipynb.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#software-used-in-this-book",
    "href": "index.html#software-used-in-this-book",
    "title": "Hyperparameter Tuning Cookbook",
    "section": "Software Used in this Book",
    "text": "Software Used in this Book\nscikit-learn is a Python module for machine learning built on top of SciPy and is distributed under the 3-Clause BSD license. The project was started in 2007 by David Cournapeau as a Google Summer of Code project, and since then many volunteers have contributed.\nPyTorch is an optimized tensor library for deep learning using GPUs and CPUs. Lightning is a lightweight PyTorch wrapper for high-performance AI research. It allows you to decouple the research from the engineering.\nRiver is a Python library for online machine learning. It is designed to be used in real-world environments, where not all data is available at once, but streaming in.\nspotpython (“Sequential Parameter Optimization Toolbox in Python”) is the Python version of the well-known hyperparameter tuner SPOT, which has been developed in the R programming environment for statistical analysis for over a decade. The related open-access book is available here: Hyperparameter Tuning for Machine and Deep Learning with R—A Practical Guide.\nspotriver provides an interface between spotpython and River.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#citation",
    "href": "index.html#citation",
    "title": "Hyperparameter Tuning Cookbook",
    "section": "Citation",
    "text": "Citation\nIf this document has been useful to you and you wish to cite it in a scientific publication, please refer to the following paper, which can be found on arXiv: https://arxiv.org/abs/2307.10262.\n@ARTICLE{bart23iArXiv,\n      author = {{Bartz-Beielstein}, Thomas},\n      title = \"{Hyperparameter Tuning Cookbook:\n          A guide for scikit-learn, PyTorch, river, and spotpython}\",\n     journal = {arXiv e-prints},\n    keywords = {Computer Science - Machine Learning,\n      Computer Science - Artificial Intelligence, 90C26, I.2.6, G.1.6},\n         year = 2023,\n        month = jul,\n          eid = {arXiv:2307.10262},\n        pages = {arXiv:2307.10262},\n          doi = {10.48550/arXiv.2307.10262},\narchivePrefix = {arXiv},\n       eprint = {2307.10262},\n primaryClass = {cs.LG},\n       adsurl = {https://ui.adsabs.harvard.edu/abs/2023arXiv230710262B},\n      adsnote = {Provided by the SAO/NASA Astrophysics Data System}\n}\n\n\n\n\n\n\nBartz, Eva, Thomas Bartz-Beielstein, Martin Zaefferer, and Olaf Mersmann, eds. 2022. Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide. Springer.\n\n\nBartz-Beielstein, Thomas. 2023. “PyTorch Hyperparameter Tuning with SPOT: Comparison with Ray Tuner and Default Hyperparameters on CIFAR10.” https://github.com/sequential-parameter-optimization/spotpython/blob/main/notebooks/14_spot_ray_hpt_torch_cifar10.ipynb.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "002_awwe.html",
    "href": "002_awwe.html",
    "title": "1  Aircraft Wing Weight Example",
    "section": "",
    "text": "1.1 AWWE Equation\n\\[ W = 0.036 S_W^{0.758} \\times W_{fw}^{0.0035} \\left( \\frac{A}{\\cos^2 \\Lambda} \\right)^{0.6} \\times  q^{0.006}  \\times \\lambda^{0.04} \\] \\[ \\times \\left( \\frac{100 R_{tc}}{\\cos \\Lambda} \\right)^{-0.3} \\times (N_z W_{dg})^{0.49}\\]",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#awwe-equation",
    "href": "002_awwe.html#awwe-equation",
    "title": "1  Aircraft Wing Weight Example",
    "section": "",
    "text": "Example from Forrester, Sóbester, and Keane (2008)\nUnderstand the weight of an unpainted light aircraft wing as a function of nine design and operational parameters:",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#awwe-parameters-and-equations-part-1",
    "href": "002_awwe.html#awwe-parameters-and-equations-part-1",
    "title": "1  Aircraft Wing Weight Example",
    "section": "1.2 AWWE Parameters and Equations (Part 1)",
    "text": "1.2 AWWE Parameters and Equations (Part 1)\n\n\n\nTable 1.1: Aircraft Wing Weight Parameters\n\n\n\n\n\n\n\n\n\n\n\n\nSymbol\nParameter\nBaseline\nMinimum\nMaximum\n\n\n\n\n\\(S_W\\)\nWing area (\\(ft^2\\))\n174\n150\n200\n\n\n\\(W_{fw}\\)\nWeight of fuel in wing (lb)\n252\n220\n300\n\n\n\\(A\\)\nAspect ratio\n7.52\n6\n10\n\n\n\\(\\Lambda\\)\nQuarter-chord sweep (deg)\n0\n-10\n10\n\n\n\\(q\\)\nDynamic pressure at cruise (\\(lb/ft^2\\))\n34\n16\n45\n\n\n\\(\\lambda\\)\nTaper ratio\n0.672\n0.5\n1\n\n\n\\(R_{tc}\\)\nAerofoil thickness to chord ratio\n0.12\n0.08\n0.18\n\n\n\\(N_z\\)\nUltimate load factor\n3.8\n2.5\n6\n\n\n\\(W_{dg}\\)\nFlight design gross weight (lb)\n2000\n1700\n2500\n\n\n\\(W_p\\)\npaint weight (lb/ft^2)\n0.064\n0.025\n0.08\n\n\n\n\n\n\nThe study begins with a baseline Cessna C172 Skyhawk Aircraft as its reference point. It aims to investigate the impact of wing area and fuel weight on the overall weight of the aircraft. Two crucial parameters in this analysis are the aspect ratio (\\(A\\)), defined as the ratio of the wing’s length to the average chord (thickness of the airfoil), and the taper ratio (\\(\\lambda\\)), which represents the ratio of the maximum to the minimum thickness of the airfoil or the maximum to minimum chord.\nIt’s important to note that the equation used in this context is not a computer simulation but will be treated as one for the purpose of illustration. This approach involves employing a true mathematical equation, even if it’s considered unknown, as a useful tool for generating realistic settings to test the methodology. The functional form of this equation was derived by “calibrating” known physical relationships to curves obtained from existing aircraft data, as referenced in Raymer (2006). Essentially, it acts as a surrogate for actual measurements of aircraft weight.\nExamining the mathematical properties of the AWWE (Aircraft Weight With Wing Area and Fuel Weight Equation), it is evident that the response is highly nonlinear concerning its inputs. While it’s common to apply the logarithm to simplify equations with complex exponents, even when modeling the logarithm, which transforms powers into slope coefficients and products into sums, the response remains nonlinear due to the presence of trigonometric terms. Given the combination of nonlinearity and high input dimension, simple linear and quadratic response surface approximations are likely to be inadequate for this analysis.",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#goals-understanding-and-optimization",
    "href": "002_awwe.html#goals-understanding-and-optimization",
    "title": "1  Aircraft Wing Weight Example",
    "section": "1.3 Goals: Understanding and Optimization",
    "text": "1.3 Goals: Understanding and Optimization\nThe primary goals of this study revolve around understanding and optimization:\n\nUnderstanding: One of the straightforward objectives is to gain a deep understanding of the input-output relationships in this context. Given the global perspective implied by this setting, it becomes evident that a more sophisticated model is almost necessary. At this stage, let’s focus on this specific scenario to establish a clear understanding.\nOptimization: Another application of this analysis could be optimization. There may be an interest in minimizing the weight of the aircraft, but it’s likely that there will be constraints in place. For example, the presence of wings with a nonzero area is essential for the aircraft to be capable of flying. In situations involving (constrained) optimization, a global perspective and, consequently, the use of flexible modeling are vital.\n\nThe provided Python code serves as a genuine computer implementation that “solves” a mathematical model. It accepts arguments encoded in the unit cube, with defaults used to represent baseline settings, as detailed in the table labeled as Table 1.1. To map values from the interval \\([a, b]\\) to the interval \\([0, 1]\\), the following formula can be employed:\n\\[\ny = f(x) = \\frac{x - a}{b - a}.\n\\tag{1.1}\\] To reverse this mapping and obtain the original values, the formula \\[\ng(y) = a + (b - a) y\n\\tag{1.2}\\] can be used. The function wingwt() expects inputs from the unit cube, which are then transformed back to their original scales using Equation 1.2. The function is defined as follows:\n\ndef wingwt(Sw=0.48, Wfw=0.4, A=0.38, L=0.5, q=0.62, l=0.344,  Rtc=0.4, Nz=0.37, Wdg=0.38):\n    # put coded inputs back on natural scale\n    Sw = Sw * (200 - 150) + 150 \n    Wfw = Wfw * (300 - 220) + 220 \n    A = A * (10 - 6) + 6 \n    L = (L * (10 - (-10)) - 10) * np.pi/180\n    q = q * (45 - 16) + 16 \n    l = l * (1 - 0.5) + 0.5  \n    Rtc = Rtc * (0.18 - 0.08) + 0.08\n    Nz = Nz * (6 - 2.5) + 2.5\n    Wdg = Wdg*(2500 - 1700) + 1700\n    # calculation on natural scale\n    W = 0.036 * Sw**0.758 * Wfw**0.0035 * (A/np.cos(L)**2)**0.6 * q**0.006 \n    W = W * l**0.04 * (100*Rtc/np.cos(L))**(-0.3) * (Nz*Wdg)**(0.49)\n    return(W)",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#properties-of-the-python-solver",
    "href": "002_awwe.html#properties-of-the-python-solver",
    "title": "1  Aircraft Wing Weight Example",
    "section": "1.4 Properties of the Python “Solver”",
    "text": "1.4 Properties of the Python “Solver”\nThe compute time required by the “wingwt” solver is extremely short and can be considered trivial in terms of computational resources. The approximation error is exceptionally small, effectively approaching machine precision, which indicates the high accuracy of the solver’s results.\nTo simulate time-consuming evaluations, a deliberate delay is introduced by incorporating a sleep(3600) command, which effectively synthesizes a one-hour execution time for a particular evaluation.\nMoving on to the AWWE visualization, plotting in two dimensions is considerably simpler than dealing with nine dimensions. To aid in creating visual representations, the code provided below establishes a grid within the unit square to facilitate the generation of sliced visuals. This involves generating a “meshgrid” as outlined in the code.\n\nx = np.linspace(0, 1, 3)\ny = np.linspace(0, 1, 3)\nX, Y = np.meshgrid(x, y)\nzp = zip(np.ravel(X), np.ravel(Y))\nlist(zp)\n\n[(np.float64(0.0), np.float64(0.0)),\n (np.float64(0.5), np.float64(0.0)),\n (np.float64(1.0), np.float64(0.0)),\n (np.float64(0.0), np.float64(0.5)),\n (np.float64(0.5), np.float64(0.5)),\n (np.float64(1.0), np.float64(0.5)),\n (np.float64(0.0), np.float64(1.0)),\n (np.float64(0.5), np.float64(1.0)),\n (np.float64(1.0), np.float64(1.0))]\n\n\nThe coding used to transform inputs from natural units is largely a matter of taste, so long as it’s easy to undo for reporting back on original scales\n\n%matplotlib inline\n# plt.style.use('seaborn-white')\nx = np.linspace(0, 1, 100)\ny = np.linspace(0, 1, 100)\nX, Y = np.meshgrid(x, y)",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#plot-1-load-factor-n_z-and-aspect-ratio-a",
    "href": "002_awwe.html#plot-1-load-factor-n_z-and-aspect-ratio-a",
    "title": "1  Aircraft Wing Weight Example",
    "section": "1.5 Plot 1: Load Factor (\\(N_z\\)) and Aspect Ratio (\\(A\\))",
    "text": "1.5 Plot 1: Load Factor (\\(N_z\\)) and Aspect Ratio (\\(A\\))\nWe will vary \\(N_z\\) and \\(A\\), with other inputs fixed at their baseline values.\n\nz = wingwt(A = X, Nz = Y)\nfig = plt.figure(figsize=(7., 5.))\nplt.contourf(X, Y, z, 20, cmap='jet')\nplt.xlabel(\"A\")\nplt.ylabel(\"Nz\")\nplt.title(\"Load factor (Nz) vs. Aspect Ratio (A)\")\nplt.colorbar()\nplt.show()\n\n\n\n\n\n\n\n\nContour plots can be refined, e.g., by adding explicit contour lines as shown in the following figure.\n\ncontours = plt.contour(X, Y, z, 4, colors='black')\nplt.clabel(contours, inline=True, fontsize=8)\nplt.xlabel(\"A\")\nplt.ylabel(\"Nz\")\n\nplt.imshow(z, extent=[0, 1, 0, 1], origin='lower',\n           cmap='jet', alpha=0.9)\nplt.colorbar()\n\n\n\n\n\n\n\n\nThe interpretation of the AWWE plot can be summarized as follows:\n\nThe figure displays the weight response as a function of two variables, \\(N_z\\) and \\(A\\), using an image-contour plot.\nThe slight curvature observed in the contours suggests an interaction between these two variables.\nNotably, the range of outputs depicted in the figure, spanning from approximately 160 to 320, nearly encompasses the entire range of outputs observed from various input settings within the full 9-dimensional input space.\nThe plot indicates that aircraft wings tend to be heavier when the aspect ratios (\\(A\\)) are high.\nThis observation aligns with the idea that wings are designed to withstand and accommodate high gravitational forces (\\(g\\)-forces, large \\(N_z\\)), and there may be a compounding effect where larger values of \\(N_z\\) contribute to increased wing weight.\nIt’s plausible that this phenomenon is related to the design considerations of fighter jets, which cannot have the efficient and lightweight glider-like wings typically found in other types of aircraft.",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#plot-2-taper-ratio-and-fuel-weight",
    "href": "002_awwe.html#plot-2-taper-ratio-and-fuel-weight",
    "title": "1  Aircraft Wing Weight Example",
    "section": "1.6 Plot 2: Taper Ratio and Fuel Weight",
    "text": "1.6 Plot 2: Taper Ratio and Fuel Weight\n\nThe same experiment for two other inputs, e.g., taper ratio \\(\\lambda\\) and fuel weight \\(W_{fw}\\)\n\n\nz = wingwt(Wfw = X,  Nz = Y)\ncontours = plt.contour(X, Y, z, 4, colors='black')\nplt.clabel(contours, inline=True, fontsize=8)\nplt.xlabel(\"WfW\")\nplt.ylabel(\"l\")\n\nplt.imshow(z, extent=[0, 1, 0, 1], origin='lower',\n           cmap='jet', alpha=0.9)\nplt.colorbar();\n\n\n\n\n\n\n\n\n\nInterpretation of Taper Ratio (\\(l\\)) and Fuel Weight (\\(W_{fw}\\))\n\nApparently, neither input has much effect on wing weight:\n\nwith \\(\\lambda\\) having a marginally greater effect, covering less than 4 percent of the span of weights observed in the \\(A \\times N_z\\) plane\n\nThere’s no interaction evident in \\(\\lambda \\times W_{fw}\\)",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#the-big-picture-combining-all-variables",
    "href": "002_awwe.html#the-big-picture-combining-all-variables",
    "title": "1  Aircraft Wing Weight Example",
    "section": "1.7 The Big Picture: Combining all Variables",
    "text": "1.7 The Big Picture: Combining all Variables\n\npl = [\"Sw\", \"Wfw\", \"A\", \"L\", \"q\", \"l\",  \"Rtc\", \"Nz\", \"Wdg\"]\n\n\nZ = []\nZlab = []\nl = len(pl)\n# lc = math.comb(l,2)\nfor i in range(l):\n    for j in range(i+1, l):\n    # for j in range(l):\n        # print(pl[i], pl[j])\n        d = {pl[i]: X, pl[j]: Y}\n        Z.append(wingwt(**d))\n        Zlab.append([pl[i],pl[j]])\n\nNow we can generate all 36 combinations, e.g., our first example is combination p = 19.\n\np = 19\nZlab[p]\n\n['A', 'Nz']\n\n\nTo help interpret outputs from experiments such as this one—to level the playing field when comparing outputs from other pairs of inputs—code below sets up a color palette that can be re-used from one experiment to the next. We use the arguments vmin=180 and vmax =360 to implement comparibility\n\nplt.contourf(X, Y, Z[p], 20, cmap='jet', vmin=180, vmax=360)\nplt.xlabel(Zlab[p][0])\nplt.ylabel(Zlab[p][1])\nplt.colorbar()\n\n\n\n\n\n\n\n\n\nLet’s plot the second example, taper ratio \\(\\lambda\\) and fuel weight \\(W_{fw}\\)\nThis is combination 11:\n\n\np = 11\nZlab[p]\n\n['Wfw', 'l']\n\n\n\nplt.contourf(X, Y, Z[p], 20, cmap='jet', vmin=180, vmax=360)\nplt.xlabel(Zlab[p][0])\nplt.ylabel(Zlab[p][1])\nplt.colorbar()\n\n\n\n\n\n\n\n\n\nUsing a global colormap indicates that these variables have minor effects on the wing weight.\nImportant factors can be detected by visual inspection\nPlotting the Big Picture: we can plot all 36 combinations in one figure.\n\n\nfig = plt.figure(figsize=(20., 20.))\ngrid = ImageGrid(fig, 111,  # similar to subplot(111)\n                 nrows_ncols=(6,6),  # creates 2x2 grid of axes\n                 axes_pad=0.5,  # pad between axes in inch.\n                 share_all=True,\n                 label_mode=\"all\",\n                 ) \ni = 0\nfor ax, im in zip(grid, Z):\n    # Iterating over the grid returns the Axes.\n    ax.set_xlabel(Zlab[i][0])\n    ax.set_ylabel(Zlab[i][1])\n    # ax.set_title(Zlab[i][1] + \" vs. \" + Zlab[i][0])\n    ax.contourf(X, Y, im, 30, cmap = \"jet\",  vmin = 180, vmax = 360)\n    i = i + 1\n       \nplt.show()",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#awwe-landscape",
    "href": "002_awwe.html#awwe-landscape",
    "title": "1  Aircraft Wing Weight Example",
    "section": "1.8 AWWE Landscape",
    "text": "1.8 AWWE Landscape\n\nOur Observations\n\nThe load factor \\(N_z\\), which determines the magnitude of the maximum aerodynamic load on the wing, is very active and involved in interactions with other variables.\n\n\nClassic example: the interaction of \\(N_z\\) with the aspect ratio \\(A\\) indicates a heavy wing for high aspect ratios and large \\(g\\)-forces\nThis is the reaon why highly manoeuvrable fighter jets cannot have very efficient, glider wings)\n\n\nAspect ratio \\(A\\) and airfoil thickness to chord ratio \\(R_{tc}\\) have nonlinear interactions.\nMost important variables:\n\n\nUltimate load factor \\(N_z\\), wing area \\(S_w\\), and flight design gross weight\\(W_{dg}\\).\n\n\nLittle impact: dynamic pressure \\(q\\), taper ratio \\(l\\), and quarter-chord sweep \\(L\\).\n\nExpert Knowledge\n\nAircraft designers know that the overall weight of the aircraft and the wing area must be kept to a minimum\nthe latter usually dictated by constraints such as required stall speed, landing distance, turn rate, etc.",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#summary-of-the-first-experiments",
    "href": "002_awwe.html#summary-of-the-first-experiments",
    "title": "1  Aircraft Wing Weight Example",
    "section": "1.9 Summary of the First Experiments",
    "text": "1.9 Summary of the First Experiments\n\nFirst, we considered two pairs of inputs, out of 36 total pairs\nThen, the “Big Picture”:\n\nFor each pair we evaluated wingwt 10,000 times\n\nDoing the same for all pairs would require 360K evaluations:\n\nnot a reasonable number with a real computer simulation that takes any non-trivial amount of time to evaluate\nOnly 1s per evaluation: \\(&gt;100\\) hours\n\nMany solvers take minutes/hours/days to execute a single run\nAnd: three-way interactions?\nConsequence: a different strategy is needed",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#exercise",
    "href": "002_awwe.html#exercise",
    "title": "1  Aircraft Wing Weight Example",
    "section": "1.10 Exercise",
    "text": "1.10 Exercise\n\n1.10.1 Adding Paint Weight\n\nPaint weight is not considered.\nAdd Paint Weight \\(W_p\\) to formula (the updated formula is shown below) and update the functions and plots in the notebook.\n\n\\[ W = 0.036S_W^{0.758} \\times W_{fw}^{0.0035} \\times \\left( \\frac{A}{\\cos^2 \\Lambda} \\right)^{0.6} \\times q^{0.006} \\times \\lambda^{0.04} \\] \\[ \\times \\left( \\frac{100 R_{tc}}{\\cos \\Lambda} \\right)^{-0.3} \\times (N_z W_{dg})^{0.49} + S_w W_p\\]",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "002_awwe.html#jupyter-notebook",
    "href": "002_awwe.html#jupyter-notebook",
    "title": "1  Aircraft Wing Weight Example",
    "section": "1.11 Jupyter Notebook",
    "text": "1.11 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository\n\n\n\n\n\n\n\nForrester, Alexander, András Sóbester, and Andy Keane. 2008. Engineering Design via Surrogate Modelling. Wiley.\n\n\nRaymer, Daniel P. 2006. Aircraft Design: A Conceptual Approach. AIAA.",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Aircraft Wing Weight Example</span>"
    ]
  },
  {
    "objectID": "003_scipy_optimize_intro.html",
    "href": "003_scipy_optimize_intro.html",
    "title": "2  Introduction to scipy.optimize",
    "section": "",
    "text": "2.1 Derivative-free Optimization Algorithms\nSciPy provides algorithms for optimization, integration, interpolation, eigenvalue problems, algebraic equations, differential equations, statistics and many other classes of problems. SciPy is a collection of mathematical algorithms and convenience functions built on NumPy. It adds significant power to Python by providing the user with high-level commands and classes for manipulating and visualizing data.\nSciPy optimize provides functions for minimizing (or maximizing) objective functions, possibly subject to constraints. It includes solvers for nonlinear problems (with support for both local and global optimization algorithms), linear programing, constrained and nonlinear least-squares, root finding, and curve fitting.\nIn this notebook, we will learn how to use the scipy.optimize module to solve optimization problems. See: https://docs.scipy.org/doc/scipy/tutorial/optimize.html\nCommon functions and objects, shared across different SciPy optimize solvers, are shown in Table 2.1.\nWe will introduce unconstrained minimization of multivariate scalar functions in this chapter. The minimize function provides a common interface to unconstrained and constrained minimization algorithms for multivariate scalar functions in scipy.optimize. To demonstrate the minimization function, consider the problem of minimizing the Rosenbrock function of N variables:\n\\[\nf(J) = \\sum_{i=1}^{N-1} 100 (x_{i+1} - x_i^2)^2 + (1 - x_i)^2\n\\]\nThe minimum value of this function is 0, which is achieved when (x_i = 1).\nNote that the Rosenbrock function and its derivatives are included in scipy.optimize. The implementations shown in the following sections provide examples of how to define an objective function as well as its Jacobian and Hessian functions. Objective functions in scipy.optimize expect a numpy array as their first parameter, which is to be optimized and must return a float value. The exact calling signature must be f(x, *args), where x represents a numpy array, and args is a tuple of additional arguments supplied to the objective function.\nSection 2.1.1 and Section 2.1.2 present two approaches that do not need gradient information to find the minimum. They use function evaluations to find the minimum.",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to `scipy.optimize`</span>"
    ]
  },
  {
    "objectID": "003_scipy_optimize_intro.html#derivative-free-optimization-algorithms",
    "href": "003_scipy_optimize_intro.html#derivative-free-optimization-algorithms",
    "title": "2  Introduction to scipy.optimize",
    "section": "",
    "text": "2.1.1 Nelder-Mead Simplex Algorithm\nThe Nelder Mead is a simple local optimization algorithm. It requires only function evaluations and is a good choice for simple minimization problems. However, because it does not use any gradient evaluations, it may take longer to find the minimum. It can be devided into the following steps:\n\nInitialize the simplex\nEvaluate the function at each vertex of the simplex\nOrder the vertices by function value\nReflect the worst point through the centroid of the remaining points\nIf the reflected point is better than the second worst, replace the worst point with the reflected point\nIf the reflected point is worse than the worst point, try contracting the simplex\nIf the reflected point is better than the best point, try expanding the simplex\nIf none of the above steps improve the simplex, shrink the simplex towards the best point\nCheck for convergence\n\nmethod='Nelder-Mead': In the example below, the minimize routine is used with the Nelder-Mead simplex algorithm (selected through the method parameter):\n\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef rosen(x):\n    \"\"\"The Rosenbrock function\"\"\"\n    return sum(100.0 * (x[1:] - x[:-1]**2.0)**2.0 + (1 - x[:-1])**2.0)\n\nx0 = np.array([1.3, 0.7, 0.8, 1.9, 1.2])\nres = minimize(rosen, x0, method='nelder-mead',\n               options={'xatol': 1e-8, 'disp': True})\n\nprint(res.x)\n\nOptimization terminated successfully.\n         Current function value: 0.000000\n         Iterations: 339\n         Function evaluations: 571\n[1. 1. 1. 1. 1.]\n\n\nThe simplex algorithm is probably the simplest way to minimize a well-behaved function. It requires only function evaluations and is a good choice for simple minimization problems. However, because it does not use any gradient evaluations, it may take longer to find the minimum.\n\n\n2.1.2 Powell’s Method\nAnother optimization algorithm that needs only function calls to find the minimum is Powell’s method, which can be selected by setting the method parameter to 'powell' in the minimize function. This algorithm consists of a conjugate direction method. It performs sequential one-dimensional minimizations along each vector of the directions set, which is updated at each iteration of the main minimization loop. It can be described by the following steps:\n\nInitialization\nMinimization along each direction\nCreate conjugate direction\nLine search along the conjugate direction\nCheck for convergence\n\n\nExample 2.1 To demonstrate how to supply additional arguments to an objective function, let’s consider minimizing the Rosenbrock function with an additional scaling factor \\(a\\) and an offset \\(b\\):\n\\[\nf(J, a, b) = \\sum_{i=1}^{N-1} a (x_{i+1} - x_i^2)^2 + (1 - x_i)^2 + b\n\\]\nYou can achieve this using the minimize routine with the example parameters \\(a=0.5\\) and \\(b=1\\):\n\ndef rosen_with_args(x, a, b):\n    \"\"\"The Rosenbrock function with additional arguments\"\"\"\n    return sum(a * (x[1:] - x[:-1]**2.0)**2.0 + (1 - x[:-1])**2.0) + b\n\nx0 = np.array([1.3, 0.7, 0.8, 1.9, 1.2])\nres = minimize(rosen_with_args, x0, method='nelder-mead',\n               args=(0.5, 1.), options={'xatol': 1e-8, 'disp': True})\n\nprint(res.x)\n\nOptimization terminated successfully.\n         Current function value: 1.000000\n         Iterations: 319\n         Function evaluations: 525\n[1.         1.         1.         1.         0.99999999]\n\n\nAs an alternative to using the args parameter of minimize, you can wrap the objective function in a new function that accepts only x. This approach is also useful when it is necessary to pass additional parameters to the objective function as keyword arguments.\n\ndef rosen_with_args(x, a, *, b):  # b is a keyword-only argument\n    return sum(a * (x[1:] - x[:-1]**2.0)**2.0 + (1 - x[:-1])**2.0) + b\n\ndef wrapped_rosen_without_args(x):\n    return rosen_with_args(x, 0.5, b=1.)  # pass in `a` and `b`\n\nx0 = np.array([1.3, 0.7, 0.8, 1.9, 1.2])\nres = minimize(wrapped_rosen_without_args, x0, method='nelder-mead',\n               options={'xatol': 1e-8,})\n\nprint(res.x)\n\n[1.         1.         1.         1.         0.99999999]\n\n\nAnother alternative is to use functools.partial.\n\nfrom functools import partial\n\npartial_rosen = partial(rosen_with_args, a=0.5, b=1.)\nres = minimize(partial_rosen, x0, method='nelder-mead',\n               options={'xatol': 1e-8,})\n\nprint(res.x)\n\n[1.         1.         1.         1.         0.99999999]",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to `scipy.optimize`</span>"
    ]
  },
  {
    "objectID": "003_scipy_optimize_intro.html#gradient-based-optimization-algorithms",
    "href": "003_scipy_optimize_intro.html#gradient-based-optimization-algorithms",
    "title": "2  Introduction to scipy.optimize",
    "section": "2.2 Gradient-based Optimization Algorithms",
    "text": "2.2 Gradient-based Optimization Algorithms\n\n2.2.1 An Introductory Example: Broyden-Fletcher-Goldfarb-Shanno Algorithm (BFGS)\nThis section introduces an optimization algorithm that uses gradient information to find the minimum. The Broyden-Fletcher-Goldfarb-Shanno (BFGS) algorithm (selected by setting method='BFGS') is an optimization algorithm that aims to converge quickly to the solution. This algorithm uses the gradient of the objective function. If the gradient is not provided by the user, it is estimated using first-differences. The BFGS method typically requires fewer function calls compared to the simplex algorithm, even when the gradient needs to be estimated.\n\nExample 2.2 (BFGS) To demonstrate the BFGS algorithm, let’s use the Rosenbrock function again. The gradient of the Rosenbrock function is a vector described by the following mathematical expression:\n\\[\\begin{align}\n\\frac{\\partial f}{\\partial x_j} = \\sum_{i=1}^{N} 200(x_i - x_{i-1}^2)(\\delta_{i,j} - 2x_{i-1}\\delta_{i-1,j}) - 2(1 - x_{i-1})\\delta_{i-1,j} \\\\\n= 200(x_j - x_{j-1}^2) - 400x_j(x_{j+1} - x_j^2) - 2(1 - x_j)\n\\end{align}\\]\nThis expression is valid for interior derivatives, but special cases are:\n\\[\n\\frac{\\partial f}{\\partial x_0} = -400x_0(x_1 - x_0^2) - 2(1 - x_0)\n\\]\n\\[\n\\frac{\\partial f}{\\partial x_{N-1}} = 200(x_{N-1} - x_{N-2}^2)\n\\]\nHere’s a Python function that computes this gradient:\n\ndef rosen_der(x):\n    xm = x[1:-1]\n    xm_m1 = x[:-2]\n    xm_p1 = x[2:]\n    der = np.zeros_like(x)\n    der[1:-1] = 200*(xm-xm_m1**2) - 400*(xm_p1 - xm**2)*xm - 2*(1-xm)\n    der[0] = -400*x[0]*(x[1]-x[0]**2) - 2*(1-x[0])\n    der[-1] = 200*(x[-1]-x[-2]**2)\n    return der\n\nYou can specify this gradient information in the minimize function using the jac parameter as illustrated below:\n\nres = minimize(rosen, x0, method='BFGS', jac=rosen_der,\n               options={'disp': True})\n\nprint(res.x)\n\nOptimization terminated successfully.\n         Current function value: 0.000000\n         Iterations: 25\n         Function evaluations: 30\n         Gradient evaluations: 30\n[1.00000004 1.0000001  1.00000021 1.00000044 1.00000092]\n\n\n\n\n\n2.2.2 Background and Basics for Gradient-based Optimization\n\n\n2.2.3 Gradient\nThe gradient \\(\\nabla f(J)\\) for a scalar function \\(f(J)\\) with \\(n\\) different variables is defined by its partial derivatives:\n\\[\n\\nabla f(J) = \\left[ \\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2}, \\ldots, \\frac{\\partial f}{\\partial x_n} \\right]\n\\]\n\n\n2.2.4 Jacobian Matrix\nThe Jacobian matrix \\(J(J)\\) for a vector-valued function \\(F(J) = [f_1(J), f_2(J), \\ldots, f_m(J)]\\) is defined as:\n\\(J(J) = \\begin{bmatrix} \\frac{\\partial f_1}{\\partial x_1} & \\frac{\\partial f_1}{\\partial x_2} & \\ldots & \\frac{\\partial f_1}{\\partial x_n} \\\\ \\frac{\\partial f_2}{\\partial x_1} & \\frac{\\partial f_2}{\\partial x_2} & \\ldots & \\frac{\\partial f_2}{\\partial x_n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\frac{\\partial f_m}{\\partial x_1} & \\frac{\\partial f_m}{\\partial x_2} & \\ldots & \\frac{\\partial f_m}{\\partial x_n} \\end{bmatrix}\\)\nIt consists of the first order partial derivatives and gives therefore an overview about the gradients of a vector valued function.\n\nExample 2.3 (acobian matrix) Consider a vector-valued function \\(f : \\mathbb{R}^2 \\rightarrow \\mathbb{R}^3\\) defined as follows: \\[f(J) = \\begin{bmatrix} x_1^2 + 2x_2 \\\\ 3x_1 - \\sin(x_2) \\\\ e^{x_1 + x_2} \\end{bmatrix}\\]\nLet’s compute the partial derivatives and construct the Jacobian matrix:\n\\(\\frac{\\partial f_1}{\\partial x_1} = 2x_1, \\quad \\frac{\\partial f_1}{\\partial x_2} = 2\\)\n\\(\\frac{\\partial f_2}{\\partial x_1} = 3, \\quad \\frac{\\partial f_2}{\\partial x_2} = -\\cos(x_2)\\)\n\\(\\frac{\\partial f_3}{\\partial x_1} = e^{x_1 + x_2}, \\quad \\frac{\\partial f_3}{\\partial x_2} = e^{x_1 + x_2}\\)\nSo, the Jacobian matrix is:\n\\[J(J) = \\begin{bmatrix} 2x_1 & 2 \\\\ 3 & -\\cos(x_2) \\\\ e^{x_1 + x_2} & e^{x_1 + x_2} \\end{bmatrix}\\]\nThis Jacobian matrix provides information about how small changes in the input variables \\(x_1\\) and \\(x_2\\) affect the corresponding changes in each component of the output vector.\n\n\n\n2.2.5 Hessian Matrix\nThe Hessian matrix \\(H(J)\\) for a scalar function \\(f(J)\\) is defined as:\n\\(H(J) = \\begin{bmatrix} \\frac{\\partial^2 f}{\\partial x_1^2} & \\frac{\\partial^2 f}{\\partial x_1 \\partial x_2} & \\ldots & \\frac{\\partial^2 f}{\\partial x_1 \\partial x_n} \\\\ \\frac{\\partial^2 f}{\\partial x_2 \\partial x_1} & \\frac{\\partial^2 f}{\\partial x_2^2} & \\ldots & \\frac{\\partial^2 f}{\\partial x_2 \\partial x_n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\frac{\\partial^2 f}{\\partial x_n \\partial x_1} & \\frac{\\partial^2 f}{\\partial x_n \\partial x_2} & \\ldots & \\frac{\\partial^2 f}{\\partial x_n^2} \\end{bmatrix}\\)\nThe Hessian matrix consists of the second order derivatives of the function. It provides information about the local curvature of the function with respect to changes in the input variables.\n\nExample 2.4 (Hessian matrix) Consider a scalar-valued function: \\[f(J) = x_1^2 + 2x_2^2 + \\sin(x_1   x_2)\\]\nThe Hessian matrix of this scalar-valued function is the matrix of its second-order partial derivatives with respect to the input variables: \\[H(J) = \\begin{bmatrix} \\frac{\\partial^2 f}{\\partial x_1^2} & \\frac{\\partial^2 f}{\\partial x_1 \\partial x_2} \\\\ \\frac{\\partial^2 f}{\\partial x_2 \\partial x_1} & \\frac{\\partial^2 f}{\\partial x_2^2} \\end{bmatrix}\\]\nLet’s compute the second-order partial derivatives and construct the Hessian matrix:\n\\[\\begin{align}\n\\frac{\\partial^2 f}{\\partial x_1^2} &= 2 + \\cos(x_1 x_2) x_2^2\\\\\n\\frac{\\partial^2 f}{\\partial x_1 \\partial x_2} &= 2x_1  x_2 \\cos(x_1 x_2) - \\sin(x_1  x_2)\\\\\n\\frac{\\partial^2 f}{\\partial x_2 \\partial x_1} &= 2x_1  x_2  \\cos(x_1  x_2) - \\sin(x_1  x_2)\\\\\n\\frac{\\partial^2 f}{\\partial x_2^2} &= 4x_2^2 + \\cos(x_1  x_2) x_1^2\n\\end{align}\\]\nSo, the Hessian matrix is:\n\\[H(J) = \\begin{bmatrix} 2 + \\cos(x_1   x_2)   x_2^2 & 2x_1   x_2   \\cos(x_1   x_2) - \\sin(x_1   x_2) \\\\ 2x_1   x_2   \\cos(x_1   x_2) - \\sin(x_1   x_2) & 4x_2^2 + \\cos(x_1   x_2)   x_1^2 \\end{bmatrix}\\]\n\n\n\n2.2.6 Gradient Descent\nIn optimization, the goal is to find the minimum or maximum of a function. Gradient-based optimization methods utilize information about the gradient (or derivative) of the function to guide the search for the optimal solution. This is particularly useful when dealing with complex, high-dimensional functions where an exhaustive search is impractical.\nThe gradient descent method can be divided in the following steps:\n\nInitialize: start with an initial guess for the parameters of the function to be optimized.\nCompute Gradient: Calculate the gradient (partial derivatives) of the function with respect to each parameter at the current point. The gradient indicates the direction of the steepest increase in the function.\nUpdate Parameters: Adjust the parameters in the opposite direction of the gradient, scaled by a learning rate. This step aims to move towards the minimum of the function:\n\n\\(x_{k+1} = x_k - \\alpha \\times \\nabla f(x_{k})\\)\n\\(x_{x}\\) is current parameter vector or point in the parameter space.\n\\(\\alpha\\) is the learning rate, a positive scalar that determines the step size in each iteration.\n\\(\\nabla f(x)\\) is the gradient of the objective function.\n\nIterate: Repeat the above steps until convergence or a predefined number of iterations. Convergence is typically determined when the change in the function value or parameters becomes negligible.\n\n\nExample 2.5 (Gradient Descent) We consider a simple quadratic function as an example: \\[\nf(x) = x^2 + 4x + y^2 + 2y + 4.\n\\]\nWe’ll use gradient descent to find the minimum of this function.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# Define the quadratic function\ndef quadratic_function(x, y):\n    return x**2 + 4*x + y**2 + 2*y + 4\n\n# Define the gradient of the quadratic function\ndef gradient_quadratic_function(x, y):\n    grad_x = 2*x + 4\n    grad_y = 2*y + 2\n    return np.array([grad_x, grad_y])\n\n# Gradient Descent for optimization in 2D\ndef gradient_descent(initial_point, learning_rate, num_iterations):\n    points = [np.array(initial_point)]\n    for _ in range(num_iterations):\n        current_point = points[-1]\n        gradient = gradient_quadratic_function(*current_point)\n        new_point = current_point - learning_rate * gradient\n        points.append(new_point)\n    return points\n\n# Visualization of optimization process with 3D surface and consistent arrow sizes\ndef plot_optimization_process_3d_consistent_arrows(points):\n    fig = plt.figure(figsize=(10, 8))\n    ax = fig.add_subplot(111, projection='3d')\n\n    x_vals = np.linspace(-10, 2, 100)\n    y_vals = np.linspace(-10, 2, 100)\n    X, Y = np.meshgrid(x_vals, y_vals)\n    Z = quadratic_function(X, Y)\n\n    ax.plot_surface(X, Y, Z, cmap='viridis', alpha=0.6)\n    ax.scatter(*zip(*points), [quadratic_function(*p) for p in points], c='red', label='Optimization Trajectory')\n\n    for i in range(len(points) - 1):  \n        x, y = points[i]\n        dx, dy = points[i + 1] - points[i]\n        dz = quadratic_function(*(points[i + 1])) - quadratic_function(*points[i])\n        gradient_length = 0.5\n\n        ax.quiver(x, y, quadratic_function(*points[i]), dx, dy, dz, color='blue', length=gradient_length, normalize=False, arrow_length_ratio=0.1)\n\n    ax.set_title('Gradient-Based Optimization with 2D Quadratic Function')\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    ax.set_zlabel('f(x, y)')\n    ax.legend()\n    plt.show()\n\n# Initial guess and parameters\ninitial_guess = [-9.0, -9.0]\nlearning_rate = 0.2\nnum_iterations = 10\n\n# Run gradient descent in 2D and visualize the optimization process with 3D surface and consistent arrow sizes\ntrajectory = gradient_descent(initial_guess, learning_rate, num_iterations)\nplot_optimization_process_3d_consistent_arrows(trajectory)\n\n\n\n\n\n\n\n\n\n\n\n2.2.7 Newton Method\nInitialization: Start with an initial guess for the optimal solution: \\(x_0\\).\nIteration: Repeat the following three steps until convergence or a predefined stopping criterion is met:\n\nCalculate the gradient (\\(\\nabla\\)) and the Hessian matrix (\\(\\nabla^2\\)) of the objective function at the current point: \\[\\nabla f(x_k) \\quad \\text{and} \\quad \\nabla^2 f(x_k)\\]\nUpdate the current solution using the Newton-Raphson update formula \\[\nx_{k+1} = x_k - [\\nabla^2 f(x_k)]^{-1} \\nabla f(x_k),\n\\] where\n* $\\nabla f(x_k)$ is the gradient (first derivative) of the objective function with respect to the variable $x$, evaluated at the current solution $x_k$.\n\n\\(\\nabla^2 f(x_k)\\): The Hessian matrix (second derivative) of the objective function with respect to \\(x\\), evaluated at the current solution \\(x_k\\).\n\\(x_k\\): The current solution or point in the optimization process.\n\\(\\nabla^2 f(x_k)]^{-1}\\): The inverse of the Hessian matrix at the current point, representing the approximation of the curvature of the objective function.\n\\(x_{k+1}\\): The updated solution or point after applying the Newton-Raphson update.\n\nCheck for convergence.\n\n\nExample 2.6 (Newton Method) We want to optimize the Rosenbrock function and use the Hessian and the Jacobian (which is equal to the gradient vector for scalar objective function) to the minimize function.\n\ndef rosenbrock(x):\n    return 100 * (x[1] - x[0]**2)**2 + (1 - x[0])**2\n\ndef rosenbrock_gradient(x):\n    dfdx0 = -400 * x[0] * (x[1] - x[0]**2) - 2 * (1 - x[0])\n    dfdx1 = 200 * (x[1] - x[0]**2)\n    return np.array([dfdx0, dfdx1])\n\ndef rosenbrock_hessian(x):\n    d2fdx0 = 1200 * x[0]**2 - 400 * x[1] + 2\n    d2fdx1 = -400 * x[0]\n    return np.array([[d2fdx0, d2fdx1], [d2fdx1, 200]])\n\ndef classical_newton_optimization_2d(initial_guess, tol=1e-6, max_iter=100):\n    x = initial_guess.copy()\n\n    for i in range(max_iter):\n        gradient = rosenbrock_gradient(x)\n        hessian = rosenbrock_hessian(x)\n\n        # Solve the linear system H * d = -g for d\n        d = np.linalg.solve(hessian, -gradient)\n\n        # Update x\n        x += d\n\n        # Check for convergence\n        if np.linalg.norm(gradient, ord=np.inf) &lt; tol:\n            break\n\n    return x\n\n# Initial guess\ninitial_guess_2d = np.array([0.0, 0.0])\n\n# Run classical Newton optimization for the 2D Rosenbrock function\nresult_2d = classical_newton_optimization_2d(initial_guess_2d)\n\n# Print the result\nprint(\"Optimal solution:\", result_2d)\nprint(\"Objective value:\", rosenbrock(result_2d))\n\nOptimal solution: [1. 1.]\nObjective value: 0.0\n\n\n\n\n\n2.2.8 BFGS-Algorithm\nBFGS is an optimization algorithm designed for unconstrained optimization problems. It belongs to the class of quasi-Newton methods and is known for its efficiency in finding the minimum of a smooth, unconstrained objective function.\n\n\n2.2.9 Procedure:\n\nInitialization:\n\nStart with an initial guess for the parameters of the objective function.\nInitialize an approximation of the Hessian matrix (inverse) denoted by \\(H\\).\n\n\nIterative Update:\n\nAt each iteration, compute the gradient vector at the current point.\nUpdate the parameters using the BFGS update formula, which involves the inverse Hessian matrix approximation, the gradient, and the difference in parameter vectors between successive iterations: \\[x_{k+1} = x_k - H_k^{-1} \\nabla f(x_k).\\]\nUpdate the inverse Hessian approximation using the BFGS update formula for the inverse Hessian. \\[H_{k+1} = H_k + \\frac{\\Delta x_k \\Delta x_k^T}{\\Delta x_k^T \\Delta g_k} - \\frac{H_k g_k g_k^T H_k}{g_k^T H_k g_k},\\] where:\n\\(x_k\\) and \\(x_{k+1}\\) are the parameter vectors at the current and updated iterations, respectively.\n\\(\\nabla f(x_k)\\) is the gradient vector at the current iteration.\n\\(\\Delta x_k = x_{k+1} - x_k\\) is the change in parameter vectors.\n\\(\\Delta g_k = \\nabla f(x_{k+1}) - \\nabla f(x_k)\\) is the change in gradient vectors.\n\nConvergence:\n\nRepeat the iterative update until the optimization converges. Convergence is typically determined by reaching a sufficiently low gradient or parameter change.\n\n\n\nExample 2.7 (BFGS for Rosenbrock)  \n\nimport numpy as np\nfrom scipy.optimize import minimize\n\n# Define the 2D Rosenbrock function\ndef rosenbrock(x):\n    return (1 - x[0])**2 + 100 * (x[1] - x[0]**2)**2\n\n# Initial guess\ninitial_guess = np.array([0.0, 0.0])\n\n# Minimize the Rosenbrock function using BFGS\nminimize(rosenbrock, initial_guess, method='BFGS')\n\n  message: Optimization terminated successfully.\n  success: True\n   status: 0\n      fun: 2.8440052847381483e-11\n        x: [ 1.000e+00  1.000e+00]\n      nit: 19\n      jac: [ 3.987e-06 -2.844e-06]\n hess_inv: [[ 4.948e-01  9.896e-01]\n            [ 9.896e-01  1.984e+00]]\n     nfev: 72\n     njev: 24\n\n\n\n\n\n2.2.10 Visualization BFGS for Rosenbrock\nA visualization of the BFGS search process on Rosenbrock’s function can be found here: https://upload.wikimedia.org/wikipedia/de/f/ff/Rosenbrock-bfgs-animation.gif",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to `scipy.optimize`</span>"
    ]
  },
  {
    "objectID": "003_scipy_optimize_intro.html#global-optimization",
    "href": "003_scipy_optimize_intro.html#global-optimization",
    "title": "2  Introduction to scipy.optimize",
    "section": "2.3 Global Optimization",
    "text": "2.3 Global Optimization\nGlobal optimization aims to find the global minimum of a function within given bounds, in the presence of potentially many local minima. Typically, global minimizers efficiently search the parameter space, while using a local minimizer (e.g., minimize) under the hood.\n\n2.3.1 Local vs Global Optimization\n\n2.3.1.1 Local Optimizater:\n\nSeeks the optimum in a specific region of the search space\nTends to exploit the local environment, to find solutions in the immediate area\nHighly sensitive to initial conditions; may converge to different local optima based on the starting point\nOften computationally efficient for low-dimensional problems but may struggle with high-dimensional or complex search spaces\nCommonly used in situations where the objective is to refine and improve existing solutions\n\n\n\n2.3.1.2 Global Optimizer:\n\nExplores the entire search space to find the global optimum\nEmphasize exploration over exploitation, aiming to search broadly and avoid premature convergence to local optima\nAim to mitigate the risk of premature convergence to local optima by employing strategies for global exploration\nLess sensitive to initial conditions, designed to navigate diverse regions of the search space\nEquipped to handle high-dimensional and complex problems, though computational demands may vary depending on the specific algorithm\nPreferred for applications where a comprehensive search of the solution space is crucial, such as in parameter tuning, machine learning, and complex engineering design\n\n\n\nExample 2.8 (Global Optimizers in SciPy) SciPy contains a number of good global optimizers. Here, we’ll use those on the same objective function, namely the (aptly named) eggholder function:\n\ndef eggholder(x):\n    return (-(x[1] + 47) * np.sin(np.sqrt(abs(x[0]/2 + (x[1]  + 47))))\n            -x[0] * np.sin(np.sqrt(abs(x[0] - (x[1]  + 47)))))\n\nbounds = [(-512, 512), (-512, 512)]\n\n\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\nx = np.arange(-512, 513)\ny = np.arange(-512, 513)\nxgrid, ygrid = np.meshgrid(x, y)\nxy = np.stack([xgrid, ygrid])\n\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.view_init(45, -45)\nax.plot_surface(xgrid, ygrid, eggholder(xy), cmap='terrain')\nax.set_xlabel('x')\nax.set_ylabel('y')\nax.set_zlabel('eggholder(x, y)')\nplt.show()\n\n\n\n\n\n\n\n\nWe now use the global optimizers to obtain the minimum and the function value at the minimum. We’ll store the results in a dictionary so we can compare different optimization results later.\n\nfrom scipy import optimize\nresults = dict()\nresults['shgo'] = optimize.shgo(eggholder, bounds)\nresults['shgo']\n\n message: Optimization terminated successfully.\n success: True\n     fun: -935.3379515605789\n    funl: [-9.353e+02]\n       x: [ 4.395e+02  4.540e+02]\n      xl: [[ 4.395e+02  4.540e+02]]\n     nit: 1\n    nfev: 45\n   nlfev: 40\n   nljev: 10\n   nlhev: 0\n\n\n\nresults['DA'] = optimize.dual_annealing(eggholder, bounds)\nresults['DA']\n\n message: ['Maximum number of iteration reached']\n success: True\n  status: 0\n     fun: -959.6406627208355\n       x: [ 5.120e+02  4.042e+02]\n     nit: 1000\n    nfev: 4055\n    njev: 18\n    nhev: 0\n\n\nAll optimizers return an OptimizeResult, which in addition to the solution contains information on the number of function evaluations, whether the optimization was successful, and more. For brevity, we won’t show the full output of the other optimizers:\n\nresults['DE'] = optimize.differential_evolution(eggholder, bounds)\nresults['DE']\n\n             message: Optimization terminated successfully.\n             success: True\n                 fun: -894.5789003905943\n                   x: [-4.657e+02  3.857e+02]\n                 nit: 24\n                nfev: 768\n          population: [[-4.662e+02  3.857e+02]\n                       [-4.669e+02  3.803e+02]\n                       ...\n                       [-4.663e+02  3.865e+02]\n                       [-4.651e+02  3.854e+02]]\n population_energies: [-8.946e+02 -8.835e+02 ... -8.944e+02 -8.945e+02]\n                 jac: [ 0.000e+00  0.000e+00]\n\n\nshgo has a second method, which returns all local minima rather than only what it thinks is the global minimum:\n\nresults['shgo_sobol'] = optimize.shgo(eggholder, bounds, n=200, iters=5,\n                                      sampling_method='sobol')\nresults['shgo_sobol']\n\n message: Optimization terminated successfully.\n success: True\n     fun: -959.640662720831\n    funl: [-9.596e+02 -9.353e+02 ... -6.591e+01 -6.387e+01]\n       x: [ 5.120e+02  4.042e+02]\n      xl: [[ 5.120e+02  4.042e+02]\n           [ 4.395e+02  4.540e+02]\n           ...\n           [ 3.165e+01 -8.523e+01]\n           [ 5.865e+01 -5.441e+01]]\n     nit: 5\n    nfev: 3529\n   nlfev: 2327\n   nljev: 634\n   nlhev: 0\n\n\nWe’ll now plot all found minima on a heatmap of the function:\n\nfig = plt.figure()\nax = fig.add_subplot(111)\nim = ax.imshow(eggholder(xy), interpolation='bilinear', origin='lower',\n               cmap='gray')\nax.set_xlabel('x')\nax.set_ylabel('y')\n\ndef plot_point(res, marker='o', color=None):\n    ax.plot(512+res.x[0], 512+res.x[1], marker=marker, color=color, ms=10)\n\nplot_point(results['DE'], color='c')  # differential_evolution - cyan\nplot_point(results['DA'], color='w')  # dual_annealing.        - white\n\n# SHGO produces multiple minima, plot them all (with a smaller marker size)\nplot_point(results['shgo'], color='r', marker='+')\nplot_point(results['shgo_sobol'], color='r', marker='x')\nfor i in range(results['shgo_sobol'].xl.shape[0]):\n    ax.plot(512 + results['shgo_sobol'].xl[i, 0],\n            512 + results['shgo_sobol'].xl[i, 1],\n            'ro', ms=2)\n\nax.set_xlim([-4, 514*2])\nax.set_ylim([-4, 514*2])\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n2.3.2 Dual Annealing Optimization\nThis function implements the Dual-Annealing optimization, which is a variant of the famous simulated annealing optimization.\nSimulated Annealing is a probabilistic optimization algorithm inspired by the annealing process in metallurgy. The algorithm is designed to find a good or optimal global solution to a problem by exploring the solution space in a controlled and adaptive manner.\n\n\n\n\n\n\nAnnealing in Metallurgy\n\n\n\nSimulated Annealing draws inspiration from the physical process of annealing in metallurgy. Just as metals are gradually cooled to achieve a more stable state, Simulated Annealing uses a similar approach to explore solution spaces in the digital world.\n\n\nHeating Phase: In metallurgy, a metal is initially heated to a high temperature. At this elevated temperature, the atoms or molecules in the material become more energetic and chaotic, allowing the material to overcome energy barriers and defects.\nAnalogy Simulated Annealing (Exploration Phase): In Simulated Annealing, the algorithm starts with a high “temperature,” which encourages exploration of the solution space. At this stage, the algorithm is more likely to accept solutions that are worse than the current one, allowing it to escape local optima and explore a broader region of the solution space.\nCooling Phase: The material is then gradually cooled at a controlled rate. As the temperature decreases, the atoms or molecules start to settle into more ordered and stable arrangements. The slow cooling rate is crucial to avoid the formation of defects and to ensure the material reaches a well-organized state.\nAnalogy Simulated Annealing (Exploitation Phase): As the algorithm progresses, the temperature is gradually reduced over time according to a cooling schedule. This reduction simulates the cooling process in metallurgy. With lower temperatures, the algorithm becomes more selective and tends to accept only better solutions, focusing on refining and exploiting the promising regions discovered during the exploration phase.\n\n2.3.2.1 Key Concepts\nTemperature: The temperature is a parameter that controls the likelihood of accepting worse solutions. We start with a high temperature, allowing the algorithm to explore the solution space braodly. The temperature decreases with the iterations of the algorithm.\nCooling Schedule: The temperature parameter is reduced according to this schedule. The analogy to the annealing of metals: a slower cooling rate allows the material to reach a more stable state.\nNeighborhood Exploration: At each iteration, the algorithm explores the neighborhood of the current solution. The neighborhood is defined by small perturbations or changes to the current solution.\nAcceptance Probability: The algorithm evaluates the objective function for the new solution in the neighborhood. If the new solution is better, it is accepted. If the new solution is worse, it may still be accepted with a certain probability. This probability is determined by both the difference in objective function values and the current temperature.\nFor minimization: If: \\[\nf(x_{t}) &gt; f(x_{t+1})\n\\] Then: \\[\nP(accept\\_new\\_point) = 1\n\\]\nIf: \\[\nf(x_{t}) &lt; f(x_{t+1})\n\\] Then: \\[\nP(accept\\_new\\_point) = e^{-(\\frac{f(x_{t+1}) - f(x_{t})}{Tt})}\n\\]\nTermination Criterion: The algorithm continues iterations until a termination condition is met. This could be a fixed number of iterations, reaching a specific temperature threshold, or achieving a satisfactory solution.\n\n\n2.3.2.2 Steps\n1. Initialization: Set an initial temperature (\\(T_{0}\\)) and an initial solution (\\(f(x_{0})\\)). The temperature is typically set high initially to encourage exploration.\n2. Generate a Neighbor: Perturb the current solution to generate a neighboring solution. The perturbation can be random or follow a specific strategy.\n3. Evaluate the Neighbor: Evaluate the objective function for the new solution in the neighborhood.\n4. Accept or Reject the Neighbor: + If the new solution is better (lower cost for minimization problems or higher for maximization problems), accept it as the new current solution. + If the new solution is worse, accept it with a probability determined by an acceptance probability function as mentioned above. The probability is influenced by the difference in objective function values and the current temperature.\n5. Cooling: Reduce the temperature according to a cooling schedule. The cooling schedule defines how fast the temperature decreases over time. Common cooling schedules include exponential or linear decay.\n6. Termination Criterion: Repeat the iterations (2-5) until a termination condition is met. This could be a fixed number of iterations, reaching a specific temperature threshold, or achieving a satisfactory solution.\n\n\n2.3.2.3 Scipy Implementation of the Dual Annealing Algorithm\nIn Scipy, we utilize the Dual Annealing optimizer, an extension of the simulated annealing algorithm that is versatile for both discrete and continuous problems.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import dual_annealing\n\ndef rastrigin_function(x):\n    return 20 + x[0]**2 - 10 * np.cos(2 * np.pi * x[0]) + x[1]**2 - 10 * np.cos(2 * np.pi * x[1])\n\n# Define the Rastrigin function for visualization\ndef rastrigin_visualization(x, y):\n    return 20 + x**2 - 10 * np.cos(2 * np.pi * x) + y**2 - 10 * np.cos(2 * np.pi * y)\n\n# Create a meshgrid for visualization\nx_vals = np.linspace(-10, 10, 100)\ny_vals = np.linspace(-10, 10, 100)\nx_mesh, y_mesh = np.meshgrid(x_vals, y_vals)\nz_mesh = rastrigin_visualization(x_mesh, y_mesh)\n\n# Visualize the Rastrigin function\nplt.figure(figsize=(10, 8))\ncontour = plt.contour(x_mesh, y_mesh, z_mesh, levels=50, cmap='viridis')\nplt.colorbar(contour, label='Rastrigin Function Value')\nplt.title('Visualization of the 2D Rastrigin Function')\n\n# Optimize the Rastrigin function using dual annealing\nresult = dual_annealing(func = rastrigin_function,\n                        x0=[5.0,3.0],                       #Initial Guess\n                        bounds= [(-10, 10), (-10, 10)],\n                        initial_temp = 5230,                #Intial Value for temperature\n                        restart_temp_ratio = 2e-05,         #Temperature schedule\n                        seed=42)\n\n# Plot the optimized point\noptimal_x, optimal_y = result.x\nplt.plot(optimal_x, optimal_y, 'ro', label='Optimal Point')\n\n# Set labels and legend\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.legend()\n\n# Show the plot\nplt.show()\n\n# Display the optimization result\nprint(\"Optimal parameters:\", result.x)\nprint(\"Minimum value of the Rastrigin function:\", result.fun)\n\n\n\n\n\n\n\n\nOptimal parameters: [-4.60133247e-09 -4.31928660e-09]\nMinimum value of the Rastrigin function: 7.105427357601002e-15\n\n\n\n\n\n2.3.3 Differential Evolution\nDifferential Evolution is an algorithm used for finding the global minimum of multivariate functions. It is stochastic in nature (does not use gradient methods), and can search large areas of candidate space, but often requires larger numbers of function evaluations than conventional gradient based techniques.\nDifferential Evolution (DE) is a versatile and global optimization algorithm inspired by natural selection and evolutionary processes. Introduced by Storn and Price in 1997, DE mimics the survival-of-the-fittest principle by evolving a population of candidate solutions through iterative mutation, crossover, and selection operations. This nature-inspired approach enables DE to efficiently explore complex and non-linear solution spaces, making it a widely adopted optimization technique in diverse fields such as engineering, finance, and machine learning.\n\n\n2.3.4 Procedure\nThe procedure boils down to the following steps:\n\nInitialization:\n\nCreate a population of candidate solutions randomly within the specified search space.\n\nMutation:\n\nFor each individual in the population, select three distinct individuals (vectors) randomly.\nGenerate a mutant vector V by combining these three vectors with a scaling factor.\n\nCrossover:\n\nPerform the crossover operation between the target vector U and the mutant vector V. Information from both vectors is used to create a trial vector U´\n\n\n\n\n\n\n\n\nCross-Over Strategies in DE\n\n\n\n\nThere are several crossover strategies in the literature. Two examples are:\n\nBinominal Crossover:\nIn this strategy, each component of the trial vector is selected from the mutant vector with a probability equal to the crossover rate (\\(CR\\)). This means that each element of the trial vector has an independent probability of being replaced by the corresponding element of the mutant vector.\n\\[U'_i =\n      \\begin{cases}\n      V_i, & \\text{if a random number} \\ \\sim U(0, 1) \\leq CR \\ \\text{(Crossover Rate)} \\\\\n      U_i, & \\text{otherwise}\n      \\end{cases}\n\\]\nExponential Crossover:\nIn exponential crossover, the trial vector is constructed by selecting a random starting point and copying elements from the mutant vector with a certain probability. The probability decreases exponentially with the distance from the starting point. This strategy introduces a correlation between neighboring elements in the trial vector.\n\n\n\nSelection:\n\nEvaluate the fitness of the trial vector obtained from the crossover.\nReplace the target vector with the trial vector if its fitness is better.\n\nTermination:\n\nRepeat the mutation, crossover, and selection steps for a predefined number of generations or until convergence criteria are met.\n\nResult:\n\nThe algorithm returns the best-found solution after the specified number of iterations.\n\n\nThe key parameters in DE include the population size, crossover probability, and the scaling factor. Tweak these parameters based on the characteristics of the optimization problem for optimal performance.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import minimize\n\n# Define the Rastrigin function\ndef rastrigin(x):\n    A = 10\n    return A * len(x) + sum([(xi**2 - A * np.cos(2 * np.pi * xi)) for xi in x])\n\n# Create a grid for visualization\nx_vals = np.linspace(-5.12, 5.12, 100)\ny_vals = np.linspace(-5.12, 5.12, 100)\nX, Y = np.meshgrid(x_vals, y_vals)\nZ = rastrigin(np.vstack([X.ravel(), Y.ravel()]))\n\n# Reshape Z to match the shape of X and Y\nZ = Z.reshape(X.shape)\n\n# Plot the Rastrigin function\nplt.contour(X, Y, Z, levels=50, cmap='viridis', label='Rastrigin Function')\n\n# Initial guess (starting point for the optimization)\ninitial_guess = (4,3,4,2)\n\n# Define the bounds for each variable in the Rastrigin function\nbounds = [(-5.12, 5.12)] * 4  # 4D problem, each variable has bounds (-5.12, 5.12)\n\n# Run the minimize function\nresult = minimize(rastrigin, initial_guess, bounds=bounds, method='L-BFGS-B')\n\n# Extract the optimal solution\noptimal_solution = result.x\n\n# Plot the optimal solution\nplt.scatter(optimal_solution[0], optimal_solution[1], color='red', marker='x', label='Optimal Solution')\n\n# Add labels and legend\nplt.title('Optimization of Rastrigin Function with Minimize')\nplt.xlabel('Variable 1')\nplt.ylabel('Variable 2')\nplt.legend()\n\n# Show the plot\nplt.show()\n\n# Print the optimization result\nprint(\"Optimal Solution:\", optimal_solution)\nprint(\"Optimal Objective Value:\", result.fun)\n\n\n\n\n\n\n\n\nOptimal Solution: [-2.52869119e-08 -2.07795060e-08 -2.52869119e-08 -1.62721002e-08]\nOptimal Objective Value: 3.907985046680551e-13\n\n\n\n\n2.3.5 Other global optimization algorithms\n\n\n2.3.6 DIRECT\nDIviding RECTangles (DIRECT) is a deterministic global optimization algorithm capable of minimizing a black box function with its variables subject to lower and upper bound constraints by sampling potential solutions in the search space\n\n\n2.3.7 SHGO\nSHGO stands for “simplicial homology global optimization”. It is considered appropriate for solving general purpose NLP and blackbox optimization problems to global optimality (low-dimensional problems).\n\n\n2.3.8 Basin-hopping\nBasin-hopping is a two-phase method that combines a global stepping algorithm with local minimization at each step. Designed to mimic the natural process of energy minimization of clusters of atoms, it works well for similar problems with “funnel-like, but rugged” energy landscapes",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to `scipy.optimize`</span>"
    ]
  },
  {
    "objectID": "003_scipy_optimize_intro.html#project-one-mass-oscillator-optimization",
    "href": "003_scipy_optimize_intro.html#project-one-mass-oscillator-optimization",
    "title": "2  Introduction to scipy.optimize",
    "section": "2.4 Project: One-Mass Oscillator Optimization",
    "text": "2.4 Project: One-Mass Oscillator Optimization\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import minimize\n\n\n2.4.1 Introduction\nIn this project, you will apply various optimization algorithms to fit a one-mass oscillator model to real-world data. The objective is to minimize the sum of the squared residuals between the model predictions and the observed amplitudes of a one-mass oscillator system across different frequencies.\n\n\n2.4.2 One-Mass Oscillator Model\nThe one-mass oscillator is characterized by the following equation, representing the amplitudes of the system:\n\\[\nV(\\omega) = \\frac{F}{\\sqrt{(1 - \\nu^2)^2 + 4D^2\\nu^2}}\n\\]\nHere, \\(\\omega\\) represents the angular frequency of the system, \\(\\nu\\) is the ratio of the excitation frequency to the natural frequency, i.e., \\[\n\\nu = \\frac{\\omega_{\\text{err}}}{\\omega_{\\text{eig}}},\n\\] \\(D\\) is the damping ratio, and \\(F\\) is the force applied to the system.\nThe goal of the project is to determine the optimal values for the parameters \\(\\omega_{\\text{eig}}\\), \\(D\\), and \\(F\\) that result in the best fit of the one-mass oscillator model to the observed amplitudes.\n\n\n2.4.3 The Real-World Data\nThere are two different measurements. J represents the measured frequencies, and N represents the measured amplitudes.\n\ndf1 = pd.read_pickle(\"./data/Hcf.d/df1.pkl\")\ndf2 = pd.read_pickle(\"./data/Hcf.d/df2.pkl\")\ndf1.describe()\n\n\n\n\n\n\n\n\nJ\nN\n\n\n\n\ncount\n33.000000\n33.000000\n\n\nmean\n8148.750252\n10.430887\n\n\nstd\n6.870023\n2.846469\n\n\nmin\n8137.649210\n4.698761\n\n\n25%\n8143.799766\n8.319253\n\n\n50%\n8146.942295\n10.152119\n\n\n75%\n8153.934051\n13.407260\n\n\nmax\n8162.504002\n14.382749\n\n\n\n\n\n\n\n\ndf1.head()\n\n\n\n\n\n\n\n\nJ\nN\n\n\n\n\n14999\n8162.504002\n5.527511\n\n\n15011\n8156.384831\n7.359789\n\n\n15016\n8159.199238\n6.532958\n\n\n15020\n8159.200889\n5.895933\n\n\n15025\n8153.934051\n9.326749\n\n\n\n\n\n\n\n\n# plot the data, i.e., the measured amplitudes as a function of the measured frequencies\nplt.scatter(df1[\"J\"], df1[\"N\"], color=\"black\", label=\"Spektralpunkte\", zorder=5, s=10)\nplt.xlabel(\"Frequency [Hz]\")\nplt.ylabel(\"Amplitude\")\nplt.show()\n\n\n\n\n\n\n\n\nNote: Low amplitudes distort the fit and are negligible therefore we define a lower threshold for N.\n\nthreshold = 0.4\ndf1.sort_values(\"N\")\nmax_N = max(df1[\"N\"])\ndf1 = df1[df1[\"N\"]&gt;=threshold*max_N]\n\nWe extract the frequency value for maximum value of the amplitude. This serves as the initial value for one decision variable.\n\ndf_max=df1[df1[\"N\"]==max(df1[\"N\"])]\ninitial_Oeig = df_max[\"J\"].values[0]\nmax_N = df_max[\"N\"].values[0]\n\nWe also have to define the other two initial guesses for the damping ratio and the force, e.g.,\n\ninitial_D = 0.006\ninitial_F = 0.120\ninitial_values = [initial_Oeig, initial_D, initial_F]\n\nAdditionally, we define the bounds for the decision variables:\n\nmin_Oerr = min(df1[\"J\"])\nmax_Oerr = max(df1[\"J\"])\n\n\nbounds = [(min_Oerr, max_Oerr), (0, 0.03), (0, 1)]\n\n\n\n2.4.4 Objective Function\nThen we define the objective function:\n\ndef one_mass_oscillator(params, Oerr) -&gt; np.ndarray:\n    # returns amplitudes of the system\n    # Defines the model of a one mass oscilator \n    Oeig, D, F = params\n    nue = Oerr / Oeig\n    V = F / (np.sqrt((1 - nue**2) ** 2 + (4 * D**2 * nue**2)))\n    return V\n\n\ndef objective_function(params, Oerr, amplitudes) -&gt; np.ndarray:\n    # objective function to compare calculated and real amplitudes\n    return np.sum((amplitudes - one_mass_oscillator(params, Oerr)) ** 2)\n\nWe define the options for the optimzer and start the optimization process:\n\noptions = {\n    \"maxfun\": 100000,\n    \"ftol\": 1e-9,\n    \"xtol\": 1e-9,\n    \"stepmx\": 10,\n    \"eta\": 0.25,\n    \"gtol\": 1e-5}\n\n\nJ = np.array(df1[\"J\"]) # measured frequency\nN = np.array(df1[\"N\"]) # measured amplitude\n\n\nresult = minimize(\n    objective_function,\n    initial_values,\n    args=(J, N),\n    method='Nelder-Mead',\n    bounds=bounds,\n    options=options)\n\n\n\n2.4.5 Results\nWe can observe the results:\n\n# map optimized values to variables\nresonant_frequency = result.x[0]\nD = result.x[1]\nF = result.x[2]\n# predict the resonant amplitude with the fitted one mass oscillator.\nX_pred = np.linspace(min_Oerr, max_Oerr, 1000)\nypred_one_mass_oscillator = one_mass_oscillator(result.x, X_pred)\nresonant_amplitude = max(ypred_one_mass_oscillator)\nprint(f\"result: {result}\")\n\nresult:        message: Optimization terminated successfully.\n       success: True\n        status: 0\n           fun: 53.54144061205875\n             x: [ 8.148e+03  7.435e-04  2.153e-02]\n           nit: 93\n          nfev: 169\n final_simplex: (array([[ 8.148e+03,  7.435e-04,  2.153e-02],\n                       [ 8.148e+03,  7.435e-04,  2.153e-02],\n                       [ 8.148e+03,  7.435e-04,  2.153e-02],\n                       [ 8.148e+03,  7.435e-04,  2.153e-02]]), array([ 5.354e+01,  5.354e+01,  5.354e+01,  5.354e+01]))\n\n\nFinally, we can plot the optimized fit and the real values:\n\nplt.scatter(\n    df1[\"J\"],\n    df1[\"N\"],\n    color=\"black\",\n    label=\"Spektralpunkte filtered\",\n    zorder=5,\n    s=10,\n)\n# color the max amplitude point red\nplt.scatter(\n    initial_Oeig,\n    max_N,\n    color=\"red\",\n    label=\"Max Amplitude\",\n    zorder=5,\n    s=10,\n)\n\nplt.plot(\n        X_pred,\n        ypred_one_mass_oscillator,\n        label=\"Alpha\",\n        color=\"blue\",\n        linewidth=1,\n    )\nplt.scatter(\n    resonant_frequency,\n    resonant_amplitude,\n    color=\"blue\",\n    label=\"Max Curve Fit\",\n    zorder=10,\n    s=20,\n)",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to `scipy.optimize`</span>"
    ]
  },
  {
    "objectID": "003_scipy_optimize_intro.html#exercises",
    "href": "003_scipy_optimize_intro.html#exercises",
    "title": "2  Introduction to scipy.optimize",
    "section": "2.5 Exercises",
    "text": "2.5 Exercises\n\nExercise 2.1 (Nelder-Mead)  \n\nWhat are the steps of the Nelder-Mead algorithm?\nWhat are the advantages and disadvantages of the Nelder-Mead algorithm?\n\n\n\nExercise 2.2 (Powell’s Method)  \n\nWhat are the steps of Powell’s method?\nWhat are the advantages and disadvantages of Powell’s method?\nWhat are similarities between the Nelder-Mead and Powell’s methods?\n\n\n\nExercise 2.3 (Gradient Descent)  \n\nWhat are the steps of the gradient descent algorithm?\nWhat is the learning rate in the gradient descent algorithm?\n\n\n\nExercise 2.4 (Newton Method)  \n\nWhat is the difference between the gradient descent and Newton method?\nWhich of the two methods converges faster?\n\n\n\nExercise 2.5 (BFGS)  \n\nIn which situations is it possible to use algorithms like BFGS, but not the classical Newton method?\nWould you choose Gradient Descent or BFGS for a large-scale optimization problem?\n\n\n\nExercise 2.6 (Dual Annealing)  \n\nWhen should you use Simulated Annealing or Dual Annealing over a local optimization algorithm?\nDescribe the Temperature parameter in Simulated Annealing.\n\n\n\nExercise 2.7 (Differential Evolution)  \n\nWhat are the key steps in the Differential Evolution algorithm?\nExplain the crossover operation in Differential Evolution.",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to `scipy.optimize`</span>"
    ]
  },
  {
    "objectID": "003_scipy_optimize_intro.html#jupyter-notebook",
    "href": "003_scipy_optimize_intro.html#jupyter-notebook",
    "title": "2  Introduction to scipy.optimize",
    "section": "2.6 Jupyter Notebook",
    "text": "2.6 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository",
    "crumbs": [
      "Optimization",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to `scipy.optimize`</span>"
    ]
  },
  {
    "objectID": "001_surrogate.html",
    "href": "001_surrogate.html",
    "title": "3  Simulation and Surrogate Modeling",
    "section": "",
    "text": "3.1 Surrogates",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Simulation and Surrogate Modeling</span>"
    ]
  },
  {
    "objectID": "001_surrogate.html#surrogates",
    "href": "001_surrogate.html#surrogates",
    "title": "3  Simulation and Surrogate Modeling",
    "section": "",
    "text": "Gathering data is expensive, and sometimes getting exactly the data you want is impossible or unethical\nSurrogate: substitute for the real thing\nIn statistics, draws from predictive equations derived from a fitted model can act as a surrogate for the data-generating mechanism\nBenefits of the surrogate approach:\n\nSurrogate could represent a cheaper way to explore relationships, and entertain “what ifs?”\nSurrogates favor faithful yet pragmatic reproduction of dynamics:\n\ninterpretation,\nestablishing causality, or\nidentification\n\nMany numerical simulators are deterministic, whereas field observations are noisy or have measurement error\n\n\n\n3.1.1 Costs of Simulation\n\nComputer simulations are generally cheaper (but not always!) than physical observation\nSome computer simulations can be just as expensive as field experimentation, but computer modeling is regarded as easier because:\n\nthe experimental apparatus is better understood\nmore aspects may be controlled.\n\n\n\n\n3.1.2 Mathematical Models and Meta-Models\n\nUse of mathematical models leveraging numerical solvers has been commonplace for some time\nMathematical models became more complex, requiring more resources to simulate/solve numerically\nPractitioners increasingly relied on meta-models built off of limited simulation campaigns\n\n\n\n3.1.3 Surrogates = Trained Meta-models\n\nData collected via expensive computer evaluations tuned flexible functional forms that could be used in lieu of further simulation to\n\nsave money or computational resources;\ncope with an inability to perform future runs (expired licenses, off-line or over-impacted supercomputers)\n\nTrained meta-models became known as surrogates\n\n\n\n3.1.4 Computer Experiments\n\nComputer experiment: design, running, and fitting meta-models.\n\nLike an ordinary statistical experiment, except the data are generated by computer codes rather than physical or field observations, or surveys\n\nSurrogate modeling is statistical modeling of computer experiments\n\n\n\n3.1.5 Limits of Mathematical Modeling\n\nMathematical biologists, economists and others had reached the limit of equilibrium-based mathematical modeling with cute closed-form solutions\nStochastic simulations replace deterministic solvers based on FEM, Navier–Stokes or Euler methods\nAgent-based simulation models are used to explore predator-prey (Lotka–Voltera) dynamics, spread of disease, management of inventory or patients in health insurance markets\nConsequence: the distinction between surrogate and statistical model is all but gone\n\n\n\n3.1.6 Why Computer Simulations are Necessary\n\nYou can’t seed a real community with Ebola and watch what happens\nIf there’s (real) field data, say on a historical epidemic, further experimentation may be almost entirely limited to the mathematical and computer modeling side\nClassical statistical methods offer little guidance\n\n\n\n3.1.7 Simulation Requirements\n\nSimulation should\n\nenable rich diagnostics to help criticize that models\nunderstanding its sensitivity to inputs and other configurations\nproviding the ability to optimize and\nrefine both automatically and with expert intervention\n\nAnd it has to do all that while remaining computationally tractable\nOne perspective is so-called response surface methods (RSMs):\na poster child from industrial statistics’ heyday, well before information technology became a dominant industry",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Simulation and Surrogate Modeling</span>"
    ]
  },
  {
    "objectID": "001_surrogate.html#applications-of-surrogate-models",
    "href": "001_surrogate.html#applications-of-surrogate-models",
    "title": "3  Simulation and Surrogate Modeling",
    "section": "3.2 Applications of Surrogate Models",
    "text": "3.2 Applications of Surrogate Models\nThe four most common usages of surrogate models are:\n\nAugmenting Expensive Simulations: Surrogate models act as a ‘curve fit’ to approximate the results of expensive simulation codes, enabling predictions without rerunning the primary source. This provides significant speed improvements while maintaining useful accuracy.\nCalibration of Predictive Codes: Surrogates bridge the gap between simpler, faster but less accurate models and more accurate, slower models. This multi-fidelity approach allows for improved accuracy without the full computational expense.\nHandling Noisy or Missing Data: Surrogates smooth out random or systematic errors in experimental or computational data, filling gaps and revealing overall trends while filtering out extraneous details.\nData Mining and Insight Generation: Surrogates help identify functional relationships between variables and their impact on results. They enable engineers to focus on critical variables and visualize data trends effectively.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Simulation and Surrogate Modeling</span>"
    ]
  },
  {
    "objectID": "001_surrogate.html#dace-and-rsm",
    "href": "001_surrogate.html#dace-and-rsm",
    "title": "3  Simulation and Surrogate Modeling",
    "section": "3.3 DACE and RSM",
    "text": "3.3 DACE and RSM\nMathematical models implemented in computer codes are used to circumvent the need for expensive field data collection. These models are particularly useful when dealing with highly nonlinear response surfaces, high signal-to-noise ratios (which often involve deterministic evaluations), and a global scope. As a result, a new approach is required in comparison to Response Surface Methodology (RSM), which is discussed in Section 6.1.\nWith the improvement in computing power and simulation fidelity, researchers gain higher confidence and a better understanding of the dynamics in physical, biological, and social systems. However, the expansion of configuration spaces and increasing input dimensions necessitates more extensive designs. High-performance computing (HPC) allows for thousands of runs, whereas previously only tens were possible. This shift towards larger models and training data presents new computational challenges.\nResearch questions for DACE (Design and Analysis of Computer Experiments) include how to design computer experiments that make efficient use of computation and how to meta-model computer codes to save on simulation effort. The choice of surrogate model for computer codes significantly impacts the optimal experiment design, and the preferred model-design pairs can vary depending on the specific goal.\nThe combination of computer simulation, design, and modeling with field data from similar real-world experiments introduces a new category of computer model tuning problems. The ultimate goal is to automate these processes to the greatest extent possible, allowing for the deployment of HPC with minimal human intervention.\nOne of the remaining differences between RSM and DACE lies in how they handle noise. DACE employs replication, a technique that would not be used in a deterministic setting, to separate signal from noise. Traditional RSM is best suited for situations where a substantial proportion of the variability in the data is due to noise, and where the acquisition of data values can be severely limited. Consequently, RSM is better suited for a different class of problems, aligning with its intended purposes.\nTwo very good texts on computer experiments and surrogate modeling are Santner, Williams, and Notz (2003) and Forrester, Sóbester, and Keane (2008). The former is the canonical reference in the statistics literature and the latter is perhaps more popular in engineering.\n\nExample 3.1 (Example: DACE and RSM) Imagine you are a chemical engineer tasked with optimizing a chemical process to maximize yield. You can control temperature and pressure, but repeated experiments show variability in yield due to inconsistencies in raw materials.\n\nUsing RSM: You would use RSM to design a series of experiments varying temperature and pressure. You would then fit a response surface (a mathematical model) to the data, helping you understand how changes in temperature and pressure affect yield. Using this model, you can identify optimal conditions for maximizing yield despite the noise.\nUsing DACE: If instead you use a computational model to simulate the chemical process and want to account for numerical noise or uncertainty in model parameters, you might use DACE. You would run simulations at different conditions, possibly repeating them to assess variability and build a surrogate model that accurately predicts yields, which can be optimized to find the best conditions.\n\n\n\n3.3.1 Noise Handling in RSM and DACE\nNoise in RSM: In experimental settings, noise often arises due to variability in experimental conditions, measurement errors, or other uncontrollable factors. This noise can significantly affect the response variable, \\(Y\\). Replication is a standard procedure for handling noise in RSM. In the context of computer experiments, noise might not be present in the traditional sense since simulations can be deterministic. However, variability can arise from uncertainty in input parameters or model inaccuracies. DACE predominantly utilizes advanced interpolation to construct accurate models of deterministic data, sometimes considering statistical noise modeling if needed.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Simulation and Surrogate Modeling</span>"
    ]
  },
  {
    "objectID": "001_surrogate.html#updating-a-surrogate-model",
    "href": "001_surrogate.html#updating-a-surrogate-model",
    "title": "3  Simulation and Surrogate Modeling",
    "section": "3.4 Updating a Surrogate Model",
    "text": "3.4 Updating a Surrogate Model\nA surrogate model is updated by incorporating new data points, known as infill points, into the model to improve its accuracy and predictive capabilities. This process is iterative and involves the following steps:\n\nIdentify Regions of Interest: The surrogate model is analyzed to determine areas where it is inaccurate or where further exploration is needed. This could be regions with high uncertainty or areas where the model predicts promising results (e.g., potential optima).\nSelect Infill Points: Infill points are new data points chosen based on specific criteria, such as:\nExploitation: Sampling near predicted optima to refine the solution. Exploration: Sampling in regions of high uncertainty to improve the model globally. Balanced Approach: Combining exploitation and exploration to ensure both local and global improvements.\nEvaluate the True Function: The true function (e.g., a simulation or experiment) is evaluated at the selected infill points to obtain their corresponding outputs.\nUpdate the Surrogate Model: The surrogate model is retrained or updated using the new data, including the infill points, to improve its accuracy.\nRepeat: The process is repeated until the model meets predefined accuracy criteria or the computational budget is exhausted.\n\n\nDefinition 3.1 (Infill Points) Infill points are strategically chosen new data points added to the surrogate model. They are selected to:\n\nReduce uncertainty in the model.\nImprove predictions in regions of interest.\nEnhance the model’s ability to identify optima or trends.\n\n\nThe selection of infill points is often guided by infill criteria, such as:\n\nExpected Improvement (EI): Maximizing the expected improvement over the current best solution.\nUncertainty Reduction: Sampling where the model’s predictions have high variance.\nProbability of Improvement (PI): Sampling where the probability of improving the current best solution is highest.\n\nThe iterative infill-points updating process ensures that the surrogate model becomes increasingly accurate and useful for optimization or decision-making tasks.\n\n\n\n\nForrester, Alexander, András Sóbester, and Andy Keane. 2008. Engineering Design via Surrogate Modelling. Wiley.\n\n\nSantner, T J, B J Williams, and W I Notz. 2003. The Design and Analysis of Computer Experiments. Berlin, Heidelberg, New York: Springer.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Simulation and Surrogate Modeling</span>"
    ]
  },
  {
    "objectID": "001_sampling.html",
    "href": "001_sampling.html",
    "title": "4  Sampling Plans",
    "section": "",
    "text": "4.1 Ideas and Concepts\nThe goal of a sampling plan is to efficiently explore the input space to understand the behavior of the computer code and build a surrogate model that accurately represents the code’s behavior. Traditionally, Response Surface Methodology (RSM) has been used to design sampling plans for computer experiments. These sampling plans are based on procedures that generate points by means of a rectangular grid or a factorial design.\nHowever, more recently, Design and Analysis of Computer Experiments (DACE) has emerged as a more flexible and powerful approach for designing sampling plans.\nEngineering design often requires the construction of a surrogate model \\(\\hat{f}\\) to approximate the expensive response of a black-box function \\(f\\). The function \\(f(x)\\) represents a continuous metric (e.g., quality, cost, or performance) defined over a design space \\(D \\subset \\mathbb{R}^k\\), where \\(x\\) is a \\(k\\)-dimensional vector of design variables. Since evaluating \\(f\\) is costly, only a sparse set of samples is used to construct \\(\\hat{f}\\), which can then provide inexpensive predictions for any \\(x \\in D\\).\nThe process involves:\nA sampling plan\n\\[\nX =\n\\left\\{\n  x^{(i)} \\in D | i = 1, \\ldots, n\n\\right\\}\n\\]\ndetermines the spatial arrangement of observations. While some models require a minimum number of data points \\(n\\), once this threshold is met, a surrogate model can be constructed to approximate \\(f\\) efficiently.\nA well-posed model does not always perform well because its ability to generalize depends heavily on the sampling plan used to collect data. If the sampling plan is poorly designed, the model may fail to capture critical behaviors in the design space. For example:",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Sampling Plans</span>"
    ]
  },
  {
    "objectID": "001_sampling.html#ideas-and-concepts",
    "href": "001_sampling.html#ideas-and-concepts",
    "title": "4  Sampling Plans",
    "section": "",
    "text": "Definition 4.1 (Sampling Plan) In the context of computer experiments, the term sampling plan refers to the set of input values, say \\(X\\),at which the computer code is evaluated.\n\n\n\n\n\n\nSampling discrete observations:\nUsing these samples to construct an approximation \\(\\hat{f}\\).\nEnsuring the surrogate model is well-posed, meaning it is mathematically valid and can generalize predictions effectively.\n\n\n\n\n\n\nExtreme Sampling: Measuring performance only at the extreme values of parameters may miss important behaviors in the center of the design space, leading to incomplete understanding.\nUneven Sampling: Concentrating samples in certain regions while neglecting others forces the model to extrapolate over unsampled areas, potentially resulting in inaccurate or misleading predictions. Additionally, in some cases, the data may come from external sources or be limited in scope, leaving little control over the sampling plan. This can further restrict the model’s ability to generalize effectively.\n\n\n4.1.1 The ‘Curse of Dimensionality’ and How to Avoid It\nThe “curse of dimensionality” refers to the exponential increase in computational complexity and data requirements as the number of dimensions (variables) in a problem grows. For a one-dimensional space, sampling \\(n\\) locations may suffice for accurate predictions. In high-dimensional spaces, the amount of data needed to maintain the same level of accuracy or coverage increases dramatically. For example, if a one-dimensional space requires \\(n\\) samples for a certain accuracy, a \\(k\\)-dimensional space would require \\(n^k\\) samples. This makes tasks like optimization, sampling, and modeling computationally expensive and often impractical in high-dimensional settings.\n\nExample 4.1 (Example: Curse of Dimensionality) Consider a simple example where we want to model the cost of a car tire based on its wheel diameter. If we have one variable (wheel diameter), we might need 10 simulations to get a good estimate of the cost. Now, if we add 8 more variables (e.g., tread pattern, rubber type, etc.), the number of simulations required increases to \\(10^8\\) (10 million). This is because the number of combinations of design variables grows exponentially with the number of dimensions. This means that the computational budget required to evaluate all combinations of design variables becomes infeasible. In this case, it would take 11,416 years to complete the simulations, making it impractical to explore the design space fully.\n\n\n\n4.1.2 Physical versus Computational Experiments\nPhysical experiments are prone to experimental errors from three main sources:\n\nHuman error: Mistakes made by the experimenter.\nRandom error: Measurement inaccuracies that vary unpredictably.\nSystematic error: Consistent bias due to flaws in the experimental setup.\n\nThe key distinction is repeatability: systematic errors remain constant across repetitions, while random errors vary.\nComputational experiments, on the other hand, are deterministic and free from random errors. However, they are still affected by:\n\nHuman error: Bugs in code or incorrect boundary conditions.\nSystematic error: Biases from model simplifications (e.g., inviscid flow approximations) or finite resolution (e.g., insufficient mesh resolution).\n\nThe term “noise” is used differently in physical and computational contexts. In physical experiments, it refers to random errors, while in computational experiments, it often refers to systematic errors.\nUnderstanding these differences is crucial for designing experiments and applying techniques like Gaussian process-based approximations. For physical experiments, replication mitigates random errors, but this is unnecessary for deterministic computational experiments.\n\n\n4.1.3 Designing Preliminary Experiments (Screening)\nMinimizing the number of design variables \\(x_1, x_2, \\dots, x_k\\) is crucial before modeling the objective function \\(f\\). This process, called screening, aims to reduce dimensionality without compromising the analysis. If \\(f\\) is at least once differentiable over the design domain \\(D\\), the partial derivative \\(\\frac{\\partial f}{\\partial x_i}\\) can be used to classify variables:\n\nNegligible Variables: If \\(\\frac{\\partial f}{\\partial x_i} = 0, \\, \\forall x \\in D\\), the variable \\(x_i\\) can be safely neglected.\nLinear Additive Variables: If \\(\\frac{\\partial f}{\\partial x_i} = \\text{constant} \\neq 0, \\, \\forall x \\in D\\), the effect of \\(x_i\\) is linear and additive.\nNonlinear Variables: If \\(\\frac{\\partial f}{\\partial x_i} = g(x_i), \\, \\forall x \\in D\\), where \\(g(x_i)\\) is a non-constant function, \\(f\\) is nonlinear in \\(x_i\\).\nInteractive Nonlinear Variables: If \\(\\frac{\\partial f}{\\partial x_i} = g(x_i, x_j, \\dots), /, \\forall x \\in D\\), where \\(g(x_i, x_j, \\dots)\\) is a function involving interactions with other variables, \\(f\\) is nonlinear in \\(x_i\\) and interacts with \\(x_j\\).\n\nMeasuring \\(\\frac{\\partial f}{\\partial x_i}\\) across the entire design space is often infeasible due to limited budgets. The percentage of time allocated to screening depends on the problem: If many variables are expected to be inactive, thorough screening can significantly improve model accuracy by reducing dimensionality. If most variables are believed to impact the objective, focus should shift to modeling instead. Screening is a trade-off between computational cost and model accuracy, and its effectiveness depends on the specific problem context.\n\n4.1.3.1 Estimating the Distribution of Elementary Effects\nIn order to simplify the presentation of what follows, we make, without loss of generality, the assumption that the design space \\(D = [0, 1]^k\\); that is, we normalize all variables into the unit cube. We shall adhere to this convention for the rest of the book and strongly urge the reader to do likewise when implementing any algorithms described here, as this step not only yields clearer mathematics in some cases but also safeguards against scaling issues.\nBefore proceeding with the description of the Morris algorithm, we need to define an important statistical concept. Let us restrict our design space \\(D\\) to a \\(k\\)-dimensional, \\(p\\)-level full factorial grid, that is,\n\\[\nx_i \\in \\{0, \\frac{1}{p-1}, \\frac{2}{p-1}, \\dots, 1\\}, \\quad \\text{ for } i = 1, \\dots, k.\n\\]\n\nDefinition 4.2 (Elementary Effect) For a given baseline value \\(x \\in D\\), let \\(d_i(x)\\) denote the elementary effect of \\(x_i\\), where:\n\\[\nd_i(x) = \\frac{f(x_1, \\dots, x_i + \\Delta, \\dots, x_k) - f(x_1, \\dots, x_i - \\Delta, \\dots, x_k)}{2\\Delta}, \\quad i = 1, \\dots, k,\n\\tag{4.1}\\] where \\(\\Delta\\) is the step size, which is defined as the distance between two adjacent levels in the grid. In other words, we have:\nwith \\[\\Delta = \\frac{\\xi}{p-1}, \\quad \\xi \\in \\mathbb{N}^*, \\quad \\text{and} \\quad x \\in D , \\text{ such that its components } x_i \\leq 1 - \\Delta.\n\\]\n\\(\\Delta\\) is the step size. The elementary effect \\(d_i(x)\\) measures the sensitivity of the function \\(f\\) to changes in the variable \\(x_i\\) at the point \\(x\\).\n\nMorris’s method aims to estimate the parameters of the distribution of elementary effects associated with each variable. A large measure of central tendency indicates that a variable has a significant influence on the objective function across the design space, while a large measure of spread suggests that the variable is involved in interactions or contributes to the nonlinearity of \\(f\\). In practice, the sample mean and standard deviation of a set of \\(d_i(x)\\) values, calculated in different parts of the design space, are used for this estimation.\nTo ensure efficiency, the preliminary sampling plan \\(X\\) should be designed so that each evaluation of the objective function \\(f\\) contributes to the calculation of two elementary effects, rather than just one (as would occur with a naive random spread of baseline \\(x\\) values and adding \\(\\Delta\\) to one variable). Additionally, the sampling plan should provide a specified number (e.g., \\(r\\)) of elementary effects for each variable, independently drawn with replacement. For a detailed discussion on constructing such a sampling plan, readers are encouraged to consult Morris’s original paper (Morris, 1991). Here, we focus on describing the process itself.\nThe random orientation of the sampling plan \\(B\\) can be constructed as follows:\n\nLet \\(B\\) be a \\((k+1) \\times k\\) matrix of 0s and 1s, where for each column \\(i\\), two rows differ only in their \\(i\\)-th entries.\nCompute a random orientation of \\(B\\), denoted \\(B^*\\):\n\n\\[\nB^* =\n\\left(\n1_{k+1,k} x^* + (\\Delta/2)\n\\left[\n(2B-1_{k+1,k})\nD^* +\n1_{k+1,k}\n\\right]\n\\right)\nP^*,\n\\]\nwhere:\n\n\\(D^*\\) is a \\(k\\)-dimensional diagonal matrix with diagonal elements \\(\\pm 1\\) (equal probability),\n\\(\\mathbf{1}\\) is a matrix of 1s,\n\\(x^*\\) is a randomly chosen point in the \\(p\\)-level design space (limited by \\(\\Delta\\)),\n\\(P^*\\) is a \\(k \\times k\\) random permutation matrix with one 1 per column and row.\n\nspotpython provides a Python implementation to compute \\(B^*\\), see https://github.com/sequential-parameter-optimization/spotPython/blob/main/src/spotpython/utils/effects.py.\nHere is the corresponding code:\n\ndef randorient(k, p, xi, seed=None):\n    # Initialize random number generator with the provided seed\n    if seed is not None:\n        rng = np.random.default_rng(seed)\n    else:\n        rng = np.random.default_rng()\n\n    # Step length\n    Delta = xi / (p - 1)\n\n    m = k + 1\n\n    # A truncated p-level grid in one dimension\n    xs = np.arange(0, 1 - Delta, 1 / (p - 1))\n    xsl = len(xs)\n    if xsl &lt; 1:\n        print(f\"xi = {xi}.\")\n        print(f\"p = {p}.\")\n        print(f\"Delta = {Delta}.\")\n        print(f\"p - 1 = {p - 1}.\")\n        raise ValueError(f\"The number of levels xsl is {xsl}, but it must be greater than 0.\")\n\n    # Basic sampling matrix\n    B = np.vstack((np.zeros((1, k)), np.tril(np.ones((k, k)))))\n\n    # Randomization\n\n    # Matrix with +1s and -1s on the diagonal with equal probability\n    Dstar = np.diag(2 * rng.integers(0, 2, size=k) - 1)\n\n    # Random base value\n    xstar = xs[rng.integers(0, xsl, size=k)]\n\n    # Permutation matrix\n    Pstar = np.zeros((k, k))\n    rp = rng.permutation(k)\n    for i in range(k):\n        Pstar[i, rp[i]] = 1\n\n    # A random orientation of the sampling matrix\n    Bstar = (np.ones((m, 1)) @ xstar.reshape(1, -1) +\n        (Delta / 2) * ((2 * B - np.ones((m, k))) @ Dstar +\n        np.ones((m, k)))) @ Pstar\n\n    return Bstar\n\nThe code following snippet generates a random orientation of a sampling matrix Bstar using the randorient() function. The input parameters are:\n\nk = 3: The number of design variables (dimensions).\np = 3: The number of levels in the grid for each variable.\nxi = 1: A parameter used to calculate the step size Delta.\n\nStep-size calculation is performed as follows: Delta = xi / (p - 1) = 1 / (3 - 1) = 0.5, which determines the spacing between levels in the grid.\nNext, random sampling matrix construction is computed:\n\nA truncated grid is created with levels [0, 0.5] (based on Delta).\nA basic sampling matrix B is constructed, which is a lower triangular matrix with 0s and 1s.\n\nThen, randomization is applied:\n\nDstar: A diagonal matrix with random entries of +1 or -1.\nxstar: A random starting point from the grid.\nPstar: A random permutation matrix.\n\nRandom orientation is applied to the basic sampling matrix B to create Bstar. This involves scaling, shifting, and permuting the rows and columns of B.\nThe final output is the matrix Bstar, which represents a random orientation of the sampling plan. Each row corresponds to a sampled point in the design space, and each column corresponds to a design variable.\n\nExample 4.2 (Random Orientation of the Sampling Matrix in 2-D)  \n\nk = 2\np = 3\nxi = 1\nBstar = randorient(k, p, xi, seed=123)\nprint(f\"Random orientation of the sampling matrix:\\n{Bstar}\")\n\nRandom orientation of the sampling matrix:\n[[0.5 0. ]\n [0.  0. ]\n [0.  0.5]]\n\n\nWe can visualize the random orientation of the sampling matrix in 2-D as shown in Figure 4.1.\n\nplt.figure(figsize=(6, 6))\nplt.scatter(Bstar[:, 0], Bstar[:, 1], color='blue', s=50, label='Hypercube Points')\nfor i in range(Bstar.shape[0]):\n    plt.text(Bstar[i, 0] + 0.01, Bstar[i, 1] + 0.01, str(i), fontsize=9)\nplt.xlim(-0.1, 1.1)\nplt.ylim(-0.1, 1.1)\nplt.xlabel('x1')\nplt.ylabel('x2')\nplt.grid()\n\n\n\n\n\n\n\nFigure 4.1: Random orientation of the sampling matrix in 2-D. The labels indicate the row index of the points.\n\n\n\n\n\n\n\nExample 4.3 (Random Orientation of the Sampling Matrix)  \n\nk = 3\np = 3\nxi = 1\nBstar = randorient(k, p, xi)\nprint(f\"Random orientation of the sampling matrix:\\n{Bstar}\")\n\nRandom orientation of the sampling matrix:\n[[0.  0.  0. ]\n [0.  0.5 0. ]\n [0.5 0.5 0. ]\n [0.5 0.5 0.5]]\n\n\n\nTo obtain \\(r\\) elementary effects for each variable, the screening plan is built from \\(r\\) random orientations:\n\\[\nX =\n\\begin{pmatrix}\nB^*_1 \\\\\nB^*_2 \\\\\n\\vdots \\\\\nB^*_r\n\\end{pmatrix}\n\\]\nThe function screeningplan() generates a screening plan by calling the randorient() function r times. It creates a list of random orientations and then concatenates them into a single array, which represents the screening plan. The screening plan implementation in Python is as follows (see https://github.com/sequential-parameter-optimization/spotPython/blob/main/src/spotpython/utils/effects.py):\n\ndef screeningplan(k, p, xi, r):\n    # Empty list to accumulate screening plan rows\n    X = []\n    for i in range(r):\n        X.append(randorient(k, p, xi))\n    # Concatenate list of arrays into a single array\n    X = np.vstack(X)\n    return X\n\nIt works like follows:\n\nThe value of the objective function \\(f\\) is computed for each row of the screening plan matrix \\(X\\). These values are stored in a column vector \\(t\\) of size \\((r * (k + 1)) \\times 1\\), where:\n\nr is the number of random orientations.\nk is the number of design variables.\n\n\nThe elementary effects are calculated using the following formula:\n\nFor each random orientation, adjacent rows of the screening plan matrix X and their corresponding function values from t are used.\nThese values are inserted into Equation 4.1 to compute elementary effects for each variable. An elementary effect measures the sensitivity of the objective function to changes in a specific variable.\n\nResults can be used for a statistical analysis. After collecting a sample of \\(r\\) elementary effects for each variable:\n\nThe sample mean (central tendency) is computed to indicate the overall influence of the variable.\nThe sample standard deviation (spread) is computed to capture variability, which may indicate interactions or nonlinearity.\n\nThe results (sample means and standard deviations) are plotted on a chart for comparison. This helps identify which variables have the most significant impact on the objective function and whether their effects are linear or involve interactions. This is implemented in the function screening_plot() in Python, which uses the helper function _screening() to calculate the elementary effects and their statistics.\n\ndef _screening(X, fun, xi, p, labels, bounds=None) -&gt; tuple:\n    \"\"\"Helper function to calculate elementary effects for a screening design.\n\n    Args:\n        X (np.ndarray): The screening plan matrix, typically structured\n            within a [0,1]^k box.\n        fun (object): The objective function to evaluate at each\n            design point in the screening plan.\n        xi (float): The elementary effect step length factor.\n        p (int): Number of discrete levels along each dimension.\n        labels (list of str): A list of variable names corresponding to\n            the design variables.\n        bounds (np.ndarray): A 2xk matrix where the first row contains\n            lower bounds and the second row contains upper bounds for\n            each variable.\n\n    Returns:\n        tuple: A tuple containing two arrays:\n            - sm: The mean of the elementary effects for each variable.\n            - ssd: The standard deviation of the elementary effects for\n            each variable.\n    \"\"\"\n    k = X.shape[1]\n    r = X.shape[0] // (k + 1)\n\n    # Scale each design point\n    t = np.zeros(X.shape[0])\n    for i in range(X.shape[0]):\n        if bounds is not None:\n            X[i, :] = bounds[0, :] + X[i, :] * (bounds[1, :] - bounds[0, :])\n        t[i] = fun(X[i, :])\n\n    # Elementary effects\n    F = np.zeros((k, r))\n    for i in range(r):\n        for j in range(i * (k + 1), i * (k + 1) + k):\n            idx = np.where(X[j, :] - X[j + 1, :] != 0)[0][0]\n            F[idx, i] = (t[j + 1] - t[j]) / (xi / (p - 1))\n\n    # Statistical measures (divide by n)\n    ssd = np.std(F, axis=1, ddof=0)\n    sm = np.mean(F, axis=1)\n    return sm, ssd\n\n\ndef screening_plot(X, fun, xi, p, labels, bounds=None, show=True) -&gt; None:\n    \"\"\"Generates a plot with elementary effect screening metrics.\n\n    This function calculates the mean and standard deviation of the\n    elementary effects for a given set of design variables and plots\n    the results.\n\n    Args:\n        X (np.ndarray):\n            The screening plan matrix, typically structured within a [0,1]^k box.\n        fun (object):\n            The objective function to evaluate at each design point in the screening plan.\n        xi (float):\n            The elementary effect step length factor.\n        p (int):\n            Number of discrete levels along each dimension.\n        labels (list of str):\n            A list of variable names corresponding to the design variables.\n        bounds (np.ndarray):\n            A 2xk matrix where the first row contains lower bounds and\n            the second row contains upper bounds for each variable.\n        show (bool):\n            If True, the plot is displayed. Defaults to True.\n\n    Returns:\n        None: The function generates a plot of the results.\n    \"\"\"\n    k = X.shape[1]\n    sm, ssd = _screening(X=X, fun=fun, xi=xi, p=p, labels=labels, bounds=bounds)\n    plt.figure()\n    for i in range(k):\n        plt.text(sm[i], ssd[i], labels[i], fontsize=10)\n    plt.axis([min(sm), 1.1 * max(sm), min(ssd), 1.1 * max(ssd)])\n    plt.xlabel(\"Sample means\")\n    plt.ylabel(\"Sample standard deviations\")\n    plt.gca().tick_params(labelsize=10)\n    plt.grid(True)\n    if show:\n        plt.show()\n\n\n\n\n4.1.4 Special Considerations When Deploying Screening Algorithms\nWhen implementing the screening algorithm described above, two specific scenarios require special attention:\n\nDuplicate Design Points: If the dimensionality \\(k\\) of the space is relatively low and you can afford a large number of elementary effects \\(r\\), we should be be aware of the increased probability of duplicate design points appearing in the sampling plan \\(X\\). *Since the responses at sample points are deterministic, there’s no value in evaluating the same point multiple times. Fortunately, this issue is relatively uncommon in practice, as screening high-dimensional spaces typically requires large numbers of elementary effects, which naturally reduces the likelihood of duplicates.\nFailed Simulations: Numerical simulation codes occasionally fail to return valid results due to meshing errors, non-convergence of partial differential equation solvers, numerical instabilities, or parameter combinations outside the stable operating range.\n\nFrom a screening perspective, this is particularly problematic because an entire random orientation \\(B^*\\) becomes compromised if even a single point within it fails to evaluate properly. Implementing error handling strategies or fallback methods to manage such cases should be considered.\nFor robust screening studies, monitoring simulation success rates and having contingency plans for failed evaluations are important aspects of the experimental design process.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Sampling Plans</span>"
    ]
  },
  {
    "objectID": "001_sampling.html#analyzing-variable-importance-in-aircraft-wing-weight",
    "href": "001_sampling.html#analyzing-variable-importance-in-aircraft-wing-weight",
    "title": "4  Sampling Plans",
    "section": "4.2 Analyzing Variable Importance in Aircraft Wing Weight",
    "text": "4.2 Analyzing Variable Importance in Aircraft Wing Weight\nLet us consider the following analytical expression used as a conceptual level estimate of the weight of a light aircraft wing as discussed in Chapter 1.\n\nfun = Analytical()\nk = 10\np = 10\nxi = 1\nr = 25\nX = screeningplan(k=k, p=p, xi=xi, r=r)  # shape (r x (k+1), k)\nvalue_range = np.array([\n    [150, 220,   6, -10, 16, 0.5, 0.08, 2.5, 1700, 0.025],\n    [200, 300,  10,  10, 45, 1.0, 0.18, 6.0, 2500, 0.08 ],\n])\nlabels = [\n    \"S_W\", \"W_fw\", \"A\", \"Lambda\",\n    \"q\",   \"lambda\", \"tc\", \"N_z\",\n    \"W_dg\", \"W_p\"\n]\nscreening_plot(\n    X=X,\n    fun=fun.fun_wingwt,\n    bounds=value_range,\n    xi=xi,\n    p=p,\n    labels=labels,\n)\n\n\n\n\n\n\n\nFigure 4.2: Estimated means and standard deviations of the elementary effects for the 10 design variables of the wing weight function. Example based on Forrester, Sóbester, and Keane (2008).\n\n\n\n\n\n\n\n\n\n\n\nNondeterministic Results\n\n\n\nThe code will generate a slightly different screening plan each time, as it uses random orientations of the sampling matrix \\(B\\).\n\n\nFigure 4.2 provides valuable insights into variable activity without requiring domain expertise. The screening study with \\(r = 25\\) elementary effects reveals distinct patterns in how variables affect wing weight:\n\nVariables with Minimal Impact: A clearly defined group of variables clusters around the origin - indicating their minimal impact on wing weight:\n\nPaint weight (\\(W_p\\)) - as expected, contributes little to overall wing weight\nDynamic pressure (\\(q\\)) - within our chosen range, this has limited effect (essentially representing different cruise altitudes at the same speed)\nTaper ratio (\\(\\lambda\\)) and quarter-chord sweep (\\(\\Lambda\\)) - these geometric parameters have minor influence within the narrow range (-10° to 10°) typical of light aircraft\n\nVariables with Linear Effects:\n\nWhile still close to the origin, fuel weight (\\(W_{fw}\\)) shows a slightly larger central tendency with very low standard deviation. This indicates moderate importance but minimal involvement in interactions with other variables.\n\nVariables with Nonlinear/Interactive Effects:\n\nAspect ratio (\\(A\\)) and airfoil thickness ratio (\\(R_{tc}\\)) show similar importance levels, but their high standard deviations suggest significant nonlinear behavior and interactions with other variables.\n\nDominant Variables: The most significant impacts come from:\n\nFlight design gross weight (\\(W_{dg}\\))\nWing area (\\(S_W\\))\nUltimate load factor (\\(N_z\\))\n\n\nThese variables show both large central tendency values and high standard deviations, indicating strong direct effects and complex interactions. The interaction between aspect ratio and load factor is particularly important - high values of both create extremely heavy wings, explaining why highly maneuverable fighter jets cannot use glider-like wing designs.\nWhat makes this screening approach valuable is its ability to identify critical variables without requiring engineering knowledge or expensive modeling. In real-world applications, we rarely have the luxury of creating comprehensive parameter space visualizations, which is precisely why surrogate modeling is needed. After identifying the active variables through screening, we can design a focused sampling plan for these key variables. This forms the foundation for building an accurate surrogate model of the objective function.\nWhen the objective function is particularly expensive to evaluate, we might recycle the runs performed during screening for the actual model fitting step. This is most effective when some variables prove to have no impact at all. However, since completely inactive variables are rare in practice, engineers must carefully balance the trade-off between reusing expensive simulation runs and introducing potential noise into the model.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Sampling Plans</span>"
    ]
  },
  {
    "objectID": "001_sampling.html#designing-a-sampling-plan",
    "href": "001_sampling.html#designing-a-sampling-plan",
    "title": "4  Sampling Plans",
    "section": "4.3 Designing a Sampling Plan",
    "text": "4.3 Designing a Sampling Plan\n\n4.3.1 Stratification\nA feature shared by all of the approximation models discussed in Forrester, Sóbester, and Keane (2008) is that they are more accurate in the vicinity of the points where we have evaluated the objective function. In later chapters we will delve into the laws that quantify our decaying trust in the model as we move away from a known, sampled point, but for the purposes of the present discussion we shall merely draw the intuitive conclusion that a uniform level of model accuracy throughout the design space requires a uniform spread of points. A sampling plan possessing this feature is said to be space-filling.\nThe most straightforward way of sampling a design space in a uniform fashion is by means of a rectangular grid of points. This is the full factorial sampling technique.\nHere is the simplified version of a Python function that will sample the unit hypercube at all levels in all dimensions, with the \\(k\\)-vector \\(q\\) containing the number of points required along each dimension, see https://github.com/sequential-parameter-optimization/spotPython/blob/main/src/spotpython/utils/sampling.py.\nThe variable Edges specifies whether we want the points to be equally spaced from edge to edge (Edges=1) or we want them to be in the centres of \\(n = q_1 \\times q_2 \\times \\ldots \\times q_k\\) bins filling the unit hypercube (for any other value of Edges).\n\ndef fullfactorial(q_param, Edges=1) -&gt; np.ndarray:\n    \"\"\"Generates a full factorial sampling plan in the unit cube.\n\n    Args:\n        q (list or np.ndarray):\n            A list or array containing the number of points along each dimension (k-vector).\n        Edges (int, optional):\n            Determines spacing of points. If `Edges=1`, points are equally spaced from edge to edge (default).\n            Otherwise, points will be in the centers of n = q[0]*q[1]*...*q[k-1] bins filling the unit cube.\n\n    Returns:\n        (np.ndarray): Full factorial sampling plan as an array of shape (n, k), where n is the total number of points and k is the number of dimensions.\n\n    Raises:\n        ValueError: If any dimension in `q` is less than 2.\n    \"\"\"\n    q_levels = np.array(q_param) # Use a distinct variable for original levels\n    if np.min(q_levels) &lt; 2:\n        raise ValueError(\"You must have at least two points per dimension.\")\n    \n    n = np.prod(q_levels)\n    k = len(q_levels)\n    X = np.zeros((n, k))\n    \n    # q_for_prod_calc is used for calculating repetitions, includes the phantom element.\n    # This matches the logic of the user-provided snippet where 'q' was modified.\n    q_for_prod_calc = np.append(q_levels, 1)\n\n    for j in range(k): # k is the original number of dimensions\n        # current_dim_levels is the number of levels for the current dimension j\n        # In the user's snippet, q[j] correctly refers to the original level count\n        # as j ranges from 0 to k-1, and q_for_prod_calc[j] = q_levels[j] for this range.\n        current_dim_levels = q_for_prod_calc[j] \n        \n        if Edges == 1:\n            one_d_slice = np.linspace(0, 1, int(current_dim_levels))\n        else:\n            # Corrected calculation for bin centers\n            if current_dim_levels == 1: # Should not be hit if np.min(q_levels) &gt;= 2\n                one_d_slice = np.array([0.5])\n            else:\n                one_d_slice = np.linspace(1 / (2 * current_dim_levels), \n                                          1 - 1 / (2 * current_dim_levels), \n                                          int(current_dim_levels))\n        \n        column = np.array([])\n        # The product q_for_prod_calc[j + 1 : k] correctly calculates \n        # the product of remaining original dimensions' levels.\n        num_consecutive_repeats = np.prod(q_for_prod_calc[j + 1 : k])\n        \n        # This loop structure replicates the logic from the user's snippet\n        while len(column) &lt; n:\n            for ll_idx in range(int(current_dim_levels)): # Iterate through levels of current dimension\n                val_to_repeat = one_d_slice[ll_idx]\n                column = np.append(column, np.ones(int(num_consecutive_repeats)) * val_to_repeat)\n        X[:, j] = column\n    return X\n\n\nq = [3, 2]\nX = fullfactorial(q, Edges=0)\nprint(X)\n\n[[0.16666667 0.25      ]\n [0.16666667 0.75      ]\n [0.5        0.25      ]\n [0.5        0.75      ]\n [0.83333333 0.25      ]\n [0.83333333 0.75      ]]\n\n\nFigure 4.3 shows the points in the unit hypercube for the case of 3x2 points.\n\n\n\n\n\n\n\n\nFigure 4.3: 2D Full Factorial Sampling (3x2 Points). Edges = 0\n\n\n\n\n\n\nX = fullfactorial(q, Edges=1)\nprint(X)\n\n[[0.  0. ]\n [0.  1. ]\n [0.5 0. ]\n [0.5 1. ]\n [1.  0. ]\n [1.  1. ]]\n\n\nFigure 4.4 shows the points in the unit hypercube for the case of 3x2 points with edges.\n\n\n\n\n\n\n\n\nFigure 4.4: 2D Full Factorial Sampling (3x2 Points). Edges = 1\n\n\n\n\n\nThe full factorial sampling plan method generates a uniform sampling design by creating a grid of points across all dimensions. For example, calling fullfactorial([3, 4, 5], 1) produces a three-dimensional sampling plan with 3, 4, and 5 levels along each dimension, respectively. While this approach satisfies the uniformity criterion, it has two significant limitations:\n\nRestricted Design Sizes: The method only works for designs where the total number of points \\(n\\) can be expressed as the product of the number of levels in each dimension, i.e., \\(n = q_1 \\times q_2 \\times \\cdots \\times q_k\\).\nOverlapping Projections: When the sampling points are projected onto individual axes, sets of points may overlap, reducing the effectiveness of the sampling plan. This can lead to non-uniform coverage in the projections, which may not fully represent the design space.\n\n\n\n4.3.2 Latin Squares and Random Latin Hypercubes\nTo improve the uniformity of projections for any individual variable, the range of that variable can be divided into a large number of equal-sized bins, and random subsamples of equal size can be generated within these bins. This method is called stratified random sampling. Extending this idea to all dimensions results in a stratified sampling plan, commonly implemented using Latin hypercube sampling.\n\nDefinition 4.3 (Latin Squares and Hypercubes) In the context of statistical sampling, a square grid containing sample positions is a Latin square if (and only if) there is only one sample in each row and each column. A Latin hypercube is the generalisation of this concept to an arbitrary number of dimensions, whereby each sample is the only one in each axis-aligned hyperplane containing it\n\nFor two-dimensional discrete variables, a Latin square ensures uniform projections. An \\((n \\times n)\\) Latin square is constructed by filling each row and column with a permutation of \\(\\{1, 2, \\dots, n\\}\\), ensuring each number appears only once per row and column.\n\nExample 4.4 (Latin Square) For \\(n = 4\\), a Latin square might look like this:\n2   1   3   4\n3   2   4   1\n1   4   2   3\n4   3   1   2\n\nLatin Hypercubes are the multidimensional extension of Latin squares. The design space is divided into equal-sized hypercubes (bins), and one point is placed in each bin. The placement ensures that moving along any axis from an occupied bin does not encounter another occupied bin. This guarantees uniform projections across all dimensions. To construct a Latin hypercube, the following steps are taken:\n\nRepresent the sampling plan as an \\(n \\times k\\) matrix \\(X\\), where \\(n\\) is the number of points and \\(k\\) is the number of dimensions.\nFill each column of \\(X\\) with random permutations of \\(\\{1, 2, \\dots, n\\}\\).\nNormalize the plan into the unit hypercube \\([0, 1]^k\\).\n\nThis approach ensures multidimensional stratification and uniformity in projections. Here is the code:\n\ndef rlh(n: int, k: int, edges: int = 0) -&gt; np.ndarray:\n    # Initialize array\n    X = np.zeros((n, k), dtype=float)\n\n    # Fill with random permutations\n    for i in range(k):\n        X[:, i] = np.random.permutation(n)\n\n    # Adjust normalization based on the edges flag\n    if edges == 1:\n        # [X=0..n-1] -&gt; [0..1]\n        X = X / (n - 1)\n    else:\n        # Points at true midpoints\n        # [X=0..n-1] -&gt; [0.5/n..(n-0.5)/n]\n        X = (X + 0.5) / n\n\n    return X\n\n\nExample 4.5 (Random Latin Hypercube) The following code can be used to generate a 2D Latin hypercube with 5 points and edges=0:\n\nX = rlh(n=5, k=2, edges=0)\nprint(X)\n\n[[0.1 0.3]\n [0.5 0.1]\n [0.7 0.5]\n [0.9 0.9]\n [0.3 0.7]]\n\n\nFigure 4.5 shows the points in the unit hypercube for the case of 5 points with edges=0.\n\n\n\n\n\n\n\n\nFigure 4.5: 2D Latin Hypercube Sampling (5 Points, Edges=0)\n\n\n\n\n\n\n\nExample 4.6 (Random Latin Hypercube with Edges) The following code can be used to generate a 2D Latin hypercube with 5 points and edges=1:\n\nX = rlh(n=5, k=2, edges=1)\nprint(X)\n\n[[0.   1.  ]\n [0.75 0.  ]\n [0.5  0.25]\n [0.25 0.5 ]\n [1.   0.75]]\n\n\nFigure 4.6 shows the points in the unit hypercube for the case of 5 points with edges=1.\n\n\n\n\n\n\n\n\nFigure 4.6: 2D Latin Hypercube Sampling (5 Points, Edges=1)\n\n\n\n\n\n\n\n\n4.3.3 Space-filling Designs: Maximin Plans\nA widely adopted measure for assessing the uniformity, or ‘space-fillingness’, of a sampling plan is the maximin metric, initially proposed by Johnson, Moore, and Ylvisaker (1990). This criterion can be formally defined as follows.\nConsider a sampling plan \\(X\\). Let \\(d_1, d_2, \\ldots, d_m\\) represent the unique distances between all possible pairs of points within \\(X\\), arranged in ascending order. Furthermore, let \\(J_1, J_2, \\ldots, J_m\\) be defined such that \\(J_j\\) denotes the count of point pairs in \\(X\\) separated by the distance \\(d_j\\).\n\nDefinition 4.4 (Maximin plan) A sampling plan \\(X\\) is considered a maximin plan if, among all candidate plans, it maximizes the smallest inter-point distance \\(d_1\\). Among plans that satisfy this condition, it further minimizes \\(J_1\\), the number of pairs separated by this minimum distance.\n\nWhile this definition is broadly applicable to any collection of sampling plans, our focus is narrowed to Latin hypercube designs to preserve their desirable stratification properties. However, even within this restricted class, Definition 4.4 may identify multiple equivalent maximin designs. To address this, a more comprehensive ‘tie-breaker’ definition, as proposed by Morris and Mitchell (1995), is employed:\n\nDefinition 4.5 (Maximin plan with tie-breaker) A sampling plan \\(X\\) is designated as the maximin plan if it sequentially optimizes the following conditions: it maximizes \\(d_1\\); among those, it minimizes \\(J_1\\); among those, it maximizes \\(d_2\\); among those, it minimizes \\(J_2\\); and so forth, concluding with minimizing \\(J_m\\).\n\nJohnson, Moore, and Ylvisaker (1990) established that the maximin criterion (Definition 4.4) is equivalent to the D-optimality criterion used in linear regression. However, the extended maximin criterion incorporating a tie-breaker (Definition 57.3) is often preferred due to its intuitive nature and practical utility. Given that the sampling plans under consideration make no assumptions about model structure, the latter criterion (Definition 57.3) will be employed.\nTo proceed, a precise definition of ‘distance’ within these contexts is necessary. The p-norm is the most widely adopted metric for this purpose:\n\nDefinition 4.6 (p-norm) The p-norm of a vector \\(\\vec{x} = (x_1, x_2, \\ldots, x_k)\\) is defined as:\n\\[\nd_p(\\vec{x}^{(i_1)}, \\vec{x}^{(i_2)}) = \\left( \\sum_{j=1}^k |x_j^{(i_1)} - x_j^{(i_2)}|^p \\right)^{1/p}.\n\\tag{4.2}\\]\n\nWhen \\(p = 1\\), Equation 4.2 defines the rectangular distance, occasionally referred to as the Manhattan norm (an allusion to a grid-like city layout). Setting \\(p = 2\\) yields the Euclidean norm. The existing literature offers limited evidence to suggest the superiority of one norm over the other for evaluating sampling plans when no model structure assumptions are made. It is important to note, however, that the rectangular distance is considerably less computationally demanding. This advantage can be quite significant, particularly when evaluating large sampling plans.\nFor the computational implementation of Definition 57.3, the initial step involves constructing the vectors \\(d_1, d_2, \\ldots, d_m\\) and \\(J_1, J_2, \\ldots, J_m\\). The jd function facilitates this task.\n\n4.3.3.1 The Function jd\nThe function jd computes the distinct p-norm distances between all pairs of points in a given set and counts their occurrences. It returns two arrays: one for the distinct distances and another for their multiplicities.\n\ndef jd(X: np.ndarray, p: float = 1.0) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Args:\n        X (np.ndarray):\n            A 2D array of shape (n, d) representing n points\n            in d-dimensional space.\n        p (float, optional):\n            The distance norm to use.\n            p=1 uses the Manhattan (L1) norm, while p=2 uses the\n            Euclidean (L2) norm. Defaults to 1.0 (Manhattan norm).\n\n    Returns:\n        (np.ndarray, np.ndarray):\n            A tuple (J, distinct_d), where:\n            - distinct_d is a 1D float array of unique,\n            sorted distances between points.\n            - J is a 1D integer array that provides\n            the multiplicity (occurrence count)\n            of each distance in distinct_d.\n    \"\"\"\n    n = X.shape[0]\n\n    # Allocate enough space for all pairwise distances\n    # (n*(n-1))/2 pairs for an n-point set\n    pair_count = n * (n - 1) // 2\n    d = np.zeros(pair_count, dtype=float)\n\n    # Fill the distance array\n    idx = 0\n    for i in range(n - 1):\n        for j in range(i + 1, n):\n            # Compute the p-norm distance\n            d[idx] = np.linalg.norm(X[i] - X[j], ord=p)\n            idx += 1\n\n    # Find unique distances and their multiplicities\n    distinct_d = np.unique(d)\n    J = np.zeros_like(distinct_d, dtype=int)\n    for i, val in enumerate(distinct_d):\n        J[i] = np.sum(d == val)\n    return J, distinct_d\n\n\nExample 4.7 (The Function jd) Consider a small 3-point set in 2D space, with points located at (0,0), (1,1), and (2,2) as shown in Figure 4.7. The distinct distances and their occurrences can be computed using the jd function, as shown in the following code:\n\n\n\n\n\n\n\n\nFigure 4.7: 3-Point Set in 2D Space\n\n\n\n\n\n\nJ, distinct_d = jd(X, p=2.0)\nprint(\"Distinct distances (d_i):\", distinct_d)\nprint(\"Occurrences (J_i):\", J)\n\nDistinct distances (d_i): [1.41421356 2.82842712]\nOccurrences (J_i): [2 1]\n\n\n\n\n\n\n4.3.4 Memory Management\nA computationally intensive part of the calculation performed with the jd-function is the creation of the vector \\(\\vec{d}\\) containing all pairwise distances. This is particularly true for large sampling plans; for instance, a 1000-point plan requires nearly half a million distance calculations.\n\nDefinition 4.7 (Pre-allocation of Memory) Pre-allocation of memory is a programming technique where a fixed amount of memory is reserved for a data structure (like an array or vector) before it is actually filled with data. This is done to avoid the computational overhead associated with dynamic memory allocation, which involves repeatedly requesting and resizing memory as new elements are added.\n\nConsequently, pre-allocating memory for the distance vector \\(\\vec{d}\\) is essential. This necessitates a slightly less direct method for computing the indices of \\(\\vec{d}\\), rather than appending each new element, which would involve costly dynamic memory allocation.\nThe implementation of Definition 57.3 is now required. Finding the most space-filling design involves pairwise comparisons. This problem can be approached using a ‘divide and conquer’ strategy, simplifying it to the task of selecting the better of two sampling plans. The function mm(X1,X2,p) is designed for this purpose. It returns an index indicating which of the two designs is more space-filling, or 0 if they are equally space-filling, based on the \\(p\\)-norm for distance computation.\n\n4.3.4.1 The Function mm\nThe function mm compares two sampling plans based on the Morris-Mitchell criterion. It uses the jd function to compute the distances and multiplicities, constructs vectors for comparison, and determines which plan is more space-filling.\n\ndef mm(X1: np.ndarray, X2: np.ndarray, p: Optional[float] = 1.0) -&gt; int:\n    \"\"\"\n    Args:\n        X1 (np.ndarray): A 2D array representing the first sampling plan.\n        X2 (np.ndarray): A 2D array representing the second sampling plan.\n        p (float, optional): The distance metric. p=1 uses Manhattan (L1) distance,\n            while p=2 uses Euclidean (L2). Defaults to 1.0.\n\n    Returns:\n        int:\n            - 0 if both plans are identical or equally space-filling\n            - 1 if X1 is more space-filling\n            - 2 if X2 is more space-filling\n    \"\"\"\n    X1_sorted = X1[np.lexsort(np.rot90(X1))]\n    X2_sorted = X2[np.lexsort(np.rot90(X2))]\n    if np.array_equal(X1_sorted, X2_sorted):\n        return 0  # Identical sampling plans\n\n    # Compute distance multiplicities for each plan\n    J1, d1 = jd(X1, p)\n    J2, d2 = jd(X2, p)\n    m1, m2 = len(d1), len(d2)\n\n    # Construct V1 and V2: alternate distance and negative multiplicity\n    V1 = np.zeros(2 * m1)\n    V1[0::2] = d1\n    V1[1::2] = -J1\n\n    V2 = np.zeros(2 * m2)\n    V2[0::2] = d2\n    V2[1::2] = -J2\n\n    # Trim the longer vector to match the size of the shorter\n    m = min(m1, m2)\n    V1 = V1[:m]\n    V2 = V2[:m]\n\n    # Compare element-by-element:\n    # c[i] = 1 if V1[i] &gt; V2[i], 2 if V1[i] &lt; V2[i], 0 otherwise.\n    c = (V1 &gt; V2).astype(int) + 2 * (V1 &lt; V2).astype(int)\n\n    if np.sum(c) == 0:\n        # Equally space-filling\n        return 0\n    else:\n        # The first non-zero entry indicates which plan is better\n        idx = np.argmax(c != 0)\n        return c[idx]\n\n\nExample 4.8 (The Function mm) We can use the mm function to compare two sampling plans. The following code creates two 3-point sampling plans in 2D (shown in Figure 4.8) and compares them using the Morris-Mitchell criterion:\n\nX1 = np.array([[0.0, 0.0],[0.5, 0.5],[0.0, 1.0], [1.0, 1.0]])\nX2 = np.array([[0.1, 0.1],[0.4, 0.6],[0.1, 0.9], [0.9, 0.9]])\n\n\n\n\n\n\n\n\n\nFigure 4.8: Comparison of Two Sampling Plans\n\n\n\n\n\nWe can compare which plan has better space-filling (Morris-Mitchell). The output is either 0, 1, or 2 depending on which plan is more space-filling.\n\nbetter = mm(X1, X2, p=2.0)\nprint(f\"Plan {better} is more space-filling.\")\n\nPlan 1 is more space-filling.\n\n\n\n\n\n4.3.4.2 The Function mmphi\nSearching across a space of potential sampling plans can be accomplished by pairwise comparisons. An optimization algorithm could, in theory, be written with mm as the comparative objective. However, experimental evidence (Morris and Mitchell 1995) suggests that the resulting optimization landscape can be quite deceptive, making it difficult to search reliably. This difficulty arises because the comparison process terminates upon finding the first non-zero element in the comparison array c. Consequently, the remaining values in the distance (\\(d_1, d_2, ..., d_m\\)) and multiplicity (\\(J_1, J_2, ..., J_m\\)) arrays are disregarded. These disregarded values, however, might contain potentially useful ‘slope’ information about the global landscape for the optimization process.\nTo address this, Morris and Mitchell (1995) defined the following scalar-valued criterion function, which is used to rank competing sampling plans. This function, while based on the logic of Definition 57.3, incorporates the complete vectors \\(d_1, d_2, ..., d_m\\) and \\(J_1, J_2, ..., J_m\\).\n\nDefinition 4.8 (Morris-Mitchell Criterion) The Morris-Mitchell criterion is defined as:\n\\[\n\\Phi_q (X) = \\left(\\sum_{j=1}^m J_j d_j^{-q}\\right)^{1/q},\n\\tag{4.3}\\]\nwhere \\(X\\) is the sampling plan, \\(d_j\\) is the distance between points, \\(J_j\\) is the multiplicity of that distance, and \\(q\\) is a user-defined exponent. The parameter \\(q\\) can be adjusted to control the influence of smaller distances on the overall metric.\n\nThe smaller the value of \\(\\Phi_q\\), the better the space-filling properties of \\(X\\) will be.\nThe function mmphi computes the Morris-Mitchell sampling plan quality criterion for a given sampling plan. It takes a 2D array of points and calculates the space-fillingness metric based on the distances between points. This can be implemented in Python as follows:\n\ndef mmphi(X: np.ndarray,\n          q: Optional[float] = 2.0,\n          p: Optional[float] = 1.0) -&gt; float:\n    \"\"\"\n    Args:\n        X (np.ndarray):\n            A 2D array representing the sampling plan,\n            where each row is a point in\n            d-dimensional space (shape: (n, d)).\n        q (float, optional):\n            Exponent used in the computation of the metric.\n            Defaults to 2.0.\n        p (float, optional):\n            The distance norm to use.\n            For example, p=1 is Manhattan (L1),\n            p=2 is Euclidean (L2). Defaults to 1.0.\n\n    Returns:\n        float:\n            The space-fillingness metric Phiq. Larger values typically indicate a more\n            space-filling plan according to the Morris-Mitchell criterion.\n    \"\"\"\n    # Compute the distance multiplicities: J, and unique distances: d\n    J, d = jd(X, p)\n    # Summation of J[i] * d[i]^(-q), then raised to 1/q\n    # This follows the Morris-Mitchell definition.\n    Phiq = np.sum(J * (d ** (-q))) ** (1.0 / q)\n    return Phiq\n\n\nExample 4.9 (The Function mmphi) We can use the mmphi function to evaluate the space-filling quality of the two sampling plans from Example 4.8. The following code uses these two 3-point sampling plans in 2D and computes their quality using the Morris-Mitchell criterion:\n\n# Two simple sampling plans from above\nquality1 = mmphi(X1, q=2, p=2)\nquality2 = mmphi(X2, q=2, p=2)\nprint(f\"Quality of sampling plan X1:  {quality1}\")\nprint(f\"Quality of sampling plan X2:  {quality2}\")\n\nQuality of sampling plan X1:  2.91547594742265\nQuality of sampling plan X2:  3.917162046269215\n\n\n\nThis equation provides a more compact representation of the maximin criterion, but the selection of the \\(q\\) value is an important consideration. Larger values of \\(q\\) ensure that terms in the sum corresponding to smaller inter-point distances (the \\(d_j\\) values, which are sorted in ascending order) have a dominant influence. As a result, \\(\\Phi_q\\) will rank sampling plans in a way that closely emulates the original maximin definition (Definition 57.3). This implies that the optimization landscape might retain the challenging characteristics that the \\(\\Phi_q\\) metric, especially with smaller \\(q\\) values, is intended to alleviate. Conversely, smaller \\(q\\) values tend to produce a \\(\\Phi_q\\) landscape that, while not perfectly aligning with the original definition, is generally more conducive to optimization.\nTo illustrate the relationship between Equation 4.3 and the maximin criterion of Definition 57.3, sets of 50 random Latin hypercubes of varying sizes and dimensionalities were considered by Forrester, Sóbester, and Keane (2008). The correlation plots from this analysis suggest that as the sampling plan size increases, a smaller \\(q\\) value is needed for the \\(\\Phi_q\\)-based ranking to closely match the ranking derived from Definition 57.3.\nRankings based on both the direct maximin comparison (mm) and the \\(\\Phi_q\\) metric (mmphi), determined using a simple bubble sort algorithm, are implemented in the Python function mmsort.\n\n\n4.3.4.3 The Function mmsort\nThe function mmsort is designed to rank multiple sampling plans based on their space-filling properties using the Morris-Mitchell criterion. It takes a 3D array of sampling plans and returns the indices of the plans sorted in ascending order of their space-filling quality.\n\ndef mmsort(X3D: np.ndarray, p: Optional[float] = 1.0) -&gt; np.ndarray:\n    \"\"\"\n    Args:\n        X3D (np.ndarray):\n            A 3D NumPy array of shape (n, d, m), where m is the number of\n            sampling plans, and each plan is an (n, d) matrix of points.\n        p (float, optional):\n            The distance metric to use. p=1 for Manhattan (L1), p=2 for\n            Euclidean (L2). Defaults to 1.0.\n\n    Returns:\n        np.ndarray:\n            A 1D integer array of length m that holds the plan indices in\n            ascending order of space-filling quality. The first index in the\n            returned array corresponds to the most space-filling plan.\n    \"\"\"\n    # Number of plans (m)\n    m = X3D.shape[2]\n\n    # Create index array (1-based to match original MATLAB convention)\n    Index = np.arange(1, m + 1)\n\n    swap_flag = True\n    while swap_flag:\n        swap_flag = False\n        i = 0\n        while i &lt; m - 1:\n            # Compare plan at Index[i] vs. Index[i+1] using mm()\n            # Note: subtract 1 from each index to convert to 0-based array indexing\n            if mm(X3D[:, :, Index[i] - 1], X3D[:, :, Index[i + 1] - 1], p) == 2:\n                # Swap indices if the second plan is more space-filling\n                Index[i], Index[i + 1] = Index[i + 1], Index[i]\n                swap_flag = True\n            i += 1\n\n    return Index\n\n\nExample 4.10 (The Function mmsort) The mmsort function can be used to rank multiple sampling plans based on their space-filling properties. The following code demonstrates how to use mmsort to compare two 3-point sampling plans in 3D space:\nSuppose we have two 3-point sampling plans X1 and X1 from above. They are sorted using the Morris-Mitchell criterion with \\(p=2.0\\). For example, the output [1, 2] indicates that X1 is more space-filling than X2:\n\nX3D = np.stack([X1, X2], axis=2)\nranking = mmsort(X3D, p=2.0)\nprint(ranking)\n\n[1 2]\n\n\n\nTo determine the optimal Latin hypercube for a specific application, a recommended approach by Morris and Mitchell (1995) involves minimizing \\(\\Phi_q\\) for a set of \\(q\\) values (1, 2, 5, 10, 20, 50, and 100). Subsequently, the best plan from these results is selected based on the actual maximin definition. The mmsort function can be utilized for this purpose: a 3D matrix, X3D, can be constructed where each 2D slice represents the best sampling plan found for each \\(\\Phi_q\\). Applying mmsort(X3D,1) then ranks these plans according to Definition 57.3, using the rectangular distance metric. The subsequent discussion will address the methods for finding these optimized \\(\\Phi_q\\) designs.\n\n\n4.3.4.4 The Function phisort\nphisort only differs from mmsort in having \\(q\\) as an additional argument, as well as the comparison line being:\nif mmphi(X3D[:, :, Index[i] - 1], q=q, p=p) &gt;\n    mmphi(X3D[:, :, Index[i + 1] - 1], q=q, p=p):\n\ndef phisort(X3D: np.ndarray,\n            q: Optional[float] = 2.0,\n            p: Optional[float] = 1.0) -&gt; np.ndarray:\n    \"\"\"\n    Args:\n        X3D (np.ndarray):\n            A 3D array of shape (n, d, m),\n            where m is the number of sampling plans.\n        q (float, optional):\n            Exponent for the mmphi metric. Defaults to 2.0.\n        p (float, optional):\n            Distance norm for mmphi.\n            p=1 is Manhattan; p=2 is Euclidean.\n            Defaults to 1.0.\n\n    Returns:\n        np.ndarray:\n            A 1D integer array of length m, giving the plan indices in ascending\n            order of mmphi. The first index in the returned array corresponds\n            to the numerically lowest mmphi value.\n    \"\"\"\n    # Number of 2D sampling plans\n    m = X3D.shape[2]\n    # Create a 1-based index array\n    Index = np.arange(1, m + 1)\n    # Bubble-sort: plan with lower mmphi() climbs toward the front\n    swap_flag = True\n    while swap_flag:\n        swap_flag = False\n        for i in range(m - 1):\n            # Retrieve mmphi values for consecutive plans\n            val_i = mmphi(X3D[:, :, Index[i] - 1], q=q, p=p)\n            val_j = mmphi(X3D[:, :, Index[i + 1] - 1], q=q, p=p)\n\n            # Swap if the left plan's mmphi is larger (i.e. 'worse')\n            if val_i &gt; val_j:\n                Index[i], Index[i + 1] = Index[i + 1], Index[i]\n                swap_flag = True\n    return Index\n\n\nExample 4.11 (The Function phisort) The phisort function can be used to rank multiple sampling plans based on the Morris-Mitchell criterion. The following code demonstrates how to use phisort to compare two 3-point sampling plans in 3D space:\n\nX1 = bestlh(n=5, k=2, population=5, iterations=10)\nX2 = bestlh(n=5, k=2, population=15, iterations=20)\nX3 = bestlh(n=5, k=2, population=25, iterations=30)\n# Map X1 and X2 so that X3D has the two sampling plans\n# in X3D[:, :, 0] and X3D[:, :, 1]\nX3D = np.array([X1, X2])\nprint(phisort(X3D))\nX3D = np.array([X3, X2])\nprint(phisort(X3D))\n\n[1 2]\n[2 1]\n\n\n\n\n\n\n4.3.5 Optimizing the Morris-Mitchell Criterion \\(\\Phi_q\\)\nOnce a criterion for assessing the quality of a Latin hypercube sampling plan has been established, a systematic method for optimizing this metric across the space of Latin hypercubes is required. This task is non-trivial; as the reader may recall from the earlier discussion on Latin squares, this search space is vast. In fact, its vastness means that for many practical applications, locating the globally optimal solution is often infeasible. Therefore, the objective becomes finding the best possible sampling plan achievable within a specific computational time budget.\nThis budget is influenced by the computational cost associated with obtaining each objective function value. Determining the optimal allocation of total computational effort—between generating the sampling plan and actually evaluating the objective function at the selected points—remains an open research question. However, it is typical for no more than approximately 5% of the total available time to be allocated to the task of generating the sampling plan itself.\nForrester, Sóbester, and Keane (2008) draw an analogy to the process of devising a revision timetable before an exam. While a well-structured timetable enhances the effectiveness of revision, an excessive amount of the revision time itself should not be consumed by the planning phase.\nA significant challenge in devising a sampling plan optimizer is ensuring that the search process remains confined to the space of valid Latin hypercubes. As previously discussed, the defining characteristic of a Latin hypercube \\(X\\) is that each of its columns represents a permutation of the possible levels for the corresponding variable. Consequently, the smallest modification that can be applied to a Latin hypercube—without compromising its crucial multidimensional stratification property—involves swapping two elements within any single column of \\(X\\). A Python implementation for ‘mutating’ a Latin hypercube through such an operation, generalized to accommodate random changes applied to multiple sites, is provided below:\n\n4.3.5.1 The Function perturb()\nThe function perturb randomly swaps elements in a Latin hypercube sampling plan. It takes a 2D array representing the sampling plan and performs a specified number of random element swaps, ensuring that the result remains a valid Latin hypercube.\n\ndef perturb(X: np.ndarray,\n            PertNum: Optional[int] = 1) -&gt; np.ndarray:\n    \"\"\"\n    Args:\n        X (np.ndarray):\n            A 2D array (sampling plan) of shape (n, k),\n            where each row is a point\n            and each column is a dimension.\n        PertNum (int, optional):\n            The number of element swaps (perturbations)\n            to perform. Defaults to 1.\n\n    Returns:\n        np.ndarray:\n            The perturbed sampling plan,\n            identical in shape to the input, with\n            one or more random column swaps executed.\n    \"\"\"\n    # Get dimensions of the plan\n    n, k = X.shape\n    if n &lt; 2 or k &lt; 2:\n        raise ValueError(\"Latin hypercubes require at least 2 points and 2 dimensions\")\n    for _ in range(PertNum):\n        # Pick a random column\n        col = int(np.floor(np.random.rand() * k))\n        # Pick two distinct row indices\n        el1, el2 = 0, 0\n        while el1 == el2:\n            el1 = int(np.floor(np.random.rand() * n))\n            el2 = int(np.floor(np.random.rand() * n))\n        # Swap the two selected elements in the chosen column\n        X[el1, col], X[el2, col] = X[el2, col], X[el1, col]\n    return X\n\n\nExample 4.12 (The Function perturb()) The perturb function can be used to randomly swap elements in a Latin hypercube sampling plan. The following code demonstrates how to use perturb to create a perturbed version of a 4x2 sampling plan:\n\nX_original = np.array([[1, 3],[2, 4],[3, 1],[4, 2]])\nprint(\"Original Sampling Plan:\")\nprint(X_original)\nprint(\"Perturbed Sampling Plan:\")\nX_perturbed = perturb(X_original, PertNum=1)\nprint(X_perturbed)\n\nOriginal Sampling Plan:\n[[1 3]\n [2 4]\n [3 1]\n [4 2]]\nPerturbed Sampling Plan:\n[[2 3]\n [1 4]\n [3 1]\n [4 2]]\n\n\n\nForrester, Sóbester, and Keane (2008) uses the term ‘mutation’, because this problem lends itself to nature-inspired computation. Morris and Mitchell (1995) use a simulated annealing algorithm, the detailed pseudocode of which can be found in their paper. As an alternative, a method based on evolutionary operation (EVOP) is offered by Forrester, Sóbester, and Keane (2008).\n\n\n\n4.3.6 Evolutionary Operation\nAs introduced by Box (1957), evolutionary operation was designed to optimize chemical processes. The current parameters of the reaction would be recorded in a box at the centre of a board, with a series of ‘offspring’ boxes along the edges containing values of the parameters slightly altered with respect to the central, ‘parent’ values. Once the reaction was completed for all of these sets of variable values and the corresponding yields recorded, the contents of the central box would be replaced with that of the setup with the highest yield and this would then become the parent of a new set of peripheral boxes.\nThis is generally viewed as a local search procedure, though this depends on the mutation step sizes, that is on the differences between the parent box and its offspring. The longer these steps, the more global is the scope of the search.\nFor the purposes of the Latin hypercube search, a variable scope strategy is applied. The process starts with a long step length (that is a relatively large number of swaps within the columns) and, as the search progresses, the current best basin of attraction is gradually approached by reducing the step length to a single change.\nIn each generation the parent is mutated (randomly, using the perturb function) a pertnum number of times. The sampling plan that yields the smallest \\(\\Phi_q\\) value (as per the Morris-Mitchell criterion, calculated usingmmphi) among all offspring and the parent is then selected; in evolutionary computation parlance this selection philosophy is referred to as elitism.\nThe EVOP based search for space-filling Latin hypercubes is thus a truly evolutionary process: the optimized sampling plan results from the nonrandom survival of random variations.\n\n\n4.3.7 Putting it all Together\nAll the pieces of the optimum Latin hypercube sampling process puzzle are now in place: the random hypercube generator as a starting point for the optimization process, the ‘spacefillingness’ metric that needs to be optimized, the optimization engine that performs this task and the comparison function that selects the best of the optima found for the various \\(q\\)’s. These pieces just need to be put into a sequence. Here is the Python embodiment of the completed puzzle. It results in a function bestlh that uses the function mmlhs to find the best Latin hypercube sampling plan for a given set of parameters.\n\n4.3.7.1 The Function mmlhs\nPerforms an evolutionary search (using perturbations) to find a Morris-Mitchell optimal Latin hypercube, starting from an initial plan X_start.\nThis function does the following:\n\nInitializes a “best” Latin hypercube (X_best) from the provided X_start.\nIteratively perturbs X_best to create offspring.\nEvaluates the space-fillingness of each offspring via the Morris-Mitchell metric (using mmphi).\nUpdates the best plan whenever a better offspring is found.\n\n\ndef mmlhs(X_start: np.ndarray,\n          population: int,\n          iterations: int,\n          q: Optional[float] = 2.0,\n          plot=False) -&gt; np.ndarray:\n    \"\"\"\n    Args:\n        X_start (np.ndarray):\n            A 2D array of shape (n, k) providing the initial Latin hypercube\n            (n points in k dimensions).\n        population (int):\n            Number of offspring to create in each generation.\n        iterations (int):\n            Total number of generations to run the evolutionary search.\n        q (float, optional):\n            The exponent used by the Morris-Mitchell space-filling criterion.\n            Defaults to 2.0.\n        plot (bool, optional):\n            If True, a simple scatter plot of the first two dimensions will be\n            displayed at each iteration. Only if k &gt;= 2. Defaults to False.\n\n    Returns:\n        np.ndarray:\n            A 2D array representing the most space-filling Latin hypercube found\n            after all iterations, of the same shape as X_start.\n    \"\"\"\n    n = X_start.shape[0]\n    if n &lt; 2:\n        raise ValueError(\"Latin hypercubes require at least 2 points\")\n    k = X_start.shape[1]\n    if k &lt; 2:\n        raise ValueError(\"Latin hypercubes are not defined for dim k &lt; 2\")\n    # Initialize best plan and its metric\n    X_best = X_start.copy()\n    Phi_best = mmphi(X_best, q=q)\n    # After 85% of iterations, reduce the mutation rate to 1\n    leveloff = int(np.floor(0.85 * iterations))\n    for it in range(1, iterations + 1):\n        # Decrease number of mutations over time\n        if it &lt; leveloff:\n            mutations = int(round(1 + (0.5 * n - 1) * (leveloff - it) / (leveloff - 1)))\n        else:\n            mutations = 1\n        X_improved = X_best.copy()\n        Phi_improved = Phi_best\n        # Create offspring, evaluate, and keep the best\n        for _ in range(population):\n            X_try = perturb(X_best.copy(), mutations)\n            Phi_try = mmphi(X_try, q=q)\n\n            if Phi_try &lt; Phi_improved:\n                X_improved = X_try\n                Phi_improved = Phi_try\n        # Update the global best if we found a better plan\n        if Phi_improved &lt; Phi_best:\n            X_best = X_improved\n            Phi_best = Phi_improved\n        # Simple visualization of the first two dimensions\n        if plot and (X_best.shape[1] &gt;= 2):\n            plt.clf()\n            plt.scatter(X_best[:, 0], X_best[:, 1], marker=\"o\")\n            plt.grid(True)\n            plt.title(f\"Iteration {it} - Current Best Plan\")\n            plt.pause(0.01)\n    return X_best\n\n\nExample 4.13 (The Function mmlhs) The mmlhs function can be used to optimize a Latin hypercube sampling plan. The following code demonstrates how to use mmlhs to optimize a 4x2 Latin hypercube starting from an initial plan:\n\n# Suppose we have an initial 4x2 plan\nX_start = np.array([[0.1, 0.3],[.1, .4],[.2, .9],[.9, .2]])\nprint(\"Initial plan:\")\nprint(X_start)\n# Search for a more space-filling plan\nX_opt = mmlhs(X_start, population=10, iterations=100, q=2)\nprint(\"Optimized plan:\")\nprint(X_opt)\n\nInitial plan:\n[[0.1 0.3]\n [0.1 0.4]\n [0.2 0.9]\n [0.9 0.2]]\nOptimized plan:\n[[0.2 0.4]\n [0.1 0.9]\n [0.1 0.2]\n [0.9 0.3]]\n\n\nFigure 4.9 shows the initial and optimized plans in 2D. The blue points represent the initial plan, while the red points represent the optimized plan.\n\n\n\n\n\n\n\n\nFigure 4.9: Comparison of the initial and optimized plans in 2D.\n\n\n\n\n\n\n\n\n4.3.7.2 The Function bestlh\nGenerates an optimized Latin hypercube by evolving the Morris-Mitchell criterion across multiple exponents (q values) and selecting the best plan.\n\ndef bestlh(n: int,\n           k: int,\n           population: int,\n           iterations: int,\n           p=1,\n           plot=False,\n           verbosity=0,\n           edges=0,\n           q_list=[1, 2, 5, 10, 20, 50, 100]) -&gt; np.ndarray:\n    \"\"\"\n    Args:\n        n (int):\n            Number of points required in the Latin hypercube.\n        k (int):\n            Number of design variables (dimensions).\n        population (int):\n            Number of offspring in each generation of the evolutionary search.\n        iterations (int):\n            Number of generations for the evolutionary search.\n        p (int, optional):\n            The distance norm to use. p=1 for Manhattan (L1), p=2 for Euclidean (L2).\n            Defaults to 1 (faster than 2).\n        plot (bool, optional):\n            If True, a scatter plot of the optimized plan in the first two dimensions\n            will be displayed. Only if k&gt;=2.  Defaults to False.\n        verbosity (int, optional):\n            Verbosity level. 0 is silent, 1 prints the best q value found. Defaults to 0.\n        edges (int, optional):\n            If 1, places centers of the extreme bins at the domain edges ([0,1]).\n            Otherwise, bins are fully contained within the domain, i.e. midpoints.\n            Defaults to 0.\n        q_list (list, optional):\n            A list of q values to optimize. Defaults to [1, 2, 5, 10, 20, 50, 100].\n            These values are used to evaluate the space-fillingness of the Latin\n            hypercube. The best plan is selected based on the lowest mmphi value.\n\n    Returns:\n        np.ndarray:\n            A 2D array of shape (n, k) representing an optimized Latin hypercube.\n    \"\"\"\n    if n &lt; 2:\n        raise ValueError(\"Latin hypercubes require at least 2 points\")\n    if k &lt; 2:\n        raise ValueError(\"Latin hypercubes are not defined for dim k &lt; 2\")\n\n    # A list of exponents (q) to optimize\n\n    # Start with a random Latin hypercube\n    X_start = rlh(n, k, edges=edges)\n\n    # Allocate a 3D array to store the results for each q\n    # (shape: (n, k, number_of_q_values))\n    X3D = np.zeros((n, k, len(q_list)))\n\n    # Evolve the plan for each q in q_list\n    for i, q_val in enumerate(q_list):\n        if verbosity &gt; 0:\n            print(f\"Now optimizing for q={q_val}...\")\n        X3D[:, :, i] = mmlhs(X_start, population, iterations, q_val)\n\n    # Sort the set of evolved plans according to the Morris-Mitchell criterion\n    index_order = mmsort(X3D, p=p)\n\n    # index_order is a 1-based array of plan indices; the first element is the best\n    best_idx = index_order[0] - 1\n    if verbosity &gt; 0:\n        print(f\"Best lh found using q={q_list[best_idx]}...\")\n\n    # The best plan in 3D array order\n    X = X3D[:, :, best_idx]\n\n    # Plot the first two dimensions\n    if plot and (k &gt;= 2):\n        plt.scatter(X[:, 0], X[:, 1], c=\"r\", marker=\"o\")\n        plt.title(f\"Morris-Mitchell optimum plan found using q={q_list[best_idx]}\")\n        plt.xlabel(\"x_1\")\n        plt.ylabel(\"x_2\")\n        plt.grid(True)\n        plt.show()\n\n    return X\n\n\nExample 4.14 (The Function bestlh) The bestlh function can be used to generate an optimized Latin hypercube sampling plan. The following code demonstrates how to use bestlh to create a 5x2 Latin hypercube with a population of 5 and 10 iterations:\n\nXbestlh= bestlh(n=5, k=2, population=5, iterations=10)\n\nFigure 4.10 shows the best Latin hypercube sampling in 2D. The red points represent the optimized plan.\n\n\n\n\n\n\n\n\nFigure 4.10: Best Latin Hypercube Sampling\n\n\n\n\n\n\nSorting all candidate plans in ascending order is not strictly necessary - after all, only the best one is truly of interest. Nonetheless, the added computational complexity is minimal (the vector will only ever contain as many elements as there are candidate \\(q\\) values, and only an index array is sorted, not the actual repository of plans). This sorting gives the reader the opportunity to compare, if desired, how different choices of \\(q\\) influence the resulting plans.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Sampling Plans</span>"
    ]
  },
  {
    "objectID": "001_sampling.html#experimental-analysis-of-the-morris-mitchell-criterion",
    "href": "001_sampling.html#experimental-analysis-of-the-morris-mitchell-criterion",
    "title": "4  Sampling Plans",
    "section": "4.4 Experimental Analysis of the Morris-Mitchell Criterion",
    "text": "4.4 Experimental Analysis of the Morris-Mitchell Criterion\nMorris-Mitchell Criterion Experimental Analysis\n\nNumber of points: 16, Dimensions: 2\nmmphi parameters: q (exponent) = 2.0, p (distance norm) = 2.0 (1=Manhattan, 2=Euclidean)\n\n\nN_POINTS = 16\nN_DIM = 2\nRANDOM_SEED = 42\nq = 2.0\np = 2.0\n\n\n4.4.1 Evaluation of Sampling Designs\nWe generate various sampling designs and evaluate their space-filling properties using the Morris-Mitchell criterion.\n\ndesigns = {}\nif int(np.sqrt(N_POINTS))**2 == N_POINTS:\n    grid_design = Grid(k=N_DIM)\n    designs[\"Grid (4x4)\"] = grid_design.generate_grid_design(points_per_dim=int(np.sqrt(N_POINTS)))\nelse:\n    print(f\"Skipping grid design as N_POINTS={N_POINTS} is not a perfect square for a simple 2D grid.\")\n\nlhs_design = SpaceFilling(k=N_DIM, seed=42)\ndesigns[\"LHS\"] = lhs_design.generate_qms_lhs_design(n_points=N_POINTS)\n\nsobol_design = Sobol(k=N_DIM, seed=42)\ndesigns[\"Sobol\"] = sobol_design.generate_sobol_design(n_points=N_POINTS)\n\nrandom_design = Random(k=N_DIM)\ndesigns[\"Random\"] = random_design.uniform(n_points=N_POINTS)\n\npoor_design = Poor(k=N_DIM)\ndesigns[\"Collinear\"] = poor_design.generate_collinear_design(n_points=N_POINTS)\n\nclustered_design = Clustered(k=N_DIM)\ndesigns[\"Clustered (3 clusters)\"] = clustered_design.generate_clustered_design(n_points=N_POINTS, n_clusters=3, seed=42)\n\nresults = {}\n\nprint(\"Calculating Morris-Mitchell metric (smaller is better):\")\nfor name, X_design in designs.items():\n    metric_val = mmphi(X_design, q=q, p=p)\n    results[name] = metric_val\n    print(f\"  {name}: {metric_val:.4f}\")\n\nCalculating Morris-Mitchell metric (smaller is better):\n  Grid (4x4): 20.2617\n  LHS: 28.1868\n  Sobol: 33.9970\n  Random: 37.4966\n  Collinear: 87.8829\n  Clustered (3 clusters): 90.3702\n\n\n\nif N_DIM == 2:\n    num_designs = len(designs)\n    cols = 2\n    rows = int(np.ceil(num_designs / cols))\n    fig, axes = plt.subplots(rows, cols, figsize=(5 * cols, 5 * rows))\n    axes = axes.ravel() # Flatten axes array for easy iteration\n\n    for i, (name, X_design) in enumerate(designs.items()):\n        ax = axes[i]\n        ax.scatter(X_design[:, 0], X_design[:, 1], s=50, edgecolors='k', alpha=0.7)\n        ax.set_title(f\"{name}\\nmmphi = {results[name]:.3f}\", fontsize=10)\n        ax.set_xlabel(\"X1\")\n        ax.set_ylabel(\"X2\")\n        ax.set_xlim(-0.05, 1.05)\n        ax.set_ylim(-0.05, 1.05)\n        ax.set_aspect('equal', adjustable='box')\n        ax.grid(True, linestyle='--', alpha=0.6)\n\n    # Hide any unused subplots\n    for j in range(i + 1, len(axes)):\n        fig.delaxes(axes[j])\n\n    plt.tight_layout()\n    plt.suptitle(f\"Comparison of 2D Sampling Designs ({N_POINTS} points each)\", fontsize=14, y=1.02)\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n4.4.2 Demonstrate the Impact of mmphi Parameters\nDemonstrating Impact of mmphi Parameters on ‘LHS’ Design\n\nX_lhs = designs[\"LHS\"]\n\n# 1. Default parameters (already calculated)\nprint(f\"  LHS (q={q}, p={p} Euclidean): {results['LHS']:.4f}\")\n\n# 2. Change q (main exponent, literature's p or k)\nq_high = 15.0\nmetric_lhs_q_high = mmphi(X_lhs, q=q_high, p=p)\nprint(f\"  LHS (q={q_high}, p={p} Euclidean): {metric_lhs_q_high:.4f} (Higher q penalizes small distances more)\")\n\n# 3. Change p (distance norm, literature's q or m)\np_manhattan = 1.0\nmetric_lhs_p_manhattan = mmphi(X_lhs, q=q, p=p_manhattan)\nprint(f\"  LHS (q={q}, p={p_manhattan} Manhattan): {metric_lhs_p_manhattan:.4f} (Using L1 distance)\")\n\n  LHS (q=2.0, p=2.0 Euclidean): 28.1868\n  LHS (q=15.0, p=2.0 Euclidean): 8.1573 (Higher q penalizes small distances more)\n  LHS (q=2.0, p=1.0 Manhattan): 22.0336 (Using L1 distance)\n\n\n\n\n4.4.3 Morris-Mitchell Criterion: Impact of Adding Points\nImpact of adding a point to a 2x2 grid design\n\n# Initial 2x2 Grid Design\nX_initial = np.array([[0.0, 0.0], [1.0, 0.0], [0.0, 1.0], [1.0, 1.0]])\nmmphi_initial = mmphi(X_initial, q=q, p=p)\n\nprint(f\"Parameters: q (exponent) = {q}, p (distance) = {p} (Euclidean)\\n\")\nprint(f\"Initial 2x2 Grid Design (4 points):\")\nprint(f\"  Points:\\n{X_initial}\")\nprint(f\"  Morris-Mitchell Criterion (Phi_q): {mmphi_initial:.4f}\\n\")\n\nParameters: q (exponent) = 2.0, p (distance) = 2.0 (Euclidean)\n\nInitial 2x2 Grid Design (4 points):\n  Points:\n[[0. 0.]\n [1. 0.]\n [0. 1.]\n [1. 1.]]\n  Morris-Mitchell Criterion (Phi_q): 2.2361\n\n\n\nScenarios for adding a 5th point:\n\nscenarios = {\n    \"Scenario 1: Add to Center\": {\n        \"new_point\": np.array([[0.5, 0.5]]),\n        \"description\": \"Adding a point in the center of the grid.\"\n    },\n    \"Scenario 2: Add Close to Existing (Cluster)\": {\n        \"new_point\": np.array([[0.1, 0.1]]),\n        \"description\": \"Adding a point very close to an existing point (0,0).\"\n    },\n    \"Scenario 3: Add on Edge\": {\n        \"new_point\": np.array([[0.5, 0.0]]),\n        \"description\": \"Adding a point on an edge between (0,0) and (1,0).\"\n    }\n}\n\nresults_summary = []\naugmented_designs_for_plotting = {\"Initial Design\": X_initial}\n\nfor name, scenario_details in scenarios.items():\n    new_point = scenario_details[\"new_point\"]\n    X_augmented = np.vstack((X_initial, new_point))\n    augmented_designs_for_plotting[name] = X_augmented\n    \n    mmphi_augmented = mmphi(X_augmented, q=q, p=p)\n    change = mmphi_augmented - mmphi_initial\n    \n    print(f\"{name}:\")\n    print(f\"  Description: {scenario_details['description']}\")\n    print(f\"  New Point Added: {new_point}\")\n    # print(f\"  Augmented Design (5 points):\\n{X_augmented}\") # Optional: print full matrix\n    print(f\"  Morris-Mitchell Criterion (Phi_q): {mmphi_augmented:.4f}\")\n    print(f\"  Change from Initial Phi_q: {change:+.4f}\\n\")\n    \n    results_summary.append({\n        \"Scenario\": name,\n        \"Initial Phi_q\": mmphi_initial,\n        \"Augmented Phi_q\": mmphi_augmented,\n        \"Change\": change\n    })\n\nScenario 1: Add to Center:\n  Description: Adding a point in the center of the grid.\n  New Point Added: [[0.5 0.5]]\n  Morris-Mitchell Criterion (Phi_q): 3.6056\n  Change from Initial Phi_q: +1.3695\n\nScenario 2: Add Close to Existing (Cluster):\n  Description: Adding a point very close to an existing point (0,0).\n  New Point Added: [[0.1 0.1]]\n  Morris-Mitchell Criterion (Phi_q): 7.6195\n  Change from Initial Phi_q: +5.3834\n\nScenario 3: Add on Edge:\n  Description: Adding a point on an edge between (0,0) and (1,0).\n  New Point Added: [[0.5 0. ]]\n  Morris-Mitchell Criterion (Phi_q): 3.8210\n  Change from Initial Phi_q: +1.5849\n\n\n\n\nnum_designs = len(augmented_designs_for_plotting)\ncols = 2\nrows = int(np.ceil(num_designs / cols))\n\nfig, axes = plt.subplots(rows, cols, figsize=(6 * cols, 5 * rows))\naxes = axes.ravel() \n\nplot_idx = 0\n# Plot initial design first\nax = axes[plot_idx]\nax.scatter(X_initial[:, 0], X_initial[:, 1], s=100, edgecolors='k', alpha=0.7, label=\"Original Points\")\nax.set_title(f\"Initial Design\\nPhi_q = {mmphi_initial:.3f}\", fontsize=10)\nax.set_xlabel(\"X1\")\nax.set_ylabel(\"X2\")\nax.set_xlim(-0.1, 1.1)\nax.set_ylim(-0.1, 1.1)\nax.set_aspect('equal', adjustable='box')\nax.grid(True, linestyle='--', alpha=0.6)\nax.legend(fontsize='small')\nplot_idx +=1\n\n# Plot augmented designs\nfor name, X_design in augmented_designs_for_plotting.items():\n    if name == \"Initial Design\":\n        continue # Already plotted\n\n    ax = axes[plot_idx]\n    # Highlight original vs new point\n    original_points = X_design[:-1, :]\n    new_point = X_design[-1, :].reshape(1,2)\n    \n    ax.scatter(original_points[:, 0], original_points[:, 1], s=100, edgecolors='k', alpha=0.7, label=\"Original Points\")\n    ax.scatter(new_point[:, 0], new_point[:, 1], s=150, color='red', edgecolors='k', marker='X', label=\"Added Point\")\n    \n    current_phi_q = next(item['Augmented Phi_q'] for item in results_summary if item[\"Scenario\"] == name)\n    ax.set_title(f\"{name}\\nPhi_q = {current_phi_q:.3f}\", fontsize=10)\n    ax.set_xlabel(\"X1\")\n    ax.set_ylabel(\"X2\")\n    ax.set_xlim(-0.1, 1.1)\n    ax.set_ylim(-0.1, 1.1)\n    ax.set_aspect('equal', adjustable='box')\n    ax.grid(True, linestyle='--', alpha=0.6)\n    ax.legend(fontsize='small')\n    plot_idx +=1\n    \n# Hide any unused subplots\nfor j in range(plot_idx, len(axes)):\n    fig.delaxes(axes[j])\n\nplt.tight_layout(rect=[0, 0, 1, 0.96]) # Adjust layout to make space for suptitle\nplt.suptitle(f\"Impact of Adding a Point to a 2x2 Grid Design (q={q}, p={p})\", fontsize=14)\nplt.show()\n\n\n\n\n\n\n\n\nSummary Table (Conceptual):\n\n\n\n\n\n\n\n\n\nScenario\nInitial Phi_q\nAugmented Phi_q\nChange\n\n\n\n\nBaseline (2x2 Grid)\n2.236\n—\n—\n\n\nScenario 1: Add to Center\n2.236\n3.606\n+1.369\n\n\nScenario 2: Add Close to Existing (Cluster)\n2.236\n7.619\n+5.383\n\n\nScenario 3: Add on Edge\n2.236\n3.821\n+1.585",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Sampling Plans</span>"
    ]
  },
  {
    "objectID": "001_sampling.html#a-sample-size-invariant-version-of-the-morris-mitchell-criterion",
    "href": "001_sampling.html#a-sample-size-invariant-version-of-the-morris-mitchell-criterion",
    "title": "4  Sampling Plans",
    "section": "4.5 A Sample-Size Invariant Version of the Morris-Mitchell Criterion",
    "text": "4.5 A Sample-Size Invariant Version of the Morris-Mitchell Criterion\n\n4.5.1 Comparison of mmphi() and mmphi_intensive()\nThe Morris-Mitchell criterion is a widely used metric for evaluating the space-filling properties of Latin hypercube sampling designs. However, it is sensitive to the number of points in the design, which can lead to misleading comparisons between designs with different sample sizes. To address this issue, a sample-size invariant version of the Morris-Mitchell criterion has been proposed. It is avaiable in the spotpython package as mmphi_intensive(), see [SOURCE].\nThe functions mmphi() and mmphi_intensive() both calculate a Morris-Mitchell criterion, but they differ in their normalization, which makes mmphi_intensive() invariant to the sample size.\nLet \\(X\\) be a sampling plan with \\(n\\) points \\(\\{x_1, x_2, \\dots, x_n\\}\\) in a \\(k\\)-dimensional space. Let \\(d_{ij} = \\|x_i - x_j\\|_p\\) be the \\(p\\)-norm distance between points \\(x_i\\) and \\(x_j\\). Let \\(J_l\\) be the multiplicity of the \\(l\\)-th unique distance \\(d_l\\) among all pairs of points in \\(X\\). Let \\(m\\) be the total number of unique distances.\n1. mmphi() (Morris-Mitchell Criterion \\(\\Phi_q\\))\nThe mmphi() function, as defined in the context and implemented in sampling.py, calculates the Morris-Mitchell criterion \\(\\Phi_q\\) as:\n\\[\n\\Phi_q(X) = \\left( \\sum_{l=1}^{m} J_l d_l^{-q} \\right)^{1/q},\n\\] where:\n\n\\(J_l\\) is the number of pairs of points separated by the unique distance \\(d_l\\).\n\\(d_l\\) are the unique pairwise distances.\n\\(q\\) is a user-defined exponent (typically \\(q &gt; 0\\)).\n\nThis formulation is directly based on the sum of inverse powers of distances. The value of \\(\\Phi_q\\) is generally dependent on the number of points \\(n\\) in the design \\(X\\), as the sum \\(\\sum J_l d_l^{-q}\\) will typically increase with more points (and thus more pairs).\n2. mmphi_intensive() (Intensive Morris-Mitchell Criterion)\nThe mmphi_intensive() function, as implemented in sampling.py calculates a sample-size invariant version of the Morris-Mitchell criterion, which will be referred to as \\(\\Phi_q^{I}\\). The formula is:\n\\[\n\\Phi_q^{I}(X) = \\left( \\frac{1}{M} \\sum_{l=1}^{m} J_l d_l^{-q} \\right)^{1/q}\n\\]\nwhere:\n\n\\(M = \\binom{n}{2} = \\frac{n(n-1)}{2}\\) is the total number of unique pairs of points in the design \\(X\\).\nThe other terms \\(J_l\\), \\(d_l\\), \\(q\\) are the same as in mmphi().\n\nThe key mathematical difference is the normalization factor \\(\\frac{1}{M}\\) inside the parentheses before the outer exponent \\(1/q\\) is applied.\n\nmmphi(): Calculates \\(\\left( \\text{SumTerm} \\right)^{1/q}\\), where SumTerm = \\(\\sum J_l d_l^{-q}\\).\nmmphi_intensive(): Calculates \\(\\left( \\frac{\\text{SumTerm}}{M} \\right)^{1/q}\\).\n\nBy dividing the sum \\(\\sum J_l d_l^{-q}\\) by \\(M\\) (the total number of pairs), mmphi_intensive() effectively calculates an average contribution per pair to the \\(-q\\)-th power of distance, before taking the \\(q\\)-th root. This normalization makes the criterion less dependent on the absolute number of points \\(n\\) and allows for more meaningful comparisons of space-fillingness between designs of different sizes. A smaller value indicates a better (more space-filling) design for both criteria.\n\n\n4.5.2 Plotting the Two Morris-Mitchell Criteria for Different Sample Sizes\nFigure 4.11 shows the comparison of the two Morris-Mitchell criteria for different sample sizes using the plot_mmphi_vs_n_lhs function. The red line represents the standard Morris-Mitchell criterion, while the blue line represents the sample-size invariant version. Note the difference in the y-axis scales, which highlights how the sample-size invariant version remains consistent across varying sample sizes.\n\ndef plot_mmphi_vs_n_lhs(k_dim: int, \n                        seed: int, \n                        n_min: int = 10, \n                        n_max: int = 100, \n                        n_step: int = 5,\n                        q_phi: float = 2.0, \n                        p_phi: float = 2.0):\n    \"\"\"\n    Generates LHS designs for varying n, calculates mmphi and mmphi_intensive,\n    and plots them against the number of samples (n).\n\n    Args:\n        k_dim (int): Number of dimensions for the LHS design.\n        seed (int): Random seed for reproducibility.\n        n_min (int): Minimum number of samples.\n        n_max (int): Maximum number of samples.\n        n_step (int): Step size for increasing n.\n        q_phi (float): Exponent q for the Morris-Mitchell criteria.\n        p_phi (float): Distance norm p for the Morris-Mitchell criteria.\n    \"\"\"\n    n_values = list(range(n_min, n_max + 1, n_step))\n    if not n_values:\n        print(\"Warning: n_values list is empty. Check n_min, n_max, and n_step.\")\n        return\n    mmphi_results = []\n    mmphi_intensive_results = []\n    lhs_generator = SpaceFilling(k=k_dim, seed=seed)\n    print(f\"Calculating for n from {n_min} to {n_max} with step {n_step}...\")\n    for n_points in n_values:\n        if n_points &lt; 2 : # mmphi requires at least 2 points to calculate distances\n            print(f\"Skipping n={n_points} as it's less than 2.\")\n            mmphi_results.append(np.nan)\n            mmphi_intensive_results.append(np.nan)\n            continue\n        try:\n            X_design = lhs_generator.generate_qms_lhs_design(n_points=n_points)\n            phi = mmphi(X_design, q=q_phi, p=p_phi)\n            phi_intensive, _, _ = mmphi_intensive(X_design, q=q_phi, p=p_phi)\n            mmphi_results.append(phi)\n            mmphi_intensive_results.append(phi_intensive)\n        except Exception as e:\n            print(f\"Error calculating for n={n_points}: {e}\")\n            mmphi_results.append(np.nan)\n            mmphi_intensive_results.append(np.nan)\n\n    fig, ax1 = plt.subplots(figsize=(9, 6))\n\n    color = 'tab:red'\n    ax1.set_xlabel('Number of Samples (n)')\n    ax1.set_ylabel('mmphi (Phiq)', color=color)\n    ax1.plot(n_values, mmphi_results, color=color, marker='o', linestyle='-', label='mmphi (Phiq)')\n    ax1.tick_params(axis='y', labelcolor=color)\n    ax1.grid(True, linestyle='--', alpha=0.7)\n\n    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n    color = 'tab:blue'\n    ax2.set_ylabel('mmphi_intensive (PhiqI)', color=color)  # we already handled the x-label with ax1\n    ax2.plot(n_values, mmphi_intensive_results, color=color, marker='x', linestyle='--', label='mmphi_intensive (PhiqI)')\n    ax2.tick_params(axis='y', labelcolor=color)\n\n    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n    plt.title(f'Morris-Mitchell Criteria vs. Number of Samples (n)\\nLHS (k={k_dim}, q={q_phi}, p={p_phi})')\n    # Add legends\n    lines, labels = ax1.get_legend_handles_labels()\n    lines2, labels2 = ax2.get_legend_handles_labels()\n    ax2.legend(lines + lines2, labels + labels2, loc='best')\n    plt.show()\n\n\nN_DIM = 2\nRANDOM_SEED = 42\nplot_mmphi_vs_n_lhs(k_dim=N_DIM, seed=RANDOM_SEED, n_min=10, n_max=100, n_step=5)\n\nCalculating for n from 10 to 100 with step 5...\n\n\n\n\n\n\n\n\nFigure 4.11: Comparison of the two Morris-Mitchell Criteria for Different Sample Sizes",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Sampling Plans</span>"
    ]
  },
  {
    "objectID": "001_sampling.html#jupyter-notebook",
    "href": "001_sampling.html#jupyter-notebook",
    "title": "4  Sampling Plans",
    "section": "4.6 Jupyter Notebook",
    "text": "4.6 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository\n\n\n\n\n\n\n\nBox, G E P. 1957. “Evolutionary operation: A method for increasing industrial productivity.” Applied Statistics 6: 81–101.\n\n\nForrester, Alexander, András Sóbester, and Andy Keane. 2008. Engineering Design via Surrogate Modelling. Wiley.\n\n\nJohnson, M. E., L. M. Moore, and D. Ylvisaker. 1990. “Minimax and Maximin Distance Designs.” Journal of Statistical Planning and Inference 26 (2): 131–48.\n\n\nMorris, Max D., and Toby J. Mitchell. 1995. “Exploratory Designs for Computational Experiments.” Journal of Statistical Planning and Inference 43 (3): 381–402. https://doi.org/https://doi.org/10.1016/0378-3758(94)00035-T.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Sampling Plans</span>"
    ]
  },
  {
    "objectID": "006_constructing_surrogate.html",
    "href": "006_constructing_surrogate.html",
    "title": "5  Constructing a Surrogate",
    "section": "",
    "text": "5.1 Stage One: Preparing the Data and Choosing a Modelling Approach\nThis black box could take the form of either a physical or computer experiment, for example, a finite element code, which calculates the maximum stress (\\(\\sigma\\)) for given product dimensions (\\(\\vec{x}\\)).\nThe first step is the identification, through a small number of observations, of the inputs that have a significant impact on \\(f\\); that is the determination of the shortest design variable vector \\(\\vec{x} = \\{x_1, x_2, \\ldots, x_k\\}^T\\) that, by sweeping the ranges of all of its variables, can still elicit most of the behavior the black box is capable of. The ranges of the various design variables also have to be established at this stage.\nThe second step is to recruit \\(n\\) of these \\(k\\)-vectors into a list \\[\nX = \\{ \\vec{x}^{(1)},\\vec{x}^{(2)}, \\ldots, \\vec{x}^{(n)} \\}^T,\n\\] where each \\(\\vec{x}^{(i)}\\) is a \\(k\\)-vector. The corresponding responses are collected in a vector such that this represents the design space as thoroughly as possible.\nIn the surrogate modeling process, the number of samples \\(n\\) is often limited, as it is constrained by the computational cost (money and/or time) associated with obtaining each observation.\nIt is advisable to scale \\(\\vec{x}\\) at this stage into the unit cube \\([0, 1]^k\\), a step that can simplify the subsequent mathematics and prevent multidimensional scaling issues.\nWe now focus on the attempt to learn \\(f\\) through data pairs \\[\n\\{ (\\vec{x}^{(1)}, y^{(1)}), (\\vec{x}^{(2)}, y^{(2)}), \\ldots, (\\vec{x}^{(n)}, y^{(n)}) \\}.\n\\]\nThis supervised learning process essentially involves searching across the space of possible functions \\(\\hat{f}\\) that would replicate observations of \\(f\\). This space of functions is infinite. Any number of hypersurfaces could be drawn to pass through or near the known observations, accounting for experimental error. However, most of these would generalize poorly; they would be practically useless at predicting responses at new sites, which is the ultimate goal.\nThere are countless other configurations, perhaps less contrived, that still generalize poorly. This suggests a need for systematic means to filter out nonsensical predictors. In our approach, we embed the structure of \\(f\\) into the model selection algorithm and search over its parameters to fine-tune the approximation to observations. For instance, consider one of the simplest models, \\[\nf(x, \\vec{w}) = \\vec{w}^T\\vec{x} + v.\n\\tag{5.1}\\] Learning \\(f\\) with this model implies that its structure—a hyperplane—is predetermined, and the fitting process involves finding the \\(k + 1\\) parameters (the slope vector \\(\\vec{w}\\) and the intercept \\(v\\)) that best fit the data. This will be accomplished in Stage Two.\nComplicating this further is the noise present in observed responses (we assume design vectors \\(\\vec{x}\\) are not corrupted). Here, we focus on learning from such data, which sometimes risks overfitting.\nIn the surrogate modeling process, the second stage as described in Section 5.2, addresses this issue of complexity control by estimating the parameters of the fixed structure model. However, foresight is necessary even at the model type selection stage.\nModel selection often involves physics-based considerations, where the modeling technique is chosen based on expected underlying responses.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Constructing a Surrogate</span>"
    ]
  },
  {
    "objectID": "006_constructing_surrogate.html#stage-one-preparing-the-data-and-choosing-a-modelling-approach",
    "href": "006_constructing_surrogate.html#stage-one-preparing-the-data-and-choosing-a-modelling-approach",
    "title": "5  Constructing a Surrogate",
    "section": "",
    "text": "Example 5.1 (The Needle(s) in the Haystack Function) An extreme example is the ‘needle(s) in the haystack’ function:\n\\[\nf(x) = \\begin{cases}\ny^{(1)}, & \\text{if } x = \\vec{x}^{(1)} \\\\\ny^{(2)}, & \\text{if } x = \\vec{x}^{(2)} \\\\\n\\vdots & \\\\\ny^{(n)}, & \\text{if } x = \\vec{x}^{(n)} \\\\\n0, & \\text{otherwise.}\n\\end{cases}\n\\]\nWhile this predictor reproduces all training data, it seems counter-intuitive and unsettling to predict 0 everywhere else for most engineering functions. Although there is a small chance that the function genuinely resembles the equation above and we sampled exactly where the needles are, it is highly unlikely.\n\n\n\n\nDefinition 5.3 (Overfitting) Overfitting occurs when the model becomes too flexible and captures not only the underlying trend but also the noise in the data.\n\n\n\n\nExample 5.2 (Model Selection) Modeling stress in an elastically deformed solid due to small strains may justify using a simple linear approximation. Without insights into the physics, and if one fails to account for the simplicity of the data, a more complex and excessively flexible model may be incorrectly chosen. Although parameter estimation might still adjust the approximation to become linear, an opportunity to develop a simpler and robust model may be lost.\n\nSimple linear (or polynomial) models, despite their lack of flexibility, have advantages like applicability in further symbolic computations.\nConversely, if we incorrectly assume a quadratic process when multiple peaks and troughs exist, the parameter estimation stage will not compensate for an unsuitable model choice. A quadratic model is too rigid to fit a multimodal function, regardless of parameter adjustments.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Constructing a Surrogate</span>"
    ]
  },
  {
    "objectID": "006_constructing_surrogate.html#sec-stage-two",
    "href": "006_constructing_surrogate.html#sec-stage-two",
    "title": "5  Constructing a Surrogate",
    "section": "5.2 Stage Two: Parameter Estimation and Training",
    "text": "5.2 Stage Two: Parameter Estimation and Training\nAssuming that Stage One helped identify the \\(k\\) critical design variables, acquire the learning data set, and select a generic model structure \\(f(\\vec{x}, \\vec{w})\\), the task now is to estimate parameters \\(\\vec{w}\\) to ensure the model fits the data optimally. Among several estimation criteria, we will discuss two methods here.\n\nDefinition 5.4 (Maximum Likelihood Estimation) Given a set of parameters \\(\\vec{w}\\), the model \\(f(\\vec{x}, \\vec{w})\\) allows computation of the probability of the data set \\[\n\\{(\\vec{x}^{(1)}, y^{(1)} \\pm \\epsilon), (\\vec{x}^{(2)}, y^{(2)} \\pm \\epsilon), \\ldots, (\\vec{x}^{(n)}, y^{(n)} \\pm \\epsilon)\\}\n\\] resulting from \\(f\\) (where \\(\\epsilon\\) is a small error margin around each data point).\n\n\n\n\n\n\n\nMaximum Likelihood Estimation\n\n\n\nSection 23.18 presents a more detailed discussion of the maximum likelihood estimation (MLE) method.\n\n\nTaking Equation 23.6 and assuming errors \\(\\epsilon\\) are independently and normally distributed with standard deviation \\(\\sigma\\), the probability of the data set is given by:\n\\[\nP = \\frac{1}{(2\\pi \\sigma^2)^{n/2}} \\exp \\left[ -\\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} \\left( y^{(i)} - f(\\vec{x}^{(i)}, \\vec{w}) \\right)^2 \\epsilon \\right].\n\\]\nIntuitively, this is equivalent to the likelihood of the parameters given the data. Accepting this intuitive relationship as a mathematical one aids in model parameter estimation. This is achieved by maximizing the likelihood or, more conveniently, minimizing the negative of its natural logarithm:\n\\[\n\\min_{\\vec{w}} \\sum_{i=1}^{n} \\frac{[y^{(i)} - f(\\vec{x}^{(i)}, \\vec{w})]^2}{2\\sigma^2} + \\frac{n}{2} \\ln \\epsilon .\n\\tag{5.2}\\]\nIf we assume \\(\\sigma\\) and \\(\\epsilon\\) are constants, Equation 5.2 simplifies to the well-known least squares criterion:\n\\[\n\\min_{\\vec{w}} \\sum_{i=1}^{n} [y^{(i)} - f(\\vec{x}^{(i)}, \\vec{w})]^2 .\n\\]\nCross-validation is another method used to estimate model performance.\n\nDefinition 5.5 (Cross-Validation) Cross-validation splits the data randomly into \\(q\\) roughly equal subsets, and then cyclically removing each subset and fitting the model to the remaining \\(q - 1\\) subsets. A loss function \\(L\\) is then computed to measure the error between the predictor and the withheld subset for each iteration, with contributions summed over all \\(q\\) iterations. More formally, if a mapping \\(\\theta: \\{1, \\ldots, n\\} \\to \\{1, \\ldots, q\\}\\) describes the allocation of the \\(n\\) training points to one of the \\(q\\) subsets and \\(f^{(-\\theta(i))}(\\vec{x})\\) is the predicted value by removing the subset \\(\\theta(i)\\) (i.e., the subset where observation \\(i\\) belongs), the cross-validation measure, used as an estimate of prediction error, is:\n\\[\nCV = \\frac{1}{n} \\sum_{i=1}^{n} L(y^{(i)}, f^{(-\\theta(i))}(\\vec{x}^{(i)})) .\n\\tag{5.3}\\]\n\nIntroducing the squared error as the loss function and considering our generic model \\(f\\) still dependent on undetermined parameters, we write Equation 5.3 as:\n\\[\nCV = \\frac{1}{n} \\sum_{i=1}^{n} [y^{(i)} - f^{(-\\theta(i))}(\\vec{x}^{(i)})]^2 .\n\\tag{5.4}\\]\nThe extent to which Equation 5.4 is an unbiased estimator of true risk depends on \\(q\\). It is shown that if \\(q = n\\), the leave-one-out cross-validation (LOOCV) measure is almost unbiased. However, LOOCV can have high variance because subsets are very similar. Hastie, Tibshirani, and Friedman (2017)) suggest using compromise values like \\(q = 5\\) or \\(q = 10\\). Using fewer subsets also reduces the computational cost of the cross-validation process, see also Arlot, Celisse, et al. (2010) and Kohavi (1995).",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Constructing a Surrogate</span>"
    ]
  },
  {
    "objectID": "006_constructing_surrogate.html#stage-three-model-testing",
    "href": "006_constructing_surrogate.html#stage-three-model-testing",
    "title": "5  Constructing a Surrogate",
    "section": "5.3 Stage Three: Model Testing",
    "text": "5.3 Stage Three: Model Testing\nIf there is a sufficient amount of observational data, a random subset should be set aside initially for model testing. Hastie, Tibshirani, and Friedman (2017) recommend setting aside approximately \\(0.25n\\) of \\(\\vec{x} \\rightarrow y\\) pairs for testing purposes. These observations must remain untouched during Stages One and Two, as their sole purpose is to evaluate the testing error—the difference between true and approximated function values at the test sites—once the model has been built. Interestingly, if the main goal is to construct an initial surrogate for seeding a global refinement criterion-based strategy (as discussed in Section 3.2 in Forrester, Sóbester, and Keane (2008)), the model testing phase might be skipped.\nIt is noted that, ideally, parameter estimation (Stage Two) should also rely on a separate subset. However, observational data is rarely abundant enough to afford this luxury (if the function is cheap to evaluate and evaluation sites are selectable, a surrogate model might not be necessary).\nWhen data are available for model testing and the primary objective is a globally accurate model, using either a root mean square error (RMSE) metric or the correlation coefficient (\\(r^2\\)) is recommended. To test the model, a test data set of size \\(n_t\\) is used alongside predictions at the corresponding locations to calculate these metrics.\nThe RMSE is defined as follows:\n\nDefinition 5.6 (Root Mean Square Error (RMSE)) \\[\n\\text{RMSE} = \\sqrt{\\frac{1}{n_t} \\sum_{i=1}^{n_t} (y^{(i)} - \\hat{y}^{(i)})^2},\n\\]\n\nIdeally, the RMSE should be minimized, acknowledging its limitation by errors in the objective function \\(f\\) calculation. If the error level is known, like a standard deviation, the aim might be to achieve an RMSE within this value. Often, the target is an RMSE within a specific percentage of the observed data’s objective value range.\nThe squared correlation coefficient \\(r\\), see Equation 23.3, between the observed \\(y\\) and predicted \\(\\hat{y}\\) values can be computed as:\n\\[\nr^2 = \\left( \\frac{\\text{cov}(y, \\hat{y})}{\\sqrt{\\text{var}(y)\\text{var}(\\hat{y})}} \\right)^2,\n\\tag{5.5}\\]\nEquation 5.5 and can be expanded as:\n\\[\nr^2 =\n\\left(\n\\frac{n_t \\sum_{i=1}^{n_t} y^{(i)} \\hat{y}^{(i)} - \\sum_{i=1}^{n_t} y^{(i)} \\sum_{i=1}^{n_t} \\hat{y}^{(i)}}{ \\sqrt{\\left( n_t \\sum_{i=1}^{n_t} (y^{(i)})^2 - \\left(\\sum_{i=1}^{n_t} y^{(i)}\\right)^2 \\right) \\left( n_t \\sum_{i=1}^{n_t} (\\hat{y}^{(i)})^2 - \\left(\\sum_{i=1}^{n_t} \\hat{y}^{(i)}\\right)^2 \\right)}}\n\\right)^2.\n\\]\nThe correlation coefficient \\(r^2\\) does not require scaling the data sets and only compares landscape shapes, not values. An \\(r^2 &gt; 0.8\\) typically indicates a surrogate with good predictive capability.\nThe methods outlined provide quantitative assessments of model accuracy, yet visual evaluations can also be insightful. In general, the RMSE will not reach zero but will stabilize around a low value. At this point, the surrogate model is saturated with data, and further additions do not enhance the model globally (though local improvements can occur at newly added points if using an interpolating model).\n\nExample 5.3 (The Tea and Sugar Analogy) Forrester, Sóbester, and Keane (2008) illustrates this saturation point using a comparison with a cup of tea and sugar. The tea represents the surrogate model, and sugar represents data. Initially, the tea is unsweetened, and adding sugar increases its sweetness. Eventually, a saturation point is reached where no more sugar dissolves, and the tea cannot get any sweeter. Similarly, a more flexible model, like one with additional parameters or employing interpolation rather than regression, can increase the saturation point—akin to making a hotter cup of tea for dissolving more sugar.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Constructing a Surrogate</span>"
    ]
  },
  {
    "objectID": "006_constructing_surrogate.html#jupyter-notebook",
    "href": "006_constructing_surrogate.html#jupyter-notebook",
    "title": "5  Constructing a Surrogate",
    "section": "5.4 Jupyter Notebook",
    "text": "5.4 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository\n\n\n\n\n\n\n\nArlot, Sylvain, Alain Celisse, et al. 2010. “A Survey of Cross-Validation Procedures for Model Selection.” Statistics Surveys 4: 40–79.\n\n\nForrester, Alexander, András Sóbester, and Andy Keane. 2008. Engineering Design via Surrogate Modelling. Wiley.\n\n\nHastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2017. The Elements of Statistical Learning. Second. Springer.\n\n\nKohavi, Ron. 1995. “A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection.” In Proceedings of the 14th International Joint Conference on Artificial Intelligence - Volume 2, 1137–43. IJCAI’95. San Francisco, CA, USA: Morgan Kaufmann Publishers Inc.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Constructing a Surrogate</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html",
    "href": "005_num_rsm.html",
    "title": "6  Response Surface Methods",
    "section": "",
    "text": "6.1 What is RSM?\nThis part deals with numerical implementations of optimization methods. The goal is to understand the implementation of optimization methods and to solve real-world problems numerically and efficiently. We will focus on the implementation of surrogate models, because they are the most efficient way to solve real-world problems.\nStarting point is the well-established response surface methodology (RSM). It will be extended to the design and analysis of computer experiments (DACE). The DACE methodology is a modern extension of the response surface methodology. It is based on the use of surrogate models, which are used to replace the real-world problem with a simpler problem. The simpler problem is then solved numerically. The solution of the simpler problem is then used to solve the real-world problem.\nResponse Surface Methods (RSM) refer to a collection of statistical and mathematical tools that are valuable for developing, improving, and optimizing processes. The overarching theme of RSM involves studying how input variables that control a product or process can potentially influence a response that measures performance or quality characteristics.\nThe advantages of RSM include a rich literature, well-established methods often used in manufacturing, the importance of careful experimental design combined with a well-understood model, and the potential to add significant value to scientific inquiry, process refinement, optimization, and more. However, there are also drawbacks to RSM, such as the use of simple and crude surrogates, the hands-on nature of the methods, and the limitation of local methods.\nRSM is related to various fields, including Design of Experiments (DoE), quality management, reliability, and productivity. Its applications are widespread in industry and manufacturing, focusing on designing, developing, and formulating new products and improving existing ones, as well as from laboratory research. RSM is commonly applied in domains such as materials science, manufacturing, applied chemistry, climate science, and many others.\nAn example of RSM involves studying the relationship between a response variable, such as yield (\\(y\\)) in a chemical process, and two process variables: reaction time (\\(\\xi_1\\)) and reaction temperature (\\(\\xi_2\\)). The provided code illustrates this scenario, following a variation of the so-called “banana function.”\nIn the context of visualization, RSM offers the choice between 3D plots and contour plots. In a 3D plot, the independent variables \\(\\xi_1\\) and \\(\\xi_2\\) are represented, with \\(y\\) as the dependent variable.\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef fun_rosen(x1, x2):\n    b = 10\n    return (x1-1)**2 + b*(x2-x1**2)**2\n\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nx = np.arange(-2.0, 2.0, 0.05)\ny = np.arange(-1.0, 3.0, 0.05)\nX, Y = np.meshgrid(x, y)\nzs = np.array(fun_rosen(np.ravel(X), np.ravel(Y)))\nZ = zs.reshape(X.shape)\n\nax.plot_surface(X, Y, Z)\n\nax.set_xlabel('X1')\nax.set_ylabel('X2')\nax.set_zlabel('Y')\n\nplt.show()\nimport numpy as np\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\n\ndelta = 0.025\nx1 = np.arange(-2.0, 2.0, delta)\nx2 = np.arange(-1.0, 3.0, delta)\nX1, X2 = np.meshgrid(x1, x2)\nY = fun_rosen(X1, X2)\nfig, ax = plt.subplots()\nCS = ax.contour(X1, X2, Y , 50)\nax.clabel(CS, inline=True, fontsize=10)\nax.set_title(\"Rosenbrock's Banana Function\")\n\nText(0.5, 1.0, \"Rosenbrock's Banana Function\")",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Response Surface Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#sec-rsm-intro",
    "href": "005_num_rsm.html#sec-rsm-intro",
    "title": "6  Response Surface Methods",
    "section": "",
    "text": "contour plot example:\n\n\\(x_1\\) and \\(x_2\\) are the independent variables\n\\(y\\) is the dependent variable\n\n\n\n\nVisual inspection: yield is optimized near \\((\\xi_1. \\xi_2)\\)\n\n\n6.1.1 Visualization: Problems in Practice\n\nTrue response surface is unknown in practice\nWhen yield evaluation is not as simple as a toy banana function, but a process requiring care to monitor, reconfigure and run, it’s far too expensive to observe over a dense grid\nAnd, measuring yield may be a noisy/inexact process\nThat’s where stats (RSM) comes in\n\n\n\n6.1.2 RSM: Strategies\n\nRSMs consist of experimental strategies for\nexploring the space of the process (i.e., independent/input) variables (above \\(\\xi_1\\) and \\(\\xi2)\\)\nempirical statistical modeling targeted toward development of an appropriate approximating relationship between the response (yield) and process variables local to a study region of interest\noptimization methods for sequential refinement in search of the levels or values of process variables that produce desirable responses (e.g., that maximize yield or explain variation)\nRSM used for fitting an Empirical Model\nTrue response surface driven by an unknown physical mechanism\nObservations corrupted by noise\nHelpful: fit an empirical model to output collected under different process configurations\nConsider response \\(Y\\) that depends on controllable input variables \\(\\xi_1, \\xi_2, \\ldots, \\xi_m\\)\nRSM: Equations of the Empirical Model\n\n\\(Y=f(\\xi_1, \\xi_2, \\ldots, \\xi_m) + \\epsilon\\)\n\\(\\mathbb{E}\\{Y\\} = \\eta = f(\\xi1_1, \\xi_2, \\ldots, \\xi_m)\\)\n\\(\\epsilon\\) is treated as zero mean idiosyncratic noise possibly representing\n\ninherent variation, or\nthe effect of other systems or\nvariables not under our purview at this time\n\n\n\n\n\n6.1.3 RSM: Noise in the Empirical Model\n\nTypical simplifying assumption: \\(\\epsilon \\sim N(0,\\sigma^2)\\)\nWe seek estimates for \\(f\\) and \\(\\sigma^2\\) from noisy observations \\(Y\\) at inputs \\(\\xi\\)\n\n\n\n6.1.4 RSM: Natural and Coded Variables\n\nInputs \\(\\xi_1, \\xi_2, \\ldots, \\xi_m\\) called natural variables:\n\nexpressed in natural units of measurement, e.g., degrees Celsius, pounds per square inch (psi), etc.\n\nTransformed to coded variables \\(x_1, x_2, \\ldots, x_m\\):\n\nto mitigate hassles and confusion that can arise when working with a multitude of scales of measurement\n\nTypical Transformations offering dimensionless inputs \\(x_1, x_2, \\ldots, x_m\\)\n\nin the unit cube, or\nscaled to have a mean of zero and standard deviation of one, are common choices.\n\nEmpirical model becomes \\(\\eta = f(x_1, x_2, \\ldots, x_m)\\)\n\n\n\n6.1.5 RSM Low-order Polynomials\n\nLow-order polynomial make the following simplifying Assumptions\n\nLearning about \\(f\\) is lots easier if we make some simplifying approximations\nAppealing to Taylor’s theorem, a low-order polynomial in a small, localized region of the input (\\(x\\)) space is one way forward\nClassical RSM:\n\ndisciplined application of local analysis and\nsequential refinement of locality through conservative extrapolation\n\nInherently a hands-on process",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Response Surface Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#first-order-models-main-effects-model",
    "href": "005_num_rsm.html#first-order-models-main-effects-model",
    "title": "6  Response Surface Methods",
    "section": "6.2 First-Order Models (Main Effects Model)",
    "text": "6.2 First-Order Models (Main Effects Model)\n\nFirst-order model (sometimes called main effects model) useful in parts of the input space where it’s believed that there’s little curvature in \\(f\\): \\[\\eta = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 \\]\nFor example: \\[\\eta = 50 + 8 x_1 + 3x_2\\]\nIn practice, such a surface would be obtained by fitting a model to the outcome of a designed experiment\nFirst-Order Model in python Evaluated on a Grid\nEvaluate model on a grid in a double-unit square centered at the origin\nCoded units are chosen arbitrarily, although one can imagine deploying this approximating function nearby \\(x^{(0)} = (0,0)\\)\n\n\ndef fun_1(x1,x2):\n    return 50 + 8*x1 + 3*x2\n\n\nimport numpy as np\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\n\ndelta = 0.025\nx1 = np.arange(-1.0, 1.0, delta)\nx2 = np.arange(-1.0, 1.0, delta)\nX1, X2 = np.meshgrid(x1, x2)\nY = fun_1(X1,X2)\nfig, ax = plt.subplots()\nCS = ax.contour(X1, X2, Y)\nax.clabel(CS, inline=True, fontsize=10)\nax.set_title('First Order Model: $50 + 8x_1 + 3x_2$')\n\nText(0.5, 1.0, 'First Order Model: $50 + 8x_1 + 3x_2$')\n\n\n\n\n\n\n\n\n\n\n6.2.1 First-Order Model Properties\n\nFirst-order model in 2d traces out a plane in \\(y \\times (x_1, x_2)\\) space\nOnly be appropriate for the most trivial of response surfaces, even when applied in a highly localized part of the input space\nAdding curvature is key to most applications:\n\nFirst-order model with interactions induces limited degree of curvature via different rates of change of \\(y\\) as \\(x_1\\) is varied for fixed \\(x_2\\), and vice versa: \\[\\eta = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_{12} x_{12} \\]\n\nFor example \\(\\eta = 50+8x_1+3x_2-4x_1x_2\\)\n\n\n\n6.2.2 First-order Model with Interactions in python\n\nCode below facilitates evaluations for pairs \\((x_1, x_2)\\)\nResponses may be observed over a mesh in the same double-unit square\n\n\ndef fun_11(x1,x2):\n    return 50 + 8 * x1 + 3 * x2 - 4 * x1 * x2\n\n\nimport numpy as np\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\n\ndelta = 0.025\nx1 = np.arange(-2.0, 2.0, delta)\nx2 = np.arange(-2.0, 2.0, delta)\nX1, X2 = np.meshgrid(x1, x2)\nY = fun_11(X1,X2)\nfig, ax = plt.subplots()\nCS = ax.contour(X1, X2, Y, 20)\nax.clabel(CS, inline=True, fontsize=10)\nax.set_title('First Order Model with Interactions')\n\nText(0.5, 1.0, 'First Order Model with Interactions')\n\n\n\n\n\n\n\n\n\n\n\n6.2.3 Observations: First-Order Model with Interactions\n\nMean response \\(\\eta\\) is increasing marginally in both \\(x_1\\) and \\(x_2\\), or conditional on a fixed value of the other until \\(x_1\\) is 0.75\nRate of increase slows as both coordinates grow simultaneously since the coefficient in front of the interaction term \\(x_1 x_2\\) is negative\nCompared to the first-order model (without interactions): surface is far more useful locally\nLeast squares regressions often flag up significant interactions when fit to data collected on a design far from local optima",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Response Surface Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#second-order-models",
    "href": "005_num_rsm.html#second-order-models",
    "title": "6  Response Surface Methods",
    "section": "6.3 Second-Order Models",
    "text": "6.3 Second-Order Models\n\nSecond-order model may be appropriate near local optima where \\(f\\) would have substantial curvature: \\[\\eta = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2  + \\beta_{11}x_1^2 + \\beta_{22}x^2 + \\beta_{12} x_1 x_2\\]\nFor example \\[\\eta = 50 + 8 x_1 + 3x_2 - 7x_1^2 - 3 x_2^2 - 4x_1x_2\\]\nImplementation of the Second-Order Model as fun_2().\n\n\ndef fun_2(x1,x2):\n    return 50 + 8 * x1 + 3 * x2 - 7 * x1**2 - 3*x2**2 - 4 * x1 * x2\n\n\nimport numpy as np\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\n\ndelta = 0.025\nx1 = np.arange(-2.0, 2.0, delta)\nx2 = np.arange(-2.0, 2.0, delta)\nX1, X2 = np.meshgrid(x1, x2)\nY = fun_2(X1,X2)\nfig, ax = plt.subplots()\nCS = ax.contour(X1, X2, Y, 20)\nax.clabel(CS, inline=True, fontsize=10)\nax.set_title('Second Order Model with Interactions. Maximum near about $(0.6,0.2)$')\n\nText(0.5, 1.0, 'Second Order Model with Interactions. Maximum near about $(0.6,0.2)$')\n\n\n\n\n\n\n\n\n\n\n6.3.1 Second-Order Models: Properties\n\nNot all second-order models would have a single stationary point (in RSM jargon called “a simple maximum”)\nIn “yield maximizing” setting we’re presuming response surface is concave down from a global viewpoint\n\neven though local dynamics may be more nuanced\n\nExact criteria depend upon the eigenvalues of a certain matrix built from those coefficients\nBox and Draper (2007) provide a diagram categorizing all of the kinds of second-order surfaces in RSM analysis, where finding local maxima is the goal\n\n\n\n6.3.2 Example: Stationary Ridge\n\nExample set of coefficients describing what’s called a stationary ridge is provided by the code below\n\n\ndef fun_ridge(x1, x2):\n    return 80 + 4*x1 + 8*x2 - 3*x1**2 - 12*x2**2 - 12*x1*x2\n\n\nimport numpy as np\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\n\ndelta = 0.025\nx1 = np.arange(-2.0, 2.0, delta)\nx2 = np.arange(-2.0, 2.0, delta)\nX1, X2 = np.meshgrid(x1, x2)\nY = fun_ridge(X1,X2)\nfig, ax = plt.subplots()\nCS = ax.contour(X1, X2, Y, 20)\nax.clabel(CS, inline=True, fontsize=10)\nax.set_title('Example of a stationary ridge')\n\nText(0.5, 1.0, 'Example of a stationary ridge')\n\n\n\n\n\n\n\n\n\n\n\n6.3.3 Observations: Second-Order Model (Ridge)\n\nRidge: a whole line of stationary points corresponding to maxima\nSituation means that the practitioner has some flexibility when it comes to optimizing:\n\ncan choose the precise setting of \\((x_1, x_2)\\) either arbitrarily or (more commonly) by consulting some tertiary criteria\n\n\n\n\n6.3.4 Example: Rising Ridge\n\nAn example of a rising ridge is implemented by the code below.\n\n\ndef fun_ridge_rise(x1, x2):\n     return 80 - 4*x1 + 12*x2 - 3*x1**2 - 12*x2**2 - 12*x1*x2\n\n\nimport numpy as np\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\n\ndelta = 0.025\nx1 = np.arange(-2.0, 2.0, delta)\nx2 = np.arange(-2.0, 2.0, delta)\nX1, X2 = np.meshgrid(x1, x2)\nY = fun_ridge_rise(X1,X2)\nfig, ax = plt.subplots()\nCS = ax.contour(X1, X2, Y, 20)\nax.clabel(CS, inline=True, fontsize=10)\nax.set_title('Rising ridge: $\\\\eta = 80 + 4x_1 + 8x_2 - 3x_1^2 - 12x_2^2 - 12x_1x_2$')\n\nText(0.5, 1.0, 'Rising ridge: $\\\\eta = 80 + 4x_1 + 8x_2 - 3x_1^2 - 12x_2^2 - 12x_1x_2$')\n\n\n\n\n\n\n\n\n\n\n\n6.3.5 Summary: Rising Ridge\n\nThe stationary point is remote to the study region\nCcontinuum of (local) stationary points along any line going through the 2d space, excepting one that lies directly on the ridge\nAlthough estimated response will increase while moving along the axis of symmetry toward its stationary point, this situation indicates\n\neither a poor fit by the approximating second-order function, or\nthat the study region is not yet precisely in the vicinity of a local optima—often both.\n\n\n\n\n6.3.6 Falling Ridge\n\nInversion of a rising ridge is a falling ridge\nSimilarly indicating one is far from local optima, except that the response decreases as you move toward the stationary point\nFinding a falling ridge system can be a back-to-the-drawing-board affair.\n\n\n\n6.3.7 Saddle Point\n\nFinally, we can get what’s called a saddle or minimax system.\n\n\ndef fun_saddle(x1, x2):\n    return 80 + 4*x1 + 8*x2 - 2*x2**2 - 12*x1*x2 \n\n\nimport numpy as np\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\n\ndelta = 0.025\nx1 = np.arange(-2.0, 2.0, delta)\nx2 = np.arange(-2.0, 2.0, delta)\nX1, X2 = np.meshgrid(x1, x2)\nY = fun_saddle(X1,X2)\nfig, ax = plt.subplots()\nCS = ax.contour(X1, X2, Y, 20)\nax.clabel(CS, inline=True, fontsize=10)\nax.set_title('Saddle Point: $\\\\eta = 80 + 4x_1 + 8x_2 - 2x_2^2 - 12x_1x_2$')\n\nText(0.5, 1.0, 'Saddle Point: $\\\\eta = 80 + 4x_1 + 8x_2 - 2x_2^2 - 12x_1x_2$')\n\n\n\n\n\n\n\n\n\n\n\n6.3.8 Interpretation: Saddle Points\n\nLikely further data collection, and/or outside expertise, is needed before determining a course of action in this situation\n\n\n\n6.3.9 Summary: Ridge Analysis\n\nFinding a simple maximum, or stationary ridge, represents ideals in the spectrum of second-order approximating functions\nBut getting there can be a bit of a slog\nUsing models fitted from data means uncertainty due to noise, and therefore uncertainty in the type of fitted second-order model\nA ridge analysis attempts to offer a principled approach to navigating uncertainties when one is seeking local maxima\nThe two-dimensional setting exemplified above is convenient for visualization, but rare in practice\nComplications compound when studying the effect of more than two process variables",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Response Surface Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#general-rsm-models",
    "href": "005_num_rsm.html#general-rsm-models",
    "title": "6  Response Surface Methods",
    "section": "6.4 General RSM Models",
    "text": "6.4 General RSM Models\n\nGeneral first-order model on \\(m\\) process variables \\(x_1, x_2, \\cdots, x_m\\) is \\[\\eta = \\beta_0 + \\beta_1x_1 + \\cdots + \\beta_m x_m\\]\nGeneral second-order model on \\(m\\) process variables \\[\n\\eta= \\beta_0 + \\sum_{j=1}^m + \\sum_{j=1}^m x_j^2 + \\sum_{j=2}^m \\sum_{k=1}^j \\beta_{kj}x_k x_j.\n\\]\n\n\n6.4.1 Ordinary Least Squares\n\nInference from data is carried out by ordinary least squares (OLS)\nFor an excellent review including R examples, see Sheather (2009)\nOLS and maximum likelihood estimators (MLEs) are in the typical Gaussian linear modeling setup basically equivalent",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Response Surface Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#general-linear-regression",
    "href": "005_num_rsm.html#general-linear-regression",
    "title": "6  Response Surface Methods",
    "section": "6.5 General Linear Regression",
    "text": "6.5 General Linear Regression\nWe are considering a model, which can be written in the form\n\\[\nY = X \\beta + \\epsilon,\n\\] where \\(Y\\) is an \\((n \\times 1)\\) vector of observations (responses), \\(X\\) is an \\((n \\times p)\\) matrix of known form, \\(\\beta\\) is a \\((1 \\times p)\\) vector of unknown parameters, and \\(\\epsilon\\) is an \\((n \\times 1)\\) vector of errors. Furthermore, \\(E(\\epsilon) = 0\\), \\(Var(\\epsilon) = \\sigma^2 I\\) and the \\(\\epsilon_i\\) are uncorrelated.\nUsing the normal equations \\[\n(X'X)b = X'Y,\n\\]\nthe solution is given by\n\\[\nb = (X'X)^{-1}X'Y.\n\\]\n\nExample 6.1 (Linear Regression)  \n\nimport numpy as np\nn = 8\nX = np.linspace(0, 2*np.pi, n, endpoint=False).reshape(-1,1)\nprint(np.round(X, 2))\ny = np.sin(X)\nprint(np.round(y, 2))\n# fit an OLS model to the data, predict the response based on the 1ßß x values\nm = 100\nx = np.linspace(0, 2*np.pi, m, endpoint=False).reshape(-1,1)\nfrom sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\nmodel.fit(X, y)\ny_pred = model.predict(x)\n# visualize the data and the fitted model\nimport matplotlib.pyplot as plt\nplt.scatter(X, y, color='black')\nplt.plot(x, y_pred, color='blue', linewidth=1)\n# add the ground truth (sine function) in orange\nplt.plot(x, np.sin(x), color='orange', linewidth=1)\nplt.show()\n\n[[0.  ]\n [0.79]\n [1.57]\n [2.36]\n [3.14]\n [3.93]\n [4.71]\n [5.5 ]]\n[[ 0.  ]\n [ 0.71]\n [ 1.  ]\n [ 0.71]\n [ 0.  ]\n [-0.71]\n [-1.  ]\n [-0.71]]",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Response Surface Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#designs",
    "href": "005_num_rsm.html#designs",
    "title": "6  Response Surface Methods",
    "section": "6.6 Designs",
    "text": "6.6 Designs\n\nImportant: Organize the data collection phase of a response surface study carefully\nDesign: choice of \\(x\\)’s where we plan to observe \\(y\\)’s, for the purpose of approximating \\(f\\)\nAnalyses and designs need to be carefully matched\nWhen using a first-order model, some designs are preferred over others\nWhen using a second-order model to capture curvature, a different sort of design is appropriate\nDesign choices often contain features enabling modeling assumptions to be challenged\n\ne.g., to check if initial impressions are supported by the data ultimately collected\n\n\n\n6.6.1 Different Designs\n\nScreening desings: determine which variables matter so that subsequent experiments may be smaller and/or more focused\nThen there are designs tailored to the form of model (first- or second-order, say) in the screened variables\nAnd then there are more designs still",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Response Surface Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#rsm-experimentation",
    "href": "005_num_rsm.html#rsm-experimentation",
    "title": "6  Response Surface Methods",
    "section": "6.7 RSM Experimentation",
    "text": "6.7 RSM Experimentation\n\n6.7.1 First Step\n\nRSM-based experimentation begins with a first-order model, possibly with interactions\nPresumption: current process operating far from optimal conditions\nCollect data and apply method of steepest ascent (gradient) on fitted surfaces to move to the optimum\n\n\n\n6.7.2 Second Step\n\nEventually, if all goes well after several such carefully iterated refinements, second-order models are used on appropriate designs in order to zero-in on ideal operating conditions\nCareful analysis of the fitted surface:\n\nRidge analysis with further refinement using gradients of, and\nstandard errors associated with, the fitted surfaces, and so on\n\n\n\n\n6.7.3 Third Step\n\nOnce the practitioner is satisfied with the full arc of\n\ndesign(s),\nfit(s), and\ndecision(s):\n\nA small experiment called confirmation test may be performed to check if the predicted optimal settings are realizable in practice",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Response Surface Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#rsm-review-and-general-considerations",
    "href": "005_num_rsm.html#rsm-review-and-general-considerations",
    "title": "6  Response Surface Methods",
    "section": "6.8 RSM: Review and General Considerations",
    "text": "6.8 RSM: Review and General Considerations\n\nFirst Glimpse, RSM seems sensible, and pretty straightforward as quantitative statistics-based analysis goes\nBut: RSM can get complicated, especially when input dimensions are not very low\nDesign considerations are particularly nuanced, since the goal is to obtain reliable estimates of main effects, interaction, and curvature while minimizing sampling effort/expense\nRSM Downside: Inefficiency\n\nDespite intuitive appeal, several RSM downsides become apparent upon reflection\nProblems in practice\nStepwise nature of sequential decision making is inefficient:\n\nNot obvious how to re-use or update analysis from earlier phases, or couple with data from other sources/related experiments\n\n\nRSM Downside: Locality\n\nIn addition to being local in experiment-time (stepwise approach), it’s local in experiment-space\nBalance between\n\nexploration (maybe we’re barking up the wrong tree) and\nexploitation (let’s make things a little better) is modest at best\n\n\nRSM Downside: Expert Knowledge\n\nInterjection of expert knowledge is limited to hunches about relevant variables (i.e., the screening phase), where to initialize search, how to design the experiments\nYet at the same time classical RSMs rely heavily on constant examination throughout stages of modeling and design and on the instincts of seasoned practitioners\n\nRSM Downside: Replicability\n\nParallel analyses, conducted according to the same best intentions, rarely lead to the same designs, model fits and so on\nSometimes that means they lead to different conclusions, which can be cause for concern\n\n\n\n6.8.1 Historical Considerations about RSM\n\nIn spite of those criticisms, however, there was historically little impetus to revise the status quo\nClassical RSM was comfortable in its skin, consistently led to improvements or compelling evidence that none can reasonably be expected\nBut then in the late 20th century came an explosive expansion in computational capability, and with it a means of addressing many of those downsides\n\n\n\n6.8.2 Status Quo\n\nNowadays, field experiments and statistical models, designs and optimizations are coupled with with mathematical models\nSimple equations are not regarded as sufficient to describe real-world systems anymore\nPhysicists figured that out fifty years ago; industrial engineers followed, biologists, social scientists, climate scientists and weather forecasters, etc.\nSystems of equations are required, solved over meshes (e.g., finite elements), or stochastically interacting agents\nGoals for those simulation experiments are as diverse as their underlying dynamics\nOptimization of systems is common, e.g., to identify worst-case scenarios\n\n\n\n6.8.3 The Role of Statistics\n\nSolving systems of equations, or interacting agents, requires computing\nStatistics involved at various stages:\n\nchoosing the mathematical model\nsolving by stochastic simulation (Monte Carlo)\ndesigning the computer experiment\nsmoothing over idiosyncrasies or noise\nfinding optimal conditions, or\ncalibrating mathematical/computer models to data from field experiments\n\n\n\n\n6.8.4 New RSM is needed: DACE\n\nClassical RSMs are not well-suited to any of those tasks, because\n\nthey lack the fidelity required to model these data\ntheir intended application is too local\nthey’re also too hands-on.\n\nOnce computers are involved, a natural inclination is to automate—to remove humans from the loop and set the computer running on the analysis in order to maximize computing throughput, or minimize idle time\nDesign and Analysis of Computer Experiments as a modern extension of RSM\nExperimentation is changing due to advances in machine learning\nGaussian process (GP) regression is the canonical surrogate model\nOrigins in geostatistics (gold mining)\nWide applicability in contexts where prediction is king\nMachine learners exposed GPs as powerful predictors for all sorts of tasks:\nfrom regression to classification,\nactive learning/sequential design,\nreinforcement learning and optimization,\nlatent variable modeling, and so on",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Response Surface Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#exercises",
    "href": "005_num_rsm.html#exercises",
    "title": "6  Response Surface Methods",
    "section": "6.9 Exercises",
    "text": "6.9 Exercises\n\nGenerate 3d Plots for the Contour Plots in this notebook.\nWrite a plot_3d function, that takes the objective function fun as an argument.\n\n\nIt should provide the following interface: plot_3d(fun).\n\n\nWrite a plot_contour function, that takes the objective function fun as an argument:\n\n\nIt should provide the following interface: plot_contour(fun).\n\n\nConsider further arguments that might be useful for both function, e.g., ranges, size, etc.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Response Surface Methods</span>"
    ]
  },
  {
    "objectID": "005_num_rsm.html#jupyter-notebook",
    "href": "005_num_rsm.html#jupyter-notebook",
    "title": "6  Response Surface Methods",
    "section": "6.10 Jupyter Notebook",
    "text": "6.10 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Response Surface Methods</span>"
    ]
  },
  {
    "objectID": "006_num_poly.html",
    "href": "006_num_poly.html",
    "title": "7  Polynomial Models",
    "section": "",
    "text": "7.1 Fitting a Polynomial\nWe will consider one-variable cases, i.e., \\(k=1\\), first.\nLet us consider the scalar-valued function \\(f: \\mathbb{R} \\to \\mathbb{R}\\) observed according to the sampling plan \\(X = \\{x^{(1)}, x^{(2)} \\dots, x^{(n)}\\}^T\\), yielding the responses \\(\\vec{y} = \\{y^{(1)}, y^{(2)}, \\dots, y^{(n)}\\}^T\\).\nA polynomial approximation of \\(f\\) of order \\(m\\) can be written as:\n\\[\n\\hat{f}(x, m, \\vec{w}) = \\sum_{i=0}^m w_i x^i.\n\\]\nIn the spirit of the earlier discussion of maximum likelihood parameter estimation, we seek to estimate \\(w = {w_0, w_1, \\dots, w_m}^T\\) through a least squares solution of:\n\\[\n\\Phi \\vec{w} = \\vec{y}\n\\] where \\(\\Phi\\) is the Vandermonde matrix:\n\\[\n\\Phi =\n\\begin{bmatrix}\n1 & x_1 & x_1^2 & \\dots & x_1^m \\\\\n1 & x_2 & x_2^2 & \\dots & x_2^m \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n1 & x_n & x_n^2 & \\dots & x_n^m\n\\end{bmatrix}.\n\\]\nThe maximum likelihood estimate of \\(w\\) is given by:\n\\[\n\\vec{w} = (\\Phi^T \\Phi)^{-1} \\Phi^T y,\n\\]\nwhere \\(\\Phi^+ = (\\Phi^T \\Phi)^{-1} \\Phi^T\\) is the Moore-Penrose pseudo-inverse of \\(\\Phi\\) (see Section 10.3).\nThe polynomial approximation of order \\(m\\) is essentially a truncated Taylor series expansion. While higher values of \\(m\\) yield more accurate approximations, they risk overfitting the noise in the data.\nTo prevent this, we estimate \\(m\\) using cross-validation. This involves minimizing the cross-validation error over a discrete set of possible orders \\(m\\) (e.g., \\(m \\in {1, 2, \\dots, 15}\\)).\nFor each \\(m\\), the data is split into \\(q\\) subsets. The model is trained on \\(q-1\\) subsets, and the error is computed on the left-out subset. This process is repeated for all subsets, and the cross-validation error is summed. The order \\(m\\) with the smallest cross-validation error is chosen.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Polynomial Models</span>"
    ]
  },
  {
    "objectID": "006_num_poly.html#polynomial-fitting-in-python",
    "href": "006_num_poly.html#polynomial-fitting-in-python",
    "title": "7  Polynomial Models",
    "section": "7.2 Polynomial Fitting in Python",
    "text": "7.2 Polynomial Fitting in Python\n\n7.2.1 Fitting the Polynomial\n\nfrom sklearn.model_selection import KFold\ndef polynomial_fit(X, Y, max_order=15, q=5):\n    \"\"\"\n    Fits a one-variable polynomial to one-dimensional data using cross-validation.\n\n    Args:\n        X (array-like): Training data vector (independent variable).\n        Y (array-like): Training data vector (dependent variable).\n        max_order (int): Maximum polynomial order to consider. Default is 15.\n        q (int): Number of cross-validation folds. Default is 5.\n\n    Returns:\n        best_order (int): The optimal polynomial order.\n        coeff (array): Coefficients of the best-fit polynomial.\n        mnstd (tuple): Normalization parameters (mean, std) for X.\n    \"\"\"\n    X = np.array(X)\n    Y = np.array(Y)\n    n = len(X)\n    # Normalize X\n    mnstd = (np.mean(X), np.std(X))\n    X_norm = (X - mnstd[0]) / mnstd[1]\n    # Cross-validation setup\n    kf = KFold(n_splits=q, shuffle=True, random_state=42)\n    cross_val_errors = np.zeros(max_order)\n    for order in range(1, max_order + 1):\n        fold_errors = []\n        for train_idx, val_idx in kf.split(X_norm):\n            X_train, X_val = X_norm[train_idx], X_norm[val_idx]\n            Y_train, Y_val = Y[train_idx], Y[val_idx]\n            # Fit polynomial\n            coeff = np.polyfit(X_train, Y_train, order)\n            # Predict on validation set\n            Y_pred = np.polyval(coeff, X_val)\n            # Compute mean squared error\n            mse = np.mean((Y_val - Y_pred) ** 2)\n            fold_errors.append(mse)\n        cross_val_errors[order - 1] = np.mean(fold_errors)\n    # Find the best order\n    best_order = np.argmin(cross_val_errors) + 1\n    # Fit the best polynomial on the entire dataset\n    best_coeff = np.polyfit(X_norm, Y, best_order)\n    return best_order, best_coeff, mnstd\n\n\n\n7.2.2 Explaining the \\(k\\)-fold Cross-Validation\nThe line\nkf = KFold(n_splits=q, shuffle=True, random_state=42)\ninitializes a \\(k\\)-Fold cross-validator object from the sklearn.model_selection library. The n_splits parameter specifies the number of folds. The data will be divided into q parts. In each iteration of the cross-validation, one part will be used as the validation set, and the remaining q-1 parts will be used as the training set.\nThe kf.split method takes the dataset X_norm as input and yields pairs of index arrays for each fold: * train_idx: In each iteration, train_idx is an array containing the indices of the data points that belong to the training set for that specific fold. * val_idx: Similarly, val_idx is an array containing the indices of the data points that belong to the validation (or test) set for that specific fold.\nThe loop will run q times (the number of splits). In each iteration, a different fold serves as the validation set, while the other q-1 folds form the training set.\nHere’s a Python example to demonstrate the values of train_idx and val_idx:\n\n# Sample data (e.g., X_norm)\nX_norm = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\nprint(f\"Original data indices: {np.arange(len(X_norm))}\\n\")\n# Number of splits (folds)\nq = 3 # Let's use 3 folds for this example\n# Initialize KFold\nkf = KFold(n_splits=q, shuffle=True, random_state=42)\n# Iterate through the splits and print the indices\nfold_number = 1\nfor train_idx, val_idx in kf.split(X_norm):\n    print(f\"--- Fold {fold_number} ---\")\n    print(f\"Train indices: {train_idx}\")\n    print(f\"Validation indices: {val_idx}\")\n    print(f\"Training data for this fold: {X_norm[train_idx]}\")\n    print(f\"Validation data for this fold: {X_norm[val_idx]}\\n\")\n    fold_number += 1\n\nOriginal data indices: [0 1 2 3 4 5 6 7 8 9]\n\n--- Fold 1 ---\nTrain indices: [2 3 4 6 7 9]\nValidation indices: [0 1 5 8]\nTraining data for this fold: [0.3 0.4 0.5 0.7 0.8 1. ]\nValidation data for this fold: [0.1 0.2 0.6 0.9]\n\n--- Fold 2 ---\nTrain indices: [0 1 3 4 5 6 8]\nValidation indices: [2 7 9]\nTraining data for this fold: [0.1 0.2 0.4 0.5 0.6 0.7 0.9]\nValidation data for this fold: [0.3 0.8 1. ]\n\n--- Fold 3 ---\nTrain indices: [0 1 2 5 7 8 9]\nValidation indices: [3 4 6]\nTraining data for this fold: [0.1 0.2 0.3 0.6 0.8 0.9 1. ]\nValidation data for this fold: [0.4 0.5 0.7]\n\n\n\n\n\n7.2.3 Making Predictions\nTo make predictions, we can use the coefficients. The data is standardized around its mean in the polynomial function, which is why the vector mnstd is required. The coefficient vector is computed based on the normalized data, and this must be taken into account if further analytical calculations are performed on the fitted model.\nThe polynomial approximation of \\(C_D\\) is:\n\\[\nC_D(x) = w_8 x^8 + w_7 x^7 + \\dots + w_1 x + w_0,\n\\]\nwhere \\(x\\) is normalized as:\n\\[\n\\bar{x} = \\frac{x - \\mu(X)}{\\sigma(X)}\n\\]\n\ndef predict_polynomial_fit(X, coeff, mnstd):\n    \"\"\"\n    Generates predictions for the polynomial fit.\n\n    Args:\n        X (array-like): Original independent variable data.\n        coeff (array): Coefficients of the best-fit polynomial.\n        mnstd (tuple): Normalization parameters (mean, std) for X.\n\n    Returns:\n        tuple: De-normalized predicted X values and corresponding Y predictions.\n    \"\"\"\n    # Normalize X\n    X_norm = (X - mnstd[0]) / mnstd[1]\n\n    # Generate predictions\n    X_pred = np.linspace(min(X_norm), max(X_norm), 100)\n    Y_pred = np.polyval(coeff, X_pred)\n\n    # De-normalize X for plotting\n    X_pred_original = X_pred * mnstd[1] + mnstd[0]\n\n    return X_pred_original, Y_pred\n\n\n\n7.2.4 Plotting the Results\n\ndef plot_polynomial_fit(X, Y, X_pred_original, Y_pred, best_order, y_true=None):\n    \"\"\"\n    Visualizes the polynomial fit.\n\n    Args:\n        X (array-like): Original independent variable data.\n        Y (array-like): Original dependent variable data.\n        X_pred_original (array): De-normalized predicted X values.\n        Y_pred (array): Predicted Y values.\n        y_true (array): True Y values.\n        best_order (int): The optimal polynomial order.\n    \"\"\"\n    plt.scatter(X, Y, label=\"Training Data\", color=\"grey\", marker=\"o\")\n    plt.plot(X_pred_original, Y_pred, label=f\"Order {best_order} Polynomial\", color=\"red\")\n    if y_true is not None:\n        plt.plot(X, y_true, label=\"True Function\", color=\"blue\", linestyle=\"--\")\n    plt.title(f\"Polynomial Fit (Order {best_order})\")\n    plt.xlabel(\"X\")\n    plt.ylabel(\"Y\")\n    plt.legend()\n    plt.show()",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Polynomial Models</span>"
    ]
  },
  {
    "objectID": "006_num_poly.html#example-one-aerofoil-drag",
    "href": "006_num_poly.html#example-one-aerofoil-drag",
    "title": "7  Polynomial Models",
    "section": "7.3 Example One: Aerofoil Drag",
    "text": "7.3 Example One: Aerofoil Drag\nThe circles in Figure 7.1 represent 101 drag coefficient values obtained through a numerical simulation by iterating each member of a family of aerofoils towards a target lift value (see the Appendix, Section A.3 in Forrester, Sóbester, and Keane (2008)). The members of the family have different shapes, as determined by the sampling plan:\n\\[\nX = {x_1, x_2, \\dots, x_{101}}\n\\]\nThe responses are:\n\\[\nC_D = \\{C_{D}^{(1)}, C_{D}^{(2)}, \\dots, C_{D}^{(101)}\\}\n\\]\nThese responses are corrupted by “noise,” which are deviations of the systematic variety caused by small changes in the computational mesh from one design to the next.\nThe original data is measured in natural units, i.e., from \\(-0.3\\) untion to \\(0.1\\) unit. The data is normalized to the range of \\(0\\) to \\(1\\) for the computation with the aerofoilcd function. The data is then fitted with a polynomial of order \\(m\\). To obtain the best polynomial through this data, the following Python code can be used:\n\nfrom spotpython.surrogate.functions.forr08a import aerofoilcd\nimport numpy as np\nimport matplotlib.pyplot as plt\nX = np.linspace(-0.3, 0.1, 101)\n# normalize the data so that it will be in the range of 0 to 1\na = np.min(X)\nb = np.max(X)\nX_cod = (X - a) / (b - a)\ny = aerofoilcd(X_cod)\nbest_order, best_coeff, mnstd = polynomial_fit(X, y)\nX_pred_original, Y_pred = predict_polynomial_fit(X, best_coeff, mnstd)\n\n\nplot_polynomial_fit(X, y, X_pred_original, Y_pred, best_order)\n\n\n\n\n\n\n\nFigure 7.1: Aerofoil drag data\n\n\n\n\n\nFigure 7.1 shows an eighth-order polynomial fitted through the aerofoil drag data. The order was selected via cross-validation, and the coefficients were determined through likelihood maximization. Results, i.e, the best polynomial order and coefficients, are printed in the console. The coefficients are stored in the vector best_coeff, which contains the coefficients of the polynomial in descending order. The first element is the coefficient of \\(x^8\\), and the last element is the constant term. The vector mnstd, containing the mean and standard deviation of \\(X\\), is:\n\nprint(f\"Best polynomial order: {best_order}\\n\")\nprint(f\"Coefficients (starting with w0):\\n {best_coeff}\\n\")\nprint(f\"Normalization parameters (mean, std):\\n {mnstd}\\n\")\n\nBest polynomial order: 8\n\nCoefficients (starting with w0):\n [-0.00022964 -0.00014636  0.00116742  0.00052988 -0.0016912  -0.00047398\n  0.00244373  0.00270342  0.03041508]\n\nNormalization parameters (mean, std):\n (np.float64(-0.09999999999999999), np.float64(0.11661903789690602))",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Polynomial Models</span>"
    ]
  },
  {
    "objectID": "006_num_poly.html#example-two-a-multimodal-test-case",
    "href": "006_num_poly.html#example-two-a-multimodal-test-case",
    "title": "7  Polynomial Models",
    "section": "7.4 Example Two: A Multimodal Test Case",
    "text": "7.4 Example Two: A Multimodal Test Case\nLet us consider the one-variable test function:\n\\[\nf(x) = (6x - 2)^2 \\sin(12x - 4).\n\\]\n\nimport numpy as np\nfrom spotpython.surrogate.functions.forr08a import onevar\nX = np.linspace(0, 1, 51)\ny_true = onevar(X)\n# initialize random seed\nnp.random.seed(42)\ny = y_true + np.random.normal(0, 1, len(X))*1.1\nbest_order, best_coeff, mnstd = polynomial_fit(X, y)\nX_pred_original, Y_pred = predict_polynomial_fit(X, best_coeff, mnstd)\n\n\nplot_polynomial_fit(X, y, X_pred_original, Y_pred, best_order, y_true=y_true)\n\n\n\n\n\n\n\nFigure 7.2: Onevar function\n\n\n\n\n\nThis function, depicted by the dotted line in Figure 7.2, has local minima of different depths, which can be deceptive to some surrogate-based optimization procedures. Here, we use it as an example of a multimodal function for polynomial fitting.\nWe generate the training data (depicted by circles in Figure 7.2) by adding normally distributed noise to the function. Figure 7.2 shows a seventh-order polynomial fitted through the noisy data. This polynomial was selected as it minimizes the cross-validation metric.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Polynomial Models</span>"
    ]
  },
  {
    "objectID": "006_num_poly.html#extending-to-multivariable-polynomial-models",
    "href": "006_num_poly.html#extending-to-multivariable-polynomial-models",
    "title": "7  Polynomial Models",
    "section": "7.5 Extending to Multivariable Polynomial Models",
    "text": "7.5 Extending to Multivariable Polynomial Models\nWhile the examples above focus on the one-variable case, real-world engineering problems typically involve multiple input variables. For \\(k\\)-variable problems, polynomial approximation becomes significantly more complex but follows the same fundamental principles. For a \\(k\\)-dimensional input space, the polynomial approximation can be expressed as:\n\\[\n\\hat{f}(\\vec{x}) = \\sum_{i=1}^N w_i \\phi_i(\\vec{x}),\n\\] where \\(\\phi_i(\\vec{x})\\) represents multivariate basis functions, and \\(N\\) is the total number of terms in the polynomial. Unlike the univariate case, these basis functions include all possible combinations of variables up to the selected polynomial order \\(m\\), which might result in a “basis function explosion” as the number of variables increases.\nFor a third-order polynomial (\\(m = 3\\)) with three variables (\\(k = 3\\)), the complete set of basis functions would include 20 terms:\n\\[\\begin{align}\n\\text{Constant term: } & {1} \\\\\n\\text{First-order terms: } & {x_1, x_2, x_3} \\\\\n\\text{Second-order terms: } & {x_1^2, x_2^2, x_3^2, x_1x_2, x_1x_3, x_2x_3} \\\\\n\\text{Third-order terms: } & {x_1^3, x_2^3, x_3^3, x_1^2x_2, x_1^2x_3, x_2^2x_1, x_2^2x_3, x_3^2x_1, x_3^2x_2, x_1x_2x_3}\n\\end{align}\\]\nThe total number of terms grows combinatorially as \\(N = \\binom{k+m}{m}\\), which quickly becomes prohibitive as dimensionality increases. For example, a 10-variable cubic polynomial requires \\(\\binom{13}{3} = 286\\) coefficients! This exponential growth creates three interrelated challenges:\n\nModel Selection: Determining the appropriate polynomial order \\(m\\) that balances complexity with generalization ability\nCoefficient Estimation: Computing the potentially large number of weights \\(\\vec{w}\\) while avoiding numerical instability\nTerm Selection: Identifying which specific basis functions should be included, as many may be irrelevant to the response\n\nSeveral techniques have been developed to address these challenges:\n\nRegularization methods (LASSO, ridge regression) that penalize model complexity\nStepwise regression algorithms that incrementally add or remove terms\nDimension reduction techniques that project the input space to lower dimensions\nOrthogonal polynomials that improve numerical stability for higher-order models\n\nThese limitations of polynomial models in higher dimensions motivate the exploration of more flexible surrogate modeling approaches like Radial Basis Functions and Kriging, which we’ll examine in subsequent sections.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Polynomial Models</span>"
    ]
  },
  {
    "objectID": "006_num_poly.html#jupyter-notebook",
    "href": "006_num_poly.html#jupyter-notebook",
    "title": "7  Polynomial Models",
    "section": "7.6 Jupyter Notebook",
    "text": "7.6 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository\n\n\n\n\n\n\n\nForrester, Alexander, András Sóbester, and Andy Keane. 2008. Engineering Design via Surrogate Modelling. Wiley.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Polynomial Models</span>"
    ]
  },
  {
    "objectID": "006_num_rbf.html",
    "href": "006_num_rbf.html",
    "title": "8  Radial Basis Function Models",
    "section": "",
    "text": "8.1 Radial Basis Function Models\nScientists and engineers frequently tackle complex functions by decomposing them into a “vocabulary” of simpler, well-understood basic functions. These fundamental building blocks possess properties that make them easier to analyze mathematically and implement computationally. We explored this concept earlier with multivariable polynomials, where complex behaviors were modeled using combinations of polynomial terms such as \\(1\\), \\(x_1\\), \\(x_2\\), \\(x_1^2\\), and \\(x_1 x_2\\). This approach is not limited to polynomials; it extends to various function classes, including trigonometric functions, exponential functions, and even more complex structures.\nWhile Fourier analysis—perhaps the most widely recognized example of this approach—excels at representing periodic phenomena through sine and cosine functions, the focus in Forrester, Sóbester, and Keane (2008) is broader. They aim to approximate arbitrary smooth, continuous functions using strategically positioned basis functions. Specifically, radial basis function (RBF) models employ symmetrical basis functions centered at selected points distributed throughout the design space. These basis functions have the unique property that their output depends only on the distance from their center point.\nFirst, we give a definition of the Euclidean distance, which is the most common distance measure used in RBF models.\nThe Euclidean distance measure represents the straight-line distance between two points in Euclidean space.\nUsing the Euclidean distance, we can define the radial basis function (RBF) model.\nIn the context of RBFs, the Euclidean distance calculation determines how much influence a particular center point \\(\\vec{c}\\) has on the prediction at point \\(\\vec{x}\\).\nWe will first examine interpolating RBF models, which assume noise-free data and pass exactly through all training points. This approach provides an elegant mathematical foundation before we consider more practical scenarios where data contains measurement or process noise.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Radial Basis Function Models</span>"
    ]
  },
  {
    "objectID": "006_num_rbf.html#radial-basis-function-models",
    "href": "006_num_rbf.html#radial-basis-function-models",
    "title": "8  Radial Basis Function Models",
    "section": "",
    "text": "Definition 8.1 (Euclidean Distance) The Euclidean distance between two points in a \\(k\\)-dimensional space is defined as:\n\\[\n\\|\\vec{x} - \\vec{c}\\| = \\sqrt{\\sum_{i=1}^{k} (x_i - c_i)^2},\n\\tag{8.1}\\]\nwhere:\n\n\\(\\vec{x} = (x_1, x_2, \\ldots, x_d)\\) is the first point,\n\\(\\vec{c} = (c_1, c_2, \\ldots, c_d)\\) is the second point, and\n\\(k\\) is the number of dimensions.\n\n\n\n\n\nDefinition 8.2 (Radial Basis Function (RBF)) Mathematically, a radial basis function \\(\\psi\\) can be expressed as:\n\\[\n\\psi(\\vec{x}) = \\psi(\\|\\vec{x} - \\vec{c}\\|),\n\\tag{8.2}\\] where \\(\\vec{x}\\) is the input vector, \\(\\vec{c}\\) is the center of the function, and \\(\\|\\vec{x} - \\vec{c}\\|\\) denotes the Euclidean distance between \\(\\vec{x}\\) and \\(\\vec{c}\\).\n\n\n\n\n8.1.1 Fitting Noise-Free Data\nLet us consider the scalar valued function \\(f\\) observed without error, according to the sampling plan \\(X = \\{\\vec{x}^{(1)}, \\vec{x}^{(2)}, \\ldots, \\vec{x}^{(n)}\\}^T\\), yielding the responses \\(\\vec{y} = \\{y^{(1)}, y^{(2)}, \\ldots, y^{(n)}\\}^T\\).\nFor a given set of \\(n_c\\) centers \\(\\vec{c}^{(i)}\\), we would like to express the RBF model as a linear combination of the basis functions centered at these points. The goal is to find the weights \\(\\vec{w}\\) that minimize the error between the predicted and observed values. Thus, we seek a radial basis function approximation to \\(f\\) of the fixed form:\n\\[\n\\hat{f}(\\vec{x}) = \\sum_{i=1}^{n_c} w_i \\psi(||\\vec{x} - \\vec{c}^{(i)}||),\n\\tag{8.3}\\] where\n\n\\(w_i\\) are the weights of the \\(n_c\\) basis functions,\n\\(\\vec{c}^{(i)}\\) are the \\(n_c\\) centres of the basis functions, and\n\\(\\psi\\) is a radial basis function.\n\nThe notation \\(||\\cdot||\\) denotes the Euclidean distance between two points in the design space as defined in Equation 8.1.\n\n8.1.1.1 Selecting Basis Functions: From Fixed to Parametric Forms\nWhen implementing a radial basis function model, we initially have one undetermined parameter per basis function: the weight applied to each function’s output. This simple parameterization remains true when we select from several standard fixed-form basis functions, such as:\n\nLinear (\\(\\psi(r) = r\\)): The simplest form, providing a response proportional to distance\nCubic (\\(\\psi(r) = r^3\\)): Offers stronger emphasis on points farther from the center\nThin plate spline (\\(\\psi(r) = r^2 \\ln r\\)): Models the physical bending of a thin sheet, providing excellent smoothness properties\n\nWhile these fixed basis functions are computationally efficient, they offer limited flexibility in how they generalize across the design space. For more adaptive modeling power, we can employ parametric basis functions that introduce additional tunable parameters:\n\nGaussian (\\(\\psi(r) = e^{-r^2/(2\\sigma^2)}\\)): Produces bell-shaped curves with \\(\\sigma\\) controlling the width of influence\nMultiquadric (\\(\\psi(r) = (r^2 + \\sigma^2)^{1/2}\\)): Provides broader coverage with less localized effects\nInverse multiquadric (\\(\\psi(r) = (r^2 + \\sigma^2)^{-1/2}\\)): Offers sharp peaks near centers with asymptotic behavior\n\nThe parameter \\(\\sigma\\) in these functions serves as a shape parameter that controls how rapidly the function’s influence decays with distance. This added flexibility enables significantly better generalization, particularly when modeling complex responses, though at the cost of a more involved parameter estimation process requiring optimization of both weights and shape parameters.\n\nExample 8.1 (Gaussian RBF) Using the general definition of a radial basis function (Equation 8.2), we can express the Gaussian RBF as: \\[\n\\psi(\\vec{x}) = \\exp\\left(-\\frac{\\|\\vec{x} - \\vec{c}\\|^2}{2\\sigma^2}\\right)  = \\exp\\left(-\\frac{\\sum_{j=1}^{k} (x_j - c_j)^2}{2\\sigma^2}\\right)\n\\tag{8.4}\\] where:\n\n\\(\\vec{x}\\) is the input vector,\n\\(\\vec{c}\\) is the center vector,\n\\(\\|\\vec{x} - \\vec{c}\\|\\) is the Euclidean distance between the input and center, and\n\\(\\sigma\\) is the width parameter that controls how quickly the function’s response diminishes with distance from the center.\n\nThe Gaussian RBF produces a bell-shaped response that reaches its maximum value of 1 when \\(\\vec{x} = \\vec{c}\\) and asymptotically approaches zero as the distance increases. The parameter \\(\\sigma\\) determines how “localized” the response is—smaller values create a narrower peak with faster decay, while larger values produce a broader, more gradual response across the input space. Figure 8.1 shows the Gaussian RBF for different values of \\(\\sigma\\) in an one-dimensional space. The center of the RBF is set at 0, and the width parameter \\(\\sigma\\) varies to illustrate how it affects the shape of the function.\n\ndef gaussian_rbf(x, center, sigma):\n    \"\"\"\n    Compute the Gaussian Radial Basis Function.\n\n    Args:\n        x (ndarray): Input points\n        center (float): Center of the RBF\n        sigma (float): Width parameter\n\n    Returns:\n        ndarray: RBF values\n    \"\"\"\n    return np.exp(-((x - center)**2) / (2 * sigma**2))\n\n\n\n\n\n\n\n\n\nFigure 8.1: Gaussian RBF\n\n\n\n\n\nThe sum of Gaussian RBFs can be visualized by summing the individual Gaussian RBFs centered at different points as shown in Figure 8.2. The following code snippet demonstrates how to create this plot showing the sum of three Gaussian RBFs with different centers and a common width parameter \\(\\sigma\\).\n\n\n\n\n\n\n\n\nFigure 8.2: Sum of Gaussian RBFs\n\n\n\n\n\n\n\n\n8.1.1.2 The Interpolation Condition: Elegant Solutions Through Linear Systems\nA remarkable property of radial basis function models is that regardless of which basis functions we choose—parametric or fixed—determining the weights \\(\\vec{w}\\) remains straightforward through interpolation. The core principle is elegantly simple: we require our model to exactly reproduce the observed data points:\n\\[\n\\hat{f}(\\vec{x}^{(i)}) = y^{(i)}, \\quad i = 1, 2, \\ldots, n.\n\\tag{8.5}\\]\nThis constraint produces one of the most powerful aspects of RBF modeling: while the system in Equation 8.5 is linear with respect to the weights \\(\\vec{w}\\), the resulting predictor \\(\\hat{f}\\) can capture highly nonlinear relationships in the data. The RBF approach transforms a complex nonlinear modeling problem into a solvable linear algebra problem.\nFor a unique solution to exist, we require that the number of basis functions equals the number of data points (\\(n_c = n\\)). The standard practice, which greatly simplifies implementation, is to center each basis function at a training data point, setting \\(\\vec{c}^{(i)} = \\vec{x}^{(i)}\\) for all \\(i = 1, 2, \\ldots, n\\). This choice allows us to express the interpolation condition as a compact matrix equation:\n\\[\n\\Psi \\vec{w} = \\vec{y}.\n\\]\nHere, \\(\\Psi\\) represents the Gram matrix (also called the design matrix or kernel matrix), whose elements measure the similarity between data points:\n\\[\n\\Psi_{i,j} = \\psi(||\\vec{x}^{(i)} - \\vec{x}^{(j)}||), \\quad i, j = 1, 2, \\ldots, n.\n\\]\nThe solution for the weight vector becomes:\n\\[\n\\vec{w} = \\Psi^{-1} \\vec{y}.\n\\]\nThis matrix inversion step is the computational core of the RBF model fitting process, and the numerical properties of this operation depend critically on the chosen basis function. Different basis functions produce Gram matrices with distinct conditioning properties, directly affecting both computational stability and the model’s generalization capabilities.\n\n\n\n8.1.2 Numerical Stability Through Positive Definite Matrices\nA significant advantage of Gaussian and inverse multiquadric basis functions lies in their mathematical guarantees. Vapnik (1998) demonstrated that these functions always produce symmetric positive definite Gram matrices when using strictly positive definite kernels (see Section 10.4), which is a critical property for numerical reliability. Unlike other basis functions that may lead to ill-conditioned systems, these functions ensure the existence of unique, stable solutions.\nThis positive definiteness enables the use of Cholesky factorization, which offers substantial computational advantages over standard matrix inversion techniques. The Cholesky approach reduces the computational cost (reducing from \\(O(n^3)\\) to roughly \\(O(n^3/3)\\)) while significantly improving numerical stability when handling the inevitable rounding errors in floating-point arithmetic. This robustness to numerical issues explains why Gaussian and inverse multiquadric basis functions remain the preferred choice in many practical RBF implementations.\nFurthermore, the positive definiteness guarantee provides theoretical assurances about the model’s interpolation properties—ensuring that the RBF interpolant exists and is unique for any distinct set of centers. This mathematical foundation gives practitioners confidence in the method’s reliability, particularly for complex engineering applications where model stability is paramount.\nThe computational advantage stems from how a symmetric positive definite matrix \\(\\Psi\\) can be efficiently decomposed into the product of an upper triangular matrix \\(U\\) and its transpose:\n\\[\n\\Psi = U^T U.\n\\]\nThis decomposition transforms the system \\[\n\\Psi \\vec{w} = \\vec{y}\n\\] into \\[\nU^T U \\vec{w} = \\vec{y},\n\\] which can be solved through two simpler triangular systems:\n\nFirst solve \\(U^T \\vec{v} = \\vec{y}\\) for the intermediate vector \\(\\vec{v}\\)\nThen solve \\(U \\vec{w} = \\vec{v}\\) for the desired weights \\(\\vec{w}\\)\n\nIn Python implementations, this process is elegantly handled using NumPy’s or SciPy’s Cholesky decomposition functions, followed by specialized solvers that exploit the triangular structure:\nfrom scipy.linalg import cholesky, cho_solve\n# Compute the Cholesky factorization\nL = cholesky(Psi, lower=True)  # L is the lower triangular factor\nweights = cho_solve((L, True), y)  # Efficient solver for (L L^T)w = y\n\n\n8.1.3 Ill-Conditioning\nAn important numerical consideration in RBF modeling is that points positioned extremely close to each other in the input space \\(X\\) can lead to severe ill-conditioning of the Gram matrix (Micchelli 1986). This ill-conditioning manifests as nearly linearly dependent rows and columns in \\(\\Psi\\), potentially causing the Cholesky factorization to fail.\nWhile this problem rarely arises with initial space-filling experimental designs (such as Latin Hypercube or quasi-random sequences), it frequently emerges during sequential optimization processes that adaptively add infill points in promising regions. As these clusters of points concentrate in areas of high interest, the condition number of the Gram matrix deteriorates, jeopardizing numerical stability.\nSeveral mitigation strategies exist: regularization through ridge-like penalties (modifying the standard RBF interpolation problem by adding a penalty term to the diagonal of the Gram matrix. This creates a literal “ridge” along the diagonal of the matrix), removing nearly coincident points, clustering, or applying more sophisticated approaches. One theoretically elegant solution involves augmenting non-conditionally positive definite basis functions with polynomial terms (Keane and Nair 2005). This technique not only improves conditioning but also ensures polynomial reproduction properties, enhancing the approximation quality for certain function classes while maintaining numerical stability.\nBeyond determining \\(\\vec{w}\\), there is, of course, the additional task of estimating any other parameters introduced via the basis functions. A typical example is the \\(\\sigma\\) of the Gaussian basis function, usually taken to be the same for all basis functions, though a different one can be selected for each centre, as is customary in the case of the Kriging basis function, to be discussed shortly (once again, we trade additional parameter estimation complexity versus increased flexibility and, hopefully, better generalization).\n\n\n8.1.4 Parameter Optimization: A Two-Level Approach\nWhen building RBF models, we face two distinct parameter estimation challenges:\n\nDetermining the weights (\\(\\vec{w}\\)): These parameters ensure our model precisely reproduces the training data. For any fixed basis function configuration, we can calculate these weights directly through linear algebra as shown earlier.\nOptimizing shape parameters (like \\(\\sigma\\) in Gaussian RBF): These parameters control how the model generalizes to new, unseen data. Unlike weights, there’s no direct formula to find their optimal values.\n\nTo address this dual challenge, we employ a nested optimization strategy (inner and outer levels):\n\n8.1.4.1 Inner Level (\\(\\vec{w}\\))\nFor each candidate value of shape parameters (e.g., \\(\\sigma\\)), we determine the corresponding optimal weights \\(\\vec{w}\\) by solving the linear system. The estim_weights() method implements the inner level optimization by calculating the optimal weights \\(\\vec{w}\\) for a given shape parameter (\\(\\sigma\\)):\ndef estim_weights(self):\n    # [...]\n    \n    # Construct the Phi (Psi) matrix\n    self.Phi = np.zeros((n, n))\n    for i in range(n):\n        for j in range(i+1):\n            self.Phi[i, j] = self.basis(d[i, j], self.sigma)\n            self.Phi[j, i] = self.Phi[i, j]\n    \n    # Calculate weights using appropriate method\n    if self.code == 4 or self.code == 6:\n        # Use Cholesky factorization for Gaussian or inverse multiquadric\n        try:\n            L = cholesky(self.Phi, lower=True)\n            self.weights = cho_solve((L, True), self.y)\n            self.success = True\n        except np.linalg.LinAlgError:\n            # Error handling...\n    else:\n        # Use direct solve for other basis functions\n        try:\n            self.weights = np.linalg.solve(self.Phi, self.y)\n            self.success = True\n        except np.linalg.LinAlgError:\n            # Error handling...\n    \n    return self\nThis method:\n\nCreates the Gram matrix (Phi) based on distances between points\nSolves the linear system \\(\\Psi\\vec{w} = \\vec{y}\\) for weights\nUses appropriate numerical methods based on the basis function type (Cholesky factorization or direct solve)\n\n\n\n8.1.4.2 Outer Level (\\(\\sigma\\))\nWe use cross-validation to evaluate how well the model generalizes with different shape parameter values. The outer level optimization is implemented within the fit() method, where cross-validation is used to evaluate different \\(\\sigma\\) values:\ndef fit(self):\n    if self.code &lt; 4:\n        # Fixed basis function, only w needs estimating\n        self.estim_weights()\n    else:\n        # Basis function requires a sigma, estimate first using cross-validation\n        # [...]\n        \n        # Generate candidate sigma values\n        sigmas = np.logspace(-2, 2, 30)\n        \n        # Setup cross-validation (determine number of folds)\n        # [...]\n        \n        cross_val = np.zeros(len(sigmas))\n        \n        # For each candidate sigma value\n        for sig_index, sigma in enumerate(sigmas):\n            print(f\"Computing cross-validation metric for Sigma={sigma:.4f}...\")\n            \n            # Perform k-fold cross-validation\n            for j in range(len(from_idx)):\n                # Create and fit model on training subset\n                temp_model = Rbf(\n                    X=X_orig[xs_temp],\n                    y=y_orig[xs_temp],\n                    code=self.code\n                )\n                temp_model.sigma = sigma\n                \n                # Call inner level optimization\n                temp_model.estim_weights()\n                \n                # Evaluate on held-out data\n                # [...]\n            \n        # Select best sigma based on cross-validation performance\n        min_cv_index = np.argmin(cross_val)\n        best_sig = sigmas[min_cv_index]\n        \n        # Use the best sigma for final model\n        self.sigma = best_sig\n        self.estim_weights()  # Call inner level again with optimal sigma\nThe outer level:\n\nGenerates a range of candidate \\(\\sigma\\) values\nFor each \\(\\sigma\\), performs k-fold cross-validation:\n\nCreates models on subsets of the data\nCalls the inner level method (estim_weights()) to determine weights\nEvaluates prediction quality on held-out data\n\nSelects the \\(\\sigma\\) that minimizes cross-validation error\nPerforms a final call to the inner level method with the optimal \\(\\sigma\\)\n\nThis two-level approach is particularly critical for parametric basis functions (Gaussian, multiquadric, etc.), where the wrong choice of shape parameter could lead to either overfitting (too much flexibility) or underfitting (too rigid). Cross-validation provides an unbiased estimate of how well different parameter choices will perform on new data, helping us balance the trade-off between fitting the training data perfectly and generalizing well.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Radial Basis Function Models</span>"
    ]
  },
  {
    "objectID": "006_num_rbf.html#sec-rbf-python",
    "href": "006_num_rbf.html#sec-rbf-python",
    "title": "8  Radial Basis Function Models",
    "section": "8.2 Python Implementation of the RBF Model",
    "text": "8.2 Python Implementation of the RBF Model\nSection 8.2 shows a Python implementation of this parameter estimation process (based on a cross-validation routine), which will represent the surrogate, once its parameters have been estimated. The model building process is very simple.\nInstead of using a dictionary for bookkeeping, we implement a Python class Rbf that encapsulates all the necessary data and functionality. The class stores the sampling plan \\(X\\) as the X attribute and the corresponding \\(n\\)-vector of responses \\(y\\) as the y attribute. The code attribute specifies the type of basis function to be used. After fitting the model, the class will also contain the estimated parameter values \\(\\vec{w}\\) and, if a parametric basis function is used, \\(\\sigma\\). These are stored in the weights and sigma attributes respectively.\nFinally, a note on prediction error estimation. We have already indicated that the guarantee of a positive definite \\(\\Psi\\) is one of the advantages of Gaussian radial basis functions. They also possess another desirable feature: it is relatively easy to estimate their prediction error at any \\(\\vec{x}\\) in the design space. Additionally, the expectation function of the improvement in minimum (or maximum) function value with respect to the minimum (or maximum) known so far can also be calculated quite easily, both of these features being very useful when the optimization of \\(f\\) is the goal of the surrogate modelling process.\n\n8.2.1 The Rbf Class\nThe Rbf class implements the Radial Basis Function model. It encapsulates all the data and methods needed for fitting the model and making predictions.\n\nimport numpy as np\nfrom scipy.linalg import cholesky, cho_solve\nimport numpy.random as rnd\n\nclass Rbf:\n    \"\"\"Radial Basis Function model implementation.\n    \n    Attributes:\n        X (ndarray): The sampling plan (input points).\n        y (ndarray): The response vector.\n        code (int): Type of basis function to use.\n        weights (ndarray, optional): The weights vector (set after fitting).\n        sigma (float, optional): Parameter for parametric basis functions.\n        Phi (ndarray, optional): The Gram matrix (set during fitting).\n        success (bool, optional): Flag indicating successful fitting.\n    \"\"\"\n    \n    def __init__(self, X=None, y=None, code=3):\n        \"\"\"Initialize the RBF model.\n        \n        Args:\n            X (ndarray, optional):\n                The sampling plan.\n            y (ndarray, optional):\n                The response vector.\n            code (int, optional):\n                Type of basis function.\n                Default is 3 (thin plate spline).\n        \"\"\"\n        self.X = X\n        self.y = y\n        self.code = code\n        self.weights = None\n        self.sigma = None\n        self.Phi = None\n        self.success = None\n    \n    def basis(self, r, sigma=None):\n        \"\"\"Compute the value of the basis function.\n        \n        Args:\n            r (float): Radius (distance)\n            sigma (float, optional): Parameter for parametric basis functions\n            \n        Returns:\n            float: Value of the basis function\n        \"\"\"\n        # Use instance sigma if not provided\n        if sigma is None and hasattr(self, 'sigma'):\n            sigma = self.sigma\n            \n        if self.code == 1:\n            # Linear function\n            return r\n        elif self.code == 2:\n            # Cubic\n            return r**3\n        elif self.code == 3:\n            # Thin plate spline\n            if r &lt; 1e-200:\n                return 0\n            else:\n                return r**2 * np.log(r)\n        elif self.code == 4:\n            # Gaussian\n            return np.exp(-(r**2)/(2*sigma**2))\n        elif self.code == 5:\n            # Multi-quadric\n            return (r**2 + sigma**2)**0.5\n        elif self.code == 6:\n            # Inverse Multi-Quadric\n            return (r**2 + sigma**2)**(-0.5)\n        else:\n            raise ValueError(\"Invalid basis function code\")\n    \n    def estim_weights(self):\n        \"\"\"Estimates the basis function weights if sigma is known or not required.\n        \n        Returns:\n            self: The updated model instance\n        \"\"\"\n        # Check if sigma is required but not provided\n        if self.code &gt; 3 and self.sigma is None:\n            raise ValueError(\"The basis function requires a sigma parameter\")\n        \n        # Number of points\n        n = len(self.y)\n        \n        # Build distance matrix\n        d = np.zeros((n, n))\n        for i in range(n):\n            for j in range(i+1):\n                d[i, j] = np.linalg.norm(self.X[i] - self.X[j])\n                d[j, i] = d[i, j]\n        \n        # Construct the Phi (Psi) matrix\n        self.Phi = np.zeros((n, n))\n        for i in range(n):\n            for j in range(i+1):\n                self.Phi[i, j] = self.basis(d[i, j], self.sigma)\n                self.Phi[j, i] = self.Phi[i, j]\n        \n        # Calculate weights using appropriate method\n        if self.code == 4 or self.code == 6:\n            # Use Cholesky factorization for Gaussian or inverse multiquadric\n            try:\n                L = cholesky(self.Phi, lower=True)\n                self.weights = cho_solve((L, True), self.y)\n                self.success = True\n            except np.linalg.LinAlgError:\n                print(\"Cholesky factorization failed.\")\n                print(\"Two points may be too close together.\")\n                self.weights = None\n                self.success = False\n        else:\n            # Use direct solve for other basis functions\n            try:\n                self.weights = np.linalg.solve(self.Phi, self.y)\n                self.success = True\n            except np.linalg.LinAlgError:\n                self.weights = None\n                self.success = False\n        \n        return self\n    \n    def fit(self):\n        \"\"\"Estimates the parameters of the Radial Basis Function model.\n        \n        Returns:\n            self: The updated model instance\n        \"\"\"\n        if self.code &lt; 4:\n            # Fixed basis function, only w needs estimating\n            self.estim_weights()\n        else:\n            # Basis function also requires a sigma, estimate first\n            # Save original model data\n            X_orig = self.X.copy()\n            y_orig = self.y.copy()\n            \n            # Direct search between 10^-2 and 10^2\n            sigmas = np.logspace(-2, 2, 30)\n            \n            # Number of cross-validation subsets\n            if len(self.X) &lt; 6:\n                q = 2\n            elif len(self.X) &lt; 15:\n                q = 3\n            elif len(self.X) &lt; 50:\n                q = 5\n            else:\n                q = 10\n            \n            # Number of sample points\n            n = len(self.X)\n            \n            # X split into q randomly selected subsets\n            xs = rnd.permutation(n)\n            full_xs = xs.copy()\n            \n            # The beginnings of the subsets...\n            from_idx = np.arange(0, n, n//q)\n            if from_idx[-1] &gt;= n:\n                from_idx = from_idx[:-1]\n            \n            # ...and their ends\n            to_idx = np.zeros_like(from_idx)\n            for i in range(len(from_idx) - 1):\n                to_idx[i] = from_idx[i+1] - 1\n            to_idx[-1] = n - 1\n            \n            cross_val = np.zeros(len(sigmas))\n            \n            # Cycling through the possible values of Sigma\n            for sig_index, sigma in enumerate(sigmas):\n                print(f\"Computing cross-validation metric for Sigma={sigma:.4f}...\")\n                \n                cross_val[sig_index] = 0\n                \n                # Model fitting to subsets of the data\n                for j in range(len(from_idx)):\n                    removed = xs[from_idx[j]:to_idx[j]+1]\n                    xs_temp = np.delete(xs, np.arange(from_idx[j], to_idx[j]+1))\n                    \n                    # Create a temporary model for CV\n                    temp_model = Rbf(\n                        X=X_orig[xs_temp],\n                        y=y_orig[xs_temp],\n                        code=self.code\n                    )\n                    temp_model.sigma = sigma\n                    \n                    # Sigma and subset chosen, now estimate w\n                    temp_model.estim_weights()\n                    \n                    if temp_model.weights is None:\n                        cross_val[sig_index] = 1e20\n                        xs = full_xs.copy()\n                        break\n                    \n                    # Compute vector of predictions at the removed sites\n                    pr = np.zeros(len(removed))\n                    for jj, idx in enumerate(removed):\n                        pr[jj] = temp_model.predict(X_orig[idx])\n                    \n                    # Calculate cross-validation error\n                    cross_val[sig_index] += np.sum((y_orig[removed] - pr)**2) / len(removed)\n                    \n                    xs = full_xs.copy()\n                \n                # Now attempt Cholesky on the full set, in case the subsets could\n                # be fitted correctly, but the complete X could not\n                temp_model = Rbf(\n                    X=X_orig,\n                    y=y_orig,\n                    code=self.code\n                )\n                temp_model.sigma = sigma\n                temp_model.estim_weights()\n                \n                if temp_model.weights is None:\n                    cross_val[sig_index] = 1e20\n                    print(\"Failed to fit complete sample data.\")\n            \n            # Find the best sigma\n            min_cv_index = np.argmin(cross_val)\n            best_sig = sigmas[min_cv_index]\n            \n            # Set the best sigma and recompute weights\n            print(f\"Selected sigma={best_sig:.4f}\")\n            self.sigma = best_sig\n            self.estim_weights()\n        \n        return self\n    \n    def predict(self, x):\n        \"\"\"Calculates the value of the Radial Basis Function surrogate model at x.\n        \n        Args:\n            x (ndarray): Point at which to make prediction\n            \n        Returns:\n            float: Predicted value\n        \"\"\"\n        # Calculate distances to all sample points\n        d = np.zeros(len(self.X))\n        for k in range(len(self.X)):\n            d[k] = np.linalg.norm(x - self.X[k])\n        \n        # Calculate basis function values\n        phi = np.zeros(len(self.X))\n        for k in range(len(self.X)):\n            phi[k] = self.basis(d[k], self.sigma)\n        \n        # Calculate prediction\n        y = np.dot(phi, self.weights)\n        return y",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Radial Basis Function Models</span>"
    ]
  },
  {
    "objectID": "006_num_rbf.html#rbf-example-the-one-dimensional-sin-function",
    "href": "006_num_rbf.html#rbf-example-the-one-dimensional-sin-function",
    "title": "8  Radial Basis Function Models",
    "section": "8.3 RBF Example: The One-Dimensional sin Function",
    "text": "8.3 RBF Example: The One-Dimensional sin Function\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.linalg import cholesky, cho_solve\n\n# Define the data points for fitting\nx_centers = np.array([np.pi/2, np.pi, 3*np.pi/2]).reshape(-1, 1)  # Centers for RBFs\ny_values = np.sin(x_centers.flatten())  # Sine values at these points\n\n# Create and fit the RBF model\nrbf_model = Rbf(X=x_centers, y=y_values, code=4)  # Code 4 is Gaussian RBF\nrbf_model.sigma = 1.0  # Set sigma parameter directly\nrbf_model.estim_weights()  # Calculate optimal weights\n\n# Print the weights\nprint(\"RBF model weights:\", rbf_model.weights)\n\n# Create a grid for visualization\nx_grid = np.linspace(0, 2*np.pi, 1000).reshape(-1, 1)\ny_true = np.sin(x_grid.flatten())  # True sine function\n\n# Generate predictions using the RBF model\ny_pred = np.zeros(len(x_grid))\nfor i in range(len(x_grid)):\n    y_pred[i] = rbf_model.predict(x_grid[i])\n\n# Calculate individual basis functions for visualization\nbasis_funcs = np.zeros((len(x_grid), len(x_centers)))\nfor i in range(len(x_grid)):\n    for j in range(len(x_centers)):\n        # Calculate distance\n        distance = np.linalg.norm(x_grid[i] - x_centers[j])\n        # Compute basis function value scaled by its weight\n        basis_funcs[i, j] = rbf_model.basis(distance, rbf_model.sigma) * rbf_model.weights[j]\n\n# Plot the results\nplt.figure(figsize=(6, 4))\n\n# Plot the true sine function\nplt.plot(x_grid, y_true, 'k-', label='True sine function', linewidth=2)\n\n# Plot individual basis functions\nfor i in range(len(x_centers)):\n    plt.plot(x_grid, basis_funcs[:, i], '--', \n             label=f'Basis function at x={x_centers[i][0]:.2f}')\n\n# Plot the RBF fit (sum of basis functions)\nplt.plot(x_grid, y_pred, 'r-', label='RBF fit', linewidth=2)\n\n# Plot the sample points\nplt.scatter(x_centers, y_values, color='blue', s=100, label='Sample points')\n\n# Add horizontal line at y=0\nplt.axhline(y=0, color='gray', linestyle='--', alpha=0.3)\n\nplt.title('RBF Approximation of Sine Function')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.grid(True)\nplt.legend()\nplt.tight_layout()\nplt.show()\n\nRBF model weights: [ 1.00724398e+00  2.32104414e-16 -1.00724398e+00]",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Radial Basis Function Models</span>"
    ]
  },
  {
    "objectID": "006_num_rbf.html#rbf-example-the-two-diemnsional-dome-function",
    "href": "006_num_rbf.html#rbf-example-the-two-diemnsional-dome-function",
    "title": "8  Radial Basis Function Models",
    "section": "8.4 RBF Example: The Two-Diemnsional dome Function",
    "text": "8.4 RBF Example: The Two-Diemnsional dome Function\nThe dome function is an example of a test function that can be used to evaluate the performance of the Radial Basis Function model. It is a simple mathematical function defined over a two-dimensional space.\n\ndef dome(x) -&gt; float:\n  \"\"\"\n  Dome test function.\n  \n  Args:\n      x (ndarray): Input vector (1D array of length 2)\n  \n  Returns:\n      float: Function value\n  \n  Examples:\n      dome(np.array([0.5, 0.5]))\n  \"\"\"\n  return np.sum(1 - (2*x - 1)**2) / len(x)\n\nThe following code demonstrates how to use the Radial Basis Function model to approximate a function. It generates a Latin Hypercube sample, computes the objective function values, estimates the model parameters, and plots the results.\n\ndef generate_rbf_data(n_samples=10, grid_points=41):\n    \"\"\"\n    Generates data for RBF visualization.\n\n    Args:\n        n_samples (int): Number of samples for the RBF model\n        grid_points (int): Number of grid points for prediction\n\n    Returns:\n        tuple: (rbf_model, X, Y, Z, Z_0) - Model and grid data for plotting\n    \"\"\"\n    from spotpython.utils.sampling import bestlh as best_lh\n    # Generate sampling plan\n    X_samples = best_lh(n_samples, 2, population=10, iterations=100)\n    # Compute objective function values\n    y_samples = np.zeros(len(X_samples))\n    for i in range(len(X_samples)):\n        y_samples[i] = dome(X_samples[i])\n    # Create and fit RBF model\n    rbf_model = Rbf(X=X_samples, y=y_samples, code=3)  # Thin plate spline\n    rbf_model.fit()\n    # Generate grid for prediction\n    x = np.linspace(0, 1, grid_points)\n    y = np.linspace(0, 1, grid_points)\n    X, Y = np.meshgrid(x, y)\n    Z_0 = np.zeros_like(X)\n    Z = np.zeros_like(X)\n    \n    # Evaluate model at grid points\n    for i in range(len(x)):\n        for j in range(len(y)):\n            Z_0[j, i] = dome(np.array([x[i], y[j]]))\n            Z[j, i] = rbf_model.predict(np.array([x[i], y[j]]))\n    \n    return rbf_model, X, Y, Z, Z_0\n\ndef plot_rbf_results(rbf_model, X, Y, Z, Z_0=None, n_contours=10):\n    \"\"\"\n    Plots RBF approximation results.\n\n    Args:\n        rbf_model (Rbf): Fitted RBF model\n        X (ndarray): Grid X-coordinates\n        Y (ndarray): Grid Y-coordinates\n        Z (ndarray): RBF model predictions\n        Z_0 (ndarray, optional): True function values for comparison\n        n_contours (int): Number of contour levels to plot\n    \"\"\"\n    import matplotlib.pyplot as plt\n    \n    plt.figure(figsize=(10, 8))\n    \n    # Plot the contour\n    contour = plt.contour(X, Y, Z, n_contours)\n\n    if Z_0 is not None:\n        contour_0 = plt.contour(X, Y, Z_0, n_contours, colors='k', linestyles='dashed')\n    \n    # Plot the sample points\n    plt.scatter(rbf_model.X[:, 0], rbf_model.X[:, 1], \n                c='r', marker='o', s=50)\n    \n    plt.title('RBF Approximation (Thin Plate Spline)')\n    plt.xlabel('x1')\n    plt.ylabel('x2')\n    plt.colorbar(label='f(x1, x2)')\n    plt.show()\n\nFigure 8.3 shows the contour plots of the underlying function \\(f(x_1, x_2) = 0.5[-(2x_1-1)^2-(2x_2-1)^2]\\) and its thin plate spline radial basis function approximation, along with the 10 points of a Morris-Mitchell optimal Latin hypercube sampling plan (obtained via best_lh()).\n\nrbf_model, X, Y, Z, Z_0 = generate_rbf_data(n_samples=10, grid_points=41)\nplot_rbf_results(rbf_model, X, Y, Z, Z_0)\n\n\n\n\n\n\n\nFigure 8.3: RBF Approximation.\n\n\n\n\n\n\n8.4.1 The Connection Between RBF Models and Neural Networks\nRadial basis function models share a profound architectural similarity with artificial neural networks, specifically with what’s known as RBF networks. This connection provides valuable intuition about how RBF models function. A radial basis function model can be viewed as a specialized neural network with the following structure:\n\nInput Layer: Receives the feature vector \\(\\vec{x}\\)\nHidden Layer: Contains neurons (basis functions) that compute radial distances\nOutput Layer: Produces a weighted sum of the hidden unit activations\n\nUnlike traditional neural networks that use dot products followed by nonlinear activation functions, RBF networks measure the distance between inputs and learned center points. This distance is then transformed by the radial basis function.\nMathematically, the equivalence between RBF models and RBF networks can be expressed as follows:\nThe RBF model equation:\n\\[\n\\hat{f}(\\vec{x}) = \\sum_{i=1}^{n_c} w_i \\psi(||\\vec{x} - \\vec{c}^{(i)}||)\n\\]\ndirectly maps to the following neural network components:\n\n\\(\\vec{x}\\): Input vector\n\\(\\vec{c}^{(i)}\\): Center vectors for each hidden neuron\n\\(\\psi(\\cdot)\\): Activation function (Gaussian, inverse multiquadric, etc.)\n\\(w_i\\): Output weights\n\\(\\hat{f}(\\vec{x})\\): Network output\n\n\nExample 8.2 (Comparison of RBF Networks and Traditional Neural Networks) Consider approximating a simple 1D function \\(f(x) = \\sin(2\\pi x)\\) over the interval \\([0,1]\\):\nThe neral network approach would use multiple layers with neurons computing \\(\\sigma(w \\cdot x + b)\\). It would require a large number of neurons and layers to capture the sine wave’s complexity. The network would learn both weights and biases, making it less interpretable.\nThe RBF network approach, on the other hand, places basis functions at strategic points (e.g., 5 evenly spaced centers). Each neuron computes \\(\\psi(||x - c_i||)\\) (e.g., using Gaussian RBF). The output layer combines these values with learned weights. If we place Gaussian RBFs with \\(\\sigma=0.15\\) at \\({0.1, 0.3, 0.5, 0.7, 0.9}\\), each neuron responds strongly when the input is close to its center and weakly otherwise. The network can then learn weights that, when multiplied by these response patterns and summed, closely approximate the sine function.\nThis locality property gives RBF networks a notable advantage: they offer more interpretable internal representations and often require fewer neurons for certain types of function approximation compared to traditional multilayer perceptrons.\nThe key insight is that while standard neural networks create complex decision boundaries through compositions of hyperplanes, RBF networks directly model functions using a set of overlapping “bumps” positioned strategically in the input space.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Radial Basis Function Models</span>"
    ]
  },
  {
    "objectID": "006_num_rbf.html#radial-basis-function-models-for-noisy-data",
    "href": "006_num_rbf.html#radial-basis-function-models-for-noisy-data",
    "title": "8  Radial Basis Function Models",
    "section": "8.5 Radial Basis Function Models for Noisy Data",
    "text": "8.5 Radial Basis Function Models for Noisy Data\nWhen the responses \\(\\vec{y} = {y^{(1)}, y^{(2)}, \\ldots, y^{(n)}}^T\\) contain measurement or simulation noise, the standard RBF interpolation approach can lead to overfitting—the model captures both the underlying function and the random noise. This compromises generalization performance on new data points. Two principal strategies address this challenge:\n\n8.5.1 Ridge Regularization Approach\nThe most straightforward solution involves introducing regularization through the parameter \\(\\lambda\\) (Poggio and Girosi 1990). This is implemented by adding \\(\\lambda\\) to the diagonal elements of the Gram matrix, creating a “ridge” that improves numerical stability. Mathematically, the weights are determined by:\n\\[\n\\vec{w} = (\\Psi + \\lambda I)^{-1} \\vec{y},\n\\]\nwhere \\(I\\) is an \\(n \\times n\\) identity matrix. This regularized solution balances two competing objectives:\n\nfitting the training data accurately versus\nkeeping the magnitude of weights controlled to prevent overfitting.\n\nTheoretically, optimal performance is achieved when \\(\\lambda\\) equals the variance of the noise in the response data \\(\\vec{y}\\) (Keane and Nair 2005). Since this information is rarely available in practice, \\(\\lambda\\) is typically estimated through cross-validation alongside other model parameters.\n\n\n8.5.2 Reduced Basis Approach\nAn alternative strategy involves reducing \\(m\\), the number of basis functions. This might result in a non-square \\(\\Psi\\) matrix. With a non-square \\(\\Psi\\) matrix, the weights are found through least squares minimization:\n\\[\n\\vec{w} = (\\Psi^T\\Psi)^{-1}\\Psi^T\\vec{y}\n\\]\nThis approach introduces an important design decision: which subset of points should serve as basis function centers? Several selection strategies exist:\n\nClustering methods that identify representative points\nGreedy algorithms that sequentially select influential centers\nSupport vector regression techniques (discussed elsewhere in the literature)\n\nAdditional parameters such as the width parameter \\(\\sigma\\) in Gaussian bases can be optimized through cross-validation to minimize generalization error estimates.\nThe ridge regularization and reduced basis approaches can be combined, allowing for a flexible modeling framework, though at the cost of a more complex parameter estimation process. This hybrid approach often yields superior results for highly noisy datasets or when the underlying function has varying complexity across the input space.\nThe broader challenge of building accurate models from noisy observations is examined comprehensively in the context of Kriging models, which provide a statistical framework for explicitly modeling both the underlying function and the noise process.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Radial Basis Function Models</span>"
    ]
  },
  {
    "objectID": "006_num_rbf.html#jupyter-notebook",
    "href": "006_num_rbf.html#jupyter-notebook",
    "title": "8  Radial Basis Function Models",
    "section": "8.6 Jupyter Notebook",
    "text": "8.6 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository\n\n\n\n\n\n\n\nForrester, Alexander, András Sóbester, and Andy Keane. 2008. Engineering Design via Surrogate Modelling. Wiley.\n\n\nKeane, Andrew J, and Prasanth B Nair. 2005. Computational Approaches for Aerospace Design: The Pursuit of Excellence. Wiley.\n\n\nMicchelli, Charles A. 1986. “Interpolation of Scattered Data: Distance Matrices and Conditionally Positive Definite Functions.” Constructive Approximation 2 (1): 11–22. https://doi.org/10.1007/BF01893414.\n\n\nPoggio, T, and F Girosi. 1990. “Regularization Algorithms for Learning That Are Equivalent to Multilayer Networks.” Science 247 (4945): 978–82. https://doi.org/10.1126/science.247.4945.978.\n\n\nVapnik, V N. 1998. Statistical learning theory. Wiley; Wiley.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Radial Basis Function Models</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html",
    "href": "006_num_gp.html",
    "title": "9  Kriging (Gaussian Process Regression)",
    "section": "",
    "text": "9.1 From Gaussian RBF to Kriging Basis Functions\nKriging can be explained using the concept of radial basis functions (RBFs), which were introduced in Chapter 8. An RBF is a real-valued function whose value depends only on the distance from a certain point, called the center, usually in a multidimensional space. The basis function is a function of the distance between the point \\(\\vec{x}\\) and the center \\(\\vec{x}^{(i)}\\). Other names for basis functions are kernel or covariance functions.\nKriging uses a specialized basis function that offers greater flexibility than standard RBFs. Examining Equation 9.1, we can observe how Kriging builds upon and extends the Gaussian basis concept. The key enhancements of Kriging over Gaussian RBF can be summarized as follows:\nThese enhancements make Kriging particularly well-suited for engineering problems where variables may operate at different scales or exhibit varying degrees of smoothness across dimensions. For now, we will only consider Kriging interpolation. We will cover Kriging regression later.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html#from-gaussian-rbf-to-kriging-basis-functions",
    "href": "006_num_gp.html#from-gaussian-rbf-to-kriging-basis-functions",
    "title": "9  Kriging (Gaussian Process Regression)",
    "section": "",
    "text": "Definition 9.1 (The Kriging Basis Functions) Kriging (also known as Gaussian Process Regression) uses \\(k\\)-dimensional basis functions of the form \\[\n\\psi^{(i)}(\\vec{x}) =\n\\psi(\\vec{x}^{(i)}, \\vec{x}) = \\exp \\left( - \\sum_{j=1}^k \\theta_j | x_{j}^{(i)} - x_{j} | ^{p_j} \\right),\n\\tag{9.1}\\] where \\(\\vec{x}\\) and \\(\\vec{x}^{(i)}\\) denote the \\(k\\)-dim vector \\(\\vec{x}= (x_1, \\ldots, x_k)^T\\) and \\(\\vec{x}^{(i)}= (x_1^{(i)}, \\ldots, x_k^{(i)})^T\\), respectively.\n\\(\\Box\\)\n\n\n\nDimension-specific width parameters: While a Gaussian RBF uses a single width parameter \\(1/\\sigma^2\\), Kriging employs a vector \\(\\vec{\\theta} = (\\theta_1, \\theta_2, \\ldots, \\theta_k)^T\\). This allows the model to automatically adjust its sensitivity to each input dimension, effectively performing automatic feature relevance determination.\nFlexible smoothness control: The Gaussian RBF fixes the exponent at 2, producing uniformly smooth functions. In contrast, Kriging’s dimension-specific exponents \\(\\vec{p} = (p_1, p_2, \\ldots, p_k)^T\\) (typically with \\(p_j \\in [1, 2]\\)) enable precise control over smoothness properties in each dimension.\nUnifying framework: When all exponents are set to \\(p_j = 2\\) and all width parameters are equal (\\(\\theta_j = 1/\\sigma^2\\) for all \\(j\\)), the Kriging basis function reduces exactly to the Gaussian RBF. This makes Gaussian RBF a special case within the more general Kriging framework.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html#building-the-kriging-model",
    "href": "006_num_gp.html#building-the-kriging-model",
    "title": "9  Kriging (Gaussian Process Regression)",
    "section": "9.2 Building the Kriging Model",
    "text": "9.2 Building the Kriging Model\nConsider sample data \\(X\\) and \\(\\vec{y}\\) from \\(n\\) locations that are available in matrix form: \\(X\\) is a \\((n \\times k)\\) matrix, where \\(k\\) denotes the problem dimension and \\(\\vec{y}\\) is a \\((n\\times 1)\\) vector. We want to find an expression for a predicted values at a new point \\(\\vec{x}\\), denoted as \\(\\hat{y}\\).\nWe start with an abstract, not really intuitive concept: The observed responses \\(\\vec{y}\\) are considered as if they are from a stochastic process, which will be denoted as \\[\n\\begin{pmatrix}\nY(\\vec{x}^{(1)})\\\\\n\\vdots\\\\\nY(\\vec{x}^{(n)})\\\\\n\\end{pmatrix}.\n\\tag{9.2}\\]\nThe set of random vectors from Equation 9.2 (also referred to as a random field) has a mean of \\(\\vec{1} \\mu\\), which is a \\((n\\times 1)\\) vector. The random vectors are correlated with each other using the basis function expression from Equation 9.1: \\[\n\\text{cor} \\left(Y(\\vec{x}^{(i)}),Y(\\vec{x}^{(l)}) \\right) = \\exp\\left(- \\sum_{j=1}^k \\theta_j |x_j^{(i)} - x_j^{(l)} |^{p_j}\\right).\n\\tag{9.3}\\] Using Equation 9.3, we can compute the \\((n \\times n)\\) correlation matrix \\(\\Psi\\) of the observed sample data as shown in Equation 9.4,\n\\[\n\\Psi = \\begin{pmatrix}\n\\text{cor}\\left(\nY(\\vec{x}^{(1)}),\nY(\\vec{x}^{(1)})\n\\right) & \\ldots &\n\\text{cor}\\left(\nY(\\vec{x}^{(1)}),\nY(\\vec{x}^{(n)})\n\\right)\\\\\n\\vdots  & \\vdots &  \\vdots\\\\\n\\text{cor}\\left(\nY(\\vec{x}^{(n)}),\nY(\\vec{x}^{(1)})\n\\right)&\n\\ldots &\n\\text{cor}\\left(\nY(\\vec{x}^{(n)}),\nY(\\vec{x}^{(n)})\n\\right)\n\\end{pmatrix},\n\\tag{9.4}\\]\nand a covariance matrix as shown in Equation 9.5,\n\\[\n\\text{Cov}(Y, Y ) = \\sigma^2\\Psi.\n\\tag{9.5}\\]\nThis assumed correlation between the sample data reflects our expectation that an engineering function will behave in a certain way and it will be smoothly and continuous.\n\nRemark 9.1 (Note on Stochastic Processes). See Section D.4 for a more detailed discussion on realizations of stochastic processes.\n\\(\\Box\\)\n\nWe now have a set of \\(n\\) random variables (\\(\\mathbf{Y}\\)) that are correlated with each other as described in the \\((n \\times n)\\) correlation matrix \\(\\Psi\\), see Equation 9.4. The correlations depend on the absolute distances in dimension \\(j\\) between the \\(i\\)-th and the \\(l\\)-th sample point \\(|x_j^{(i)} - x_j^{(l)}|\\) and the corresponding parameters \\(p_j\\) and \\(\\theta_j\\) for dimension \\(j\\). The correlation is intuitive, because when\n\ntwo points move close together, then \\(|x_j^{(i)} - x_j| \\to 0\\) and \\(\\exp \\left(-|x_j^{(i)} - x_j|^{p_j} \\right) \\to 1\\) (these points show very close correlation and \\(Y(x_j^{(i)}) = Y(x_j)\\)).\ntwo points move far apart, then \\(|x_j^{(i)} - x_j| \\to \\infty\\) and \\(\\exp \\left(-|x_j^{(i)} - x_j|^{p_j} \\right) \\to 0\\) (these points show very low correlation).\n\n\nExample 9.1 (Correlations for different \\(p_j\\)) Three different correlations are shown in Figure 9.1: \\(p_j= 0.1, 1, 2\\). The smoothness parameter \\(p_j\\) affects the correlation:\n\nWith \\(p_j=0.1\\), there is basicaly no immediate correlation between the points and there is a near discontinuity between the points \\(Y(\\vec{x}_j^{(i)})\\) and \\(Y(\\vec{x}_j)\\).\nWith \\(p_j=2\\), the correlation is more smooth and we have a continuous gradient through \\(x_j^{(i)} - x_j\\).\n\nReducing \\(p_j\\) increases the rate at which the correlation initially drops with distance. This is shown in Figure 9.1.\n\n\n\n\n\n\n\n\nFigure 9.1: Correlations with varying \\(p\\). \\(\\theta\\) set to 1.\n\n\n\n\n\n\\(\\Box\\)\n\n\nExample 9.2 (Correlations for different \\(\\theta\\)) Figure 9.2 visualizes the correlation between two points \\(Y(\\vec{x}_j^{(i)})\\) and \\(Y(\\vec{x}_j)\\) for different values of \\(\\theta\\). The parameter \\(\\theta\\) can be seen as a width parameter:\n\nlow \\(\\theta_j\\) means that all points will have a high correlation, with \\(Y(x_j)\\) being similar across the sample.\nhigh \\(\\theta_j\\) means that there is a significant difference between the \\(Y(x_j)\\)’s.\n\\(\\theta_j\\) is a measure of how active the function we are approximating is.\nHigh \\(\\theta_j\\) indicate important parameters, see Figure 9.2.\n\n\n\n\n\n\n\n\n\nFigure 9.2: Correlations with varying \\(\\theta\\). \\(p\\) set to 2.\n\n\n\n\n\n\\(\\Box\\)\n\nConsidering the activity parameter \\(\\theta\\) is useful in high-dimensional problems where it is difficult to visualize the design landscape and the effect of the variable is unknown. By examining the elements of the vector \\(\\vec{\\theta}\\), we can identify the most important variables and focus on them. This is a crucial step in the optimization process, as it allows us to reduce the dimensionality of the problem and focus on the most important variables.\n\nExample 9.3 (The Correlation Matrix (Detailed Computation)) Let \\(n=4\\) and \\(k=3\\). The sample plan is represented by the following matrix \\(X\\): \\[\nX = \\begin{pmatrix} x_{11} & x_{12} & x_{13}\\\\\nx_{21} & x_{22} & x_{23}\\\\\nx_{31} & x_{32} & x_{33}\\\\\nx_{41} & x_{42} & x_{43}\\\\\n\\end{pmatrix}\n\\]\nTo compute the elements of the matrix \\(\\Psi\\), the following \\(k\\) (one for each of the \\(k\\) dimensions) \\((n,n)\\)-matrices have to be computed:\n\nFor \\(k=1\\), i.e., the first column of \\(X\\): \\[\nD_1 = \\begin{pmatrix} x_{11} - x_{11} & x_{11} - x_{21} & x_{11} -x_{31} & x_{11} - x_{41} \\\\  x_{21} - x_{11} & x_{21} - x_{21} & x_{21} -x_{31} & x_{21} - x_{41} \\\\ x_{31} - x_{11} & x_{31} - x_{21} & x_{31} -x_{31} & x_{31} - x_{41} \\\\ x_{41} - x_{11} & x_{41} - x_{21} & x_{41} -x_{31} & x_{41} - x_{41} \\\\\n\\end{pmatrix}\n\\]\nFor \\(k=2\\), i.e., the second column of \\(X\\): \\[\nD_2 = \\begin{pmatrix} x_{12} - x_{12} & x_{12} - x_{22} & x_{12} -x_{32} & x_{12} - x_{42} \\\\  x_{22} - x_{12} & x_{22} - x_{22} & x_{22} -x_{32} & x_{22} - x_{42} \\\\ x_{32} - x_{12} & x_{32} - x_{22} & x_{32} -x_{32} & x_{32} - x_{42} \\\\ x_{42} - x_{12} & x_{42} - x_{22} & x_{42} -x_{32} & x_{42} - x_{42} \\\\\n\\end{pmatrix}\n\\]\nFor \\(k=3\\), i.e., the third column of \\(X\\): \\[\nD_3 = \\begin{pmatrix} x_{13} - x_{13} & x_{13} - x_{23} & x_{13} -x_{33} & x_{13} - x_{43} \\\\  x_{23} - x_{13} & x_{23} - x_{23} & x_{23} -x_{33} & x_{23} - x_{43} \\\\ x_{33} - x_{13} & x_{33} - x_{23} & x_{33} -x_{33} & x_{33} - x_{43} \\\\ x_{43} - x_{13} & x_{43} - x_{23} & x_{43} -x_{33} & x_{43} - x_{43} \\\\\\end{pmatrix}\n\\]\n\nSince the matrices are symmetric and the main diagonals are zero, it is sufficient to compute the following matrices: \\[\nD_1 = \\begin{pmatrix} 0 & x_{11} - x_{21} & x_{11} -x_{31} & x_{11} - x_{41} \\\\  0 &  0 & x_{21} -x_{31} & x_{21} - x_{41} \\\\ 0 & 0 & 0 & x_{31} - x_{41} \\\\ 0 & 0 & 0 & 0 \\\\\\end{pmatrix}\n\\] \\[\nD_2 = \\begin{pmatrix} 0 & x_{12} - x_{22} & x_{12} -x_{32} & x_{12} - x_{42} \\\\  0 & 0 & x_{22} -x_{32} & x_{22} - x_{42} \\\\ 0 & 0 & 0 & x_{32} - x_{42} \\\\ 0 & 0 & 0 & 0 \\\\\n\\end{pmatrix}\n\\]\n\\[\nD_3 = \\begin{pmatrix} 0 & x_{13} - x_{23} & x_{13} -x_{33} & x_{13} - x_{43} \\\\  0 & 0 & x_{23} -x_{33} & x_{23} - x_{43} \\\\ 0 & 0 & 0 & x_{33} - x_{43} \\\\ 0 & 0 & 0 & 0 \\\\\\end{pmatrix}\n\\]\nWe will consider \\(p_l=2\\). The differences will be squared and multiplied by \\(\\theta_i\\), i.e.:\n\\[\nD_1 = \\theta_1 \\begin{pmatrix} 0 & (x_{11} - x_{21})^2 & (x_{11} -x_{31})^2 & (x_{11} - x_{41})^2 \\\\  0 &  0 & (x_{21} -x_{31})^2 & (x_{21} - x_{41})^2 \\\\ 0 & 0 & 0 & (x_{31} - x_{41})^2 \\\\ 0 & 0 & 0 & 0 \\\\\\end{pmatrix}\n\\]\n\\[\nD_2 = \\theta_2 \\begin{pmatrix} 0 & (x_{12} - x_{22})^2 & (x_{12} -x_{32})^2 & (x_{12} - x_{42})^2 \\\\  0 & 0 & (x_{22} -x_{32})^2 & (x_{22} - x_{42})^2 \\\\ 0 & 0 & 0 & (x_{32} - x_{42})^2 \\\\ 0 & 0 & 0 & 0 \\\\\\end{pmatrix}\n\\]\n\\[\nD_3 = \\theta_3 \\begin{pmatrix} 0 & (x_{13} - x_{23})^2 & (x_{13} -x_{33})^2 & (x_{13} - x_{43})^2 \\\\  0 & 0 & (x_{23} -x_{33})^2 & (x_{23} - x_{43})^2 \\\\ 0 & 0 & 0 & (x_{33} - x_{43})^2 \\\\ 0 & 0 & 0 & 0 \\\\\\end{pmatrix}\n\\]\nThe sum of the three matrices \\(D=D_1+ D_2 + D_3\\) will be calculated next:\n\\[\n\\begin{pmatrix} 0 &\n\\theta_1  (x_{11} - x_{21})^2 + \\theta_2 (x_{12} - x_{22})^2 + \\theta_3  (x_{13} - x_{23})^2  &\n\\theta_1 (x_{11} -x_{31})^2 + \\theta_2  (x_{12} -x_{32})^2 + \\theta_3  (x_{13} -x_{33})^2 &\n\\theta_1  (x_{11} - x_{41})^2 + \\theta_2  (x_{12} - x_{42})^2 + \\theta_3 (x_{13} - x_{43})^2\n\\\\  0 &  0 &\n\\theta_1  (x_{21} -x_{31})^2 + \\theta_2 (x_{22} -x_{32})^2 + \\theta_3  (x_{23} -x_{33})^2 &\n\\theta_1  x_{21} - x_{41})^2 + \\theta_2  (x_{22} - x_{42})^2 + \\theta_3 (x_{23} - x_{43})^2\n\\\\ 0 & 0 & 0 &\n\\theta_1 (x_{31} - x_{41})^2 + \\theta_2 (x_{32} - x_{42})^2 + \\theta_3 (x_{33} - x_{43})^2\n\\\\ 0 & 0 & 0 & 0 \\\\\\end{pmatrix}\n\\]\nFinally, \\[ \\Psi = \\exp(-D)\\] is computed.\nNext, we will demonstrate how this computation can be implemented in Python. We will consider four points in three dimensions and compute the correlation matrix \\(\\Psi\\) using the basis function from Equation 9.1. These points are placed at the origin, at the unit vectors, and at the points \\((100, 100, 100)\\) and \\((101, 100, 100)\\). So, they form two clusters: one at the origin and one at \\((100, 100, 100)\\).\n\ntheta = np.array([1,2,3])\nX = np.array([ [1,0,0], [0,1,0], [100, 100, 100], [101, 100, 100]])\nX\n\narray([[  1,   0,   0],\n       [  0,   1,   0],\n       [100, 100, 100],\n       [101, 100, 100]])\n\n\n\ndef build_Psi(X, theta):\n    n = X.shape[0]\n    k = X.shape[1]\n    D = zeros((k, n, n))\n    for l in range(k):\n        for i in range(n):\n            for j in range(i, n):\n                D[l, i, j] = theta[l]*(X[i,l] - X[j,l])**2\n    D = sum(D)\n    D = D + D.T\n    return exp(-D)  \n\n\nPsi = build_Psi(X, theta)\nPsi\n\narray([[1.        , 0.04978707, 0.        , 0.        ],\n       [0.04978707, 1.        , 0.        , 0.        ],\n       [0.        , 0.        , 1.        , 0.36787944],\n       [0.        , 0.        , 0.36787944, 1.        ]])\n\n\n\n\n\n\n\n\n\n\nFigure 9.3: Correlation matrix \\(\\Psi\\).\n\n\n\n\n\n\\(\\Box\\)\n\n\nExample 9.4 (Example: The Correlation Matrix (Using Existing Functions)) The same result as computed in Example 9.3 can be obtained with existing python functions, e.g., from the package scipy.\n\ndef build_Psi(X, theta, eps=sqrt(spacing(1))):\n    return exp(- squareform(pdist(X,\n                            metric='sqeuclidean',\n                            out=None,\n                            w=theta))) +  multiply(eye(X.shape[0]),\n                                                   eps)\n\nPsi = build_Psi(X, theta, eps=.0)\nPsi\n\narray([[1.        , 0.04978707, 0.        , 0.        ],\n       [0.04978707, 1.        , 0.        , 0.        ],\n       [0.        , 0.        , 1.        , 0.36787944],\n       [0.        , 0.        , 0.36787944, 1.        ]])\n\n\nThe condition number of the correlation matrix \\(\\Psi\\) is a measure of how well the matrix can be inverted. A high condition number indicates that the matrix is close to singular, which can lead to numerical instability in computations involving the inverse of the matrix, see Section 10.2.\n\nnp.linalg.cond(Psi)\n\nnp.float64(2.163953413738652)\n\n\n\\(\\Box\\)",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html#mle-to-estimate-theta-and-p",
    "href": "006_num_gp.html#mle-to-estimate-theta-and-p",
    "title": "9  Kriging (Gaussian Process Regression)",
    "section": "9.3 MLE to estimate \\(\\theta\\) and \\(p\\)",
    "text": "9.3 MLE to estimate \\(\\theta\\) and \\(p\\)\n\n9.3.1 The Log-Likelihood\nUntil now, the observed data \\(\\vec{y}\\) was not used. We know what the correlations mean, but how do we estimate the values of \\(\\theta_j\\) and where does our observed data \\(y\\) come in? To estimate the values of \\(\\vec{\\theta}\\) and \\(\\vec{p}\\), they are chosen to maximize the likelihood of \\(\\vec{y}\\), \\[\nL = L\\left(Y(\\vec{x}^{(1)}), \\ldots, Y(\\vec{x}^{(n)}) | \\mu, \\sigma \\right) = \\frac{1}{(2\\pi \\sigma^2)^{n/2}} \\exp\\left[ - \\frac{\\sum_{i=1}^n(Y(\\vec{x}^{(i)})-\\mu)^2}{2 \\sigma^2}\\right],\n\\tag{9.6}\\] where \\(\\mu\\) is the mean of the observed data \\(\\vec{y}\\) and \\(\\sigma\\) is the standard deviation of the errors \\(\\epsilon\\), which can be expressed in terms of the sample data \\[\nL = \\frac{1}{(2\\pi \\sigma^2)^{n/2} |\\vec{\\Psi}|^{1/2}} \\exp\\left[ - \\frac{(\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1}(\\vec{y} - \\vec{1}\\mu) }{2 \\sigma^2}\\right].\n\\tag{9.7}\\]\n\nRemark 9.2. The transition from Equation 9.6 to Equation 9.7 reflects a shift from assuming independent errors in the observed data to explicitly modeling the correlation structure between the observed responses, which is a key aspect of the stochastic process framework used in methods like Kriging. It can be explained as follows:\n\nInitial Likelihood Expression (assuming independent errors): Equation 9.6 is an expression for the likelihood of the data set, which is based on the assumption that the errors \\(\\epsilon\\) are independently randomly distributed according to a normal distribution with standard deviation \\(\\sigma\\). This form is characteristic of the likelihood of \\(n\\) independent observations \\(Y(\\vec{x}^{(i)})\\), each following a normal distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\).\nUsing Vector Notation. The sum in the exponent, i.e., \\[\n\\sum_{i=1}^n(Y(\\vec{x}^{(i)})-\\mu)^2\n\\] is equivalent to \\[\n(\\vec{y} - \\vec{1}\\mu)^T (\\vec{y} - \\vec{1}\\mu),\n\\] assuming \\(Y(\\vec{x}^{(i)}) = y^{(i)}\\) and using vector notation for \\(\\vec{y}\\) and \\(\\vec{1}\\mu\\).\nAssuming Independent Observations: Equation 9.6 assumes that the observations are independent, which means that the covariance between any two observations \\(Y(\\vec{x}^{(i)})\\) and \\(Y(\\vec{x}^{(l)})\\) is zero for \\(i \\neq l\\). In this case, the covariance matrix of the observations would be a diagonal matrix with \\(\\sigma^2\\) along the diagonal (i.e., \\(\\sigma^2 I\\)), where \\(I\\) is the identity matrix.\nStochastic Process and Correlation: In the context of Kriging, the observed responses \\(\\vec{y}\\) are considered as if they are from a stochastic process or random field. This means the random variables \\(Y(\\vec{x}^{(i)})\\) at different locations \\(\\vec{x}^{(i)}\\) are not independent, but they correlated with each other. This correlation is described by an \\((n \\times n)\\) correlation matrix \\(\\Psi\\), which is used instead of \\(\\sigma^2 I\\). The strength of the correlation between two points \\(Y(\\vec{x}^{(i)})\\) and \\(Y(\\vec{x}^{(l)})\\) depends on the distance between them and model parameters \\(\\theta_j\\) and \\(p_j\\).\nMultivariate Normal Distribution: When random variables are correlated, their joint probability distribution is generally described by a multivariate distribution. Assuming the stochastic process follows a Gaussian process, the joint distribution of the observed responses \\(\\vec{y}\\) is a multivariate normal distribution. A multivariate normal distribution for a vector \\(\\vec{Y}\\) with mean vector \\(\\vec{\\mu}\\) and covariance matrix \\(\\Sigma\\) has a probability density function given by: \\[\np(\\vec{y}) = \\frac{1}{\\sqrt{(2\\pi)^n |\\Sigma|}} \\exp\\left[ -\\frac{1}{2}(\\vec{y} - \\vec{\\mu})^T \\Sigma^{-1}(\\vec{y} - \\vec{\\mu}) \\right].\n\\]\nConnecting the Expressions: In the stochastic process framework, the following holds:\n\nThe mean vector of the observed data \\(\\vec{y}\\) is \\(\\vec{1}\\mu\\).\nThe covariance matrix \\(\\Sigma\\) is constructed by considering both the variance \\(\\sigma^2\\) and the correlations \\(\\Psi\\).\nThe covariance between \\(Y(\\vec{x}^{(i)})\\) and \\(Y(\\vec{x}^{(l)})\\) is \\(\\sigma^2 \\text{cor}(Y(\\vec{x}^{(i)}), Y(\\vec{x}^{(l)}))\\).\nTherefore, the covariance matrix is \\(\\Sigma = \\sigma^2 \\vec{\\Psi}\\).\nSubstituting \\(\\vec{\\mu} = \\vec{1}\\mu\\) and \\(\\Sigma = \\sigma^2 \\vec{\\Psi}\\) into the multivariate normal PDF formula, we get: \\[\n\\Sigma^{-1} = (\\sigma^2 \\vec{\\Psi})^{-1} = \\frac{1}{\\sigma^2} \\vec{\\Psi}^{-1}\n\\] and \\[\n|\\Sigma| = |\\sigma^2 \\vec{\\Psi}| = (\\sigma^2)^n |\\vec{\\Psi}|.\n\\] The PDF becomes: \\[\np(\\vec{y}) = \\frac{1}{\\sqrt{(2\\pi)^n (\\sigma^2)^n |\\vec{\\Psi}|}} \\exp\\left[ -\\frac{1}{2}(\\vec{y} - \\vec{1}\\mu)^T \\left(\\frac{1}{\\sigma^2} \\vec{\\Psi}^{-1}\\right)(\\vec{y} - \\vec{1}\\mu) \\right]\n\\] and simplifies to: \\[\np(\\vec{y}) = \\frac{1}{(2\\pi \\sigma^2)^{n/2} |\\vec{\\Psi}|^{1/2}} \\exp\\left[ -\\frac{1}{2\\sigma^2}(\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1}(\\vec{y} - \\vec{1}\\mu) \\right].\n\\] This is the likelihood of the sample data \\(\\vec{y}\\) given the parameters \\(\\mu\\), \\(\\sigma\\), and the correlation structure defined by the parameters within \\(\\vec{\\Psi}\\) (i.e., \\(\\vec{\\theta}\\) and \\(\\vec{p}\\)).\n\n\nIn summary, the Equation 9.6 represents the likelihood under a simplified assumption of independent errors, whereas Equation 9.7 is the likelihood derived from the assumption that the observed data comes from a multivariate normal distribution where observations are correlated according to the matrix \\(\\vec{\\Psi}\\). Equation 9.7, using the sample data vector \\(\\vec{y}\\) and the correlation matrix \\(\\vec{\\Psi}\\), properly accounts for the dependencies between data points inherent in the stochastic process model. Maximizing this likelihood is how the correlation parameters \\(\\vec{\\theta}\\) and \\(\\vec{p}\\) are estimated in Kriging.\n\\(\\Box\\)\n\nEquation 9.7 can be formulated as the log-likelihood: \\[\n\\ln(L) = - \\frac{n}{2} \\ln(2\\pi \\sigma) - \\frac{1}{2} \\ln |\\vec{\\Psi}| - \\frac{(\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1}(\\vec{y} - \\vec{1}\\mu) }{2 \\sigma^2}.\n\\tag{9.8}\\]\n\n\n9.3.2 Differentiation with Respect to \\(\\mu\\)\nLooking at the log-likelihood function, only the last term depends on \\(\\mu\\):\n\\[\n\\frac{1}{2 \\sigma^2} (\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1} (\\vec{y} - \\vec{1}\\mu)\n\\]\nTo differentiate this with respect to the scalar \\(\\mu\\), we can use matrix calculus rules.\nLet \\(\\mathbf{v} = \\vec{y} - \\vec{1}\\mu\\). \\(\\vec{y}\\) is a constant vector with respect to \\(\\mu\\), and \\(\\vec{1}\\mu\\) is a vector whose derivative with respect to the scalar \\(\\mu\\) is \\(\\vec{1}\\). So, \\(\\frac{\\partial \\mathbf{v}}{\\partial \\mu} = -\\vec{1}\\).\nThe term is in the form \\(\\mathbf{v}^T \\mathbf{A} \\mathbf{v}\\), where \\(\\mathbf{A} = \\vec{\\Psi}^{-1}\\) is a symmetric matrix. The derivative of \\(\\mathbf{v}^T \\mathbf{A} \\mathbf{v}\\) with respect to \\(\\mathbf{v}\\) is \\(2 \\mathbf{A} \\mathbf{v}\\) as explained in Remark 9.3.\n\nRemark 9.3 (Derivative of a Quadratic Form). Consider the derivative of \\(\\mathbf{v}^T \\mathbf{A} \\mathbf{v}\\) with respect to \\(\\mathbf{v}\\):\n\nThe derivative of a scalar function \\(f(\\mathbf{v})\\) with respect to a vector \\(\\mathbf{v}\\) is a vector (the gradient).\nFor a quadratic form \\(\\mathbf{v}^T \\mathbf{A} \\mathbf{v}\\), where \\(\\mathbf{A}\\) is a matrix and \\(\\mathbf{v}\\) is a vector, the general formula for the derivative with respect to \\(\\mathbf{v}\\) is \\(\\frac{\\partial}{\\partial \\mathbf{v}} (\\mathbf{v}^T \\mathbf{A} \\mathbf{v}) = \\mathbf{A} \\mathbf{v} + \\mathbf{A}^T \\mathbf{v}\\). (This is a standard result in matrix calculus and explained in Equation 10.1).\nSince \\(\\mathbf{A} = \\vec{\\Psi}^{-1}\\) is a symmetric matrix, its transpose \\(\\mathbf{A}^T\\) is equal to \\(\\mathbf{A}\\).\nSubstituting \\(\\mathbf{A}^T = \\mathbf{A}\\) into the general derivative formula, we get \\(\\mathbf{A} \\mathbf{v} + \\mathbf{A} \\mathbf{v} = 2 \\mathbf{A} \\mathbf{v}\\).\n\n\\(\\Box\\)\n\nUsing the chain rule for differentiation with respect to the scalar \\(\\mu\\): \\[ \\frac{\\partial}{\\partial \\mu} (\\mathbf{v}^T \\mathbf{A} \\mathbf{v}) = 2 \\left(\\frac{\\partial \\mathbf{v}}{\\partial \\mu}\\right)^T \\mathbf{A} \\mathbf{v} \\] Substituting \\(\\frac{\\partial \\mathbf{v}}{\\partial \\mu} = -\\vec{1}\\) and \\(\\mathbf{v} = \\vec{y} - \\vec{1}\\mu\\): \\[\n\\frac{\\partial}{\\partial \\mu} (\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1} (\\vec{y} - \\vec{1}\\mu) = 2 (-\\vec{1})^T \\vec{\\Psi}^{-1} (\\vec{y} - \\vec{1}\\mu) = -2 \\vec{1}^T \\vec{\\Psi}^{-1} (\\vec{y} - \\vec{1}\\mu)\n\\]\nNow, differentiate the full log-likelihood term depending on \\(\\mu\\):\n\\[\n\\frac{\\partial}{\\partial \\mu} \\left( - \\frac{1}{2 \\sigma^2} (\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1} (\\vec{y} - \\vec{1}\\mu) \\right) = - \\frac{1}{2 \\sigma^2} \\left( -2 \\vec{1}^T \\vec{\\Psi}^{-1} (\\vec{y} - \\vec{1}\\mu) \\right) = \\frac{1}{\\sigma^2} \\vec{1}^T \\vec{\\Psi}^{-1} (\\vec{y} - \\vec{1}\\mu)\n\\]\nSetting this to zero for maximization gives:\n\\[\n\\frac{1}{\\sigma^2} \\vec{1}^T \\vec{\\Psi}^{-1} (\\vec{y} - \\vec{1}\\mu) = 0.\n\\]\nRearranging gives: \\[\n\\vec{1}^T \\vec{\\Psi}^{-1} (\\vec{y} - \\vec{1}\\mu) = 0.\n\\]\nSolving for \\(\\mu\\) gives: \\[\n\\vec{1}^T \\vec{\\Psi}^{-1} \\vec{y} = \\mu \\vec{1}^T \\vec{\\Psi}^{-1} \\vec{1}.\n\\]\n\n\n9.3.3 Differentiation with Respect to \\(\\sigma\\)\nLet \\(\\nu = \\sigma^2\\) for simpler differentiation notation. The log-likelihood becomes: \\[\n\\ln(L) = C_1 - \\frac{n}{2} \\ln(\\nu) - \\frac{(\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1}(\\vec{y} - \\vec{1}\\mu)}{2\\nu},\n\\] where \\(C_1 = - \\frac{n}{2} \\ln(2\\pi) - \\frac{1}{2} \\ln |\\vec{\\Psi}|\\) is a constant with respect to \\(\\nu = \\sigma^2\\).\nWe differentiate with respect to \\(\\nu\\): \\[\n\\frac{\\partial \\ln(L)}{\\partial \\nu} = \\frac{\\partial}{\\partial \\nu} \\left( -\\frac{n}{2} \\ln(\\nu) \\right) + \\frac{\\partial}{\\partial \\nu} \\left( - \\frac{(\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1}(\\vec{y} - \\vec{1}\\mu)}{2\\nu} \\right).\n\\]\nThe first term’s derivative is straightforward: \\[\n\\frac{\\partial}{\\partial \\nu} \\left( -\\frac{n}{2} \\ln(\\nu) \\right) = -\\frac{n}{2} \\cdot \\frac{1}{\\nu} = -\\frac{n}{2\\sigma^2}.\n\\]\nFor the second term, let \\(C_2 = (\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1}(\\vec{y} - \\vec{1}\\mu)\\). This term is constant with respect to \\(\\sigma^2\\). The derivative is:\n\\[\n\\frac{\\partial}{\\partial \\nu} \\left( - \\frac{C_2}{2\\nu} \\right) = - \\frac{C_2}{2} \\frac{\\partial}{\\partial \\nu} (\\nu^{-1}) = - \\frac{C_2}{2} (-\\nu^{-2}) = \\frac{C_2}{2\\nu^2} = \\frac{(\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1}(\\vec{y} - \\vec{1}\\mu)}{2(\\sigma^2)^2}.\n\\]\nCombining the derivatives, the gradient of the log-likelihood with respect to \\(\\sigma^2\\) is: \\[\n\\frac{\\partial \\ln(L)}{\\partial \\sigma^2} = -\\frac{n}{2\\sigma^2} + \\frac{(\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1}(\\vec{y} - \\vec{1}\\mu)}{2(\\sigma^2)^2}.\n\\]\nSetting this to zero for maximization gives: \\[\n-\\frac{n}{2\\sigma^2} + \\frac{(\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1}(\\vec{y} - \\vec{1}\\mu)}{2(\\sigma^2)^2} = 0.\n\\]\n\n\n9.3.4 Results of the Optimizations\nOptimization of the log-likelihood by taking derivatives with respect to \\(\\mu\\) and \\(\\sigma\\) results in \\[\n\\hat{\\mu} = \\frac{\\vec{1}^T \\vec{\\Psi}^{-1} \\vec{y}^T}{\\vec{1}^T \\vec{\\Psi}^{-1} \\vec{1}^T}\n\\tag{9.9}\\] and \\[\n\\hat{\\sigma}^2 = \\frac{(\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1}(\\vec{y} - \\vec{1}\\mu)}{n}.\n\\tag{9.10}\\]\n\n\n9.3.5 The Concentrated Log-Likelihood Function\nCombining the equations, i.e., substituting Equation 9.9 and Equation 9.10 into Equation 9.8 leads to the concentrated log-likelihood function: \\[\n\\ln(L) \\approx - \\frac{n}{2} \\ln(\\hat{\\sigma}) - \\frac{1}{2} \\ln |\\vec{\\Psi}|.\n\\tag{9.11}\\]\n\nRemark 9.4 (The Concentrated Log-Likelihood). \n\nThe first term in Equation 9.11 requires information about the measured point (observations) \\(y_i\\).\nTo maximize \\(\\ln(L)\\), optimal values of \\(\\vec{\\theta}\\) and \\(\\vec{p}\\) are determined numerically, because the function (Equation 9.11) is not differentiable.\n\n\\(\\Box\\)\n\n\n\n9.3.6 Optimizing the Parameters \\(\\vec{\\theta}\\) and \\(\\vec{p}\\)\nThe concentrated log-likelihood function is very quick to compute. We do not need a statistical model, because we are only interested in the maximum likelihood estimate (MLE) of \\(\\theta\\) and \\(p\\). Optimizers such as Nelder-Mead, Conjugate Gradient, or Simulated Annealing can be used to determine optimal values for \\(\\theta\\) and \\(p\\). After the optimization, the correlation matrix \\(\\Psi\\) is build with the optimized \\(\\theta\\) and \\(p\\) values. This is best (most likely) Kriging model for the given data \\(y\\).\nObserving Figure 9.2, there’s significant change between \\(\\theta = 0.1\\) and \\(\\theta = 1\\), just as there is between \\(\\theta = 1\\) and \\(\\theta = 10\\). Hence, it is sensible to search for \\(\\theta\\) on a logarithmic scale. Suitable search bounds typically range from \\(10^{-3}\\) to \\(10^2\\), although this is not a stringent requirement. Importantly, the scaling of the observed data does not affect the values of \\(\\hat{\\theta}\\), but the scaling of the design space does. Therefore, it is advisable to consistently scale variable ranges between zero and one to ensure consistency in the degree of activity \\(\\hat{\\theta}_j\\) represents across different problems.\n\n\n9.3.7 Correlation and Covariance Matrices Revisited\nThe covariance matrix \\(\\Sigma\\) is constructed by considering both the variance \\(\\sigma^2\\) and the correlation matrix \\(\\Psi\\). They are related as follows:\n\nCovariance vs. Correlation: Covariance is a measure of the joint variability of two random variables, while correlation is a standardized measure of this relationship, ranging from -1 to 1. The relationship between covariance and correlation for two random variables \\(X\\) and \\(Y\\) is given by \\(\\text{cor}(X, Y) = \\text{cov}(X, Y) / (\\sigma_X \\sigma_Y)\\), where \\(\\sigma_X\\) and \\(\\sigma_Y\\) are their standard deviations.\nThe Covariance Matrix \\(\\Sigma\\): The covariance matrix \\(\\Sigma\\) (or \\(\\text{Cov}(Y, Y)\\) for the vector \\(\\vec{Y}\\)) captures the pairwise covariances between all elements of the vector of observed responses.\nConnecting \\(\\sigma^2\\) and \\(\\Psi\\) to \\(\\Sigma\\): In the Kriging framework described, the variance of each observation is often assumed to be constant, \\(\\sigma^2\\). The covariance between any two observations \\(Y(\\vec{x}^{(i)})\\) and \\(Y(\\vec{x}^{(l)})\\) is given by \\(\\sigma^2\\) multiplied by their correlation. That is, \\[\n\\text{cov}(Y(\\vec{x}^{(i)}), Y(\\vec{x}^{(l)})) = \\sigma^2 \\text{cor}(Y(\\vec{x}^{(i)}), Y(\\vec{x}^{(l)})).\n\\] This relationship holds for all pairs of points. When expressed in matrix form, the covariance matrix \\(\\Sigma\\) is the product of the variance \\(\\sigma^2\\) (a scalar) and the correlation matrix \\(\\Psi\\): \\[\n\\Sigma = \\sigma^2 \\Psi.\n\\]\n\nIn essence, the correlation matrix \\(\\Psi\\) defines the structure or shape of the dependencies between the data points based on their locations. The parameter \\(\\sigma^2\\) acts as a scaling factor that converts these unitless correlation values (which are between -1 and 1) into actual covariance values with units of variance, setting the overall level of variability in the system.\nSo, \\(\\sigma^2\\) tells us about the general spread or variability of the underlying process, while \\(\\Psi\\) tells you how that variability is distributed and how strongly points are related to each other based on their positions. Together, they completely define the covariance structure of your observed data in the multivariate normal distribution used in Kriging.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html#implementing-an-mle-of-the-model-parameters",
    "href": "006_num_gp.html#implementing-an-mle-of-the-model-parameters",
    "title": "9  Kriging (Gaussian Process Regression)",
    "section": "9.4 Implementing an MLE of the Model Parameters",
    "text": "9.4 Implementing an MLE of the Model Parameters\nThe matrix algebra necessary for calculating the likelihood is the most computationally intensive aspect of the Kriging process. It is crucial to ensure that the code implementation is as efficient as possible.\nGiven that \\(\\Psi\\) (our correlation matrix) is symmetric, only half of the matrix needs to be computed before adding it to its transpose. When calculating the log-likelihood, several matrix inversions are required. The fastest approach is to conduct one Cholesky factorization and then apply backward and forward substitution for each inverse.\nThe Cholesky factorization is applicable only to positive-definite matrices, which \\(\\Psi\\) generally is. However, if \\(\\Psi\\) becomes nearly singular, such as when the \\(\\vec{x}^{(i)}\\)’s are densely packed, the Cholesky factorization might fail. In these cases, one could employ an LU-decomposition, though the result might be unreliable. When \\(\\Psi\\) is near singular, the best course of action is to either use regression techniques or, as we do here, assign a poor likelihood value to parameters generating the near singular matrix, thus diverting the MLE search towards better-conditioned \\(\\Psi\\) matrices.\nWhen working with correlation matrices, increasing the values on the main diagonal of a matrix will increase the absolute value of its determinant. A critical numerical consideration in calculating the concentrated log-likelihood is that for poorly conditioned matrices, \\(\\det(\\Psi)\\) approaches zero, leading to potential numerical instability. To address this issue, it is advisable to calculate \\(\\ln(\\lvert\\Psi\\rvert)\\) in Equation 9.11 using twice the sum of the logarithms of the diagonal elements of the Cholesky factorization. This approach provides a more numerically stable method for computing the log-determinant, as the Cholesky decomposition \\(\\Psi = L L^T\\) allows us to express \\(\\ln(\\lvert\\Psi\\rvert) = 2\\sum_{i=1}^{n} \\ln(L_{ii})\\), avoiding the direct computation of potentially very small determinant values.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html#kriging-prediction",
    "href": "006_num_gp.html#kriging-prediction",
    "title": "9  Kriging (Gaussian Process Regression)",
    "section": "9.5 Kriging Prediction",
    "text": "9.5 Kriging Prediction\nWe will use the Kriging correlation \\(\\Psi\\) to predict new values based on the observed data. The presentation follows the approach described in Forrester, Sóbester, and Keane (2008) and Bartz et al. (2022).\nMain idea for prediction is that the new \\(Y(\\vec{x})\\) should be consistent with the old sample data \\(X\\). For a new prediction \\(\\hat{y}\\) at \\(\\vec{x}\\), the value of \\(\\hat{y}\\) is chosen so that it maximizes the likelihood of the sample data \\(X\\) and the prediction, given the (optimized) correlation parameter \\(\\vec{\\theta}\\) and \\(\\vec{p}\\) from above. The observed data \\(\\vec{y}\\) is augmented with the new prediction \\(\\hat{y}\\) which results in the augmented vector \\(\\vec{\\tilde{y}} = ( \\vec{y}^T, \\hat{y})^T\\). A vector of correlations between the observed data and the new prediction is defined as\n\\[ \\vec{\\psi} = \\begin{pmatrix}\n\\text{cor}\\left(\nY(\\vec{x}^{(1)}),\nY(\\vec{x})\n\\right) \\\\\n\\vdots  \\\\\n\\text{cor}\\left(\nY(\\vec{x}^{(n)}),\nY(\\vec{x})\n\\right)\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\vec{\\psi}^{(1)}\\\\\n\\vdots\\\\\n\\vec{\\psi}^{(n)}\n\\end{pmatrix}.\n\\]\n\nDefinition 9.2 (The Augmented Correlation Matrix) The augmented correlation matrix is constructed as \\[ \\tilde{\\vec{\\Psi}} =\n\\begin{pmatrix}\n\\vec{\\Psi} & \\vec{\\psi} \\\\\n\\vec{\\psi}^T & 1\n\\end{pmatrix}.\n\\]\n\\(\\Box\\)\n\nThe log-likelihood of the augmented data is \\[\n\\ln(L) = - \\frac{n}{2} \\ln(2\\pi) - \\frac{n}{2} \\ln(\\hat{\\sigma}^2) - \\frac{1}{2} \\ln |\\vec{\\hat{\\Psi}}| -  \\frac{(\\vec{\\tilde{y}} - \\vec{1}\\hat{\\mu})^T \\vec{\\tilde{\\Psi}}^{-1}(\\vec{\\tilde{y}} - \\vec{1}\\hat{\\mu})}{2 \\hat{\\sigma}^2},\n\\tag{9.12}\\]\nwhere \\(\\vec{1}\\) is a vector of ones and \\(\\hat{\\mu}\\) and \\(\\hat{\\sigma}^2\\) are the MLEs from Equation 9.9 and Equation 9.10. Only the last term in Equation 9.12 depends on \\(\\hat{y}\\), so we need only consider this term in the maximization. Details can be found in Forrester, Sóbester, and Keane (2008). Finally, the MLE for \\(\\hat{y}\\) can be calculated as \\[\n\\hat{y}(\\vec{x}) = \\hat{\\mu} + \\vec{\\psi}^T \\vec{\\tilde{\\Psi}}^{-1} (\\vec{y} - \\vec{1}\\hat{\\mu}).\n\\tag{9.13}\\]\nEquation 9.13 reveals two important properties of the Kriging predictor:\n\nBasis functions: The basis function impacts the vector \\(\\vec{\\psi}\\), which contains the \\(n\\) correlations between the new point \\(\\vec{x}\\) and the observed locations. Values from the \\(n\\) basis functions are added to a mean base term \\(\\mu\\) with weightings \\[\n\\vec{w} = \\vec{\\tilde{\\Psi}}^{(-1)} (\\vec{y} - \\vec{1}\\hat{\\mu}).\n\\]\nInterpolation: The predictions interpolate the sample data. When calculating the prediction at the \\(i\\)th sample point, \\(\\vec{x}^{(i)}\\), the \\(i\\)th column of \\(\\vec{\\Psi}^{-1}\\) is \\(\\vec{\\psi}\\), and \\(\\vec{\\psi}  \\vec{\\Psi}^{-1}\\) is the \\(i\\)th unit vector. Hence,\n\n\\[\n\\hat{y}(\\vec{x}^{(i)}) = y^{(i)}.\n\\]",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html#kriging-example-sinusoid-function",
    "href": "006_num_gp.html#kriging-example-sinusoid-function",
    "title": "9  Kriging (Gaussian Process Regression)",
    "section": "9.6 Kriging Example: Sinusoid Function",
    "text": "9.6 Kriging Example: Sinusoid Function\nToy example in 1d where the response is a simple sinusoid measured at eight equally spaced \\(x\\)-locations in the span of a single period of oscillation.\n\n9.6.1 Calculating the Correlation Matrix \\(\\Psi\\)\nThe correlation matrix \\(\\Psi\\) is based on the pairwise squared distances between the input locations. Here we will use \\(n=8\\) sample locations and \\(\\theta\\) is set to 1.0.\n\nn = 8\nX = np.linspace(0, 2*np.pi, n, endpoint=False).reshape(-1,1)\nprint(np.round(X, 2))\n\n[[0.  ]\n [0.79]\n [1.57]\n [2.36]\n [3.14]\n [3.93]\n [4.71]\n [5.5 ]]\n\n\nEvaluate at sample points\n\ny = np.sin(X)\nprint(np.round(y, 2))\n\n[[ 0.  ]\n [ 0.71]\n [ 1.  ]\n [ 0.71]\n [ 0.  ]\n [-0.71]\n [-1.  ]\n [-0.71]]\n\n\nWe have the data points shown in Table 9.1.\n\n\n\nTable 9.1: Data points for the sinusoid function\n\n\n\n\n\n\\(x\\)\n\\(y\\)\n\n\n\n\n0.0\n0.0\n\n\n0.79\n0.71\n\n\n1.57\n1.0\n\n\n2.36\n0.71\n\n\n3.14\n0.0\n\n\n3.93\n-0.71\n\n\n4.71\n-1.0\n\n\n5.5\n-0.71\n\n\n\n\n\n\nThe data points are visualized in Figure 9.4.\n\nplt.plot(X, y, \"bo\")\nplt.title(f\"Sin(x) evaluated at {n} points\")\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\nFigure 9.4: Sin(x) evaluated at 8 points.\n\n\n\n\n\n\n\n9.6.2 Computing the \\(\\Psi\\) Matrix\nWe will use the build_Psi function from Example 9.4 to compute the correlation matrix \\(\\Psi\\). \\(\\theta\\) should be an array of one value, because we are only working in one dimension (\\(k=1\\)).\n\ntheta = np.array([1.0])\nPsi = build_Psi(X, theta)\nprint(np.round(Psi, 2))\n\n[[1.   0.54 0.08 0.   0.   0.   0.   0.  ]\n [0.54 1.   0.54 0.08 0.   0.   0.   0.  ]\n [0.08 0.54 1.   0.54 0.08 0.   0.   0.  ]\n [0.   0.08 0.54 1.   0.54 0.08 0.   0.  ]\n [0.   0.   0.08 0.54 1.   0.54 0.08 0.  ]\n [0.   0.   0.   0.08 0.54 1.   0.54 0.08]\n [0.   0.   0.   0.   0.08 0.54 1.   0.54]\n [0.   0.   0.   0.   0.   0.08 0.54 1.  ]]\n\n\nFigure 9.5 visualizes the \\((8, 8)\\) correlation matrix \\(\\Psi\\).\n\n\n\n\n\n\n\n\nFigure 9.5: Correlation matrix \\(\\Psi\\) for the sinusoid function.\n\n\n\n\n\n\n\n9.6.3 Selecting the New Locations\nWe would like to predict at \\(m = 100\\) new locations (or testign locations) in the interval \\([0, 2\\pi]\\). The new locations are stored in the variable x.\n\nm = 100\nx = np.linspace(0, 2*np.pi, m, endpoint=False).reshape(-1,1)\n\n\n\n9.6.4 Computing the \\(\\psi\\) Vector\nDistances between testing locations \\(x\\) and training data locations \\(X\\).\n\ndef build_psi(X, x, theta, eps=sqrt(spacing(1))):\n    n = X.shape[0]\n    k = X.shape[1]\n    m = x.shape[0]\n    psi = zeros((n, m))\n    theta = theta * ones(k)\n    D = zeros((n, m))\n    D = cdist(x.reshape(-1, k),\n              X.reshape(-1, k),\n              metric='sqeuclidean',\n              out=None,\n              w=theta)    \n    psi = exp(-D)\n    # return psi transpose to be consistent with the literature\n    print(f\"Dimensions of psi: {psi.T.shape}\")\n    return(psi.T)\n\npsi = build_psi(X, x, theta)\n\nDimensions of psi: (8, 100)\n\n\nFigure 9.6 visualizes the \\((8, 100)\\) prediction matrix \\(\\psi\\).\n\n\n\n\n\n\n\n\nFigure 9.6: Visualization of the predition matrix \\(\\psi\\)\n\n\n\n\n\n\n\n9.6.5 Predicting at New Locations\nComputation of the predictive equations.\n\nU = cholesky(Psi).T\none = np.ones(n).reshape(-1,1)\nmu = (one.T.dot(solve(U, solve(U.T, y)))) / one.T.dot(solve(U, solve(U.T, one)))\nf = mu * ones(m).reshape(-1,1) + psi.T.dot(solve(U, solve(U.T, y - one * mu)))\nprint(f\"Dimensions of f: {f.shape}\")\n\nDimensions of f: (100, 1)\n\n\nTo compute \\(f\\), Equation 9.13 is used.\n\n\n9.6.6 Visualization\n\nplt.plot(x, f, color = \"orange\", label=\"Fitted\")\nplt.plot(x, np.sin(x), color = \"grey\", label=\"Original\")\nplt.plot(X, y, \"bo\", label=\"Measurements\")\nplt.title(\"Kriging prediction of sin(x) with {} points.\\n theta: {}\".format(n, theta[0]))\nplt.legend(loc='upper right')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n9.6.7 The Complete Python Code for the Example\nHere is the self-contained Python code for direct use in a notebook:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom numpy import (array, zeros, power, ones, exp, multiply, eye, linspace, spacing, sqrt, arange, append, ravel)\nfrom numpy.linalg import cholesky, solve\nfrom scipy.spatial.distance import squareform, pdist, cdist\n\n# --- 1. Kriging Basis Functions (Defining the Correlation) ---\n# The core of Kriging uses a specialized basis function for correlation:\n# psi(x^(i), x) = exp(- sum_{j=1}^k theta_j |x_j^(i) - x_j|^p_j)\n# For this 1D example (k=1), and with p_j=2 (squared Euclidean distance implicit from pdist usage)\n# and theta_j = theta (a single value), it simplifies.\n\ndef build_Psi(X, theta, eps=sqrt(spacing(1))):\n    \"\"\"\n    Computes the correlation matrix Psi based on pairwise squared Euclidean distances\n    between input locations, scaled by theta.\n    Adds a small epsilon to the diagonal for numerical stability (nugget effect).\n    \"\"\"\n    # Calculate pairwise squared Euclidean distances (D) between points in X\n    D = squareform(pdist(X, metric='sqeuclidean', out=None, w=theta))\n    # Compute Psi = exp(-D)\n    Psi = exp(-D)\n    # Add a small value to the diagonal for numerical stability (nugget)\n    # This is often done in Kriging implementations, though a regression method\n    # with a 'nugget' parameter (Lambda) is explicitly mentioned for noisy data later.\n    # The source code snippet for build_Psi explicitly includes `multiply(eye(X.shape), eps)`.\n    # FIX: Use X.shape to get the number of rows for the identity matrix\n    Psi += multiply(eye(X.shape[0]), eps) # Corrected line\n    return Psi\n\ndef build_psi(X_train, x_predict, theta):\n    \"\"\"\n    Computes the correlation vector (or matrix) psi between new prediction locations\n    and training data locations.\n    \"\"\"\n    # Calculate pairwise squared Euclidean distances (D) between prediction points (x_predict)\n    # and training points (X_train).\n    # `cdist` computes distances between each pair of the two collections of inputs.\n    D = cdist(x_predict, X_train, metric='sqeuclidean', out=None, w=theta)\n    # Compute psi = exp(-D)\n    psi = exp(-D)\n    return psi.T # Return transpose to be consistent with literature (n x m or n x 1)\n\n# --- 2. Data Points for the Sinusoid Function Example ---\n# The example uses a 1D sinusoid measured at eight equally spaced x-locations [153, Table 9.1].\nn = 8 # Number of sample locations\nX_train = np.linspace(0, 2 * np.pi, n, endpoint=False).reshape(-1, 1) # Generate x-locations\ny_train = np.sin(X_train) # Corresponding y-values (sine of x)\n\nprint(\"--- Training Data (X_train, y_train) ---\")\nprint(\"x values:\\n\", np.round(X_train, 2))\nprint(\"y values:\\n\", np.round(y_train, 2))\nprint(\"-\" * 40)\n\n# Visualize the data points\nplt.figure(figsize=(8, 5))\nplt.plot(X_train, y_train, \"bo\", label=f\"Measurements ({n} points)\")\nplt.title(f\"Sin(x) evaluated at {n} points\")\nplt.xlabel(\"x\")\nplt.ylabel(\"sin(x)\")\nplt.grid(True)\nplt.legend()\nplt.show()\n\n# --- 3. Calculating the Correlation Matrix (Psi) ---\n# Psi is based on pairwise squared distances between input locations.\n# theta is set to 1.0 for this 1D example.\ntheta = np.array([1.0])\nPsi = build_Psi(X_train, theta)\n\nprint(\"\\n--- Computed Correlation Matrix (Psi) ---\")\nprint(\"Dimensions of Psi:\", Psi.shape) # Should be (8, 8)\nprint(\"First 5x5 block of Psi:\\n\", np.round(Psi[:5,:5], 2))\nprint(\"-\" * 40)\n\n# --- 4. Selecting New Locations (for Prediction) ---\n# We want to predict at m = 100 new locations in the interval [0, 2*pi].\nm = 100 # Number of new locations\nx_predict = np.linspace(0, 2 * np.pi, m, endpoint=True).reshape(-1, 1)\n\nprint(\"\\n--- New Locations for Prediction (x_predict) ---\")\nprint(f\"Number of prediction points: {m}\")\nprint(\"First 5 prediction points:\\n\", np.round(x_predict[:5], 2).flatten())\nprint(\"-\" * 40)\n\n# --- 5. Computing the psi Vector ---\n# This vector contains correlations between each of the n observed data points\n# and each of the m new prediction locations.\npsi = build_psi(X_train, x_predict, theta)\n\nprint(\"\\n--- Computed Prediction Correlation Matrix (psi) ---\")\nprint(\"Dimensions of psi:\", psi.shape) # Should be (8, 100)\nprint(\"First 5x5 block of psi:\\n\", np.round(psi[:5,:5], 2))\nprint(\"-\" * 40)\n\n# --- 6. Predicting at New Locations (Kriging Prediction) ---\n# The Maximum Likelihood Estimate (MLE) for y_hat is calculated using the formula:\n# y_hat(x) = mu_hat + psi.T @ Psi_inv @ (y - 1 * mu_hat) [p. 2 of previous response, and 263]\n# Matrix inversion is efficiently performed using Cholesky factorization.\n\n# Step 6a: Cholesky decomposition of Psi\nU = cholesky(Psi).T # Note: `cholesky` in numpy returns lower triangular L, we need U (upper) so transpose L.\n\n# Step 6b: Calculate mu_hat (estimated mean)\n# mu_hat = (one.T @ Psi_inv @ y) / (one.T @ Psi_inv @ one) [p. 2 of previous response]\none = np.ones(n).reshape(-1, 1) # Vector of ones\nmu_hat = (one.T @ solve(U, solve(U.T, y_train))) / (one.T @ solve(U, solve(U.T, one)))\nmu_hat = mu_hat.item() # Extract scalar value\n\nprint(\"\\n--- Kriging Prediction Calculation ---\")\nprint(f\"Estimated mean (mu_hat): {np.round(mu_hat, 4)}\")\n\n# Step 6c: Calculate predictions f (y_hat) at new locations\n# f = mu_hat * ones(m) + psi.T @ Psi_inv @ (y - one * mu_hat)\nf_predict = mu_hat * np.ones(m).reshape(-1, 1) + psi.T @ solve(U, solve(U.T, y_train - one * mu_hat))\n\nprint(f\"Dimensions of predicted values (f_predict): {f_predict.shape}\") # Should be (100, 1)\nprint(\"First 5 predicted f values:\\n\", np.round(f_predict[:5], 2).flatten())\nprint(\"-\" * 40)\n\n# --- 7. Visualization ---\n# Plot the original sinusoid function, the measured points, and the Kriging predictions.\n\nplt.figure(figsize=(10, 6))\nplt.plot(x_predict, f_predict, color=\"orange\", label=\"Kriging Prediction\")\nplt.plot(x_predict, np.sin(x_predict), color=\"grey\", linestyle='--', label=\"True Sinusoid Function\")\nplt.plot(X_train, y_train, \"bo\", markersize=8, label=\"Measurements\")\nplt.title(f\"Kriging prediction of sin(x) with {n} points. (theta: {theta})\")\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.legend(loc='upper right')\nplt.grid(True)\nplt.show()\n\n--- Training Data (X_train, y_train) ---\nx values:\n [[0.  ]\n [0.79]\n [1.57]\n [2.36]\n [3.14]\n [3.93]\n [4.71]\n [5.5 ]]\ny values:\n [[ 0.  ]\n [ 0.71]\n [ 1.  ]\n [ 0.71]\n [ 0.  ]\n [-0.71]\n [-1.  ]\n [-0.71]]\n----------------------------------------\n\n\n\n\n\n\n\n\n\n\n--- Computed Correlation Matrix (Psi) ---\nDimensions of Psi: (8, 8)\nFirst 5x5 block of Psi:\n [[1.   0.54 0.08 0.   0.  ]\n [0.54 1.   0.54 0.08 0.  ]\n [0.08 0.54 1.   0.54 0.08]\n [0.   0.08 0.54 1.   0.54]\n [0.   0.   0.08 0.54 1.  ]]\n----------------------------------------\n\n--- New Locations for Prediction (x_predict) ---\nNumber of prediction points: 100\nFirst 5 prediction points:\n [0.   0.06 0.13 0.19 0.25]\n----------------------------------------\n\n--- Computed Prediction Correlation Matrix (psi) ---\nDimensions of psi: (8, 100)\nFirst 5x5 block of psi:\n [[1.   1.   0.98 0.96 0.94]\n [0.54 0.59 0.65 0.7  0.75]\n [0.08 0.1  0.12 0.15 0.18]\n [0.   0.01 0.01 0.01 0.01]\n [0.   0.   0.   0.   0.  ]]\n----------------------------------------\n\n--- Kriging Prediction Calculation ---\nEstimated mean (mu_hat): -0.0499\nDimensions of predicted values (f_predict): (100, 1)\nFirst 5 predicted f values:\n [0.   0.05 0.1  0.15 0.21]\n----------------------------------------",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "006_num_gp.html#jupyter-notebook",
    "href": "006_num_gp.html#jupyter-notebook",
    "title": "9  Kriging (Gaussian Process Regression)",
    "section": "9.7 Jupyter Notebook",
    "text": "9.7 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository\n\n\n\n\n\n\n\nBartz, Eva, Thomas Bartz-Beielstein, Martin Zaefferer, and Olaf Mersmann, eds. 2022. Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide. Springer.\n\n\nForrester, Alexander, András Sóbester, and Andy Keane. 2008. Engineering Design via Surrogate Modelling. Wiley.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Kriging (Gaussian Process Regression)</span>"
    ]
  },
  {
    "objectID": "006_matrices.html",
    "href": "006_matrices.html",
    "title": "10  Matrices",
    "section": "",
    "text": "10.1 Derivatives of Quadratic Forms\nWe present a step-by-step derivation of the general formula \\[\n\\frac{\\partial}{\\partial \\mathbf{v}} (\\mathbf{v}^T \\mathbf{A} \\mathbf{v}) = \\mathbf{A} \\mathbf{v} + \\mathbf{A}^T \\mathbf{v}.\n\\tag{10.1}\\]",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "006_matrices.html#sec-derivative-quadratic-form",
    "href": "006_matrices.html#sec-derivative-quadratic-form",
    "title": "10  Matrices",
    "section": "",
    "text": "Define the components. Let \\(\\mathbf{v}\\) be a vector of size \\(n \\times 1\\), and let \\(\\mathbf{A}\\) be a matrix of size \\(n \\times n\\).\nWrite out the quadratic form in summation notation. The product \\(\\mathbf{v}^T \\mathbf{A} \\mathbf{v}\\) is a scalar. It can be expanded and be rewritten as a double summation: \\[\n\\mathbf{v}^T \\mathbf{A} \\mathbf{v} = \\sum_{i=1}^n \\sum_{j=1}^n v_i a_{ij} v_j.\n\\]\nCalculate the partial derivative with respect to a component \\(v_k\\): The derivative of the scalar \\(\\mathbf{v}^T \\mathbf{A} \\mathbf{v}\\) with respect to the vector \\(\\mathbf{v}\\) is the gradient vector, whose \\(k\\)-th component is \\(\\frac{\\partial}{\\partial v_k} (\\mathbf{v}^T \\mathbf{A} \\mathbf{v})\\). We need to find \\(\\frac{\\partial}{\\partial v_k} \\left( \\sum_{i=1}^n \\sum_{j=1}^n v_i a_{ij} v_j \\right)\\). Consider the terms in the summation that involve \\(v_k\\). A term \\(v_i a_{ij} v_j\\) involves \\(v_k\\) if \\(i=k\\) or \\(j=k\\) (or both).\n\nTerms where \\(i=k\\): \\(v_k a_{kj} v_j\\). The derivative with respect to \\(v_k\\) is \\(a_{kj} v_j\\).\nTerms where \\(j=k\\): \\(v_i a_{ik} v_k\\). The derivative with respect to \\(v_k\\) is \\(v_i a_{ik}\\).\nThe term where \\(i=k\\) and \\(j=k\\): \\(v_k a_{kk} v_k = a_{kk} v_k^2\\). Its derivative with respect to \\(v_k\\) is \\(2 a_{kk} v_k\\). Notice this term is included in both cases above when \\(i=k\\) and \\(j=k\\). When \\(i=k\\), the term is \\(v_k a_{kk} v_k\\), derivative is \\(a_{kk} v_k\\). When \\(j=k\\), the term is \\(v_k a_{kk} v_k\\), derivative is \\(v_k a_{kk}\\). Summing these two gives \\(2 a_{kk} v_k\\).\n\nLet’s differentiate the sum \\(\\sum_{i=1}^n \\sum_{j=1}^n v_i a_{ij} v_j\\) with respect to \\(v_k\\): \\[\n\\frac{\\partial}{\\partial v_k} \\left( \\sum_{i=1}^n \\sum_{j=1}^n v_i a_{ij} v_j \\right) = \\sum_{i=1}^n \\sum_{j=1}^n \\frac{\\partial}{\\partial v_k} (v_i a_{ij} v_j).\n\\]\nThe partial derivative \\(\\frac{\\partial}{\\partial v_k} (v_i a_{ij} v_j)\\) is non-zero only if \\(i=k\\) or \\(j=k\\).\n\nIf \\(i=k\\) and \\(j \\ne k\\): \\(\\frac{\\partial}{\\partial v_k} (v_k a_{kj} v_j) = a_{kj} v_j\\).\nIf \\(i \\ne k\\) and \\(j = k\\): \\(\\frac{\\partial}{\\partial v_k} (v_i a_{ik} v_k) = v_i a_{ik}\\).\nIf \\(i=k\\) and \\(j=k\\): \\(\\frac{\\partial}{\\partial v_k} (v_k a_{kk} v_k) = \\frac{\\partial}{\\partial v_k} (a_{kk} v_k^2) = 2 a_{kk} v_k\\).\n\nSo, the partial derivative is the sum of derivatives of all terms involving \\(v_k\\): \\(\\frac{\\partial}{\\partial v_k} (\\mathbf{v}^T \\mathbf{A} \\mathbf{v}) = \\sum_{j \\ne k} (a_{kj} v_j) + \\sum_{i \\ne k} (v_i a_{ik}) + (2 a_{kk} v_k)\\).\nWe can rewrite this by including the \\(i=k, j=k\\) term back into the summations: \\(\\sum_{j \\ne k} (a_{kj} v_j) + a_{kk} v_k + \\sum_{i \\ne k} (v_i a_{ik}) + v_k a_{kk}\\) (since \\(v_k a_{kk} = a_{kk} v_k\\)) \\(= \\sum_{j=1}^n a_{kj} v_j + \\sum_{i=1}^n v_i a_{ik}\\).\nConvert back to matrix/vector notation: The first summation \\(\\sum_{j=1}^n a_{kj} v_j\\) is the \\(k\\)-th component of the matrix-vector product \\(\\mathbf{A} \\mathbf{v}\\).The second summation \\(\\sum_{i=1}^n v_i a_{ik}\\) can be written as \\(\\sum_{i=1}^n a_{ik} v_i\\). Recall that the element in the \\(k\\)-th row and \\(i\\)-th column of the transpose matrix \\(\\mathbf{A}^T\\) is \\((A^T)_{ki} = a_{ik}\\). So, \\(\\sum_{i=1}^n a_{ik} v_i = \\sum_{i=1}^n (A^T)_{ki} v_i\\), which is the \\(k\\)-th component of the matrix-vector product \\(\\mathbf{A}^T \\mathbf{v}\\).\nAssemble the gradient vector: The \\(k\\)-th component of the gradient \\(\\frac{\\partial}{\\partial \\mathbf{v}} (\\mathbf{v}^T \\mathbf{A} \\mathbf{v})\\) is \\((\\mathbf{A} \\mathbf{v})_k + (\\mathbf{A}^T \\mathbf{v})_k\\). Since this holds for all \\(k = 1, \\dots, n\\), the gradient vector is the sum of the two vectors \\(\\mathbf{A} \\mathbf{v}\\) and \\(\\mathbf{A}^T \\mathbf{v}\\). Therefore, the general formula for the derivative is \\(\\frac{\\partial}{\\partial \\mathbf{v}} (\\mathbf{v}^T \\mathbf{A} \\mathbf{v}) = \\mathbf{A} \\mathbf{v} + \\mathbf{A}^T \\mathbf{v}\\).",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "006_matrices.html#sec-conditon-number",
    "href": "006_matrices.html#sec-conditon-number",
    "title": "10  Matrices",
    "section": "10.2 The Condition Number",
    "text": "10.2 The Condition Number\nA small value, eps, can be passed to the function build_Psi to improve the condition number. For example, eps=sqrt(spacing(1)) can be used. The numpy function spacing() returns the distance between a number and its nearest adjacent number.\nThe condition number of a matrix is a measure of its sensitivity to small changes in its elements. It is used to estimate how much the output of a function will change if the input is slightly altered.\nA matrix with a low condition number is well-conditioned, which means its behavior is relatively stable, while a matrix with a high condition number is ill-conditioned, meaning its behavior is unstable with respect to numerical precision.\n\nimport numpy as np\n\n# Define a well-conditioned matrix (low condition number)\nA = np.array([[1, 0.1], [0.1, 1]])\nprint(\"Condition number of A: \", np.linalg.cond(A))\n\n# Define an ill-conditioned matrix (high condition number)\nB = np.array([[1, 0.99999999], [0.99999999, 1]])\nprint(\"Condition number of B: \", np.linalg.cond(B))\n\nCondition number of A:  1.2222222222222225\nCondition number of B:  200000000.57495335",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "006_matrices.html#sec-matrix-pseudoinverse",
    "href": "006_matrices.html#sec-matrix-pseudoinverse",
    "title": "10  Matrices",
    "section": "10.3 The Moore-Penrose Pseudoinverse",
    "text": "10.3 The Moore-Penrose Pseudoinverse\n\n10.3.1 Definitions\nThe Moore-Penrose pseudoinverse is a generalization of the inverse matrix for non-square or singular matrices. It is computed as\n\\[\nA^+ = (A^* A)^{-1} A^*,\n\\] where \\(A^*\\) is the conjugate transpose of \\(A\\).\nIt satisfies the following properties:\n\n\\(AA^+A = A\\)\n\\(A^+AA^+ = A^+\\)\n\\((AA^+)^* = AA^+\\).\n\\((A^+A)^* = A^+A\\)\n\\(A^+ = (A^*)^+\\)\n\\(A^+ = A^T\\) if \\(A\\) is a square matrix and \\(A\\) is invertible.\n\nThe pseudoinverse can be computed using Singular Value Decomposition (SVD).\n\n\n10.3.2 Implementation in Python\n\nimport numpy as np\nfrom numpy.linalg import pinv\nA = np.array([[1, 2], [3, 4], [5, 6]])\nprint(f\"Matrix A:\\n {A}\")\nA_pseudo_inv = pinv(A)\nprint(f\"Moore-Penrose Pseudoinverse:\\n {A_pseudo_inv}\")\n\nMatrix A:\n [[1 2]\n [3 4]\n [5 6]]\nMoore-Penrose Pseudoinverse:\n [[-1.33333333 -0.33333333  0.66666667]\n [ 1.08333333  0.33333333 -0.41666667]]",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "006_matrices.html#sec-strictly-positive-definite",
    "href": "006_matrices.html#sec-strictly-positive-definite",
    "title": "10  Matrices",
    "section": "10.4 Strictly Positive Definite Kernels",
    "text": "10.4 Strictly Positive Definite Kernels\n\n10.4.1 Definition\n\nDefinition 10.1 (Strictly Positive Definite Kernel) A kernel function \\(k(x,y)\\) is called strictly positive definite if for any finite collection of distinct points \\({x_1, x_2, \\ldots, x_n}\\) in the input space and any non-zero vector of coefficients \\(\\alpha = (\\alpha_1, \\alpha_2, \\ldots, \\alpha_n)\\), the following inequality holds:\n\\[\n\\sum_{i=1}^{n} \\sum_{j=1}^{n} \\alpha_i \\alpha_j k(x_i, x_j) &gt; 0.\n\\tag{10.2}\\]\n\nIn contrast, a kernel function \\(k(x,y)\\) is called positive definite (but not strictly) if the “\\(&gt;\\)” sign is replaced by “\\(\\geq\\)” in the above inequality.\n\n\n10.4.2 Connection to Positive Definite Matrices\nThe connection between strictly positive definite kernels and positive definite matrices lies in the Gram matrix construction:\n\nWhen we evaluate a kernel function \\(k(x,y)\\) at all pairs of data points in our sample, we construct the Gram matrix \\(K\\) where \\(K_{ij} = k(x_i, x_j)\\).\nIf the kernel function \\(k\\) is strictly positive definite, then for any set of distinct points, the resulting Gram matrix will be symmetric positive definite.\n\nA symmetric matrix is positive definite if and only if for any non-zero vector \\(\\alpha\\), the quadratic form \\(\\alpha^T K \\alpha &gt; 0\\), which directly corresponds to the kernel definition above.\n\n\n10.4.3 Connection to RBF Models\nFor RBF models, the kernel function is the radial basis function itself: \\[\nk(x,y) = \\psi(||x-y||).\n\\]\nThe Gaussian RBF kernel \\(\\psi(r) = e^{-r^2/(2\\sigma^2)}\\) is strictly positive definite in \\(\\mathbb{R}^n\\) for any dimension \\(n\\). The inverse multiquadric kernel \\(\\psi(r) = (r^2 + \\sigma^2)^{-1/2}\\) is also strictly positive definite in any dimension.\nThis mathematical property guarantees that the interpolation problem has a unique solution (the weight vector \\(\\vec{w}\\) is uniquely determined). The linear system \\(\\Psi \\vec{w} = \\vec{y}\\) can be solved reliably using Cholesky decomposition. The RBF interpolant exists and is unique for any distinct set of centers.",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "006_matrices.html#cholesky-decomposition-and-positive-definite-matrices",
    "href": "006_matrices.html#cholesky-decomposition-and-positive-definite-matrices",
    "title": "10  Matrices",
    "section": "10.5 Cholesky Decomposition and Positive Definite Matrices",
    "text": "10.5 Cholesky Decomposition and Positive Definite Matrices\nWe consider the definiteness of a matrix, before discussing the Cholesky decomposition.\n\nDefinition 10.2 (Positive Definite Matrix) A symmetric matrix \\(A\\) is positive definite if all its eigenvalues are positive.\n\n\nExample 10.1 (Positive Definite Matrix) Given a symmetric matrix \\(A = \\begin{pmatrix} 9 & 4 \\\\ 4 & 9 \\end{pmatrix}\\), the eigenvalues of \\(A\\) are \\(\\lambda_1 = 13\\) and \\(\\lambda_2 = 5\\). Since both eigenvalues are positive, the matrix \\(A\\) is positive definite.\n\n\nDefinition 10.3 (Negative Definite, Positive Semidefinite, and Negative Semidefinite Matrices) Similarily, a symmetric matrix \\(A\\) is negative definite if all its eigenvalues are negative. It is positive semidefinite if all its eigenvalues are non-negative, and negative semidefinite if all its eigenvalues are non-positive.\n\nThe covariance matrix must be positive definite for a multivariate normal distribution for a couple of reasons:\n\nSemidefinite vs Definite: A covariance matrix is always symmetric and positive semidefinite. However, for a multivariate normal distribution, it must be positive definite, not just semidefinite. This is because a positive semidefinite matrix can have zero eigenvalues, which would imply that some dimensions in the distribution have zero variance, collapsing the distribution in those dimensions. A positive definite matrix has all positive eigenvalues, ensuring that the distribution has positive variance in all dimensions.\nInvertibility: The multivariate normal distribution’s probability density function involves the inverse of the covariance matrix. If the covariance matrix is not positive definite, it may not be invertible, and the density function would be undefined.\n\nIn summary, the covariance matrix being positive definite ensures that the multivariate normal distribution is well-defined and has positive variance in all dimensions.\nThe definiteness of a matrix can be checked by examining the eigenvalues of the matrix. If all eigenvalues are positive, the matrix is positive definite.\n\nimport numpy as np\n\ndef is_positive_definite(matrix):\n    return np.all(np.linalg.eigvals(matrix) &gt; 0)\n\nmatrix = np.array([[9, 4], [4, 9]])\nprint(is_positive_definite(matrix))  # Outputs: True\n\nTrue\n\n\nHowever, a more efficient way to check the definiteness of a matrix is through the Cholesky decomposition.\n\nDefinition 10.4 (Cholesky Decomposition) For a given symmetric positive-definite matrix \\(A \\in \\mathbb{R}^{n \\times n}\\), there exists a unique lower triangular matrix \\(L \\in \\mathbb{R}^{n \\times n}\\) with positive diagonal elements such that:\n\\[\nA = L L^T.\n\\]\nHere, \\(L^T\\) denotes the transpose of \\(L\\).\n\n\nExample 10.2 (Cholesky decomposition using numpy) linalg.cholesky computes the Cholesky decomposition of a matrix, i.e., it computes a lower triangular matrix \\(L\\) such that \\(LL^T = A\\). If the matrix is not positive definite, an error (LinAlgError) is raised.\n\nimport numpy as np\n\n# Define a Hermitian, positive-definite matrix\nA = np.array([[9, 4], [4, 9]]) \n\n# Compute the Cholesky decomposition\nL = np.linalg.cholesky(A)\n\nprint(\"L = \\n\", L)\nprint(\"L*LT = \\n\", np.dot(L, L.T))\n\nL = \n [[3.         0.        ]\n [1.33333333 2.68741925]]\nL*LT = \n [[9. 4.]\n [4. 9.]]\n\n\n\n\nExample 10.3 (Cholesky Decomposition) Given a symmetric positive-definite matrix \\(A = \\begin{pmatrix} 9 & 4 \\\\ 4 & 9 \\end{pmatrix}\\), the Cholesky decomposition computes the lower triangular matrix \\(L\\) such that \\(A = L L^T\\). The matrix \\(L\\) is computed as: \\[\nL = \\begin{pmatrix} 3 & 0 \\\\ 4/3 & 2 \\end{pmatrix},\n\\] so that \\[\nL L^T = \\begin{pmatrix} 3 & 0 \\\\ 4/3 & \\sqrt{65}/3 \\end{pmatrix} \\begin{pmatrix} 3 & 4/3 \\\\ 0 & \\sqrt{65}/3 \\end{pmatrix} = \\begin{pmatrix} 9 & 4 \\\\ 4 & 9 \\end{pmatrix} = A.\n\\]\n\nAn efficient implementation of the definiteness-check based on Cholesky is already available in the numpy library. It provides the np.linalg.cholesky function to compute the Cholesky decomposition of a matrix. This more efficient numpy-approach can be used as follows:\n\nimport numpy as np\n\ndef is_pd(K):\n    try:\n        np.linalg.cholesky(K)\n        return True\n    except np.linalg.linalg.LinAlgError as err:\n        if 'Matrix is not positive definite' in err.message:\n            return False\n        else:\n            raise\nmatrix = np.array([[9, 4], [4, 9]])\nprint(is_pd(matrix))  # Outputs: True\n\nTrue\n\n\n\n10.5.1 Example of Cholesky Decomposition\nWe consider dimension \\(k=1\\) and \\(n=2\\) sample points. The sample points are located at \\(x_1=1\\) and \\(x_2=5\\). The response values are \\(y_1=2\\) and \\(y_2=10\\). The correlation parameter is \\(\\theta=1\\) and \\(p\\) is set to \\(1\\). Using Equation 9.1, we can compute the correlation matrix \\(\\Psi\\):\n\\[\n\\Psi = \\begin{pmatrix}\n1 & e^{-1}\\\\\ne^{-1} & 1\n\\end{pmatrix}.\n\\]\nTo determine MLE as in Equation 9.13, we need to compute \\(\\Psi^{-1}\\):\n\\[\n\\Psi^{-1} = \\frac{e}{e^2 -1} \\begin{pmatrix}\ne & -1\\\\\n-1 & e\n\\end{pmatrix}.\n\\]\nCholesky-decomposition of \\(\\Psi\\) is recommended to compute \\(\\Psi^{-1}\\). Cholesky decomposition is a decomposition of a positive definite symmetric matrix into the product of a lower triangular matrix \\(L\\), a diagonal matrix \\(D\\) and the transpose of \\(L\\), which is denoted as \\(L^T\\). Consider the following example:\n\\[\nLDL^T=\n\\begin{pmatrix}\n1 & 0 \\\\\nl_{21} & 1\n\\end{pmatrix}\n\\begin{pmatrix}\nd_{11} & 0 \\\\\n0 & d_{22}\n\\end{pmatrix}\n\\begin{pmatrix}\n1 & l_{21} \\\\\n0 & 1\n\\end{pmatrix}=\n\\]\n\\[\n\\begin{pmatrix}\nd_{11} & 0 \\\\\nd_{11} l_{21} & d_{22}\n\\end{pmatrix}\n\\begin{pmatrix}\n1 & l_{21} \\\\\n0 & 1\n\\end{pmatrix}\n=\n\\begin{pmatrix}\nd_{11} & d_{11} l_{21} \\\\\nd_{11} l_{21} & d_{11} l_{21}^2 + d_{22}\n\\end{pmatrix}.\n\\tag{10.3}\\]\nUsing Equation 10.3, we can compute the Cholesky decomposition of \\(\\Psi\\):\n\n\\(d_{11} = 1\\),\n\\(l_{21}d_{11} = e^{-1} \\Rightarrow l_{21} = e^{-1}\\), and\n\\(d_{11} l_{21}^2 + d_{22} = 1 \\Rightarrow d_{22} = 1 - e^{-2}\\).\n\nThe Cholesky decomposition of \\(\\Psi\\) is \\[\n\\Psi = \\begin{pmatrix}\n1 & 0\\\\\ne^{-1} & 1\\\\\n\\end{pmatrix}\n\\begin{pmatrix}\n1 & 0\\\\\n0 & 1 - e^{-2}\\\\\n\\end{pmatrix}\n\\begin{pmatrix}\n1 & e^{-1}\\\\\n0 & 1\\\\\n\\end{pmatrix}\n= LDL^T\\]\nSome programs use \\(U\\) instead of \\(L\\). The Cholesky decomposition of \\(\\Psi\\) is \\[\n\\Psi = LDL^T = U^TDU.\n\\]\nUsing \\[\n\\sqrt{D} =\\begin{pmatrix}\n1 & 0\\\\\n0 & \\sqrt{1 - e^{-2}}\\\\\n\\end{pmatrix},\n\\] we can write the Cholesky decomposition of \\(\\Psi\\) without a diagonal matrix \\(D\\) as \\[\n\\Psi = \\begin{pmatrix}\n1 & 0\\\\\ne^{-1} & \\sqrt{1 - e^{-2}}\\\\\n\\end{pmatrix}\n\\begin{pmatrix}\n1 & e^{-1}\\\\\n0 & \\sqrt{1 - e^{-2}}\\\\\n\\end{pmatrix}\n= U^TU.\n\\]\n\n\n10.5.2 Inverse Matrix Using Cholesky Decomposition\nTo compute the inverse of a matrix using the Cholesky decomposition, you can follow these steps:\n\nDecompose the matrix \\(A\\) into \\(L\\) and \\(L^T\\), where \\(L\\) is a lower triangular matrix and \\(L^T\\) is the transpose of \\(L\\).\nCompute \\(L^{-1}\\), the inverse of \\(L\\).\nThe inverse of \\(A\\) is then \\((L^{-1})^T  L^-1\\).\n\nPlease note that this method only applies to symmetric, positive-definite matrices.\nThe inverse of the matrix \\(\\Psi\\) from above is:\n\\[\n\\Psi^{-1} = \\frac{e}{e^2 -1} \\begin{pmatrix}\ne & -1\\\\\n-1 & e\n\\end{pmatrix}.\n\\]\nHere’s an example of how to compute the inverse of a matrix using Cholesky decomposition in Python:\n\nimport numpy as np\nfrom scipy.linalg import cholesky, inv\nE = np.exp(1)\n\n# Psi is a symmetric, positive-definite matrix \nPsi = np.array([[1, 1/E], [1/E, 1]])\nL = cholesky(Psi, lower=True)\nL_inv = inv(L)\n# The inverse of A is (L^-1)^T * L^-1\nPsi_inv = np.dot(L_inv.T, L_inv)\n\nprint(\"Psi:\\n\", Psi)\nprint(\"Psi Inverse:\\n\", Psi_inv)\n\nPsi:\n [[1.         0.36787944]\n [0.36787944 1.        ]]\nPsi Inverse:\n [[ 1.15651764 -0.42545906]\n [-0.42545906  1.15651764]]",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "006_matrices.html#jupyter-notebook",
    "href": "006_matrices.html#jupyter-notebook",
    "title": "10  Matrices",
    "section": "10.6 Jupyter Notebook",
    "text": "10.6 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository",
    "crumbs": [
      "Numerical Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Matrices</span>"
    ]
  },
  {
    "objectID": "007_spot_intro.html",
    "href": "007_spot_intro.html",
    "title": "11  Introduction to Sequential Parameter Optimization",
    "section": "",
    "text": "11.1 An Initial Example\nThis document describes the Spot features. The official spotpython documentation can be found here: https://sequential-parameter-optimization.github.io/spotpython/.\nThe spotpython package provides several classes of objective functions. We will use an analytical objective function, i.e., a function that can be described by a (closed) formula: \\[\nf(x) = x^2.\n\\]\nfun = Analytical().fun_sphere\nx = np.linspace(-1,1,100).reshape(-1,1)\ny = fun(x)\nplt.figure()\nplt.plot(x,y, \"k\")\nplt.show()\nfrom spotpython.utils.init import fun_control_init, design_control_init, surrogate_control_init, optimizer_control_init\nspot_1 = Spot(fun=fun,\n                   fun_control=fun_control_init(\n                        lower = np.array([-10]),\n                        upper = np.array([100]),\n                        fun_evals = 7,\n                        fun_repeats = 1,\n                        max_time = inf,\n                        noise = False,\n                        tolerance_x = np.sqrt(np.spacing(1)),\n                        var_type=[\"num\"],\n                        infill_criterion = \"y\",\n                        n_points = 1,\n                        seed=123,\n                        log_level = 50),\n                   design_control=design_control_init(\n                        init_size=5,\n                        repeats=1),\n                   surrogate_control=surrogate_control_init(\n                        method=\"interpolation\",\n                        min_theta=-4,\n                        max_theta=3,\n                        n_theta=1,\n                        model_optimizer=differential_evolution,\n                        model_fun_evals=10000))\nspot_1.run()\n\nspotpython tuning: 51.152288363788145 [#########-] 85.71% \nspotpython tuning: 21.640274267756638 [##########] 100.00% Done...\n\nExperiment saved to 000_res.pkl\n\n\n&lt;spotpython.spot.spot.Spot at 0x109b26810&gt;",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "007_spot_intro.html#organization",
    "href": "007_spot_intro.html#organization",
    "title": "11  Introduction to Sequential Parameter Optimization",
    "section": "11.2 Organization",
    "text": "11.2 Organization\nSpot organizes the surrogate based optimization process in four steps:\n\nSelection of the objective function: fun.\nSelection of the initial design: design.\nSelection of the optimization algorithm: optimizer.\nSelection of the surrogate model: surrogate.\n\nFor each of these steps, the user can specify an object:\n\nfrom spotpython.fun.objectivefunctions import Analytical\nfun = Analytical().fun_sphere\nfrom spotpython.design.spacefilling import SpaceFilling\ndesign = SpaceFilling(2)\nfrom scipy.optimize import differential_evolution\noptimizer = differential_evolution\nfrom spotpython.surrogate.kriging import Kriging\nsurrogate = Kriging()\n\nFor each of these steps, the user can specify a dictionary of control parameters.\n\nfun_control\ndesign_control\noptimizer_control\nsurrogate_control\n\nEach of these dictionaries has an initialzaion method, e.g., fun_control_init(). The initialization methods set the default values for the control parameters.\n\n\n\n\n\n\nImportant:\n\n\n\n\nThe specification of an lower bound in fun_control is mandatory.\n\n\n\n\nfrom spotpython.utils.init import fun_control_init, design_control_init, optimizer_control_init, surrogate_control_init\nfun_control=fun_control_init(lower=np.array([-1, -1]),\n                            upper=np.array([1, 1]))\ndesign_control=design_control_init()\noptimizer_control=optimizer_control_init()\nsurrogate_control=surrogate_control_init()",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "007_spot_intro.html#the-spot-object",
    "href": "007_spot_intro.html#the-spot-object",
    "title": "11  Introduction to Sequential Parameter Optimization",
    "section": "11.3 The Spot Object",
    "text": "11.3 The Spot Object\nBased on the definition of the fun, design, optimizer, and surrogate objects, and their corresponding control parameter dictionaries, fun_control, design_control, optimizer_control, and surrogate_control, the spot object can be build as follows:\n\nfrom spotpython.spot import Spot\nspot_tuner = Spot(fun=fun,\n                       fun_control=fun_control,\n                       design_control=design_control,\n                       optimizer_control=optimizer_control,\n                       surrogate_control=surrogate_control)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "007_spot_intro.html#run",
    "href": "007_spot_intro.html#run",
    "title": "11  Introduction to Sequential Parameter Optimization",
    "section": "11.4 Run",
    "text": "11.4 Run\n\nspot_tuner.run()\n\nspotpython tuning: 0.0013050614212698486 [#######---] 73.33% \nspotpython tuning: 0.0003479187873901382 [########--] 80.00% \nspotpython tuning: 0.00022767416623665655 [#########-] 86.67% \nspotpython tuning: 0.00020787497784734184 [#########-] 93.33% \nspotpython tuning: 0.00020393508736265477 [##########] 100.00% Done...\n\nExperiment saved to 000_res.pkl\n\n\n&lt;spotpython.spot.spot.Spot at 0x15a4e0740&gt;",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "007_spot_intro.html#print-the-results",
    "href": "007_spot_intro.html#print-the-results",
    "title": "11  Introduction to Sequential Parameter Optimization",
    "section": "11.5 Print the Results",
    "text": "11.5 Print the Results\n\nspot_tuner.print_results()\n\nmin y: 0.00020393508736265477\nx0: 0.014161858193549292\nx1: 0.0018376234294478113\n\n\n[['x0', np.float64(0.014161858193549292)],\n ['x1', np.float64(0.0018376234294478113)]]",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "007_spot_intro.html#show-the-progress",
    "href": "007_spot_intro.html#show-the-progress",
    "title": "11  Introduction to Sequential Parameter Optimization",
    "section": "11.6 Show the Progress",
    "text": "11.6 Show the Progress\n\nspot_tuner.plot_progress()",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "007_spot_intro.html#visualize-the-surrogate",
    "href": "007_spot_intro.html#visualize-the-surrogate",
    "title": "11  Introduction to Sequential Parameter Optimization",
    "section": "11.7 Visualize the Surrogate",
    "text": "11.7 Visualize the Surrogate\n\nThe plot method of the kriging surrogate is used.\nNote: the plot uses the interval defined by the ranges of the natural variables.\n\n\nspot_tuner.surrogate.plot()",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "007_spot_intro.html#run-with-a-specific-start-design",
    "href": "007_spot_intro.html#run-with-a-specific-start-design",
    "title": "11  Introduction to Sequential Parameter Optimization",
    "section": "11.8 Run With a Specific Start Design",
    "text": "11.8 Run With a Specific Start Design\nTo pass a specific start design, use the X_start argument of the run method.\n\nspot_x0 = Spot(fun=fun,\n                    fun_control=fun_control_init(\n                        lower = np.array([-10]),\n                        upper = np.array([100]),\n                        fun_evals = 7,\n                        fun_repeats = 1,\n                        max_time = inf,\n                        noise = False,\n                        tolerance_x = np.sqrt(np.spacing(1)),\n                        var_type=[\"num\"],\n                        infill_criterion = \"y\",\n                        n_points = 1,\n                        seed=123,\n                        log_level = 50),\n                    design_control=design_control_init(\n                        init_size=5,\n                        repeats=1),\n                    surrogate_control=surrogate_control_init(\n                        method=\"interpolation\",\n                        min_theta=-4,\n                        max_theta=3,\n                        n_theta=1,\n                        model_optimizer=differential_evolution,\n                        model_fun_evals=10000))\nspot_x0.run(X_start=np.array([0.5, -0.5]))\nspot_x0.plot_progress()\n\nspotpython tuning: 51.152288363788145 [#########-] 85.71% \nspotpython tuning: 21.640274267756638 [##########] 100.00% Done...\n\nExperiment saved to 000_res.pkl",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "007_spot_intro.html#init-build-initial-design",
    "href": "007_spot_intro.html#init-build-initial-design",
    "title": "11  Introduction to Sequential Parameter Optimization",
    "section": "11.9 Init: Build Initial Design",
    "text": "11.9 Init: Build Initial Design\n\nfrom spotpython.design.spacefilling import SpaceFilling\nfrom spotpython.surrogate.kriging import Kriging\nfrom spotpython.fun.objectivefunctions import Analytical\nfrom spotpython.utils.init import fun_control_init\ngen = SpaceFilling(2)\nrng = np.random.RandomState(1)\nlower = np.array([-5,-0])\nupper = np.array([10,15])\nfun = Analytical().fun_branin\n\nfun_control = fun_control_init(sigma=0)\n\nX = gen.scipy_lhd(10, lower=lower, upper = upper)\nprint(X)\ny = fun(X, fun_control=fun_control)\nprint(y)\n\n[[ 8.97647221 13.41926847]\n [ 0.66946019  1.22344228]\n [ 5.23614115 13.78185824]\n [ 5.6149825  11.5851384 ]\n [-1.72963184  1.66516096]\n [-4.26945568  7.1325531 ]\n [ 1.26363761 10.17935555]\n [ 2.88779942  8.05508969]\n [-3.39111089  4.15213772]\n [ 7.30131231  5.22275244]]\n[128.95676449  31.73474356 172.89678121 126.71295908  64.34349975\n  70.16178611  48.71407916  31.77322887  76.91788181  30.69410529]",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "007_spot_intro.html#replicability",
    "href": "007_spot_intro.html#replicability",
    "title": "11  Introduction to Sequential Parameter Optimization",
    "section": "11.10 Replicability",
    "text": "11.10 Replicability\nSeed\n\ngen = SpaceFilling(2, seed=123)\nX0 = gen.scipy_lhd(3)\ngen = SpaceFilling(2, seed=345)\nX1 = gen.scipy_lhd(3)\nX2 = gen.scipy_lhd(3)\ngen = SpaceFilling(2, seed=123)\nX3 = gen.scipy_lhd(3)\nX0, X1, X2, X3\n\n(array([[0.77254938, 0.31539299],\n        [0.59321338, 0.93854273],\n        [0.27469803, 0.3959685 ]]),\n array([[0.78373509, 0.86811887],\n        [0.06692621, 0.6058029 ],\n        [0.41374778, 0.00525456]]),\n array([[0.121357  , 0.69043832],\n        [0.41906219, 0.32838498],\n        [0.86742658, 0.52910374]]),\n array([[0.77254938, 0.31539299],\n        [0.59321338, 0.93854273],\n        [0.27469803, 0.3959685 ]]))",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "007_spot_intro.html#surrogates",
    "href": "007_spot_intro.html#surrogates",
    "title": "11  Introduction to Sequential Parameter Optimization",
    "section": "11.11 Surrogates",
    "text": "11.11 Surrogates\n\n11.11.1 A Simple Predictor\nThe code below shows how to use a simple model for prediction. Assume that only two (very costly) measurements are available:\n\nf(0) = 0.5\nf(2) = 2.5\n\nWe are interested in the value at \\(x_0 = 1\\), i.e., \\(f(x_0 = 1)\\), but cannot run an additional, third experiment.\n\nfrom sklearn import linear_model\nX = np.array([[0], [2]])\ny = np.array([0.5, 2.5])\nS_lm = linear_model.LinearRegression()\nS_lm = S_lm.fit(X, y)\nX0 = np.array([[1]])\ny0 = S_lm.predict(X0)\nprint(y0)\n\n[1.5]\n\n\nCentral Idea: Evaluation of the surrogate model S_lm is much cheaper (or / and much faster) than running the real-world experiment \\(f\\).",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "007_spot_intro.html#tensorboard-setup",
    "href": "007_spot_intro.html#tensorboard-setup",
    "title": "11  Introduction to Sequential Parameter Optimization",
    "section": "11.12 Tensorboard Setup",
    "text": "11.12 Tensorboard Setup\n\n11.12.1 Tensorboard Configuration\nThe TENSORBOARD_CLEAN argument can be set to True in the fun_control dictionary to archive the TensorBoard folder if it already exists. This is useful if you want to start a hyperparameter tuning process from scratch. If you want to continue a hyperparameter tuning process, set TENSORBOARD_CLEAN to False. Then the TensorBoard folder will not be archived and the old and new TensorBoard files will shown in the TensorBoard dashboard.\n\n\n11.12.2 Starting TensorBoard\nTensorBoard can be started as a background process with the following command, where ./runs is the default directory for the TensorBoard log files:\ntensorboard --logdir=\"./runs\"\n\n\n\n\n\n\nTENSORBOARD_PATH\n\n\n\nThe TensorBoard path can be printed with the following command (after a fun_control object has been created):\n\nfrom spotpython.utils.init import get_tensorboard_path\nget_tensorboard_path(fun_control)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "007_spot_intro.html#demotest-objective-function-fails",
    "href": "007_spot_intro.html#demotest-objective-function-fails",
    "title": "11  Introduction to Sequential Parameter Optimization",
    "section": "11.13 Demo/Test: Objective Function Fails",
    "text": "11.13 Demo/Test: Objective Function Fails\nSPOT expects np.nan values from failed objective function values. These are handled. Note: SPOT’s counter considers only successful executions of the objective function.\n\nimport numpy as np\nfrom spotpython.fun.objectivefunctions import Analytical\nfrom spotpython.spot import Spot\nimport numpy as np\nfrom math import inf\n# number of initial points:\nni = 20\n# number of points\nn = 30\n\nfun = Analytical().fun_random_error\nfun_control=fun_control_init(\n    lower = np.array([-1]),\n    upper= np.array([1]),\n    fun_evals = n,\n    show_progress=False)\ndesign_control=design_control_init(init_size=ni)\n\nspot_1 = Spot(fun=fun,\n                     fun_control=fun_control,\n                     design_control=design_control)\n\n# assert value error from the run method\ntry:\n    spot_1.run()\nexcept ValueError as e:\n    print(e)\n\nExperiment saved to 000_res.pkl",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "007_spot_intro.html#handling-results-printing-saving-and-loading",
    "href": "007_spot_intro.html#handling-results-printing-saving-and-loading",
    "title": "11  Introduction to Sequential Parameter Optimization",
    "section": "11.14 Handling Results: Printing, Saving, and Loading",
    "text": "11.14 Handling Results: Printing, Saving, and Loading\nThe results can be printed with the following command:\n\nspot_tuner.print_results(print_screen=False)\n\nThe tuned hyperparameters can be obtained as a dictionary with the following command:\n\nfrom spotpython.hyperparameters.values import get_tuned_hyperparameters\nget_tuned_hyperparameters(spot_tuner, fun_control)\n\nThe results can be saved and reloaded with the following commands:\n\nfrom spotpython.utils.file import save_pickle, load_pickle\nfrom spotpython.utils.init import get_experiment_name\nexperiment_name = get_experiment_name(\"024\")\nSAVE_AND_LOAD = False\nif SAVE_AND_LOAD == True:\n    save_pickle(spot_tuner, experiment_name)\n    spot_tuner = load_pickle(experiment_name)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "007_spot_intro.html#spotpython-as-a-hyperparameter-tuner",
    "href": "007_spot_intro.html#spotpython-as-a-hyperparameter-tuner",
    "title": "11  Introduction to Sequential Parameter Optimization",
    "section": "11.15 spotpython as a Hyperparameter Tuner",
    "text": "11.15 spotpython as a Hyperparameter Tuner\n\n11.15.1 Modifying Hyperparameter Levels\nspotpython distinguishes between different types of hyperparameters. The following types are supported:\n\nint (integer)\nfloat (floating point number)\nboolean (boolean)\nfactor (categorical)\n\n\n11.15.1.1 Integer Hyperparameters\nInteger hyperparameters can be modified with the set_int_hyperparameter_values() [SOURCE] function. The following code snippet shows how to modify the n_estimators hyperparameter of a random forest model:\n\nfrom spotriver.hyperdict.river_hyper_dict import RiverHyperDict\nfrom spotpython.utils.init import fun_control_init\nfrom spotpython.hyperparameters.values import set_int_hyperparameter_values\nfrom spotpython.utils.eda import print_exp_table\nfun_control = fun_control_init(\n    core_model_name=\"forest.AMFRegressor\",\n    hyperdict=RiverHyperDict,\n)\nprint(\"Before modification:\")\nprint_exp_table(fun_control)\nset_int_hyperparameter_values(fun_control, \"n_estimators\", 2, 5)\nprint(\"After modification:\")\nprint_exp_table(fun_control)\n\nBefore modification:\n| name            | type   |   default |   lower |   upper | transform             |\n|-----------------|--------|-----------|---------|---------|-----------------------|\n| n_estimators    | int    |         3 |     2   |       5 | transform_power_2_int |\n| step            | float  |         1 |     0.1 |      10 | None                  |\n| use_aggregation | factor |         1 |     0   |       1 | None                  |\nSetting hyperparameter n_estimators to value [2, 5].\nVariable type is int.\nCore type is None.\nCalling modify_hyper_parameter_bounds().\nAfter modification:\n| name            | type   |   default |   lower |   upper | transform             |\n|-----------------|--------|-----------|---------|---------|-----------------------|\n| n_estimators    | int    |         3 |     2   |       5 | transform_power_2_int |\n| step            | float  |         1 |     0.1 |      10 | None                  |\n| use_aggregation | factor |         1 |     0   |       1 | None                  |\n\n\n\n\n11.15.1.2 Float Hyperparameters\nFloat hyperparameters can be modified with the set_float_hyperparameter_values() [SOURCE] function. The following code snippet shows how to modify the step hyperparameter of a hyperparameter of a Mondrian Regression Tree model:\n\nfrom spotriver.hyperdict.river_hyper_dict import RiverHyperDict\nfrom spotpython.utils.init import fun_control_init\nfrom spotpython.hyperparameters.values import set_float_hyperparameter_values\nfrom spotpython.utils.eda import print_exp_table\nfun_control = fun_control_init(\n    core_model_name=\"forest.AMFRegressor\",\n    hyperdict=RiverHyperDict,\n)\nprint(\"Before modification:\")\nprint_exp_table(fun_control)\nset_float_hyperparameter_values(fun_control, \"step\", 0.2, 5)\nprint(\"After modification:\")\nprint_exp_table(fun_control)\n\nBefore modification:\n| name            | type   |   default |   lower |   upper | transform             |\n|-----------------|--------|-----------|---------|---------|-----------------------|\n| n_estimators    | int    |         3 |     2   |       5 | transform_power_2_int |\n| step            | float  |         1 |     0.1 |      10 | None                  |\n| use_aggregation | factor |         1 |     0   |       1 | None                  |\nSetting hyperparameter step to value [0.2, 5].\nVariable type is float.\nCore type is None.\nCalling modify_hyper_parameter_bounds().\nAfter modification:\n| name            | type   |   default |   lower |   upper | transform             |\n|-----------------|--------|-----------|---------|---------|-----------------------|\n| n_estimators    | int    |         3 |     2   |       5 | transform_power_2_int |\n| step            | float  |         1 |     0.2 |       5 | None                  |\n| use_aggregation | factor |         1 |     0   |       1 | None                  |\n\n\n\n\n11.15.1.3 Boolean Hyperparameters\nBoolean hyperparameters can be modified with the set_boolean_hyperparameter_values() [SOURCE] function. The following code snippet shows how to modify the use_aggregation hyperparameter of a Mondrian Regression Tree model:\n\nfrom spotriver.hyperdict.river_hyper_dict import RiverHyperDict\nfrom spotpython.utils.init import fun_control_init\nfrom spotpython.hyperparameters.values import set_boolean_hyperparameter_values\nfrom spotpython.utils.eda import print_exp_table\nfun_control = fun_control_init(\n    core_model_name=\"forest.AMFRegressor\",\n    hyperdict=RiverHyperDict,\n)\nprint(\"Before modification:\")\nprint_exp_table(fun_control)\nset_boolean_hyperparameter_values(fun_control, \"use_aggregation\", 0, 0)\nprint(\"After modification:\")\nprint_exp_table(fun_control)\n\nBefore modification:\n| name            | type   |   default |   lower |   upper | transform             |\n|-----------------|--------|-----------|---------|---------|-----------------------|\n| n_estimators    | int    |         3 |     2   |       5 | transform_power_2_int |\n| step            | float  |         1 |     0.1 |      10 | None                  |\n| use_aggregation | factor |         1 |     0   |       1 | None                  |\nSetting hyperparameter use_aggregation to value [0, 0].\nVariable type is factor.\nCore type is bool.\nCalling modify_boolean_hyper_parameter_levels().\nAfter modification:\n| name            | type   |   default |   lower |   upper | transform             |\n|-----------------|--------|-----------|---------|---------|-----------------------|\n| n_estimators    | int    |         3 |     2   |       5 | transform_power_2_int |\n| step            | float  |         1 |     0.1 |      10 | None                  |\n| use_aggregation | factor |         1 |     0   |       0 | None                  |\n\n\n\n\n11.15.1.4 Factor Hyperparameters\nFactor hyperparameters can be modified with the set_factor_hyperparameter_values() [SOURCE] function. The following code snippet shows how to modify the leaf_model hyperparameter of a Hoeffding Tree Regressor model:\n\nfrom spotriver.hyperdict.river_hyper_dict import RiverHyperDict\nfrom spotpython.utils.init import fun_control_init\nfrom spotpython.hyperparameters.values import set_factor_hyperparameter_values\nfrom spotpython.utils.eda import print_exp_table\nfun_control = fun_control_init(\n    core_model_name=\"tree.HoeffdingTreeRegressor\",\n    hyperdict=RiverHyperDict,\n)\nprint(\"Before modification:\")\nprint_exp_table(fun_control)\nset_factor_hyperparameter_values(fun_control, \"leaf_model\", ['LinearRegression',\n                                                    'Perceptron'])\nprint(\"After modification:\")\n\nBefore modification:\n| name                   | type   | default          |   lower |    upper | transform              |\n|------------------------|--------|------------------|---------|----------|------------------------|\n| grace_period           | int    | 200              |  10     | 1000     | None                   |\n| max_depth              | int    | 20               |   2     |   20     | transform_power_2_int  |\n| delta                  | float  | 1e-07            |   1e-08 |    1e-06 | None                   |\n| tau                    | float  | 0.05             |   0.01  |    0.1   | None                   |\n| leaf_prediction        | factor | mean             |   0     |    2     | None                   |\n| leaf_model             | factor | LinearRegression |   0     |    2     | None                   |\n| model_selector_decay   | float  | 0.95             |   0.9   |    0.99  | None                   |\n| splitter               | factor | EBSTSplitter     |   0     |    2     | None                   |\n| min_samples_split      | int    | 5                |   2     |   10     | None                   |\n| binary_split           | factor | 0                |   0     |    1     | None                   |\n| max_size               | float  | 500.0            | 100     | 1000     | None                   |\n| memory_estimate_period | int    | 6                |   3     |    8     | transform_power_10_int |\n| stop_mem_management    | factor | 0                |   0     |    1     | None                   |\n| remove_poor_attrs      | factor | 0                |   0     |    1     | None                   |\n| merit_preprune         | factor | 1                |   0     |    1     | None                   |\nAfter modification:",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "007_spot_intro.html#advantages-of-the-spotpython-approach",
    "href": "007_spot_intro.html#advantages-of-the-spotpython-approach",
    "title": "11  Introduction to Sequential Parameter Optimization",
    "section": "12.1 Advantages of the spotpython approach",
    "text": "12.1 Advantages of the spotpython approach\n\nNeural networks and many ML algorithms are non-deterministic, so results are noisy (i.e., depend on the the initialization of the weights). Enhanced noise handling strategies, OCBA (description from HPT-book).\nOptimal Computational Budget Allocation (OCBA) is a very efficient solution to solve the “general ranking and selection problem” if the objective function is noisy. It allocates function evaluations in an uneven manner to identify the best solutions and to reduce the total optimization costs. [Chen10a, Bart11b] Given a total number of optimization samples \\(N\\) to be allocated to \\(k\\) competing solutions whose performance is depicted by random variables with means \\(\\bar{y}_i\\) (\\(i=1, 2, \\ldots, k\\)), and finite variances \\(\\sigma_i^2\\), respectively, as \\(N \\to \\infty\\), the can be asymptotically maximized when \\[\\begin{align}\n\\frac{N_i}{N_j} & = \\left( \\frac{ \\sigma_i / \\delta_{b,i}}{\\sigma_j/ \\delta_{b,j}} \\right)^2, i,j \\in \\{ 1, 2, \\ldots, k\\}, \\text{ and }\ni \\neq j \\neq b,\\\\\nN_b &= \\sigma_b \\sqrt{\n\\sum_{i=1, i\\neq b}^k \\frac{N_i^2}{\\sigma_i^2}\n},\n\\end{align}\\] where \\(N_i\\) is the number of replications allocated to solution \\(i\\), \\(\\delta_{b,i} = \\bar{y}_b - \\bar{y}_i\\), and \\(\\bar{y}_b \\leq \\min_{i\\neq b} \\bar{y}_i\\) Bartz-Beielstein and Friese (2011).\nSurrogate-based optimization: Better than grid search and random search (Reference to HPT-book)\nVisualization\nImportance based on the Kriging model\nSensitivity analysis. Exploratory fitness landscape analysis. Provides XAI methods (feature importance, integrated gradients, etc.)\nUncertainty quantification\nFlexible, modular meta-modeling handling. spotpython come with a Kriging model, which can be replaced by any model implemented in scikit-learn.\nEnhanced metric handling, especially for categorical hyperparameters (any sklearn metric can be used). Default is..\nIntegration with TensorBoard: Visualization of the hyperparameter tuning process, of the training steps, the model graph. Parallel coordinates plot, scatter plot matrix, and more.\nReproducibility. Results are stored as pickle files. The results can be loaded and visualized at any time and be transferred between different machines and operating systems.\nHandles scikit-learn models and pytorch models out-of-the-box. The user has to add a simple wrapper for passing the hyperparemeters to use a pytorch model in spotpython.\nCompatible with Lightning.\nUser can add own models as plain python code.\nUser can add own data sets in various formats.\nFlexible data handling and data preprocessing.\nMany examples online (hyperparameter-tuning-cookbook).\nspotpython uses a robust optimizer that can even deal with hyperparameter-settings that cause crashes of the algorithms to be tuned.\neven if the optimum is not found, HPT with spotpython prevents the user from choosing bad hyperparameters in a systematic way (design of experiments).",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "007_spot_intro.html#disadvantages-of-the-spotpython-approach",
    "href": "007_spot_intro.html#disadvantages-of-the-spotpython-approach",
    "title": "11  Introduction to Sequential Parameter Optimization",
    "section": "12.2 Disadvantages of the spotpython approach",
    "text": "12.2 Disadvantages of the spotpython approach\n\nTime consuming\nSurrogate can be misguiding\nno parallelization implement yet",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "007_spot_intro.html#sampling-in-spotpython",
    "href": "007_spot_intro.html#sampling-in-spotpython",
    "title": "11  Introduction to Sequential Parameter Optimization",
    "section": "12.3 Sampling in spotpython",
    "text": "12.3 Sampling in spotpython\nspotpython uses a class for generating space-filling designs using Latin Hypercube Sampling (LHS) and maximin distance criteria. It is based on scipy’s LatinHypercube class. The following example demonstrates how to generate a Latin Hypercube Sampling design using spotpython. The result is shown in Figure 12.1. As can seen in the figure, a Latin hypercube sample generates \\(n\\) points in \\([0,1)^{d}\\). Each univariate marginal distribution is stratified, placing exactly one point in \\([j/n, (j+1)/n)\\) for \\(j=0,1,...,n-1\\).\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom spotpython.design.spacefilling import SpaceFilling\nlhd = SpaceFilling(k=2, seed=123)\nX = lhd.scipy_lhd(n=10, repeats=1, lower=np.array([0, 0]), upper=np.array([10, 10]))\nplt.scatter(X[:, 0], X[:, 1])\nplt.xlabel('x1')\nplt.ylabel('x2')\nplt.grid()\n\n\n\n\n\n\n\nFigure 12.1: Latin Hypercube Sampling design (sampling plan)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "007_spot_intro.html#example-spot-and-the-sphere-function",
    "href": "007_spot_intro.html#example-spot-and-the-sphere-function",
    "title": "11  Introduction to Sequential Parameter Optimization",
    "section": "12.4 Example: Spot and the Sphere Function",
    "text": "12.4 Example: Spot and the Sphere Function\nCentral Idea: Evaluation of the surrogate model S is much cheaper (or / and much faster) than running the real-world experiment \\(f\\). We start with a small example.\n\nimport numpy as np\nfrom math import inf\nfrom spotpython.fun.objectivefunctions import Analytical\nfrom spotpython.utils.init import fun_control_init, design_control_init\nfrom spotpython.hyperparameters.values import set_control_key_value\nfrom spotpython.spot import Spot\nimport matplotlib.pyplot as plt\n\n\n12.4.1 The Objective Function: Sphere\nThe spotpython package provides several classes of objective functions. We will use an analytical objective function, i.e., a function that can be described by a (closed) formula: \\[\nf(x) = x^2\n\\]\n\nfun = Analytical().fun_sphere\n\nWe can apply the function fun to input values and plot the result:\n\nx = np.linspace(-1,1,100).reshape(-1,1)\ny = fun(x)\nplt.figure()\nplt.plot(x, y, \"k\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n12.4.2 The Spot Method as an Optimization Algorithm Using a Surrogate Model\nWe initialize the fun_control dictionary. The fun_control dictionary contains the parameters for the objective function. The fun_control dictionary is passed to the Spot method.\n\nfun_control=fun_control_init(lower = np.array([-1]),\n                     upper = np.array([1]))\nspot_0 = Spot(fun=fun,\n                   fun_control=fun_control)\nspot_0.run()\n\nspotpython tuning: 6.690918515799129e-09 [#######---] 73.33% \nspotpython tuning: 6.719979618922052e-11 [########--] 80.00% \nspotpython tuning: 6.719979618922052e-11 [#########-] 86.67% \nspotpython tuning: 6.719979618922052e-11 [#########-] 93.33% \nspotpython tuning: 6.719979618922052e-11 [##########] 100.00% Done...\n\nExperiment saved to 000_res.pkl\n\n\n&lt;spotpython.spot.spot.Spot at 0x15c5556a0&gt;\n\n\nThe method print_results() prints the results, i.e., the best objective function value (“min y”) and the corresponding input value (“x0”).\n\nspot_0.print_results()\n\nmin y: 6.719979618922052e-11\nx0: 8.197548181573593e-06\n\n\n[['x0', np.float64(8.197548181573593e-06)]]\n\n\nTo plot the search progress, the method plot_progress() can be used. The parameter log_y is used to plot the objective function values on a logarithmic scale.\n\nspot_0.plot_progress(log_y=True)\n\n\n\n\n\n\n\nFigure 12.2: Visualization of the search progress of the Spot method. The black elements (points and line) represent the initial design, before the surrogate is build. The red elements represent the search on the surrogate.\n\n\n\n\n\nIf the dimension of the input space is one, the method plot_model() can be used to visualize the model and the underlying objective function values.\n\nspot_0.plot_model()\n\n\n\n\n\n\n\nFigure 12.3: Visualization of the model and the underlying objective function values.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "007_spot_intro.html#spot-parameters-fun_evals-init_size-and-show_models",
    "href": "007_spot_intro.html#spot-parameters-fun_evals-init_size-and-show_models",
    "title": "11  Introduction to Sequential Parameter Optimization",
    "section": "12.5 Spot Parameters: fun_evals, init_size and show_models",
    "text": "12.5 Spot Parameters: fun_evals, init_size and show_models\nWe will modify three parameters:\n\nThe number of function evaluations (fun_evals) will be set to 10 (instead of 15, which is the default value) in the fun_control dictionary.\nThe parameter show_models, which visualizes the search process for each single iteration for 1-dim functions, in the fun_control dictionary.\nThe size of the initial design (init_size) in the design_control dictionary.\n\nThe full list of the Spot parameters is shown in code reference on GitHub, see Spot.\n\nfun_control=fun_control_init(lower = np.array([-1]),\n                     upper = np.array([1]),\n                     fun_evals = 10,\n                     show_models = True)               \ndesign_control = design_control_init(init_size=9)\nspot_1 = Spot(fun=fun,\n                   fun_control=fun_control,\n                   design_control=design_control)\nspot_1.run()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nspotpython tuning: 9.7097578737121e-06 [##########] 100.00% Done...\n\nExperiment saved to 000_res.pkl",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "007_spot_intro.html#print-the-results-1",
    "href": "007_spot_intro.html#print-the-results-1",
    "title": "11  Introduction to Sequential Parameter Optimization",
    "section": "12.6 Print the Results",
    "text": "12.6 Print the Results\n\nspot_1.print_results()\n\nmin y: 9.7097578737121e-06\nx0: 0.0031160484389226206\n\n\n[['x0', np.float64(0.0031160484389226206)]]",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "007_spot_intro.html#show-the-progress-1",
    "href": "007_spot_intro.html#show-the-progress-1",
    "title": "11  Introduction to Sequential Parameter Optimization",
    "section": "12.7 Show the Progress",
    "text": "12.7 Show the Progress\n\nspot_1.plot_progress()",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "007_spot_intro.html#sec-visualizing-tensorboard-01",
    "href": "007_spot_intro.html#sec-visualizing-tensorboard-01",
    "title": "11  Introduction to Sequential Parameter Optimization",
    "section": "12.8 Visualizing the Optimization and Hyperparameter Tuning Process with TensorBoard",
    "text": "12.8 Visualizing the Optimization and Hyperparameter Tuning Process with TensorBoard\nspotpython supports the visualization of the hyperparameter tuning process with TensorBoard. The following example shows how to use TensorBoard with spotpython.\nFirst, we define an “PREFIX” to identify the hyperparameter tuning process. The PREFIX is used to create a directory for the TensorBoard files.\n\nfun_control = fun_control_init(\n    PREFIX = \"01\",\n    lower = np.array([-1]),\n    upper = np.array([2]),\n    fun_evals=100,\n    TENSORBOARD_CLEAN=True,\n    tensorboard_log=True)\ndesign_control = design_control_init(init_size=5)\n\nMoving TENSORBOARD_PATH: runs/ to TENSORBOARD_PATH_OLD: runs_OLD/runs_2025_06_15_12_27_03_0\nCreated spot_tensorboard_path: runs/spot_logs/01_maans08_2025-06-15_12-27-03 for SummaryWriter()\n\n\nSince the tensorboard_log is True, spotpython will log the optimization process in the TensorBoard files. The argument TENSORBOARD_CLEAN=True will move the TensorBoard files from the previous run to a backup folder, so that TensorBoard files from previous runs are not overwritten and a clean start in the runs folder is guaranteed.\n\nspot_tuner = Spot(fun=fun,                   \n                   fun_control=fun_control,\n                   design_control=design_control)\nspot_tuner.run()\nspot_tuner.print_results()\n\nspotpython tuning: 0.0005401959712392311 [#---------] 6.00% \nspotpython tuning: 0.00017194734221844825 [#---------] 7.00% \nspotpython tuning: 0.00012951639447619488 [#---------] 8.00% \nspotpython tuning: 0.00011593270967604635 [#---------] 9.00% \nspotpython tuning: 8.960832462042882e-05 [#---------] 10.00% \nspotpython tuning: 1.1087652041635331e-05 [#---------] 11.00% \nspotpython tuning: 1.5733042163261654e-06 [#---------] 12.00% \nspotpython tuning: 1.1001891458836728e-08 [#---------] 13.00% \nspotpython tuning: 1.1001891458836728e-08 [#---------] 14.00% \nspotpython tuning: 1.1001891458836728e-08 [##--------] 15.00% \nspotpython tuning: 1.1001891458836728e-08 [##--------] 16.00% \nspotpython tuning: 1.1001891458836728e-08 [##--------] 17.00% \nspotpython tuning: 1.1001891458836728e-08 [##--------] 18.00% \nspotpython tuning: 1.1001891458836728e-08 [##--------] 19.00% \nspotpython tuning: 1.1001891458836728e-08 [##--------] 20.00% \nspotpython tuning: 1.1001891458836728e-08 [##--------] 21.00% \nspotpython tuning: 1.1001891458836728e-08 [##--------] 22.00% \nspotpython tuning: 1.1001891458836728e-08 [##--------] 23.00% \nspotpython tuning: 1.1001891458836728e-08 [##--------] 24.00% \nspotpython tuning: 1.1001891458836728e-08 [##--------] 25.00% \nspotpython tuning: 1.1001891458836728e-08 [###-------] 26.00% \nspotpython tuning: 1.1001891458836728e-08 [###-------] 27.00% \nspotpython tuning: 1.1001891458836728e-08 [###-------] 28.00% \nspotpython tuning: 1.1001891458836728e-08 [###-------] 29.00% \nspotpython tuning: 1.1001891458836728e-08 [###-------] 30.00% \nspotpython tuning: 1.1001891458836728e-08 [###-------] 31.00% \nspotpython tuning: 1.1001891458836728e-08 [###-------] 32.00% \nspotpython tuning: 1.1001891458836728e-08 [###-------] 33.00% \nspotpython tuning: 1.1001891458836728e-08 [###-------] 34.00% \nspotpython tuning: 1.1001891458836728e-08 [####------] 35.00% \nspotpython tuning: 1.1001891458836728e-08 [####------] 36.00% \nspotpython tuning: 1.1001891458836728e-08 [####------] 37.00% \nspotpython tuning: 1.1001891458836728e-08 [####------] 38.00% \nspotpython tuning: 1.1001891458836728e-08 [####------] 39.00% \nspotpython tuning: 1.1001891458836728e-08 [####------] 40.00% \nspotpython tuning: 1.1001891458836728e-08 [####------] 41.00% \nspotpython tuning: 1.1001891458836728e-08 [####------] 42.00% \nspotpython tuning: 1.1001891458836728e-08 [####------] 43.00% \nspotpython tuning: 1.1001891458836728e-08 [####------] 44.00% \nspotpython tuning: 1.1001891458836728e-08 [####------] 45.00% \nspotpython tuning: 1.1001891458836728e-08 [#####-----] 46.00% \nspotpython tuning: 1.1001891458836728e-08 [#####-----] 47.00% \nspotpython tuning: 1.1001891458836728e-08 [#####-----] 48.00% \nspotpython tuning: 1.1001891458836728e-08 [#####-----] 49.00% \nspotpython tuning: 1.1001891458836728e-08 [#####-----] 50.00% \nspotpython tuning: 1.1001891458836728e-08 [#####-----] 51.00% \nspotpython tuning: 1.1001891458836728e-08 [#####-----] 52.00% \nspotpython tuning: 1.1001891458836728e-08 [#####-----] 53.00% \nspotpython tuning: 1.1001891458836728e-08 [#####-----] 54.00% \nspotpython tuning: 1.1001891458836728e-08 [######----] 55.00% \nspotpython tuning: 1.1001891458836728e-08 [######----] 56.00% \nspotpython tuning: 1.1001891458836728e-08 [######----] 57.00% \nspotpython tuning: 1.1001891458836728e-08 [######----] 58.00% \nspotpython tuning: 1.1001891458836728e-08 [######----] 59.00% \nspotpython tuning: 1.1001891458836728e-08 [######----] 60.00% \nspotpython tuning: 1.1001891458836728e-08 [######----] 61.00% \nspotpython tuning: 1.1001891458836728e-08 [######----] 62.00% \nspotpython tuning: 1.1001891458836728e-08 [######----] 63.00% \nspotpython tuning: 1.1001891458836728e-08 [######----] 64.00% \nspotpython tuning: 1.1001891458836728e-08 [######----] 65.00% \nspotpython tuning: 1.1001891458836728e-08 [#######---] 66.00% \nspotpython tuning: 1.1001891458836728e-08 [#######---] 67.00% \nspotpython tuning: 1.1001891458836728e-08 [#######---] 68.00% \nspotpython tuning: 1.1001891458836728e-08 [#######---] 69.00% \nspotpython tuning: 1.1001891458836728e-08 [#######---] 70.00% \nspotpython tuning: 1.1001891458836728e-08 [#######---] 71.00% \nspotpython tuning: 1.1001891458836728e-08 [#######---] 72.00% \nspotpython tuning: 1.1001891458836728e-08 [#######---] 73.00% \nspotpython tuning: 1.1001891458836728e-08 [#######---] 74.00% \nspotpython tuning: 1.1001891458836728e-08 [########--] 75.00% \nspotpython tuning: 1.1001891458836728e-08 [########--] 76.00% \nspotpython tuning: 1.1001891458836728e-08 [########--] 77.00% \nspotpython tuning: 1.1001891458836728e-08 [########--] 78.00% \nspotpython tuning: 1.1001891458836728e-08 [########--] 79.00% \nspotpython tuning: 1.1001891458836728e-08 [########--] 80.00% \nspotpython tuning: 1.1001891458836728e-08 [########--] 81.00% \nspotpython tuning: 1.1001891458836728e-08 [########--] 82.00% \nspotpython tuning: 1.1001891458836728e-08 [########--] 83.00% \nspotpython tuning: 1.1001891458836728e-08 [########--] 84.00% \nspotpython tuning: 1.1001891458836728e-08 [########--] 85.00% \nspotpython tuning: 1.1001891458836728e-08 [#########-] 86.00% \nspotpython tuning: 1.1001891458836728e-08 [#########-] 87.00% \nspotpython tuning: 1.1001891458836728e-08 [#########-] 88.00% \nspotpython tuning: 1.386815256673593e-09 [#########-] 89.00% \nspotpython tuning: 1.386815256673593e-09 [#########-] 90.00% \nspotpython tuning: 1.386815256673593e-09 [#########-] 91.00% \nspotpython tuning: 1.386815256673593e-09 [#########-] 92.00% \nspotpython tuning: 1.386815256673593e-09 [#########-] 93.00% \nspotpython tuning: 1.386815256673593e-09 [#########-] 94.00% \nspotpython tuning: 1.386815256673593e-09 [##########] 95.00% \nspotpython tuning: 1.386815256673593e-09 [##########] 96.00% \nspotpython tuning: 1.386815256673593e-09 [##########] 97.00% \nspotpython tuning: 3.952064321854671e-11 [##########] 98.00% \nspotpython tuning: 3.952064321854671e-11 [##########] 99.00% \nspotpython tuning: 3.952064321854671e-11 [##########] 100.00% Done...\n\nExperiment saved to 01_res.pkl\nmin y: 3.952064321854671e-11\nx0: -6.2865446167625905e-06\n\n\n[['x0', np.float64(-6.2865446167625905e-06)]]\n\n\nNow we can start TensorBoard in the background. The TensorBoard process will read the TensorBoard files and visualize the hyperparameter tuning process. From the terminal, we can start TensorBoard with the following command:\ntensorboard --logdir=\"./runs\"\nlogdir is the directory where the TensorBoard files are stored. In our case, the TensorBoard files are stored in the directory ./runs.\nTensorBoard will start a web server on port 6006. We can access the TensorBoard web server with the following URL:\nhttp://localhost:6006/\nThe first TensorBoard visualization shows the objective function values plotted against the wall time. The wall time is the time that has passed since the start of the hyperparameter tuning process. The five initial design points are shown in the upper left region of the plot. The line visualizes the optimization process. \nThe second TensorBoard visualization shows the input values, i.e., \\(x_0\\), plotted against the wall time. \nThe third TensorBoard plot illustrates how spotpython can be used as a microscope for the internal mechanisms of the surrogate-based optimization process. Here, one important parameter, the learning rate \\(\\theta\\) of the Kriging surrogate is plotted against the number of optimization steps.\n\n\n\nTensorBoard visualization of the spotpython process.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "007_spot_intro.html#jupyter-notebook",
    "href": "007_spot_intro.html#jupyter-notebook",
    "title": "11  Introduction to Sequential Parameter Optimization",
    "section": "12.9 Jupyter Notebook",
    "text": "12.9 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository\n\n\n\n\n\n\n\nBartz-Beielstein, Thomas, and Martina Friese. 2011. “Sequential Parameter Optimization and Optimal Computational Budget Allocation for Noisy Optimization Problems.” Cologne University of Applied Science, Faculty of Computer Science; Engineering Science.\n\n\nChen, Chun Hung. 2010. Stochastic simulation optimization: an optimal computing budget allocation. World Scientific.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Introduction to Sequential Parameter Optimization</span>"
    ]
  },
  {
    "objectID": "008_num_spot_multidim.html",
    "href": "008_num_spot_multidim.html",
    "title": "12  Multi-dimensional Functions",
    "section": "",
    "text": "12.1 The Objective Function: 3-dim Sphere\nThis chapter illustrates how high-dimensional functions can be optimized and analyzed. For reasons of illustration, we will use the three-dimensional Sphere function, which is a simple and well-known function. The problem dimension is \\(k=3\\), but can be easily adapted to other, higher dimensions.\nThe spotpython package provides several classes of objective functions. We will use an analytical objective function, i.e., a function that can be described by a (closed) formula: \\[\nf(x) = \\sum_i^k x_i^2.\n\\]\nThe Sphere function is continuous, convex and unimodal. The plot shows its two-dimensional form. The global minimum is \\[\nf(x) = 0, \\text{at } x = (0,0, \\ldots, 0).\n\\]\nIt is available as fun_sphere in the Analytical class [SOURCE].\nfun = Analytical().fun_sphere\nHere we will use problem dimension \\(k=3\\), which can be specified by the lower bound arrays. The size of the lower bound array determines the problem dimension. If we select -1.0 * np.ones(3), a three-dimensional function is created.\nIn contrast to the one-dimensional case (Section 12.8), where only one theta value was used, we will use three different theta values (one for each dimension), i.e., we set n_theta=3 in the surrogate_control. As default, spotpython sets the n_theta to the problem dimension. Therefore, the n_theta parameter can be omitted in this case. More specifically, if n_theta is larger than 1 or set to the string “anisotropic”, then the \\(k\\) theta values are used, where \\(k\\) is the problem dimension. The meaning of “anisotropic” is explained in @#sec-iso-aniso-kriging.\nThe prefix is set to \"03\" to distinguish the results from the one-dimensional case. Again, TensorBoard can be used to monitor the progress of the optimization.\nWe can also add interpretable labels to the dimensions, which will be used in the plots. Therefore, we set var_name=[\"Pressure\", \"Temp\", \"Lambda\"] instead of the default var_name=None, which would result in the labels x_0, x_1, and x_2.\nfun_control = fun_control_init(\n              PREFIX=\"03\",\n              lower = -1.0*np.ones(3),\n              upper = np.ones(3),\n              var_name=[\"Pressure\", \"Temp\", \"Lambda\"],\n              TENSORBOARD_CLEAN=True,\n              tensorboard_log=True)\nsurrogate_control = surrogate_control_init(n_theta=3)\nspot_3 = Spot(fun=fun,\n                  fun_control=fun_control,\n                  surrogate_control=surrogate_control)\nspot_3.run()\n\nMoving TENSORBOARD_PATH: runs/ to TENSORBOARD_PATH_OLD: runs_OLD/runs_2025_06_15_12_27_42_0\nCreated spot_tensorboard_path: runs/spot_logs/03_maans08_2025-06-15_12-27-42 for SummaryWriter()\nspotpython tuning: 0.04499639370770697 [#######---] 73.33% \nspotpython tuning: 0.02879181572787603 [########--] 80.00% \nspotpython tuning: 0.0022744029851669532 [#########-] 86.67% \nspotpython tuning: 0.0014897478896309436 [#########-] 93.33% \nspotpython tuning: 0.0012759691122765592 [##########] 100.00% Done...\n\nExperiment saved to 03_res.pkl\n\n\n&lt;spotpython.spot.spot.Spot at 0x10816cc50&gt;",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multi-dimensional Functions</span>"
    ]
  },
  {
    "objectID": "008_num_spot_multidim.html#the-objective-function-3-dim-sphere",
    "href": "008_num_spot_multidim.html#the-objective-function-3-dim-sphere",
    "title": "12  Multi-dimensional Functions",
    "section": "",
    "text": "Note\n\n\n\nNow we can start TensorBoard in the background with the following command:\ntensorboard --logdir=\"./runs\"\nand can access the TensorBoard web server with the following URL:\nhttp://localhost:6006/\n\n\n\n12.1.1 Results\n\n12.1.1.1 Best Objective Function Values\nThe best objective function value and its corresponding input values are printed as follows:\n\n_ = spot_3.print_results()\n\nmin y: 0.0012759691122765592\nPressure: 0.018303752441652287\nTemp: 0.01971734567381022\nLambda: -0.023498256071690607\n\n\nThe method plot_progress() plots current and best found solutions versus the number of iterations as shown in Figure 12.1.\n\nspot_3.plot_progress()\n\n\n\n\n\n\n\nFigure 12.1: Progress of the optimization process for the 3-dim Sphere function. The initial design points are shown in black, whereas the points that were found by the search on the surrogate are plotted in red.\n\n\n\n\n\n\n\n12.1.1.2 A Contour Plot\nWe can select two dimensions, say \\(i=0\\) and \\(j=1\\), and generate a contour plot as follows. Note, we have specified identical min_z and max_z values to generate comparable plots.\n\nspot_3.plot_contour(i=0, j=1, min_z=0, max_z=2.25)\n\n\n\n\n\n\n\n\n\nIn a similar manner, we can plot dimension \\(i=0\\) and \\(j=2\\):\n\n\nspot_3.plot_contour(i=0, j=2, min_z=0, max_z=2.25)\n\n\n\n\n\n\n\n\n\nThe final combination is \\(i=1\\) and \\(j=2\\):\n\n\nspot_3.plot_contour(i=1, j=2, min_z=0, max_z=2.25)\n\n\n\n\n\n\n\n\n\nThe three plots look very similar, because the fun_sphere is symmetric.\nThis can also be seen from the variable importance:\n\n\n_ = spot_3.print_importance()\n\nPressure:  89.07395721056233\nTemp:  100.0\nLambda:  80.2593685337925\n\n\n\nspot_3.plot_importance()\n\n\n\n\n\n\n\n\n\n\n\n12.1.2 TensorBoard\n\n\n\nTensorBoard visualization of the spotpython process. Objective function values plotted against wall time.\n\n\nThe second TensorBoard visualization shows the input values, i.e., \\(x_0, \\ldots, x_2\\), plotted against the wall time. \nThe third TensorBoard plot illustrates how spotpython can be used as a microscope for the internal mechanisms of the surrogate-based optimization process. Here, one important parameter, the learning rate \\(\\theta\\) of the Kriging surrogate is plotted against the number of optimization steps.\n\n\n\nTensorBoard visualization of the spotpython surrogate model.\n\n\n\n\n12.1.3 Conclusion\nBased on this quick analysis, we can conclude that all three dimensions are equally important (as expected, because the Analytical function is known).",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multi-dimensional Functions</span>"
    ]
  },
  {
    "objectID": "008_num_spot_multidim.html#exercises",
    "href": "008_num_spot_multidim.html#exercises",
    "title": "12  Multi-dimensional Functions",
    "section": "12.2 Exercises",
    "text": "12.2 Exercises\n\nExercise 12.1 (The Three Dimensional fun_cubed) The spotpython package provides several classes of objective functions.\nWe will use the fun_cubed in the Analytical class [SOURCE]. The input dimension is 3. The search range is \\(-1 \\leq x \\leq 1\\) for all dimensions.\nTasks: * Generate contour plots * Calculate the variable importance. * Discuss the variable importance: * Are all variables equally important? * If not: * Which is the most important variable? * Which is the least important variable?\n\n\nExercise 12.2 (The Ten Dimensional fun_wing_wt)  \n\nThe input dimension is 10. The search range is \\(0 \\leq x \\leq 1\\) for all dimensions.\nCalculate the variable importance.\nDiscuss the variable importance:\n\nAre all variables equally important?\nIf not:\n\nWhich is the most important variable?\nWhich is the least important variable?\n\nGenerate contour plots for the three most important variables. Do they confirm your selection?\n\n\n\n\nExercise 12.3 (The Three Dimensional fun_runge)  \n\nThe input dimension is 3. The search range is \\(-5 \\leq x \\leq 5\\) for all dimensions.\nGenerate contour plots\nCalculate the variable importance.\nDiscuss the variable importance:\n\nAre all variables equally important?\nIf not:\n\nWhich is the most important variable?\nWhich is the least important variable?\n\n\n\n\n\nExercise 12.4 (The Three Dimensional fun_linear)  \n\nThe input dimension is 3. The search range is \\(-5 \\leq x \\leq 5\\) for all dimensions.\nGenerate contour plots\nCalculate the variable importance.\nDiscuss the variable importance:\n\nAre all variables equally important?\nIf not:\n\nWhich is the most important variable?\nWhich is the least important variable?\n\n\n\n\n\nExercise 12.5 (The Two Dimensional Rosenbrock Function fun_rosen)  \n\nThe input dimension is 2. The search range is \\(-5 \\leq x \\leq 10\\) for all dimensions.\nSee Rosenbrock function and Rosenbrock Function for details.\nGenerate contour plots\nCalculate the variable importance.\nDiscuss the variable importance:\n\nAre all variables equally important?\nIf not:\n\nWhich is the most important variable?\nWhich is the least important variable?",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multi-dimensional Functions</span>"
    ]
  },
  {
    "objectID": "008_num_spot_multidim.html#selected-solutions",
    "href": "008_num_spot_multidim.html#selected-solutions",
    "title": "12  Multi-dimensional Functions",
    "section": "12.3 Selected Solutions",
    "text": "12.3 Selected Solutions\n\nSolution 12.1 (Solution to Exercise 12.1: The Three-dimensional Cubed Function fun_cubed). We instanciate the fun_cubed function from the Analytical class.\n\nfrom spotpython.fun.objectivefunctions import Analytical\nfun_cubed = Analytical().fun_cubed\n\n\nHere we will use problem dimension \\(k=3\\), which can be specified by the lower bound arrays. The size of the lower bound array determines the problem dimension. If we select -1.0 * np.ones(3), a three-dimensional function is created.\nIn contrast to the one-dimensional case, where only one theta value was used, we will use three different theta values (one for each dimension), i.e., we can set n_theta=3 in the surrogate_control. However, this is not necessary, because by default, n_theta is set to the number of dimensions.\nThe prefix is set to \"03\" to distinguish the results from the one-dimensional case.\nWe will set the fun_evals=20 to limit the number of function evaluations to 20 for this example.\nThe size of the initial design is set to 10 by default. It can be changed by setting init_size=10 via design_control_init in the design_control dictionary.\nAgain, TensorBoard can be used to monitor the progress of the optimization.\nWe can also add interpretable labels to the dimensions, which will be used in the plots. Therefore, we set var_name=[\"Pressure\", \"Temp\", \"Lambda\"] instead of the default var_name=None, which would result in the labels x_0, x_1, and x_2.\n\nHere is the link to the documentation of the fun_control_init function: [DOC]. The documentation of the design_control_init function can be found here: [DOC].\nThe setup can be done as follows:\n\nfun_control = fun_control_init(\n              PREFIX=\"cubed\",\n              fun_evals=20,\n              lower = -1.0*np.ones(3),\n              upper = np.ones(3),\n              var_name=[\"Pressure\", \"Temp\", \"Lambda\"],\n              TENSORBOARD_CLEAN=True,\n              tensorboard_log=True\n              )\n\nsurrogate_control = surrogate_control_init(n_theta=3)\ndesign_control = design_control_init(init_size=10)\n\nMoving TENSORBOARD_PATH: runs/ to TENSORBOARD_PATH_OLD: runs_OLD/runs_2025_06_15_12_27_45_0\nCreated spot_tensorboard_path: runs/spot_logs/cubed_maans08_2025-06-15_12-27-45 for SummaryWriter()\n\n\n\nAfter the setup, we can pass the dictionaries to the Spot class and run the optimization process.\n\n\nspot_cubed = Spot(fun=fun_cubed,\n                  fun_control=fun_control,\n                  surrogate_control=surrogate_control)\nspot_cubed.run()\n\nspotpython tuning: -1.4662953667287653 [######----] 55.00% \nspotpython tuning: -1.4662953667287653 [######----] 60.00% \nspotpython tuning: -1.4662953667287653 [######----] 65.00% \nspotpython tuning: -2.1232188292307277 [#######---] 70.00% \nspotpython tuning: -2.1232188292307277 [########--] 75.00% \nspotpython tuning: -2.2387452533097423 [########--] 80.00% \nspotpython tuning: -3.0 [########--] 85.00% \nspotpython tuning: -3.0 [#########-] 90.00% \nspotpython tuning: -3.0 [##########] 95.00% \nspotpython tuning: -3.0 [##########] 100.00% Done...\n\nExperiment saved to cubed_res.pkl\n\n\n&lt;spotpython.spot.spot.Spot at 0x174d06ea0&gt;\n\n\n\nResults\n\n\n_ = spot_cubed.print_results()\n\nmin y: -3.0\nPressure: -1.0\nTemp: -1.0\nLambda: -1.0\n\n\n\nspot_cubed.plot_progress()\n\n\n\n\n\n\n\n\n\nContour Plots\n\nWe can select two dimensions, say \\(i=0\\) and \\(j=1\\), and generate a contour plot as follows.\nWe can specify identical min_z and max_z values to generate comparable plots. The default values are min_z=None and max_z=None, which will be replaced by the minimum and maximum values of the objective function.\n\nmin_z = -3\nmax_z = 1\nspot_cubed.plot_contour(i=0, j=1, min_z=min_z, max_z=max_z)\n\n\n\n\n\n\n\n\n\nIn a similar manner, we can plot dimension \\(i=0\\) and \\(j=2\\):\n\n\nspot_cubed.plot_contour(i=0, j=2, min_z=min_z, max_z=max_z)\n\n\n\n\n\n\n\n\n\nThe final combination is \\(i=1\\) and \\(j=2\\):\n\n\nspot_cubed.plot_contour(i=1, j=2, min_z=min_z, max_z=max_z)\n\n\n\n\n\n\n\n\n\nThe variable importance can be printed and visualized as follows:\n\n\n_ = spot_cubed.print_importance()\n\nPressure:  100.00000000000001\nTemp:  15.132821048272005\nLambda:  5.452153854543634\n\n\n\nspot_cubed.plot_importance()\n\n\n\n\n\n\n\n\n\n\nSolution 12.2 (Solution to Exercise 12.5: The Two-dimensional Rosenbrock Function fun_rosen). \n\nimport numpy as np\nfrom spotpython.fun.objectivefunctions import Analytical\nfrom spotpython.utils.init import fun_control_init, surrogate_control_init\nfrom spotpython.spot import Spot\n\n\nThe Objective Function: 2-dim fun_rosen\n\nThe spotpython package provides several classes of objective functions. We will use the fun_rosen in the Analytical class [SOURCE].\n\nfun_rosen = Analytical().fun_rosen\n\n\nHere we will use problem dimension \\(k=2\\), which can be specified by the lower bound arrays.\nThe size of the lower bound array determines the problem dimension. If we select -5.0 * np.ones(2), a two-dimensional function is created.\nIn contrast to the one-dimensional case, where only one theta value is used, we will use \\(k\\) different theta values (one for each dimension), i.e., we set n_theta=3 in the surrogate_control.\nThe prefix is set to \"ROSEN\".\nAgain, TensorBoard can be used to monitor the progress of the optimization.\n\n\nfun_control = fun_control_init(\n              PREFIX=\"ROSEN\",\n              lower = -5.0*np.ones(2),\n              upper = 10*np.ones(2),\n              fun_evals=25)\nsurrogate_control = surrogate_control_init(n_theta=2)\nspot_rosen = Spot(fun=fun_rosen,\n                  fun_control=fun_control,\n                  surrogate_control=surrogate_control)\nspot_rosen.run()\n\nspotpython tuning: 65.06022753421351 [####------] 44.00% \nspotpython tuning: 1.25687656241917 [#####-----] 48.00% \nspotpython tuning: 1.25687656241917 [#####-----] 52.00% \nspotpython tuning: 1.25687656241917 [######----] 56.00% \nspotpython tuning: 1.25687656241917 [######----] 60.00% \nspotpython tuning: 1.25687656241917 [######----] 64.00% \nspotpython tuning: 1.25687656241917 [#######---] 68.00% \nspotpython tuning: 0.9617179972268041 [#######---] 72.00% \nspotpython tuning: 0.961504528152653 [########--] 76.00% \nspotpython tuning: 0.9608396537747581 [########--] 80.00% \nspotpython tuning: 0.9600173239788774 [########--] 84.00% \nspotpython tuning: 0.9593146019130889 [#########-] 88.00% \nspotpython tuning: 0.958637527629652 [#########-] 92.00% \nspotpython tuning: 0.9578239644646188 [##########] 96.00% \nspotpython tuning: 0.956940169960332 [##########] 100.00% Done...\n\nExperiment saved to ROSEN_res.pkl\n\n\n&lt;spotpython.spot.spot.Spot at 0x175bd1d30&gt;\n\n\nNow we can start TensorBoard in the background with the following command:\ntensorboard --logdir=\"./runs\"\nand can access the TensorBoard web server with the following URL:\nhttp://localhost:6006/\n\nResults\n\n\n_ = spot_rosen.print_results()\n\nmin y: 0.956940169960332\nx0: 0.02384561040687396\nx1: 0.020724946230769436\n\n\n\nspot_rosen.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\nA Contour Plot: We can select two dimensions, say \\(i=0\\) and \\(j=1\\), and generate a contour plot as follows.\nNote: For higher dimensions, it might be useful to have identical min_z and max_z values to generate comparable plots. The default values are min_z=None and max_z=None, which will be replaced by the minimum and maximum values of the objective function.\n\n\nmin_z = None\nmax_z = None\nspot_rosen.plot_contour(i=0, j=1, min_z=min_z, max_z=max_z)\n\n\n\n\n\n\n\n\n\nThe variable importance can be calculated as follows:\n\n\n_ = spot_rosen.print_importance()\n\nx0:  100.0\nx1:  1.413709918826025\n\n\n\nspot_rosen.plot_importance()",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multi-dimensional Functions</span>"
    ]
  },
  {
    "objectID": "008_num_spot_multidim.html#jupyter-notebook",
    "href": "008_num_spot_multidim.html#jupyter-notebook",
    "title": "12  Multi-dimensional Functions",
    "section": "12.4 Jupyter Notebook",
    "text": "12.4 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multi-dimensional Functions</span>"
    ]
  },
  {
    "objectID": "009_num_spot_anisotropic.html",
    "href": "009_num_spot_anisotropic.html",
    "title": "13  Isotropic and Anisotropic Kriging",
    "section": "",
    "text": "13.1 Example: Isotropic Spot Surrogate and the 2-dim Sphere Function\nThis chapter illustrates the difference between isotropic and anisotropic Kriging models. The difference is illustrated with the help of the spotpython package. Isotropic Kriging models use the same theta value for every dimension. Anisotropic Kriging models use different theta values for each dimension.\nimport numpy as np\nfrom math import inf\nfrom spotpython.fun.objectivefunctions import Analytical\nfrom spotpython.spot import Spot\nfrom spotpython.utils.init import fun_control_init, surrogate_control_init\nPREFIX=\"003\"",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Isotropic and Anisotropic Kriging</span>"
    ]
  },
  {
    "objectID": "009_num_spot_anisotropic.html#sec-spot-2d-sphere-iso",
    "href": "009_num_spot_anisotropic.html#sec-spot-2d-sphere-iso",
    "title": "13  Isotropic and Anisotropic Kriging",
    "section": "",
    "text": "13.1.1 The Objective Function: 2-dim Sphere\nThe spotpython package provides several classes of objective functions. We will use an analytical objective function, i.e., a function that can be described by a (closed) formula:\n\\[\nf(x, y) = x^2 + y^2\n\\] The size of the lower bound vector determines the problem dimension. Here we will use np.array([-1, -1]), i.e., a two-dimensional function.\n\nfun = Analytical().fun_sphere\nfun_control = fun_control_init(PREFIX=PREFIX,\n                               lower = np.array([-1, -1]),\n                               upper = np.array([1, 1]))\n\nAlthough the default spot surrogate model is an isotropic Kriging model, we will explicitly set the n_theta parameter to a value of 1, so that the same theta value is used for both dimensions. This is done to illustrate the difference between isotropic and anisotropic Kriging models.\n\nsurrogate_control=surrogate_control_init(n_theta=1)\n\n\nspot_2 = Spot(fun=fun,\n                   fun_control=fun_control,\n                   surrogate_control=surrogate_control)\n\nspot_2.run()\n\nspotpython tuning: 0.0013050614212698486 [#######---] 73.33% \nspotpython tuning: 0.0003479187873901382 [########--] 80.00% \nspotpython tuning: 0.00022767416623665655 [#########-] 86.67% \nspotpython tuning: 0.00020787497784734184 [#########-] 93.33% \nspotpython tuning: 0.00020393508736265477 [##########] 100.00% Done...\n\nExperiment saved to 003_res.pkl\n\n\n&lt;spotpython.spot.spot.Spot at 0x140fabc80&gt;\n\n\n\n\n13.1.2 Results\n\nspot_2.print_results()\n\nmin y: 0.00020393508736265477\nx0: 0.014161858193549292\nx1: 0.0018376234294478113\n\n\n[['x0', np.float64(0.014161858193549292)],\n ['x1', np.float64(0.0018376234294478113)]]\n\n\n\nspot_2.plot_progress(log_y=True)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Isotropic and Anisotropic Kriging</span>"
    ]
  },
  {
    "objectID": "009_num_spot_anisotropic.html#example-with-anisotropic-kriging",
    "href": "009_num_spot_anisotropic.html#example-with-anisotropic-kriging",
    "title": "13  Isotropic and Anisotropic Kriging",
    "section": "13.2 Example With Anisotropic Kriging",
    "text": "13.2 Example With Anisotropic Kriging\nAs described in Section 13.1, the default parameter setting of spotpython’s Kriging surrogate uses the same theta value for every dimension. This is referred to as “using an isotropic kernel”. If different theta values are used for each dimension, then an anisotropic kernel is used. To enable anisotropic models in spotpython, the number of theta values should be larger than one. We can use surrogate_control=surrogate_control_init(n_theta=2) to enable this behavior (2 is the problem dimension).\n\nsurrogate_control = surrogate_control_init(n_theta=2)\nspot_2_anisotropic = Spot(fun=fun,\n                    fun_control=fun_control,\n                    surrogate_control=surrogate_control)\nspot_2_anisotropic.run()\n\nspotpython tuning: 0.0013050614212698486 [#######---] 73.33% \nspotpython tuning: 0.0003479187873901382 [########--] 80.00% \nspotpython tuning: 0.00022767416623665655 [#########-] 86.67% \nspotpython tuning: 0.00020787497784734184 [#########-] 93.33% \nspotpython tuning: 0.00020393508736265477 [##########] 100.00% Done...\n\nExperiment saved to 003_res.pkl\n\n\n&lt;spotpython.spot.spot.Spot at 0x166ec2300&gt;\n\n\nThe search progress of the optimization with the anisotropic model can be visualized:\n\nspot_2_anisotropic.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\nspot_2_anisotropic.print_results()\n\nmin y: 0.00020393508736265477\nx0: 0.014161858193549292\nx1: 0.0018376234294478113\n\n\n[['x0', np.float64(0.014161858193549292)],\n ['x1', np.float64(0.0018376234294478113)]]\n\n\n\nspot_2_anisotropic.surrogate.plot()\n\n\n\n\n\n\n\n\n\n13.2.1 Taking a Look at the theta Values\n\n13.2.1.1 theta Values from the spot Model\nWe can check, whether one or several theta values were used. The theta values from the surrogate can be printed as follows:\n\nspot_2_anisotropic.surrogate.theta\n\narray([-0.40325798, -0.43218074])\n\n\n\nSince the surrogate from the isotropic setting was stored as spot_2, we can also take a look at the theta value from this model:\n\n\nspot_2.surrogate.theta\n\narray([-0.40325798, -0.43218074])\n\n\n\n\n13.2.1.2 TensorBoard\nNow we can start TensorBoard in the background with the following command:\ntensorboard --logdir=\"./runs\"\nWe can access the TensorBoard web server with the following URL:\nhttp://localhost:6006/\nThe TensorBoard plot illustrates how spotpython can be used as a microscope for the internal mechanisms of the surrogate-based optimization process. Here, one important parameter, the learning rate \\(\\theta\\) of the Kriging surrogate is plotted against the number of optimization steps.\n\n\n\nTensorBoard visualization of the spotpython surrogate model.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Isotropic and Anisotropic Kriging</span>"
    ]
  },
  {
    "objectID": "009_num_spot_anisotropic.html#exercises",
    "href": "009_num_spot_anisotropic.html#exercises",
    "title": "13  Isotropic and Anisotropic Kriging",
    "section": "13.3 Exercises",
    "text": "13.3 Exercises\n\n13.3.1 1. The Branin Function fun_branin\n\nDescribe the function.\n\nThe input dimension is 2. The search range is \\(-5 \\leq x_1 \\leq 10\\) and \\(0 \\leq x_2 \\leq 15\\).\n\nCompare the results from spotpython run a) with isotropic and b) anisotropic surrogate models.\nModify the termination criterion: instead of the number of evaluations (which is specified via fun_evals), the time should be used as the termination criterion. This can be done as follows (max_time=1 specifies a run time of one minute):\n\n\nfrom math import inf\nfun_control = fun_control_init(\n              fun_evals=inf,\n              max_time=1)\n\n\n\n13.3.2 2. The Two-dimensional Sin-Cos Function fun_sin_cos\n\nDescribe the function.\n\nThe input dimension is 2. The search range is \\(-2\\pi \\leq x_1 \\leq 2\\pi\\) and \\(-2\\pi \\leq x_2 \\leq 2\\pi\\).\n\nCompare the results from spotpython run a) with isotropic and b) anisotropic surrogate models.\nModify the termination criterion (max_time instead of fun_evals) as described for fun_branin.\n\n\n\n13.3.3 3. The Two-dimensional Runge Function fun_runge\n\nDescribe the function.\n\nThe input dimension is 2. The search range is \\(-5 \\leq x_1 \\leq 5\\) and \\(-5 \\leq x_2 \\leq 5\\).\n\nCompare the results from spotpython run a) with isotropic and b) anisotropic surrogate models.\nModify the termination criterion (max_time instead of fun_evals) as described for fun_branin.\n\n\n\n13.3.4 4. The Ten-dimensional Wing-Weight Function fun_wingwt\n\nDescribe the function.\n\nThe input dimension is 10. The search ranges are between 0 and 1 (values are mapped internally to their natural bounds).\n\nCompare the results from spotpython run a) with isotropic and b) anisotropic surrogate models.\nModify the termination criterion (max_time instead of fun_evals) as described for fun_branin.\n\n\n\n13.3.5 5. The Two-dimensional Rosenbrock Function fun_rosen\n\nDescribe the function.\n\nThe input dimension is 2. The search ranges are between -5 and 10.\n\nCompare the results from spotpython run a) with isotropic and b) anisotropic surrogate models.\nModify the termination criterion (max_time instead of fun_evals) as described for fun_branin.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Isotropic and Anisotropic Kriging</span>"
    ]
  },
  {
    "objectID": "009_num_spot_anisotropic.html#selected-solutions",
    "href": "009_num_spot_anisotropic.html#selected-solutions",
    "title": "13  Isotropic and Anisotropic Kriging",
    "section": "13.4 Selected Solutions",
    "text": "13.4 Selected Solutions\n\n13.4.1 Solution to Exercise Section 13.3.5: The Two-dimensional Rosenbrock Function fun_rosen\n\n13.4.1.1 The Two Dimensional fun_rosen: The Isotropic Case\n\nimport numpy as np\nfrom spotpython.fun.objectivefunctions import Analytical\nfrom spotpython.utils.init import fun_control_init, surrogate_control_init\nfrom spotpython.spot import Spot\n\nThe spotpython package provides several classes of objective functions. We will use the fun_rosen in the analytical class [SOURCE].\n\nfun_rosen = Analytical().fun_rosen\n\nHere we will use problem dimension \\(k=2\\), which can be specified by the lower bound arrays. The size of the lower bound array determines the problem dimension.\nThe prefix is set to \"ROSEN\" to distinguish the results from the one-dimensional case. Again, TensorBoard can be used to monitor the progress of the optimization.\n\nfun_control = fun_control_init(\n              PREFIX=\"ROSEN\",\n              lower = np.array([-5, -5]),\n              upper = np.array([10, 10]),\n              show_progress=True)\nsurrogate_control = surrogate_control_init(n_theta=1)\nspot_rosen = Spot(fun=fun_rosen,\n                  fun_control=fun_control,\n                  surrogate_control=surrogate_control)\nspot_rosen.run()\n\nspotpython tuning: 65.06022753421351 [#######---] 73.33% \nspotpython tuning: 1.25687656241917 [########--] 80.00% \nspotpython tuning: 1.25687656241917 [#########-] 86.67% \nspotpython tuning: 1.25687656241917 [#########-] 93.33% \nspotpython tuning: 1.25687656241917 [##########] 100.00% Done...\n\nExperiment saved to ROSEN_res.pkl\n\n\n&lt;spotpython.spot.spot.Spot at 0x169edd340&gt;\n\n\n\n\n\n\n\n\nNote\n\n\n\nNow we can start TensorBoard in the background with the following command:\ntensorboard --logdir=\"./runs\"\nand can access the TensorBoard web server with the following URL:\nhttp://localhost:6006/\n\n\n\n13.4.1.1.1 Results\n\n_ = spot_rosen.print_results()\n\nmin y: 1.25687656241917\nx0: 0.056952323626011235\nx1: -0.18846914563710274\n\n\n\nspot_rosen.plot_progress()\n\n\n\n\n\n\n\n\n\n\n13.4.1.1.2 A Contour Plot\nWe can select two dimensions, say \\(i=0\\) and \\(j=1\\), and generate a contour plot as follows.\n\nmin_z = None\nmax_z = None\nspot_rosen.plot_contour(i=0, j=1, min_z=min_z, max_z=max_z)\n\n\n\n\n\n\n\n\n\nThe variable importance cannot be calculated, because only one theta value was used.\n\n\n\n13.4.1.1.3 TensorBoard\nTBD\n\n\n\n13.4.1.2 The Two Dimensional fun_rosen: The Anisotropic Case\n\nimport numpy as np\nfrom spotpython.fun.objectivefunctions import Analytical\nfrom spotpython.utils.init import fun_control_init, surrogate_control_init\nfrom spotpython.spot import Spot\n\nThe spotpython package provides several classes of objective functions. We will use the fun_rosen in the analytical class [SOURCE].\n\nfun_rosen = Analytical().fun_rosen\n\nHere we will use problem dimension \\(k=2\\), which can be specified by the lower bound arrays. The size of the lower bound array determines the problem dimension.\nWe can also add interpreable labels to the dimensions, which will be used in the plots.\n\nfun_control = fun_control_init(\n              PREFIX=\"ROSEN\",\n              lower = np.array([-5, -5]),\n              upper = np.array([10, 10]),\n              show_progress=True)\nsurrogate_control = surrogate_control_init(n_theta=2)\nspot_rosen = Spot(fun=fun_rosen,\n                  fun_control=fun_control,\n                  surrogate_control=surrogate_control)\nspot_rosen.run()\n\nspotpython tuning: 65.06022753421351 [#######---] 73.33% \nspotpython tuning: 1.25687656241917 [########--] 80.00% \nspotpython tuning: 1.25687656241917 [#########-] 86.67% \nspotpython tuning: 1.25687656241917 [#########-] 93.33% \nspotpython tuning: 1.25687656241917 [##########] 100.00% Done...\n\nExperiment saved to ROSEN_res.pkl\n\n\n&lt;spotpython.spot.spot.Spot at 0x16a2641a0&gt;\n\n\n\n\n\n\n\n\nNote\n\n\n\nNow we can start TensorBoard in the background with the following command:\ntensorboard --logdir=\"./runs\"\nand can access the TensorBoard web server with the following URL:\nhttp://localhost:6006/\n\n\n\n13.4.1.2.1 Results\n\n_ = spot_rosen.print_results()\n\nmin y: 1.25687656241917\nx0: 0.056952323626011235\nx1: -0.18846914563710274\n\n\n\nspot_rosen.plot_progress()\n\n\n\n\n\n\n\n\n\n\n13.4.1.2.2 A Contour Plot\nWe can select two dimensions, say \\(i=0\\) and \\(j=1\\), and generate a contour plot as follows.\n\nmin_z = None\nmax_z = None\nspot_rosen.plot_contour(i=0, j=1, min_z=min_z, max_z=max_z)\n\n\n\n\n\n\n\n\n\nThe variable importance can be calculated as follows:\n\n\n_ = spot_rosen.print_importance()\n\nx0:  100.0\nx1:  1.98917702191357\n\n\n\nspot_rosen.plot_importance()\n\n\n\n\n\n\n\n\n\n\n13.4.1.2.3 TensorBoard\nTBD",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Isotropic and Anisotropic Kriging</span>"
    ]
  },
  {
    "objectID": "009_num_spot_anisotropic.html#jupyter-notebook",
    "href": "009_num_spot_anisotropic.html#jupyter-notebook",
    "title": "13  Isotropic and Anisotropic Kriging",
    "section": "13.5 Jupyter Notebook",
    "text": "13.5 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Isotropic and Anisotropic Kriging</span>"
    ]
  },
  {
    "objectID": "004_spot_sklearn_optimization.html",
    "href": "004_spot_sklearn_optimization.html",
    "title": "14  Sequential Parameter Optimization: Using scipy Optimizers",
    "section": "",
    "text": "14.1 The Objective Function Branin\nAs a default optimizer, spotpython uses differential_evolution from the scipy.optimize package. Alternatively, any other optimizer from the scipy.optimize package can be used. This chapter describes how different optimizers from the scipy optimize package can be used on the surrogate. The optimization algorithms are available from https://docs.scipy.org/doc/scipy/reference/optimize.html\nThe spotpython package provides several classes of objective functions. We will use an analytical objective function, i.e., a function that can be described by a (closed) formula. Here we will use the Branin function. The 2-dim Branin function is \\[\ny = a  (x_2 - b  x_1^2 + c  x_1 - r) ^2 + s  (1 - t)  \\cos(x_1) + s,\n\\] where values of \\(a\\), \\(b\\), \\(c\\), \\(r\\), \\(s\\) and \\(t\\) are: \\(a = 1\\), \\(b = 5.1 / (4\\pi^2)\\), \\(c = 5 / \\pi\\), \\(r = 6\\), \\(s = 10\\) and \\(t = 1 / (8\\pi)\\).\nIt has three global minima: \\(f(x) = 0.397887\\) at \\((-\\pi, 12.275)\\), \\((\\pi, 2.275)\\), and \\((9.42478, 2.475)\\).\nInput Domain: This function is usually evaluated on the square \\(x_1 \\in  [-5, 10] \\times x_2 \\in  [0, 15]\\).\nfrom spotpython.fun.objectivefunctions import Analytical\nlower = np.array([-5,-0])\nupper = np.array([10,15])\nfun = Analytical(seed=123).fun_branin",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Sequential Parameter Optimization: Using `scipy` Optimizers</span>"
    ]
  },
  {
    "objectID": "004_spot_sklearn_optimization.html#sec-optimizer",
    "href": "004_spot_sklearn_optimization.html#sec-optimizer",
    "title": "14  Sequential Parameter Optimization: Using scipy Optimizers",
    "section": "14.2 The Optimizer",
    "text": "14.2 The Optimizer\nDifferential Evolution (DE) from the scikit.optimize package, see https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.differential_evolution.html#scipy.optimize.differential_evolution is the default optimizer for the search on the surrogate. Other optimiers that are available in spotpython, see https://docs.scipy.org/doc/scipy/reference/optimize.html#global-optimization.\n\ndual_annealing\ndirect\nshgo\nbasinhopping\n\nThese optimizers can be selected as follows:\n\nfrom scipy.optimize import differential_evolution\noptimizer = differential_evolution\n\nAs noted above, we will use differential_evolution. The optimizer can use 1000 evaluations. This value will be passed to the differential_evolution method, which has the argument maxiter (int). It defines the maximum number of generations over which the entire differential evolution population is evolved, see https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.differential_evolution.html#scipy.optimize.differential_evolution\n\n\n\n\n\n\nTensorBoard\n\n\n\nSimilar to the one-dimensional case, which is discussed in Section 12.8, we can use TensorBoard to monitor the progress of the optimization. We will use a similar code, only the prefix is different:\n\nfun_control=fun_control_init(\n                    lower = lower,\n                    upper = upper,\n                    fun_evals = 20,\n                    PREFIX = \"04_DE_\"\n                    )\nsurrogate_control=surrogate_control_init(\n                    n_theta=len(lower))\n\n\n\n\nspot_de = Spot(fun=fun,\n                    fun_control=fun_control,\n                    surrogate_control=surrogate_control)\nspot_de.run()\n\nspotpython tuning: 3.6961557165023953 [######----] 55.00% \nspotpython tuning: 3.483508988983779 [######----] 60.00% \nspotpython tuning: 3.0409502575998015 [######----] 65.00% \nspotpython tuning: 2.456350051306707 [#######---] 70.00% \nspotpython tuning: 2.4047922291552375 [########--] 75.00% \nspotpython tuning: 2.3739197901896123 [########--] 80.00% \nspotpython tuning: 2.355976671386384 [########--] 85.00% \nspotpython tuning: 2.348822784282971 [#########-] 90.00% \nspotpython tuning: 2.348822784282971 [##########] 95.00% \nspotpython tuning: 2.348822784282971 [##########] 100.00% Done...\n\nExperiment saved to 04_DE__res.pkl\n\n\n&lt;spotpython.spot.spot.Spot at 0x107dd8320&gt;\n\n\n\n14.2.1 TensorBoard\nIf the prefix argument in fun_control_init()is not None (as above, where the prefix was set to 04_DE_) , we can start TensorBoard in the background with the following command:\ntensorboard --logdir=\"./runs\"\nWe can access the TensorBoard web server with the following URL:\nhttp://localhost:6006/\nThe TensorBoard plot illustrates how spotpython can be used as a microscope for the internal mechanisms of the surrogate-based optimization process. Here, one important parameter, the learning rate \\(\\theta\\) of the Kriging surrogate is plotted against the number of optimization steps.\n\n\n\nTensorBoard visualization of the spotpython optimization process and the surrogate model.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Sequential Parameter Optimization: Using `scipy` Optimizers</span>"
    ]
  },
  {
    "objectID": "004_spot_sklearn_optimization.html#print-the-results",
    "href": "004_spot_sklearn_optimization.html#print-the-results",
    "title": "14  Sequential Parameter Optimization: Using scipy Optimizers",
    "section": "14.3 Print the Results",
    "text": "14.3 Print the Results\n\nspot_de.print_results()\n\nmin y: 2.348822784282971\nx0: 3.1733035041022477\nx1: 3.645429652665629\n\n\n[['x0', np.float64(3.1733035041022477)], ['x1', np.float64(3.645429652665629)]]",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Sequential Parameter Optimization: Using `scipy` Optimizers</span>"
    ]
  },
  {
    "objectID": "004_spot_sklearn_optimization.html#show-the-progress",
    "href": "004_spot_sklearn_optimization.html#show-the-progress",
    "title": "14  Sequential Parameter Optimization: Using scipy Optimizers",
    "section": "14.4 Show the Progress",
    "text": "14.4 Show the Progress\n\nspot_de.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\nspot_de.surrogate.plot()",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Sequential Parameter Optimization: Using `scipy` Optimizers</span>"
    ]
  },
  {
    "objectID": "004_spot_sklearn_optimization.html#exercises",
    "href": "004_spot_sklearn_optimization.html#exercises",
    "title": "14  Sequential Parameter Optimization: Using scipy Optimizers",
    "section": "14.5 Exercises",
    "text": "14.5 Exercises\n\n14.5.1 dual_annealing\n\nDescribe the optimization algorithm, see scipy.optimize.dual_annealing.\nUse the algorithm as an optimizer on the surrogate.\n\n\n\n\n\n\n\nTip: Selecting the Optimizer for the Surrogate\n\n\n\nWe can run spotpython with the dual_annealing optimizer as follows:\n\nspot_da = Spot(fun=fun,\n                    fun_control=fun_control,\n                    optimizer=dual_annealing,\n                    surrogate_control=surrogate_control)\nspot_da.run()\nspot_da.print_results()\nspot_da.plot_progress(log_y=True)\nspot_da.surrogate.plot()\n\nspotpython tuning: 3.696151364195096 [######----] 55.00% \nspotpython tuning: 3.483508760948294 [######----] 60.00% \nspotpython tuning: 3.0403979799851646 [######----] 65.00% \nspotpython tuning: 2.456351950973671 [#######---] 70.00% \nspotpython tuning: 2.4046755988763344 [########--] 75.00% \nspotpython tuning: 2.3764453024469283 [########--] 80.00% \nspotpython tuning: 2.362272749066122 [########--] 85.00% \nspotpython tuning: 2.361636390960074 [#########-] 90.00% \nspotpython tuning: 2.361636390960074 [##########] 95.00% \nspotpython tuning: 2.361636390960074 [##########] 100.00% Done...\n\nExperiment saved to 04_DE__res.pkl\nmin y: 2.361636390960074\nx0: 3.1767738440354223\nx1: 3.646940192088105\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n14.5.2 direct\n\nDescribe the optimization algorithm\nUse the algorithm as an optimizer on the surrogate\n\n\n\n\n\n\n\nTip: Selecting the Optimizer for the Surrogate\n\n\n\nWe can run spotpython with the direct optimizer as follows:\n\nspot_di = Spot(fun=fun,\n                    fun_control=fun_control,\n                    optimizer=direct,\n                    surrogate_control=surrogate_control)\nspot_di.run()\nspot_di.print_results()\nspot_di.plot_progress(log_y=True)\nspot_di.surrogate.plot()\n\nspotpython tuning: 3.676976757805569 [######----] 55.00% \nspotpython tuning: 3.475991674101529 [######----] 60.00% \nspotpython tuning: 2.868437104503963 [######----] 65.00% \nspotpython tuning: 2.472089897497276 [#######---] 70.00% \nspotpython tuning: 2.3608759795941676 [########--] 75.00% \nspotpython tuning: 2.3020349459926672 [########--] 80.00% \nspotpython tuning: 2.2514916165157715 [########--] 85.00% \nspotpython tuning: 2.189644482495839 [#########-] 90.00% \nspotpython tuning: 2.04625864428877 [##########] 95.00% \nspotpython tuning: 1.642088997537579 [##########] 100.00% Done...\n\nExperiment saved to 04_DE__res.pkl\nmin y: 1.642088997537579\nx0: 3.076131687242797\nx1: 3.4327846364883405\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n14.5.3 shgo\n\nDescribe the optimization algorithm\nUse the algorithm as an optimizer on the surrogate\n\n\n\n\n\n\n\nTip: Selecting the Optimizer for the Surrogate\n\n\n\nWe can run spotpython with the direct optimizer as follows:\n\nspot_sh = Spot(fun=fun,\n                    fun_control=fun_control,\n                    optimizer=shgo,\n                    surrogate_control=surrogate_control)\nspot_sh.run()\nspot_sh.print_results()\nspot_sh.plot_progress(log_y=True)\nspot_sh.surrogate.plot()\n\nspotpython tuning: 3.696158422862448 [######----] 55.00% \nspotpython tuning: 3.48351065347906 [######----] 60.00% \nspotpython tuning: 3.040368769129441 [######----] 65.00% \nspotpython tuning: 2.4564036280645185 [#######---] 70.00% \nspotpython tuning: 2.4047133036821 [########--] 75.00% \nspotpython tuning: 2.3763717663570914 [########--] 80.00% \nspotpython tuning: 2.3621941253656855 [########--] 85.00% \nspotpython tuning: 2.361459710666984 [#########-] 90.00% \nspotpython tuning: 2.361459710666984 [##########] 95.00% \nspotpython tuning: 2.361459710666984 [##########] 100.00% Done...\n\nExperiment saved to 04_DE__res.pkl\nmin y: 2.361459710666984\nx0: 3.176699445547513\nx1: 3.6469433701030436\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n14.5.4 basinhopping\n\nDescribe the optimization algorithm\nUse the algorithm as an optimizer on the surrogate\n\n\n\n\n\n\n\nTip: Selecting the Optimizer for the Surrogate\n\n\n\nWe can run spotpython with the direct optimizer as follows:\n\nspot_bh = Spot(fun=fun,\n                    fun_control=fun_control,\n                    optimizer=basinhopping,\n                    surrogate_control=surrogate_control)\nspot_bh.run()\nspot_bh.print_results()\nspot_bh.plot_progress(log_y=True)\nspot_bh.surrogate.plot()\n\nspotpython tuning: 3.696197709339935 [######----] 55.00% \nspotpython tuning: 3.4835593225124644 [######----] 60.00% \nspotpython tuning: 3.0395966545106026 [######----] 65.00% \nspotpython tuning: 2.4563675121684057 [#######---] 70.00% \nspotpython tuning: 2.404442684372791 [########--] 75.00% \nspotpython tuning: 2.3759612272708743 [########--] 80.00% \nspotpython tuning: 2.361506968913666 [########--] 85.00% \nspotpython tuning: 2.3604186560858285 [#########-] 90.00% \nspotpython tuning: 2.3604186560858285 [##########] 95.00% \nspotpython tuning: 2.3604186560858285 [##########] 100.00% Done...\n\nExperiment saved to 04_DE__res.pkl\nmin y: 2.3604186560858285\nx0: 3.1764625539229465\nx1: 3.646782335781278\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n14.5.5 Performance Comparison\nCompare the performance and run time of the 5 different optimizers:\n\ndifferential_evolution\ndual_annealing\ndirect\nshgo\nbasinhopping.\n\nThe Branin function has three global minima:\n\n\\(f(x) = 0.397887\\) at\n\n\\((-\\pi, 12.275)\\),\n\\((\\pi, 2.275)\\), and\n\\((9.42478, 2.475)\\).\n\n\nWhich optima are found by the optimizers?\nDoes the seed argument in fun = Analytical(seed=123).fun_branin change this behavior?",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Sequential Parameter Optimization: Using `scipy` Optimizers</span>"
    ]
  },
  {
    "objectID": "004_spot_sklearn_optimization.html#jupyter-notebook",
    "href": "004_spot_sklearn_optimization.html#jupyter-notebook",
    "title": "14  Sequential Parameter Optimization: Using scipy Optimizers",
    "section": "14.6 Jupyter Notebook",
    "text": "14.6 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this chapter is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Sequential Parameter Optimization: Using `scipy` Optimizers</span>"
    ]
  },
  {
    "objectID": "010_num_spot_sklearn_surrogate.html",
    "href": "010_num_spot_sklearn_surrogate.html",
    "title": "15  Using sklearn Surrogates in spotpython",
    "section": "",
    "text": "15.1 Example: Branin Function with spotpython’s Internal Kriging Surrogate\nBesides the internal kriging surrogate, which is used as a default by spotpython, any surrogate model from scikit-learn can be used as a surrogate in spotpython. This chapter explains how to use scikit-learn surrogates in spotpython.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Using `sklearn` Surrogates in `spotpython`</span>"
    ]
  },
  {
    "objectID": "010_num_spot_sklearn_surrogate.html#example-branin-function-with-spotpythons-internal-kriging-surrogate",
    "href": "010_num_spot_sklearn_surrogate.html#example-branin-function-with-spotpythons-internal-kriging-surrogate",
    "title": "15  Using sklearn Surrogates in spotpython",
    "section": "",
    "text": "15.1.1 The Objective Function Branin\n\nThe spotpython package provides several classes of objective functions.\nWe will use an analytical objective function, i.e., a function that can be described by a (closed) formula.\nHere we will use the Branin function:\n  y = a * (x2 - b * x1**2 + c * x1 - r) ** 2 + s * (1 - t) * np.cos(x1) + s,\n  where values of a, b, c, r, s and t are: a = 1, b = 5.1 / (4*pi**2),\n  c = 5 / pi, r = 6, s = 10 and t = 1 / (8*pi).\nIt has three global minima:\n  f(x) = 0.397887 at (-pi, 12.275), (pi, 2.275), and (9.42478, 2.475).\n\n\nfrom spotpython.fun.objectivefunctions import Analytical\nfun = Analytical().fun_branin\n\n\n\n\n\n\n\nTensorBoard\n\n\n\nSimilar to the one-dimensional case, which was introduced in Section Section 12.8, we can use TensorBoard to monitor the progress of the optimization. We will use the same code, only the prefix is different:\n\nfrom spotpython.utils.init import fun_control_init, design_control_init\nPREFIX = \"04\"\nfun_control = fun_control_init(\n    PREFIX=PREFIX,\n    lower = np.array([-5,-0]),\n    upper = np.array([10,15]),\n    fun_evals=20,\n    max_time=inf)\n\ndesign_control = design_control_init(\n    init_size=10)\n\n\n\n\n\n15.1.2 Running the surrogate model based optimizer Spot:\n\nspot_2 = Spot(fun=fun,\n                   fun_control=fun_control,\n                   design_control=design_control)\n\n\nspot_2.run()\n\nspotpython tuning: 3.6961557165023953 [######----] 55.00% \nspotpython tuning: 3.483508988983779 [######----] 60.00% \nspotpython tuning: 3.0409502575998015 [######----] 65.00% \nspotpython tuning: 2.456350051306707 [#######---] 70.00% \nspotpython tuning: 2.4047922291552375 [########--] 75.00% \nspotpython tuning: 2.3739197901896123 [########--] 80.00% \nspotpython tuning: 2.355976671386384 [########--] 85.00% \nspotpython tuning: 2.348822784282971 [#########-] 90.00% \nspotpython tuning: 2.348822784282971 [##########] 95.00% \nspotpython tuning: 2.348822784282971 [##########] 100.00% Done...\n\nExperiment saved to 04_res.pkl\n\n\n&lt;spotpython.spot.spot.Spot at 0x1501be600&gt;\n\n\n\n\n15.1.3 TensorBoard\nNow we can start TensorBoard in the background with the following command:\ntensorboard --logdir=\"./runs\"\nWe can access the TensorBoard web server with the following URL:\nhttp://localhost:6006/\nThe TensorBoard plot illustrates how spotpython can be used as a microscope for the internal mechanisms of the surrogate-based optimization process. Here, one important parameter, the learning rate \\(\\theta\\) of the Kriging surrogate is plotted against the number of optimization steps.\n\n\n\nTensorBoard visualization of the spotpython optimization process and the surrogate model.\n\n\n\n\n15.1.4 Print the Results\n\nspot_2.print_results()\n\nmin y: 2.348822784282971\nx0: 3.1733035041022477\nx1: 3.645429652665629\n\n\n[['x0', np.float64(3.1733035041022477)], ['x1', np.float64(3.645429652665629)]]\n\n\n\n\n15.1.5 Show the Progress and the Surrogate\n\nspot_2.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\nspot_2.surrogate.plot()",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Using `sklearn` Surrogates in `spotpython`</span>"
    ]
  },
  {
    "objectID": "010_num_spot_sklearn_surrogate.html#example-using-surrogates-from-scikit-learn",
    "href": "010_num_spot_sklearn_surrogate.html#example-using-surrogates-from-scikit-learn",
    "title": "15  Using sklearn Surrogates in spotpython",
    "section": "15.2 Example: Using Surrogates From scikit-learn",
    "text": "15.2 Example: Using Surrogates From scikit-learn\n\nDefault is the spotpython (i.e., the internal) kriging surrogate.\nIt can be called explicitely and passed to Spot.\n\n\nfrom spotpython.surrogate.kriging import Kriging\nS_0 = Kriging(name='kriging', seed=123)\n\n\nAlternatively, models from scikit-learn can be selected, e.g., Gaussian Process, RBFs, Regression Trees, etc.\n\n\n# Needed for the sklearn surrogates:\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn import linear_model\nfrom sklearn import tree\nimport pandas as pd\n\n\nHere are some additional models that might be useful later:\n\n\nS_Tree = DecisionTreeRegressor(random_state=0)\nS_LM = linear_model.LinearRegression()\nS_Ridge = linear_model.Ridge()\nS_RF = RandomForestRegressor(max_depth=2, random_state=0)\n\n\n15.2.1 GaussianProcessRegressor as a Surrogate\n\nTo use a Gaussian Process model from sklearn, that is similar to spotpython’s Kriging, we can proceed as follows:\n\n\nkernel = 1 * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2))\nS_GP = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\n\n\nThe scikit-learn GP model S_GP is selected for Spot as follows:\nsurrogate = S_GP\nWe can check the kind of surogate model with the command isinstance:\n\n\nisinstance(S_GP, GaussianProcessRegressor) \n\nTrue\n\n\n\nisinstance(S_0, Kriging)\n\nTrue\n\n\n\nSimilar to the Spot run with the internal Kriging model, we can call the run with the scikit-learn surrogate:\n\n\nfun = Analytical(seed=123).fun_branin\nspot_2_GP = Spot(fun=fun,\n                     fun_control=fun_control,\n                     design_control=design_control,\n                     surrogate = S_GP)\nspot_2_GP.run()\n\nspotpython tuning: 18.865129821249617 [######----] 55.00% \nspotpython tuning: 4.066961682805861 [######----] 60.00% \nspotpython tuning: 3.4619112320780285 [######----] 65.00% \nspotpython tuning: 3.4619112320780285 [#######---] 70.00% \nspotpython tuning: 1.3283123221495199 [########--] 75.00% \nspotpython tuning: 0.9548698218896146 [########--] 80.00% \nspotpython tuning: 0.9356616728510581 [########--] 85.00% \nspotpython tuning: 0.39968125707661706 [#########-] 90.00% \nspotpython tuning: 0.3983050744842078 [##########] 95.00% \n\n\nspotpython tuning: 0.39821610604643354 [##########] 100.00% Done...\n\nExperiment saved to 04_res.pkl\n\n\n&lt;spotpython.spot.spot.Spot at 0x151b4eff0&gt;\n\n\n\nspot_2_GP.plot_progress()\n\n\n\n\n\n\n\n\n\nspot_2_GP.print_results()\n\nmin y: 0.39821610604643354\nx0: 3.1496411777654334\nx1: 2.272943969041002\n\n\n[['x0', np.float64(3.1496411777654334)], ['x1', np.float64(2.272943969041002)]]",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Using `sklearn` Surrogates in `spotpython`</span>"
    ]
  },
  {
    "objectID": "010_num_spot_sklearn_surrogate.html#example-one-dimensional-sphere-function-with-spotpythons-kriging",
    "href": "010_num_spot_sklearn_surrogate.html#example-one-dimensional-sphere-function-with-spotpythons-kriging",
    "title": "15  Using sklearn Surrogates in spotpython",
    "section": "15.3 Example: One-dimensional Sphere Function With spotpython’s Kriging",
    "text": "15.3 Example: One-dimensional Sphere Function With spotpython’s Kriging\n\nIn this example, we will use an one-dimensional function, which allows us to visualize the optimization process.\n\nshow_models= True is added to the argument list.\n\n\n\nfrom spotpython.fun.objectivefunctions import Analytical\nfun_control = fun_control_init(\n    lower = np.array([-1]),\n    upper = np.array([1]),\n    fun_evals=10,\n    max_time=inf,\n    show_models= True,\n    tolerance_x = np.sqrt(np.spacing(1)))\nfun = Analytical(seed=123).fun_sphere\ndesign_control = design_control_init(\n    init_size=3)\n\n\nspot_1 = Spot(fun=fun,\n                    fun_control=fun_control,\n                    design_control=design_control)\nspot_1.run()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.03475485848264724 [####------] 40.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.03475485848264724 [#####-----] 50.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.03475481964033922 [######----] 60.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.03475479804192463 [#######---] 70.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.03475446167786181 [########--] 80.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.03474447900832713 [#########-] 90.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.034515878522411086 [##########] 100.00% Done...\n\nExperiment saved to 000_res.pkl\n\n\n\n15.3.1 Results\n\nspot_1.print_results()\n\nmin y: 0.034515878522411086\nx0: 0.1857844948385389\n\n\n[['x0', np.float64(0.1857844948385389)]]\n\n\n\nspot_1.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\nThe method plot_model plots the final surrogate:\n\n\nspot_1.plot_model()",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Using `sklearn` Surrogates in `spotpython`</span>"
    ]
  },
  {
    "objectID": "010_num_spot_sklearn_surrogate.html#example-sklearn-model-gaussianprocess",
    "href": "010_num_spot_sklearn_surrogate.html#example-sklearn-model-gaussianprocess",
    "title": "15  Using sklearn Surrogates in spotpython",
    "section": "15.4 Example: Sklearn Model GaussianProcess",
    "text": "15.4 Example: Sklearn Model GaussianProcess\n\nThis example visualizes the search process on the GaussianProcessRegression surrogate from sklearn.\nTherefore surrogate = S_GP is added to the argument list.\n\n\nfun = Analytical(seed=123).fun_sphere\nspot_1_GP = Spot(fun=fun,\n                      fun_control=fun_control,\n                      design_control=design_control,\n                      surrogate = S_GP)\nspot_1_GP.run()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.004925671418704527 [####------] 40.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.002612062398164981 [#####-----] 50.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 5.609944300870913e-07 [######----] 60.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 3.399776625316493e-08 [#######---] 70.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 2.8303204876737398e-08 [########--] 80.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 2.8303204876737398e-08 [#########-] 90.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 2.2894458385368016e-08 [##########] 100.00% Done...\n\nExperiment saved to 000_res.pkl\n\n\n\nspot_1_GP.print_results()\n\nmin y: 2.2894458385368016e-08\nx0: 0.0001513091483862361\n\n\n[['x0', np.float64(0.0001513091483862361)]]\n\n\n\nspot_1_GP.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\nspot_1_GP.plot_model()",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Using `sklearn` Surrogates in `spotpython`</span>"
    ]
  },
  {
    "objectID": "010_num_spot_sklearn_surrogate.html#exercises",
    "href": "010_num_spot_sklearn_surrogate.html#exercises",
    "title": "15  Using sklearn Surrogates in spotpython",
    "section": "15.5 Exercises",
    "text": "15.5 Exercises\n\n15.5.1 1. A decision tree regressor: DecisionTreeRegressor\n\nDescribe the surrogate model. Use the information from the scikit-learn documentation.\nUse the surrogate as the model for optimization.\n\n\n\n15.5.2 2. A random forest regressor: RandomForestRegressor\n\nDescribe the surrogate model. Use the information from the scikit-learn documentation.\nUse the surrogate as the model for optimization.\n\n\n\n15.5.3 3. Ordinary least squares Linear Regression: LinearRegression\n\nDescribe the surrogate model. Use the information from the scikit-learn documentation.\nUse the surrogate as the model for optimization.\n\n\n\n15.5.4 4. Linear least squares with l2 regularization: Ridge\n\nDescribe the surrogate model. Use the information from the scikit-learn documentation.\nUse the surrogate as the model for optimization.\n\n\n\n15.5.5 5. Gradient Boosting: HistGradientBoostingRegressor\n\nDescribe the surrogate model. Use the information from the scikit-learn documentation.\nUse the surrogate as the model for optimization.\n\n\n\n15.5.6 6. Comparison of Surrogates\n\nUse the following two objective functions\n\nthe 1-dim sphere function fun_sphere and\nthe two-dim Branin function fun_branin:\n\nfor a comparison of the performance of the five different surrogates:\n\nspotpython’s internal Kriging\nDecisionTreeRegressor\nRandomForestRegressor\nlinear_model.LinearRegression\nlinear_model.Ridge.\n\nGenerate a table with the results (number of function evaluations, best function value, and best parameter vector) for each surrogate and each function as shown in Table 15.1.\n\n\n\n\nTable 15.1: Result table\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsurrogate\nfun\nfun_evals\nmax_time\nx_0\nmin_y\nComments\n\n\n\n\nKriging\nfun_sphere\n10\ninf\n\n\n\n\n\nKriging\nfun_branin\n10\ninf\n\n\n\n\n\nDecisionTreeRegressor\nfun_sphere\n10\ninf\n\n\n\n\n\n…\n…\n…\n…\n\n\n\n\n\nRidge\nfun_branin\n10\ninf\n\n\n\n\n\n\n\n\n\n\nDiscuss the results. Which surrogate is the best for which function? Why?",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Using `sklearn` Surrogates in `spotpython`</span>"
    ]
  },
  {
    "objectID": "010_num_spot_sklearn_surrogate.html#selected-solutions",
    "href": "010_num_spot_sklearn_surrogate.html#selected-solutions",
    "title": "15  Using sklearn Surrogates in spotpython",
    "section": "15.6 Selected Solutions",
    "text": "15.6 Selected Solutions\n\n15.6.1 Solution to Exercise Section 15.5.5: Gradient Boosting\n\n15.6.1.1 Branin: Using SPOT\n\nimport numpy as np\nfrom math import inf\nfrom spotpython.fun.objectivefunctions import Analytical\nfrom spotpython.utils.init import fun_control_init, design_control_init\nfrom spotpython.spot import Spot\n\n\nThe Objective Function Branin\n\n\nfun = Analytical().fun_branin\nPREFIX = \"BRANIN\"\nfun_control = fun_control_init(\n    PREFIX=PREFIX,\n    lower = np.array([-5,-0]),\n    upper = np.array([10,15]),\n    fun_evals=20,\n    max_time=inf)\n\ndesign_control = design_control_init(\n    init_size=10)\n\n\nRunning the surrogate model based optimizer Spot:\n\n\nspot_2 = Spot(fun=fun,\n                   fun_control=fun_control,\n                   design_control=design_control)\nspot_2.run()\n\nspotpython tuning: 3.6961557165023953 [######----] 55.00% \nspotpython tuning: 3.483508988983779 [######----] 60.00% \nspotpython tuning: 3.0409502575998015 [######----] 65.00% \nspotpython tuning: 2.456350051306707 [#######---] 70.00% \nspotpython tuning: 2.4047922291552375 [########--] 75.00% \nspotpython tuning: 2.3739197901896123 [########--] 80.00% \nspotpython tuning: 2.355976671386384 [########--] 85.00% \nspotpython tuning: 2.348822784282971 [#########-] 90.00% \nspotpython tuning: 2.348822784282971 [##########] 95.00% \nspotpython tuning: 2.348822784282971 [##########] 100.00% Done...\n\nExperiment saved to BRANIN_res.pkl\n\n\n&lt;spotpython.spot.spot.Spot at 0x15fb11520&gt;\n\n\n\nPrint the results\n\n\nspot_2.print_results()\n\nmin y: 2.348822784282971\nx0: 3.1733035041022477\nx1: 3.645429652665629\n\n\n[['x0', np.float64(3.1733035041022477)], ['x1', np.float64(3.645429652665629)]]\n\n\n\nShow the optimization progress:\n\n\nspot_2.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\nGenerate a surrogate model plot:\n\n\nspot_2.surrogate.plot()\n\n\n\n\n\n\n\n\n\n\n15.6.1.2 Branin: Using Surrogates From scikit-learn\n\nThe HistGradientBoostingRegressor model from scikit-learn is selected:\n\n\n# Needed for the sklearn surrogates:\nfrom sklearn.ensemble import HistGradientBoostingRegressor\nimport pandas as pd\nS_XGB = HistGradientBoostingRegressor()\n\n\nThe scikit-learn XGB model S_XGB is selected for Spot as follows: surrogate = S_XGB.\nSimilar to the Spot run with the internal Kriging model, we can call the run with the scikit-learn surrogate:\n\n\nfun = Analytical(seed=123).fun_branin\nspot_2_XGB = Spot(fun=fun,\n                     fun_control=fun_control,\n                     design_control=design_control,\n                     surrogate = S_XGB)\nspot_2_XGB.run()\n\nspotpython tuning: 30.69410528614059 [######----] 55.00% \nspotpython tuning: 30.69410528614059 [######----] 60.00% \nspotpython tuning: 30.69410528614059 [######----] 65.00% \nspotpython tuning: 30.69410528614059 [#######---] 70.00% \nspotpython tuning: 1.3263745845108854 [########--] 75.00% \nspotpython tuning: 1.3263745845108854 [########--] 80.00% \nspotpython tuning: 1.3263745845108854 [########--] 85.00% \nspotpython tuning: 1.3263745845108854 [#########-] 90.00% \nspotpython tuning: 1.3263745845108854 [##########] 95.00% \nspotpython tuning: 1.3263745845108854 [##########] 100.00% Done...\n\nExperiment saved to BRANIN_res.pkl\n\n\n&lt;spotpython.spot.spot.Spot at 0x16a3ab200&gt;\n\n\n\nPrint the Results\n\n\nspot_2_XGB.print_results()\n\nmin y: 1.3263745845108854\nx0: -2.872730773493426\nx1: 10.874313833535739\n\n\n[['x0', np.float64(-2.872730773493426)],\n ['x1', np.float64(10.874313833535739)]]\n\n\n\nShow the Progress\n\n\nspot_2_XGB.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\nSince the sklearn model does not provide a plot method, we cannot generate a surrogate model plot.\n\n\n\n15.6.1.3 One-dimensional Sphere Function With spotpython’s Kriging\n\nIn this example, we will use an one-dimensional function, which allows us to visualize the optimization process.\n\nshow_models= True is added to the argument list.\n\n\n\nfrom spotpython.fun.objectivefunctions import Analytical\nfun_control = fun_control_init(\n    lower = np.array([-1]),\n    upper = np.array([1]),\n    fun_evals=10,\n    max_time=inf,\n    show_models= True,\n    tolerance_x = np.sqrt(np.spacing(1)))\nfun = Analytical(seed=123).fun_sphere\ndesign_control = design_control_init(\n    init_size=3)\n\n\nspot_1 = Spot(fun=fun,\n                    fun_control=fun_control,\n                    design_control=design_control)\nspot_1.run()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.03475485848264724 [####------] 40.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.03475485848264724 [#####-----] 50.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.03475481964033922 [######----] 60.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.03475479804192463 [#######---] 70.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.03475446167786181 [########--] 80.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.03474447900832713 [#########-] 90.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.034515878522411086 [##########] 100.00% Done...\n\nExperiment saved to 000_res.pkl\n\n\n\nPrint the Results\n\n\nspot_1.print_results()\n\nmin y: 0.034515878522411086\nx0: 0.1857844948385389\n\n\n[['x0', np.float64(0.1857844948385389)]]\n\n\n\nShow the Progress\n\n\nspot_1.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\nThe method plot_model plots the final surrogate:\n\n\nspot_1.plot_model()\n\n\n\n\n\n\n\n\n\n\n15.6.1.4 One-dimensional Sphere Function With Sklearn Model HistGradientBoostingRegressor\n\nThis example visualizes the search process on the HistGradientBoostingRegressor surrogate from sklearn.\nTherefore surrogate = S_XGB is added to the argument list.\n\n\nfun_control = fun_control_init(\n    lower = np.array([-1]),\n    upper = np.array([1]),\n    fun_evals=10,\n    max_time=inf,\n    show_models= True,\n    tolerance_x = np.sqrt(np.spacing(1)))\nfun = Analytical(seed=123).fun_sphere\ndesign_control = design_control_init(\n    init_size=3)\nspot_1_XGB = Spot(fun=fun,\n                      fun_control=fun_control,\n                      design_control=design_control,\n                      surrogate = S_XGB)\nspot_1_XGB.run()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.03475493366922229 [####------] 40.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.03475493366922229 [#####-----] 50.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.03475493366922229 [######----] 60.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.03475493366922229 [#######---] 70.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.008730885505764131 [########--] 80.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.008730885505764131 [#########-] 90.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.008730885505764131 [##########] 100.00% Done...\n\nExperiment saved to 000_res.pkl\n\n\n\nspot_1_XGB.print_results()\n\nmin y: 0.008730885505764131\nx0: 0.09343920754032609\n\n\n[['x0', np.float64(0.09343920754032609)]]\n\n\n\nspot_1_XGB.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\nspot_1_XGB.plot_model()",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Using `sklearn` Surrogates in `spotpython`</span>"
    ]
  },
  {
    "objectID": "010_num_spot_sklearn_surrogate.html#jupyter-notebook",
    "href": "010_num_spot_sklearn_surrogate.html#jupyter-notebook",
    "title": "15  Using sklearn Surrogates in spotpython",
    "section": "15.7 Jupyter Notebook",
    "text": "15.7 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Using `sklearn` Surrogates in `spotpython`</span>"
    ]
  },
  {
    "objectID": "011_num_spot_sklearn_gaussian.html",
    "href": "011_num_spot_sklearn_gaussian.html",
    "title": "16  Sequential Parameter Optimization: Gaussian Process Models",
    "section": "",
    "text": "16.1 Gaussian Processes Regression: Basic Introductory scikit-learn Example\nThis chapter analyzes differences between the Kriging implementation in spotpython and the GaussianProcessRegressor in scikit-learn.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Sequential Parameter Optimization:  Gaussian Process Models</span>"
    ]
  },
  {
    "objectID": "011_num_spot_sklearn_gaussian.html#gaussian-processes-regression-basic-introductory-scikit-learn-example",
    "href": "011_num_spot_sklearn_gaussian.html#gaussian-processes-regression-basic-introductory-scikit-learn-example",
    "title": "16  Sequential Parameter Optimization: Gaussian Process Models",
    "section": "",
    "text": "This is the example from scikit-learn: https://scikit-learn.org/stable/auto_examples/gaussian_process/plot_gpr_noisy_targets.html\nAfter fitting our model, we see that the hyperparameters of the kernel have been optimized.\nNow, we will use our kernel to compute the mean prediction of the full dataset and plot the 95% confidence interval.\n\n\n16.1.1 Train and Test Data\n\nX = np.linspace(start=0, stop=10, num=1_000).reshape(-1, 1)\ny = np.squeeze(X * np.sin(X))\nrng = np.random.RandomState(1)\ntraining_indices = rng.choice(np.arange(y.size), size=6, replace=False)\nX_train, y_train = X[training_indices], y[training_indices]\n\n\n\n16.1.2 Building the Surrogate With Sklearn\n\nThe model building with sklearn consisits of three steps:\n\nInstantiating the model, then\nfitting the model (using fit), and\nmaking predictions (using predict)\n\n\n\nkernel = 1 * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2))\ngaussian_process = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\ngaussian_process.fit(X_train, y_train)\nmean_prediction, std_prediction = gaussian_process.predict(X, return_std=True)\n\n\n\n16.1.3 Plotting the SklearnModel\n\nplt.plot(X, y, label=r\"$f(x) = x \\sin(x)$\", linestyle=\"dotted\")\nplt.scatter(X_train, y_train, label=\"Observations\")\nplt.plot(X, mean_prediction, label=\"Mean prediction\")\nplt.fill_between(\n    X.ravel(),\n    mean_prediction - 1.96 * std_prediction,\n    mean_prediction + 1.96 * std_prediction,\n    alpha=0.5,\n    label=r\"95% confidence interval\",\n)\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"sk-learn Version: Gaussian process regression on noise-free dataset\")\n\n\n\n\n\n\n\n\n\n\n16.1.4 The spotpython Version\n\nThe spotpython version is very similar:\n\nInstantiating the model, then\nfitting the model and\nmaking predictions (using predict).\n\n\n\nS = Kriging(name='kriging',  seed=123, log_level=50, cod_type=\"norm\")\nS.fit(X_train, y_train)\nS_mean_prediction, S_std_prediction, S_ei = S.predict(X, return_val=\"all\")\n\n\nplt.plot(X, y, label=r\"$f(x) = x \\sin(x)$\", linestyle=\"dotted\")\nplt.scatter(X_train, y_train, label=\"Observations\")\nplt.plot(X, S_mean_prediction, label=\"Mean prediction\")\nplt.fill_between(\n    X.ravel(),\n    S_mean_prediction - 1.96 * S_std_prediction,\n    S_mean_prediction + 1.96 * S_std_prediction,\n    alpha=0.5,\n    label=r\"95% confidence interval\",\n)\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"spotpython Version: Gaussian process regression on noise-free dataset\")\n\n\n\n\n\n\n\n\n\n\n16.1.5 Visualizing the Differences Between the spotpython and the sklearn Model Fits\n\nplt.plot(X, y, label=r\"$f(x) = x \\sin(x)$\", linestyle=\"dotted\")\nplt.scatter(X_train, y_train, label=\"Observations\")\nplt.plot(X, S_mean_prediction, label=\"spotpython Mean prediction\")\nplt.plot(X, mean_prediction, label=\"Sklearn Mean Prediction\")\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"Comparing Mean Predictions\")",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Sequential Parameter Optimization:  Gaussian Process Models</span>"
    ]
  },
  {
    "objectID": "011_num_spot_sklearn_gaussian.html#exercises",
    "href": "011_num_spot_sklearn_gaussian.html#exercises",
    "title": "16  Sequential Parameter Optimization: Gaussian Process Models",
    "section": "16.2 Exercises",
    "text": "16.2 Exercises\n\n16.2.1 Schonlau Example Function\n\nThe Schonlau Example Function is based on sample points only (there is no analytical function description available):\n\n\nX = np.linspace(start=0, stop=13, num=1_000).reshape(-1, 1)\nX_train = np.array([1., 2., 3., 4., 12.]).reshape(-1,1)\ny_train = np.array([0., -1.75, -2, -0.5, 5.])\n\n\nDescribe the function.\nCompare the two models that were build using the spotpython and the sklearn surrogate.\nNote: Since there is no analytical function available, you might be interested in adding some points and describe the effects.\n\n\n\n16.2.2 Forrester Example Function\n\nThe Forrester Example Function is defined as follows:\nf(x) = (6x- 2)^2 sin(12x-4) for x in [0,1].\nData points are generated as follows:\n\n\nfrom spotpython.utils.init import fun_control_init\nX = np.linspace(start=-0.5, stop=1.5, num=1_000).reshape(-1, 1)\nX_train = np.array([0.0, 0.175, 0.225, 0.3, 0.35, 0.375, 0.5,1]).reshape(-1,1)\nfun = Analytical().fun_forrester\nfun_control = fun_control_init(sigma = 0.1)\ny = fun(X, fun_control=fun_control)\ny_train = fun(X_train, fun_control=fun_control)\n\n\nDescribe the function.\nCompare the two models that were build using the spotpython and the sklearn surrogate.\nNote: Modify the noise level (\"sigma\"), e.g., use a value of 0.2, and compare the two models.\n\n\nfun_control = fun_control_init(sigma = 0.2)\n\n\n\n16.2.3 fun_runge Function (1-dim)\n\nThe Runge function is defined as follows:\nf(x) = 1/ (1 + sum(x_i))^2\nData points are generated as follows:\n\n\ngen = SpaceFilling(1)\nrng = np.random.RandomState(1)\nlower = np.array([-10])\nupper = np.array([10])\nfun = Analytical().fun_runge\nfun_control = fun_control_init(sigma = 0.025)\nX_train = gen.scipy_lhd(10, lower=lower, upper = upper).reshape(-1,1)\ny_train = fun(X, fun_control=fun_control)\nX = np.linspace(start=-13, stop=13, num=1000).reshape(-1, 1)\ny = fun(X, fun_control=fun_control)\n\n\nDescribe the function.\nCompare the two models that were build using the spotpython and the sklearn surrogate.\nNote: Modify the noise level (\"sigma\"), e.g., use a value of 0.05, and compare the two models.\n\n\nfun_control = fun_control_init(sigma = 0.5)\n\n\n\n16.2.4 fun_cubed (1-dim)\n\nThe Cubed function is defined as follows:\nnp.sum(X[i]** 3)\nData points are generated as follows:\n\n\ngen = SpaceFilling(1)\nrng = np.random.RandomState(1)\nfun_control = fun_control_init(sigma = 0.025,\n                lower = np.array([-10]),\n                upper = np.array([10]))\nfun = Analytical().fun_cubed\nX_train = gen.scipy_lhd(10, lower=lower, upper = upper).reshape(-1,1)\ny_train = fun(X, fun_control=fun_control)\nX = np.linspace(start=-13, stop=13, num=1000).reshape(-1, 1)\ny = fun(X, fun_control=fun_control)\n\n\nDescribe the function.\nCompare the two models that were build using the spotpython and the sklearn surrogate.\nNote: Modify the noise level (\"sigma\"), e.g., use a value of 0.05, and compare the two models.\n\n\nfun_control = fun_control_init(sigma = 0.025)\n\n\n\n16.2.5 The Effect of Noise\nHow does the behavior of the spotpython fit changes when the argument noise is set to True, i.e.,\nS = Kriging(name='kriging',  seed=123, n_theta=1, method=\"regression\")\nis used?",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Sequential Parameter Optimization:  Gaussian Process Models</span>"
    ]
  },
  {
    "objectID": "012_num_spot_ei.html",
    "href": "012_num_spot_ei.html",
    "title": "17  Expected Improvement",
    "section": "",
    "text": "17.1 Example: Spot and the 1-dim Sphere Function\nThis chapter describes, analyzes, and compares different infill criterion. An infill criterion defines how the next point \\(x_{n+1}\\) is selected from the surrogate model \\(S\\). Expected improvement is a popular infill criterion in Bayesian optimization.\nimport numpy as np\nfrom math import inf\nfrom spotpython.fun.objectivefunctions import Analytical\nfrom spotpython.spot import Spot\nfrom spotpython.utils.init import fun_control_init, surrogate_control_init, design_control_init\nimport matplotlib.pyplot as plt",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Expected Improvement</span>"
    ]
  },
  {
    "objectID": "012_num_spot_ei.html#example-spot-and-the-1-dim-sphere-function",
    "href": "012_num_spot_ei.html#example-spot-and-the-1-dim-sphere-function",
    "title": "17  Expected Improvement",
    "section": "",
    "text": "17.1.1 The Objective Function: 1-dim Sphere\n\nThe spotpython package provides several classes of objective functions.\nWe will use an analytical objective function, i.e., a function that can be described by a (closed) formula: \\[f(x) = x^2 \\]\n\n\nfun = Analytical().fun_sphere\n\n\nThe size of the lower bound vector determines the problem dimension.\nHere we will use np.array([-1]), i.e., a one-dim function.\n\n\n\n\n\n\n\nTensorBoard\n\n\n\nSimilar to the one-dimensional case, which was introduced in Section Section 12.8, we can use TensorBoard to monitor the progress of the optimization. We will use the same code, only the prefix is different:\n\nfrom spotpython.utils.init import fun_control_init\nPREFIX = \"07_Y\"\nfun_control = fun_control_init(\n    PREFIX=PREFIX,\n    fun_evals = 25,\n    lower = np.array([-1]),\n    upper = np.array([1]),\n    tolerance_x = np.sqrt(np.spacing(1)),)\ndesign_control = design_control_init(init_size=10)\n\n\n\n\nspot_1 = Spot(\n            fun=fun,\n            fun_control=fun_control,\n            design_control=design_control)\nspot_1.run()\n\nspotpython tuning: 6.690918515799129e-09 [####------] 44.00% \nspotpython tuning: 6.719979618922052e-11 [#####-----] 48.00% \nspotpython tuning: 6.719979618922052e-11 [#####-----] 52.00% \nspotpython tuning: 6.719979618922052e-11 [######----] 56.00% \nspotpython tuning: 6.719979618922052e-11 [######----] 60.00% \nspotpython tuning: 6.719979618922052e-11 [######----] 64.00% \nspotpython tuning: 6.719979618922052e-11 [#######---] 68.00% \nspotpython tuning: 6.719979618922052e-11 [#######---] 72.00% \nspotpython tuning: 6.719979618922052e-11 [########--] 76.00% \nspotpython tuning: 6.719979618922052e-11 [########--] 80.00% \nspotpython tuning: 6.719979618922052e-11 [########--] 84.00% \nspotpython tuning: 6.719979618922052e-11 [#########-] 88.00% \nspotpython tuning: 6.719979618922052e-11 [#########-] 92.00% \nspotpython tuning: 6.719979618922052e-11 [##########] 96.00% \nspotpython tuning: 6.719979618922052e-11 [##########] 100.00% Done...\n\nExperiment saved to 07_Y_res.pkl\n\n\n&lt;spotpython.spot.spot.Spot at 0x10ce4d040&gt;\n\n\n\n\n17.1.2 Results\n\nspot_1.print_results()\n\nmin y: 6.719979618922052e-11\nx0: 8.197548181573593e-06\n\n\n[['x0', np.float64(8.197548181573593e-06)]]\n\n\n\nspot_1.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\n\n\nTensorBoard visualization of the spotpython optimization process and the surrogate model.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Expected Improvement</span>"
    ]
  },
  {
    "objectID": "012_num_spot_ei.html#same-but-with-ei-as-infill_criterion",
    "href": "012_num_spot_ei.html#same-but-with-ei-as-infill_criterion",
    "title": "17  Expected Improvement",
    "section": "17.2 Same, but with EI as infill_criterion",
    "text": "17.2 Same, but with EI as infill_criterion\n\nPREFIX = \"07_EI_ISO\"\nfun_control = fun_control_init(\n    PREFIX=PREFIX,\n    lower = np.array([-1]),\n    upper = np.array([1]),\n    fun_evals = 25,\n    tolerance_x = np.sqrt(np.spacing(1)),\n    infill_criterion = \"ei\")\n\n\nspot_1_ei = Spot(fun=fun,\n                     fun_control=fun_control)\nspot_1_ei.run()\n\nspotpython tuning: 6.690918515799129e-09 [####------] 44.00% \nspotpython tuning: 6.719979618922052e-11 [#####-----] 48.00% \nspotpython tuning: 6.719979618922052e-11 [#####-----] 52.00% \nspotpython tuning: 6.719979618922052e-11 [######----] 56.00% \nspotpython tuning: 6.719979618922052e-11 [######----] 60.00% \nspotpython tuning: 6.719979618922052e-11 [######----] 64.00% \nspotpython tuning: 6.719979618922052e-11 [#######---] 68.00% \nspotpython tuning: 6.719979618922052e-11 [#######---] 72.00% \nspotpython tuning: 6.719979618922052e-11 [########--] 76.00% \nspotpython tuning: 6.719979618922052e-11 [########--] 80.00% \nspotpython tuning: 6.719979618922052e-11 [########--] 84.00% \nspotpython tuning: 6.719979618922052e-11 [#########-] 88.00% \nspotpython tuning: 6.719979618922052e-11 [#########-] 92.00% \nspotpython tuning: 6.719979618922052e-11 [##########] 96.00% \nspotpython tuning: 6.719979618922052e-11 [##########] 100.00% Done...\n\nExperiment saved to 07_EI_ISO_res.pkl\n\n\n&lt;spotpython.spot.spot.Spot at 0x174879a60&gt;\n\n\n\nspot_1_ei.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\nspot_1_ei.print_results()\n\nmin y: 6.719979618922052e-11\nx0: 8.197548181573593e-06\n\n\n[['x0', np.float64(8.197548181573593e-06)]]\n\n\n\n\n\nTensorBoard visualization of the spotpython optimization process and the surrogate model. Expected improvement, isotropic Kriging.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Expected Improvement</span>"
    ]
  },
  {
    "objectID": "012_num_spot_ei.html#non-isotropic-kriging",
    "href": "012_num_spot_ei.html#non-isotropic-kriging",
    "title": "17  Expected Improvement",
    "section": "17.3 Non-isotropic Kriging",
    "text": "17.3 Non-isotropic Kriging\n\nPREFIX = \"07_EI_NONISO\"\nfun_control = fun_control_init(\n    PREFIX=PREFIX,\n    lower = np.array([-1, -1]),\n    upper = np.array([1, 1]),\n    fun_evals = 25,\n    tolerance_x = np.sqrt(np.spacing(1)),\n    infill_criterion = \"ei\")\nsurrogate_control = surrogate_control_init(\n    n_theta=2,\n    method=\"interpolation\",\n    )\n\n\nspot_2_ei_noniso = Spot(fun=fun,\n                   fun_control=fun_control,\n                   surrogate_control=surrogate_control)\nspot_2_ei_noniso.run()\n\nspotpython tuning: 0.001300040921033532 [####------] 44.00% \nspotpython tuning: 0.00032084547313593353 [#####-----] 48.00% \nspotpython tuning: 0.00019406280738811914 [#####-----] 52.00% \nspotpython tuning: 0.00015939359695595043 [######----] 56.00% \nspotpython tuning: 0.00014737851302527218 [######----] 60.00% \nspotpython tuning: 0.0001458874607475838 [######----] 64.00% \nspotpython tuning: 0.0001458874607475838 [#######---] 68.00% \nspotpython tuning: 0.0001458874607475838 [#######---] 72.00% \nspotpython tuning: 0.00014498403599255805 [########--] 76.00% \nspotpython tuning: 0.0001393597102409414 [########--] 80.00% \nspotpython tuning: 0.00010625540134140391 [########--] 84.00% \nspotpython tuning: 5.864391313750128e-05 [#########-] 88.00% \nspotpython tuning: 4.049967051189472e-05 [#########-] 92.00% \nspotpython tuning: 2.5450459678851107e-05 [##########] 96.00% \nspotpython tuning: 1.6373659109908014e-05 [##########] 100.00% Done...\n\nExperiment saved to 07_EI_NONISO_res.pkl\n\n\n&lt;spotpython.spot.spot.Spot at 0x174cf2ae0&gt;\n\n\n\nspot_2_ei_noniso.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\nspot_2_ei_noniso.print_results()\n\nmin y: 1.6373659109908014e-05\nx0: 0.004003772156272264\nx1: 0.0005860611150442899\n\n\n[['x0', np.float64(0.004003772156272264)],\n ['x1', np.float64(0.0005860611150442899)]]\n\n\n\nspot_2_ei_noniso.surrogate.plot()\n\n\n\n\n\n\n\n\n\n\n\nTensorBoard visualization of the spotpython optimization process and the surrogate model. Expected improvement, isotropic Kriging.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Expected Improvement</span>"
    ]
  },
  {
    "objectID": "012_num_spot_ei.html#using-sklearn-surrogates",
    "href": "012_num_spot_ei.html#using-sklearn-surrogates",
    "title": "17  Expected Improvement",
    "section": "17.4 Using sklearn Surrogates",
    "text": "17.4 Using sklearn Surrogates\n\n17.4.1 The spot Loop\nThe spot loop consists of the following steps:\n\nInit: Build initial design \\(X\\)\nEvaluate initial design on real objective \\(f\\): \\(y = f(X)\\)\nBuild surrogate: \\(S = S(X,y)\\)\nOptimize on surrogate: \\(X_0 =  \\text{optimize}(S)\\)\nEvaluate on real objective: \\(y_0 = f(X_0)\\)\nImpute (Infill) new points: \\(X = X \\cup X_0\\), \\(y = y \\cup y_0\\).\nGot 3.\n\nThe spot loop is implemented in R as follows:\n\n\n\nVisual representation of the model based search with SPOT. Taken from: Bartz-Beielstein, T., and Zaefferer, M. Hyperparameter tuning approaches. In Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide, E. Bartz, T. Bartz-Beielstein, M. Zaefferer, and O. Mersmann, Eds. Springer, 2022, ch. 4, pp. 67–114.\n\n\n\n\n17.4.2 spot: The Initial Model\n\n17.4.2.1 Example: Modifying the initial design size\nThis is the “Example: Modifying the initial design size” from Chapter 4.5.1 in [bart21i].\n\nspot_ei = Spot(fun=fun,\n                fun_control=fun_control_init(\n                lower = np.array([-1,-1]),\n                upper= np.array([1,1])), \n                design_control = design_control_init(init_size=5))\nspot_ei.run()\n\nspotpython tuning: 0.004169879899427079 [####------] 40.00% \nspotpython tuning: 0.004169879899427079 [#####-----] 46.67% \nspotpython tuning: 0.0008971492855200217 [#####-----] 53.33% \nspotpython tuning: 0.00047732364387283296 [######----] 60.00% \nspotpython tuning: 0.00047732364387283296 [#######---] 66.67% \nspotpython tuning: 0.00047732364387283296 [#######---] 73.33% \nspotpython tuning: 0.00043930823984539394 [########--] 80.00% \nspotpython tuning: 0.00040531992496737674 [#########-] 86.67% \nspotpython tuning: 0.00038005812225023545 [#########-] 93.33% \nspotpython tuning: 0.00036548617270809396 [##########] 100.00% Done...\n\nExperiment saved to 000_res.pkl\n\n\n&lt;spotpython.spot.spot.Spot at 0x174d6c470&gt;\n\n\n\nspot_ei.plot_progress()\n\n\n\n\n\n\n\n\n\nnp.min(spot_1.y), np.min(spot_ei.y)\n\n(np.float64(6.719979618922052e-11), np.float64(0.00036548617270809396))\n\n\n\n\n\n17.4.3 Init: Build Initial Design\n\nfrom spotpython.design.spacefilling import SpaceFilling\nfrom spotpython.surrogate.kriging import Kriging\nfrom spotpython.fun.objectivefunctions import Analytical\ngen = SpaceFilling(2)\nrng = np.random.RandomState(1)\nlower = np.array([-5,-0])\nupper = np.array([10,15])\nfun = Analytical().fun_branin\n\nX = gen.scipy_lhd(10, lower=lower, upper = upper)\nprint(X)\ny = fun(X, fun_control=fun_control)\nprint(y)\n\n[[ 8.97647221 13.41926847]\n [ 0.66946019  1.22344228]\n [ 5.23614115 13.78185824]\n [ 5.6149825  11.5851384 ]\n [-1.72963184  1.66516096]\n [-4.26945568  7.1325531 ]\n [ 1.26363761 10.17935555]\n [ 2.88779942  8.05508969]\n [-3.39111089  4.15213772]\n [ 7.30131231  5.22275244]]\n[128.95676449  31.73474356 172.89678121 126.71295908  64.34349975\n  70.16178611  48.71407916  31.77322887  76.91788181  30.69410529]\n\n\n\nS = Kriging(name='kriging',  seed=123)\nS.fit(X, y)\nS.plot()\n\n\n\n\n\n\n\n\n\ngen = SpaceFilling(2, seed=123)\nX0 = gen.scipy_lhd(3)\ngen = SpaceFilling(2, seed=345)\nX1 = gen.scipy_lhd(3)\nX2 = gen.scipy_lhd(3)\ngen = SpaceFilling(2, seed=123)\nX3 = gen.scipy_lhd(3)\nX0, X1, X2, X3\n\n(array([[0.77254938, 0.31539299],\n        [0.59321338, 0.93854273],\n        [0.27469803, 0.3959685 ]]),\n array([[0.78373509, 0.86811887],\n        [0.06692621, 0.6058029 ],\n        [0.41374778, 0.00525456]]),\n array([[0.121357  , 0.69043832],\n        [0.41906219, 0.32838498],\n        [0.86742658, 0.52910374]]),\n array([[0.77254938, 0.31539299],\n        [0.59321338, 0.93854273],\n        [0.27469803, 0.3959685 ]]))\n\n\n\n\n17.4.4 Evaluate\n\n\n17.4.5 Build Surrogate\n\n\n17.4.6 A Simple Predictor\nThe code below shows how to use a simple model for prediction.\n\nAssume that only two (very costly) measurements are available:\n\nf(0) = 0.5\nf(2) = 2.5\n\nWe are interested in the value at \\(x_0 = 1\\), i.e., \\(f(x_0 = 1)\\), but cannot run an additional, third experiment.\n\n\nfrom sklearn import linear_model\nX = np.array([[0], [2]])\ny = np.array([0.5, 2.5])\nS_lm = linear_model.LinearRegression()\nS_lm = S_lm.fit(X, y)\nX0 = np.array([[1]])\ny0 = S_lm.predict(X0)\nprint(y0)\n\n[1.5]\n\n\n\nCentral Idea:\n\nEvaluation of the surrogate model S_lm is much cheaper (or / and much faster) than running the real-world experiment \\(f\\).",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Expected Improvement</span>"
    ]
  },
  {
    "objectID": "012_num_spot_ei.html#gaussian-processes-regression-basic-introductory-example",
    "href": "012_num_spot_ei.html#gaussian-processes-regression-basic-introductory-example",
    "title": "17  Expected Improvement",
    "section": "17.5 Gaussian Processes regression: basic introductory example",
    "text": "17.5 Gaussian Processes regression: basic introductory example\nThis example was taken from scikit-learn. After fitting our model, we see that the hyperparameters of the kernel have been optimized. Now, we will use our kernel to compute the mean prediction of the full dataset and plot the 95% confidence interval.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport math as m\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF\n\nX = np.linspace(start=0, stop=10, num=1_000).reshape(-1, 1)\ny = np.squeeze(X * np.sin(X))\nrng = np.random.RandomState(1)\ntraining_indices = rng.choice(np.arange(y.size), size=6, replace=False)\nX_train, y_train = X[training_indices], y[training_indices]\n\nkernel = 1 * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2))\ngaussian_process = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\ngaussian_process.fit(X_train, y_train)\ngaussian_process.kernel_\n\nmean_prediction, std_prediction = gaussian_process.predict(X, return_std=True)\n\nplt.plot(X, y, label=r\"$f(x) = x \\sin(x)$\", linestyle=\"dotted\")\nplt.scatter(X_train, y_train, label=\"Observations\")\nplt.plot(X, mean_prediction, label=\"Mean prediction\")\nplt.fill_between(\n    X.ravel(),\n    mean_prediction - 1.96 * std_prediction,\n    mean_prediction + 1.96 * std_prediction,\n    alpha=0.5,\n    label=r\"95% confidence interval\",\n)\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"sk-learn Version: Gaussian process regression on noise-free dataset\")\n\n\n\n\n\n\n\n\n\nfrom spotpython.surrogate.kriging import Kriging\nimport numpy as np\nimport matplotlib.pyplot as plt\nrng = np.random.RandomState(1)\nX = np.linspace(start=0, stop=10, num=1_000).reshape(-1, 1)\ny = np.squeeze(X * np.sin(X))\ntraining_indices = rng.choice(np.arange(y.size), size=6, replace=False)\nX_train, y_train = X[training_indices], y[training_indices]\n\n\nS = Kriging(name='kriging',  seed=123, log_level=50, cod_type=\"norm\")\nS.fit(X_train, y_train)\n\nmean_prediction, std_prediction, ei = S.predict(X, return_val=\"all\")\n\nstd_prediction\n\nplt.plot(X, y, label=r\"$f(x) = x \\sin(x)$\", linestyle=\"dotted\")\nplt.scatter(X_train, y_train, label=\"Observations\")\nplt.plot(X, mean_prediction, label=\"Mean prediction\")\nplt.fill_between(\n    X.ravel(),\n    mean_prediction - 1.96 * std_prediction,\n    mean_prediction + 1.96 * std_prediction,\n    alpha=0.5,\n    label=r\"95% confidence interval\",\n)\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"spotpython Version: Gaussian process regression on noise-free dataset\")",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Expected Improvement</span>"
    ]
  },
  {
    "objectID": "012_num_spot_ei.html#the-surrogate-using-scikit-learn-models",
    "href": "012_num_spot_ei.html#the-surrogate-using-scikit-learn-models",
    "title": "17  Expected Improvement",
    "section": "17.6 The Surrogate: Using scikit-learn models",
    "text": "17.6 The Surrogate: Using scikit-learn models\nDefault is the internal kriging surrogate.\n\nS_0 = Kriging(name='kriging', seed=123)\n\nModels from scikit-learn can be selected, e.g., Gaussian Process:\n\n# Needed for the sklearn surrogates:\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn import linear_model\nfrom sklearn import tree\nimport pandas as pd\n\n\nkernel = 1 * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2))\nS_GP = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\n\n\nand many more:\n\n\nS_Tree = DecisionTreeRegressor(random_state=0)\nS_LM = linear_model.LinearRegression()\nS_Ridge = linear_model.Ridge()\nS_RF = RandomForestRegressor(max_depth=2, random_state=0) \n\n\nThe scikit-learn GP model S_GP is selected.\n\n\nS = S_GP\n\n\nisinstance(S, GaussianProcessRegressor)\n\nTrue\n\n\n\nfrom spotpython.fun.objectivefunctions import Analytical\nfun = Analytical().fun_branin\nfun_control = fun_control_init(\n    lower = np.array([-5,-0]),\n    upper = np.array([10,15]),\n    fun_evals = 15)    \ndesign_control = design_control_init(init_size=5)\nspot_GP = Spot(fun=fun, \n                    fun_control=fun_control,\n                    surrogate=S, \n                    design_control=design_control)\nspot_GP.run()\n\nspotpython tuning: 24.51465459019188 [####------] 40.00% \nspotpython tuning: 11.003092545432404 [#####-----] 46.67% \nspotpython tuning: 11.003092545432404 [#####-----] 53.33% \nspotpython tuning: 7.281405479109784 [######----] 60.00% \nspotpython tuning: 7.281405479109784 [#######---] 66.67% \nspotpython tuning: 7.281405479109784 [#######---] 73.33% \nspotpython tuning: 2.9520033012954237 [########--] 80.00% \nspotpython tuning: 2.9520033012954237 [#########-] 86.67% \nspotpython tuning: 2.1049818033904044 [#########-] 93.33% \nspotpython tuning: 1.9431597967021723 [##########] 100.00% Done...\n\nExperiment saved to 000_res.pkl\n\n\n&lt;spotpython.spot.spot.Spot at 0x17734f200&gt;\n\n\n\nspot_GP.y\n\narray([ 69.32459936, 152.38491454, 107.92560483,  24.51465459,\n        76.73500031,  86.30426863,  11.00309255,  16.11758333,\n         7.28140548,  21.82343562,  10.96088904,   2.9520033 ,\n         3.02912616,   2.1049818 ,   1.9431598 ])\n\n\n\nspot_GP.plot_progress()\n\n\n\n\n\n\n\n\n\nspot_GP.print_results()\n\nmin y: 1.9431597967021723\nx0: 10.0\nx1: 2.99858238342458\n\n\n[['x0', np.float64(10.0)], ['x1', np.float64(2.99858238342458)]]",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Expected Improvement</span>"
    ]
  },
  {
    "objectID": "012_num_spot_ei.html#additional-examples",
    "href": "012_num_spot_ei.html#additional-examples",
    "title": "17  Expected Improvement",
    "section": "17.7 Additional Examples",
    "text": "17.7 Additional Examples\n\n# Needed for the sklearn surrogates:\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn import linear_model\nfrom sklearn import tree\nimport pandas as pd\n\n\nkernel = 1 * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2))\nS_GP = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\n\n\nfrom spotpython.surrogate.kriging import Kriging\nimport numpy as np\nimport spotpython\nfrom spotpython.fun.objectivefunctions import Analytical\nfrom spotpython.spot import Spot\n\nS_K = Kriging(name='kriging',\n              seed=123,\n              log_level=50,\n              infill_criterion = \"y\",\n              n_theta=1,\n              method=\"interpolation\",\n              cod_type=\"norm\")\nfun = Analytical().fun_sphere\n\nfun_control = fun_control_init(\n    lower = np.array([-1,-1]),\n    upper = np.array([1,1]),\n    fun_evals = 25)\n\nspot_S_K = Spot(fun=fun,\n                     fun_control=fun_control,\n                     surrogate=S_K,\n                     design_control=design_control,\n                     surrogate_control=surrogate_control)\nspot_S_K.run()\n\nspotpython tuning: 0.09898480231445653 [##--------] 24.00% \nspotpython tuning: 0.011600518140914177 [###-------] 28.00% \nspotpython tuning: 0.003049615554913117 [###-------] 32.00% \nspotpython tuning: 0.003049615554913117 [####------] 36.00% \nspotpython tuning: 0.0005799644213399475 [####------] 40.00% \nspotpython tuning: 0.00032701651343083606 [####------] 44.00% \nspotpython tuning: 0.00026223112073428154 [#####-----] 48.00% \nspotpython tuning: 0.00025012027991100133 [#####-----] 52.00% \nspotpython tuning: 0.00025012027991100133 [######----] 56.00% \nspotpython tuning: 0.00025012027991100133 [######----] 60.00% \nspotpython tuning: 0.00025012027991100133 [######----] 64.00% \nspotpython tuning: 0.00025012027991100133 [#######---] 68.00% \nspotpython tuning: 0.0002490731534486115 [#######---] 72.00% \nspotpython tuning: 0.00024350109120356873 [########--] 76.00% \nspotpython tuning: 0.00019117601867302202 [########--] 80.00% \nspotpython tuning: 8.697745687224928e-05 [########--] 84.00% \nspotpython tuning: 7.454180600841285e-05 [#########-] 88.00% \nspotpython tuning: 7.393231742566199e-05 [#########-] 92.00% \nspotpython tuning: 7.393231742566199e-05 [##########] 96.00% \nspotpython tuning: 7.393231742566199e-05 [##########] 100.00% Done...\n\nExperiment saved to 000_res.pkl\n\n\n&lt;spotpython.spot.spot.Spot at 0x177464e60&gt;\n\n\n\nspot_S_K.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\nspot_S_K.surrogate.plot()\n\n\n\n\n\n\n\n\n\nspot_S_K.print_results()\n\nmin y: 7.393231742566199e-05\nx0: -0.00047899231068674524\nx1: 0.00858503836869498\n\n\n[['x0', np.float64(-0.00047899231068674524)],\n ['x1', np.float64(0.00858503836869498)]]\n\n\n\n17.7.1 Optimize on Surrogate\n\n\n17.7.2 Evaluate on Real Objective\n\n\n17.7.3 Impute / Infill new Points",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Expected Improvement</span>"
    ]
  },
  {
    "objectID": "012_num_spot_ei.html#tests",
    "href": "012_num_spot_ei.html#tests",
    "title": "17  Expected Improvement",
    "section": "17.8 Tests",
    "text": "17.8 Tests\n\nimport numpy as np\nfrom spotpython.spot import Spot\nfrom spotpython.fun.objectivefunctions import Analytical\n\nfun_sphere = Analytical().fun_sphere\n\nfun_control = fun_control_init(\n                    lower=np.array([-1, -1]),\n                    upper=np.array([1, 1]),\n                    n_points = 2)\nspot_1 = Spot(\n    fun=fun_sphere,\n    fun_control=fun_control,\n)\n\n# (S-2) Initial Design:\nspot_1.X = spot_1.design.scipy_lhd(\n    spot_1.design_control[\"init_size\"], lower=spot_1.lower, upper=spot_1.upper\n)\nprint(spot_1.X)\n\n# (S-3): Eval initial design:\nspot_1.y = spot_1.fun(spot_1.X)\nprint(spot_1.y)\n\nspot_1.fit_surrogate()\nX0 = spot_1.suggest_new_X()\nprint(X0)\nassert X0.size == spot_1.n_points * spot_1.k\n\n[[ 0.86352963  0.7892358 ]\n [-0.24407197 -0.83687436]\n [ 0.36481882  0.8375811 ]\n [ 0.415331    0.54468512]\n [-0.56395091 -0.77797854]\n [-0.90259409 -0.04899292]\n [-0.16484832  0.35724741]\n [ 0.05170659  0.07401196]\n [-0.78548145 -0.44638164]\n [ 0.64017497 -0.30363301]]\n[1.36857656 0.75992983 0.83463487 0.46918172 0.92329124 0.8170764\n 0.15480068 0.00815134 0.81623768 0.502017  ]\n[[0.02672918 0.02430251]\n [0.02673036 0.02430322]]",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Expected Improvement</span>"
    ]
  },
  {
    "objectID": "012_num_spot_ei.html#ei-the-famous-schonlau-example",
    "href": "012_num_spot_ei.html#ei-the-famous-schonlau-example",
    "title": "17  Expected Improvement",
    "section": "17.9 EI: The Famous Schonlau Example",
    "text": "17.9 EI: The Famous Schonlau Example\n\nX_train0 = np.array([1, 2, 3, 4, 12]).reshape(-1,1)\nX_train = np.linspace(start=0, stop=10, num=5).reshape(-1, 1)\n\n\nfrom spotpython.surrogate.kriging import Kriging\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nX_train = np.array([1., 2., 3., 4., 12.]).reshape(-1,1)\ny_train = np.array([0., -1.75, -2, -0.5, 5.])\n\nS = Kriging(name='kriging',  seed=123, log_level=50, n_theta=1, method=\"interpolation\", cod_type=\"norm\")\nS.fit(X_train, y_train)\n\nX = np.linspace(start=0, stop=13, num=1000).reshape(-1, 1)\nmean_prediction, std_prediction, ei = S.predict(X, return_val=\"all\")\n\nplt.scatter(X_train, y_train, label=\"Observations\")\nplt.plot(X, mean_prediction, label=\"Mean prediction\")\nif True:\n    plt.fill_between(\n        X.ravel(),\n        mean_prediction - 2 * std_prediction,\n        mean_prediction + 2 * std_prediction,\n        alpha=0.5,\n        label=r\"95% confidence interval\",\n    )\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"Gaussian process regression on noise-free dataset\")\n\n\n\n\n\n\n\n\n\n#plt.plot(X, y, label=r\"$f(x) = x \\sin(x)$\", linestyle=\"dotted\")\n# plt.scatter(X_train, y_train, label=\"Observations\")\nplt.plot(X, -ei, label=\"Expected Improvement\")\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"Gaussian process regression on noise-free dataset\")\n\n\n\n\n\n\n\n\n\nS.get_model_params()\n\n{'log_theta_lambda': array([-0.96348969]),\n 'U': array([[1.00000001e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n         0.00000000e+00],\n        [8.96936418e-01, 4.42159561e-01, 0.00000000e+00, 0.00000000e+00,\n         0.00000000e+00],\n        [6.49160127e-01, 7.11691192e-01, 2.68489834e-01, 0.00000000e+00,\n         0.00000000e+00],\n        [3.79752007e-01, 6.97817607e-01, 5.72781159e-01, 2.01892941e-01,\n         0.00000000e+00],\n        [2.62778955e-06, 4.93854753e-05, 5.35595721e-04, 3.72289632e-03,\n         9.99992933e-01]]),\n 'X': array([[ 1.],\n        [ 2.],\n        [ 3.],\n        [ 4.],\n        [12.]]),\n 'y': array([ 0.  , -1.75, -2.  , -0.5 ,  5.  ]),\n 'negLnLike': np.float64(1.3376589344577305)}",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Expected Improvement</span>"
    ]
  },
  {
    "objectID": "012_num_spot_ei.html#ei-the-forrester-example",
    "href": "012_num_spot_ei.html#ei-the-forrester-example",
    "title": "17  Expected Improvement",
    "section": "17.10 EI: The Forrester Example",
    "text": "17.10 EI: The Forrester Example\n\nfrom spotpython.surrogate.kriging import Kriging\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport spotpython\nfrom spotpython.fun.objectivefunctions import Analytical\nfrom spotpython.spot import Spot\n\n# exact x locations are unknown:\nX_train = np.array([0.0, 0.175, 0.225, 0.3, 0.35, 0.375, 0.5,1]).reshape(-1,1)\n\nfun = Analytical().fun_forrester\nfun_control = fun_control_init(\n    PREFIX=\"07_EI_FORRESTER\",\n    sigma=1.0,\n    seed=123,)\ny_train = fun(X_train, fun_control=fun_control)\n\nS = Kriging(name='kriging',  seed=123, log_level=50, n_theta=1, method=\"interpolation\", cod_type=\"norm\")\nS.fit(X_train, y_train)\n\nX = np.linspace(start=0, stop=1, num=1000).reshape(-1, 1)\nmean_prediction, std_prediction, ei = S.predict(X, return_val=\"all\")\n\nplt.scatter(X_train, y_train, label=\"Observations\")\nplt.plot(X, mean_prediction, label=\"Mean prediction\")\nif True:\n    plt.fill_between(\n        X.ravel(),\n        mean_prediction - 2 * std_prediction,\n        mean_prediction + 2 * std_prediction,\n        alpha=0.5,\n        label=r\"95% confidence interval\",\n    )\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"Gaussian process regression on noise-free dataset\")\n\n\n\n\n\n\n\n\n\n#plt.plot(X, y, label=r\"$f(x) = x \\sin(x)$\", linestyle=\"dotted\")\n# plt.scatter(X_train, y_train, label=\"Observations\")\nplt.plot(X, -ei, label=\"Expected Improvement\")\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"Gaussian process regression on noise-free dataset\")",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Expected Improvement</span>"
    ]
  },
  {
    "objectID": "012_num_spot_ei.html#noise",
    "href": "012_num_spot_ei.html#noise",
    "title": "17  Expected Improvement",
    "section": "17.11 Noise",
    "text": "17.11 Noise\n\nimport numpy as np\nimport spotpython\nfrom spotpython.fun.objectivefunctions import Analytical\nfrom spotpython.spot import Spot\nfrom spotpython.design.spacefilling import SpaceFilling\nfrom spotpython.surrogate.kriging import Kriging\nimport matplotlib.pyplot as plt\n\ngen = SpaceFilling(1)\nrng = np.random.RandomState(1)\nlower = np.array([-10])\nupper = np.array([10])\nfun = Analytical().fun_sphere\nfun_control = fun_control_init(\n    PREFIX=\"07_Y\",\n    sigma=2.0,\n    seed=123,)\nX = gen.scipy_lhd(10, lower=lower, upper = upper)\nprint(X)\ny = fun(X, fun_control=fun_control)\nprint(y)\ny.shape\nX_train = X.reshape(-1,1)\ny_train = y\n\nS = Kriging(name='kriging',\n            seed=123,\n            log_level=50,\n            n_theta=1,\n            method=\"interpolation\")\nS.fit(X_train, y_train)\n\nX_axis = np.linspace(start=-13, stop=13, num=1000).reshape(-1, 1)\nmean_prediction, std_prediction, ei = S.predict(X_axis, return_val=\"all\")\n\n#plt.plot(X, y, label=r\"$f(x) = x \\sin(x)$\", linestyle=\"dotted\")\nplt.scatter(X_train, y_train, label=\"Observations\")\n#plt.plot(X, ei, label=\"Expected Improvement\")\nplt.plot(X_axis, mean_prediction, label=\"mue\")\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"Sphere: Gaussian process regression on noisy dataset\")\n\n[[ 0.63529627]\n [-4.10764204]\n [-0.44071975]\n [ 9.63125638]\n [-8.3518118 ]\n [-3.62418901]\n [ 4.15331   ]\n [ 3.4468512 ]\n [ 6.36049088]\n [-7.77978539]]\n[-1.57464135 16.13714981  2.77008442 93.14904827 71.59322218 14.28895359\n 15.9770567  12.96468767 39.82265329 59.88028242]\n\n\n\n\n\n\n\n\n\n\nS.get_model_params()\n\n{'log_theta_lambda': array([-2.8650639]),\n 'U': array([[ 1.00000001e+00,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00],\n        [ 9.70233664e-01,  2.42170709e-01,  0.00000000e+00,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00],\n        [ 9.98422699e-01,  5.51288247e-02,  1.06274479e-02,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00],\n        [ 8.97612652e-01, -3.83100587e-01, -1.48544680e-01,\n          1.59561775e-01,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00],\n        [ 8.97802437e-01,  4.33533096e-01, -4.95341501e-02,\n          2.65097408e-02,  5.33240574e-02,  0.00000000e+00,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00],\n        [ 9.75897078e-01,  2.18154520e-01,  3.80893163e-03,\n         -1.06623799e-03, -1.89880937e-03,  3.77658329e-03,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00],\n        [ 9.83463162e-01, -1.70629980e-01, -4.39109597e-02,\n          3.68970891e-02,  7.81794822e-04,  6.46676677e-05,\n          1.98859254e-02,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00],\n        [ 9.89382452e-01, -1.37921302e-01, -3.34099058e-02,\n          2.61135398e-02,  5.33523731e-04,  4.66725261e-05,\n          1.66561653e-02,  4.92346777e-03,  0.00000000e+00,\n          0.00000000e+00],\n        [ 9.57003753e-01, -2.65908685e-01, -8.19094811e-02,\n          7.91152594e-02,  1.32031981e-03,  1.17850785e-04,\n          1.81285930e-02, -3.34173608e-03,  1.12448081e-02,\n          0.00000000e+00],\n        [ 9.09754374e-01,  4.10161726e-01, -4.09836684e-02,\n          2.16163708e-02,  4.40634520e-02, -7.94485222e-04,\n         -3.31779455e-04,  4.06237708e-05, -1.78780589e-04,\n          5.00610297e-03]]),\n 'X': array([[ 0.63529627],\n        [-4.10764204],\n        [-0.44071975],\n        [ 9.63125638],\n        [-8.3518118 ],\n        [-3.62418901],\n        [ 4.15331   ],\n        [ 3.4468512 ],\n        [ 6.36049088],\n        [-7.77978539]]),\n 'y': array([-1.57464135, 16.13714981,  2.77008442, 93.14904827, 71.59322218,\n        14.28895359, 15.9770567 , 12.96468767, 39.82265329, 59.88028242]),\n 'negLnLike': np.float64(23.978516035724688)}\n\n\n\nS = Kriging(name='kriging',\n            seed=123,\n            log_level=50,\n            n_theta=1,\n            method=\"regression\")\nS.fit(X_train, y_train)\n\nX_axis = np.linspace(start=-13, stop=13, num=1000).reshape(-1, 1)\nmean_prediction, std_prediction, ei = S.predict(X_axis, return_val=\"all\")\n\n#plt.plot(X, y, label=r\"$f(x) = x \\sin(x)$\", linestyle=\"dotted\")\nplt.scatter(X_train, y_train, label=\"Observations\")\n#plt.plot(X, ei, label=\"Expected Improvement\")\nplt.plot(X_axis, mean_prediction, label=\"mue\")\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"Sphere: Gaussian process regression with nugget on noisy dataset\")\n\n\n\n\n\n\n\n\n\nS.get_model_params()\n\n{'log_theta_lambda': array([-2.62131641, -3.75862539]),\n 'U': array([[ 1.00008716e+00,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00],\n        [ 9.48327184e-01,  3.17568707e-01,  0.00000000e+00,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00],\n        [ 9.97149951e-01,  7.28390322e-02,  2.36808169e-02,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00],\n        [ 8.27434508e-01, -4.42368906e-01, -1.65566198e-01,\n          3.04013241e-01,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00],\n        [ 8.27741190e-01,  5.46207104e-01, -6.50155056e-02,\n          5.81284294e-02,  9.52403399e-02,  0.00000000e+00,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00],\n        [ 9.58051531e-01,  2.86208289e-01,  6.68282049e-03,\n         -3.36541069e-03,  1.53206920e-04,  1.84499595e-02,\n          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00],\n        [ 9.71109280e-01, -2.16060531e-01, -4.64176726e-02,\n          8.25053371e-02,  8.45582501e-03, -4.90044955e-03,\n          3.71712011e-02,  0.00000000e+00,  0.00000000e+00,\n          0.00000000e+00],\n        [ 9.81377837e-01, -1.75909975e-01, -3.36315238e-02,\n          6.14634924e-02,  6.93957968e-03, -4.36266056e-03,\n          2.84741202e-02,  1.84593200e-02,  0.00000000e+00,\n          0.00000000e+00],\n        [ 9.25777067e-01, -3.26826942e-01, -9.19064015e-02,\n          1.61897427e-01,  1.02726000e-02, -4.96607986e-03,\n          3.03391347e-02,  4.64846247e-03,  2.37798355e-02,\n          0.00000000e+00],\n        [ 8.47153093e-01,  5.20486762e-01, -5.38733186e-02,\n          4.83017604e-02,  7.75510320e-02,  1.55114657e-03,\n         -6.49927513e-04, -1.94890748e-04, -8.83882576e-05,\n          1.86297412e-02]]),\n 'X': array([[ 0.63529627],\n        [-4.10764204],\n        [-0.44071975],\n        [ 9.63125638],\n        [-8.3518118 ],\n        [-3.62418901],\n        [ 4.15331   ],\n        [ 3.4468512 ],\n        [ 6.36049088],\n        [-7.77978539]]),\n 'y': array([-1.57464135, 16.13714981,  2.77008442, 93.14904827, 71.59322218,\n        14.28895359, 15.9770567 , 12.96468767, 39.82265329, 59.88028242]),\n 'negLnLike': np.float64(22.35624628588101)}",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Expected Improvement</span>"
    ]
  },
  {
    "objectID": "012_num_spot_ei.html#cubic-function",
    "href": "012_num_spot_ei.html#cubic-function",
    "title": "17  Expected Improvement",
    "section": "17.12 Cubic Function",
    "text": "17.12 Cubic Function\n\nimport numpy as np\nimport spotpython\nfrom spotpython.fun.objectivefunctions import Analytical\nfrom spotpython.spot import Spot\nfrom spotpython.design.spacefilling import SpaceFilling\nfrom spotpython.surrogate.kriging import Kriging\nimport matplotlib.pyplot as plt\n\ngen = SpaceFilling(1)\nrng = np.random.RandomState(1)\nlower = np.array([-10])\nupper = np.array([10])\nfun = Analytical().fun_cubed\nfun_control = fun_control_init(\n    PREFIX=\"07_Y\",\n    sigma=10.0,\n    seed=123,)\n\nX = gen.scipy_lhd(10, lower=lower, upper = upper)\nprint(X)\ny = fun(X, fun_control=fun_control)\nprint(y)\ny.shape\nX_train = X.reshape(-1,1)\ny_train = y\n\nS = Kriging(name='kriging',  seed=123, log_level=50, n_theta=1, method=\"interpolation\")\nS.fit(X_train, y_train)\n\nX_axis = np.linspace(start=-13, stop=13, num=1000).reshape(-1, 1)\nmean_prediction, std_prediction, ei = S.predict(X_axis, return_val=\"all\")\n\nplt.scatter(X_train, y_train, label=\"Observations\")\n#plt.plot(X, ei, label=\"Expected Improvement\")\nplt.plot(X_axis, mean_prediction, label=\"mue\")\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"Cubed: Gaussian process regression on noisy dataset\")\n\n[[ 0.63529627]\n [-4.10764204]\n [-0.44071975]\n [ 9.63125638]\n [-8.3518118 ]\n [-3.62418901]\n [ 4.15331   ]\n [ 3.4468512 ]\n [ 6.36049088]\n [-7.77978539]]\n[  -9.63480707  -72.98497325   12.7936499   895.34567477 -573.35961837\n  -41.83176425   65.27989461   46.37081417  254.1530734  -474.09587355]\n\n\n\n\n\n\n\n\n\n\nS = Kriging(name='kriging',  seed=123, log_level=0, n_theta=1, method=\"regression\")\nS.fit(X_train, y_train)\n\nX_axis = np.linspace(start=-13, stop=13, num=1000).reshape(-1, 1)\nmean_prediction, std_prediction, ei = S.predict(X_axis, return_val=\"all\")\n\nplt.scatter(X_train, y_train, label=\"Observations\")\n#plt.plot(X, ei, label=\"Expected Improvement\")\nplt.plot(X_axis, mean_prediction, label=\"mue\")\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"Cubed: Gaussian process with nugget regression on noisy dataset\")\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport spotpython\nfrom spotpython.fun.objectivefunctions import Analytical\nfrom spotpython.spot import Spot\nfrom spotpython.design.spacefilling import SpaceFilling\nfrom spotpython.surrogate.kriging import Kriging\nimport matplotlib.pyplot as plt\n\ngen = SpaceFilling(1)\nrng = np.random.RandomState(1)\nlower = np.array([-10])\nupper = np.array([10])\nfun = Analytical().fun_runge\nfun_control = fun_control_init(\n    PREFIX=\"07_Y\",\n    sigma=0.25,\n    seed=123,)\n\nX = gen.scipy_lhd(10, lower=lower, upper = upper)\nprint(X)\ny = fun(X, fun_control=fun_control)\nprint(y)\ny.shape\nX_train = X.reshape(-1,1)\ny_train = y\n\nS = Kriging(name='kriging',  seed=123, log_level=50, n_theta=1, method=\"interpolation\")\nS.fit(X_train, y_train)\n\nX_axis = np.linspace(start=-13, stop=13, num=1000).reshape(-1, 1)\nmean_prediction, std_prediction, ei = S.predict(X_axis, return_val=\"all\")\n\nplt.scatter(X_train, y_train, label=\"Observations\")\n#plt.plot(X, ei, label=\"Expected Improvement\")\nplt.plot(X_axis, mean_prediction, label=\"mue\")\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"Gaussian process regression on noisy dataset\")\n\n[[ 0.63529627]\n [-4.10764204]\n [-0.44071975]\n [ 9.63125638]\n [-8.3518118 ]\n [-3.62418901]\n [ 4.15331   ]\n [ 3.4468512 ]\n [ 6.36049088]\n [-7.77978539]]\n[ 0.46517267 -0.03599548  1.15933822  0.05915901  0.24419145  0.21502359\n -0.10432134  0.21312309 -0.05502681 -0.06434374]\n\n\n\n\n\n\n\n\n\n\nS = Kriging(name='kriging',\n            seed=123,\n            log_level=50,\n            n_theta=1,\n            method=\"regression\")\nS.fit(X_train, y_train)\n\nX_axis = np.linspace(start=-13, stop=13, num=1000).reshape(-1, 1)\nmean_prediction, std_prediction, ei = S.predict(X_axis, return_val=\"all\")\n\nplt.scatter(X_train, y_train, label=\"Observations\")\n#plt.plot(X, ei, label=\"Expected Improvement\")\nplt.plot(X_axis, mean_prediction, label=\"mue\")\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"Gaussian process regression with nugget on noisy dataset\")",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Expected Improvement</span>"
    ]
  },
  {
    "objectID": "012_num_spot_ei.html#modifying-lambda-search-space",
    "href": "012_num_spot_ei.html#modifying-lambda-search-space",
    "title": "17  Expected Improvement",
    "section": "17.13 Modifying Lambda Search Space",
    "text": "17.13 Modifying Lambda Search Space\n\nS = Kriging(name='kriging',\n            seed=123,\n            log_level=50,\n            n_theta=1,\n            method=\"regression\",\n            min_Lambda=0.1,\n            max_Lambda=10)\nS.fit(X_train, y_train)\n\nprint(f\"Lambda: {S.Lambda}\")\n\nLambda: -0.0698939568220746\n\n\n\nX_axis = np.linspace(start=-13, stop=13, num=1000).reshape(-1, 1)\nmean_prediction, std_prediction, ei = S.predict(X_axis, return_val=\"all\")\n\nplt.scatter(X_train, y_train, label=\"Observations\")\n#plt.plot(X, ei, label=\"Expected Improvement\")\nplt.plot(X_axis, mean_prediction, label=\"mue\")\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"Gaussian process regression with nugget on noisy dataset. Modified Lambda search space.\")",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Expected Improvement</span>"
    ]
  },
  {
    "objectID": "013_num_spot_noisy.html",
    "href": "013_num_spot_noisy.html",
    "title": "18  Handling Noise",
    "section": "",
    "text": "18.1 Example: Spot and the Noisy Sphere Function\nThis chapter demonstrates how noisy functions can be handled by Spot and how noise can be simulated, i.e., added to the objective function.\nimport numpy as np\nfrom math import inf\nfrom spotpython.fun.objectivefunctions import Analytical\nfrom spotpython.spot import Spot\nimport matplotlib.pyplot as plt\nfrom spotpython.utils.init import fun_control_init, get_spot_tensorboard_path\nfrom spotpython.utils.init import fun_control_init, design_control_init, surrogate_control_init\n\nPREFIX = \"08\"",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Handling Noise</span>"
    ]
  },
  {
    "objectID": "013_num_spot_noisy.html#example-spot-and-the-noisy-sphere-function",
    "href": "013_num_spot_noisy.html#example-spot-and-the-noisy-sphere-function",
    "title": "18  Handling Noise",
    "section": "",
    "text": "18.1.1 The Objective Function: Noisy Sphere\nThe spotpython package provides several classes of objective functions, which return a one-dimensional output \\(y=f(x)\\) for a given input \\(x\\) (independent variable). Several objective functions allow one- or multidimensional input, some also combinations of real-valued and categorial input values.\nAn objective function is considered as “analytical” if it can be described by a closed mathematical formula, e.g., \\[\nf(x, y) = x^2 + y^2.\n\\]\nTo simulate measurement errors, adding artificial noise to the function value \\(y\\) is a common practice, e.g.,:\n\\[\nf(x, y) = x^2 + y^2 + \\epsilon.\n\\]\nUsually, noise is assumed to be normally distributed with mean \\(\\mu=0\\) and standard deviation \\(\\sigma\\). spotpython uses numpy’s scale parameter, which specifies the standard deviation (spread or “width”) of the distribution is used. This must be a non-negative value, see https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html.\n\n\n\n\n\n\nExample: The sphere function without noise\n\n\n\nThe default setting does not use any noise.\n\nfrom spotpython.fun.objectivefunctions import Analytical\nfun = Analytical().fun_sphere\nx = np.linspace(-1,1,100).reshape(-1,1)\ny = fun(x)\nplt.figure()\nplt.plot(x,y, \"k\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample: The sphere function with noise\n\n\n\nNoise can be added to the sphere function as follows:\n\nfrom spotpython.fun.objectivefunctions import Analytical\nfun = Analytical(seed=123, sigma=0.02).fun_sphere\nx = np.linspace(-1,1,100).reshape(-1,1)\ny = fun(x)\nplt.figure()\nplt.plot(x,y, \"k\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n18.1.2 Reproducibility: Noise Generation and Seed Handling\nspotpython provides two mechanisms for generating random noise:\n\nThe seed is initialized once, i.e., when the objective function is instantiated. This can be done using the following call: fun = Analytical(sigma=0.02, seed=123).fun_sphere.\nThe seed is set every time the objective function is called. This can be done using the following call: y = fun(x, sigma=0.02, seed=123).\n\nThese two different ways lead to different results as explained in the following tables:\n\n\n\n\n\n\nExample: Noise added to the sphere function\n\n\n\nSince sigma is set to 0.02, noise is added to the function:\n\nfrom spotpython.fun.objectivefunctions import Analytical\nfun = Analytical(sigma=0.02, seed=123).fun_sphere\nx = np.array([1]).reshape(-1,1)\nfor i in range(3):\n    print(f\"{i}: {fun(x)}\")\n\n0: [0.98021757]\n1: [0.98021757]\n2: [0.98021757]\n\n\nThe seed is set once. Every call to fun() results in a different value. The whole experiment can be repeated, the initial seed is used to generate the same sequence as shown below:\n\n\n\n\n\n\n\n\nExample: Noise added to the sphere function\n\n\n\nSince sigma is set to 0.02, noise is added to the function:\n\nfrom spotpython.fun.objectivefunctions import Analytical\nfun = Analytical(sigma=0.02, seed=123).fun_sphere\nx = np.array([1]).reshape(-1,1)\nfor i in range(3):\n    print(f\"{i}: {fun(x)}\")\n\n0: [0.98021757]\n1: [0.98021757]\n2: [0.98021757]\n\n\n\n\nIf spotpython is used as a hyperparameter tuner, it is important that only one realization of the noise function is optimized. This behaviour can be accomplished by passing the same seed via the dictionary fun_control to every call of the objective function fun as shown below:\n\n\n\n\n\n\nExample: The same noise added to the sphere function\n\n\n\nSince sigma is set to 0.02, noise is added to the function:\n\nfrom spotpython.fun.objectivefunctions import Analytical\nfun = Analytical().fun_sphere\nfun_control = fun_control_init(\n    PREFIX=PREFIX,\n    sigma=0.02)\ny = fun(x, fun_control=fun_control)\nx = np.array([1]).reshape(-1,1)\nfor i in range(3):\n    print(f\"{i}: {fun(x)}\")\n\n0: [0.98021757]\n1: [0.98021757]\n2: [0.98021757]",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Handling Noise</span>"
    ]
  },
  {
    "objectID": "013_num_spot_noisy.html#spotpythons-noise-handling-approaches",
    "href": "013_num_spot_noisy.html#spotpythons-noise-handling-approaches",
    "title": "18  Handling Noise",
    "section": "18.2 spotpython’s Noise Handling Approaches",
    "text": "18.2 spotpython’s Noise Handling Approaches\nThe following setting will be used for the next steps:\n\nfun = Analytical().fun_sphere\nfun_control = fun_control_init(\n    PREFIX=PREFIX,\n    sigma=0.02,\n)\n\nspotpython is adopted as follows to cope with noisy functions:\n\nfun_repeats is set to a value larger than 1 (here: 2)\nnoise is set to true. Therefore, a nugget (Lambda) term is added to the correlation matrix\ninit size (of the design_control dictionary) is set to a value larger than 1 (here: 3)\n\n\nspot_1_noisy = Spot(fun=fun,\n                   fun_control=fun_control_init(\n                                    lower = np.array([-1]),\n                                    upper = np.array([1]),\n                                    fun_evals = 20,\n                                    fun_repeats = 2,\n                                    noise = True,\n                                    show_models=True),\n                   design_control=design_control_init(init_size=3, repeats=2),\n                   surrogate_control=surrogate_control_init(method=\"regression\"))\n\n\nspot_1_noisy.run()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.03475488114202547 [####------] 40.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.034754842384453005 [#####-----] 50.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.0347547994840775 [######----] 60.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.034754767383189285 [#######---] 70.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.03475472191365096 [########--] 80.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.03475462984552639 [#########-] 90.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.03475448487120397 [##########] 100.00% Done...\n\nExperiment saved to 000_res.pkl",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Handling Noise</span>"
    ]
  },
  {
    "objectID": "013_num_spot_noisy.html#print-the-results",
    "href": "013_num_spot_noisy.html#print-the-results",
    "title": "18  Handling Noise",
    "section": "18.3 Print the Results",
    "text": "18.3 Print the Results\n\nspot_1_noisy.print_results()\n\nmin y: 0.03475448487120397\nmin mean y: 0.03475448487120397\nx0: 0.18642554779644332\n\n\n[['x0', np.float64(0.18642554779644332)]]\n\n\n\nspot_1_noisy.plot_progress(log_y=False,\n    filename=\"./figures/\" + PREFIX + \"_progress.png\")\n\n\n\n\nProgress plot. Black dots denote results from the initial design. Red dots illustrate the improvement found by the surrogate model based optimization.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Handling Noise</span>"
    ]
  },
  {
    "objectID": "013_num_spot_noisy.html#noise-and-surrogates-the-nugget-effect",
    "href": "013_num_spot_noisy.html#noise-and-surrogates-the-nugget-effect",
    "title": "18  Handling Noise",
    "section": "18.4 Noise and Surrogates: The Nugget Effect",
    "text": "18.4 Noise and Surrogates: The Nugget Effect\n\n18.4.1 The Noisy Sphere\n\n18.4.1.1 The Data\n\nWe prepare some data first:\n\n\nimport numpy as np\nimport spotpython\nfrom spotpython.fun.objectivefunctions import Analytical\nfrom spotpython.spot import Spot\nfrom spotpython.design.spacefilling import SpaceFilling\nfrom spotpython.surrogate.kriging import Kriging\nimport matplotlib.pyplot as plt\n\ngen = SpaceFilling(1)\nrng = np.random.RandomState(1)\nlower = np.array([-10])\nupper = np.array([10])\nfun = Analytical().fun_sphere\nfun_control = fun_control_init(\n    PREFIX=PREFIX,\n    sigma=4)\nX = gen.scipy_lhd(10, lower=lower, upper = upper)\ny = fun(X, fun_control=fun_control)\nX_train = X.reshape(-1,1)\ny_train = y\n\n\nA surrogate without nugget is fitted to these data:\n\n\nS = Kriging(name='kriging',\n            n_theta=1,\n            method=\"interpolation\")\nS.fit(X_train, y_train)\n\nX_axis = np.linspace(start=-13, stop=13, num=1000).reshape(-1, 1)\nmean_prediction, std_prediction, ei = S.predict(X_axis, return_val=\"all\")\n\nplt.scatter(X_train, y_train, label=\"Observations\")\nplt.plot(X_axis, mean_prediction, label=\"mue\")\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"Sphere: Gaussian process regression on noisy dataset\")\n\n\n\n\n\n\n\n\n\nIn comparison to the surrogate without nugget, we fit a surrogate with nugget to the data:\n\n\nS_nug = Kriging(name='kriging',\n            n_theta=1,\n            method=\"regression\")\nS_nug.fit(X_train, y_train)\nX_axis = np.linspace(start=-13, stop=13, num=1000).reshape(-1, 1)\nmean_prediction, std_prediction, ei = S_nug.predict(X_axis, return_val=\"all\")\nplt.scatter(X_train, y_train, label=\"Observations\")\nplt.plot(X_axis, mean_prediction, label=\"mue\")\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"Sphere: Gaussian process regression with nugget on noisy dataset\")\n\n\n\n\n\n\n\n\n\nThe value of the nugget term can be extracted from the model as follows:\n\n\nS.Lambda\n\n\nS_nug.Lambda\n\nnp.float64(-2.983429108510847)\n\n\n\nWe see:\n\nthe first model S has no nugget,\nwhereas the second model has a nugget value (Lambda) larger than zero.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Handling Noise</span>"
    ]
  },
  {
    "objectID": "013_num_spot_noisy.html#exercises",
    "href": "013_num_spot_noisy.html#exercises",
    "title": "18  Handling Noise",
    "section": "18.5 Exercises",
    "text": "18.5 Exercises\n\n18.5.1 Noisy fun_cubed\n\nAnalyse the effect of noise on the fun_cubed function with the following settings:\n\n\nfun = Analytical().fun_cubed\nfun_control = fun_control_init(\n    sigma=10)\nlower = np.array([-10])\nupper = np.array([10])\n\n\n\n18.5.2 fun_runge\n\nAnalyse the effect of noise on the fun_runge function with the following settings:\n\n\nlower = np.array([-10])\nupper = np.array([10])\nfun = Analytical().fun_runge\nfun_control = fun_control_init(\n    sigma=0.25)\n\n\n\n18.5.3 fun_forrester\n\nAnalyse the effect of noise on the fun_forrester function with the following settings:\n\n\nlower = np.array([0])\nupper = np.array([1])\nfun = Analytical().fun_forrester\nfun_control = fun_control_init(\n    sigma=5)\n\n\n\n18.5.4 fun_xsin\n\nAnalyse the effect of noise on the fun_xsin function with the following settings:\n\n\nlower = np.array([-1.])\nupper = np.array([1.])\nfun = Analytical().fun_xsin\nfun_control = fun_control_init(    \n    sigma=0.5)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Handling Noise</span>"
    ]
  },
  {
    "objectID": "014_num_spot_ocba.html",
    "href": "014_num_spot_ocba.html",
    "title": "19  Optimal Computational Budget Allocation in spotpython",
    "section": "",
    "text": "Citation\nThis chapter demonstrates how noisy functions can be handled spotpython:\nIf this document has been useful to you and you wish to cite it in a scientific publication, please refer to the following paper, which can be found on arXiv: https://arxiv.org/abs/2307.10262.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Optimal Computational Budget Allocation in spotpython</span>"
    ]
  },
  {
    "objectID": "014_num_spot_ocba.html#citation",
    "href": "014_num_spot_ocba.html#citation",
    "title": "19  Optimal Computational Budget Allocation in spotpython",
    "section": "",
    "text": "@ARTICLE{bart23iArXiv,\n      author = {{Bartz-Beielstein}, Thomas},\n      title = \"{Hyperparameter Tuning Cookbook:\n          A guide for scikit-learn, PyTorch, river, and spotpython}\",\n     journal = {arXiv e-prints},\n    keywords = {Computer Science - Machine Learning,\n      Computer Science - Artificial Intelligence, 90C26, I.2.6, G.1.6},\n         year = 2023,\n        month = jul,\n          eid = {arXiv:2307.10262},\n          doi = {10.48550/arXiv.2307.10262},\narchivePrefix = {arXiv},\n       eprint = {2307.10262},\n primaryClass = {cs.LG}\n}",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Optimal Computational Budget Allocation in spotpython</span>"
    ]
  },
  {
    "objectID": "014_num_spot_ocba.html#example-spotpython-ocba-and-the-noisy-sphere-function",
    "href": "014_num_spot_ocba.html#example-spotpython-ocba-and-the-noisy-sphere-function",
    "title": "19  Optimal Computational Budget Allocation in spotpython",
    "section": "19.1 Example: spotpython, OCBA, and the Noisy Sphere Function",
    "text": "19.1 Example: spotpython, OCBA, and the Noisy Sphere Function\n\nimport numpy as np\nfrom math import inf\nfrom spotpython.fun.objectivefunctions import Analytical\nfrom spotpython.spot import Spot\nimport matplotlib.pyplot as plt\nfrom spotpython.utils.init import fun_control_init, get_spot_tensorboard_path\nfrom spotpython.utils.init import fun_control_init, design_control_init, surrogate_control_init\n\nPREFIX = \"14\"\n\n\n19.1.1 The Objective Function: Noisy Sphere\nThe spotpython package provides several classes of objective functions. We will use an analytical objective function with noise, i.e., a function that can be described by a (closed) formula: \\[f(x) = x^2 + \\epsilon\\]\nSince sigma is set to 0.1, noise is added to the function:\n\nfun = Analytical().fun_sphere\nfun_control = fun_control_init(\n    PREFIX=PREFIX,\n    sigma=0.1)\n\nA plot (Figure 19.1) illustrates the noise:\n\nx = np.linspace(-1,1,100).reshape(-1,1)\ny = fun(x, fun_control=fun_control)\nplt.figure()\nplt.plot(x,y, \"k\")\nplt.show()\n\n\n\n\n\n\n\nFigure 19.1: The noisy sphere function with noise.\n\n\n\n\n\n\n\n\n\n\n\nNoise Handling in spotpython\n\n\n\nspotpython has several options to cope with noisy functions:\n\nfun_repeats is set to a value larger than 1, e.g., 2, which means every function evaluation during the search on the surrogate is repeated twice. The mean of the two evaluations is used as the function value.\ninit size (of the design_control dictionary) is set to a value larger than 1 (here: 2).\nocba_delta is set to a value larger than 1 (here: 2). This means that the OCBA algorithm is used to allocate the computational budget optimally.\nUsing a nugget term in the surrogate model. This is done by setting method=\"regression\" in the surrogate_control dictionary. An example is given in Section 19.3.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Optimal Computational Budget Allocation in spotpython</span>"
    ]
  },
  {
    "objectID": "014_num_spot_ocba.html#sec-ocba-example",
    "href": "014_num_spot_ocba.html#sec-ocba-example",
    "title": "19  Optimal Computational Budget Allocation in spotpython",
    "section": "19.2 Using Optimal Computational Budget Allocation (OCBA)",
    "text": "19.2 Using Optimal Computational Budget Allocation (OCBA)\nThe Optimal Computational Budget Allocation (OCBA) algorithm is a powerful tool for efficiently distributing computational resources (Chen 2010). It is specifically designed to maximize the Probability of Correct Selection (PCS) while minimizing computational costs. By strategically allocating more simulation effort to design alternatives that are either more challenging to evaluate or more likely to yield optimal results, OCBA ensures an efficient use of resources. This approach enables researchers and decision-makers to achieve accurate outcomes more quickly and with fewer computational demands, making it an invaluable method for simulation optimization.\nThe OCBA algorithm is implemented in spotpython and can be used by setting ocba_delta to a value larger than 0. The source code is available in the spotpython package, see [DOC]. See also Bartz-Beielstein et al. (2011).\n\nExample 19.1 To reproduce the example from p.49 in Chen (2010), the following spotpython code can be used:\n\nimport numpy as np\nfrom spotpython.budget.ocba import get_ocba\nmean_y = np.array([1,2,3,4,5])\nvar_y = np.array([1,1,9,9,4])\nget_ocba(mean_y, var_y, 50)\n\narray([11,  9, 19,  9,  2])\n\n\n\n\n19.2.1 The Noisy Sphere\nWe will demonstrate the OCBA algorithm on the noisy sphere function defined in Section 19.1.1. The OCBA algorithm is used to allocate the computational budget optimally. This means that the function evaluations are repeated several times, and the best function value is used for the next iteration.\n\n\n\n\n\n\nVisualizing the Search of the OCBA Algorithm\n\n\n\n\nThe show_models parameter in the fun_control dictionary is set to True. This means that the surrogate model is shown during the search.\nTo keep the visualization simple, only the ground truth and the surrogate model are shown. The surrogate model is shown in blue, and the ground truth is shown in orange. The noisy function was shown in Figure 19.1.\n\n\n\n\nspot_1_noisy = Spot(fun=fun,\n                   fun_control=fun_control_init( \n                   lower = np.array([-1]),\n                   upper = np.array([1]),\n                   fun_evals = 20,\n                   fun_repeats = 1,\n                   noise = True,\n                   tolerance_x=0.0,\n                   ocba_delta = 2,                   \n                   show_models=True),\n                   design_control=design_control_init(init_size=5, repeats=2),\n                   surrogate_control=surrogate_control_init(method=\"regression\"))\n\n\nspot_1_noisy.run()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.005320352324811128 [######----] 55.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 0.000565644894785201 [######----] 60.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 1.591451674748005e-05 [######----] 65.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 6.91090859790612e-07 [#######---] 70.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 1.8899294735019857e-07 [########--] 75.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 1.2178603905219397e-07 [########--] 80.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 1.0212580354992866e-07 [########--] 85.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 9.357713991612833e-08 [#########-] 90.00% \n\n\n\n\n\n\n\n\n\nspotpython tuning: 9.357713991612833e-08 [##########] 100.00% Done...\n\nExperiment saved to 000_res.pkl\n\n\n\n\n19.2.2 Print the Results\n\nspot_1_noisy.print_results()\n\nmin y: 9.357713991612833e-08\nmin mean y: 9.357713991612833e-08\nx0: 0.0003059038082733334\n\n\n[['x0', np.float64(0.0003059038082733334)]]\n\n\n\nspot_1_noisy.plot_progress(log_y=True)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Optimal Computational Budget Allocation in spotpython</span>"
    ]
  },
  {
    "objectID": "014_num_spot_ocba.html#sec-nugget",
    "href": "014_num_spot_ocba.html#sec-nugget",
    "title": "19  Optimal Computational Budget Allocation in spotpython",
    "section": "19.3 Noise and Surrogates: The Nugget Effect",
    "text": "19.3 Noise and Surrogates: The Nugget Effect\nIn the previous example, we have seen that the fun_repeats parameter can be used to repeat function evaluations. This is useful when the function is noisy. However, it is not always possible to repeat function evaluations, e.g., when the function is expensive to evaluate. In this case, we can use a surrogate model with a nugget term. The nugget term is a small value that is added to the diagonal of the covariance matrix. This allows the surrogate model to fit the data better, even if the data is noisy. The nugget term is added, if method=\"regression\" is set in the surrogate_control dictionary.\n\n19.3.1 The Noisy Sphere\n\n19.3.1.1 The Data\nWe prepare some data first:\n\nimport numpy as np\nimport spotpython\nfrom spotpython.fun.objectivefunctions import Analytical\nfrom spotpython.spot import Spot\nfrom spotpython.design.spacefilling import SpaceFilling\nfrom spotpython.surrogate.kriging import Kriging\nimport matplotlib.pyplot as plt\n\ngen = SpaceFilling(1)\nrng = np.random.RandomState(1)\nlower = np.array([-10])\nupper = np.array([10])\nfun = Analytical().fun_sphere\nfun_control = fun_control_init(    \n    sigma=2,\n    seed=125)\nX = gen.scipy_lhd(10, lower=lower, upper = upper)\ny = fun(X, fun_control=fun_control)\nX_train = X.reshape(-1,1)\ny_train = y\n\nA surrogate without nugget is fitted to these data:\n\nS = Kriging(name='kriging',\n            seed=123,\n            log_level=50,\n            n_theta=1,\n            method=\"interpolation\")\nS.fit(X_train, y_train)\n\nX_axis = np.linspace(start=-13, stop=13, num=1000).reshape(-1, 1)\nmean_prediction, std_prediction, ei = S.predict(X_axis, return_val=\"all\")\n\nplt.scatter(X_train, y_train, label=\"Observations\")\nplt.plot(X_axis, mean_prediction, label=\"mue\")\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"Sphere: Gaussian process regression on noisy dataset\")\n\n\n\n\n\n\n\n\nIn comparison to the surrogate without nugget, we fit a surrogate with nugget to the data:\n\nS_nug = Kriging(name='kriging',\n            seed=123,\n            log_level=50,\n            n_theta=1,\n            method=\"regression\")\nS_nug.fit(X_train, y_train)\nX_axis = np.linspace(start=-13, stop=13, num=1000).reshape(-1, 1)\nmean_prediction, std_prediction, ei = S_nug.predict(X_axis, return_val=\"all\")\nplt.scatter(X_train, y_train, label=\"Observations\")\nplt.plot(X_axis, mean_prediction, label=\"mue\")\nplt.legend()\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$f(x)$\")\n_ = plt.title(\"Sphere: Gaussian process regression with nugget on noisy dataset\")\n\n\n\n\n\n\n\n\nThe value of the nugget term can be extracted from the model as follows:\n\nS.Lambda\n\n\n10**S_nug.Lambda\n\nnp.float64(0.0002592770433217388)\n\n\nWe see:\n\nthe first model S has no nugget,\nwhereas the second model has a nugget value (Lambda) larger than zero.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Optimal Computational Budget Allocation in spotpython</span>"
    ]
  },
  {
    "objectID": "014_num_spot_ocba.html#exercises",
    "href": "014_num_spot_ocba.html#exercises",
    "title": "19  Optimal Computational Budget Allocation in spotpython",
    "section": "19.4 Exercises",
    "text": "19.4 Exercises\n\n19.4.1 Noisy fun_cubed\nAnalyse the effect of noise on the fun_cubed function with the following settings:\n\nfun = Analytical().fun_cubed\nfun_control = fun_control_init(    \n    sigma=10,\n    seed=123)\nlower = np.array([-10])\nupper = np.array([10])\n\n\n\n19.4.2 fun_runge\nAnalyse the effect of noise on the fun_runge function with the following settings:\n\nlower = np.array([-10])\nupper = np.array([10])\nfun = Analytical().fun_runge\nfun_control = fun_control_init(    \n    sigma=0.25,\n    seed=123)\n\n\n\n19.4.3 fun_forrester\nAnalyse the effect of noise on the fun_forrester function with the following settings:\n\nlower = np.array([0])\nupper = np.array([1])\nfun = Analytical().fun_forrester\nfun_control = {\"sigma\": 5,\n               \"seed\": 123}\n\n\n\n19.4.4 fun_xsin\nAnalyse the effect of noise on the fun_xsin function with the following settings:\n\nlower = np.array([-1.])\nupper = np.array([1.])\nfun = Analytical().fun_xsin\nfun_control = fun_control_init(    \n    sigma=0.5,\n    seed=123)",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Optimal Computational Budget Allocation in spotpython</span>"
    ]
  },
  {
    "objectID": "014_num_spot_ocba.html#jupyter-notebook",
    "href": "014_num_spot_ocba.html#jupyter-notebook",
    "title": "19  Optimal Computational Budget Allocation in spotpython",
    "section": "19.5 Jupyter Notebook",
    "text": "19.5 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this chapter is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository\n\n\n\n\n\n\n\nBartz-Beielstein, Thomas, Martina Friese, Martin Zaefferer, Boris Naujoks, Oliver Flasch, Wolfgang Konen, and Patrick Koch. 2011. “Noisy optimization with sequential parameter optimization and optimal computational budget allocation.” In Proceedings of the 13th Annual Conference Companion on Genetic and Evolutionary Computation, 119–20. New York, NY, USA: ACM.\n\n\nChen, Chun Hung. 2010. Stochastic simulation optimization: an optimal computing budget allocation. World Scientific.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Optimal Computational Budget Allocation in spotpython</span>"
    ]
  },
  {
    "objectID": "015_num_spot_correlation_p.html",
    "href": "015_num_spot_correlation_p.html",
    "title": "20  Kriging with Varying Correlation-p",
    "section": "",
    "text": "20.1 Example: Spot Surrogate and the 2-dim Sphere Function\nThis chapter illustrates the difference between Kriging models with varying p. The difference is illustrated with the help of the spotpython package.\nimport numpy as np\nfrom math import inf\nfrom spotpython.fun.objectivefunctions import Analytical\nfrom spotpython.spot import Spot\nfrom spotpython.utils.init import fun_control_init, surrogate_control_init\nPREFIX=\"015\"",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Kriging with Varying Correlation-p</span>"
    ]
  },
  {
    "objectID": "015_num_spot_correlation_p.html#example-spot-surrogate-and-the-2-dim-sphere-function",
    "href": "015_num_spot_correlation_p.html#example-spot-surrogate-and-the-2-dim-sphere-function",
    "title": "20  Kriging with Varying Correlation-p",
    "section": "",
    "text": "20.1.1 The Objective Function: 2-dim Sphere\n\nThe spotpython package provides several classes of objective functions.\nWe will use an analytical objective function, i.e., a function that can be described by a (closed) formula: \\[f(x, y) = x^2 + y^2\\]\nThe size of the lower bound vector determines the problem dimension.\nHere we will use np.array([-1, -1]), i.e., a two-dim function.\n\n\nfun = Analytical().fun_sphere\nfun_control = fun_control_init(PREFIX=PREFIX,\n                               lower = np.array([-1, -1]),\n                               upper = np.array([1, 1]))\n\n\nAlthough the default spot surrogate model is an isotropic Kriging model, we will explicitly set the theta parameter to a value of 1 for both dimensions. This is done to illustrate the difference between isotropic and anisotropic Kriging models.\n\n\nsurrogate_control=surrogate_control_init(n_p=1,\n                                         p_val=2.0,)\n\n\nspot_2 = Spot(fun=fun,\n                   fun_control=fun_control,\n                   surrogate_control=surrogate_control)\n\nspot_2.run()\n\nspotpython tuning: 0.0013050614212698486 [#######---] 73.33% \nspotpython tuning: 0.0003479187873901382 [########--] 80.00% \nspotpython tuning: 0.00022767416623665655 [#########-] 86.67% \nspotpython tuning: 0.00020787497784734184 [#########-] 93.33% \nspotpython tuning: 0.00020393508736265477 [##########] 100.00% Done...\n\nExperiment saved to 015_res.pkl\n\n\n&lt;spotpython.spot.spot.Spot at 0x1082f2630&gt;\n\n\n\n\n20.1.2 Results\n\nspot_2.print_results()\n\nmin y: 0.00020393508736265477\nx0: 0.014161858193549292\nx1: 0.0018376234294478113\n\n\n[['x0', np.float64(0.014161858193549292)],\n ['x1', np.float64(0.0018376234294478113)]]\n\n\n\nspot_2.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\nspot_2.surrogate.plot()",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Kriging with Varying Correlation-p</span>"
    ]
  },
  {
    "objectID": "015_num_spot_correlation_p.html#example-with-modified-p",
    "href": "015_num_spot_correlation_p.html#example-with-modified-p",
    "title": "20  Kriging with Varying Correlation-p",
    "section": "20.2 Example With Modified p",
    "text": "20.2 Example With Modified p\n\nWe can use set p to a value other than 2 to obtain a different Kriging model.\n\n\nsurrogate_control = surrogate_control_init(n_p=1,\n                                           p_val=1.0)\nspot_2_p1= Spot(fun=fun,\n                    fun_control=fun_control,\n                    surrogate_control=surrogate_control)\nspot_2_p1.run()\n\nspotpython tuning: 0.0013050614212698486 [#######---] 73.33% \nspotpython tuning: 0.0003479187873901382 [########--] 80.00% \nspotpython tuning: 0.00022767416623665655 [#########-] 86.67% \nspotpython tuning: 0.00020787497784734184 [#########-] 93.33% \nspotpython tuning: 0.00020393508736265477 [##########] 100.00% Done...\n\nExperiment saved to 015_res.pkl\n\n\n&lt;spotpython.spot.spot.Spot at 0x1633819a0&gt;\n\n\n\nThe search progress of the optimization with the anisotropic model can be visualized:\n\n\nspot_2_p1.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\nspot_2_p1.print_results()\n\nmin y: 0.00020393508736265477\nx0: 0.014161858193549292\nx1: 0.0018376234294478113\n\n\n[['x0', np.float64(0.014161858193549292)],\n ['x1', np.float64(0.0018376234294478113)]]\n\n\n\nspot_2_p1.surrogate.plot()\n\n\n\n\n\n\n\n\n\n20.2.1 Taking a Look at the p Values\n\n20.2.1.1 p Values from the spot Model\n\nWe can check, which p values the spot model has used:\nThe p values from the surrogate can be printed as follows:\n\n\nspot_2_p1.surrogate.p\n\n2\n\n\n\nSince the surrogate from the isotropic setting was stored as spot_2, we can also take a look at the theta value from this model:\n\n\nspot_2.surrogate.p\n\n2",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Kriging with Varying Correlation-p</span>"
    ]
  },
  {
    "objectID": "015_num_spot_correlation_p.html#optimization-of-the-p-values",
    "href": "015_num_spot_correlation_p.html#optimization-of-the-p-values",
    "title": "20  Kriging with Varying Correlation-p",
    "section": "20.3 Optimization of the p Values",
    "text": "20.3 Optimization of the p Values\n\nsurrogate_control = surrogate_control_init(n_p=1,\n                                           optim_p=True)\nspot_2_pm= Spot(fun=fun,\n                    fun_control=fun_control,\n                    surrogate_control=surrogate_control)\nspot_2_pm.run()\n\nspotpython tuning: 0.0013050614212698486 [#######---] 73.33% \nspotpython tuning: 0.0003479187873901382 [########--] 80.00% \nspotpython tuning: 0.00022767416623665655 [#########-] 86.67% \nspotpython tuning: 0.00020787497784734184 [#########-] 93.33% \nspotpython tuning: 0.00020393508736265477 [##########] 100.00% Done...\n\nExperiment saved to 015_res.pkl\n\n\n&lt;spotpython.spot.spot.Spot at 0x163510980&gt;\n\n\n\nspot_2_pm.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\nspot_2_pm.print_results()\n\nmin y: 0.00020393508736265477\nx0: 0.014161858193549292\nx1: 0.0018376234294478113\n\n\n[['x0', np.float64(0.014161858193549292)],\n ['x1', np.float64(0.0018376234294478113)]]\n\n\n\nspot_2_pm.surrogate.plot()\n\n\n\n\n\n\n\n\n\nspot_2_pm.surrogate.p\n\n2",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Kriging with Varying Correlation-p</span>"
    ]
  },
  {
    "objectID": "015_num_spot_correlation_p.html#optimization-of-multiple-p-values",
    "href": "015_num_spot_correlation_p.html#optimization-of-multiple-p-values",
    "title": "20  Kriging with Varying Correlation-p",
    "section": "20.4 Optimization of Multiple p Values",
    "text": "20.4 Optimization of Multiple p Values\n\nsurrogate_control = surrogate_control_init(n_p=2,\n                                           optim_p=True)\nspot_2_pmo= Spot(fun=fun,\n                    fun_control=fun_control,\n                    surrogate_control=surrogate_control)\nspot_2_pmo.run()\n\nspotpython tuning: 0.0013050614212698486 [#######---] 73.33% \nspotpython tuning: 0.0003479187873901382 [########--] 80.00% \nspotpython tuning: 0.00022767416623665655 [#########-] 86.67% \nspotpython tuning: 0.00020787497784734184 [#########-] 93.33% \nspotpython tuning: 0.00020393508736265477 [##########] 100.00% Done...\n\nExperiment saved to 015_res.pkl\n\n\n&lt;spotpython.spot.spot.Spot at 0x163dc0c50&gt;\n\n\n\nspot_2_pmo.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\n\nspot_2_pmo.print_results()\n\nmin y: 0.00020393508736265477\nx0: 0.014161858193549292\nx1: 0.0018376234294478113\n\n\n[['x0', np.float64(0.014161858193549292)],\n ['x1', np.float64(0.0018376234294478113)]]\n\n\n\nspot_2_pmo.surrogate.plot()\n\n\n\n\n\n\n\n\n\nspot_2_pmo.surrogate.p\n\n2",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Kriging with Varying Correlation-p</span>"
    ]
  },
  {
    "objectID": "015_num_spot_correlation_p.html#exercises",
    "href": "015_num_spot_correlation_p.html#exercises",
    "title": "20  Kriging with Varying Correlation-p",
    "section": "20.5 Exercises",
    "text": "20.5 Exercises\n\n20.5.1 fun_branin\n\nDescribe the function.\n\nThe input dimension is 2. The search range is \\(-5 \\leq x_1 \\leq 10\\) and \\(0 \\leq x_2 \\leq 15\\).\n\nCompare the results from spotpython runs with different options for p.\nModify the termination criterion: instead of the number of evaluations (which is specified via fun_evals), the time should be used as the termination criterion. This can be done as follows (max_time=1 specifies a run time of one minute):\n\n\nfun_evals=inf,\nmax_time=1,\n\n\n\n20.5.2 fun_sin_cos\n\nDescribe the function.\n\nThe input dimension is 2. The search range is \\(-2\\pi \\leq x_1 \\leq 2\\pi\\) and \\(-2\\pi \\leq x_2 \\leq 2\\pi\\).\n\nCompare the results from spotpython run a) with isotropic and b) anisotropic surrogate models.\nModify the termination criterion (max_time instead of fun_evals) as described for fun_branin.\n\n\n\n20.5.3 fun_runge\n\nDescribe the function.\n\nThe input dimension is 2. The search range is \\(-5 \\leq x_1 \\leq 5\\) and \\(-5 \\leq x_2 \\leq 5\\).\n\nCompare the results from spotpython runs with different options for p.\nModify the termination criterion (max_time instead of fun_evals) as described for fun_branin.\n\n\n\n20.5.4 fun_wingwt\n\nDescribe the function.\n\nThe input dimension is 10. The search ranges are between 0 and 1 (values are mapped internally to their natural bounds).\n\nCompare the results from spotpython runs with different options for p.\nModify the termination criterion (max_time instead of fun_evals) as described for fun_branin.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Kriging with Varying Correlation-p</span>"
    ]
  },
  {
    "objectID": "015_num_spot_correlation_p.html#jupyter-notebook",
    "href": "015_num_spot_correlation_p.html#jupyter-notebook",
    "title": "20  Kriging with Varying Correlation-p",
    "section": "20.6 Jupyter Notebook",
    "text": "20.6 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Kriging with Varying Correlation-p</span>"
    ]
  },
  {
    "objectID": "016_num_spot_factorial.html",
    "href": "016_num_spot_factorial.html",
    "title": "21  Factorial Variables",
    "section": "",
    "text": "21.1 Jupyter Notebook\nUntil now, we have considered continuous variables. However, in many applications, the variables are not continuous, but rather discrete or categorical. For example, the number of layers in a neural network, the number of trees in a random forest, or the type of kernel in a support vector machine are all discrete variables. In the following, we will consider a simple example with two numerical variables and one categorical variable.\nFirst, we generate the test data set for fitting the Kriging model. We use the SpaceFilling class to generate the first two diemnsion of \\(n=30\\) design points. The third dimension is a categorical variable, which can take the values \\(0\\), \\(1\\), or \\(2\\).\nThe objective function is the fun_branin_factor in the analytical class [SOURCE]. It calculates the Branin function of \\((x_1, x_2)\\) with an additional factor based on the value of \\(x_3\\). If \\(x_3 = 1\\), the value of the Branin function is increased by 10. If \\(x_3 = 2\\), the value of the Branin function is decreased by 10. Otherwise, the value of the Branin function is not changed.\nWe fit two Kriging models, one with three numerical variables and one with two numerical variables and one categorical variable. We then compare the predictions of the two models.\nWe can now compare the predictions of the two models. We generate a new test data set and calculate the sum of the absolute differences between the predictions of the two models and the true values of the objective function. If the categorical variable is important, the sum of the absolute differences should be smaller than if the categorical variable is not important.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Factorial Variables</span>"
    ]
  },
  {
    "objectID": "016_num_spot_factorial.html#jupyter-notebook",
    "href": "016_num_spot_factorial.html#jupyter-notebook",
    "title": "21  Factorial Variables",
    "section": "",
    "text": "Note\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Factorial Variables</span>"
    ]
  },
  {
    "objectID": "017_num_spot_user_function.html",
    "href": "017_num_spot_user_function.html",
    "title": "22  User-Specified Functions: Extending the Analytical Class",
    "section": "",
    "text": "22.1 Software Requirements\nThis chapter illustrates how user-specified functions can be optimized and analyzed. It covers singe-objective function in Section 22.2 and multi-objective functions in Section 22.6, and how to use the spotpython package to optimize them. It shows a simple approach to define a user-specified function, both for single- and multi-objective optimization, and how to extend the Analytical class to create a custom function.\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom spotpython.fun.objectivefunctions import Analytical\nfrom spotpython.utils.init import fun_control_init, surrogate_control_init\nfrom spotpython.spot import Spot",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>User-Specified Functions: Extending the Analytical Class</span>"
    ]
  },
  {
    "objectID": "017_num_spot_user_function.html#software-requirements",
    "href": "017_num_spot_user_function.html#software-requirements",
    "title": "22  User-Specified Functions: Extending the Analytical Class",
    "section": "",
    "text": "The code examples in this chapter require the spotpython package, which can be installed via pip.\nFurthermore, the following Python packages are required:",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>User-Specified Functions: Extending the Analytical Class</span>"
    ]
  },
  {
    "objectID": "017_num_spot_user_function.html#sec-single-objective",
    "href": "017_num_spot_user_function.html#sec-single-objective",
    "title": "22  User-Specified Functions: Extending the Analytical Class",
    "section": "22.2 The Single-Objective Function: User Specified",
    "text": "22.2 The Single-Objective Function: User Specified\nWe will use an analytical objective function, i.e., a function that can be described by a (closed) formula: \\[\nf(x) = \\sum_i^k x_i^4.\n\\]\nThis function is continuous, convex and unimodal. Since it returns one value for each input vector, it is a single-objective function. Multiple-objective functions can also be handled by spotpython. They are covered in Section 22.6.\nThe global minimum of the single-objective function is \\[\nf(x) = 0, \\text{at } x = (0,0, \\ldots, 0).\n\\]\nIt can be implemented in Python as follows:\n\ndef user_fun(X):\n    return(np.sum((X) **4, axis=1))\n\nFor example, if we have \\(X = (1, 2, 3)\\), then \\[\nf(x) = 1^4 + 2^4 + 3^4 = 1 + 16 + 81 = 98,\n\\] and if we have \\(X = (4, 5, 6)\\), then \\[\nf(x) = 4^4 + 5^4 + 6^4 = 256 + 625 + 1296 = 2177.\n\\]\nWe can pass a 2D array to the function, and it will return a 1D array with the results for each row:\n\nuser_fun(np.array([[1, 2, 3], [4, 5, 6]]))\n\narray([  98, 2177])\n\n\nTo make user_fun compatible with the spotpython package, we need to extend its argument list, so that it can handle the fun_control dictionary.\n\ndef user_fun(X, fun_control=None):\n    return(np.sum((X) **4, axis=1))\n\nAlternatively, you can add the **kwargs argument to the function, which will allow you to pass any additional keyword arguments:\n\ndef user_fun(X, **kwargs):\n    return(np.sum((X) **4, axis=1))\n\n\nfun_control = fun_control_init(\n              lower = np.array( [-1, -1]),\n              upper = np.array([1, 1]),\n)\nS = Spot(fun=user_fun,\n                 fun_control=fun_control)\nS.run()\nS.plot_progress()\n\nspotpython tuning: 3.715394917589437e-05 [#######---] 73.33% \nspotpython tuning: 3.715394917589437e-05 [########--] 80.00% \nspotpython tuning: 3.715394917589437e-05 [#########-] 86.67% \nspotpython tuning: 3.715394917589437e-05 [#########-] 93.33% \nspotpython tuning: 3.715394917589437e-05 [##########] 100.00% Done...\n\nExperiment saved to 000_res.pkl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSummary: Using spotpython with Single-Objective User-Specified Functions\n\n\n\n\nspotpython accepts user-specified functions that can be defined in Python.\nThe function should accept a 2D array as input and return a 1D array as output.\nThe function can be defined with an additional argument fun_control to handle control parameters.\nThe fun_control dictionary can be initialized with the fun_control_init function, which allows you to specify the bounds of the input variables.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>User-Specified Functions: Extending the Analytical Class</span>"
    ]
  },
  {
    "objectID": "017_num_spot_user_function.html#the-objective-function-extending-the-analytical-class",
    "href": "017_num_spot_user_function.html#the-objective-function-extending-the-analytical-class",
    "title": "22  User-Specified Functions: Extending the Analytical Class",
    "section": "22.3 The Objective Function: Extending the Analytical Class",
    "text": "22.3 The Objective Function: Extending the Analytical Class\n\nThe Analytical class is a base class for analytical functions in the spotpython package.\nIt provides a framework for defining and evaluating analytical functions, including the ability to add noise to the output.\nThe Analytical class can be extended as follows:\n\n\nfrom typing import Optional, Dict\n\nclass UserAnalytical(Analytical):\n    def fun_user_function(self, X: np.ndarray, fun_control: Optional[Dict] = None) -&gt; np.ndarray:\n        \"\"\"\n        Custom new function: f(x) = x^4\n        \n        Args:\n            X (np.ndarray): Input data as a 2D array.\n            fun_control (Optional[Dict]): Control parameters for the function.\n        \n        Returns:\n            np.ndarray: Computed values with optional noise.\n        \n        Examples:\n            &gt;&gt;&gt; import numpy as np\n            &gt;&gt;&gt; X = np.array([[1, 2, 3], [4, 5, 6]])\n            &gt;&gt;&gt; fun = UserAnalytical()\n            &gt;&gt;&gt; fun.fun_user_function(X)\n        \"\"\"\n        X = self._prepare_input_data(X, fun_control)\n     \n        offset = np.ones(X.shape[1]) * self.offset\n        y = np.sum((X - offset) **4, axis=1) \n\n        # Add noise if specified in fun_control\n        return self._add_noise(y)\n\n\nIn comparison to the user_fun function, the UserAnalytical class provides additional functionality, such as adding noise to the output and preparing the input data.\nFirst, we use the user_fun function as above.\n\n\nuser_fun = UserAnalytical()\nX = np.array([[0, 0, 0], [1, 1, 1]])\nresults = user_fun.fun_user_function(X)\nprint(results)\n\n[0. 3.]\n\n\n\nThen we can add an offset to the function, which will shift the function by a constant value. This is useful for testing the optimization algorithm’s ability to find the global minimum.\n\n\nuser_fun = UserAnalytical(offset=1.0)\nX = np.array([[0, 0, 0], [1, 1, 1]])\nresults = user_fun.fun_user_function(X)\nprint(results)\n\n[3. 0.]\n\n\n\nAnd, we can add noise to the function, which will add a random value to the output. This is useful for testing the optimization algorithm’s ability to find the global minimum in the presence of noise.\n\n\nuser_fun = UserAnalytical(sigma=1.0)\nX = np.array([[0, 0, 0], [1, 1, 1]])\nresults = user_fun.fun_user_function(X)\nprint(results)\n\n[0.06691138 3.11495313]\n\n\n\nHere is an example of how to use the UserAnalytical class with the spotpython package:\n\n\nuser_fun = UserAnalytical().fun_user_function\nfun_control = fun_control_init(\n              PREFIX=\"USER\",              \n              lower = -1.0*np.ones(2),\n              upper = np.ones(2),\n              var_name=[\"User Pressure\", \"User Temp\"],\n              TENSORBOARD_CLEAN=True,\n              tensorboard_log=True)\nspot_user = Spot(fun=user_fun,\n                  fun_control=fun_control)\nspot_user.run()\n\nMoving TENSORBOARD_PATH: runs/ to TENSORBOARD_PATH_OLD: runs_OLD/runs_2025_06_15_12_34_24_0\nCreated spot_tensorboard_path: runs/spot_logs/USER_maans08_2025-06-15_12-34-24 for SummaryWriter()\nspotpython tuning: 3.715394917589437e-05 [#######---] 73.33% \nspotpython tuning: 3.715394917589437e-05 [########--] 80.00% \nspotpython tuning: 3.715394917589437e-05 [#########-] 86.67% \nspotpython tuning: 3.715394917589437e-05 [#########-] 93.33% \nspotpython tuning: 3.715394917589437e-05 [##########] 100.00% Done...\n\nExperiment saved to USER_res.pkl\n\n\n&lt;spotpython.spot.spot.Spot at 0x302e1bf50&gt;",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>User-Specified Functions: Extending the Analytical Class</span>"
    ]
  },
  {
    "objectID": "017_num_spot_user_function.html#results",
    "href": "017_num_spot_user_function.html#results",
    "title": "22  User-Specified Functions: Extending the Analytical Class",
    "section": "22.4 Results",
    "text": "22.4 Results\n\n_ = spot_user.print_results()\n\nmin y: 3.715394917589437e-05\nUser Pressure: 0.05170658955305796\nUser Temp: 0.07401195908206382\n\n\n\nspot_user.plot_progress()",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>User-Specified Functions: Extending the Analytical Class</span>"
    ]
  },
  {
    "objectID": "017_num_spot_user_function.html#a-contour-plot",
    "href": "017_num_spot_user_function.html#a-contour-plot",
    "title": "22  User-Specified Functions: Extending the Analytical Class",
    "section": "22.5 A Contour Plot",
    "text": "22.5 A Contour Plot\nWe can select two dimensions, say \\(i=0\\) and \\(j=1\\), and generate a contour plot as follows.\n\n\n\n\n\n\nNote:\n\n\n\nWe have specified identical min_z and max_z values to generate comparable plots.\n\n\n\nspot_user.plot_contour(i=0, j=1, min_z=0, max_z=2.25)\n\n\n\n\n\n\n\n\n\nThe variable importance:\n\n\n_ = spot_user.print_importance()\n\nUser Pressure:  62.089314080820216\nUser Temp:  100.0\n\n\n\nspot_user.plot_importance()",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>User-Specified Functions: Extending the Analytical Class</span>"
    ]
  },
  {
    "objectID": "017_num_spot_user_function.html#sec-multi-objective",
    "href": "017_num_spot_user_function.html#sec-multi-objective",
    "title": "22  User-Specified Functions: Extending the Analytical Class",
    "section": "22.6 Multi-Objective Functions",
    "text": "22.6 Multi-Objective Functions\n\nThe spotpython package can also handle multi-objective functions, which are functions that return multiple values for each input vector.\nAs noted in Section 22.2, in the single-objective case, the function returns one value for each input vector and spotpython expects a 1D array as output.\nIf the function returns a 2D array as output, spotpython will treat it as a multi-objective function result.\n\n\n22.6.1 Response Surface Experiment\nMyers, Montgomery, and Anderson-Cook (2016) describe a response surface experiment where three input variables (reaction time, reaction temperature, and percent catalyst) were used to model two characteristics of a chemical reaction: percent conversion and thermal activity. Their model is based on the following equations:\n\\[\\begin{align*}\nf_{\\text{con}}(x) =\n&\n81.09\n+\n1.0284 \\cdot x_1\n+\n4.043 \\cdot x_2\n+\n6.2037 \\cdot x_3\n+\n1.8366 \\cdot x_1^2\n+\n2.9382 \\cdot x_2^2 \\\\\n&\n+\n5.1915 \\cdot x_3^2\n+\n2.2150 \\cdot x_1 \\cdot x_2\n+\n11.375 \\cdot x_1 \\cdot x_3\n+\n3.875 \\cdot x_2 \\cdot x_3\n\\end{align*}\\] and \\[\\begin{align*}\nf_{\\text{act}}(x) =\n&\n59.85\n+ 3.583 \\cdot x_1\n+ 0.2546 \\cdot x_2\n+ 2.2298 \\cdot x_3\n+ 0.83479 \\cdot x_1^2\n+ 0.07484 \\cdot x_2^2\n\\\\\n&\n+ 0.05716 \\cdot x_3^2\n+ 0.3875 \\cdot x_1 \\cdot x_2\n+ 0.375 \\cdot x_1 \\cdot x_3\n+ 0.3125 \\cdot x_2 \\cdot x_3.\n\\end{align*}\\]\n\n22.6.1.1 Defining the Multi-Objective Function myer16a\n\nThe multi-objective function myer16a combines the results of two single-objective functions: conversion and activity.\nIt is implemented in spotpython as follows:\n\n\nimport numpy as np\n\ndef conversion_pred(X):\n    \"\"\"\n    Compute conversion predictions for each row in the input array.\n\n    Args:\n        X (np.ndarray): 2D array where each row is a configuration.\n\n    Returns:\n        np.ndarray: 1D array of conversion predictions.\n    \"\"\"\n    return (\n        81.09\n        + 1.0284 * X[:, 0]\n        + 4.043 * X[:, 1]\n        + 6.2037 * X[:, 2]\n        - 1.8366 * X[:, 0]**2\n        + 2.9382 * X[:, 1]**2\n        - 5.1915 * X[:, 2]**2\n        + 2.2150 * X[:, 0] * X[:, 1]\n        + 11.375 * X[:, 0] * X[:, 2]\n        - 3.875 * X[:, 1] * X[:, 2]\n    )\n\ndef activity_pred(X):\n    \"\"\"\n    Compute activity predictions for each row in the input array.\n\n    Args:\n        X (np.ndarray): 2D array where each row is a configuration.\n\n    Returns:\n        np.ndarray: 1D array of activity predictions.\n    \"\"\"\n    return (\n        59.85\n        + 3.583 * X[:, 0]\n        + 0.2546 * X[:, 1]\n        + 2.2298 * X[:, 2]\n        + 0.83479 * X[:, 0]**2\n        + 0.07484 * X[:, 1]**2\n        + 0.05716 * X[:, 2]**2\n        - 0.3875 * X[:, 0] * X[:, 1]\n        - 0.375 * X[:, 0] * X[:, 2]\n        + 0.3125 * X[:, 1] * X[:, 2]\n    )\n\ndef fun_myer16a(X, fun_control=None):\n    \"\"\"\n    Compute both conversion and activity predictions for each row in the input array.\n\n    Args:\n        X (np.ndarray): 2D array where each row is a configuration.\n        fun_control (dict, optional): Additional control parameters (not used here).\n\n    Returns:\n        np.ndarray: 2D array where each row contains [conversion_pred, activity_pred].\n    \"\"\"\n    return np.column_stack((conversion_pred(X), activity_pred(X)))\n\nNow the function returns a 2D array with two columns, one for each objective function. The first column corresponds to the conversion prediction, and the second column corresponds to the activity prediction.\n\nX = np.array([[1, 2, 3], [4, 5, 6]])\nresults = fun_myer16a(X)\nprint(results)\n\n[[ 87.3132   72.25519]\n [200.8662   98.7442 ]]\n\n\n\n\n22.6.1.2 Using a Weighted Sum\n\nThe spotpython package can also handle multi-objective functions, which are functions that return multiple values for each input vector.\nIn this case, we can use a weighted sum to combine the two objectives into a single objective function.\nThe function aggergate takes the two objectives and combines them into a single objective function by applying weights to each objective.\nThe weights can be adjusted to give more importance to one objective over the other.\nFor example, if we want to give more importance to the conversion prediction, we can set the weight for the conversion prediction to 2 and the weight for the activity prediction to 0.1.\n\n\n# Weight first objective with 2, second with 1/10\ndef aggregate(y):\n    return np.sum(y*np.array([2, 0.1]), axis=1)\n\nThe aggregate function object is passed to the fun_control dictionary aas the fun_mo2so argument.\n\nfun_control = fun_control_init(\n              lower = np.array( [0, 0, 0]),\n              upper = np.array([1, 1, 1]),\n              fun_mo2so=aggregate)\nS = Spot(fun=fun_myer16a,\n        fun_control=fun_control)\nS.run()\nS.plot_progress()\n\nspotpython tuning: 171.91645662554126 [#######---] 73.33% \nspotpython tuning: 168.29206829613202 [########--] 80.00% \nspotpython tuning: 168.29206829613202 [#########-] 86.67% \nspotpython tuning: 168.25685825618206 [#########-] 93.33% \nspotpython tuning: 168.16500000000002 [##########] 100.00% Done...\n\nExperiment saved to 000_res.pkl\n\n\n\n\n\n\n\n\n\nIf no fun_mo2so function is specified, the spotpython package will use the first return value of the multi-objective function as the single objective function.\nspotpython allows access to the complete history of multi-objective return values. They are stored in the y_mo attribute of the Spot object. The y_mo attribute is a 2D array where each row corresponds to a configuration and each column corresponds to an objective function. These values can be visualized as shown in Figure 22.1.\n\ny_mo = S.y_mo\ny = S.y\nplt.xlim(0, len(y_mo))\nplt.ylim(0.9 * np.min(y_mo), 1.1* np.max(y))\nplt.scatter(range(len(y_mo)), y_mo[:, 0], label='Conversion', marker='o')\nplt.scatter(range(len(y_mo)), y_mo[:, 1], label='Activity', marker='x')\nplt.plot(np.minimum.accumulate(y_mo[:, 0]), label='Cum. Min Conversion')\nplt.plot(np.minimum.accumulate(y_mo[:, 1]), label='Cum. Min Activity')\nplt.scatter(range(len(y)), y, label='Agg. Result', marker='D', color='red')\nplt.plot(np.minimum.accumulate(y), label='Cum. Min Agg. Res.', color='red')\nplt.xlabel('Iteration')\nplt.ylabel('Objective Function Value')\nplt.grid()\nplt.title('Single- and Multi-Obj. Function Values')\nplt.legend(loc='upper left', bbox_to_anchor=(1, 1))\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\nFigure 22.1: Single- and Multi-Objective Function Values. The red line shows the optimization progress based on the aggregated objective function. The blue lines show the progress of the conversion objective, the orange line the progress of the activity objective. Points denote individual evaluations, lines the cumulative minimum of the respective objective function.\n\n\n\n\n\nSince all values from the multi-objective functions can be accessed, more sophisticated multi-objective optimization methods can be implemented. For example, the spotpython package provides a pareto_front function that can be used to compute the Pareto front of the multi-objective function values, see pareto. The Pareto front is a set of solutions that are not dominated by any other solution in the objective space.\n\n\n\n\n\n\nSummary: Using spotpython with Multi-Objective User-Specified Functions\n\n\n\n\nspotpython accepts user-specified multi-objective functions that can be defined in Python.\nThe function should accept a 2D array as input and return a 2D array as output.\nAn aggregate function can be used to combine multiple objectives into a single objective function.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>User-Specified Functions: Extending the Analytical Class</span>"
    ]
  },
  {
    "objectID": "017_num_spot_user_function.html#jupyter-notebook",
    "href": "017_num_spot_user_function.html#jupyter-notebook",
    "title": "22  User-Specified Functions: Extending the Analytical Class",
    "section": "22.7 Jupyter Notebook",
    "text": "22.7 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository\n\n\n\n\n\n\n\nMyers, Raymond H, Douglas C Montgomery, and Christine M Anderson-Cook. 2016. Response Surface Methodology: Process and Product Optimization Using Designed Experiments. John Wiley & Sons.",
    "crumbs": [
      "Sequential Parameter Optimization Toolbox (SPOT)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>User-Specified Functions: Extending the Analytical Class</span>"
    ]
  },
  {
    "objectID": "100_ddmo_eda.html",
    "href": "100_ddmo_eda.html",
    "title": "23  Basic Statistics and Data Analysis",
    "section": "",
    "text": "23.1 Exploratory Data Analysis\nThis chapter covers basic statistical concepts, namely descriptive statistics, probability distributions, and hypothesis testing. These concepts are fundamental to understanding data and making informed decisions based on data analysis. The chapter also introduces the concept of exploratory data analysis (EDA), data preprocessing (Principal Component Analysis), and data visualization techniques.",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Basic Statistics and Data Analysis</span>"
    ]
  },
  {
    "objectID": "100_ddmo_eda.html#exploratory-data-analysis",
    "href": "100_ddmo_eda.html#exploratory-data-analysis",
    "title": "23  Basic Statistics and Data Analysis",
    "section": "",
    "text": "23.1.1 Histograms\nCreating a histogram and calculating the probabilities from a dataset can be approached with scientific precision\n\nData Collection: Obtain the dataset you wish to analyze. This dataset could represent any quantitative measure, such to examine its distribution.\nDecide on the Number of Bins: The number of bins influences the histogram’s granularity. There are several statistical rules to determine an optimal number of bins:\n\nSquare-root rule: suggests using the square root of the number of data points as the number of bins.\nSturges’ formula: \\(k = 1 + 3.322 \\log_{10}(n)\\), where \\(n\\) is the number of data points and \\(k\\) is the suggested number of bins.\nFreedman-Diaconis rule: uses the interquartile range (IQR) and the cube root of the number of data points \\(n\\) to calculate bin width as \\(2 \\dfrac{IQR}{n^{1/3}}\\).\n\nDetermine Range and Bin Width: Calculate the range of data by subtracting the minimum data point value from the maximum. Divide this range by the number of bins to determine the width of each bin.\nAllocate Data Points to Bins: Iterate through the data, sorting each data point into the appropriate bin based on its value.\nDraw the Histogram: Use a histogram to visualize the frequency or relative frequency (probability) of data points within each bin.\nCalculate Probabilities: The relative frequency of data within each bin represents the probability of a randomly selected data point falling within that bin’s range.\n\nBelow is a Python script that demonstrates how to generate a histogram and compute probabilities using the matplotlib library for visualization and numpy for data manipulation.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Sample data: Randomly generated for demonstration\ndata = np.random.normal(0, 1, 1000)  # 1000 data points with a normal distribution\n\n# Step 2: Decide on the number of bins\nnum_bins = int(np.ceil(1 + 3.322 * np.log10(len(data))))  # Sturges' formula\n\n# Step 3: Determine range and bin width -- handled internally by matplotlib\n\n# Steps 4 & 5: Sort data into bins and draw the histogram\nfig, ax = plt.subplots()\nn, bins, patches = ax.hist(data, bins=num_bins, density=True, alpha=0.75, edgecolor='black')\n\n# Calculate probabilities (relative frequencies) manually, if needed\nbin_width = np.diff(bins)  # np.diff finds the difference between adjacent bin boundaries\nprobabilities = n * bin_width  # n is already normalized to form a probability density if `density=True`\n\n# Adding labels and title for clarity\nax.set_xlabel('Data Value')\nax.set_ylabel('Probability Density')\nax.set_title('Histogram with Probability Density')\n\n\n\n\n\n\nText(0.5, 1.0, 'Histogram with Probability Density')\n\n\n(a) Histogram with Probability Density\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\nFigure 23.1\n\n\n\n\n\nfor i, prob in enumerate(probabilities):\n    print(f\"Bin {i+1} Probability: {prob:.4f}\")\n\n# Ensure probabilities sum to 1 (or very close, due to floating-point arithmetic)\nprint(f\"Sum of probabilities: {np.sum(probabilities)}\")\n\nBin 1 Probability: 0.0050\nBin 2 Probability: 0.0160\nBin 3 Probability: 0.0550\nBin 4 Probability: 0.1570\nBin 5 Probability: 0.2280\nBin 6 Probability: 0.2450\nBin 7 Probability: 0.1850\nBin 8 Probability: 0.0810\nBin 9 Probability: 0.0230\nBin 10 Probability: 0.0040\nBin 11 Probability: 0.0010\nSum of probabilities: 1.0\n\n\nThis code segment goes through the necessary steps to generate a histogram and calculate probabilities for a synthetic dataset. It demonstrates important scientific and computational practices including binning, visualization, and probability calculation in Python.\nKey Points:\n\nThe histogram represents the distribution of data, with the histogram’s bins outlining the data’s spread and density.\nThe option density=True in ax.hist() normalizes the histogram so that the total area under the histogram sums to 1, thereby converting frequencies to probability densities.\nThe choice of bin number and width has a significant influence on the histogram’s shape and the insights that can be drawn from it, highlighting the importance of selecting appropriate binning strategies based on the dataset’s characteristics and the analysis objectives.\nVideo: Histograms, Clearly Explained\n\n\n\n23.1.2 Boxplots\n\nVideo: Boxplots are Awesome",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Basic Statistics and Data Analysis</span>"
    ]
  },
  {
    "objectID": "100_ddmo_eda.html#probability-distributions",
    "href": "100_ddmo_eda.html#probability-distributions",
    "title": "23  Basic Statistics and Data Analysis",
    "section": "23.2 Probability Distributions",
    "text": "23.2 Probability Distributions\nWhat happens when we use smaller bins in a histogram? The histogram becomes more detailed, revealing the distribution of data points with greater precision. However, as the bin size decreases, the number of data points within each bin may decrease, leading to sparse or empty bins. This sparsity can make it challenging to estimate probabilities accurately, especially for data points that fall within these empty bins.\nAdvantages, when using a probability distribution, include:\n\nBlanks can be filled\nProbabilities can be calculated\nParameters are sufficient to describe the distribution, e.g., mean and variance for the normal distribution\n\nProbability distributions offer a powerful solution to the challenges posed by limited data in estimating probabilities. When data is scarce, constructing a histogram to determine the probability of certain outcomes can lead to inaccurate or unreliable results due to the lack of detail in the dataset. However, collecting vast amounts of data to populate a histogram for more precise estimates can often be impractical, time-consuming, and expensive.\nA probability distribution is a mathematical function that provides the probabilities of occurrence of different possible outcomes for an experiment. It is a more efficient approach to understanding the likelihood of various outcomes than relying solely on extensive data collection. For continuous data, this is often represented graphically by a smooth curve.\n\nVideo: The Main Ideas behind Probability Distributions\n\n\n23.2.1 Sampling from a Distribution\n\nVideo: Sampling from a Distribution, Clearly Explained!!!",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Basic Statistics and Data Analysis</span>"
    ]
  },
  {
    "objectID": "100_ddmo_eda.html#discrete-distributions",
    "href": "100_ddmo_eda.html#discrete-distributions",
    "title": "23  Basic Statistics and Data Analysis",
    "section": "23.3 Discrete Distributions",
    "text": "23.3 Discrete Distributions\nDiscrete probability distributions are essential tools in statistics, providing a mathematical foundation to model and analyze situations with discrete outcomes. Histograms, which can be seen as discrete distributions with data organized into bins, offer a way to visualize and estimate probabilities based on the collected data. However, they come with limitations, especially when data is scarce or when we encounter gaps in the data (blank spaces in histograms). These gaps can make it challenging to accurately estimate probabilities.\nA more efficient approach, especially for discrete data, is to use mathematical equations—particularly those defining discrete probability distributions—to calculate probabilities directly, thus bypassing the intricacies of data collection and histogram interpretation.\n\n23.3.1 Bernoulli Distribution\nThe Bernoulli distribution, named after Swiss scientist Jacob Bernoulli, is a discrete probability distribution, which takes value \\(1\\) with success probability \\(p\\) and value \\(0\\) with failure probability \\(q = 1-p\\). So if \\(X\\) is a random variable with this distribution, we have: \\[\nP(X=1) = 1-P(X=0) = p = 1-q.\n\\]\n\n\n23.3.2 Binomial Distribution\nThe Binomial Distribution is a prime example of a discrete probability distribution that is particularly useful for binary outcomes (e.g., success/failure, yes/no, pumpkin pie/blueberry pie). It leverages simple mathematical principles to calculate the probability of observing a specific number of successes (preferred outcomes) in a fixed number of trials, given the probability of success in each trial.\n\nExample 23.1 (Pie Preference) Consider a scenario from “StatLand” where 70% of people prefer pumpkin pie over blueberry pie. The question is: What is the probability that, out of three people asked, the first two prefer pumpkin pie and the third prefers blueberry pie?\nUsing the concept of the Binomial Distribution, the probability of such an outcome can be calculated without the need to layout every possible combination by hand. This process not only simplifies calculations but also provides a clear and precise method to determine probabilities in scenarios involving discrete choices. We will use Python to calculate the probability of observing exactly two out of three people prefer pumpkin pie, given the 70% preference rate:\n\nfrom scipy.stats import binom\nn = 3  # Number of trials (people asked)\np = 0.7  # Probability of success (preferring pumpkin pie)\nx = 2  # Number of successes (people preferring pumpkin pie)\n# Probability calculation using Binomial Distribution\nprob = binom.pmf(x, n, p)\nprint(f\"The probability that exactly 2 out of 3 people prefer pumpkin pie is: {prob:.3f}\")\n\nThe probability that exactly 2 out of 3 people prefer pumpkin pie is: 0.441\n\n\nThis code uses the binom.pmf() function from scipy.stats to calculate the probability mass function (PMF) of observing exactly x successes in n trials, where each trial has a success probability of p.\n\nA Binomial random variable is the sum of \\(n\\) independent, identically distributed Bernoulli random variables, each with probability \\(p\\) of success. We may indicate a random variable \\(X\\) with Bernoulli distribution using the notation \\(X \\sim \\mathrm{Bi}(1,\\theta)\\). Then, the notation for the Binomial is \\(X \\sim \\mathrm{Bi}(n,\\theta)\\). Its probability and distribution functions are, respectively, \\[\np_X(x) = {n\\choose x}\\theta^x(1-\\theta)^{n-x}, \\qquad F_X(x) = \\Pr\\{X \\le x\\} = \\sum_{i=0}^{x} {n\\choose i}\\theta^i(1-\\theta)^{n-i}.\n\\]\nThe mean of the binomial distribution is \\(\\text{E}[X] = n\\theta\\). The variance of the distribution is \\(\\text{Var}[X] = n\\theta(1-\\theta)\\) (see next section).\nA process consists of a sequence of \\(n\\) independent trials, i.e., the outcome of each trial does not depend on the outcome of previous trials. The outcome of each trial is either a success or a failure. The probability of success is denoted as \\(p\\), and \\(p\\) is constant for each trial. Coin tossing is a classical example for this setting.\nThe binomial distribution is a statistical distribution giving the probability of obtaining a specified number of successes in a binomial experiment; written Binomial(n, p), where \\(n\\) is the number of trials, and \\(p\\) the probability of success in each.\n\nDefinition 23.1 (Binomial Distribution) The binomial distribution with parameters \\(n\\) and \\(p\\), where \\(n\\) is the number of trials, and \\(p\\) the probability of success in each, is \\[\\begin{equation}\np(x) = { n \\choose k } p^x(1-p)^{n-x} \\qquad x = 0,1, \\ldots, n.\n\\end{equation}\\] The mean \\(\\mu\\) and the variance \\(\\sigma^2\\) of the binomial distribution are \\[\\begin{equation}\n\\mu = np\n\\end{equation}\\] and \\[\\begin{equation}\n\\sigma^2 = np(1-p).\n\\end{equation}\\]\n\nNote, the Bernoulli distribution is simply Binomial(1,p).",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Basic Statistics and Data Analysis</span>"
    ]
  },
  {
    "objectID": "100_ddmo_eda.html#continuous-distributions",
    "href": "100_ddmo_eda.html#continuous-distributions",
    "title": "23  Basic Statistics and Data Analysis",
    "section": "23.4 Continuous Distributions",
    "text": "23.4 Continuous Distributions\nOur considerations regarding probability distributions, expectations, and standard deviations will be extended from discrete distributions to continuous distributions. One simple example of a continuous distribution is the uniform distribution. Continuous distributions are defined by probability density functions.\n\n23.4.1 Distribution functions: PDFs and CDFs\nThe density for a continuous distribution is a measure of the relative probability of “getting a value close to \\(x\\).” Probability density functions \\(f\\) and cumulative distribution function \\(F\\) are related as follows. \\[\\begin{equation}\nf(x) = \\frac{d}{dx} F(x)\n\\end{equation}\\]",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Basic Statistics and Data Analysis</span>"
    ]
  },
  {
    "objectID": "100_ddmo_eda.html#background-expectation-mean-standard-deviation",
    "href": "100_ddmo_eda.html#background-expectation-mean-standard-deviation",
    "title": "23  Basic Statistics and Data Analysis",
    "section": "23.5 Background: Expectation, Mean, Standard Deviation",
    "text": "23.5 Background: Expectation, Mean, Standard Deviation\nThe distribution of a random vector is characterized by some indexes. These are the expectation, the mean, and the standard deviation. The expectation is a measure of the central tendency of a random variable, while the standard deviation quantifies the spread of the distribution. These indexes are essential for understanding the behavior of random variables and making predictions based on them.\n\nDefinition 23.2 (Random Variable) A random variable \\(X\\) is a mapping from the sample space of a random experiment to the real numbers. It assigns a numerical value to each outcome of the experiment. Random variables can be either:\n\nDiscrete: If \\(X\\) takes on a countable number of distinct values.\nContinuous: If \\(X\\) takes on an uncountable number of values.\n\nMathematically, a random variable is a function \\(X: \\Omega \\rightarrow \\mathbb{R}\\), where \\(\\Omega\\) is the sample space.\n\n\nDefinition 23.3 (Probability Distribution) A probability distribution describes how the values of a random variable are distributed. It is characterized for a discrete random variable \\(X\\) by the probability mass function (PMF) \\(p_X(x)\\) and for a continuous random variable \\(X\\) by the probability density function (PDF) \\(f_X(x)\\).\n\n\nDefinition 23.4 (Probability Mass Function (PMF)) \\(p_X(x) = P(X = x)\\) gives the probability that \\(X\\) takes the value \\(x\\).\n\n\nDefinition 23.5 (Probability Density Function (PDF):) \\(f_X(x)\\) is a function such that for any interval \\([a, b]\\), the probability that \\(X\\) falls within this interval is given by the integral \\(\\int_a^b f_X(x) \\mathrm{d}x\\).\n\nThe distribution function must satisfy: \\[\n\\sum_{x \\in D_X} p_X(x) = 1\n\\] for discrete random variables, where \\(D_X\\) is the domain of \\(X\\) and \\[\n\\int_{-\\infty}^{\\infty} f_X(x) \\mathrm{d}x = 1\n\\] for continuous random variables.\nWith these definitions in place, we can now introduce the definition of the expectation, which is a fundamental measure of the central tendency of a random variable.\n\nDefinition 23.6 (Expectation) The expectation or expected value of a random variable \\(X\\), denoted \\(E[X]\\), is defined as follows:\nFor a discrete random variable \\(X\\): \\[\nE[X] = \\sum_{x \\in D_X} x p_X(x) \\quad \\text{if $X$ is discrete}.\n\\]\nFor a continuous random variable \\(X\\): \\[\nE[X] = \\int_{x \\in D_X} x f_X(x) \\mathrm{d}x \\quad \\text{if $X$ is continuous.}\n\\]\n\nThe mean, \\(\\mu\\), of a probability distribution is a measure of its central tendency or location. That is, \\(E(X)\\) is defined as the average of all possible values of \\(X\\), weighted by their probabilities.\n\nExample 23.2 (Expectation) Let \\(X\\) denote the number produced by rolling a fair die. Then \\[\nE(X) = 1 \\times 1/6 + 2 \\times 1/6 + 3 \\times 1/6 + 4 \\times 1/6 + 5 \\times 1/6 + 6\\times 1/6 = 3.5.\n\\]\n\n\nDefinition 23.7 (Sample Mean) The sample mean is an important estimate of the population mean. The sample mean of a sample \\(\\{x_i\\}\\) (\\(i=1,2,\\ldots,n\\)) is defined as \\[\n\\overline{x}  = \\frac{1}{n} \\sum_i x_i.\n\\]\n\nWhile both the expectation of a random variable and the sample mean provide measures of central tendency, they differ in their context, calculation, and interpretation.\n\nThe expectation is a theoretical measure that characterizes the average value of a random variable over an infinite number of repetitions of an experiment. The expectation is calculated using a probability distribution and provides a parameter of the entire population or distribution. It reflects the long-term average or central value of the outcomes generated by the random process.\nThe sample mean is a statistic. It provides an estimate of the population mean based on a finite sample of data. It is computed directly from the data sample, and its value can vary between different samples from the same population. It serves as an approximation or estimate of the population mean. It is used in statistical inference to make conclusions about the population mean based on sample data.\n\nIf we are trying to predict the value of a random variable \\(X\\) by its mean \\(\\mu = E(X)\\), the error will be \\(X-\\mu\\). In many situations it is useful to have an idea how large this deviation or error is. Since \\(E(X-\\mu) = E(X) -\\mu = 0\\), it is necessary to use the absolute value or the square of (\\(X-\\mu\\)). The squared error is the first choice, because the derivatives are easier to calculate. These considerations motivate the definition of the variance:\n\nDefinition 23.8 (Variance) The variance of a random variable \\(X\\) is the mean squared deviation of \\(X\\) from its expected value \\(\\mu = E(X)\\). \\[\\begin{equation}\nVar(X) = E[ (X-\\mu)^2].\n\\end{equation}\\]\n\nThe variance is a measure of the spread of a distribution. It quantifies how much the values of a random variable differ from the mean. A high variance indicates that the values are spread out over a wide range, while a low variance indicates that the values are clustered closely around the mean.\n\nDefinition 23.9 (Standard Deviation) Taking the square root of the variance to get back to the same scale of units as \\(X\\) gives the standard deviation. The standard deviation of \\(X\\) is the square root of the variance of \\(X\\). \\[\\begin{equation}\nsd(X) = \\sqrt{Var(X)}.\n\\end{equation}\\]",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Basic Statistics and Data Analysis</span>"
    ]
  },
  {
    "objectID": "100_ddmo_eda.html#distributions-and-random-numbers-in-python",
    "href": "100_ddmo_eda.html#distributions-and-random-numbers-in-python",
    "title": "23  Basic Statistics and Data Analysis",
    "section": "23.6 Distributions and Random Numbers in Python",
    "text": "23.6 Distributions and Random Numbers in Python\nResults from computers are deterministic, so it sounds like a contradiction in terms to generate random numbers on a computer. Standard computers generate pseudo-randomnumbers, i.e., numbers that behave as if they were drawn randomly.\n\n\n\n\n\n\nDeterministic Random Numbers\n\n\n\n\nIdea: Generate deterministically numbers that look (behave) as if they were drawn randomly.\n\n\n\n\n23.6.1 Calculation of the Standard Deviation with Python\nThe function numpy.std returns the standard deviation, a measure of the spread of a distribution, of the array elements. The argument ddof specifies the Delta Degrees of Freedom. The divisor used in calculations is N - ddof, where N represents the number of elements. By default ddof is zero, i.e., std uses the formula \\[\n\\sqrt{  \\frac{1}{N} \\sum_i \\left( x_i - \\bar{x} \\right)^2  } \\qquad \\text{with } \\quad \\bar{x} = \\sum_{i=1}^N x_i /N.\n\\]\n\nExample 23.3 (Standard Deviation with Python) Consider the array \\([1,2,3]\\): Since \\(\\bar{x} = 2\\), the following value is computed: \\[ \\sqrt{1/3 \\times \\left( (1-2)^2 + (2-2)^2 + (3-2)^2  \\right)} = \\sqrt{2/3}.\\]\n\nimport numpy as np\na = np.array([[1, 2, 3]])\nnp.std(a)\n\nnp.float64(0.816496580927726)\n\n\n\nThe empirical standard deviation (which uses \\(N-1\\)), \\(\\sqrt{1/2 \\times \\left( (1-2)^2 + (2-2)^2 + (3-2)^2  \\right)} = \\sqrt{2/2}\\), can be calculated in Python as follows:\n\nnp.std(a, ddof=1)\n\nnp.float64(1.0)\n\n\n\n\n23.6.2 The Argument “axis”\nWhen you compute np.std with axis=0, it calculates the standard deviation along the vertical axis, meaning it computes the standard deviation for each column of the array. On the other hand, when you compute np.std with axis=1, it calculates the standard deviation along the horizontal axis, meaning it computes the standard deviation for each row of the array. If the axis parameter is not specified, np.std computes the standard deviation of the flattened array, i.e., it calculates the standard deviation of all the elements in the array.\n\nExample 23.4 (Axes along which the standard deviation is computed)  \n\nA = np.array([[1, 2], [3, 4]])\nA\n\narray([[1, 2],\n       [3, 4]])\n\n\nFirst, we calculate the standard deviation of all elements in the array:\n\nnp.std(A)\n\nnp.float64(1.118033988749895)\n\n\nSetting axis=0 calculates the standard deviation along the vertical axis (column-wise):\n\nnp.std(A, axis=0)\n\narray([1., 1.])\n\n\nFinally, setting axis=1 calculates the standard deviation along the horizontal axis (row-wise):\n\nnp.std(A, axis=1)\n\narray([0.5, 0.5])",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Basic Statistics and Data Analysis</span>"
    ]
  },
  {
    "objectID": "100_ddmo_eda.html#expectation-continuous",
    "href": "100_ddmo_eda.html#expectation-continuous",
    "title": "23  Basic Statistics and Data Analysis",
    "section": "23.7 Expectation (Continuous)",
    "text": "23.7 Expectation (Continuous)\n\nDefinition 23.10 (Expectation (Continuous)) \\[\\begin{equation}\n  \\text{E}(X) = \\int_{-\\infty}^\\infty x f(x) \\, dx\n  \\end{equation}\\]",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Basic Statistics and Data Analysis</span>"
    ]
  },
  {
    "objectID": "100_ddmo_eda.html#variance-and-standard-deviation-continuous",
    "href": "100_ddmo_eda.html#variance-and-standard-deviation-continuous",
    "title": "23  Basic Statistics and Data Analysis",
    "section": "23.8 Variance and Standard Deviation (Continuous)",
    "text": "23.8 Variance and Standard Deviation (Continuous)\n\nDefinition 23.11 (Variance (Continuous)) Variance can be calculated with \\(\\text{E}(X)\\) and \\[\\begin{equation}\n  \\text{E}(X^2) = \\int_{-\\infty}^\\infty x^2 f(x) \\, dx\n\\end{equation}\\] as \\[\\begin{equation*}\n  \\text{Var}(X) = \\text{E}(X^2) - [ E(X)]^2.\n  \\end{equation*}\\] \\(\\Box\\)\n\n\nDefinition 23.12 (Standard Deviation (Continuous)) Standard deviation can be calculated as \\[\\begin{equation*}\n  \\text{sd}(X) = \\sqrt{\\text{Var}(X)}.\n  \\end{equation*}\\] \\(\\Box\\)\n\n\nVideo: Population and Estimated Parameters, Clearly Explained\nVideo: Calculating the Mean, Variance, and Standard Deviation\n\n\n23.8.1 The Uniform Distribution\n\nDefinition 23.13 (The Uniform Distribution) The probability density function of the uniform distribution is defined as: \\[\nf_X(x) = \\frac{1}{b-a} \\qquad \\text{for $x \\in [a,b]$}.\n\\]\n\nGenerate 10 random numbers from a uniform distribution between \\(a=0\\) and \\(b=1\\):\n\nimport numpy as np\n# Initialize the random number generator\nrng = np.random.default_rng(seed=123456789)\nn = 10\nx = rng.uniform(low=0.0, high=1.0, size=n)\nx\n\narray([0.02771274, 0.90670006, 0.88139355, 0.62489728, 0.79071481,\n       0.82590801, 0.84170584, 0.47172795, 0.95722878, 0.94659153])\n\n\nGenerate 10,000 random numbers from a uniform distribution between 0 and 10 and plot a histogram of the numbers:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Initialize the random number generator\nrng = np.random.default_rng(seed=123456789)\n\n# Generate random numbers from a uniform distribution\nx = rng.uniform(low=0, high=10, size=10000)\n\n# Plot a histogram of the numbers\nplt.hist(x, bins=50, density=True, edgecolor='black')\nplt.title('Uniform Distribution [0,10]')\nplt.xlabel('Value')\nplt.ylabel('Frequency')\nplt.show()",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Basic Statistics and Data Analysis</span>"
    ]
  },
  {
    "objectID": "100_ddmo_eda.html#the-uniform-distribution-2",
    "href": "100_ddmo_eda.html#the-uniform-distribution-2",
    "title": "23  Basic Statistics and Data Analysis",
    "section": "23.9 The Uniform Distribution",
    "text": "23.9 The Uniform Distribution\nThis variable is defined in the interval \\([a,b]\\). We write it as \\(X \\sim U[a,b]\\). Its density and cumulative distribution functions are, respectively, \\[\nf_X(x) = \\frac{I_{[a,b]}(x)}{b-a},  \\quad\\quad F_X(x) = \\frac{1}{b-a}\\int\\limits_{-\\infty}\\limits^x I_{[a,b]}(t) \\mathrm{d}t = \\frac{x-a}{b-a},\n\\] where \\(I_{[a,b]}(\\cdot)\\) is the indicator function of the interval \\([a,b]\\). Note that, if we set \\(a=0\\) and \\(b=1\\), we obtain \\(F_X(x) = x\\), \\(x\\) \\(\\in\\) \\([0,1]\\).\nA typical example is the following: the cdf of a continuous r.v. is uniformly distributed in \\([0,1]\\). The proof of this statement is as follows: For \\(u\\) \\(\\in\\) \\([0,1]\\), we have \\[\\begin{eqnarray*}\n\\Pr\\{F_X(X) \\leq u\\} &=& \\Pr\\{F_X^{-1}(F_X(X)) \\leq F_X^{-1}(u)\\} = \\Pr\\{X \\leq F_X^{-1}(u)\\} \\\\\n                      &=& F_X(F_X^{-1}(u)) = u.     \n\\end{eqnarray*}\\] This means that, when \\(X\\) is continuous, there is a one-to-one relationship (given by the cdf) between \\(x\\) \\(\\in\\) \\(D_X\\) and \\(u\\) \\(\\in\\) \\([0,1]\\).\nThe has a constant density over a specified interval, say \\([a,b]\\). The uniform \\(U(a,b)\\) distribution has density \\[\\begin{equation}\nf(x) =\n\\left\\{\n  \\begin{array}{ll}\n  1/(b-a) & \\textrm{ if } a &lt; x &lt; b,\\\\\n  0 & \\textrm{ otherwise}\n  \\end{array}\n  \\right.\n  \\end{equation}\\]\n\n23.9.1 The Normal Distribution\nA normally distributed random variable is a random variable whose associated probability distribution is the normal (or Gaussian) distribution. The normal distribution is a continuous probability distribution characterized by a symmetric bell-shaped curve.\nThe distribution is defined by two parameters: the mean \\(\\mu\\) and the standard deviation \\(\\sigma\\). The mean indicates the center of the distribution, while the standard deviation measures the spread or dispersion of the distribution.\nThis distribution is widely used in statistics and the natural and social sciences as a simple model for random variables with unknown distributions.\n\nDefinition 23.14 (The Normal Distribution) The probability density function of the normal distribution is defined as: \\[\nf_X(x) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp\\left(-\\frac{1}{2} \\left(\\frac{x-\\mu}{\\sigma}\\right)^2\\right),\n\\tag{23.1}\\] where: \\(\\mu\\) is the mean; \\(\\sigma\\) is the standard deviation.\n\nTo generate ten random numbers from a normal distribution, the following command can be used.\n\nimport numpy as np\nrng = np.random.default_rng()\nn = 10\nmu, sigma = 2, 0.1\nx = rng.normal(mu, sigma, n)\nx\n\narray([1.99016955, 2.0746593 , 2.0013354 , 2.00884099, 2.09354383,\n       1.91402814, 2.04411936, 2.12011129, 1.94387639, 2.1308799 ])\n\n\nVerify the mean:\n\nabs(mu - np.mean(x))\n\nnp.float64(0.03215641584864759)\n\n\nNote: To verify the standard deviation, we use ddof = 1 (empirical standard deviation):\n\nabs(sigma - np.std(x, ddof=1))\n\nnp.float64(0.02681492092067539)\n\n\n\nplot_normal_distribution(mu=0, sigma=1, num_samples=10000)\n\n\n\n\n\n\n\n\n\n\n23.9.2 Visualization of the Standard Deviation\nThe standard deviation of normal distributed can be visualized in terms of the histogram of \\(X\\):\n\nabout 68% of the values will lie in the interval within one standard deviation of the mean\n95% lie within two standard deviation of the mean\nand 99.9% lie within 3 standard deviations of the mean.\n\n\n\n\n\n\n\n\n\n\n\n\n23.9.3 Realizations of a Normal Distribution\nRealizations of a normal distribution refers to the actual values that you get when you draw samples from a normal distribution. Each sample drawn from the distribution is a realization of that distribution.\n\nExample 23.5 (Realizations of a Normal Distribution) If you have a normal distribution with a mean of 0 and a standard deviation of 1, each number you draw from that distribution is a realization. Here is a Python example that generates 10 realizations of a normal distribution with a mean of 0 and a standard deviation of 1:\n\nimport numpy as np\nmu = 0\nsigma = 1\nrealizations = np.random.normal(mu, sigma, 10)\nprint(realizations)\n\n[ 0.48951662  0.23879586 -0.44811181 -0.610795   -2.02994507  0.60794659\n -0.35410888  0.15258149  0.50127485 -0.78640277]\n\n\nIn this code, np.random.normal generates ten realizations of a normal distribution with a mean of 0 and a standard deviation of 1. The realizations array contains the actual values drawn from the distribution.",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Basic Statistics and Data Analysis</span>"
    ]
  },
  {
    "objectID": "100_ddmo_eda.html#the-normal-distribution-2",
    "href": "100_ddmo_eda.html#the-normal-distribution-2",
    "title": "23  Basic Statistics and Data Analysis",
    "section": "23.10 The Normal Distribution",
    "text": "23.10 The Normal Distribution\nA commonly encountered probability distribution is the normal distribution, known for its characteristic bell-shaped curve. This curve represents how the values of a variable are distributed: most of the observations cluster around the mean (or center) of the distribution, with frequencies gradually decreasing as values move away from the mean.\nThe normal distribution is particularly useful because of its defined mathematical properties. It is determined entirely by its mean (mu, \\(\\mu\\)) and its standard deviation (sigma, \\(\\sigma\\)). The area under the curve represents probability, making it possible to calculate the likelihood of a random variable falling within a specific range.\n\nVideo: The Normal Distribution, Clearly Explained!!!\n\n\nExample 23.6 (Normal Distribution: Estimating Probabilities) Consider we are interested in the heights of adults in a population. Instead of measuring the height of every adult (which would be impractical), we can use the normal distribution to estimate the probability of adults’ heights falling within certain intervals, assuming we know the mean and standard deviation of the heights.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\nmu = 170  # e.g., mu height of adults in cm\nsd = 10  # e.g., standard deviation of heights in cm\nheights = np.linspace(mu - 3*sd, mu + 3*sd, 1000)\n# Calculate the probability density function for the normal distribution\npdf = norm.pdf(heights, mu, sd)\n# Plot the normal distribution curve\nplt.plot(heights, pdf, color='blue', linewidth=2)\nplt.fill_between(heights, pdf, where=(heights &gt;= mu - 2 * sd) & (heights &lt;= mu + 2*sd), color='grey', alpha=0.5)\nplt.xlabel('Height (cm)')\nplt.ylabel('Probability Density')\nplt.show()\n\n\n\n\n\n\n\nFigure 23.2: Normal Distribution Curve with Highlighted Probability Area. 95 percent of the data falls within two standard deviations of the mean.\n\n\n\n\n\nThis Python code snippet generates a plot of the normal distribution for adult heights, with a mean of 170 cm and a standard deviation of 10 cm. It visually approximates a histogram with a blue bell-shaped curve, and highlights (in grey) the area under the curve between \\(\\mu \\pm 2 \\times \\sigma\\). This area corresponds to the probability of randomly selecting an individual whose height falls within this range.\nBy using the area under the curve, we can efficiently estimate probabilities without needing to collect and analyze a vast amount of data. This method not only saves time and resources but also provides a clear and intuitive way to understand and communicate statistical probabilities.\n\n\nDefinition 23.15 (Normal Distribution) This variable is defined on the support \\(D_X = \\mathbb{R}\\) and its density function is given by \\[\nf_X(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left \\{-\\frac{1}{2\\sigma^2}(x-\\mu)^2 \\right \\}.\n\\] The density function is identified by the pair of parameters \\((\\mu,\\sigma^2)\\), where \\(\\mu\\) \\(\\in\\) \\(\\mathbb{R}\\) is the mean (or location parameter) and \\(\\sigma^2 &gt; 0\\) is the variance (or dispersion parameter) of \\(X\\). \\(\\Box\\)\n\nThe density function is symmetric around \\(\\mu\\). The normal distribution belongs to the location-scale family distributions. This means that, if \\(Z \\sim N(0,1)\\) (read, \\(Z\\) has a standard normal distribution; i.e., with \\(\\mu=0\\) and \\(\\sigma^2=1\\)), and we consider the linear transformation \\(X = \\mu + \\sigma Z\\), then \\(X \\sim N(\\mu,\\sigma^2)\\) (read, \\(X\\) has a normal distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\)). This means that one can obtain the probability of any interval \\((-\\infty,x]\\), \\(x\\) \\(\\in\\) \\(R\\) for any normal distribution (i.e., for any pair of the parameters \\(\\mu\\) and \\(\\sigma\\)) once the quantiles of the standard normal distribution are known. Indeed \\[\\begin{eqnarray*}\nF_X(x) &=& \\Pr\\left\\{X \\leq x \\right\\} = \\Pr\\left\\{\\frac{X-\\mu}{\\sigma} \\leq \\frac{x-\\mu}{\\sigma} \\right\\} \\\\\n           &=& \\Pr\\left\\{Z \\leq \\frac{x-\\mu}{\\sigma}\\right\\}  = F_Z\\left(\\frac{x-\\mu}{\\sigma}\\right)    \\qquad x \\in \\mathbb{R}.\n\\end{eqnarray*}\\] The quantiles of the standard normal distribution are available in any statistical program. The density and cumulative distribution function of the standard normal r.v.~at point \\(x\\) are usually denoted by the symbols \\(\\phi(x)\\) and \\(\\Phi(x)\\).\nThe standard normal distribution is based on the \\[\n\\varphi(z) = \\frac{1}{\\sqrt{2\\pi}} \\exp \\left(- \\frac{z^2}{2} \\right).\n\\tag{23.2}\\]\nAn important application of the standardization introduced in Equation 23.2 reads as follows. In case the distribution of \\(X\\) is approximately normal, the distribution of X^{*} is approximately standard normal. That is \\[\\begin{equation*}\n  P(X\\leq b) = P( \\frac{X-\\mu}{\\sigma} \\leq \\frac{b-\\mu}{\\sigma}) = P(X^{*} \\leq \\frac{b-\\mu}{\\sigma})\n\\end{equation*}\\] The probability \\(P(X\\leq b)\\) can be approximated by \\(\\Phi(\\frac{b-\\mu}{\\sigma})\\), where \\(\\Phi\\) is the standard normal cumulative distribution function.\nIf \\(X\\) is a normal random variable with mean \\(\\mu\\) and variance \\(\\sigma^2\\), i.e., \\(X \\sim \\cal{N} (\\mu, \\sigma^2)\\), then \\[\\begin{equation}\n  X = \\mu + \\sigma Z \\textrm{ where } Z \\sim \\cal{N}(0,1).\n  \\end{equation}\\]\nIf \\(Z \\sim \\cal{N}(0,1)\\) and \\(X\\sim \\cal{N}(\\mu, \\sigma^2)\\), then \\[\\begin{equation*}\n  X = \\mu + \\sigma Z.\n\\end{equation*}\\]\nThe probability of getting a value in a particular interval is the area under the corresponding part of the curve. Consider the density function of the normal distribution. It can be plotted using the following commands. The result is shown in Figure 23.3.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\nx = np.arange(-4, 4, 0.1)\n# Calculating the normal distribution's density function values for each point in x\ny = norm.pdf(x, 0, 1)\nplt.plot(x, y, linestyle='-', linewidth=2)\nplt.title('Normal Distribution')\nplt.xlabel('X')\nplt.ylabel('Density')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\nFigure 23.3: Normal Distribution Density Function\n\n\n\n\n\nThe (CDF) describes the probability of “hitting” \\(x\\) or less in a given distribution. We consider the CDF function of the normal distribution. It can be plotted using the following commands. The result is shown in Figure 23.4.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Generating a sequence of numbers from -4 to 4 with 0.1 intervals\nx = np.arange(-4, 4, 0.1)\n\n# Calculating the cumulative distribution function value of the normal distribution for each point in x\ny = norm.cdf(x, 0, 1)  # mean=0, stddev=1\n\n# Plotting the results. The equivalent of 'type=\"l\"' in R (line plot) becomes the default plot type in matplotlib.\nplt.plot(x, y, linestyle='-', linewidth=2)\nplt.title('Normal Distribution CDF')\nplt.xlabel('X')\nplt.ylabel('Cumulative Probability')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\nFigure 23.4: Normal Distribution Cumulative Distribution Function",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Basic Statistics and Data Analysis</span>"
    ]
  },
  {
    "objectID": "100_ddmo_eda.html#the-exponential-distribution",
    "href": "100_ddmo_eda.html#the-exponential-distribution",
    "title": "23  Basic Statistics and Data Analysis",
    "section": "23.11 The Exponential Distribution",
    "text": "23.11 The Exponential Distribution\nThe exponential distribution is a continuous probability distribution that describes the time between events in a Poisson process, where events occur continuously and independently at a constant average rate. It is characterized by a single parameter, the rate parameter \\(\\lambda\\), which represents the average number of events per unit time.\n\n23.11.1 Standardization of Random Variables\nTo compare statistical properties of random variables which use different units, it is a common practice to transform these random variables into standardized variables.\n\nDefinition 23.16 (Standard Units) If a random variable \\(X\\) has expectation \\(E(X) = \\mu\\) and standard deviation \\(sd(X) = \\sigma &gt;0\\), the random variable \\[\nX^{\\ast} = (X-\\mu)/\\sigma\n\\] is called \\(X\\) in standard units. It has \\(E(X^{\\ast}) = 0\\) and \\(sd(X^{\\ast}) =1\\).",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Basic Statistics and Data Analysis</span>"
    ]
  },
  {
    "objectID": "100_ddmo_eda.html#covariance-and-correlation",
    "href": "100_ddmo_eda.html#covariance-and-correlation",
    "title": "23  Basic Statistics and Data Analysis",
    "section": "23.12 Covariance and Correlation",
    "text": "23.12 Covariance and Correlation\n\n23.12.1 The Multivariate Normal Distribution\nThe multivariate normal, multinormal, or Gaussian distribution serves as a generalization of the one-dimensional normal distribution to higher dimensions. We will consider \\(n\\)-dimensional random vectors \\(X = (X_1, X_2, \\ldots, X_n)\\). When drawing samples from this distribution, it results in a set of values represented as \\(\\{x_1, x_2, \\ldots, x_n\\}\\). To fully define this distribution, it is necessary to specify its mean \\(\\mu\\) and covariance matrix \\(\\Sigma\\). These parameters are analogous to the mean, which represents the central location, and the variance (squared standard deviation) of the one-dimensional normal distribution introduced in Equation 23.1.\n\nDefinition 23.17 (The Multivariate Normal Distribution) The probability density function (PDF) of the multivariate normal distribution is defined as: \\[\nf_X(x) = \\frac{1}{\\sqrt{(2\\pi)^n \\det(\\Sigma)}} \\exp\\left(-\\frac{1}{2} (x-\\mu)^T\\Sigma^{-1} (x-\\mu)\\right),\n\\] where: \\(\\mu\\) is the \\(n \\times 1\\) mean vector; \\(\\Sigma\\) is the \\(n \\times n\\) covariance matrix. The covariance matrix \\(\\Sigma\\) is assumed to be positive definite, so that its determinant is strictly positive.\n\nIn the context of the multivariate normal distribution, the mean takes the form of a coordinate within an \\(k\\)-dimensional space. This coordinate represents the location where samples are most likely to be generated, akin to the peak of the bell curve in a one-dimensional or univariate normal distribution.\n\nDefinition 23.18 (Covariance of two random variables) For two random variables \\(X\\) and \\(Y\\), the covariance is defined as the expected value (or mean) of the product of their deviations from their individual expected values: \\[\n\\operatorname{cov}(X, Y) = \\operatorname{E}{\\big[(X - \\operatorname{E}[X])(Y - \\operatorname{E}[Y])\\big]}\n\\]\nFor discrete random variables, covariance can be written as: \\[\n\\operatorname{cov} (X,Y) = \\frac{1}{n}\\sum_{i=1}^n (x_i-E(X)) (y_i-E(Y)).\n\\]\n\nThe covariance within the multivariate normal distribution denotes the extent to which two variables vary together. The elements of the covariance matrix, such as \\(\\Sigma_{ij}\\), represent the covariances between the variables \\(x_i\\) and \\(x_j\\). These covariances describe how the different variables in the distribution are related to each other in terms of their variability.\n\nExample 23.7 (The Bivariate Normal Distribution with Positive Covariances) Figure 23.5 shows draws from a bivariate normal distribution with \\(\\mu = \\begin{pmatrix}0 \\\\ 0\\end{pmatrix}\\) and \\(\\Sigma=\\begin{pmatrix} 9 & 4 \\\\ 4 & 9 \\end{pmatrix}\\).\n\n\n\n\n\n\n\n\nFigure 23.5: Bivariate Normal. Mean zero and covariance \\(\\Sigma=\\begin{pmatrix} 9 & 4 \\\\ 4 & 9\\end{pmatrix}\\)\n\n\n\n\n\n\nThe covariance matrix of a bivariate normal distribution determines the shape, orientation, and spread of the distribution in the two-dimensional space.\nThe diagonal elements of the covariance matrix (\\(\\sigma_1^2\\), \\(\\sigma_2^2\\)) are the variances of the individual variables. They determine the spread of the distribution along each axis. A larger variance corresponds to a greater spread along that axis.\nThe off-diagonal elements of the covariance matrix (\\(\\sigma_{12}, \\sigma_{21}\\)) are the covariances between the variables. They determine the orientation and shape of the distribution. If the covariance is positive, the distribution is stretched along the line \\(y=x\\), indicating that the variables tend to increase together. If the covariance is negative, the distribution is stretched along the line \\(y=-x\\), indicating that one variable tends to decrease as the other increases. If the covariance is zero, the variables are uncorrelated and the distribution is axis-aligned.\nIn Figure 23.5, the variances are identical and the variables are correlated (covariance is 4), so the distribution is stretched along the line \\(y=x\\).\n\n\n\n\n\n\n\n\nFigure 23.6: Bivariate Normal. Mean zero and covariance \\(\\Sigma=\\begin{pmatrix} 9 & 4 \\\\ 4 & 9\\end{pmatrix}\\).\n\n\n\n\n\n\nExample 23.8 (The Bivariate Normal Distribution with Mean Zero and Zero Covariances) The Bivariate Normal Distribution with Mean Zero and Zero Covariances \\(\\sigma_{12} = \\sigma_{21} = 0\\).\n\\(\\Sigma=\\begin{pmatrix} 9 & 0 \\\\ 0 & 9\\end{pmatrix}\\)\n\n\n\n\n\n\n\n\nFigure 23.7: Bivariate Normal. Mean zero and covariance \\(\\Sigma=\\begin{pmatrix} 9 & 0 \\\\ 0 & 9\\end{pmatrix}\\)\n\n\n\n\n\n\n\nExample 23.9 (The Bivariate Normal Distribution with Mean Zero and Negative Covariances) The Bivariate Normal Distribution with Mean Zero and Negative Covariances \\(\\sigma_{12} = \\sigma_{21} = -4\\).\n\\(\\Sigma=\\begin{pmatrix} 9 & -4 \\\\ -4 & 9\\end{pmatrix}\\)\n\n\n\n\n\n\n\n\nFigure 23.8: Bivariate Normal. Mean zero and covariance \\(\\Sigma=\\begin{pmatrix} 9 & -4 \\\\ -4 & 9\\end{pmatrix}\\)",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Basic Statistics and Data Analysis</span>"
    ]
  },
  {
    "objectID": "100_ddmo_eda.html#covariance",
    "href": "100_ddmo_eda.html#covariance",
    "title": "23  Basic Statistics and Data Analysis",
    "section": "23.13 Covariance",
    "text": "23.13 Covariance\nIn statistics, understanding the relationship between random variables is crucial for making inferences and predictions. Two common measures of such relationships are covariance and correlation. Covariance is a measure of how much two random variables change together. If the variables tend to show similar behavior (i.e., when one increases, the other tends to increase), the covariance is positive. Conversely, if they tend to move in opposite directions, the covariance is negative.\n\nDefinition 23.19 (Covariance) Covariance is calculated as:\n\\[\n\\text{Cov}(X, Y) = E[(X - E[X])(Y - E[Y])] = E[XY] - E[X]E[Y]\n\\]\nHere, \\(E[X]\\) and \\(E[Y]\\) are the expected values (means) of \\(X\\) and \\(Y\\), respectively. Covariance has units that are the product of the units of \\(X\\) and \\(Y\\).\n\nFor a vector of random variables \\(\\mathbf{Y} = \\begin{pmatrix} Y^{(1)}, \\ldots, Y^{(n)} \\end{pmatrix}^T\\), the covariance matrix \\(\\Sigma\\) encapsulates the covariances between each pair of variables:\n\\[\n\\Sigma = \\text{Cov}(\\mathbf{Y}, \\mathbf{Y}) =\n\\begin{pmatrix}\n\\text{Var}(Y^{(1)}) & \\text{Cov}(Y^{(1)}, Y^{(2)}) & \\ldots \\\\\n\\text{Cov}(Y^{(2)}, Y^{(1)}) & \\text{Var}(Y^{(2)}) & \\ldots \\\\\n\\vdots & \\vdots & \\ddots\n\\end{pmatrix}\n\\]\nThe diagonal elements represent the variances, while the off-diagonal elements are the covariances.",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Basic Statistics and Data Analysis</span>"
    ]
  },
  {
    "objectID": "100_ddmo_eda.html#correlation",
    "href": "100_ddmo_eda.html#correlation",
    "title": "23  Basic Statistics and Data Analysis",
    "section": "23.14 Correlation",
    "text": "23.14 Correlation\n\n23.14.1 Definitions\n\nDefinition 23.20 ((Pearson) Correlation Coefficient) The Pearson correlation coefficient, often denoted by \\(\\rho\\) for the population or \\(r\\) for a sample, is calculated by dividing the covariance of two variables by the product of their standard deviations.\n\\[\n\\rho_{XY} = \\frac{\\text{Cov}(X, Y)}{\\sigma_X \\sigma_Y},\n\\tag{23.3}\\]\nwhere \\(\\text{Cov}(X, Y)\\) is the covariance between variables \\(X\\) and \\(Y\\), and \\(\\sigma_X\\) and \\(\\sigma_Y\\) are the standard deviations of \\(X\\) and \\(Y\\), respectively.\n\nCorrelation, specifically the correlation coefficient, is a normalized measure of the linear relationship between two variables. It provides a value ranging from \\(-1\\) to \\(1\\), which is scale-free, making it easier to interpret:\n\n\\(-1\\): Perfect negative correlation, indicating that as one variable increases, the other decreases.\n\\(0\\): No correlation, indicating no linear relationship between the variables.\n\\(1\\): Perfect positive correlation, indicating that both variables increase together.\n\nThe correlation matrix \\(\\Psi\\) provides a way to quantify the linear relationship between multiple variables, extending the notion of the correlation coefficient beyond just pairs of variables. It is derived from the covariance matrix \\(\\Sigma\\) by normalizing each element with respect to the variances of the relevant variables.\n\nDefinition 23.21 (The Correlation Matrix \\(\\Psi\\)) Given a set of random variables \\(X_1, X_2, \\ldots, X_n\\), the covariance matrix \\(\\Sigma\\) is:\n\\[\n\\Sigma = \\begin{pmatrix}\n\\sigma_{11} & \\sigma_{12} & \\cdots & \\sigma_{1n} \\\\\n\\sigma_{21} & \\sigma_{22} & \\cdots & \\sigma_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\sigma_{n1} & \\sigma_{n2} & \\cdots & \\sigma_{nn}\n\\end{pmatrix},\n\\]\nwhere \\(\\sigma_{ij} = \\text{cov}(X_i, X_j)\\) is the covariance between the \\(i^{\\text{th}}\\) and \\(j^{\\text{th}}\\) variables. The correlation matrix \\(\\Psi\\) is then defined as:\n\\[\n\\Psi = \\begin{pmatrix} \\rho_{ij} \\end{pmatrix} = \\begin{pmatrix} \\frac{\\sigma_{ij}}{\\sqrt{\\sigma_{ii} \\sigma_{jj}}} \\end{pmatrix},\n\\]\nwhere:\n\n\\(\\rho_{ij}\\) is the correlation coefficient between the \\(i^{\\text{th}}\\) and \\(j^{\\text{th}}\\) variables.\n\\(\\sigma_{ii}\\) is the variance of the \\(i^{\\text{th}}\\) variable, i.e., \\(\\sigma_i^2\\).\n\\(\\sqrt{\\sigma_{ii}}\\) is the standard deviation of the \\(i^{\\text{th}}\\) variable, denoted as \\(\\sigma_i\\).\n\nThus, \\(\\Psi\\) can also be expressed as:\n\\[\n\\Psi = \\begin{pmatrix}\n1 & \\frac{\\sigma_{12}}{\\sigma_1 \\sigma_2} & \\cdots & \\frac{\\sigma_{1n}}{\\sigma_1 \\sigma_n} \\\\\n\\frac{\\sigma_{21}}{\\sigma_2 \\sigma_1} & 1 & \\cdots & \\frac{\\sigma_{2n}}{\\sigma_2 \\sigma_n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\frac{\\sigma_{n1}}{\\sigma_n \\sigma_1} & \\frac{\\sigma_{n2}}{\\sigma_n \\sigma_2} & \\cdots & 1\n\\end{pmatrix}\n\\]\n\nThe correlation matrix \\(\\Psi\\) has the following properties:\n\nThe matrix \\(\\Psi\\) is symmetric, meaning \\(\\rho_{ij} = \\rho_{ji}\\).\nThe diagonal elements are all 1, as \\(\\rho_{ii} = \\frac{\\sigma_{ii}}{\\sigma_i \\sigma_i} = 1\\).\nEach off-diagonal element is constrained between -1 and 1, indicating the strength and direction of the linear relationship between pairs of variables.\n\n\n\n23.14.2 Computations\n\nExample 23.10 (Computing a Correlation Matrix) Suppose you have a dataset consisting of three variables: \\(X\\), \\(Y\\), and \\(Z\\). You can compute the correlation matrix as follows:\n\nCalculate the covariance matrix \\(\\Sigma\\), which contains covariances between all pairs of variables.\nExtract the standard deviations for each variable from the diagonal elements of \\(\\Sigma\\).\nUse the standard deviations to compute the correlation matrix \\(\\Psi\\).\n\nSuppose we have two sets of data points:\n\n\\(X = [1, 2, 3]\\)\n\\(Y = [4, 5, 6]\\)\n\nWe want to compute the correlation matrix \\(\\Psi\\) for these variables. First, calculate the mean of each variable.\n\\[\n\\bar{X} = \\frac{1 + 2 + 3}{3} = 2\n\\]\n\\[\n\\bar{Y} = \\frac{4 + 5 + 6}{3} = 5\n\\]\nSecond, compute the covariance between \\(X\\) and \\(Y\\). The covariance is calculated as:\n\\[\n\\text{Cov}(X, Y) = \\frac{1}{n-1} \\sum_{i=1}^{n} (X_i - \\bar{X})(Y_i - \\bar{Y})\n\\]\nFor our data:\n\\[\n\\text{Cov}(X, Y) = \\frac{1}{3-1} \\left[(1 - 2)(4 - 5) + (2 - 2)(5 - 5) + (3 - 2)(6 - 5)\\right]\n\\]\n\\[\n= \\frac{1}{2} \\left[1 + 0 + 1\\right] = 1\n\\]\nThird, calculate the variances of \\(X\\) and \\(Y\\). Variance is calculated as:\n\\[\n\\text{Var}(X) = \\frac{1}{n-1} \\sum_{i=1}^{n} (X_i - \\bar{X})^2\n\\]\n\\[\n= \\frac{1}{2} \\left[(1-2)^2 + (2-2)^2 + (3-2)^2\\right] = \\frac{1}{2} (1 + 0 + 1) = 1\n\\]\nSimilarly,\n\\[\n\\text{Var}(Y) = \\frac{1}{2} \\left[(4-5)^2 + (5-5)^2 + (6-5)^2\\right] = \\frac{1}{2} (1 + 0 + 1) = 1\n\\]\nThen, compute the correlation coefficient. The correlation coefficient \\(\\rho_{XY}\\) is:\n\\[\n\\rho_{XY} = \\frac{\\text{Cov}(X, Y)}{\\sqrt{\\text{Var}(X)} \\cdot \\sqrt{\\text{Var}(Y)}}\n\\]\n\\[\n= \\frac{1}{\\sqrt{1} \\cdot \\sqrt{1}} = 1\n\\]\nFinally, construct the correlation matrix. The correlation matrix \\(\\Psi\\) is given as:\n\\[\n\\Psi = \\begin{pmatrix}\n1 & \\rho_{XY} \\\\\n\\rho_{XY} & 1\n\\end{pmatrix}\n= \\begin{pmatrix}\n1 & 1 \\\\\n1 & 1\n\\end{pmatrix}\n\\]\nThus, for these two variables, the correlation matrix indicates a perfect positive linear relationship (correlation coefficient of 1) between \\(X\\) and \\(Y\\).\n\n\n\n23.14.3 The Outer-product and the np.outer Function\nThe function np.outer from the NumPy library computes the outer product of two vectors. The outer product of two vectors results in a matrix, where each element is the product of an element from the first vector and an element from the second vector.\n\nDefinition 23.22 (Outer Product) For two vectors \\(\\mathbf{a}\\) and \\(\\mathbf{b}\\), the outer product is defined in terms of their elements as:\n\\[\n\\text{outer}(\\mathbf{a}, \\mathbf{b}) = \\begin{pmatrix}\na_1 \\cdot b_1 & a_1 \\cdot b_2 & \\cdots & a_1 \\cdot b_n \\\\\na_2 \\cdot b_1 & a_2 \\cdot b_2 & \\cdots & a_2 \\cdot b_n \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_m \\cdot b_1 & a_m \\cdot b_2 & \\cdots & a_m \\cdot b_n\n\\end{pmatrix},\n\\]\nwhere \\(\\mathbf{a}\\) is a vector of length \\(m\\) and \\(\\mathbf{b}\\) is a vector of length \\(n\\).\n\n\nExample 23.11 (Computing the Outer Product) We will consider two vectors, \\(\\mathbf{a}\\) and \\(\\mathbf{b}\\):\n\nimport numpy as np\n\na = np.array([1, 2, 3])\nb = np.array([4, 5])\nouter_product = np.outer(a, b)\nprint(\"Vector a:\", a)\nprint(\"Vector b:\", b)\nprint(\"Outer Product:\\n\", outer_product)\n\nVector a: [1 2 3]\nVector b: [4 5]\nOuter Product:\n [[ 4  5]\n [ 8 10]\n [12 15]]\n\n\nFor the vectors defined:\n\\[\n\\mathbf{a} = [1, 2, 3], \\quad \\mathbf{b} = [4, 5]\n\\]\nThe outer product will be:\n\\[\n\\begin{pmatrix}\n1 \\cdot 4 & 1 \\cdot 5 \\\\\n2 \\cdot 4 & 2 \\cdot 5 \\\\\n3 \\cdot 4 & 3 \\cdot 5\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n4 & 5 \\\\\n8 & 10 \\\\\n12 & 15\n\\end{pmatrix}.\n\\]\n\nThus, np.outer creates a matrix with dimensions \\(m \\times n\\), where \\(m\\) is the length of the first vector and \\(n\\) is the length of the second vector. The function is particularly useful in various mathematical and scientific computations where matrix representations of vector relationships are needed.\n\nExample 23.12 (Computing the Covariance and the Correlation Matrix) The following Python code computes the covariance and correlation matrices using the NumPy library.\n\nimport numpy as np\n\ndef calculate_cov_corr_matrices(data, rowvar=False)-&gt;(np.array, np.array):\n    \"\"\"\n    Calculate the covariance and correlation matrices of the input data.\n\n    Args:\n        data (np.array):\n            Input data array.\n        rowvar (bool):\n            Whether the data is row-wise or column-wise.\n            Default is False (column-wise).\n\n    Returns:\n        np.array: Covariance matrix.\n        np.array: Correlation matrix.\n\n    Examples:\n        &gt;&gt;&gt; data = np.array([[1, 2, 3],\n                         [4, 5, 6],\n                         [7, 8, 9]])\n        &gt;&gt;&gt; calculate_cov_corr_matrices(data)\n    \"\"\"   \n    cov_matrix = np.cov(data, rowvar=rowvar)\n    std_devs = np.sqrt(np.diag(cov_matrix))\n    # check whether the standard deviations are zero\n    # and throw an error if they are\n    if np.any(std_devs == 0):\n        raise ValueError(\"Correlation matrix cannot be computed,\"+\n                         \" because one or more variables have zero variance.\")\n    corr_matrix = cov_matrix / np.outer(std_devs, std_devs)\n    return cov_matrix, corr_matrix\n\n\nA = np.array([[0,1],\n                 [1,0]])\nprint(f\"Input matrix:\\n {A}\")\nSigma, Psi = calculate_cov_corr_matrices(A)\nprint(f\"Covariance matrix:\\n {Sigma}\")\nprint(f\"Correlation matrix:\\n {Psi}\")\n\nInput matrix:\n [[0 1]\n [1 0]]\nCovariance matrix:\n [[ 0.5 -0.5]\n [-0.5  0.5]]\nCorrelation matrix:\n [[ 1. -1.]\n [-1.  1.]]\n\n\n\n\n\n23.14.4 Correlation and Independence\n\nDefinition 23.23 (Statistical Independence (Independence of Random Vectors)) Two random vectors are statistically independent if the joint distribution of the vectors is equal to the product of their marginal distributions.\n\nThis means that knowing the realization of one vector gives you no information about the realization of the other vector. This independence is a probabilistic concept used in statistics and probability theory to denote that two sets of random variables do not affect each other. Independence implies that all pairwise covariances between the components of the two vectors are zero, but zero covariance does not imply independence unless certain conditions are met (e.g., normality). Statistical independence is a stronger condition than zero covariance. Statistical independence is not related to the linear independence of vectors in linear algebra.\n\nExample 23.13 (Covariance of Independent Variables) Consider a covariance matrix where variables are independent:\n\nA = np.array([[1,-1],\n[2,0],\n[3,1],\n[4,0],\n[5,-1]])\nprint(f\"Input matrix:\\n {A}\")\nSigma, Psi = calculate_cov_corr_matrices(A)\nprint(f\"Covariance matrix:\\n {Sigma}\")\nprint(f\"Correlation matrix:\\n {Psi}\")\n\nInput matrix:\n [[ 1 -1]\n [ 2  0]\n [ 3  1]\n [ 4  0]\n [ 5 -1]]\nCovariance matrix:\n [[2.5 0. ]\n [0.  0.7]]\nCorrelation matrix:\n [[1. 0.]\n [0. 1.]]\n\n\nHere, since the off-diagonal elements are 0, the variables are uncorrelated. \\(X\\) increases linearly, while \\(Y\\) alternates in a simple pattern with no trend that is linearly related to \\(Y\\).\n\n\nExample 23.14 (Strong Correlation) For a covariance matrix with strong positive correlation:\n\nA = np.array([[10,-1],\n[20,0],\n[30,1],\n[40,2],\n[50,3]])\nprint(f\"Input matrix:\\n {A}\")\nSigma, Psi = calculate_cov_corr_matrices(A)\nprint(f\"Covariance matrix:\\n {Sigma}\")\nprint(f\"Correlation matrix:\\n {Psi}\") \n\nInput matrix:\n [[10 -1]\n [20  0]\n [30  1]\n [40  2]\n [50  3]]\nCovariance matrix:\n [[250.   25. ]\n [ 25.    2.5]]\nCorrelation matrix:\n [[1. 1.]\n [1. 1.]]\n\n\nA value close to 1 suggests a strong positive relationship between the variables.\n\n\nExample 23.15 (Strong Negative Correlation)  \n\nA = np.array([[10,1],\n[20,0],\n[30,-1],\n[40,-2],\n[50,-3]])\nprint(f\"Input matrix:\\n {A}\")\nSigma, Psi = calculate_cov_corr_matrices(A)\nprint(f\"Covariance matrix:\\n {Sigma}\")\nprint(f\"Correlation matrix:\\n {Psi}\") \n\nInput matrix:\n [[10  1]\n [20  0]\n [30 -1]\n [40 -2]\n [50 -3]]\nCovariance matrix:\n [[250.  -25. ]\n [-25.    2.5]]\nCorrelation matrix:\n [[ 1. -1.]\n [-1.  1.]]\n\n\nThis matrix indicates a perfect negative correlation where one variable increases as the other decreases.\n\n\n\n23.14.5 Pearson’s Correlation\n\nVideo: [Pearson’s Correlation, Clearly Explained]\n\n\n\n23.14.6 Interpreting the Correlation: Correlation Squared\nRummel (1976) describes how to interpret correlations as follows:\nSeldom, indeed, will a correlation be zero or perfect. Usually, the covariation between things will be something like \\(.56\\) or \\(-.16\\). Clearly \\(.56\\) is positive, indicating positive covariation; \\(-.16\\) is negative, indicating some negative covariation. Moreover, we can say that the positive correlation is greater than the negative. But, we require more than. If we have a correlation of \\(.56\\) between two variables, for example, what precisely can we say other than the correlation is positive and \\(.56\\)? The squared correlation describes the proportion of variance in common between the two variables. If we multiply this by 100 we then get the percent of variance in common between two variables. That is:\n\\[\nr^2_{XY} \\times  100 = \\text{percent of variance in common between} X \\text{ and } Y.\n\\]\nFor example, we found that the correlation between a nation’s power and its defense budget was \\(.66\\). This correlation squared is \\(.45\\), which means that across the fourteen nations constituting the sample \\(45\\) percent of their variance on the two variables is in common (or \\(55\\) percent is not in common). In thus squaring correlations and transforming covariance to percentage terms we have an easy to understand meaning of correlation. And we are then in a position to evaluate a particular correlation. As a matter of routine it is the squared correlations that should be interpreted. This is because the correlation coefficient is misleading in suggesting the existence of more covariation than exists, and this problem gets worse as the correlation approaches zero.\n\nExample 23.16 (The relationship between study time and test scores) Imagine we are examining the relationship between the number of hours students study for a subject (Variable \\(A\\)) and their scores on a test (Variable \\(B\\)). After analyzing the data, we calculate a correlation of 0.8 between study time and test scores. When we square this correlation coefficient (\\(0.8^2\\) = 0.64), we get 0.64 or 64%. This means that 64% of the variability in test scores can be accounted for by the variability in study hours. This indicates that a substantial part of why students score differently on the test can be explained by how much they studied. However, there remains 36% of the variability in test scores that needs to be explained by other factors, such as individual abilities, the difficulty of the test, or other external influences.\n\n\n\n23.14.7 Partial Correlation\nOften, a correlation between two variables \\(X\\) and \\(Y\\) can be found only because both variables are correlated with a third variable \\(Z\\). The correlation between \\(X\\) and \\(Y\\) is then a spurious correlation. Therefore, it is often of interest to determine the correlation between \\(X\\) and \\(Y\\) while partializing a variable \\(Z\\), i.e., the correlation between \\(X\\) and \\(Y\\) that exists without the influence of \\(Z\\). Such a correlation \\(\\rho_{(X,Y)/Z}\\) is called the partial correlation of \\(X\\) and \\(Y\\) while holding \\(Z\\) constant. It is given by \\[\\begin{equation}\n\\rho_{(X,Y)/Z} = \\frac{\\rho_{XY} - \\rho_{XZ}\\rho_{YZ}}{\\sqrt{(1-\\rho_{XZ}^2)(1-\\rho_{YZ}^2)}},\n\\end{equation}\\] where \\(\\rho_{XY}\\) is the correlation between \\(X\\) and \\(Y\\), \\(\\rho_{XZ}\\) is the correlation between \\(X\\) and \\(Z\\), and \\(\\rho_{YZ}\\) is the correlation between \\(Y\\) and \\(Z\\) (Hartung, Elpert, and Klösener 1995).\nIf the variables \\(X\\), \\(Y\\) and \\(Z\\) are jointly normally distributed in the population of interest, one can estimate \\(\\rho_{(X,Y)/Z}\\) based on \\(n\\) realizations \\(x_1, \\ldots, x_n\\), \\(y_1, \\ldots, y_n\\) and \\(z_1, \\ldots, z_n\\) of the random variables \\(X\\), \\(Y\\) and \\(Z\\) by replacing the simple correlations \\(\\rho_{XY}\\), \\(\\rho_{XZ}\\) and \\(\\rho_{YZ}\\) with the empirical correlations \\(\\hat{\\rho}_{XY}\\), \\(\\hat{\\rho}_{XZ}\\) and \\(\\hat{\\rho}_{YZ}\\). The partial correlation coefficient \\(\\hat{\\rho}_{(X,Y)/Z}\\) is then estimated using \\[\\begin{equation}\nr_{(X,Y)/Z} = \\frac{r_{XY} - r_{XZ}r_{YZ}}{\\sqrt{(1-r_{XZ}^2)(1-r_{YZ}^2)}}.\n\\end{equation}\\] Based on this estimated value for the partial correlation, a test at the \\(\\alpha\\) level for partial uncorrelatedness or independence of \\(X\\) and \\(Y\\) under \\(Z\\) can also be carried out. The hypothesis\n\\[\\begin{equation}\nH_0: \\rho_{(X,Y)/Z} = 0\n\\end{equation}\\] is tested against the alternative \\[\\begin{equation}\nH_1: \\rho_{(X,Y)/Z} \\neq 0\n\\end{equation}\\] at the level \\(\\alpha\\) is discarded if \\[\n\\left|\n\\frac{r_{(X,Y)/Z} \\sqrt{n-3}}{\\sqrt{1-r_{(X,Y)/Z}^2}}\n\\right| &gt; t_{n-3, 1-\\alpha/2}\n\\] applies. Here \\(t_{n-3, 1-\\alpha/2}\\) is the (\\(1-\\alpha/2\\))-quantile of the \\(t\\)-distribution with \\(n-3\\) degrees of freedom.\n\nExample 23.17 For example, given economic data on the consumption \\(X\\), income \\(Y\\), and wealth \\(Z\\) of various individuals, consider the relationship between consumption and income. Failing to control for wealth when computing a correlation coefficient between consumption and income would give a misleading result, since income might be numerically related to wealth which in turn might be numerically related to consumption; a measured correlation between consumption and income might actually be contaminated by these other correlations. The use of a partial correlation avoids this problem (Wikipedia contributors 2024).\n\n\nExample 23.18 (Partial Correlation. Numerical Example) Given the following data, calculate the partial correlation between \\(A\\) and \\(B\\), controlling for \\(C\\). \\[\nA = \\begin{pmatrix}\n2\\\\\n4\\\\\n15\\\\\n20\n\\end{pmatrix}, \\quad B = \\begin{pmatrix}\n1\\\\\n2\\\\\n3\\\\\n4\n\\end{pmatrix}, \\quad C = \\begin{pmatrix}\n0\\\\\n0\\\\\n1\\\\\n1\n\\end{pmatrix}\n\\]\n\nfrom spotpython.utils.stats import partial_correlation\nimport numpy as np\nimport pandas as pd\ndata = pd.DataFrame({\n    'A': [2, 4, 15, 20],\n    'B': [1, 2, 3, 4],\n    'C': [0, 0, 1, 1]\n})\nprint(f\"Correlation between A and B: {data['A'].corr(data['B'])}\")\npc = partial_correlation(data, method='pearson')\nprint(f\"Partial Correlation between A and B: {pc[\"estimate\"][0, 1]}\")\n\nCorrelation between A and B: 0.9695015519208121\nPartial Correlation between A and B: 0.9191450300180576\n\n\n\nInstead of considering only one variable \\(Z\\), multiple variables \\(Z_i\\) can be considered. The formal definiton of partial correlation reads as follows:\n\nDefinition 23.24 (Partial Correlation) Formally, the partial correlation between \\(X\\) and \\(Y\\) given a set of \\(n\\) controlling variables \\(\\mathbf{Z} = \\{Z_1, Z_2, \\ldots, Z_n\\}\\), written \\(\\rho_{XY \\cdot \\mathbf{Z}}\\), is the correlation between the residuals \\(e_X\\) and \\(e_Y\\) resulting from the linear regression of \\(X\\) with \\(\\mathbf{Z}\\) and of \\(Y\\) with \\(\\mathbf{Z}\\), respectively. The first-order partial correlation (i.e., when \\(n = 1\\)) is the difference between a correlation and the product of the removable correlations divided by the product of the coefficients of alienation of the removable correlations (Wikipedia contributors 2024).\n\nLike the correlation coefficient, the partial correlation coefficient takes on a value in the range from -1 to 1. The value -1 conveys a perfect negative correlation controlling for some variables (that is, an exact linear relationship in which higher values of one variable are associated with lower values of the other); the value 1 conveys a perfect positive linear relationship, and the value 0 conveys that there is no linear relationship (Wikipedia contributors 2024).\n\nLemma 23.1 (Matrix Representation of the Partial Correlation) The partial correlation can also be written in terms of the joint precision matrix (Wikipedia contributors 2024). Consider a set of random variables, \\(\\mathbf{V} = \\{X_1,\\dots, X_n\\}\\) of cardinality \\(n\\). We want the partial correlation between two variables \\(X_i\\) and \\(X_j\\) given all others, i.e., \\(\\mathbf{V} \\setminus \\{X_i, X_j\\}\\). Suppose the (joint/full) covariance matrix \\(\\Sigma = (\\sigma_{ij})\\) is positive definite and therefore invertible. If the precision matrix is defined as \\(\\Omega = (p_{ij}) = \\Sigma^{-1}\\), then \\[\\begin{equation}\n\\rho_{X_i X_j \\cdot \\mathbf{V} \\setminus \\{X_i,X_j\\}} = - \\frac{p_{ij}}{\\sqrt{p_{ii}p_{jj}}}\n\\end{equation}\\]\n\nThe semipartial correlation statistic is similar to the partial correlation statistic; both compare variations of two variables after certain factors are controlled for. However, to calculate the semipartial correlation, one holds the third variable constant for either X or Y but not both; whereas for the partial correlation, one holds the third variable constant for both (Wikipedia contributors 2024).",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Basic Statistics and Data Analysis</span>"
    ]
  },
  {
    "objectID": "100_ddmo_eda.html#hypothesis-testing-and-the-null-hypothesis",
    "href": "100_ddmo_eda.html#hypothesis-testing-and-the-null-hypothesis",
    "title": "23  Basic Statistics and Data Analysis",
    "section": "23.15 Hypothesis Testing and the Null-Hypothesis",
    "text": "23.15 Hypothesis Testing and the Null-Hypothesis\n\n23.15.1 Alternative Hypotheses, Main Ideas\n\n\n23.15.2 p-values: What they are and how to interpret them\n\n23.15.2.1 How to calculate p-values\n\n\n23.15.2.2 p-hacking: What it is and how to avoid it",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Basic Statistics and Data Analysis</span>"
    ]
  },
  {
    "objectID": "100_ddmo_eda.html#statistical-power",
    "href": "100_ddmo_eda.html#statistical-power",
    "title": "23  Basic Statistics and Data Analysis",
    "section": "23.16 Statistical Power",
    "text": "23.16 Statistical Power\n\nVideo: Statistical Power, Clearly Explained\n\n\n23.16.0.1 Power Analysis\n\nVideo: Power Analysis, Clearly Explained!!!",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Basic Statistics and Data Analysis</span>"
    ]
  },
  {
    "objectID": "100_ddmo_eda.html#the-central-limit-theorem",
    "href": "100_ddmo_eda.html#the-central-limit-theorem",
    "title": "23  Basic Statistics and Data Analysis",
    "section": "23.17 The Central Limit Theorem",
    "text": "23.17 The Central Limit Theorem\n\nVideo: The Central Limit Theorem, Clearly Explained!!!",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Basic Statistics and Data Analysis</span>"
    ]
  },
  {
    "objectID": "100_ddmo_eda.html#sec-max-likelihood",
    "href": "100_ddmo_eda.html#sec-max-likelihood",
    "title": "23  Basic Statistics and Data Analysis",
    "section": "23.18 Maximum Likelihood",
    "text": "23.18 Maximum Likelihood\nMaximum likelihood estimation is a method used to estimate the parameters of a statistical model. It is based on the principle of choosing the parameter values that maximize the likelihood of the observed data. The likelihood function represents the probability of observing the data given the model parameters. By maximizing this likelihood, we can find the parameter values that best explain the observed data.\n\nExample 23.19 (Maximum Likelihood Estimation: Bernoulli Experiment) Bernoulli experiment for the event \\(A\\), repeated \\(n\\) times, with the probability of success \\(p\\). Result given as \\(n\\) tuple with entries \\(A\\) and \\(\\overline{A}\\). \\(A\\) appears \\(k\\) times. The probability of this event is given by \\[\\begin{equation}\nL(p) = p^k (1-p)^{n-k}\n\\end{equation}\\] Applying maximum likelihood estimation, we find the maximum of the likelihood function \\(L(p)\\), i.e., we are trying to find the value of \\(p\\) that maximizes the probability of observing the data. This value will be denoted as \\(\\hat{p}\\).\nDifferentiating the likelihood function with respect to \\(p\\) and setting the derivative to zero, we find the maximum likelihood estimate \\(\\hat{p}\\). We get \\[\\begin{align}\n\\frac{d}{dp} L(p) & = k p^{k-1} (1-p)^{n-k} - p^k (n-k) (1-p)^{n-k-1}\\\\\n                  & = p^{k-1} (1-p)^{n-k-1} \\left(k(1-p) - p(n-k)\\right) = 0\n\\end{align}\\]\nBecause \\[\np \\neq 0 \\text{ and } (1-p) p \\neq 0,\n\\] we can divide by \\(p^{k-1} (1-p)^{n-k-1}\\) and get \\[\\begin{equation}\nk(1-p) - p(n-k) = 0.\n\\end{equation}\\] Solving for \\(p\\) gives \\[\\begin{equation}\n\\hat{p} = \\frac{k}{n}\n\\end{equation}\\]\nTherefore, the maximum likelihood estimate for the probability of success in a Bernoulli experiment is the ratio of the number of successes to the total number of trials.\n\\(\\Box\\)\n\n\nExample 23.20 (Maximum Likelihood Estimation: Normal Distribution) Random variable \\(X \\sim \\mathcal{N}(\\mu, \\sigma^2)\\) with \\(n\\) observations \\(x_1, x_2, \\ldots, x_n\\). The likelihood function is given by \\[\\begin{equation}\nL(x_1, x_2, \\ldots, x_n, \\mu, \\sigma^2) = \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp\\left(-\\frac{(x_i - \\mu)^2}{2\\sigma^2}\\right)\n\\end{equation}\\]\nTaking the logarithm of the likelihood function, we get \\[\\begin{equation}\n\\log L(x_1, x_2, \\ldots, x_n, \\mu, \\sigma^2) = -\\frac{n}{2} \\log(2\\pi) - \\frac{n}{2} \\log(\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^n (x_i - \\mu)^2\n\\end{equation}\\]\nPartial derivative with respect to \\(\\mu\\) is \\[\\begin{align}\n\\frac{\\partial}{\\partial \\mu} \\log L(x_1, x_2, \\ldots, x_n, \\mu, \\sigma^2) & = \\frac{1}{\\sigma^2} \\sum_{i=1}^n (x_i - \\mu) = 0\n\\end{align}\\] We obtain the maximum likelihood estimate for \\(\\mu\\) as \\[\n\\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^n x_i,\n\\tag{23.4}\\] which is the sample mean \\(\\overline{x}\\).\nThe partial derivative with respect to \\(\\sigma^2\\) is \\[\\begin{align}\n\\frac{\\partial}{\\partial \\sigma^2} \\log L(x_1, x_2, \\ldots, x_n, \\mu, \\sigma^2) & = -\\frac{n}{2\\sigma^2} + \\frac{1}{2(\\sigma^2)^2} \\sum_{i=1}^n (x_i - \\mu)^2 = 0\n\\end{align}\\] This can be simplified to \\[\\begin{align}\n-n + \\frac{1}{\\sigma^2} \\sum_{i=1}^n (x_i - \\mu)^2 = 0\\\\\n\\Rightarrow n \\sigma^2 = \\sum_{i=1}^n (x_i - \\mu)^2\n\\end{align}\\] Using the maximum likelihood estimate for \\(\\mu\\) from Equation 23.4, we get \\[\\begin{equation}\n\\hat{\\sigma}^2 = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\hat{\\mu})^2\n= \\frac{1}{n} \\sum_{i=1}^n (x_i - \\overline{x})^2\n\\end{equation}\\] \\[\\begin{equation}\n= \\frac{n-1}{n} \\frac{\\sum_{i=1}^n (x_i - \\hat{\\mu})^2}{n-1} = \\frac{n-1}{n} s^2,\n\\end{equation}\\] where \\[\\begin{equation}\ns = \\sqrt{\\frac{\\sum_{i=1}^n (x_i- \\overline{x})}{n-1}}\n\\end{equation}\\] is the sample standard deviation. We obtain the maximum likelihood estimate for \\(\\sigma^2\\) as \\[\\begin{equation}\n\\hat{\\sigma}^2 = \\frac{n-1}{n} s^2\n\\end{equation}\\]\n\n\nVideo: Maximum Likelihood, clearly explained!!!\nVideo: Probability is not Likelihood. Find out why!!!",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Basic Statistics and Data Analysis</span>"
    ]
  },
  {
    "objectID": "100_ddmo_eda.html#maximum-likelihood-estimation-multivariate-normal-distribution",
    "href": "100_ddmo_eda.html#maximum-likelihood-estimation-multivariate-normal-distribution",
    "title": "23  Basic Statistics and Data Analysis",
    "section": "23.19 Maximum Likelihood Estimation: Multivariate Normal Distribution",
    "text": "23.19 Maximum Likelihood Estimation: Multivariate Normal Distribution\n\n23.19.1 The Joint Probability Density Function of the Multivariate Normal Distribution\nConsider the first \\(n\\) terms of an identically and independently distributed (i.i..d.) sequence \\({X^{(j)}}\\) of \\(k\\)-dimensional multivariate normal random vectors, i.e., \\[\nX^{(j)} \\sim N(\\mu, \\Sigma), j=1,2,\\ldots.\n\\tag{23.5}\\]\nThe joint probability density function of the \\(j\\)-th term of the sequence is \\[\nf_X(x_j) = \\frac{1}{\\sqrt{(2\\pi)^k \\det(\\Sigma)}} \\exp\\left(-\\frac{1}{2} (x_j-\\mu)^T\\Sigma^{-1} (x_j-\\mu)\\right),\n\\]\nwhere: \\(\\mu\\) is the \\(k \\times 1\\) mean vector; \\(\\Sigma\\) is the \\(k \\times k\\) covariance matrix. The covariance matrix \\(\\Sigma\\) is assumed to be positive definite, so that its determinant is strictly positive. We use \\(x_1, \\ldots x_n\\), i.e., the realizations of the first \\(n\\) random vectors in the sequence, to estimate the two unknown parameters \\(\\mu\\) and \\(\\Sigma\\).\n\n\n23.19.2 The Log-Likelihood Function\n\nDefinition 23.25 (Likelihood Function) The likelihood function is defined as the joint probability density function of the observed data, viewed as a function of the unknown parameters.\n\nSince the terms in the sequence Equation 23.5 are independent, their joint density is equal to the product of their marginal densities. As a consequence, the likelihood function can be written as the product of the individual densities:\n\\[\nL(\\mu, \\Sigma) = \\prod_{j=1}^n f_X(x_j) = \\prod_{j=1}^n \\frac{1}{\\sqrt{(2\\pi)^k \\det(\\Sigma)}} \\exp\\left(-\\frac{1}{2} (x_j-\\mu)^T\\Sigma^{-1} (x_j-\\mu)\\right)\n\\] \\[\n= \\frac{1}{(2\\pi)^{nk/2} \\det(\\Sigma)^{n/2}} \\exp\\left(-\\frac{1}{2} \\sum_{j=1}^n (x_j-\\mu)^T\\Sigma^{-1} (x_j-\\mu)\\right).\n\\tag{23.6}\\]\nTaking the natural logarithm of the likelihood function, we obtain the log-likelihood function:\n\nExample 23.21 (Log-Likelihood Function of the Multivariate Normal Distribution) The log-likelihood function of the multivariate normal distribution is given by \\[\n\\ell(\\mu, \\Sigma) = -\\frac{nk}{2} \\ln(2\\pi) - \\frac{n}{2} \\ln(\\det(\\Sigma)) - \\frac{1}{2} \\sum_{j=1}^n (x_j-\\mu)^T\\Sigma^{-1} (x_j-\\mu).\n\\]\n\nThe likelihood function is well-defined only if \\(\\det(\\Sigma)&gt;0\\).",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Basic Statistics and Data Analysis</span>"
    ]
  },
  {
    "objectID": "100_ddmo_eda.html#cross-validation",
    "href": "100_ddmo_eda.html#cross-validation",
    "title": "23  Basic Statistics and Data Analysis",
    "section": "23.20 Cross-Validation",
    "text": "23.20 Cross-Validation\n\nVideo: Machine Learning Fundamentals: Cross Validation\n\n\n23.20.0.1 Bias and Variance\n\nVideo: Machine Learning Fundamentals: Bias and Variance",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Basic Statistics and Data Analysis</span>"
    ]
  },
  {
    "objectID": "100_ddmo_eda.html#mutual-information",
    "href": "100_ddmo_eda.html#mutual-information",
    "title": "23  Basic Statistics and Data Analysis",
    "section": "23.21 Mutual Information",
    "text": "23.21 Mutual Information\n\\(R^2\\) works only for numerical data. Mutual information can also be used, when the dependent variable is boolean or categorical. Mutual information provides a way to quantify the relationship of a mixture of continuous and discrete variables to a target variable. Mutual information explains how closely related two variables are. It is a measure of the amount of information that one variable provides about another variable.\n\nDefinition 23.26 (Mutual Information) \\[\n\\text{MI} =\n\\sum_{x \\in X} \\sum_{y \\in Y} p(x, y) \\log \\left(\\frac{p(x, y)}{p(x)p(y)}\\right)\n\\tag{23.7}\\]\n\nThe terms in the nominator and denominator in Equation 23.7 are the joint probability, \\(p(x, y)\\), the marginal probability of \\(X\\), \\(p(x)\\) and the marginal probability of \\(Y\\), \\(p(y)\\) respectively. Joint probabilites are the probabilities of two events happening together. Marginal probabilities are the probabilities of individual events happening. If \\(p(x,y) = p(x)p(y)\\), then \\(X\\) and \\(Y\\) are independent. In this case, the mutual information is one.\nThe mutual information of two variables \\(X\\) and \\(Y\\) is \\[\\begin{align}\n\\text{MI}(X, Y) =\np(X,Y) \\log \\left(\\frac{p(X,Y)}{p(X)p(Y)}\\right) +\np(X, \\overline{Y}) \\log \\left(\\frac{p(X, \\overline{Y})}{p(X)p(\\overline{Y})}\\right) +  \\\\\np(\\overline{X}, Y) \\log \\left(\\frac{p(\\overline{X}, Y)}{p(\\overline{X})p(Y)}\\right) +\np(\\overline{X}, \\overline{Y}) \\log \\left(\\frac{p(\\overline{X}, \\overline{Y})}{p(\\overline{X})p(\\overline{Y})}\\right)\n\\end{align}\\]\nIn general, when at least one of the two features has no variance (i.e., it is constant), the mutual information is zero, because something that never changes cannot tell us about something that does. When two features change, but change in exact the same way, then \\(\\text{MI}\\) is \\(1/2\\). When two factors change, but in exact the opposite way, then \\(\\text{MI}\\) is \\(1/2\\). When both features change, it does not matter if they change in the exact same or exact opposite ways; both result in the same \\(\\text{MI}\\) value\n\n\n\n\n\n\nMutual Information\n\n\n\n\nVideo: Mutual Information, Clearly Explained",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Basic Statistics and Data Analysis</span>"
    ]
  },
  {
    "objectID": "100_ddmo_eda.html#t-sne",
    "href": "100_ddmo_eda.html#t-sne",
    "title": "23  Basic Statistics and Data Analysis",
    "section": "23.22 t-SNE",
    "text": "23.22 t-SNE\n\nVideo: t-SNE, Clearly Explained\n\n\n\n\n\nHartung, Joachim, Bärbel Elpert, and Karl-Heinz Klösener. 1995. Statistik. Oldenbourg.\n\n\nRummel, R. J. 1976. “Understanding Correlation.” https://www.hawaii.edu/powerkills/UC.HTM.\n\n\nWikipedia contributors. 2024. “Partial Correlation — Wikipedia, the Free Encyclopedia.” https://en.wikipedia.org/w/index.php?title=Partial_correlation&oldid=1253637419.",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Basic Statistics and Data Analysis</span>"
    ]
  },
  {
    "objectID": "100_ddmo_pca.html",
    "href": "100_ddmo_pca.html",
    "title": "24  Multicollinearity and Principle Component Analysis (PCA)",
    "section": "",
    "text": "24.1 Loading and Preprocessing the Data\nFirst, the data is preprocessed to ensure that it does not contain any NaN or infinite values. Then, PCA is performed to reduce the dimensions and extract the principal components. Finally, a linear regression is conducted on the extracted factors.\nWe load the data set and display the first few rows. The data set contains information about car sales, including various features such as price, engine size, horsepower, and more.\ndf = pd.read_csv(\"data/car_sales.csv\", encoding=\"utf-8\")\nprint(df.shape)\ndf.head()\n\n(157, 27)\n\n\n\n\n\n\n\n\n\nUnnamed: 0\nmanufact\nmodel\nsales\nresale\ntype\nprice\nengine_s\nhorsepow\nwheelbas\n...\nztype\nzprice\nzengine_\nzhorsepo\nzwheelba\nzwidth\nzlength\nzcurb_wg\nzfuel_ca\nzmpg\n\n\n\n\n0\n1\nAcura\nIntegra\n16.919\n16.360\n0\n21.50\n1.8\n140.0\n101.2\n...\n-0.592619\n-0.410458\n-1.207001\n-0.810378\n-0.822789\n-1.115337\n-1.112557\n-1.172124\n-1.222227\n0.970527\n\n\n1\n2\nAcura\nTL\n39.384\n19.875\n0\n28.40\n3.2\n225.0\n108.1\n...\n-0.592619\n0.070323\n0.133157\n0.688731\n0.080198\n-0.246243\n0.413677\n0.220418\n-0.193400\n0.270037\n\n\n2\n3\nAcura\nCL\n14.114\n18.225\n0\nNaN\n3.2\n225.0\n106.9\n...\n-0.592619\nNaN\n0.133157\n0.688731\n-0.076843\n-0.159334\n0.346672\n0.145875\n-0.193400\n0.503534\n\n\n3\n4\nAcura\nRL\n8.588\n29.725\n0\n42.00\n3.5\n210.0\n114.6\n...\n-0.592619\n1.017949\n0.420333\n0.424182\n0.930839\n0.072424\n0.689144\n0.748569\n0.012366\n-0.430452\n\n\n4\n5\nAudi\nA4\n20.397\n22.255\n0\n23.99\n1.8\n150.0\n102.6\n...\n-0.592619\n-0.236959\n-1.207001\n-0.634013\n-0.639574\n-0.854609\n-0.695634\n-0.602736\n-0.399165\n0.737030\n\n\n\n\n5 rows × 27 columns\n# Remove the first column (assuming it is an index or non-informative)\ndf = df.drop(df.columns[0], axis=1)\n# print the column names\nprint(df.columns)\n\nIndex(['manufact', 'model', 'sales', 'resale', 'type', 'price', 'engine_s',\n       'horsepow', 'wheelbas', 'width', 'length', 'curb_wgt', 'fuel_cap',\n       'mpg', 'lnsales', 'zresale', 'ztype', 'zprice', 'zengine_', 'zhorsepo',\n       'zwheelba', 'zwidth', 'zlength', 'zcurb_wg', 'zfuel_ca', 'zmpg'],\n      dtype='object')",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Multicollinearity and Principle Component Analysis (PCA)</span>"
    ]
  },
  {
    "objectID": "100_ddmo_pca.html#loading-and-preprocessing-the-data",
    "href": "100_ddmo_pca.html#loading-and-preprocessing-the-data",
    "title": "24  Multicollinearity and Principle Component Analysis (PCA)",
    "section": "",
    "text": "24.1.1 The Target Variable y\nTransform sales to log scale; handle negative or zero sales separately. Explicitly check and handle missing and infinite values.\n\ndf['ln_sales'] = np.log(df['sales'].replace(0, np.nan))\nif df['ln_sales'].isnull().any() or np.isinf(df['ln_sales']).any():\n    df['ln_sales'] = df['ln_sales'].fillna(df['ln_sales'].median())  # Or any other strategy\ny = df['ln_sales']\n\n\n\n24.1.2 The Features X\n\n\n24.1.3 Numerical Features\n\n\n24.1.4 Data Preprocessing\nThe following steps are performed during data preprocessing: 1. Check for NaN or infinite values in X. 2. Replace NaN and infinite values with the median of the respective column. 3. Remove constant or nearly constant columns. 4. Standardize the numerical predictors in X using StandardScaler. 5. Verify that X_scaled does not contain any NaN or infinite values.\n\n# Use columns from 'price' to 'mpg' as predictors\nindependent_var_columns = ['price', 'engine_s', 'horsepow', 'wheelbas', \n                           'width', 'length', 'curb_wgt', 'fuel_cap', 'mpg']\n\n# Select those columns, ensuring they are numeric\nX = df[independent_var_columns].apply(pd.to_numeric, errors='coerce')\n\n# Handle missing/nans in features by using an appropriate imputation strategy\nX = X.fillna(X.median())  # Impute with median or any other appropriate strategy\n# Display the first few rows of the features\nX.head()\n\n\n\n\n\n\n\n\nprice\nengine_s\nhorsepow\nwheelbas\nwidth\nlength\ncurb_wgt\nfuel_cap\nmpg\n\n\n\n\n0\n21.500\n1.8\n140.0\n101.2\n67.3\n172.4\n2.639\n13.2\n28.0\n\n\n1\n28.400\n3.2\n225.0\n108.1\n70.3\n192.9\n3.517\n17.2\n25.0\n\n\n2\n22.799\n3.2\n225.0\n106.9\n70.6\n192.0\n3.470\n17.2\n26.0\n\n\n3\n42.000\n3.5\n210.0\n114.6\n71.4\n196.6\n3.850\n18.0\n22.0\n\n\n4\n23.990\n1.8\n150.0\n102.6\n68.2\n178.0\n2.998\n16.4\n27.0\n\n\n\n\n\n\n\n\nif X.isnull().any().any():\n    print(\"NaNs detected in X. Filling with column medians.\")\n    X = X.fillna(X.median())\n\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\nif np.isnan(X_scaled).any() or np.isinf(X_scaled).any():\n    raise ValueError(\"X_scaled contains NaN or infinite values after preprocessing.\")\n# Convert the scaled data back to a DataFrame\nX_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n# Display the first few rows of the scaled features\nX_scaled.head()\n\n\n\n\n\n\n\n\nprice\nengine_s\nhorsepow\nwheelbas\nwidth\nlength\ncurb_wgt\nfuel_cap\nmpg\n\n\n\n\n0\n-0.410053\n-1.214376\n-0.814577\n-0.827661\n-1.121287\n-1.119971\n-1.182726\n-1.228700\n0.982411\n\n\n1\n0.075070\n0.134385\n0.694066\n0.081122\n-0.246689\n0.416070\n0.223285\n-0.193381\n0.272833\n\n\n2\n-0.318723\n0.134385\n0.694066\n-0.076927\n-0.159229\n0.348634\n0.148020\n-0.193381\n0.509359\n\n\n3\n1.031255\n0.423406\n0.427835\n0.937221\n0.073997\n0.693306\n0.756545\n0.013683\n-0.436744\n\n\n4\n-0.234987\n-1.214376\n-0.637089\n-0.643270\n-0.858907\n-0.700370\n-0.607830\n-0.400444\n0.745885\n\n\n\n\n\n\n\n\n\n24.1.5 Categorical Features\n\ncategorical_cols = ['type']  # Replace if more categorical variables exist\nencoder = OneHotEncoder(drop='first', sparse_output=False)\nX_categorical_encoded = encoder.fit_transform(df[categorical_cols])\n# Convert encoded data into a DataFrame\nX_categorical_encoded_df = pd.DataFrame(X_categorical_encoded,\n                                        columns=encoder.get_feature_names_out(categorical_cols))\nX_categorical_encoded_df.describe(include='all')\n\n\n\n\n\n\n\n\ntype_1\n\n\n\n\ncount\n157.000000\n\n\nmean\n0.261146\n\n\nstd\n0.440665\n\n\nmin\n0.000000\n\n\n25%\n0.000000\n\n\n50%\n0.000000\n\n\n75%\n1.000000\n\n\nmax\n1.000000\n\n\n\n\n\n\n\n\n\n24.1.6 Combine non-categorical and categorical (encoded) data\n\nX_encoded = pd.concat([X_scaled, X_categorical_encoded_df], axis=1)\nX_encoded.describe(include='all')\n\n\n\n\n\n\n\n\nprice\nengine_s\nhorsepow\nwheelbas\nwidth\nlength\ncurb_wgt\nfuel_cap\nmpg\ntype_1\n\n\n\n\ncount\n1.570000e+02\n1.570000e+02\n1.570000e+02\n1.570000e+02\n1.570000e+02\n1.570000e+02\n1.570000e+02\n1.570000e+02\n1.570000e+02\n157.000000\n\n\nmean\n-5.091469e-16\n1.018294e-16\n1.584012e-16\n3.892145e-15\n-2.489162e-16\n-1.584012e-16\n-2.941737e-16\n5.657187e-17\n1.980016e-17\n0.261146\n\n\nstd\n1.003200e+00\n1.003200e+00\n1.003200e+00\n1.003200e+00\n1.003200e+00\n1.003200e+00\n1.003200e+00\n1.003200e+00\n1.003200e+00\n0.440665\n\n\nmin\n-1.272376e+00\n-1.985097e+00\n-2.323220e+00\n-1.960346e+00\n-2.491490e+00\n-2.843334e+00\n-2.374152e+00\n-1.979307e+00\n-2.092426e+00\n0.000000\n\n\n25%\n-6.459349e-01\n-7.326758e-01\n-6.370894e-01\n-5.905870e-01\n-8.006008e-01\n-7.303412e-01\n-6.446622e-01\n-5.557424e-01\n-6.732705e-01\n0.000000\n\n\n50%\n-3.187230e-01\n-5.829498e-02\n-1.489990e-01\n-6.375655e-02\n-1.738055e-01\n4.142561e-02\n-5.695606e-02\n-1.933806e-01\n3.630749e-02\n0.000000\n\n\n75%\n3.232563e-01\n4.234056e-01\n5.165788e-01\n6.211231e-01\n6.570627e-01\n6.558419e-01\n6.412452e-01\n4.019282e-01\n5.093595e-01\n1.000000\n\n\nmax\n4.089638e+00\n4.758711e+00\n4.687533e+00\n4.111375e+00\n2.552025e+00\n2.783820e+00\n3.514119e+00\n3.637302e+00\n5.003353e+00\n1.000000",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Multicollinearity and Principle Component Analysis (PCA)</span>"
    ]
  },
  {
    "objectID": "100_ddmo_pca.html#fit-the-linear-regression-model-using-statsmodels",
    "href": "100_ddmo_pca.html#fit-the-linear-regression-model-using-statsmodels",
    "title": "24  Multicollinearity and Principle Component Analysis (PCA)",
    "section": "24.2 Fit the Linear Regression Model using statsmodels",
    "text": "24.2 Fit the Linear Regression Model using statsmodels\n\nX_encoded_with_const = sm.add_constant(X_encoded)  # Adds a constant term (intercept) to the model\nmodel = sm.OLS(df['ln_sales'], X_encoded_with_const).fit()",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Multicollinearity and Principle Component Analysis (PCA)</span>"
    ]
  },
  {
    "objectID": "100_ddmo_pca.html#model-summary-and-interpretation",
    "href": "100_ddmo_pca.html#model-summary-and-interpretation",
    "title": "24  Multicollinearity and Principle Component Analysis (PCA)",
    "section": "24.3 Model Summary and Interpretation",
    "text": "24.3 Model Summary and Interpretation\n\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:               ln_sales   R-squared:                       0.485\nModel:                            OLS   Adj. R-squared:                  0.449\nMethod:                 Least Squares   F-statistic:                     13.73\nDate:                Sun, 15 Jun 2025   Prob (F-statistic):           7.69e-17\nTime:                        12:34:53   Log-Likelihood:                -213.62\nNo. Observations:                 157   AIC:                             449.2\nDf Residuals:                     146   BIC:                             482.9\nDf Model:                          10                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          3.0678      0.114     26.962      0.000       2.843       3.293\nprice         -0.6451      0.177     -3.655      0.000      -0.994      -0.296\nengine_s       0.3557      0.192      1.854      0.066      -0.023       0.735\nhorsepow      -0.1364      0.229     -0.596      0.552      -0.589       0.316\nwheelbas       0.3166      0.174      1.816      0.071      -0.028       0.661\nwidth         -0.0763      0.140     -0.547      0.586      -0.352       0.200\nlength         0.2029      0.185      1.099      0.273      -0.162       0.568\ncurb_wgt       0.0842      0.211      0.399      0.691      -0.333       0.501\nfuel_cap      -0.2284      0.179     -1.276      0.204      -0.582       0.125\nmpg            0.3232      0.167      1.941      0.054      -0.006       0.652\ntype_1         0.8735      0.317      2.756      0.007       0.247       1.500\n==============================================================================\nOmnibus:                       41.296   Durbin-Watson:                   1.423\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              107.145\nSkew:                          -1.064   Prob(JB):                     5.42e-24\nKurtosis:                       6.442   Cond. No.                         11.4\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n24.3.1 The OLS Regression Results\nThe ANOVA table shows a significant F-value (observed in the output as Prob (F-statistic), with a value close to zero). This indicates that using the model is better than estimating the mean. Overall, the regression performs well in modeling the selected target variable (ln_sales). Nearly 40% of the variation in the ln_sales values is explained by the model, as shown by Adj. R-squared.\nAlthough the model fit appears positive, the coefficients (coef) reveal that too many predictors are included in the model. There are several non-significant coefficients (P&gt;|t| much larger than \\(0.05\\)), indicating that these variables contribute little to the model.\n\n\n24.3.2 The Coefficient Table\n\ncoeffs_table = compute_coefficients_table(\n    model=model,\n    X_encoded=X_encoded_with_const,\n    y=y,\n    vif_table=None\n)\nprint(\"\\nCoefficients Table:\")\nprint(coeffs_table)\n\n\nCoefficients Table:\n   Variable  Zero-Order r  Partial r  Semipartial r  Tolerance       VIF\n0     price     -0.551325  -0.289521      -0.217155   0.195662  5.110865\n1  engine_s     -0.139066   0.151682       0.110172   0.165615  6.038084\n2  horsepow     -0.386896  -0.049229      -0.035386   0.116244  8.602562\n3  wheelbas      0.292461   0.148618       0.107895   0.200566  4.985881\n4     width      0.040572  -0.045185      -0.032473   0.312675  3.198207\n5    length      0.216882   0.090597       0.065310   0.178835  5.591740\n6  curb_wgt     -0.040042   0.032981       0.023691   0.136742  7.313045\n7  fuel_cap     -0.017278  -0.105041      -0.075831   0.190355  5.253349\n8       mpg      0.119998   0.158587       0.115313   0.219810  4.549388\n9    type_1      0.273500   0.222382       0.163754   0.314477  3.179880\n\n\nThe coefficient table further suggests that there may be a problem with multicollinearity. For most predictors, the values of the partial correlations (Partial r) decrease significantly compared to the zero-order correlation (Zero-Order r).\nThe tolerance (Tolerance) indicates the percentage of variance in a specific predictor that cannot be explained by the other predictors. The low tolerances therefore show that approximately 70%-90%, i.e., 1 minus the Tolerance value in percent, of the variance in a given predictor can be explained by the other predictors. When tolerances are close to 0, high multicollinearity exists.\nA variance inflation factor (VIF) greater than 2 is typically considered problematic, and the smallest VIF in the table is already greater than 2.",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Multicollinearity and Principle Component Analysis (PCA)</span>"
    ]
  },
  {
    "objectID": "100_ddmo_pca.html#eigenvalues",
    "href": "100_ddmo_pca.html#eigenvalues",
    "title": "24  Multicollinearity and Principle Component Analysis (PCA)",
    "section": "24.4 Eigenvalues",
    "text": "24.4 Eigenvalues\nEigenvalues indicate how many factors can be meaningfully extracted. An eigenvalue greater than 1 suggests that the factor explains more variance than a single variable.\n\nfa_temp = FactorAnalyzer(n_factors=X_encoded.shape[1], method=\"principal\", rotation=None)\ntry:\n    fa_temp.fit(X_encoded)\n    ev, _ = fa_temp.get_eigenvalues()\n    # sort eigenvalues in ascending order\n    ev = np.sort(ev)\n    print(\"Eigenvalues for each component:\\n\", ev)\nexcept Exception as e:\n    print(f\"Error during factor analysis fitting: {e}\")\n    print(\"Consider reducing multicollinearity or removing problematic features.\")\n\nEigenvalues for each component:\n [0.06453844 0.09238346 0.13143422 0.15658714 0.20129034 0.25457714\n 0.33712112 1.14556836 1.64880929 5.96769049]",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Multicollinearity and Principle Component Analysis (PCA)</span>"
    ]
  },
  {
    "objectID": "100_ddmo_pca.html#collinearity-diagnostics-based-on-eigenvalues",
    "href": "100_ddmo_pca.html#collinearity-diagnostics-based-on-eigenvalues",
    "title": "24  Multicollinearity and Principle Component Analysis (PCA)",
    "section": "24.5 Collinearity Diagnostics Based on Eigenvalues",
    "text": "24.5 Collinearity Diagnostics Based on Eigenvalues\n\nX_cond = copy.deepcopy(X_encoded)\ncondition_index_df = condition_index(X_cond)\nprint(\"\\nCondition Index:\")\nprint(condition_index_df)\n\n\nCondition Index:\n   Index  Eigenvalue  Condition Index\n0      0    0.047116        11.150268\n1      1    0.067199         9.336595\n2      2    0.121066         6.955955\n3      3    0.146634         6.320499\n4      4    0.157663         6.095428\n5      5    0.248119         4.858905\n6      6    0.338187         4.161884\n7      7    0.736900         2.819449\n8      8    1.531162         1.955951\n9      9    5.857833         1.000000\n\n\nThe eigenvalue-based collinearity diagnostics confirm that there are serious issues with multicollinearity. Several eigenvalues (Eigenvalue) are close to 0, indicating that the predictors are highly correlated and that small changes in the data values can lead to large changes in the coefficient estimates.\nThe condition indices (Condition Index) are calculated as the square roots of the ratios of the largest eigenvalue to each subsequent eigenvalue. Values greater than 15 indicate a potential collinearity problem, while values greater than 30 suggest a severe issue. Five of these indices exceed 30, highlighting a very serious problem with multicollinearity.\n\n24.5.1 Kayser-Meyer-Olkin (KMO) Measure\nThe KMO measure (Kaiser-Meyer-Olkin) is a metric for assessing the suitability of data for factor analysis. A KMO value of 0.6 or higher is often considered acceptable; see also Wikipedia. A KMO value below 0.5 indicates that the data is not suitable for factor analysis.\n\nThe KMO measure is based on the correlation and partial correlation between variables.\nIt is calculated as follows: For each variable, the ratio of the squared sums of correlations to the squared sums of partial correlations is computed. The formula for the KMO measure is:\n\n\\[\nKMO = \\frac{\\displaystyle \\underset{j\\neq k}{\\sum\\sum} r_{jk}^2}{\\displaystyle \\underset{j\\neq k}{\\sum\\sum} r_{jk}^2+\\underset{j\\neq k}{\\sum\\sum} p_{jk}^2},\n\\]\nwhere \\(r_{ij}^2\\) are the squares of the correlations between variables \\(i\\) and \\(j\\), and \\(p_{ij}^2\\) are the squares of the partial correlations between variables \\(i\\) and \\(j\\).\n\nThe KMO measure ranges between 0 and 1.\nValues close to 1 indicate that factor analysis is suitable, as the variables are strongly correlated.\nValues close to 0 indicate that factor analysis is unsuitable, as the variables are only weakly correlated.\n\n\nkmo_all, kmo_model = calculate_kmo(X_encoded)\nprint(f\"\\nKMO measure: {kmo_model:.3f} (0.6+ is often considered acceptable)\")\n\n\nKMO measure: 0.835 (0.6+ is often considered acceptable)",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Multicollinearity and Principle Component Analysis (PCA)</span>"
    ]
  },
  {
    "objectID": "100_ddmo_pca.html#principal-component-analysis-factor-analysis-pca",
    "href": "100_ddmo_pca.html#principal-component-analysis-factor-analysis-pca",
    "title": "24  Multicollinearity and Principle Component Analysis (PCA)",
    "section": "24.6 Principal Component Analysis, Factor Analysis, PCA",
    "text": "24.6 Principal Component Analysis, Factor Analysis, PCA\nTo solve the multicollinearity problem, we can use PCA to reduce the number of predictors. PCA transforms the original correlated variables into a smaller set of uncorrelated variables called principal components. These components can then be used in regression models to avoid multicollinearity issues.\n\n24.6.1 Application of PCA in Regression Problems:\n\nDimensionality Reduction: PCA reduces the number of explanatory variables (features) by transforming the original variables into a smaller number of uncorrelated principal components. This can be particularly useful when dealing with many features, as fewer dimensions make the regression algorithm less prone to overfitting.\nReducing Multicollinearity: In linear regression models, multicollinearity among independent variables can lead to unstable estimates. PCA helps eliminate this multicollinearity because the resulting principal components are orthogonal to each other.\nHandling High-Dimensional Data: For datasets with a large number of variables, PCA can be used to reduce the dimensions to a manageable level before starting the regression.\nReduced Overfitting Tendencies: By removing redundant and highly correlated variables, PCA can help reduce the risk of overfitting by focusing the model on the most influential features.\nImproved Model Performance: In many cases, performing regression on the most important principal components instead of the original features can lead to better generalization and improved model performance on new, unseen data.\nInterpretation of Feature Importance: PCA provides insights into the importance of the original features through the variance explained by each principal component. This information can be used to identify which combinations of variables best represent the data.\n\n\n\n24.6.2 Loading Scores\n\nLoading Scores can be viewed as directional vectors in the feature space. The magnitude of the score indicates how dominant the variable is in the component, while the sign represents a direction.\nA high positive loading score means that the variable has a positive influence on the principal component and is correlated with it.\nA high negative loading score indicates that the variable is negatively correlated with the principal component, meaning it varies in the opposite direction.\nContribution to Variance: The loading score values indicate how much each original variable contributes to the explained variance in the respective principal component.",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Multicollinearity and Principle Component Analysis (PCA)</span>"
    ]
  },
  {
    "objectID": "100_ddmo_pca.html#pca-for-car-sales",
    "href": "100_ddmo_pca.html#pca-for-car-sales",
    "title": "24  Multicollinearity and Principle Component Analysis (PCA)",
    "section": "24.7 PCA for Car Sales",
    "text": "24.7 PCA for Car Sales\nThe Principal Component Analysis (PCA) is applied only to the features, not to the target variables. Here we use the pca_analysis function to perform PCA on the dataset. The function takes the following parameters:\n\ndf: The input DataFrame containing the features.\ndf_name: The name of the DataFrame (for display purposes).\nk: The number of principal components to extract.\nscaler: The scaler to use for standardizing the data (e.g., StandardScaler).\nmax_scree: The maximum number of components to display in the scree plot.\n\n\ntop_features = pca_analysis(df=X_encoded, df_name=\"car_sales\", k=10, scaler=StandardScaler(), max_scree=10)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Display the top features\nprint(\"Top Features from PCA:\")\nprint(f\"PCA 1: {top_features[0]}\")\nprint(f\"PCA 2: {top_features[1]}\")\n\nTop Features from PCA:\nPCA 1: Index(['curb_wgt', 'fuel_cap', 'engine_s', 'mpg', 'width', 'horsepow',\n       'wheelbas', 'length', 'price', 'type_1'],\n      dtype='object')\nPCA 2: Index(['price', 'horsepow', 'type_1', 'wheelbas', 'engine_s', 'length',\n       'fuel_cap', 'width', 'curb_wgt', 'mpg'],\n      dtype='object')",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Multicollinearity and Principle Component Analysis (PCA)</span>"
    ]
  },
  {
    "objectID": "100_ddmo_pca.html#pca-application-for-addressing-multicollinearity",
    "href": "100_ddmo_pca.html#pca-application-for-addressing-multicollinearity",
    "title": "24  Multicollinearity and Principle Component Analysis (PCA)",
    "section": "24.8 PCA Application for Addressing Multicollinearity",
    "text": "24.8 PCA Application for Addressing Multicollinearity\n\n24.8.1 Determining the Number of Factors for Factor Analysis\nThe number of factors is set to anz_fak=10 to reduce the dimensions. Factor analysis is performed with a Varimax rotation to improve the interpretability of the factors.\n\nanz_fak = 10\nn_factors = min(anz_fak, X_encoded.shape[1])\nfa = FactorAnalyzer(n_factors=n_factors, method=\"principal\", rotation=\"varimax\")\nfa.fit(X_encoded)\n# Factor loadings\nfactor_loadings = fa.loadings_\nactual_factors = factor_loadings.shape[1]  # Number of factors actually extracted\nprint(f\"actual_factors: {actual_factors}\")\nif actual_factors &lt; n_factors:\n    print(\n        f\"\\nWarning: Only {actual_factors} factors could be extracted \"\n        f\"(requested {n_factors}).\"\n    )\nfactor_columns = [f\"Factor{i+1}\" for i in range(actual_factors)]\n\nactual_factors: 10\n\n\n\n\n24.8.2 Factor Loadings\nFactor Loadings indicate how strongly each original variable is correlated with the extracted factors. High values suggest that the variable has a significant influence on the factor.\n\n# Print factor loadings with 2 decimals\nprint(\"Factor Loadings (rounded to 2 decimals):\\n\", np.round(factor_loadings, 2))\n\nFactor Loadings (rounded to 2 decimals):\n [[ 0.12  0.97 -0.01  0.06 -0.01  0.08  0.01  0.09  0.01 -0.15]\n [ 0.12  0.6   0.18  0.28  0.61  0.2   0.31  0.09 -0.01  0.02]\n [ 0.06  0.87 -0.01  0.19  0.26  0.16  0.19  0.01 -0.02  0.26]\n [ 0.13  0.07  0.26  0.18  0.04  0.09  0.9   0.03  0.26 -0.01]\n [ 0.14  0.25  0.12  0.77  0.15  0.14  0.51  0.08  0.    0.01]\n [ 0.09  0.12  0.    0.2   0.14  0.11  0.92  0.09 -0.23  0.03]\n [ 0.28  0.43  0.41  0.26  0.15  0.25  0.44  0.48 -0.01 -0.  ]\n [ 0.63  0.32  0.46  0.22  0.11  0.24  0.4   0.12  0.01  0.  ]\n [-0.2  -0.41 -0.46 -0.2  -0.17 -0.66 -0.25 -0.1  -0.   -0.01]\n [ 0.1  -0.06  0.98  0.06  0.05  0.12  0.1   0.05  0.01 -0.  ]]\n\n\n\n# Create a DataFrame for the factor loadings\nfactor_loadings_df = pd.DataFrame(\n    factor_loadings,\n    index=X_encoded.columns,  # Original feature names\n    columns=factor_columns  # Factor names\n)\n\n# Plot the heatmap\nplt.figure(figsize=(10, 8))\nsns.heatmap(\n    factor_loadings_df,\n    annot=True,  # Annotate with values\n    fmt=\".2f\",  # Format values to 2 decimals\n    cmap=\"coolwarm\",  # Color map\n    cbar=True  # Show color bar\n)\nplt.title(\"Factor Loadings Heatmap\")\nplt.xlabel(\"Factors\")\nplt.ylabel(\"Features\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n24.8.2.1 Factor Scores\nThe factor scores are the transformed values of the original variables based on the extracted factors. These scores can be used as new features in regression models.\n\n# Factor scores for each row (shape: [n_samples, actual_factors])\nX_factor_scores = fa.transform(X_encoded)\nprint(f\"X_factor_scores shape: {X_factor_scores.shape}\")\n\n# Adapt the factor column names to the actual factor count\ndf_factors = pd.DataFrame(X_factor_scores, columns=factor_columns)\nprint(f\"df_factors shape: {df_factors.shape}\")\nprint(f\"df_factors head:\\n{df_factors.head()}\")\n\nX_factor_scores shape: (157, 10)\ndf_factors shape: (157, 10)\ndf_factors head:\n    Factor1   Factor2   Factor3   Factor4   Factor5   Factor6   Factor7  \\\n0 -0.647996 -0.310986 -0.395620 -0.514476 -0.753763 -0.171572 -0.691765   \n1 -0.171241  0.352069 -0.579629 -0.677204  0.113380 -0.329903  0.434305   \n2  0.077192  0.050156 -0.595317 -0.396626  0.412052 -0.688322  0.246025   \n3 -0.683708  0.820534 -0.676114 -0.796906 -0.241928  0.602161  1.058645   \n4  0.615152 -0.262258 -0.541357 -0.489288 -1.207964 -0.186946 -0.485740   \n\n    Factor8   Factor9  Factor10  \n0 -0.233725  0.567292 -0.139248  \n1  0.852994 -0.099874  1.690789  \n2  0.941176 -0.209195  2.468886  \n3  1.063771  1.022527 -1.245557  \n4  0.259073  0.073952  0.308099  \n\n\n\n\n\n24.8.3 Creating the Regression Model with all ten Extracted Factors\n\nX_model = sm.add_constant(df_factors)\nmodel_factors = sm.OLS(y, X_model).fit()\nprint(\"\\nRegression on Factor Scores:\")\nprint(model_factors.summary())\n\n\nRegression on Factor Scores:\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:               ln_sales   R-squared:                       0.485\nModel:                            OLS   Adj. R-squared:                  0.449\nMethod:                 Least Squares   F-statistic:                     13.73\nDate:                Sun, 15 Jun 2025   Prob (F-statistic):           7.69e-17\nTime:                        12:34:54   Log-Likelihood:                -213.62\nNo. Observations:                 157   AIC:                             449.2\nDf Residuals:                     146   BIC:                             482.9\nDf Model:                          10                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          3.2959      0.078     42.215      0.000       3.142       3.450\nFactor1       -0.1366      0.078     -1.749      0.082      -0.291       0.018\nFactor2       -0.7022      0.078     -8.994      0.000      -0.856      -0.548\nFactor3        0.3035      0.078      3.888      0.000       0.149       0.458\nFactor4     9.177e-06      0.078      0.000      1.000      -0.154       0.154\nFactor5        0.1719      0.078      2.201      0.029       0.018       0.326\nFactor6       -0.1653      0.078     -2.117      0.036      -0.320      -0.011\nFactor7        0.4130      0.078      5.290      0.000       0.259       0.567\nFactor8       -0.0072      0.078     -0.092      0.927      -0.161       0.147\nFactor9        0.0317      0.078      0.407      0.685      -0.123       0.186\nFactor10       0.0665      0.078      0.852      0.396      -0.088       0.221\n==============================================================================\nOmnibus:                       41.296   Durbin-Watson:                   1.423\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              107.145\nSkew:                          -1.064   Prob(JB):                     5.42e-24\nKurtosis:                       6.442   Cond. No.                         1.00\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\ncoeffs_table = compute_coefficients_table(\n    model=model_factors,\n    X_encoded=X_model,\n    y=y,\n    vif_table=None\n)\nprint(\"\\nCoefficients Table:\")\nprint(coeffs_table)\n\n\nCoefficients Table:\n   Variable  Zero-Order r  Partial r  Semipartial r  Tolerance  VIF\n0   Factor1     -0.103920  -0.143257      -0.103920        1.0  1.0\n1   Factor2     -0.534367  -0.597080      -0.534367        1.0  1.0\n2   Factor3      0.231004   0.306300       0.231004        1.0  1.0\n3   Factor4      0.000007   0.000010       0.000007        1.0  1.0\n4   Factor5      0.130790   0.179228       0.130790        1.0  1.0\n5   Factor6     -0.125772  -0.172560      -0.125772        1.0  1.0\n6   Factor7      0.314284   0.401023       0.314284        1.0  1.0\n7   Factor8     -0.005478  -0.007630      -0.005478        1.0  1.0\n8   Factor9      0.024158   0.033630       0.024158        1.0  1.0\n9  Factor10      0.050594   0.070298       0.050594        1.0  1.0\n\n\nAs expected, the collinearity statistics show that the factor values are uncorrelated. Additionally, it is important to note that the variability of the coefficient estimates in this model is not artificially inflated by collinearity. Consequently, the coefficient estimates are larger relative to their standard errors compared to the original model. This means that more factors are identified as statistically significant, which can influence your final results if you aim to create a model that includes only significant effects.\nTo verify, we calculate the condition indices for the extracted factors. These should all be close to 1, indicating that there are no serious issues with multicollinearity.\n\nX_cond = copy.deepcopy(df_factors)\ncondition_index_df = condition_index(X_cond)\nprint(\"\\nCondition Index:\")\nprint(condition_index_df)\n\n\nCondition Index:\n   Index  Eigenvalue  Condition Index\n0      0     1.00641              1.0\n1      1     1.00641              1.0\n2      2     1.00641              1.0\n3      3     1.00641              1.0\n4      4     1.00641              1.0\n5      5     1.00641              1.0\n6      6     1.00641              1.0\n7      7     1.00641              1.0\n8      8     1.00641              1.0\n9      9     1.00641              1.0\n\n\n\n\n24.8.4 Comparison of Model Performance\n\n# Predictions from the Linear Regression Model (model)\npredictions_linear = model.predict(X_encoded_with_const)\n\n# Predictions from the Factor Analysis Regression Model (model_factors)\npredictions_factors = model_factors.predict(X_model)\n\n# Calculate R-squared and Adjusted R-squared for both models\nr2_linear = model.rsquared\nadj_r2_linear = model.rsquared_adj\n\nr2_factors = model_factors.rsquared\nadj_r2_factors = model_factors.rsquared_adj\n\n# Calculate Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) for both models\nmse_linear = mean_squared_error(y, predictions_linear)\nrmse_linear = np.sqrt(mse_linear)\n\nmse_factors = mean_squared_error(y, predictions_factors)\nrmse_factors = np.sqrt(mse_factors)\n\n# Print the comparison\nprint(\"Vergleich der beiden Modelle\")\nprint(\"\\nLinear Regression Model:\")\nprint(f\"R-squared: {r2_linear:.4f}\")\nprint(f\"Adjusted R-squared: {adj_r2_linear:.4f}\")\nprint(f\"MSE: {mse_linear:.4f}\")\nprint(f\"RMSE: {rmse_linear:.4f}\")\n\nprint(\"\\nFactor Analysis Regression Model:\")\nprint(f\"R-squared: {r2_factors:.4f}\")\nprint(f\"Adjusted R-squared: {adj_r2_factors:.4f}\")\nprint(f\"MSE: {mse_factors:.4f}\")\nprint(f\"RMSE: {rmse_factors:.4f}\")\n\nVergleich der beiden Modelle\n\nLinear Regression Model:\nR-squared: 0.4846\nAdjusted R-squared: 0.4493\nMSE: 0.8899\nRMSE: 0.9434\n\nFactor Analysis Regression Model:\nR-squared: 0.4846\nAdjusted R-squared: 0.4493\nMSE: 0.8899\nRMSE: 0.9434\n\n\nIf the R-squared and Adjusted R-squared values for model_factors are close to those of model, this indicates that the regression model based on factor analysis performs similarly well while potentially reducing multicollinearity. Lower MSE and RMSE values suggest better predictive performance.\n\n\n24.8.5 Creating the Regression Model with three Extracted Factors only\n\n# Create a regression model using only the first three factors\n# select the first three factors\ndf_factors = df_factors.iloc[:, :3]\n\n\nX_model = sm.add_constant(df_factors)\nmodel_factors = sm.OLS(y, X_model).fit()\nprint(\"\\nRegression on Factor Scores:\")\nprint(model_factors.summary())\n\n\nRegression on Factor Scores:\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:               ln_sales   R-squared:                       0.350\nModel:                            OLS   Adj. R-squared:                  0.337\nMethod:                 Least Squares   F-statistic:                     27.43\nDate:                Sun, 15 Jun 2025   Prob (F-statistic):           2.99e-14\nTime:                        12:34:54   Log-Likelihood:                -231.87\nNo. Observations:                 157   AIC:                             471.7\nDf Residuals:                     153   BIC:                             484.0\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          3.2959      0.086     38.474      0.000       3.127       3.465\nFactor1       -0.1366      0.086     -1.594      0.113      -0.306       0.033\nFactor2       -0.7022      0.086     -8.197      0.000      -0.871      -0.533\nFactor3        0.3035      0.086      3.543      0.001       0.134       0.473\n==============================================================================\nOmnibus:                       43.992   Durbin-Watson:                   1.418\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              134.618\nSkew:                          -1.068   Prob(JB):                     5.86e-30\nKurtosis:                       7.002   Cond. No.                         1.00\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\ncoeffs_table = compute_coefficients_table(\n    model=model_factors,\n    X_encoded=X_model,\n    y=y,\n    vif_table=None\n)\nprint(\"\\nCoefficients Table:\")\nprint(coeffs_table)\n\n\nCoefficients Table:\n  Variable  Zero-Order r  Partial r  Semipartial r  Tolerance  VIF\n0  Factor1     -0.103920  -0.127811      -0.103920        1.0  1.0\n1  Factor2     -0.534367  -0.552381      -0.534367        1.0  1.0\n2  Factor3      0.231004   0.275385       0.231004        1.0  1.0\n\n\nAs expected, the collinearity statistics show that the factor values are uncorrelated. Additionally, it is important to note that the variability of the coefficient estimates in this model is not artificially inflated by collinearity. Consequently, the coefficient estimates are larger relative to their standard errors compared to the original model. This means that more factors are identified as statistically significant, which can influence your final results if you aim to create a model that includes only significant effects.\nTo verify, we calculate the condition indices for the extracted factors. These should all be close to 1, indicating that there are no serious issues with multicollinearity.\n\nX_cond = copy.deepcopy(df_factors)\ncondition_index_df = condition_index(X_cond)\nprint(\"\\nCondition Index:\")\nprint(condition_index_df)\n\n\nCondition Index:\n   Index  Eigenvalue  Condition Index\n0      0     1.00641              1.0\n1      1     1.00641              1.0\n2      2     1.00641              1.0\n\n\n\n\n24.8.6 Comparison of Model Performance of the Reduced Model and the Full Model\n\n# Predictions from the Linear Regression Model (model)\npredictions_linear = model.predict(X_encoded_with_const)\n\n# Predictions from the Factor Analysis Regression Model (model_factors)\npredictions_factors = model_factors.predict(X_model)\n\n# Calculate R-squared and Adjusted R-squared for both models\nr2_linear = model.rsquared\nadj_r2_linear = model.rsquared_adj\n\nr2_factors = model_factors.rsquared\nadj_r2_factors = model_factors.rsquared_adj\n\n# Calculate Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) for both models\nmse_linear = mean_squared_error(y, predictions_linear)\nrmse_linear = np.sqrt(mse_linear)\n\nmse_factors = mean_squared_error(y, predictions_factors)\nrmse_factors = np.sqrt(mse_factors)\n\n# Print the comparison\nprint(\"Vergleich der beiden Modelle\")\nprint(\"\\nLinear Regression Model:\")\nprint(f\"R-squared: {r2_linear:.4f}\")\nprint(f\"Adjusted R-squared: {adj_r2_linear:.4f}\")\nprint(f\"MSE: {mse_linear:.4f}\")\nprint(f\"RMSE: {rmse_linear:.4f}\")\n\nprint(\"\\nFactor Analysis Regression Model:\")\nprint(f\"R-squared: {r2_factors:.4f}\")\nprint(f\"Adjusted R-squared: {adj_r2_factors:.4f}\")\nprint(f\"MSE: {mse_factors:.4f}\")\nprint(f\"RMSE: {rmse_factors:.4f}\")\n\nVergleich der beiden Modelle\n\nLinear Regression Model:\nR-squared: 0.4846\nAdjusted R-squared: 0.4493\nMSE: 0.8899\nRMSE: 0.9434\n\nFactor Analysis Regression Model:\nR-squared: 0.3497\nAdjusted R-squared: 0.3370\nMSE: 1.1228\nRMSE: 1.0596\n\n\nIf the R-squared and Adjusted R-squared values for model_factors are close to those of model, this indicates that the regression model based on factor analysis performs similarly well while potentially reducing multicollinearity. Lower MSE and RMSE values suggest better predictive performance.",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Multicollinearity and Principle Component Analysis (PCA)</span>"
    ]
  },
  {
    "objectID": "100_ddmo_pca.html#summary",
    "href": "100_ddmo_pca.html#summary",
    "title": "24  Multicollinearity and Principle Component Analysis (PCA)",
    "section": "24.9 Summary",
    "text": "24.9 Summary\n\n24.9.1 Interpretation of the Regression Model model_factors\nThe model_factors regression model is based on factor analysis, which reduces the dimensionality of the input data by transforming the original variables into a smaller group of uncorrelated factors. These factors are linear combinations of the original variables and are designed to capture the underlying structure of the data.\nFactors: Instead of using the original variables, the regression is performed on the extracted factors. Each factor represents a weighted combination of the original variables.\nCoefficients: The coefficients in the model_factors regression model indicate the relationship between the target variable (y) and the extracted factors.\n\n\n24.9.2 Differences Compared to the Standard OLS Model\nInput Variables:\n\nOLS Model (model): Uses the original variables (X_encoded) as predictors.\nFactor Analysis Model (model_factors): Uses the extracted factors (df_factors) as predictors.\n\nMulticollinearity:\n\nOLS Model: Can suffer from multicollinearity if the predictors are highly correlated, leading to unstable coefficients and inflated standard errors.\nFactor Analysis Model: Reduces multicollinearity by using uncorrelated factors as predictors.\n\nInterpretability:\n\nOLS Model: Coefficients correspond directly to the original variables, making it easier to interpret the influence of each variable on the target variable.\nFactor Analysis Model: Coefficients relate to abstract factors, which are combinations of the original variables, making interpretation more challenging.\n\nDimensionality:\n\nOLS Model: Uses all original variables, which may include redundant or irrelevant features.\nFactor Analysis Model: Reduces the number of predictors by combining the original variables into a smaller number of factors.\n\n\n\n24.9.3 Advantages of Using model_factors\n\nReduced Multicollinearity: By using uncorrelated factors, the model avoids instability caused by multicollinearity.\nDimensionality Reduction: The model uses fewer predictors, improving computational efficiency and generalization.\nFocus on Underlying Structure: Factor analysis captures the latent structure of the data, providing better insights into the relationships between variables.\n\n\n\n24.9.4 Disadvantages of Using model_factors\n\nLoss of Interpretability: Factors are abstract combinations of the original variables, making it harder to directly interpret the coefficients. To understand the influence of individual variables on the target variable, factor loadings must be analyzed.\nPotential Information Loss: If too few factors are retained, information from the original variables may be lost, reducing predictive accuracy.\nComplexity: The process of extracting factors and interpreting their meaning adds complexity to the modeling process.\nDependence on Factor Selection: The number of factors to retain is subjective and can affect model performance. Too few factors may oversimplify the data, while too many factors may reintroduce multicollinearity.\n\n\n\n24.9.5 Summary\n\nmodel_factors is a good choice when multicollinearity is a problem and the focus is on predictive performance rather than interpretability.\nThe model is preferable when interpretability is crucial and multicollinearity is not a significant issue.",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Multicollinearity and Principle Component Analysis (PCA)</span>"
    ]
  },
  {
    "objectID": "100_ddmo_pca.html#using-model_factors-in-other-models",
    "href": "100_ddmo_pca.html#using-model_factors-in-other-models",
    "title": "24  Multicollinearity and Principle Component Analysis (PCA)",
    "section": "24.10 Using model_factors in Other Models",
    "text": "24.10 Using model_factors in Other Models\n\n24.10.1 Random Forest Regressor with the Full Dataset\n\nFirst, use the original variables.\n\n\n# ------------------------------------------------------------------------\n# 1. Prepare Data\n# ------------------------------------------------------------------------\n\n# Use the original input features (X_encoded) as predictors\nX_original = X_encoded\n\n# Split the data into training and testing sets\nX_train_orig, X_test_orig, y_train_orig, y_test_orig = train_test_split(X_original, y, test_size=0.2, random_state=42)\n\n# ------------------------------------------------------------------------\n# 2. Fit Random Forest Model\n# ------------------------------------------------------------------------\n\n# Initialize the Random Forest Regressor\nrf_model_orig = RandomForestRegressor(n_estimators=100, random_state=42)\n\n# Train the model on the training data\nrf_model_orig.fit(X_train_orig, y_train_orig)\n\n# ------------------------------------------------------------------------\n# 3. Evaluate the Model\n# ------------------------------------------------------------------------\n\n# Make predictions on the test set\ny_pred_orig = rf_model_orig.predict(X_test_orig)\n\n# Calculate evaluation metrics\nr2_rf_orig = r2_score(y_test_orig, y_pred_orig)\nmse_rf_orig = mean_squared_error(y_test_orig, y_pred_orig)\nrmse_rf_orig = np.sqrt(mse_rf_orig)\n\n# Print the results\nprint(\"\\nRandom Forest Model (using original data):\")\nprint(f\"R-squared: {r2_rf_orig:.4f}\")\nprint(f\"MSE: {mse_rf_orig:.4f}\")\nprint(f\"RMSE: {rmse_rf_orig:.4f}\")\n\n\nRandom Forest Model (using original data):\nR-squared: 0.4032\nMSE: 1.3118\nRMSE: 1.1453\n\n\n\n\n24.10.2 Random Forest Regressor with Extracted Factors\n\nThen use the extracted factors.\n\n\n# ------------------------------------------------------------------------\n# 1. Prepare Data\n# ------------------------------------------------------------------------\n\n# Use the extracted factors as predictors\nX_factors = df_factors\n\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X_factors, y, test_size=0.2, random_state=42)\n\n# ------------------------------------------------------------------------\n# 2. Fit Random Forest Model\n# ------------------------------------------------------------------------\n\n# Initialize the Random Forest Regressor\nrf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n\n# Train the model on the training data\nrf_model.fit(X_train, y_train)\n\n# ------------------------------------------------------------------------\n# 3. Evaluate the Model\n# ------------------------------------------------------------------------\n\n# Make predictions on the test set\ny_pred = rf_model.predict(X_test)\n\n# Calculate evaluation metrics\nr2_rf = r2_score(y_test, y_pred)\nmse_rf = mean_squared_error(y_test, y_pred)\nrmse_rf = np.sqrt(mse_rf)\n\n# Print the results\nprint(\"\\nRandom Forest Model (using extracted factors):\")\nprint(f\"R-squared: {r2_rf:.4f}\")\nprint(f\"MSE: {mse_rf:.4f}\")\nprint(f\"RMSE: {rmse_rf:.4f}\")\n\n\nRandom Forest Model (using extracted factors):\nR-squared: 0.2901\nMSE: 1.5605\nRMSE: 1.2492\n\n\n\n\n24.10.3 Comparison of the two Random Forest Models\n\n# Print comparison of Random Forest models\nprint(\"\\nComparison of Random Forest Models:\")\nprint(\"\\nUsing Extracted Factors:\")\nprint(f\"R-squared: {r2_rf:.4f}\")\nprint(f\"MSE: {mse_rf:.4f}\")\nprint(f\"RMSE: {rmse_rf:.4f}\")\n\nprint(\"\\nUsing Original Data:\")\nprint(f\"R-squared: {r2_rf_orig:.4f}\")\nprint(f\"MSE: {mse_rf_orig:.4f}\")\nprint(f\"RMSE: {rmse_rf_orig:.4f}\")\n\n\nComparison of Random Forest Models:\n\nUsing Extracted Factors:\nR-squared: 0.2901\nMSE: 1.5605\nRMSE: 1.2492\n\nUsing Original Data:\nR-squared: 0.4032\nMSE: 1.3118\nRMSE: 1.1453",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Multicollinearity and Principle Component Analysis (PCA)</span>"
    ]
  },
  {
    "objectID": "100_ddmo_pca.html#multicollinearity-conclusion-and-recommendation",
    "href": "100_ddmo_pca.html#multicollinearity-conclusion-and-recommendation",
    "title": "24  Multicollinearity and Principle Component Analysis (PCA)",
    "section": "24.11 Multicollinearity: Conclusion and Recommendation",
    "text": "24.11 Multicollinearity: Conclusion and Recommendation\n\nPCA is a standard method for addressing multicollinearity.\nThe principal components determined using linear regression are no longer multicollinear.\nThese components can also be used for other models, such as Random Forest.\nThe principal components are not easy to interpret.",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Multicollinearity and Principle Component Analysis (PCA)</span>"
    ]
  },
  {
    "objectID": "100_ddmo_pca.html#videos-principal-component-analysis-pca",
    "href": "100_ddmo_pca.html#videos-principal-component-analysis-pca",
    "title": "24  Multicollinearity and Principle Component Analysis (PCA)",
    "section": "24.12 Videos: Principal Component Analysis (PCA)",
    "text": "24.12 Videos: Principal Component Analysis (PCA)\n\nVideo: Principal Component Analysis (PCA), Step-by-Step\nVideo: PCA - Practical Tips\nVideo: PCA in Python",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Multicollinearity and Principle Component Analysis (PCA)</span>"
    ]
  },
  {
    "objectID": "100_ddmo_pca.html#jupyter-notebook",
    "href": "100_ddmo_pca.html#jupyter-notebook",
    "title": "24  Multicollinearity and Principle Component Analysis (PCA)",
    "section": "24.13 Jupyter Notebook",
    "text": "24.13 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Multicollinearity and Principle Component Analysis (PCA)</span>"
    ]
  },
  {
    "objectID": "100_ddmo_regression.html",
    "href": "100_ddmo_regression.html",
    "title": "25  Regression",
    "section": "",
    "text": "25.1 Supervised and Unsupervised Learning\nTwo important types: supervised and unsupervised learning. There is even more, e.g., semi-supervised learning.",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "100_ddmo_regression.html#supervised-and-unsupervised-learning",
    "href": "100_ddmo_regression.html#supervised-and-unsupervised-learning",
    "title": "25  Regression",
    "section": "",
    "text": "25.1.1 Starting point\n\nOutcome measurement \\(Y\\) (dependent variable, response, target).\nVector of \\(p\\) predictor measurements \\(X\\) (inputs, regressors, covariates, features, independent variables).\nTraining data \\((x_1, y1), \\ldots ,(x_N, y_N)\\). These are observations (examples, instances) of these measurements.\n\nIn the regression problem, \\(Y\\) is quantitative (e.g., price, blood pressure). In the classification problem, \\(Y\\) takes values in a finite, unordered set (e.g., survived/died, digit 0-9, cancer class of tissue sample).\n\n\n25.1.2 Philosophy\nIt is important to understand the ideas behind the various techniques, in order to know how and when to use them. One has to understand the simpler methods first, in order to grasp the more sophisticated ones. It is important to accurately assess the performance of a method, to know how well or how badly it is working (simpler methods often perform as well as fancier ones!) This is an exciting research area, having important applications in science, industry and finance. Statistical learning is a fundamental ingredient in the training of a modern data scientist.\n\n\n25.1.3 Supervised Learning\nObjectives of supervised learning: On the basis of the training data we would like to:\n\nAccurately predict unseen test cases.\nUnderstand which inputs affect the outcome, and how.\nAssess the quality of our predictions and inferences.\n\nNote: Supervised means \\(Y\\) is known.\n\nExercise 25.1  \n\nDo children learn supervised?\nWhen do you learn supervised?\nCan learning be unsupervised?\n\n\n\n\n25.1.4 Unsupervised Learning\nNo outcome variable, just a set of predictors (features) measured on a set of samples. The objective is more fuzzy—find groups of samples that behave similarly, find features that behave similarly, find linear combinations of features with the most variation. It is difficult to know how well your are doing. Unsupervised learning different from supervised learning, but can be useful as a pre-processing step for supervised learning. Clustering and principle component analysis are important techniques.\nUnsupervised: \\(Y\\) is unknown, there is no \\(Y\\), no trainer, no teacher, but: distances between the inputs values (features). A distance (or similarity) measure is necessary.\n\n25.1.4.0.1 Statistical Learning\nWe consider supervised learning first.\n\n\n\n\n\n\nFigure 25.1: Sales as a function of TV, radio and newspaper. Taken from James et al. (2014)\n\n\n\nSales figures from a marketing campaign, see Figure 25.1. Trend shown using regression. First seems to be stronger than the third.\nCan we predict \\(Y\\) = Sales using these three? Perhaps we can do better using a model \\[\nY = Sales \\approx  f(X_1 = TV,  X_2 = Radio, X_3= Newspaper)\n\\] modeling the joint relationsship.\nHere Sales is a response or target that we wish to predict. We generically refer to the response as \\(Y\\). TV is a feature, or input, or predictor; we name it \\(X_1\\). Likewise name Radio as \\(X_2\\), and so on. We can refer to the input vector collectively as \\[\nX =\n\\begin{pmatrix}\nX_1\\\\\nX_2\\\\\nX_3\n\\end{pmatrix}\n\\]\nNow we write our model as \\[\nY = f(X) + \\epsilon\n\\] where \\(\\epsilon\\) captures measurement errors and other discrepancies.\nWhat is \\(f\\) good for? With a good \\(f\\) we can make predictions of \\(Y\\) at new points \\(X = x\\). We can understand which components of \\(X = (X_1, X_2, \\ldots X_p)\\) are important in explaining \\(Y\\), and which are irrelevant.\nFor example, Seniority and Years of Education have a big impact on Income, but Marital Status typically does not. Depending on the complexity of \\(f\\), we may be able to understand how each component \\(X_j\\) of \\(X\\) affects \\(Y\\).",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "100_ddmo_regression.html#linear-regression",
    "href": "100_ddmo_regression.html#linear-regression",
    "title": "25  Regression",
    "section": "25.2 Linear Regression",
    "text": "25.2 Linear Regression\n\n25.2.1 The main ideas of fitting a line to data (The main ideas of least squares and linear regression.)\n\nVideo: The main ideas of fitting a line to data (The main ideas of least squares and linear regression.)\n\n\n25.2.1.1 Linear Regression\n\nVideo: Linear Regression, Clearly Explained\n\n\n\n25.2.1.2 Multiple Regression\n\nVideo: Multiple Regression, Clearly Explained\n\n\n\n25.2.1.3 A Gentle Introduction to Machine Learning\n\nVideo: A Gentle Introduction to Machine Learning\n\n\n\n25.2.1.4 Regression Function\n\n\n\n\n\n\nFigure 25.2: Scatter plot of 2000 points (population). What is a good function \\(f\\)? There are many function values at \\(X=4\\). A function can return only one value. We can take the mean from these values as a return value. Taken from James et al. (2014)\n\n\n\nConsider Figure 25.2. Is there an ideal \\(f(X)\\)? In particular, what is a good value for \\(f(X)\\) at any selected value of \\(X\\), say \\(X = 4\\)? There can be many \\(Y\\) values at \\(X=4\\). A good value is \\[\nf(4) = E(Y |X = 4).\n\\]\n\\(E(Y |X = 4)\\) means expected value (average) of \\(Y\\) given \\(X = 4\\).\nThe ideal \\(f(x) = E(Y |X = x)\\) is called the regression function. Read: The regression function gives the conditional expectation of \\(Y\\) given \\(X\\).\nThe regression function \\(f(x)\\) is also defined for the vector \\(X\\); e.g., \\(f(x) = f(x_1, x_2, x_3) = E(Y | X_1 =x_1, X_2 =x_2, X_3 =x_3).\\)\n\n\n\n25.2.2 Optimal Predictor\nThe regression function is the ideal or optimal predictor of \\(Y\\) with regard to mean-squared prediction error: It means that \\(f(x) = E(Y | X = x)\\) is the function that minimizes \\[\nE[(Y - g(X))^2|X = x]\n\\] over all functions \\(g\\) at all points \\(X = x\\).\n\n\n25.2.2.1 Residuals, Reducible and Irreducible Error\nAt each point \\(X\\) we make mistakes: \\[\n\\epsilon = Y-f(x)\n\\] is the residual. Even if we knew \\(f(x)\\), we would still make errors in prediction, since at each \\(X=x\\) there is typically a distribution of possible \\(Y\\) values as is illustrated in Figure 25.2.\nFor any estimate \\(\\hat{f}(x)\\) of \\(f(x)\\), we have \\[\nE\\left[ ( Y - \\hat{f}(X))^2 | X = x\\right] = \\left[ f(x) - \\hat{f}(x) \\right]^2 + \\text{var}(\\epsilon),\n\\] and \\(\\left[ f(x) - \\hat{f}(x) \\right]^2\\) is the reducible error, because it depends on the model (changing the model \\(f\\) might reduce this error), and \\(\\text{var}(\\epsilon)\\) is the irreducible error.\n\n\n25.2.2.2 Local Regression (Smoothing)\nTypically we have few if any data points with \\(X = 4\\) exactly. So we cannot compute \\(E(Y |X = x)\\)! Idea: Relax the definition and let \\[\n\\hat{f}(x)=  Ave(Y|X \\in  \\cal{N}(x)),\n\\] where \\(\\cal{N} (x)\\) is some neighborhood of \\(x\\), see Figure 25.3.\n\n\n\n\n\n\nFigure 25.3: Relaxing the definition. There is no \\(Y\\) value at \\(X=4\\). Taken from James et al. (2014)\n\n\n\nNearest neighbor averaging can be pretty good for small \\(p\\), i.e., \\(p \\leq 4\\) and large-ish \\(N\\). We will discuss smoother versions, such as kernel and spline smoothing later in the course.\n\n\n25.2.3 Curse of Dimensionality and Parametric Models\n\n\n\n\n\n\nFigure 25.4: A 10% neighborhood in high dimensions need no longer be local. Left: Values of two variables \\(x_1\\) and \\(x_2\\), uniformly distributed. Form two 10% neighborhoods: (a) the first is just involving \\(x_1\\) ignoring \\(x_2\\). (b) is the neighborhood in two dimension. Notice that the radius of the circle is much larger than the lenght of the interval in one dimension. Right: radius plotted against fraction of the volume. In 10 dim, you have to break out the interval \\([-1;+1]\\) to get 10% of the data. Taken from James et al. (2014)\n\n\n\nLocal, e.g., nearest neighbor, methods can be lousy when \\(p\\) is large. Reason: the curse of dimensionality, i.e., nearest neighbors tend to be far away in high dimensions. We need to get a reasonable fraction of the \\(N\\) values of \\(y_i\\) to average to bring the variance down—e.g., 10%. A 10% neighborhood in high dimensions need no longer be local, so we lose the spirit of estimating \\(E(Y |X = x)\\) by local averaging, see Figure 25.4. If the curse of dimensionality does not exist, nearest neighbor models would be perfect prediction models.\nWe will use structured (parametric) models to deal with the curse of dimensionality. The linear model is an important example of a parametric model: \\[\nf_L(X) = \\beta_0 + \\beta_1 X_1 + \\ldots + \\beta_p X_p.\n\\] A linear model is specified in terms of \\(p + 1\\) parameters \\(\\beta_1, \\beta_2, \\ldots, \\beta_p\\). We estimate the parameters by fitting the model to . Although it is almost never correct, a linear model often serves as a good and interpretable approximation to the unknown true function \\(f(X)\\).\nThe linear model is avoiding the curse of dimensionality, because it is not relying on any local properties. Linear models belong to the class of approaches: they replace the problem of estimating \\(f\\) with estimating a fixed set of coefficients \\(\\beta_i\\), with \\(i=1,2, \\ldots, p\\).\n\n\n\n\n\n\nFigure 25.5: A linear model \\(\\hat{f}_L\\) gives a reasonable fit. Taken from James et al. (2014)\n\n\n\n\n\n\n\n\n\nFigure 25.6: A quadratic model \\(\\hat{f}_Q\\) fits slightly better. Taken from James et al. (2014)\n\n\n\nA linear model \\[\n\\hat{f}_L(X) = \\hat{\\beta}_0 + \\hat{\\beta}_1 X\n\\] gives a reasonable fit, see Figure 25.5. A quadratic model \\[\n\\hat{f}_Q(X) = \\hat{\\beta}_0 + \\hat{\\beta}_1 X + \\hat{\\beta}_2 X^2\n\\] gives a slightly improved fit, see Figure 25.6.\nFigure 25.7 shows a simulated example. Red points are simulated values for income from the model \\[\nincome = f(education, seniority) + \\epsilon\n\\] \\(f\\) is the blue surface.\n\n\n\n\n\n\nFigure 25.7: The true model. Red points are simulated values for income from the model, \\(f\\) is the blue surface. Taken from James et al. (2014)\n\n\n\n\n\n\n\n\n\nFigure 25.8: Linear regression fit to the simulated data (red points). Taken from James et al. (2014)\n\n\n\nThe linear regression model \\[\n\\hat{f}(education, seniority) = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\times education +\n\\hat{\\beta}_2 \\times seniority\n\\] captures the important information. But it does not capture everything. More flexible regression model \\[\n\\hat{f}_S (education, seniority)\n\\] fit to the simulated data. Here we use a technique called a thin-plate spline to fit a flexible surface. Even more flexible spline regression model \\[\n\\hat{f}_S (education, seniority)\n\\] fit to the simulated data. Here the fitted model makes no errors on the training data! Also known as overfitting.\n\n\n\n\n\n\nFigure 25.9: Thin-plate spline models \\(\\hat{f}_S (education, seniority)\\) fitted to the model from Figure 25.7. Taken from James et al. (2014)\n\n\n\n\n\n\n\n\n\nFigure 25.10: Thin-plate spline models \\(\\hat{f}_S (education, seniority)\\) fitted to the model from Figure 25.7. The model makes no errors on the training data (overfitting). Taken from James et al. (2014)\n\n\n\n\n25.2.3.1 Trade-offs\n\nPrediction accuracy versus interpretability: Linear models are easy to interpret; thin-plate splines are not.\nGood fit versus over-fit or under-fit: How do we know when the fit is just right?\nParsimony (Occam’s razor) versus black-box: We often prefer a simpler model involving fewer variables over a black-box predictor involving them all.\n\nThe trad-offs are visualized in Figure 25.11.\n\n\n\n\n\n\nFigure 25.11: Interpretability versus flexibility. Flexibility corresponds with the number of model parameters. Taken from James et al. (2014)\n\n\n\n\n\n\n25.2.4 Assessing Model Accuracy and Bias-Variance Trade-off\n\n\n\n\n\n\nFigure 25.12: Black curve is truth. Red curve on right is \\(MSETe\\), grey curve is \\(MSETr\\). Orange, blue and green curves/squares correspond to fits of different flexibility. The dotted line represents the irreducible error, i.e., \\(var(\\epsilon)\\). Taken from James et al. (2014)\n\n\n\n\n\n\n\n\n\nFigure 25.13: Here, the truth is smoother. Black curve is truth. Red curve on right is \\(MSETe\\), grey curve is \\(MSETr\\). Orange, blue and green curves/squares correspond to fits of different flexibility. The dotted line represents the irreducible error, i.e., \\(var(\\epsilon)\\). Taken from James et al. (2014)\n\n\n\n\n\n\n\n\n\nFigure 25.14: Here the truth is wiggly and the noise is low, so the more flexible fits do the best. Black curve is truth. Red curve on right is \\(MSETe\\), grey curve is \\(MSETr\\). Orange, blue and green curves/squares correspond to fits of different flexibility. The dotted line represents the irreducible error, i.e., \\(var(\\epsilon)\\). Taken from James et al. (2014)\n\n\n\nSuppose we fit a model \\(f(x)\\) to some training data \\(Tr = \\{x_i, y_i \\}^N_1\\), and we wish to see how well it performs. We could compute the average squared prediction error over \\(Tr\\): \\[\nMSE_{Tr} = Ave_{i \\in Tr}[y_i - \\hat{f}(x_i)]^2.\n\\] This may be biased toward more overfit models. Instead we should, if possible, compute it using fresh test data \\(Te== \\{x_i, y_i \\}^N_1\\): \\[\nMSE_{Te} = Ave_{i \\in Te}[y_i - \\hat{f}(x_i)]^2.\n\\] The red curve, which illustrated the test error, can be estimated by holding out some data to get the test-data set.\n\n25.2.4.1 Bias-Variance Trade-off\nSuppose we have fit a model \\(f(x)\\) to some training data \\(Tr\\), and let \\((x_0, y_0)\\) be a test observation drawn from the population. If the true model is \\[\nY = f(X) + \\epsilon  \\qquad \\text{ with } f(x) = E(Y|X=x),\n\\] then \\[\nE \\left( y_0 - \\hat{f}(x_0) \\right)^2 = \\text{var} (\\hat{f}(x_0)) + [Bias(\\hat{f}(x_0))]^2 + \\text{var}(\\epsilon).\n\\tag{25.1}\\]\nHere, \\(\\text{var}(\\epsilon)\\) is the irreducible error. The reducible error consists of two components:\n\n\\(\\text{var} (\\hat{f}(x_0))\\) is the variance that comes from different training sets. Different training sets result in different functions \\(\\hat{f}\\).\n\\(Bias(\\hat{f}(x_0)) = E[\\hat{f}(x_0)] - f(x_0)\\).\n\nThe expectation averages over the variability of \\(y_0\\) as well as the variability in \\(Tr\\). Note that \\[\nBias(\\hat{f}(x_0)) = E[\\hat{f}(x_0)] - f(x_0).\n\\] Typically as the flexibility of \\(\\hat{f}\\) increases, its variance increases (because the fits differ from training set to trainig set), and its bias decreases. So choosing the flexibility based on average test error amounts to a bias-variance trade-off, see Figure 25.15.\n\n\n\n\n\n\nFigure 25.15: Bias-variance trade-off for the three examples. Taken from James et al. (2014)\n\n\n\nIf we add the two components (reducible and irreducible error), we get the MSE in Figure 25.15 as can be seen in Equation 25.1.\n\nVideo: Machine Learning Fundamentals: Bias and Variance",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "100_ddmo_regression.html#multiple-regression-1",
    "href": "100_ddmo_regression.html#multiple-regression-1",
    "title": "25  Regression",
    "section": "25.3 Multiple Regression",
    "text": "25.3 Multiple Regression",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "100_ddmo_regression.html#r-squared",
    "href": "100_ddmo_regression.html#r-squared",
    "title": "25  Regression",
    "section": "25.4 R-squared",
    "text": "25.4 R-squared\n\n25.4.1 R-Squared in Simple Linear Regression\nIn simple linear regression, the relationship between the independent variable \\(X\\) and the dependent variable \\(Y\\) is modeled using the equation:\n\\[\nY = \\beta_0 + \\beta_1 X + \\epsilon\n\\]\nHere, \\(\\beta_0\\) is the intercept, \\(\\beta_1\\) is the slope or regression coefficient, and \\(\\epsilon\\) is the error term.\n\nDefinition 25.1 (R-Squared (\\(R^2\\))) \\(R^2\\) is a measure of how well the regression model explains the variance in the dependent variable. It is calculated as the square of the correlation coefficient (\\(r\\)) between the actual values \\(Y\\) and the predicted values \\(\\hat{Y}\\) from the regression model. It ranges from 0 to 1, where:\n\n1 indicates that the regression predictions perfectly fit the data.\n0 indicates that the model does not explain any of the variability in the target data around its mean.\n\n\nIn simple linear regression, where there is one independent variable \\(X\\) and one dependent variable \\(Y\\), the R-squared (\\(R^2\\)) is the square of the Pearson correlation coefficient (\\(r\\)) between the observed values of the dependent variable and the values predicted by the regression model. That is, in simple linear regression, we have\n\\[\nR^2 = r^2.\n\\]\nThis equivalence holds specifically for simple linear regression due to the direct relationship between the linear fit and the correlation of two variables. In multiple linear regression, while \\(R^2\\) still represents the proportion of variance explained by the model, it is not simply the square of a single correlation coefficient as it involves multiple predictors.\n\nVideo: R-squared, Clearly Explained",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "100_ddmo_regression.html#assessing-confounding-effects-in-multiple-regression",
    "href": "100_ddmo_regression.html#assessing-confounding-effects-in-multiple-regression",
    "title": "25  Regression",
    "section": "25.5 Assessing Confounding Effects in Multiple Regression",
    "text": "25.5 Assessing Confounding Effects in Multiple Regression\nConfounding is a bias introduced by the imbalanced distribution of extraneous risk factors among comparison groups (Wang 2007). spotpython provides tools for assessing confounding effects in multiple regression models.\n\nExample 25.1 (Assessing Confounding Effects in Multiple Regression with spotpython) Consider the following data generation function generate_data and the fit_ols_model function to fit an ordinary least squares (OLS) regression model.\n\nimport numpy as np\nimport pandas as pd\nimport statsmodels.formula.api as smf\n\ndef generate_data(n_samples=100, b0=0, b1=-1, b2=0, b3=10, b12=0, b13=0, b23=0, b123=0, noise_std=1) -&gt; pd.DataFrame:\n    \"\"\"\n    Generate data for the linear formula y ~ b0 + b1*x1 + b2*x2 + b3*x3 + b12*x1*x2 + b13*x1*x3 + b23*x2*x3 + b123*x1*x2*x3.\n\n    Args:\n        n_samples (int): Number of samples to generate.\n        b0 (float): Coefficient for the intercept.\n        b1 (float): Coefficient for x1.\n        b2 (float): Coefficient for x2.\n        b3 (float): Coefficient for x3.\n        b12 (float): Coefficient for the interaction term x1*x2.\n        b13 (float): Coefficient for the interaction term x1*x3.\n        b23 (float): Coefficient for the interaction term x2*x3.\n        b123 (float): Coefficient for the interaction term x1*x2*x3.\n        noise_std (float): Standard deviation of the Gaussian noise added to y.\n\n    Returns:\n        pd.DataFrame: A DataFrame containing the generated data with columns ['x1', 'x2', 'x3', 'y'].\n    \"\"\"\n    np.random.seed(42)  # For reproducibility\n    x1 = np.random.uniform(0, 1, n_samples)\n    x2 = np.random.uniform(0, 1, n_samples)\n    x3 = np.random.uniform(0, 1, n_samples)\n    \n    y = (b0 + b1*x1 + b2*x2 + b3*x3 + b12*x1*x2 + b13*x1*x3 + b23*x2*x3 + b123*x1*x2*x3 +\n         np.random.normal(0, noise_std, n_samples))\n    \n    data = pd.DataFrame({'y': y, 'x1': x1, 'x2': x2, 'x3': x3})\n    return data\n\ndef fit_ols_model(formula, data) -&gt; dict:\n    \"\"\"\n    Fit an OLS model using the given formula and data, and print the results.\n\n    Args:\n        formula (str): The formula for the OLS model.\n        data (pd.DataFrame): The data frame containing the variables.\n\n    Returns:\n        dict: A dictionary containing the p-values, estimates, confidence intervals, and AIC value.\n    \"\"\"\n    mod_0 = smf.ols(formula=formula, data=data).fit()\n    p = mod_0.pvalues.iloc[1]\n    estimate = mod_0.params.iloc[1]\n    conf_int = mod_0.conf_int().iloc[1]\n    aic_value = mod_0.aic\n\n    print(f\"p-values: {p}\")\n    print(f\"estimate: {estimate}\")\n    print(f\"conf_int: {conf_int}\")\n    print(f\"aic: {aic_value}\")\n\nThese functions can be used to generate data and fit an OLS model. Here we use the model \\[\ny = f(x_1, x_2, x_3) + \\epsilon =  x_1 + 10 x_3 + \\epsilon.\n\\] We set up the basic model \\(y_0 = f_0(x_1)\\) and analyze how the model fit changes when adding \\(x_2\\) and \\(x_3\\) to the model. If the \\(p\\)-values are decreasing by adding a variable, this indicates that the variable is relevant for the model. Similiarly, if the \\(p\\)-values are increasing by removing a variable, this indicates that the variable is not relevant for the model.\n\ndata = generate_data(b0=0, b1=1, b2=0, b3=10, b12=0, b13=0, b23=0, b123=0, noise_std=1)\nfit_ols_model(\"y ~ x1\", data)\nfit_ols_model(\"y ~ x1 + x2\", data)\nfit_ols_model(\"y ~ x1 + x3\", data)\nfit_ols_model(\"y ~ x1 + x2 + x3\", data)\n\np-values: 0.34343741859526267\nestimate: 1.025306391110114\nconf_int: 0   -1.111963\n1    3.162575\nName: x1, dtype: float64\naic: 517.6397392012537\np-values: 0.3637511850778461\nestimate: 0.9810502049698089\nconf_int: 0   -1.152698\n1    3.114798\nName: x1, dtype: float64\naic: 518.1426513151566\np-values: 4.9467606744218404e-05\nestimate: 1.4077923469421165\nconf_int: 0    0.750106\n1    2.065479\nName: x1, dtype: float64\naic: 282.73524524532\np-values: 4.849840959643538e-05\nestimate: 1.4159292625696247\nconf_int: 0    0.755494\n1    2.076364\nName: x1, dtype: float64\naic: 284.34665447613634\n\n\nThe function fit_all_lm() simplifies this procedure. It can be used to fit all possible linear models with the given data and print the results in a systematic way for various combinations of variables.\n\nfrom spotpython.utils.stats import fit_all_lm, plot_coeff_vs_pvals, plot_coeff_vs_pvals_by_included\nres = fit_all_lm(\"y ~ x1\", [\"x2\", \"x3\"], data)\nprint(res[\"estimate\"])\n\nThe basic model is: y ~ x1\nThe following features will be used for fitting the basic model: Index(['x2', 'x1', 'x3', 'y'], dtype='object')\np-values: 0.34343741859526267\nestimate: 1.025306391110114\nconf_int: 0   -1.111963\n1    3.162575\nName: x1, dtype: float64\naic: 517.6397392012537\nCombinations: [('x2',), ('x3',), ('x2', 'x3')]\n  variables  estimate  conf_low  conf_high         p         aic    n\n0     basic  1.025306 -1.111963   3.162575  0.343437  517.639739  100\n1        x2  0.981050 -1.152698   3.114798  0.363751  518.142651  100\n2        x3  1.407792  0.750106   2.065479  0.000049  282.735245  100\n3    x2, x3  1.415929  0.755494   2.076364  0.000048  284.346654  100\n\n\nInterpreting the results, we can see that the \\(p\\)-values decrease when adding \\(x_3\\) (as well as both \\(x_2\\) and $x_3) to the model, indicating that \\(x_3\\) is relevant for the model. Adding only \\(x_2\\) does not significantly improve the model fit.\nIn addition to the textural output, the function plot_coeff_vs_pvals_by_included() can be used to visualize the coefficients and p-values of the fitted models.\n\nplot_coeff_vs_pvals_by_included(res)\n\n\n\n\n\n\n\nFigure 25.16: Coefficients vs. p-values for different models. The right plot indicates that x3 should be included in the model, whereas the left plot shows that x2 is not relevant.\n\n\n\n\n\nFigure 25.16 shows the coefficients and p-values for different models. Because \\(y\\) depends on \\(x1\\) and \\(x3\\), the p-value much smaller if \\(x3\\) is included in the model as can be seen in the right plot in Figure 25.16. The left plot shows that including \\(x2\\) in the model does not significantly improve the model fit.",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "100_ddmo_regression.html#cross-validation",
    "href": "100_ddmo_regression.html#cross-validation",
    "title": "25  Regression",
    "section": "25.6 Cross-Validation",
    "text": "25.6 Cross-Validation\n\nVideo: Machine Learning Fundamentals: Cross Validation\n\n\n\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2014. An Introduction to Statistical Learning with Applications in R. 7th ed. Springer.\n\n\nWang, Zhiqiang. 2007. “Two Postestimation Commands for Assessing Confounding Effects in Epidemiological Studies.” The Stata Journal 7 (2): 183–96.",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "100_ddmo_classification.html",
    "href": "100_ddmo_classification.html",
    "title": "26  Classification",
    "section": "",
    "text": "26.1 Classification: Some Details\nIn classification we have a qualitative response variable.\nHere the response variable \\(Y\\) is qualitative, e.g., email is one of \\(\\cal{C} = (spam, ham)\\), where ham is good email, digit class is one of \\(\\cal{C} = \\{ 0, 1, \\ldots, 9 \\}\\). Our goals are to:\nSimulation example depicted in@fig-0218a. \\(Y\\) takes two values, zero and one, and \\(X\\) has only one value. Big sample: each single vertical bar indicates an occurrance of a zero (orange) or one (blue) as a function of the \\(X\\)s. Black curve generated the data: it is the probability of generating a one. For high values of \\(X\\), the probability of ones is increasing. What is an ideal classifier \\(C(X)\\)?\nSuppose the \\(K\\) elements in \\(\\cal{C}\\) are numbered \\(1,2,\\ldots, K\\). Let \\[\np_k(x) = Pr(Y = k|X = x), k = 1,2,\\ldots,K.\n\\]\nThese are the conditional class probabilities at \\(x\\); e.g. see little barplot at \\(x = 5\\). Then the Bayes optimal classifier at \\(x\\) is \\[\nC(x) = j \\qquad \\text{ if }  p_j(x) = \\max \\{p_1(x),p_2(x),\\ldots, p_K(x)\\}.\n\\] At \\(x=5\\) there is an 80% probability of one, and an 20% probability of a zero. So, we classify this point to the class with the highest probability, the majority class.\nNearest-neighbor averaging can be used as before. This is illustrated in Fig.~\\(\\ref{fig:0219a}\\). Here, we consider 100 points only. Nearest-neighbor averaging also breaks down as dimension grows. However, the impact on \\(\\hat{C}(x)\\) is less than on \\(\\hat{p}_k (x)\\), \\(k = 1, \\ldots, K\\).\nAverage number of errors made to measure the performance. Typically we measure the performance of \\(\\hat{C}(x)\\) using the misclassification error rate: \\[\nErr_{Te} = Ave_{i\\in Te} I[y_i \\neq \\hat{C} (x_i) ].\n\\] The Bayes classifier (using the true \\(p_k(x)\\)) has smallest error (in the population).",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "100_ddmo_classification.html#k-nearest-neighbor-classification",
    "href": "100_ddmo_classification.html#k-nearest-neighbor-classification",
    "title": "26  Classification",
    "section": "26.2 k-Nearest Neighbor Classification",
    "text": "26.2 k-Nearest Neighbor Classification\nConsider k-nearest neighbors in two dimensions. Orange and blue dots label the true class memberships of the underlying points in the 2-dim plane. Dotted line is the decision boundary, that is the contour with equal probability for both classes.\nNearest-neighbor averaging in 2-dim. At any given point we want to classify, we spread out a little neighborhood, say \\(K=10\\) points from the neighborhood and calulated the percentage of blue and orange. We assign the color with the highest probability to this point. If this is done for every point in the plane, we obtain the solid black curve as the esitmated decsion boundary.\nWe can use \\(K=1\\). This is the nearest-neighbor classifier. The decision boundary is piecewise linear. Islands occur. Approximation is rather noisy.\n\\(K=100\\) leads to a smooth decision boundary. But gets uninteresting.\n\n\n\n\n\n\nFigure 26.3: K-nearest neighbors in two dimensions. Taken from James et al. (2014)\n\n\n\n\n\n\n\n\n\nFigure 26.4: K-nearest neighbors in two dimensions. Taken from James et al. (2014)\n\n\n\n\n\n\n\n\n\nFigure 26.5: K-nearest neighbors in two dimensions. Taken from James et al. (2014)\n\n\n\n\\(K\\) large means higher bias, so \\(1/K\\) is chosen, because we go from low to high complexity on the \\(x\\)-error, see Figure 26.6. Horizontal dotted line is the base error.\n\n\n\n\n\n\nFigure 26.6: K-nearest neighbors classification error. Taken from James et al. (2014)\n\n\n\n\n26.2.1 Minkowski Distance\nThe Minkowski distance of order \\(p\\) (where \\(p\\) is an integer) between two points \\(X=(x_1,x_2,\\ldots,x_n)\\text{ and }Y=(y_1,y_2,\\ldots,y_n) \\in \\mathbb{R}^n\\) is defined as: \\[\nD \\left( X,Y \\right) = \\left( \\sum_{i=1}^n |x_i-y_i|^p \\right)^\\frac{1}{p}.\n\\]\n\n\nVideo: StatQuest: K-nearest neighbors, Clearly Explained",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "100_ddmo_classification.html#decision-and-classification-trees",
    "href": "100_ddmo_classification.html#decision-and-classification-trees",
    "title": "26  Classification",
    "section": "26.3 Decision and Classification Trees",
    "text": "26.3 Decision and Classification Trees\n\n26.3.1 Decision Trees\n\n26.3.1.1 Decision and Classification Trees, Clearly Explained\n\n\n26.3.1.2 StatQuest: Decision Trees, Part 2 - Feature Selection and Missing Data\n\n\n\n26.3.2 Regression Trees\n\n26.3.2.1 Regression Trees, Clearly Explained!!!\n\n\n26.3.2.2 How to Prune Regression Trees, Clearly Explained!!!",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "100_ddmo_classification.html#the-confusion-matrix",
    "href": "100_ddmo_classification.html#the-confusion-matrix",
    "title": "26  Classification",
    "section": "26.4 The Confusion Matrix",
    "text": "26.4 The Confusion Matrix\n\nVideo: Machine Learning Fundamentals: The Confusion Matrix\n\n\n26.4.1 Sensitivity and Specificity\n\nVideo: Machine Learning Fundamentals: Sensitivity and Specificity",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "100_ddmo_classification.html#naive-bayes",
    "href": "100_ddmo_classification.html#naive-bayes",
    "title": "26  Classification",
    "section": "26.5 Naive Bayes",
    "text": "26.5 Naive Bayes\n\nVideo: Naive Bayes, Clearly Explained!!!",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "100_ddmo_classification.html#gaussian-naive-bayes",
    "href": "100_ddmo_classification.html#gaussian-naive-bayes",
    "title": "26  Classification",
    "section": "26.6 Gaussian Naive Bayes",
    "text": "26.6 Gaussian Naive Bayes\n\nVideo: Gaussian Naive Bayes, Clearly Explained!!!\n\n\n\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2014. An Introduction to Statistical Learning with Applications in R. 7th ed. Springer.",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Classification</span>"
    ]
  },
  {
    "objectID": "100_ddmo_clustering.html",
    "href": "100_ddmo_clustering.html",
    "title": "27  Clustering",
    "section": "",
    "text": "27.1 DBSCAN",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Clustering</span>"
    ]
  },
  {
    "objectID": "100_ddmo_clustering.html#dbscan",
    "href": "100_ddmo_clustering.html#dbscan",
    "title": "27  Clustering",
    "section": "",
    "text": "Video: Clustering with DBSCAN, Clearly Explained!!!",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Clustering</span>"
    ]
  },
  {
    "objectID": "100_ddmo_clustering.html#k-means-clustering",
    "href": "100_ddmo_clustering.html#k-means-clustering",
    "title": "27  Clustering",
    "section": "27.2 k-Means Clustering",
    "text": "27.2 k-Means Clustering\nThe \\(k\\)-means algorithm is an unsupervised learning algorithm that has a loose relationship to the \\(k\\)-nearest neighbor classifier. The \\(k\\)-means algorithm works as follows:\n\nStep 1: Randomly choose \\(k\\) centers. Assign points to cluster.\nStep 2: Determine the distances of each data point to the centroids and re-assign each point to the closest cluster centroid based upon minimum distance\nStep 3: Calculate cluster centroids again\nStep 4: Repeat steps 2 and 3 until we reach global optima where no improvements are possible and no switching of data points from one cluster to other.\n\nThe basic principle of the \\(k\\)-means algorithm is illustrated in Figure 27.1, Figure 27.2, Figure 27.3, and Figure 27.4.\n\n\n\n\n\n\nFigure 27.1: k-means algorithm. Step 1. Randomly choose \\(k\\) centers. Assign points to cluster. \\(k\\) initial means(in this case \\(k=3\\)) are randomly generated within the data domain (shown in color). Attribution: I, Weston.pace, CC BY-SA 3.0 http://creativecommons.org/licenses/by-sa/3.0/, via Wikimedia Commons\n\n\n\n\n\n\n\n\n\nFigure 27.2: k-means algorithm. Step 2. \\(k\\) clusters are created by associating every observation with the nearest mean. The partitions here represent the Voronoi diagram generated by the means. Attribution: I, Weston.pace, CC BY-SA 3.0 http://creativecommons.org/licenses/by-sa/3.0/, via Wikimedia Commons\n\n\n\n\n\n\n\n\n\nFigure 27.3: k-means algorithm. Step 3. The centroid of each of the \\(k\\) clusters becomes the new mean. Attribution: I, Weston.pace, CC BY-SA 3.0 http://creativecommons.org/licenses/by-sa/3.0/, via Wikimedia Commons\n\n\n\n\n\n\n\n\n\nFigure 27.4: k-means algorithm. Step 4. Steps 2 and 3 are repeated until convergence has been reached. Attribution: I, Weston.pace, CC BY-SA 3.0 http://creativecommons.org/licenses/by-sa/3.0/, via Wikimedia Commons\n\n\n\n\nVideo: K-means clustering",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Clustering</span>"
    ]
  },
  {
    "objectID": "100_ddmo_clustering.html#ddmo-additional-videos",
    "href": "100_ddmo_clustering.html#ddmo-additional-videos",
    "title": "27  Clustering",
    "section": "27.3 DDMO-Additional Videos",
    "text": "27.3 DDMO-Additional Videos\n\nOdds and Log(Odds), Clearly Explained!!!\nOne-Hot, Label, Target and K-Fold Target Encoding, Clearly Explained!!!\nMaximum Likelihood for the Exponential Distribution, Clearly Explained!!!\nROC and AUC, Clearly Explained!\nEntropy (for data science) Clearly Explained!!!\nClassification Trees in Python from Start to Finish: Long live video!",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Clustering</span>"
    ]
  },
  {
    "objectID": "100_ddmo_clustering.html#ddmo-exercises",
    "href": "100_ddmo_clustering.html#ddmo-exercises",
    "title": "27  Clustering",
    "section": "27.4 DDMO-Exercises",
    "text": "27.4 DDMO-Exercises\n\nExercise 27.1 (Smaller Bins) What happens when we use smaller bins in a histogram?\n\n\nExercise 27.2 (Density Curve) Why plot a curve to approximate a histogram?\n\n\nExercise 27.3 (TwoSDQuestion) How many samples are plus/minus two SD around the mean?\n\n\nExercise 27.4 (OneSDQuestion) How many samples are plus/minus one SD around the mean?\n\n\nExercise 27.5 (ThreeSDQuestion) How many samples are plus/minus three SD around the mean?\n\n\nExercise 27.6 (DataRangeQuestion) You have a mean at 100 and a SD of 10. Where are 95% of the data?\n\n\nExercise 27.7 (PeakHeightQuestion) If the peak is very high, is the SD low or high?\n\n\nExercise 27.8 (ProbabilityQuestion) If we have a certain curve and want to calculate the probability of values equal to 20 if the mean is 20.\n\n\nExercise 27.9 (MeanDifferenceQuestion) The difference between \\(\\mu\\) and x-bar?\n\n\nExercise 27.10 (EstimateMeanQuestion) How do you calculate the sample mean?\n\n\nExercise 27.11 (SigmaSquaredQuestion) What is sigma squared?\n\n\nExercise 27.12 (EstimatedSDQuestion) What is the formula for the estimated standard deviation?\n\n\nExercise 27.13 (VarianceDifferenceQuestion) Difference between the variance and the estimated variance?\n\n\nExercise 27.14 (ModelBenefitsQuestion) What are the benefits of using models?\n\n\nExercise 27.15 (SampleDefinitionQuestion) What is a sample in statistics?\n\n\nExercise 27.16 (RejectHypothesisQuestion) What does it mean to reject a hypothesis?\n\n\nExercise 27.17 (NullHypothesisQuestion) What is a null hypothesis?\n\n\nExercise 27.18 (BetterDrugQuestion) How can you show that you have found a better drug?\n\n\nExercise 27.19 (PValueIntroductionQuestion) What is the reason for introducing the p-value?\n\n\nExercise 27.20 (PValueRangeQuestion) Is there any range for p-values? Can it be negative?\n\n\nExercise 27.21 (PValueRangeQuestion) Is there any range for p-values? Can it be negative?\n\n\nExercise 27.22 (TypicalPValueQuestion) What are typical values of the p-value and what does it mean? 5%?\n\n\nExercise 27.23 (FalsePositiveQuestion) What is a false-positive?\n\n\nExercise 27.24 (CalculatePValueQuestion) How to calculate p-value?\n\n\nExercise 27.25 (SDCalculationQuestion) What is the SD if the mean is 155 and in the range from 142 - 169 there are 95% of the data?\n\n\nExercise 27.26 (SidedPValueQuestion) When do we need the two-sided p-value and when the one-sided?\n\n\nExercise 27.27 (CoinTestQuestion) Test a coin with Tail-Head-Head. What is the p-value?\n\n\nExercise 27.28 (BorderPValueQuestion) If you get exactly the 0.05 border value, can you reject?\n\n\nExercise 27.29 (OneSidedPValueCautionQuestion) Why should you be careful with a one-sided p-test?\n\n\nExercise 27.30 (BinomialDistributionQuestion) What is the binomial distribution?\n\n\nExercise 27.31 (PHackingWaysQuestion) Name two typical ways of p-hacking.\n\n\nExercise 27.32 (AvoidPHackingQuestion) How can p-hacking be avoided?\n\n\nExercise 27.33 (MultipleTestingProblemQuestion) What is the multiple testing problem?\n\n\n27.4.0.1 Covariance\n\nExercise 27.34 (CovarianceDefinitionQuestion) What is covariance?\n\n\nExercise 27.35 (CovarianceMeaningQuestion) What is the meaning of covariance?\n\n\nExercise 27.36 (CovarianceVarianceRelationshipQuestion) What is the relationship between covariance and variance?\n\n\nExercise 27.37 (HighCovarianceQuestion) If covariance is high, is there a strong relationship?\n\n\nExercise 27.38 (ZeroCovarianceQuestion) What if the covariance is zero?\n\n\nExercise 27.39 (NegativeCovarianceQuestion) Can covariance be negative?\n\n\nExercise 27.40 (NegativeVarianceQuestion) Can variance be negative?\n\n\nExercise 27.41 (CorrelationValueQuestion) What do you do if the correlation value is 10?\n\n\nExercise 27.42 (CorrelationRangeQuestion) What is the possible range of correlation values?\n\n\nExercise 27.43 (CorrelationFormulaQuestion) What is the formula for correlation?\n\n\nExercise 27.44 (UnderstandingStatisticalPower) What is the definition of power in a statistical test?\n\n\nExercise 27.45 (DistributionEffectOnPower) What is the implication for power analysis if the samples come from the same distribution?\n\n\nExercise 27.46 (IncreasingPower) How can you increase the power if the distributions are very similar?\n\n\nExercise 27.47 (PreventingPHacking) What should be done to avoid p-hacking when the distributions are close to each other?\n\n\nExercise 27.48 (SampleSizeAndPower) If there is overlap and the sample size is small, will the power be high or low?\n\n\nExercise 27.49 (FactorsAffectingPower) Which are the two main factors that affect power?\n\n\nExercise 27.50 (PurposeOfPowerAnalysis) What does power analysis tell us?\n\n\nExercise 27.51 (ExperimentRisks) What are the two risks faced when performing an experiment?\n\n\nExercise 27.52 (PerformingPowerAnalysis) How do you perform a power analysis?\n\n\nExercise 27.53 (CentralLimitTheoremExplanation) What does the Central Limit Theorem state?\n\n\nExercise 27.54 (MedianInBoxplot) What is represented by the middle line in a boxplot?\n\n\nExercise 27.55 (BoxContentInBoxplot) What does the box in a boxplot represent?\n\n\nExercise 27.56 (RSquaredDefinition) What is R-squared? Show the formula.\n\n\nExercise 27.57 (NegativeRSquared) Can the R-squared value be negative?\n\n\nExercise 27.58 (RSquaredCalculation) Perform a calculation involving R-squared.\n\n\nExercise 27.59 (LeastSquaresMeaning) What is the meaning of the least squares method?\n\n\nExercise 27.60 (RegressionVsClassification) What is the difference between regression and classification?\n\n\nExercise 27.61 (LikelihoodConcept) What is the idea of likelihood?\n\n\nExercise 27.62 (ProbabilityVsLikelihood) What is the difference between probability and likelihood?\n\n\nExercise 27.63 (TrainVsTestData) What is the difference between training and testing data?\n\n\nExercise 27.64 (SingleValidationIssue) What is the problem if you validate the model only once?\n\n\nExercise 27.65 (FoldDefinition) What is a fold in cross-validation?\n\n\nExercise 27.66 (LeaveOneOutValidation) What is leave-one-out cross-validation?\n\n\nExercise 27.67 (DrawingConfusionMatrix) Draw the confusion matrix.\n\n\nExercise 27.68 (SensitivitySpecificityCalculation1) Calculate the sensitivity and specificity for a given confusion matrix.\n\n\nExercise 27.69 (SensitivitySpecificityCalculation2) Calculate the sensitivity and specificity for a given confusion matrix.\n\n\nExercise 27.70 (BiasAndVariance) What are bias and variance?\n\n\nExercise 27.71 (MutualInformationExample) Provide an example and calculate if mutual information is high or low.\n\n\nExercise 27.72 (WhatIsPCA) What is PCA?\n\n\nExercise 27.73 (ScreePlotExplanation) What is a scree plot?\n\n\nExercise 27.74 (LeastSquaresInPCA) Does PCA use least squares?\n\n\nExercise 27.75 (PCASteps) Which steps are performed by PCA?\n\n\nExercise 27.76 (EigenvaluePC1) What is the eigenvalue of the first principal component?\n\n\nExercise 27.77 (DifferencesBetweenPoints) Are the differences between red and yellow the same as the differences between red and blue points?\n\n\nExercise 27.78 (ScalingInPCA) How to scale data in PCA?\n\n\nExercise 27.79 (DetermineNumberOfComponents) How to determine the number of principal components?\n\n\nExercise 27.80 (LimitingNumberOfComponents) How is the number of principal components limited?\n\n\nExercise 27.81 (WhyUseTSNE) Why use t-SNE?\n\n\nExercise 27.82 (MainIdeaOfTSNE) What is the main idea of t-SNE?\n\n\nExercise 27.83 (BasicConceptOfTSNE) What is the basic concept of t-SNE?\n\n\nExercise 27.84 (TSNESteps) What are the steps in t-SNE?\n\n\nExercise 27.85 (HowKMeansWorks) How does K-means clustering work?\n\n\nExercise 27.86 (QualityOfClusters) How can the quality of the resulting clusters be calculated?\n\n\nExercise 27.87 (IncreasingK) Why is it not a good idea to increase k too much?\n\n\nExercise 27.88 (CorePointInDBSCAN) What is a core point in DBSCAN?\n\n\nExercise 27.89 (AddingVsExtending) What is the difference between adding and extending in DBSCAN?\n\n\nExercise 27.90 (OutliersInDBSCAN) What are outliers in DBSCAN?\n\n\nExercise 27.91 (AdvantagesAndDisadvantagesOfK) What are the advantages and disadvantages of k = 1 and k = 100 in K-nearest neighbors?\n\n\nExercise 27.92 (NaiveBayesFormula) What is the formula for Naive Bayes?\n\n\nExercise 27.93 (CalculateProbabilities) Calculate the probabilities for a given example using Naive Bayes.\n\n\nExercise 27.94 (UnderflowProblem) Why is underflow a problem in Gaussian Naive Bayes?\n\n\nExercise 27.95 (Tree Usage) For what can we use trees?\n\n\nExercise 27.96 (Tree Usage) Based on a shown tree graph:\n\nHow can you use this tree?\nWhat is the root node?\nWhat are branches and internal nodes?\nWhat are the leafs?\nAre the leafs pure or impure?\nWhich of the leafs is more impure?\n\n\n\nExercise 27.97 (Tree Feature Importance) Is the most or least important feature on top?\n\n\nExercise 27.98 (Tree Feature Imputation) How can you fill a gap/missing data?\n\n\nSolution 27.1 (Tree Feature Imputation). \n\nMean\nMedian\nComparing to column with high correlation\n\n\n\nExercise 27.99 (Regression Tree Limitations) What are limitations?\n\n\nExercise 27.100 (Regression Tree Score) How is the tree score calculated?\n\n\nExercise 27.101 (Regression Tree Alpha Value Small) What can we say about the tree if the alpha value is small?\n\n\nExercise 27.102 (Regression Tree Increase Alpha Value) What happens if you increase alpha?\n\n\nExercise 27.103 (Regression Tree Pruning) What is the meaning of pruning?",
    "crumbs": [
      "Data-Driven Modeling and Optimization",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Clustering</span>"
    ]
  },
  {
    "objectID": "200_mlai.html",
    "href": "200_mlai.html",
    "title": "28  Machine Learning and Artificial Intelligence",
    "section": "",
    "text": "28.1 Jupyter Notebooks",
    "crumbs": [
      "Machine Learning and AI",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Machine Learning and Artificial Intelligence</span>"
    ]
  },
  {
    "objectID": "200_mlai.html#jupyter-notebooks",
    "href": "200_mlai.html#jupyter-notebooks",
    "title": "28  Machine Learning and Artificial Intelligence",
    "section": "",
    "text": "The Jupyter-Notebook version of this file can be found here: malai.ipynb",
    "crumbs": [
      "Machine Learning and AI",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Machine Learning and Artificial Intelligence</span>"
    ]
  },
  {
    "objectID": "200_mlai.html#videos",
    "href": "200_mlai.html#videos",
    "title": "28  Machine Learning and Artificial Intelligence",
    "section": "28.2 Videos",
    "text": "28.2 Videos\n\n28.2.1 June, 11th 2024\n\nHappy Halloween (Neural Networks Are Not Scary)\nThe Essential Main Ideas of Neural Networks\n\n\n\n28.2.2 June, 18th 2024\n\nThe Chain Rule\nGradient Descent, Step-by-Step\nNeural Networks Pt. 2: Backpropagation Main Ideas\n\n\n28.2.2.1 Gradient Descent\n\nExercise 28.1 (GradDescStepSize) How is the step size calculated?\n\n\nExercise 28.2 (GradDescIntercept) How to calculate the new intercept?\n\n\nExercise 28.3 (GradDescIntercept) When does the gradient descend stop?\n\n\n\n28.2.2.2 Backpropagation\n\nExercise 28.4 (ChainRuleAndGradientDescent) What are the key components involved in backpropagation?\n\n\nExercise 28.5 (BackpropagationNaming) Why is it called backpropagation?\n\n\n\n28.2.2.3 ReLU\n\nExercise 28.6 (Graph ReLU) Draw the graph of a ReLU function.\n\n\nBackpropagation Details Pt. 1: Optimizing 3 parameters simultaneously.\nBackpropagation Details Pt. 2: Going bonkers with The Chain Rule\nNeural Networks Pt. 3: ReLU In Action!!!\nNeural Networks Pt. 4: Multiple Inputs and Outputs\nNeural Networks Part 5: ArgMax and SoftMax\nTensors for Neural Networks, Clearly Explained!!!\nEssential Matrix Algebra for Neural Networks, Clearly Explained!!!\nThe StatQuest Introduction to PyTorch\n\n\n\n28.2.2.4 PyTorch Links\n\nStatQuest: Introduction to Coding Neural Networks with PyTorch\nML-AI Pytorch Introduction\n\n\n\n\n28.2.3 June, 25th 2024\n\n\n28.2.4 CNNs\n\n28.2.4.1 Neural Networks Part 8: Image Classification with Convolutional Neural Networks (CNNs)\n\nExercise 28.7 (CNNImageRecognition) Why are classical neural networks poor at image recognition?\n\n\nExercise 28.8 (CNNFiltersInitialization) How are the filter values in CNNs initialized and optimized?\n\n\nExercise 28.9 (CNNFilterInitialization) How are the filter values determined in Convolutional Neural Networks (CNNs)?\n\n\nExercise 28.10 (GenNNStockPrediction) What is a limitation of using classical neural networks for stock market prediction?\n\n\n\n\n28.2.5 RNN\n\n28.2.5.1 Recurrent Neural Networks (RNNs), Clearly Explained!!!\n\nExercise 28.11 (RNNUnrolling) How does the unrolling process work in Recurrent Neural Networks (RNNs)?\n\n\nExercise 28.12 (RNNReliability) Why do Recurrent Neural Networks (RNNs) sometimes fail to work reliably?\n\n\n\n\n28.2.6 LSTM\n\n28.2.6.1 Long Short-Term Memory (LSTM), Clearly Explained\n\nExercise 28.13 (LSTMSigmoidTanh) What are the differences between the sigmoid and tanh activation functions?\n\n\nExercise 28.14 (LSTMSigmoidTanh) What is the ?\n\n\nExercise 28.15 (LSTMGates) What are the gates in an LSTM network and their functions?\n\n\nExercise 28.16 (LSTMLongTermInfo) In which gate is long-term information used in an LSTM network?\n\n\nExercise 28.17 (LSTMUpdateGates) In which Gates is it updated in an LSTM?\n\n\n\n\n28.2.7 Pytorch/Lightning\n\n28.2.7.1 Introduction to Coding Neural Networks with PyTorch and Lightning\n\nExercise 28.18 (PyTorchRequiresGrad) What does requires_grad mean in PyTorch?\n\n\n\n\n28.2.8 July, 2nd 2024\n\nWord Embedding and Word2Vec, Clearly Explained!!!\nSequence-to-Sequence (seq2seq) Encoder-Decoder Neural Networks, Clearly Explained!!!\nAttention for Neural Networks, Clearly Explained!!!\n\n\n28.2.8.1 Embeddings\n\nExercise 28.19 (NN Strings) Can neural networks process strings?\n\n\nExercise 28.20 (Embedding Definition) What is the meaning of word embedding?\n\n\nExercise 28.21 (Embedding Dimensions) Why do we need high dimension in word embedding?\n\n\n\n28.2.8.2 Sequence to Sequence\n\nExercise 28.22 (LSTM) Why are LSTMs used?\n\n\nExercise 28.23 (Teacher Forcing) Why is teacher forcing used?\n\n\nExercise 28.24 (Attention) What is the idea of attention?\n\n\n\n\n28.2.9 Additional Lecture (July, 9th 2024)?\n\nTransformer Neural Networks, ChatGPT’s foundation, Clearly Explained!!!\nDecoder-Only Transformers, ChatGPTs specific Transformer, Clearly Explained!!!\nThe matrix math behind transformer neural networks, one step at a time!!!\nWord Embedding in PyTorch + Lightning\n\n\n28.2.9.1 Transformers\n\nExercise 28.25 (ChatGPT) What kind of transformer does ChatGPT use?\n\n\nExercise 28.26 (Translation) What kind of NN are used for translation?\n\n\nExercise 28.27 (Difference Encoder-Decoder and Decoder Only.) What is the encoder-decoder transformer and the decoder only transformer?\n\n\nExercise 28.28 (Weights) How are the weights initialized (a) and trained (b)?\n\n\nExercise 28.29 (Order of Words) How is the word order preserved?\n\n\nExercise 28.30 (Relationship Between Words) How is the relationship between words modeled?\n\n\nExercise 28.31 (Masked Self Attention) What is masked self-attention?\n\n\nExercise 28.32 (Softmax) Why is Softmax used to calculate percentage of similarities?\n\n\nExercise 28.33 (Softmax Output) How is the percentage output of softmax in Transformers used?\n\n\nExercise 28.34 (V´s) What is done with the scaled V´s that we get for each token so far (example: “is”,”what”)?\n\n\nExercise 28.35 (Residual Connections) What are residual connections?\n\n\nExercise 28.36 (Generate Known Word in Sequence) Why do we want to generate the word in the sequence that comes after “what” that we already know? (Example from video)\n\n\nExercise 28.37 (Masked-Self-Attention Values and Bypass) How do we use the two values (“masked-self-attention values + bypass”) which we have for each input? (Example from video: (“What”, ”is”, ”StatQuest”))\n\n\n\n\n28.2.10 Additional Videos\n\nThe SoftMax Derivative, Step-by-Step!!!\nNeural Networks Part 6: Cross Entropy\nNeural Networks Part 7: Cross Entropy Derivatives and Backpropagation\n\n\n\n28.2.11 All Videos in a Playlist\n\nFull Playlist ML-AI",
    "crumbs": [
      "Machine Learning and AI",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Machine Learning and Artificial Intelligence</span>"
    ]
  },
  {
    "objectID": "200_mlai.html#the-statquest-introduction-to-pytorch",
    "href": "200_mlai.html#the-statquest-introduction-to-pytorch",
    "title": "28  Machine Learning and Artificial Intelligence",
    "section": "28.3 The StatQuest Introduction to PyTorch",
    "text": "28.3 The StatQuest Introduction to PyTorch\nThe following code is taken from The StatQuest Introduction to PyTorch. Attribution goes to Josh Starmer, the creator of StatQuest, see Josh Starmer.\n\nimport torch # torch provides basic functions, from setting a random seed (for reproducability) to creating tensors.\nimport torch.nn as nn # torch.nn allows us to create a neural network.\nimport torch.nn.functional as F # nn.functional give us access to the activation and loss functions.\nfrom torch.optim import SGD # optim contains many optimizers. Here, we're using SGD, stochastic gradient descent.\n\nimport matplotlib.pyplot as plt ## matplotlib allows us to draw graphs.\nimport seaborn as sns ## seaborn makes it easier to draw nice-looking graphs.\n\n%matplotlib inline\n\nBuilding a neural network in PyTorch means creating a new class with two methods: init() and forward(). The init() method defines and initializes all of the parameters that we want to use, and the forward() method tells PyTorch what should happen during a forward pass through the neural network.\n\n28.3.1 Build a Simple Neural Network in PyTorch\n__init__() is the class constructor function, and we use it to initialize the weights and biases.\n\n## create a neural network class by creating a class that inherits from nn.Module.\nclass BasicNN(nn.Module):\n\n    def __init__(self): # __init__() is the class constructor function, and we use it to initialize the weights and biases.\n        \n        super().__init__() # initialize an instance of the parent class, nn.Model.\n        \n        ## Now create the weights and biases that we need for our neural network.\n        ## Each weight or bias is an nn.Parameter, which gives us the option to optimize the parameter by setting\n        ## requires_grad, which is short for \"requires gradient\", to True. Since we don't need to optimize any of these\n        ## parameters now, we set requires_grad=False.\n        ##\n        ## NOTE: Because our neural network is already fit to the data, we will input specific values\n        ## for each weight and bias. In contrast, if we had not already fit the neural network to the data,\n        ## we might start with a random initalization of the weights and biases.\n        self.w00 = nn.Parameter(torch.tensor(1.7), requires_grad=False)\n        self.b00 = nn.Parameter(torch.tensor(-0.85), requires_grad=False)\n        self.w01 = nn.Parameter(torch.tensor(-40.8), requires_grad=False)\n        \n        self.w10 = nn.Parameter(torch.tensor(12.6), requires_grad=False)\n        self.b10 = nn.Parameter(torch.tensor(0.0), requires_grad=False)\n        self.w11 = nn.Parameter(torch.tensor(2.7), requires_grad=False)\n\n        self.final_bias = nn.Parameter(torch.tensor(-16.), requires_grad=False)\n        \n        \n    def forward(self, input): ## forward() takes an input value and runs it though the neural network \n                              ## illustrated at the top of this notebook. \n        \n        ## the next three lines implement the top of the neural network (using the top node in the hidden layer).\n        input_to_top_relu = input * self.w00 + self.b00\n        top_relu_output = F.relu(input_to_top_relu)\n        scaled_top_relu_output = top_relu_output * self.w01\n        \n        ## the next three lines implement the bottom of the neural network (using the bottom node in the hidden layer).\n        input_to_bottom_relu = input * self.w10 + self.b10\n        bottom_relu_output = F.relu(input_to_bottom_relu)\n        scaled_bottom_relu_output = bottom_relu_output * self.w11\n        \n        ## here, we combine both the top and bottom nodes from the hidden layer with the final bias.\n        input_to_final_relu = scaled_top_relu_output + scaled_bottom_relu_output + self.final_bias\n        \n        output = F.relu(input_to_final_relu)\n    \n        return output # output is the predicted effectiveness for a drug dose.\n\nOnce we have created the class that defines the neural network, we can create an actual neural network and print out its parameters, just to make sure things are what we expect.\n\n## create the neural network. \nmodel = BasicNN()\n\n## print out the name and value for each parameter\nfor name, param in model.named_parameters():\n    print(name, param.data)\n\nw00 tensor(1.7000)\nb00 tensor(-0.8500)\nw01 tensor(-40.8000)\nw10 tensor(12.6000)\nb10 tensor(0.)\nw11 tensor(2.7000)\nfinal_bias tensor(-16.)\n\n\n\n\n28.3.2 Use the Neural Network and Graph the Output\nNow that we have a neural network, we can use it on a variety of doses to determine which will be effective. Then we can make a graph of these data, and this graph should match the green bent shape fit to the training data that’s shown at the top of this document. So, let’s start by making a sequence of input doses…\n\n## now create the different doses we want to run through the neural network.\n## torch.linspace() creates the sequence of numbers between, and including, 0 and 1.\ninput_doses = torch.linspace(start=0, end=1, steps=11)\n\n# now print out the doses to make sure they are what we expect...\ninput_doses\n\ntensor([0.0000, 0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000,\n        0.9000, 1.0000])\n\n\nNow that we have input_doses, let’s run them through the neural network and graph the output…\n\n## create the neural network. \nmodel = BasicNN() \n\n## now run the different doses through the neural network.\noutput_values = model(input_doses)\n\n## Now draw a graph that shows the effectiveness for each dose.\n##\n## First, set the style for seaborn so that the graph looks cool.\nsns.set(style=\"whitegrid\")\n\n## create the graph (you might not see it at this point, but you will after we save it as a PDF).\nsns.lineplot(x=input_doses, \n     y=output_values, \n     color='green', \n     linewidth=2.5)\n\n## now label the y- and x-axes.\nplt.ylabel('Effectiveness')\nplt.xlabel('Dose')\n\n## optionally, save the graph as a PDF.\n# plt.savefig('BasicNN.pdf')\n\nText(0.5, 0, 'Dose')\n\n\n\n\n\n\n\n\n\nThe graph shows that the neural network fits the training data. In other words, so far, we don’t have any bugs in our code.\n\n\n28.3.3 Optimize (Train) a Parameter in the Neural Network and Graph the Output\nNow that we know how to create and use a simple neural network, and we can graph the output relative to the input, let’s see how to train a neural network. The first thing we need to do is tell PyTorch which parameter (or parameters) we want to train, and we do that by setting requiresgrad=True. In this example, we’ll train finalbias.\nNow we create a neural network by creating a class that inherits from nn.Module.\nNOTE: This code is the same as before, except we changed the class name to BasicNN_train and we modified final_bias in two ways:\n1) we set the value of the tensor to 0, and\n2) we set \"requires_grad=True\".\nNow let’s graph the output of BasicNN_train, which is currently not optimized, and compare it to the graph we drew earlier of the optimized neural network.\n\nclass BasicNN_train(nn.Module):\n\n    def __init__(self): # __init__ is the class constructor function, and we use it to initialize the weights and biases.\n        \n        super().__init__() # initialize an instance of the parent class, nn.Module.\n        \n        self.w00 = nn.Parameter(torch.tensor(1.7), requires_grad=False)\n        self.b00 = nn.Parameter(torch.tensor(-0.85), requires_grad=False)\n        self.w01 = nn.Parameter(torch.tensor(-40.8), requires_grad=False)\n        \n        self.w10 = nn.Parameter(torch.tensor(12.6), requires_grad=False)\n        self.b10 = nn.Parameter(torch.tensor(0.0), requires_grad=False)\n        self.w11 = nn.Parameter(torch.tensor(2.7), requires_grad=False)\n\n        ## we want to modify final_bias to demonstrate how to optimize it with backpropagation.\n        ## The optimal value for final_bias is -16...\n#         self.final_bias = nn.Parameter(torch.tensor(-16.), requires_grad=False)\n        ## ...so we set it to 0 and tell Pytorch that it now needs to calculate the gradient for this parameter.\n        self.final_bias = nn.Parameter(torch.tensor(0.), requires_grad=True) \n        \n    def forward(self, input):\n        \n        input_to_top_relu = input * self.w00 + self.b00\n        top_relu_output = F.relu(input_to_top_relu)\n        scaled_top_relu_output = top_relu_output * self.w01\n        \n        input_to_bottom_relu = input * self.w10 + self.b10\n        bottom_relu_output = F.relu(input_to_bottom_relu)\n        scaled_bottom_relu_output = bottom_relu_output * self.w11\n    \n        input_to_final_relu = scaled_top_relu_output + scaled_bottom_relu_output + self.final_bias\n        \n        output = F.relu(input_to_final_relu)\n        \n        return output\n\n\n## create the neural network. \nmodel = BasicNN_train() \n\n## now run the different doses through the neural network.\noutput_values = model(input_doses)\n\n## Now draw a graph that shows the effectiveness for each dose.\n##\n## set the style for seaborn so that the graph looks cool.\nsns.set(style=\"whitegrid\")\n\n## create the graph (you might not see it at this point, but you will after we save it as a PDF).\nsns.lineplot(x=input_doses, \n             y=output_values.detach(), ## NOTE: because final_bias has a gradident, we call detach() \n                                       ## to return a new tensor that only has the value and not the gradient.\n             color='green', \n             linewidth=2.5)\n\n## now label the y- and x-axes.\nplt.ylabel('Effectiveness')\nplt.xlabel('Dose')\n\n## lastly, save the graph as a PDF.\n# plt.savefig('BasicNN_train.pdf')\n\nText(0.5, 0, 'Dose')\n\n\n\n\n\n\n\n\n\nThe graph shows that when the dose is 0.5, the output from the unoptimized neural network is 17, which is wrong, since the output value should be 1. So, now that we have a parameter we can optimize, let’s create some training data that we can use to optimize it.\n\n## create the training data for the neural network.\ninputs = torch.tensor([0., 0.5, 1.])\nlabels = torch.tensor([0., 1., 0.])\n\n..and now let’s use that training data to train (or optimize) final_bias.\n\n## create the neural network we want to train.\nmodel = BasicNN_train()\n\noptimizer = SGD(model.parameters(), lr=0.1) ## here we're creating an optimizer to train the neural network.\n                                            ## NOTE: There are a bunch of different ways to optimize a neural network.\n                                            ## In this example, we'll use Stochastic Gradient Descent (SGD). However,\n                                            ## another popular algortihm is Adam (which will be covered in a StatQuest).\n\nprint(\"Final bias, before optimization: \" + str(model.final_bias.data) + \"\\n\")\n\n## this is the optimization loop. Each time the optimizer sees all of the training data is called an \"epoch\".\nfor epoch in range(100):\n\n    ## we create and initialize total_loss for each epoch so that we can evaluate how well model fits the\n    ## training data. At first, when the model doesn't fit the training data very well, total_loss\n    ## will be large. However, as gradient descent improves the fit, total_loss will get smaller and smaller.\n    ## If total_loss gets really small, we can decide that the model fits the data well enough and stop\n    ## optimizing the fit. Otherwise, we can just keep optimizing until we reach the maximum number of epochs. \n    total_loss = 0\n\n    ## this internal loop is where the optimizer sees all of the training data and where we \n    ## calculate the total_loss for all of the training data.\n    for iteration in range(len(inputs)):\n\n        input_i = inputs[iteration] ## extract a single input value (a single dose)...\n        label_i = labels[iteration] ## ...and its corresponding label (the effectiveness for the dose).\n\n        output_i = model(input_i) ## calculate the neural network output for the input (the single dose).\n\n        loss = (output_i - label_i)**2 ## calculate the loss for the single value.\n                                       ## NOTE: Because output_i = model(input_i), \"loss\" has a connection to \"model\"\n                                       ## and the derivative (calculated in the next step) is kept and accumulated\n                                       ## in \"model\".\n\n        loss.backward() # backward() calculates the derivative for that single value and adds it to the previous one.\n\n        total_loss += float(loss) # accumulate the total loss for this epoch.\n\n\n    if (total_loss &lt; 0.0001):\n        print(\"Num steps: \" + str(epoch))\n        break\n\n    optimizer.step() ## take a step toward the optimal value.\n    optimizer.zero_grad() ## This zeroes out the gradient stored in \"model\". \n                          ## Remember, by default, gradients are added to the previous step (the gradients are accumulated),\n                          ## and we took advantage of this process to calculate the derivative one data point at a time.\n                          ## NOTE: \"optimizer\" has access to \"model\" because of how it was created with the call \n                          ## (made earlier): optimizer = SGD(model.parameters(), lr=0.1).\n                          ## ALSO NOTE: Alternatively, we can zero out the gradient with model.zero_grad().\n    if epoch % 10 == 0:\n        print(\"Step: \" + str(epoch) + \" Final Bias: \" + str(model.final_bias.data) + \"\\n\")\n    ## now go back to the start of the loop and go through another epoch.\n\nprint(\"Total loss: \" + str(total_loss))\nprint(\"Final bias, after optimization: \" + str(model.final_bias.data))\n\nFinal bias, before optimization: tensor(0.)\n\nStep: 0 Final Bias: tensor(-3.2020)\n\nStep: 10 Final Bias: tensor(-14.6348)\n\nStep: 20 Final Bias: tensor(-15.8623)\n\nStep: 30 Final Bias: tensor(-15.9941)\n\nNum steps: 34\nTotal loss: 6.58966600894928e-05\nFinal bias, after optimization: tensor(-16.0019)\n\n\nSo, if everything worked correctly, the optimizer should have converged on final_bias = 16.0019 after 34 steps, or epochs. BAM!\nLastly, let’s graph the output from the optimized neural network and see if it’s the same as what we started with. If so, then the optimization worked.\n\n## run the different doses through the neural network\noutput_values = model(input_doses)\n\n## set the style for seaborn so that the graph looks cool.\nsns.set(style=\"whitegrid\")\n\n## create the graph (you might not see it at this point, but you will after we save it as a PDF).\nsns.lineplot(x=input_doses, \n     y=output_values.detach(), ## NOTE: we call detach() because final_bias has a gradient\n     color='green', \n     linewidth=2.5)\n\n## now label the y- and x-axes.\nplt.ylabel('Effectiveness')\nplt.xlabel('Dose')\n\n## lastly, save the graph as a PDF.\n# plt.savefig('BascNN_optimized.pdf')\n\nText(0.5, 0, 'Dose')\n\n\n\n\n\n\n\n\n\nAnd we see that the optimized model results in the same graph that we started with, so the optimization worked as expected.",
    "crumbs": [
      "Machine Learning and AI",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Machine Learning and Artificial Intelligence</span>"
    ]
  },
  {
    "objectID": "200_mlai.html#build-a-long-short-term-memory-unit-by-hand-using-pytorch-lightning",
    "href": "200_mlai.html#build-a-long-short-term-memory-unit-by-hand-using-pytorch-lightning",
    "title": "28  Machine Learning and Artificial Intelligence",
    "section": "28.4 Build a Long Short-Term Memory unit by hand using PyTorch + Lightning",
    "text": "28.4 Build a Long Short-Term Memory unit by hand using PyTorch + Lightning\nThe following code is based on Long Short-Term Memory with PyTorch + Lightning and StatQuest: Long Short-Term Memory (LSTM) with PyTorch + Lightning!!!. Attribution goes to Josh Starmer, the creator of StatQuest, see Josh Starmer.\n\nimport torch # torch will allow us to create tensors.\nimport torch.nn as nn # torch.nn allows us to create a neural network.\nimport torch.nn.functional as F # nn.functional give us access to the activation and loss functions.\nfrom torch.optim import Adam # optim contains many optimizers. This time we're using Adam\n\nimport lightning as L # lightning has tons of cool tools that make neural networks easier\nfrom torch.utils.data import TensorDataset, DataLoader # these are needed for the training data\n\nA Long Short-Term Memory (LSTM) unit is a type of neural network, and that means we need to create a new class. To make it easy to train the LSTM, this class will inherit from LightningModule and we’ll create the following methods:\n\ninit() to initialize the Weights and Biases and keep track of a few other house keeping things.\nlstm_unit() to do the LSTM math. For example, to calculate the percentage of the long-term memory to remember.\nforward() to make a forward pass through the unrolled LSTM. In other words forward() calls lstm_unit() for each data point.\nconfigure_optimizers() to configure the opimimizer. In the past, we have use SGD (Stochastic Gradient Descent), however, in this tutorial we’ll change things up and use Adam, another popular algorithm for optimizing the Weights and Biases.\ntraining_step() to pass the training data to forward(), calculate the loss and to keep track of the loss values in a log file.\n\n\nclass LSTMbyHand(L.LightningModule):\n\n    def __init__(self):\n        super().__init__()\n        L.seed_everything(seed=42)\n\n        ## NOTE: nn.LSTM() uses random values from a uniform distribution to initialize the tensors\n        ## Here we can do it 2 different ways 1) Normal Distribution and 2) Uniform Distribution\n        ## We'll start with the Normal distribution.\n        mean = torch.tensor(0.0)\n        std = torch.tensor(1.0)\n\n        ## NOTE: In this case, I'm only using the normal distribution for the Weights.\n        ## All Biases are initialized to 0.\n        ##\n        ## These are the Weights and Biases in the first stage, which determines what percentage\n        ## of the long-term memory the LSTM unit will remember.\n        self.wlr1 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n        self.wlr2 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n        self.blr1 = nn.Parameter(torch.tensor(0.), requires_grad=True)\n\n        ## These are the Weights and Biases in the second stage, which determines the new\n        ## potential long-term memory and what percentage will be remembered.\n        self.wpr1 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n        self.wpr2 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n        self.bpr1 = nn.Parameter(torch.tensor(0.), requires_grad=True)\n\n        self.wp1 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n        self.wp2 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n        self.bp1 = nn.Parameter(torch.tensor(0.), requires_grad=True)\n\n        ## These are the Weights and Biases in the third stage, which determines the\n        ## new short-term memory and what percentage will be sent to the output.\n        self.wo1 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n        self.wo2 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n        self.bo1 = nn.Parameter(torch.tensor(0.), requires_grad=True)\n\n        ## We can also initialize all Weights and Biases using a uniform distribution. This is\n        ## how nn.LSTM() does it.\n#         self.wlr1 = nn.Parameter(torch.rand(1), requires_grad=True)\n#         self.wlr2 = nn.Parameter(torch.rand(1), requires_grad=True)\n#         self.blr1 = nn.Parameter(torch.rand(1), requires_grad=True)\n\n#         self.wpr1 = nn.Parameter(torch.rand(1), requires_grad=True)\n#         self.wpr2 = nn.Parameter(torch.rand(1), requires_grad=True)\n#         self.bpr1 = nn.Parameter(torch.rand(1), requires_grad=True)\n\n#         self.wp1 = nn.Parameter(torch.rand(1), requires_grad=True)\n#         self.wp2 = nn.Parameter(torch.rand(1), requires_grad=True)\n#         self.bp1 = nn.Parameter(torch.rand(1), requires_grad=True)\n\n#         self.wo1 = nn.Parameter(torch.rand(1), requires_grad=True)\n#         self.wo2 = nn.Parameter(torch.rand(1), requires_grad=True)\n#         self.bo1 = nn.Parameter(torch.rand(1), requires_grad=True)\n\n\n    def lstm_unit(self, input_value, long_memory, short_memory):\n        ## lstm_unit does the math for a single LSTM unit.\n\n        ## NOTES:\n        ## long term memory is also called \"cell state\"\n        ## short term memory is also called \"hidden state\"\n\n        ## 1) The first stage determines what percent of the current long-term memory\n        ##    should be remembered\n        long_remember_percent = torch.sigmoid((short_memory * self.wlr1) +\n                                              (input_value * self.wlr2) +\n                                              self.blr1)\n\n        ## 2) The second stage creates a new, potential long-term memory and determines what\n        ##    percentage of that to add to the current long-term memory\n        potential_remember_percent = torch.sigmoid((short_memory * self.wpr1) +\n                                                   (input_value * self.wpr2) +\n                                                   self.bpr1)\n        potential_memory = torch.tanh((short_memory * self.wp1) +\n                                      (input_value * self.wp2) +\n                                      self.bp1)\n\n        ## Once we have gone through the first two stages, we can update the long-term memory\n        updated_long_memory = ((long_memory * long_remember_percent) +\n                       (potential_remember_percent * potential_memory))\n\n        ## 3) The third stage creates a new, potential short-term memory and determines what\n        ##    percentage of that should be remembered and used as output.\n        output_percent = torch.sigmoid((short_memory * self.wo1) +\n                                       (input_value * self.wo2) +\n                                       self.bo1)\n        updated_short_memory = torch.tanh(updated_long_memory) * output_percent\n\n        ## Finally, we return the updated long and short-term memories\n        return([updated_long_memory, updated_short_memory])\n\n    def forward(self, input):\n        ## forward() unrolls the LSTM for the training data by calling lstm_unit() for each day of training data\n        ## that we have. forward() also keeps track of the long and short-term memories after each day and returns\n        ## the final short-term memory, which is the 'output' of the LSTM.\n\n        long_memory = 0 # long term memory is also called \"cell state\" and indexed with c0, c1, ..., cN\n        short_memory = 0 # short term memory is also called \"hidden state\" and indexed with h0, h1, ..., cN\n        day1 = input[0]\n        day2 = input[1]\n        day3 = input[2]\n        day4 = input[3]\n\n        ## Day 1\n        long_memory, short_memory = self.lstm_unit(day1, long_memory, short_memory)\n\n        ## Day 2\n        long_memory, short_memory = self.lstm_unit(day2, long_memory, short_memory)\n\n        ## Day 3\n        long_memory, short_memory = self.lstm_unit(day3, long_memory, short_memory)\n\n        ## Day 4\n        long_memory, short_memory = self.lstm_unit(day4, long_memory, short_memory)\n\n        ##### Now return short_memory, which is the 'output' of the LSTM.\n        return short_memory\n\n    def configure_optimizers(self): # this configures the optimizer we want to use for backpropagation.\n        # return Adam(self.parameters(), lr=0.1) # NOTE: Setting the learning rate to 0.1 trains way faster than\n                                                 # using the default learning rate, lr=0.001, which requires a lot more\n                                                 # training. However, if we use the default value, we get\n                                                 # the exact same Weights and Biases that I used in\n                                                 # the LSTM Clearly Explained StatQuest video. So we'll use the\n                                                 # default value.\n        return Adam(self.parameters())\n\n\n    def training_step(self, batch, batch_idx): # take a step during gradient descent.\n        input_i, label_i = batch # collect input\n        output_i = self.forward(input_i[0]) # run input through the neural network\n        loss = (output_i - label_i)**2 ## loss = sum of squared residual\n        # Logging the loss and the predicted values so we can evaluate the training:\n        self.log(\"train_loss\", loss)\n        ## NOTE: Our dataset consists of two sequences of values representing Company A and Company B\n        ## For Company A, the goal is to predict that the value on Day 5 = 0, and for Company B,\n        ## the goal is to predict that the value on Day 5 = 1. We use label_i, the value we want to\n        ## predict, to keep track of which company we just made a prediction for and\n        ## log that output value in a company specific file\n        if (label_i == 0):\n            self.log(\"out_0\", output_i)\n        else:\n            self.log(\"out_1\", output_i)\n        return loss\n\nOnce we have created the class that defines an LSTM, we can use it to create a model and print out the randomly initialized Weights and Biases. Then, just for fun, we’ll see what those random Weights and Biases predict for Company A and Company B. If they are good predictions, then we’re done! However, the chances of getting good predictions from random values is very small.\n\n## Create the model object, print out parameters and see how well\n## the untrained LSTM can make predictions...\nmodel = LSTMbyHand() \n\nprint(\"Before optimization, the parameters are...\")\nfor name, param in model.named_parameters():\n    print(name, param.data)\n\nprint(\"\\nNow let's compare the observed and predicted values...\")\n## NOTE: To make predictions, we pass in the first 4 days worth of stock values \n## in an array for each company. In this case, the only difference between the\n## input values for Company A and B occurs on the first day. Company A has 0 and\n## Company B has 1.\nprint(\"Company A: Observed = 0, Predicted =\", \n      model(torch.tensor([0., 0.5, 0.25, 1.])).detach())\nprint(\"Company B: Observed = 1, Predicted =\", \n      model(torch.tensor([1., 0.5, 0.25, 1.])).detach())\n\nBefore optimization, the parameters are...\nwlr1 tensor(0.3367)\nwlr2 tensor(0.1288)\nblr1 tensor(0.)\nwpr1 tensor(0.2345)\nwpr2 tensor(0.2303)\nbpr1 tensor(0.)\nwp1 tensor(-1.1229)\nwp2 tensor(-0.1863)\nbp1 tensor(0.)\nwo1 tensor(2.2082)\nwo2 tensor(-0.6380)\nbo1 tensor(0.)\n\nNow let's compare the observed and predicted values...\nCompany A: Observed = 0, Predicted = tensor(-0.0377)\nCompany B: Observed = 1, Predicted = tensor(-0.0383)\n\n\nWith the unoptimized paramters, the predicted value for Company A, -0.0377, isn’t terrible, since it is relatively close to the observed value, 0. However, the predicted value for Company B, -0.0383, is terrible, because it is relatively far from the observed value, 1. So, that means we need to train the LSTM.\n\n28.4.1 Train the LSTM unit and use Lightning and TensorBoard to evaluate: Part 1 - Getting Started\nSince we are using Lightning training, training the LSTM we created by hand is pretty easy. All we have to do is create the training data and put it into a DataLoader…\n\n## create the training data for the neural network.\ninputs = torch.tensor([[0., 0.5, 0.25, 1.], [1., 0.5, 0.25, 1.]])\nlabels = torch.tensor([0., 1.])\n\ndataset = TensorDataset(inputs, labels)\ndataloader = DataLoader(dataset)\n\n# show the training data\nfor i, (input_i, label_i) in enumerate(dataloader):\n    print(\"Training data: \", input_i, label_i)\n\nTraining data:  tensor([[0.0000, 0.5000, 0.2500, 1.0000]]) tensor([0.])\nTraining data:  tensor([[1.0000, 0.5000, 0.2500, 1.0000]]) tensor([1.])\n\n\n…and then create a Lightning Trainer, L.Trainer, and fit it to the training data. NOTE: We are starting with 2000 epochs. This may be enough to successfully optimize all of the parameters, but it might not. We’ll find out after we compare the predictions to the observed values.\n\ntrainer = L.Trainer(max_epochs=2000) # with default learning rate, 0.001 (this tiny learning rate makes learning slow)\ntrainer.fit(model, train_dataloaders=dataloader)\n\n\n\n\nNow that we’ve trained the model with 2000 epochs, we can see how good the predictions are…\n\nprint(\"\\nNow let's compare the observed and predicted values...\")\nprint(\"Company A: Observed = 0, Predicted =\", model(torch.tensor([0., 0.5, 0.25, 1.])).detach())\nprint(\"Company B: Observed = 1, Predicted =\", model(torch.tensor([1., 0.5, 0.25, 1.])).detach())\n\n\nNow let's compare the observed and predicted values...\nCompany A: Observed = 0, Predicted = tensor(0.4342)\nCompany B: Observed = 1, Predicted = tensor(0.6171)\n\n\nUnfortunately, these predictions are terrible. So it seems like we’ll have to do more training. However, it would be awesome if we could be confident that more training will actually improve the predictions. If not, we can spare ourselves a lot of time, and potentially money, and just give up. So, before we dive into more training, let’s look at the loss values and predictions that we saved in log files with TensorBoard. TensorBoard will graph everything that we logged during training, making it super easy to see if things are headed in the right direction or not.\nTo get TensorBoard working:\n\nFirst, check to see if the TensorBoard plugin is installed. If it’s not, install it with the following command: pip install tensorboard\nNext, run the following command: tensorboard --logdir lightning_logs\n\nNOTE: If your graphs look messed up and you see a bunch of different lines, instead of just one red line per graph, then check where this notebook is saved for a directory called lightning_logs. Delete lightning_logs and the re-run everything in this notebook. One source of problems with the graphs is that every time we train a model, a new batch of log files is created and stored in lightning_logs and TensorBoard, by default, will plot all of them. You can turn off unwanted log files in TensorBoard, and we’ll do this later on in this notebook, but for now, the easiest thing to do is to start with a clean slate.\nAnyway, if we look at the loss (trainloss), we see that it is going down, which is good, but it still has further to go. When we look at the predictions for Company A (out0), we see that they started out pretty good, close to 0, but then got really bad early on in training, shooting all the way up to 0.5, but are starting to get smaller. In contrast, when we look at the predictions for Company B (out_1), we see that they started out really bad, close to 0, but have been getting better ever since and look like they could continue to get better if we kept training.\nIn summary, the graphs seem to suggest that if we continued training our model, the predictions would improve. So let’s add more epochs to the training.\n\n\n28.4.2 Optimizing (Training) the Weights and Biases in the LSTM that we made by hand: Part 2 - Adding More Epochs without Starting Over\nThe good news is that because we’re using Lightning, we can pick up where we left off training without having to start over from scratch. This is because when we train with Lightning, it creates checkpoint files that keep track of the Weights and Biases as they change. As a result, all we have to do to pick up where we left off is tell the Trainer where the checkpoint files are located. This is awesome and will save us a lot of time since we don’t have to retrain the first 2000 epochs. So let’s add an additional 1000 epochs to the training.\n\n## First, find where the most recent checkpoint files are stored\npath_to_checkpoint = trainer.checkpoint_callback.best_model_path ## By default, \"best\" = \"most recent\"\nprint(\"The new trainer will start where the last left off, and the check point data is here: \" + \n      path_to_checkpoint + \"\\n\")\n\n## Then create a new Lightning Trainer\ntrainer = L.Trainer(max_epochs=3000) # Before, max_epochs=2000, so, by setting it to 3000, we're adding 1000 more.\n## And then call fit() using the path to the most recent checkpoint files\n## so that we can pick up where we left off.\ntrainer.fit(model, train_dataloaders=dataloader, ckpt_path=path_to_checkpoint)\n\nThe new trainer will start where the last left off, and the check point data is here: /Users/bartz/workspace/Hyperparameter-Tuning-Cookbook/lightning_logs/version_1854/checkpoints/epoch=1999-step=4000.ckpt\n\n\n\n\n\n\nNow that we have added 1000 epochs to the training, let’s check the predictions…\n\nprint(\"\\nNow let's compare the observed and predicted values...\")\nprint(\"Company A: Observed = 0, Predicted =\", model(torch.tensor([0., 0.5, 0.25, 1.])).detach())\nprint(\"Company B: Observed = 1, Predicted =\", model(torch.tensor([1., 0.5, 0.25, 1.])).detach())\n\n\nNow let's compare the observed and predicted values...\nCompany A: Observed = 0, Predicted = tensor(0.2708)\nCompany B: Observed = 1, Predicted = tensor(0.7534)\n\n\nThe blue lines in each graph represents the values we logged during the extra 1000 epochs. The loss is getting smaller and the predictions for both companies are improving! Hooray!!! However, because it looks like there is even more room for improvement, let’s add 2000 more epochs to the training.\n\n## First, find where the most recent checkpoint files are stored\npath_to_checkpoint = trainer.checkpoint_callback.best_model_path ## By default, \"best\" = \"most recent\"\nprint(\"The new trainer will start where the last left off, and the check point data is here: \" + \n      path_to_checkpoint + \"\\n\")\n\n## Then create a new Lightning Trainer\ntrainer = L.Trainer(max_epochs=5000) # Before, max_epochs=3000, so, by setting it to 5000, we're adding 2000 more.\n## And then call fit() using the path to the most recent checkpoint files\n## so that we can pick up where we left off.\ntrainer.fit(model, train_dataloaders=dataloader, ckpt_path=path_to_checkpoint)\n\nThe new trainer will start where the last left off, and the check point data is here: /Users/bartz/workspace/Hyperparameter-Tuning-Cookbook/lightning_logs/version_1855/checkpoints/epoch=2999-step=6000.ckpt\n\n\n\n\n\n\nNow that we have added 2000 more epochs to the training (for a total of 5000 epochs), let’s check the predictions.\n\nprint(\"\\nNow let's compare the observed and predicted values...\")\nprint(\"Company A: Observed = 0, Predicted =\", model(torch.tensor([0., 0.5, 0.25, 1.])).detach())\nprint(\"Company B: Observed = 1, Predicted =\", model(torch.tensor([1., 0.5, 0.25, 1.])).detach())\n\n\nNow let's compare the observed and predicted values...\nCompany A: Observed = 0, Predicted = tensor(0.0022)\nCompany B: Observed = 1, Predicted = tensor(0.9693)\n\n\nThe prediction for Company A is super close to 0, which is exactly what we want, and the prediction for Company B is close to 1, which is also what we want.\nThe dark red lines show how things changed when we added an additional 2000 epochs to the training, for a total of 5000 epochs. Now we see that the loss (train_loss) and the predictions for each company appear to be tapering off, suggesting that adding more epochs may not improve the predictions much, so we’re done!\nLastly, let’s print out the final estimates for the Weights and Biases. In theory, they should be the same (within rounding error) as what we used in the StatQuest on Long Short-Term Memory and seen in the diagram of the LSTM unit at the top of this Jupyter notebook.\n\nprint(\"After optimization, the parameters are...\")\nfor name, param in model.named_parameters():\n    print(name, param.data)\n\nAfter optimization, the parameters are...\nwlr1 tensor(2.7043)\nwlr2 tensor(1.6307)\nblr1 tensor(1.6234)\nwpr1 tensor(1.9983)\nwpr2 tensor(1.6525)\nbpr1 tensor(0.6204)\nwp1 tensor(1.4122)\nwp2 tensor(0.9393)\nbp1 tensor(-0.3217)\nwo1 tensor(4.3848)\nwo2 tensor(-0.1943)\nbo1 tensor(0.5935)",
    "crumbs": [
      "Machine Learning and AI",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Machine Learning and Artificial Intelligence</span>"
    ]
  },
  {
    "objectID": "200_mlai.html#using-and-optimzing-the-pytorch-lstm-nn.lstm",
    "href": "200_mlai.html#using-and-optimzing-the-pytorch-lstm-nn.lstm",
    "title": "28  Machine Learning and Artificial Intelligence",
    "section": "28.5 Using and optimzing the PyTorch LSTM, nn.LSTM()",
    "text": "28.5 Using and optimzing the PyTorch LSTM, nn.LSTM()\nNow that we know how to create an LSTM unit by hand, train it, and then use it to make good predictions, let’s learn how to take advantage of PyTorch’s nn.LSTM() function. For the most part, using nn.LSTM() allows us to simplify the init() function and the forward() function. The other big difference is that this time, we’re not going to try and recreate the parameter values we used in the StatQuest on Long Short-Term Memory, and that means we can set the learning rate for the Adam to 0.1. This will speed up training a lot. Everything else stays the same.\n\n## Instead of coding an LSTM by hand, let's see what we can do with PyTorch's nn.LSTM()\nclass LightningLSTM(L.LightningModule):\n\n    def __init__(self): # __init__() is the class constructor function, and we use it to initialize the Weights and Biases.\n\n        super().__init__() # initialize an instance of the parent class, LightningModule.\n\n        L.seed_everything(seed=42)\n\n        ## input_size = number of features (or variables) in the data. In our example\n        ##              we only have a single feature (value)\n        ## hidden_size = this determines the dimension of the output\n        ##               in other words, if we set hidden_size=1, then we have 1 output node\n        ##               if we set hidden_size=50, then we hve 50 output nodes (that can then be 50 input\n        ##               nodes to a subsequent fully connected neural network.\n        self.lstm = nn.LSTM(input_size=1, hidden_size=1)\n\n\n    def forward(self, input):\n        ## transpose the input vector\n        input_trans = input.view(len(input), 1)\n\n        lstm_out, temp = self.lstm(input_trans)\n\n        ## lstm_out has the short-term memories for all inputs. We make our prediction with the last one\n        prediction = lstm_out[-1]\n        return prediction\n\n\n    def configure_optimizers(self): # this configures the optimizer we want to use for backpropagation.\n        return Adam(self.parameters(), lr=0.1) ## we'll just go ahead and set the learning rate to 0.1\n\n\n    def training_step(self, batch, batch_idx): # take a step during gradient descent.\n        input_i, label_i = batch # collect input\n        output_i = self.forward(input_i[0]) # run input through the neural network\n        loss = (output_i - label_i)**2 ## loss = squared residual\n        self.log(\"train_loss\", loss)\n\n        if (label_i == 0):\n            self.log(\"out_0\", output_i)\n        else:\n            self.log(\"out_1\", output_i)\n\n        return loss\n\nNow let’s create the model and print out the initial Weights and Biases and predictions.\n\nmodel = LightningLSTM() # First, make model from the class\n\n## print out the name and value for each parameter\nprint(\"Before optimization, the parameters are...\")\nfor name, param in model.named_parameters():\n    print(name, param.data)\n\nprint(\"\\nNow let's compare the observed and predicted values...\")\nprint(\"Company A: Observed = 0, Predicted =\", model(torch.tensor([0., 0.5, 0.25, 1.])).detach())\nprint(\"Company B: Observed = 1, Predicted =\", model(torch.tensor([1., 0.5, 0.25, 1.])).detach())\n\nBefore optimization, the parameters are...\nlstm.weight_ih_l0 tensor([[ 0.7645],\n        [ 0.8300],\n        [-0.2343],\n        [ 0.9186]])\nlstm.weight_hh_l0 tensor([[-0.2191],\n        [ 0.2018],\n        [-0.4869],\n        [ 0.5873]])\nlstm.bias_ih_l0 tensor([ 0.8815, -0.7336,  0.8692,  0.1872])\nlstm.bias_hh_l0 tensor([ 0.7388,  0.1354,  0.4822, -0.1412])\n\nNow let's compare the observed and predicted values...\nCompany A: Observed = 0, Predicted = tensor([0.6675])\nCompany B: Observed = 1, Predicted = tensor([0.6665])\n\n\nAs expected, the predictions are bad, so we will train the model. However, because we’ve increased the learning rate to 0.1, we only need to train for 300 epochs.\n\n## NOTE: Because we have set Adam's learning rate to 0.1, we will train much, much faster.\n## Before, with the hand made LSTM and the default learning rate, 0.001, it took about 5000 epochs to fully train\n## the model. Now, with the learning rate set to 0.1, we only need 300 epochs. Now, because we are doing so few epochs,\n## we have to tell the trainer add stuff to the log files every 2 steps (or epoch, since we have to rows of training data)\n## because the default, updating the log files every 50 steps, will result in a terrible looking graphs. So\ntrainer = L.Trainer(max_epochs=300, log_every_n_steps=2)\n\ntrainer.fit(model, train_dataloaders=dataloader)\n\nprint(\"After optimization, the parameters are...\")\nfor name, param in model.named_parameters():\n    print(name, param.data)\n\n\n\n\nAfter optimization, the parameters are...\nlstm.weight_ih_l0 tensor([[3.5364],\n        [1.3869],\n        [1.5390],\n        [1.2488]])\nlstm.weight_hh_l0 tensor([[5.2070],\n        [2.9577],\n        [3.2652],\n        [2.0678]])\nlstm.bias_ih_l0 tensor([-0.9143,  0.3724, -0.1815,  0.6376])\nlstm.bias_hh_l0 tensor([-1.0570,  1.2414, -0.5685,  0.3092])\n\n\nNow that training is done, let’s print out the new predictions…\n\nprint(\"\\nNow let's compare the observed and predicted values...\")\nprint(\"Company A: Observed = 0, Predicted =\", model(torch.tensor([0., 0.5, 0.25, 1.])).detach())\nprint(\"Company B: Observed = 1, Predicted =\", model(torch.tensor([1., 0.5, 0.25, 1.])).detach())\n\n\nNow let's compare the observed and predicted values...\nCompany A: Observed = 0, Predicted = tensor([6.8527e-05])\nCompany B: Observed = 1, Predicted = tensor([0.9809])\n\n\n…and, as we can see, after just 300 epochs, the LSTM is making great predictions. The prediction for Company A is close to the observed value 0 and the prediction for Company B is close to the observed value 1.\nLastly, let’s go back to TensorBoard to see the latest graphs. NOTE: To make it easier to see what we just did, deselect version0, version1 and version2 and make sure version3 is checked on the left-hand side of the page, under where it says Runs. This allows us to just look at the log files from the most recent training, which only went for 300 epochs.\nIn all three graphs, the loss (trainloss) and the predictions for Company A (out0) and Company B (out_1) started to taper off after 500 steps, or just 250 epochs, suggesting that adding more epochs may not improve the predictions much, so we’re done!",
    "crumbs": [
      "Machine Learning and AI",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Machine Learning and Artificial Intelligence</span>"
    ]
  },
  {
    "objectID": "300_hpt_intro.html",
    "href": "300_hpt_intro.html",
    "title": "29  Hyperparameter Tuning",
    "section": "",
    "text": "29.1 Structure of the Hyperparameter Tuning Chapters\nThe first part is structured as follows:\nThe concept of the hyperparameter tuning is described in Section 29.2.\nHyperparameter tuning with sklearn in Python is described in Chapter 30.\nHyperparameter tuning with river in Python is described in Chapter 33.\nThis part of the book is concluded with a description of the most recent PyTorch hyperparameter tuning approach, which is the integration of spotpython into the PyTorch Lightning training workflow. Hyperparameter tuning with PyTorch Lightning in Python is described in Chapter 41. This is considered as the most effective, efficient, and flexible way to integrate spotpython into the PyTorch training workflow.\nFigure 29.1 shows the graphical user interface of spotpython that is used in this book.",
    "crumbs": [
      "Introduction to Hyperparameter Tuning",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Hyperparameter Tuning</span>"
    ]
  },
  {
    "objectID": "300_hpt_intro.html#structure-of-the-hyperparameter-tuning-chapters",
    "href": "300_hpt_intro.html#structure-of-the-hyperparameter-tuning-chapters",
    "title": "29  Hyperparameter Tuning",
    "section": "",
    "text": "Figure 29.1: spot GUI",
    "crumbs": [
      "Introduction to Hyperparameter Tuning",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Hyperparameter Tuning</span>"
    ]
  },
  {
    "objectID": "300_hpt_intro.html#sec-hyperparameter-tuning-goals",
    "href": "300_hpt_intro.html#sec-hyperparameter-tuning-goals",
    "title": "29  Hyperparameter Tuning",
    "section": "29.2 Goals of Hyperparameter Tuning",
    "text": "29.2 Goals of Hyperparameter Tuning\nThe goal of hyperparameter tuning is to optimize the hyperparameters in a way that improves the performance of the machine learning or deep learning model. Hyperparameters are parameters that are not learned during the training process, but are set before the training process begins. Hyperparameter tuning is an important, but often difficult and computationally intensive task. Changing the architecture of a neural network or the learning rate of an optimizer can have a significant impact on the performance.\nHyperparameter tuning is referred to as “hyperparameter optimization” (HPO) in the literature. However, since we do not consider the optimization, but also the understanding of the hyperparameters, we use the term “hyperparameter tuning” in this book. See also the discussion in Chapter 2 of Bartz et al. (2022), which lays the groundwork and presents an introduction to the process of tuning Machine Learning and Deep Learning hyperparameters and the respective methodology. Since the key elements such as the hyperparameter tuning process and measures of tunability and performance are presented in Bartz et al. (2022), we refer to this chapter for details.\nThe simplest, but also most computationally expensive, hyperparameter tuning approach uses manual search (or trial-and-error (Meignan et al. 2015)). Commonly encountered is simple random search, i.e., random and repeated selection of hyperparameters for evaluation, and lattice search (“grid search”). In addition, methods that perform directed search and other model-free algorithms, i.e., algorithms that do not explicitly rely on a model, e.g., evolution strategies (Bartz-Beielstein et al. 2014) or pattern search (Lewis, Torczon, and Trosset 2000) play an important role. Also, “hyperband”, i.e., a multi-armed bandit strategy that dynamically allocates resources to a set of random configurations and uses successive bisections to stop configurations with poor performance (Li et al. 2016), is very common in hyperparameter tuning. The most sophisticated and efficient approaches are the Bayesian optimization and surrogate model based optimization methods, which are based on the optimization of cost functions determined by simulations or experiments.\nWe consider a surrogate optimization based hyperparameter tuning approach that uses the Python version of the SPOT (“Sequential Parameter Optimization Toolbox”) (Bartz-Beielstein, Lasarczyk, and Preuss 2005), which is suitable for situations where only limited resources are available. This may be due to limited availability and cost of hardware, or due to the fact that confidential data may only be processed locally, e.g., due to legal requirements. Furthermore, in our approach, the understanding of algorithms is seen as a key tool for enabling transparency and explainability. This can be enabled, for example, by quantifying the contribution of machine learning and deep learning components (nodes, layers, split decisions, activation functions, etc.). Understanding the importance of hyperparameters and the interactions between multiple hyperparameters plays a major role in the interpretability and explainability of machine learning models. SPOT provides statistical tools for understanding hyperparameters and their interactions. Last but not least, it should be noted that the SPOT software code is available in the open source spotpython package on github1, allowing replicability of the results. This tutorial describes the Python variant of SPOT, which is called spotpython. The R implementation is described in Bartz et al. (2022). SPOT is an established open source software that has been maintained for more than 15 years (Bartz-Beielstein, Lasarczyk, and Preuss 2005) (Bartz et al. 2022).\n\n\n\n\nBartz, Eva, Thomas Bartz-Beielstein, Martin Zaefferer, and Olaf Mersmann, eds. 2022. Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide. Springer.\n\n\nBartz-Beielstein, Thomas, Jürgen Branke, Jörn Mehnen, and Olaf Mersmann. 2014. “Evolutionary Algorithms.” Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery 4 (3): 178–95.\n\n\nBartz-Beielstein, Thomas, Christian Lasarczyk, and Mike Preuss. 2005. “Sequential Parameter Optimization.” In Proceedings 2005 Congress on Evolutionary Computation (CEC’05), Edinburgh, Scotland, edited by B McKay et al., 773–80. Piscataway NJ: IEEE Press.\n\n\nLewis, R M, V Torczon, and M W Trosset. 2000. “Direct search methods: Then and now.” Journal of Computational and Applied Mathematics 124 (1–2): 191–207.\n\n\nLi, Lisha, Kevin Jamieson, Giulia DeSalvo, Afshin Rostamizadeh, and Ameet Talwalkar. 2016. “Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization.” arXiv e-Prints, March, arXiv:1603.06560.\n\n\nMeignan, David, Sigrid Knust, Jean-Marc Frayet, Gilles Pesant, and Nicolas Gaud. 2015. “A Review and Taxonomy of Interactive Optimization Methods in Operations Research.” ACM Transactions on Interactive Intelligent Systems, September.",
    "crumbs": [
      "Introduction to Hyperparameter Tuning",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Hyperparameter Tuning</span>"
    ]
  },
  {
    "objectID": "300_hpt_intro.html#footnotes",
    "href": "300_hpt_intro.html#footnotes",
    "title": "29  Hyperparameter Tuning",
    "section": "",
    "text": "https://github.com/sequential-parameter-optimization↩︎",
    "crumbs": [
      "Introduction to Hyperparameter Tuning",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Hyperparameter Tuning</span>"
    ]
  },
  {
    "objectID": "400_spot_hpt_sklearn.html",
    "href": "400_spot_hpt_sklearn.html",
    "title": "30  HPT: sklearn",
    "section": "",
    "text": "30.1 Introduction to sklearn",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>HPT: sklearn</span>"
    ]
  },
  {
    "objectID": "401_spot_hpt_sklearn_classification.html",
    "href": "401_spot_hpt_sklearn_classification.html",
    "title": "31  HPT: sklearn SVC on Moons Data",
    "section": "",
    "text": "31.1 Step 1: Setup\nThis chapter is a tutorial for the Hyperparameter Tuning (HPT) of a sklearn SVC model on the Moons dataset.\nBefore we consider the detailed experimental setup, we select the parameters that affect run time, initial design size and the device that is used.\nMAX_TIME = 1\nINIT_SIZE = 10\nPREFIX = \"10\"",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>HPT: sklearn SVC on Moons Data</span>"
    ]
  },
  {
    "objectID": "401_spot_hpt_sklearn_classification.html#sec-setup-17",
    "href": "401_spot_hpt_sklearn_classification.html#sec-setup-17",
    "title": "31  HPT: sklearn SVC on Moons Data",
    "section": "",
    "text": "Caution: Run time and initial design size should be increased for real experiments\n\n\n\n\nMAX_TIME is set to one minute for demonstration purposes. For real experiments, this should be increased to at least 1 hour.\nINIT_SIZE is set to 5 for demonstration purposes. For real experiments, this should be increased to at least 10.",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>HPT: sklearn SVC on Moons Data</span>"
    ]
  },
  {
    "objectID": "401_spot_hpt_sklearn_classification.html#step-2-initialization-of-the-empty-fun_control-dictionary",
    "href": "401_spot_hpt_sklearn_classification.html#step-2-initialization-of-the-empty-fun_control-dictionary",
    "title": "31  HPT: sklearn SVC on Moons Data",
    "section": "31.2 Step 2: Initialization of the Empty fun_control Dictionary",
    "text": "31.2 Step 2: Initialization of the Empty fun_control Dictionary\nspotpython supports the visualization of the hyperparameter tuning process with TensorBoard. The following example shows how to use TensorBoard with spotpython. The fun_control dictionary is the central data structure that is used to control the optimization process. It is initialized as follows:\n\nfrom spotpython.utils.init import fun_control_init\nfrom spotpython.hyperparameters.values import set_control_key_value\nfrom spotpython.utils.eda import print_res_table\nfun_control = fun_control_init(\n    PREFIX=PREFIX,\n    TENSORBOARD_CLEAN=True,\n    max_time=MAX_TIME,\n    fun_evals=inf,\n    tolerance_x = np.sqrt(np.spacing(1)))\n\nMoving TENSORBOARD_PATH: runs/ to TENSORBOARD_PATH_OLD: runs_OLD/runs_2025_06_15_12_39_26_0\n\n\n\n\n\n\n\n\nTip: TensorBoard\n\n\n\n\nSince the spot_tensorboard_path argument is not None, which is the default, spotpython will log the optimization process in the TensorBoard folder.\nThe TENSORBOARD_CLEAN argument is set to True to archive the TensorBoard folder if it already exists. This is useful if you want to start a hyperparameter tuning process from scratch. If you want to continue a hyperparameter tuning process, set TENSORBOARD_CLEAN to False. Then the TensorBoard folder will not be archived and the old and new TensorBoard files will shown in the TensorBoard dashboard.",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>HPT: sklearn SVC on Moons Data</span>"
    ]
  },
  {
    "objectID": "401_spot_hpt_sklearn_classification.html#sec-data-loading-14",
    "href": "401_spot_hpt_sklearn_classification.html#sec-data-loading-14",
    "title": "31  HPT: sklearn SVC on Moons Data",
    "section": "31.3 Step 3: SKlearn Load Data (Classification)",
    "text": "31.3 Step 3: SKlearn Load Data (Classification)\nRandomly generate classification data.\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import make_moons, make_circles, make_classification\nn_features = 2\nn_samples = 500\ntarget_column = \"y\"\nds =  make_moons(n_samples, noise=0.5, random_state=0)\nX, y = ds\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=42\n)\ntrain = pd.DataFrame(np.hstack((X_train, y_train.reshape(-1, 1))))\ntest = pd.DataFrame(np.hstack((X_test, y_test.reshape(-1, 1))))\ntrain.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\ntest.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\ntrain.head()\n\n\n\n\n\n\n\n\nx1\nx2\ny\n\n\n\n\n0\n1.960101\n0.383172\n0.0\n\n\n1\n2.354420\n-0.536942\n1.0\n\n\n2\n1.682186\n-0.332108\n0.0\n\n\n3\n1.856507\n0.687220\n1.0\n\n\n4\n1.925524\n0.427413\n1.0\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\n\nx_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\ny_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\ncm = plt.cm.RdBu\ncm_bright = ListedColormap([\"#FF0000\", \"#0000FF\"])\nax = plt.subplot(1, 1, 1)\nax.set_title(\"Input data\")\n# Plot the training points\nax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors=\"k\")\n# Plot the testing points\nax.scatter(\n    X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6, edgecolors=\"k\"\n)\nax.set_xlim(x_min, x_max)\nax.set_ylim(y_min, y_max)\nax.set_xticks(())\nax.set_yticks(())\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nn_samples = len(train)\n# add the dataset to the fun_control\nfun_control.update({\"data\": None, # dataset,\n               \"train\": train,\n               \"test\": test,\n               \"n_samples\": n_samples,\n               \"target_column\": target_column})",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>HPT: sklearn SVC on Moons Data</span>"
    ]
  },
  {
    "objectID": "401_spot_hpt_sklearn_classification.html#sec-specification-of-preprocessing-model-401",
    "href": "401_spot_hpt_sklearn_classification.html#sec-specification-of-preprocessing-model-401",
    "title": "31  HPT: sklearn SVC on Moons Data",
    "section": "31.4 Step 4: Specification of the Preprocessing Model",
    "text": "31.4 Step 4: Specification of the Preprocessing Model\nData preprocesssing can be very simple, e.g., you can ignore it. Then you would choose the prep_model “None”:\n\nprep_model = None\nfun_control.update({\"prep_model\": prep_model})\n\nA default approach for numerical data is the StandardScaler (mean 0, variance 1). This can be selected as follows:\n\nfrom sklearn.preprocessing import StandardScaler\nprep_model = StandardScaler\nfun_control.update({\"prep_model\": prep_model})\n\nEven more complicated pre-processing steps are possible, e.g., the follwing pipeline:\ncategorical_columns = []\none_hot_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\nprep_model = ColumnTransformer(\n         transformers=[\n             (\"categorical\", one_hot_encoder, categorical_columns),\n         ],\n         remainder=StandardScaler,\n     )",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>HPT: sklearn SVC on Moons Data</span>"
    ]
  },
  {
    "objectID": "401_spot_hpt_sklearn_classification.html#step-5-select-model-algorithm-and-core_model_hyper_dict",
    "href": "401_spot_hpt_sklearn_classification.html#step-5-select-model-algorithm-and-core_model_hyper_dict",
    "title": "31  HPT: sklearn SVC on Moons Data",
    "section": "31.5 Step 5: Select Model (algorithm) and core_model_hyper_dict",
    "text": "31.5 Step 5: Select Model (algorithm) and core_model_hyper_dict\nThe selection of the algorithm (ML model) that should be tuned is done by specifying the its name from the sklearn implementation. For example, the SVC support vector machine classifier is selected as follows:\n\nfrom spotpython.hyperparameters.values import add_core_model_to_fun_control\nfrom spotpython.hyperdict.sklearn_hyper_dict import SklearnHyperDict\nfrom sklearn.svm import SVC\nadd_core_model_to_fun_control(core_model=SVC,\n                              fun_control=fun_control,\n                              hyper_dict=SklearnHyperDict,\n                              filename=None)\n\nNow fun_control has the information from the JSON file. The corresponding entries for the core_model class are shown below.\n\nfun_control['core_model_hyper_dict']\n\n{'C': {'type': 'float',\n  'default': 1.0,\n  'transform': 'None',\n  'lower': 0.1,\n  'upper': 10.0},\n 'kernel': {'levels': ['linear', 'poly', 'rbf', 'sigmoid'],\n  'type': 'factor',\n  'default': 'rbf',\n  'transform': 'None',\n  'core_model_parameter_type': 'str',\n  'lower': 0,\n  'upper': 3},\n 'degree': {'type': 'int',\n  'default': 3,\n  'transform': 'None',\n  'lower': 3,\n  'upper': 3},\n 'gamma': {'levels': ['scale', 'auto'],\n  'type': 'factor',\n  'default': 'scale',\n  'transform': 'None',\n  'core_model_parameter_type': 'str',\n  'lower': 0,\n  'upper': 1},\n 'coef0': {'type': 'float',\n  'default': 0.0,\n  'transform': 'None',\n  'lower': 0.0,\n  'upper': 0.0},\n 'shrinking': {'levels': [0, 1],\n  'type': 'factor',\n  'default': 0,\n  'transform': 'None',\n  'core_model_parameter_type': 'bool',\n  'lower': 0,\n  'upper': 1},\n 'probability': {'levels': [0, 1],\n  'type': 'factor',\n  'default': 0,\n  'transform': 'None',\n  'core_model_parameter_type': 'bool',\n  'lower': 0,\n  'upper': 1},\n 'tol': {'type': 'float',\n  'default': 0.001,\n  'transform': 'None',\n  'lower': 0.0001,\n  'upper': 0.01},\n 'cache_size': {'type': 'float',\n  'default': 200,\n  'transform': 'None',\n  'lower': 100,\n  'upper': 400},\n 'break_ties': {'levels': [0, 1],\n  'type': 'factor',\n  'default': 0,\n  'transform': 'None',\n  'core_model_parameter_type': 'bool',\n  'lower': 0,\n  'upper': 1}}\n\n\n\n\n\n\n\n\nsklearn Model Selection\n\n\n\nThe following sklearn models are supported by default:\n\nRidgeCV\nRandomForestClassifier\nSVC\nLogisticRegression\nKNeighborsClassifier\nGradientBoostingClassifier\nGradientBoostingRegressor\nElasticNet\n\nThey can be imported as follows:\n\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.linear_model import ElasticNet",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>HPT: sklearn SVC on Moons Data</span>"
    ]
  },
  {
    "objectID": "401_spot_hpt_sklearn_classification.html#step-6-modify-hyper_dict-hyperparameters-for-the-selected-algorithm-aka-core_model",
    "href": "401_spot_hpt_sklearn_classification.html#step-6-modify-hyper_dict-hyperparameters-for-the-selected-algorithm-aka-core_model",
    "title": "31  HPT: sklearn SVC on Moons Data",
    "section": "31.6 Step 6: Modify hyper_dict Hyperparameters for the Selected Algorithm aka core_model",
    "text": "31.6 Step 6: Modify hyper_dict Hyperparameters for the Selected Algorithm aka core_model\nspotpython provides functions for modifying the hyperparameters, their bounds and factors as well as for activating and de-activating hyperparameters without re-compilation of the Python source code. These functions were described in Section 11.15.1.\n\n31.6.1 Modify hyperparameter of type numeric and integer (boolean)\nNumeric and boolean values can be modified using the modify_hyper_parameter_bounds method.\n\n\n\n\n\n\nsklearn Model Hyperparameters\n\n\n\nThe hyperparameters of the sklearn SVC model are described in the sklearn documentation.\n\n\n\nFor example, to change the tol hyperparameter of the SVC model to the interval [1e-5, 1e-3], the following code can be used:\n\n\nfrom spotpython.hyperparameters.values import modify_hyper_parameter_bounds\nmodify_hyper_parameter_bounds(fun_control, \"tol\", bounds=[1e-5, 1e-3])\nmodify_hyper_parameter_bounds(fun_control, \"probability\", bounds=[0, 0])\nfun_control[\"core_model_hyper_dict\"][\"tol\"]\n\n{'type': 'float',\n 'default': 0.001,\n 'transform': 'None',\n 'lower': 1e-05,\n 'upper': 0.001}\n\n\n\n\n31.6.2 Modify hyperparameter of type factor\nFactors can be modified with the modify_hyper_parameter_levels function. For example, to exclude the sigmoid kernel from the tuning, the kernel hyperparameter of the SVC model can be modified as follows:\n\nfrom spotpython.hyperparameters.values import modify_hyper_parameter_levels\nmodify_hyper_parameter_levels(fun_control, \"kernel\", [\"poly\", \"rbf\"])\nfun_control[\"core_model_hyper_dict\"][\"kernel\"]\n\n{'levels': ['poly', 'rbf'],\n 'type': 'factor',\n 'default': 'rbf',\n 'transform': 'None',\n 'core_model_parameter_type': 'str',\n 'lower': 0,\n 'upper': 1}\n\n\n\n\n31.6.3 Optimizers\nOptimizers are described in Section 14.2.",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>HPT: sklearn SVC on Moons Data</span>"
    ]
  },
  {
    "objectID": "401_spot_hpt_sklearn_classification.html#step-7-selection-of-the-objective-loss-function",
    "href": "401_spot_hpt_sklearn_classification.html#step-7-selection-of-the-objective-loss-function",
    "title": "31  HPT: sklearn SVC on Moons Data",
    "section": "31.7 Step 7: Selection of the Objective (Loss) Function",
    "text": "31.7 Step 7: Selection of the Objective (Loss) Function\nThere are two metrics:\n\nmetric_river is used for the river based evaluation via eval_oml_iter_progressive.\nmetric_sklearn is used for the sklearn based evaluation.\n\n\nfrom sklearn.metrics import mean_absolute_error, accuracy_score, roc_curve, roc_auc_score, log_loss, mean_squared_error\nfun_control.update({\n               \"metric_sklearn\": log_loss,\n               \"weights\": 1.0,\n               })\n\n\n\n\n\n\n\nmetric_sklearn: Minimization and Maximization\n\n\n\n\nBecause the metric_sklearn is used for the sklearn based evaluation, it is important to know whether the metric should be minimized or maximized.\nThe weights parameter is used to indicate whether the metric should be minimized or maximized.\nIf weights is set to -1.0, the metric is maximized.\nIf weights is set to 1.0, the metric is minimized, e.g., weights = 1.0 for mean_absolute_error, or weights = -1.0 for roc_auc_score.\n\n\n\n\n31.7.1 Predict Classes or Class Probabilities\nIf the key \"predict_proba\" is set to True, the class probabilities are predicted. False is the default, i.e., the classes are predicted.\n\nfun_control.update({\n               \"predict_proba\": False,\n               })",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>HPT: sklearn SVC on Moons Data</span>"
    ]
  },
  {
    "objectID": "401_spot_hpt_sklearn_classification.html#step-8-calling-the-spot-function",
    "href": "401_spot_hpt_sklearn_classification.html#step-8-calling-the-spot-function",
    "title": "31  HPT: sklearn SVC on Moons Data",
    "section": "31.8 Step 8: Calling the SPOT Function",
    "text": "31.8 Step 8: Calling the SPOT Function\n\n31.8.1 The Objective Function\nThe objective function is selected next. It implements an interface from sklearn’s training, validation, and testing methods to spotpython.\n\nfrom spotpython.fun.hypersklearn import HyperSklearn\nfun = HyperSklearn().fun_sklearn\n\nThe following code snippet shows how to get the default hyperparameters as an array, so that they can be passed to the Spot function.\n\nfrom spotpython.hyperparameters.values import get_default_hyperparameters_as_array\nX_start = get_default_hyperparameters_as_array(fun_control)\n\n\n\n31.8.2 Run the Spot Optimizer\nThe class Spot [SOURCE] is the hyperparameter tuning workhorse. It is initialized with the following parameters:\n\nfun: the objective function\nfun_control: the dictionary with the control parameters for the objective function\ndesign: the experimental design\ndesign_control: the dictionary with the control parameters for the experimental design\nsurrogate: the surrogate model\nsurrogate_control: the dictionary with the control parameters for the surrogate model\noptimizer: the optimizer\noptimizer_control: the dictionary with the control parameters for the optimizer\n\n\n\n\n\n\n\nNote: Total run time\n\n\n\nThe total run time may exceed the specified max_time, because the initial design (here: init_size = INIT_SIZE as specified above) is always evaluated, even if this takes longer than max_time.\n\n\n\nfrom spotpython.utils.init import design_control_init, surrogate_control_init\ndesign_control = design_control_init()\nset_control_key_value(control_dict=design_control,\n                        key=\"init_size\",\n                        value=INIT_SIZE,\n                        replace=True)\n\nsurrogate_control = surrogate_control_init(method=\"regression\",\n                                           n_theta=2)\nfrom spotpython.spot import Spot\nspot_tuner = Spot(fun=fun,\n                   fun_control=fun_control,\n                   design_control=design_control,\n                   surrogate_control=surrogate_control)\nspot_tuner.run(X_start=X_start)\n\nspotpython tuning: 6.436366676628063 [----------] 1.78% \nspotpython tuning: 6.436366676628063 [----------] 2.92% \nspotpython tuning: 6.436366676628063 [----------] 4.01% \nspotpython tuning: 6.436366676628063 [#---------] 5.14% \nspotpython tuning: 6.436366676628063 [#---------] 6.34% \nspotpython tuning: 6.436366676628063 [#---------] 7.48% \nspotpython tuning: 6.436366676628063 [#---------] 8.68% \nspotpython tuning: 6.436366676628063 [#---------] 9.75% \nspotpython tuning: 6.436366676628063 [#---------] 10.89% \nspotpython tuning: 6.436366676628063 [#---------] 12.15% \nspotpython tuning: 6.436366676628063 [#---------] 13.39% \nspotpython tuning: 6.436366676628063 [#---------] 14.54% \nspotpython tuning: 6.436366676628063 [##--------] 15.71% \nspotpython tuning: 6.436366676628063 [##--------] 16.88% \nspotpython tuning: 6.436366676628063 [##--------] 18.15% \nspotpython tuning: 6.436366676628063 [##--------] 19.52% \nspotpython tuning: 6.436366676628063 [##--------] 20.86% \nspotpython tuning: 6.436366676628063 [##--------] 22.48% \nspotpython tuning: 6.436366676628063 [##--------] 24.01% \nspotpython tuning: 6.436366676628063 [###-------] 25.70% \nspotpython tuning: 6.436366676628063 [###-------] 27.36% \nspotpython tuning: 6.436366676628063 [###-------] 29.38% \nspotpython tuning: 6.436366676628063 [###-------] 31.18% \nspotpython tuning: 6.436366676628063 [###-------] 32.92% \nspotpython tuning: 6.436366676628063 [###-------] 34.72% \nspotpython tuning: 6.436366676628063 [####------] 36.30% \nspotpython tuning: 6.436366676628063 [####------] 37.93% \nspotpython tuning: 6.436366676628063 [####------] 39.64% \nspotpython tuning: 6.436366676628063 [####------] 41.68% \nspotpython tuning: 6.436366676628063 [####------] 43.46% \nspotpython tuning: 6.436366676628063 [#####-----] 45.04% \nspotpython tuning: 6.436366676628063 [#####-----] 46.66% \nspotpython tuning: 6.436366676628063 [#####-----] 48.51% \nspotpython tuning: 6.436366676628063 [#####-----] 50.19% \nspotpython tuning: 6.436366676628063 [#####-----] 51.90% \nspotpython tuning: 6.436366676628063 [#####-----] 53.74% \nspotpython tuning: 6.436366676628063 [######----] 55.56% \nspotpython tuning: 6.436366676628063 [######----] 57.39% \nspotpython tuning: 6.436366676628063 [######----] 59.26% \nspotpython tuning: 6.436366676628063 [######----] 60.96% \nspotpython tuning: 6.436366676628063 [######----] 62.54% \nspotpython tuning: 6.436366676628063 [######----] 63.98% \nspotpython tuning: 6.436366676628063 [#######---] 65.65% \nspotpython tuning: 6.436366676628063 [#######---] 67.28% \nspotpython tuning: 6.436366676628063 [#######---] 69.11% \nspotpython tuning: 6.436366676628063 [#######---] 70.88% \nspotpython tuning: 6.436366676628063 [#######---] 72.79% \nspotpython tuning: 6.436366676628063 [#######---] 74.40% \nspotpython tuning: 6.436366676628063 [########--] 75.95% \nspotpython tuning: 6.436366676628063 [########--] 77.44% \nspotpython tuning: 6.436366676628063 [########--] 79.14% \nspotpython tuning: 6.436366676628063 [########--] 80.85% \nspotpython tuning: 6.436366676628063 [########--] 82.68% \nspotpython tuning: 6.436366676628063 [########--] 84.42% \nspotpython tuning: 6.436366676628063 [#########-] 86.03% \nspotpython tuning: 6.436366676628063 [#########-] 87.86% \nspotpython tuning: 6.436366676628063 [#########-] 89.48% \nspotpython tuning: 6.436366676628063 [#########-] 91.43% \nspotpython tuning: 6.436366676628063 [#########-] 92.93% \nspotpython tuning: 6.436366676628063 [#########-] 94.45% \nspotpython tuning: 6.436366676628063 [##########] 96.34% \nspotpython tuning: 6.436366676628063 [##########] 98.07% \nspotpython tuning: 6.436366676628063 [##########] 100.00% Done...\n\nExperiment saved to 10_res.pkl\n\n\n&lt;spotpython.spot.spot.Spot at 0x12276bbf0&gt;\n\n\n\n\n31.8.3 TensorBoard\nNow we can start TensorBoard in the background with the following command, where ./runs is the default directory for the TensorBoard log files:\ntensorboard --logdir=\"./runs\"\n\n\n\n\n\n\nTip: TENSORBOARD_PATH\n\n\n\nThe TensorBoard path can be printed with the following command:\n\nfrom spotpython.utils.init import get_tensorboard_path\nget_tensorboard_path(fun_control)\n\n'runs/'\n\n\n\n\nWe can access the TensorBoard web server with the following URL:\nhttp://localhost:6006/\nThe TensorBoard plot illustrates how spotpython can be used as a microscope for the internal mechanisms of the surrogate-based optimization process. Here, one important parameter, the learning rate \\(\\theta\\) of the Kriging surrogate [SOURCE] is plotted against the number of optimization steps.\n\n\n\nTensorBoard visualization of the spotpython optimization process and the surrogate model.",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>HPT: sklearn SVC on Moons Data</span>"
    ]
  },
  {
    "objectID": "401_spot_hpt_sklearn_classification.html#sec-results-tuning-17",
    "href": "401_spot_hpt_sklearn_classification.html#sec-results-tuning-17",
    "title": "31  HPT: sklearn SVC on Moons Data",
    "section": "31.9 Step 9: Results",
    "text": "31.9 Step 9: Results\nAfter the hyperparameter tuning run is finished, the results can be saved and reloaded with the following commands:\n\nfrom spotpython.utils.file import save_pickle, load_pickle\nfrom spotpython.utils.init import get_experiment_name\nexperiment_name = get_experiment_name(PREFIX)\nSAVE_AND_LOAD = False\nif SAVE_AND_LOAD == True:\n    save_pickle(spot_tuner, experiment_name)\n    spot_tuner = load_pickle(experiment_name)\n\nAfter the hyperparameter tuning run is finished, the progress of the hyperparameter tuning can be visualized. The black points represent the performace values (score or metric) of hyperparameter configurations from the initial design, whereas the red points represents the hyperparameter configurations found by the surrogate model based optimization.\n\nspot_tuner.plot_progress(log_y=True, filename=\"./figures/\" + experiment_name+\"_progress.pdf\")\n\n\n\n\n\n\n\n\nResults can also be printed in tabular form.\n\nprint_res_table(spot_tuner)\n\n| name        | type   | default   |   lower |   upper | tuned                 | transform   |   importance | stars   |\n|-------------|--------|-----------|---------|---------|-----------------------|-------------|--------------|---------|\n| C           | float  | 1.0       |     0.1 |    10.0 | 1.3459476182876375    | None        |         0.01 |         |\n| kernel      | factor | rbf       |     0.0 |     1.0 | rbf                   | None        |       100.00 | ***     |\n| degree      | int    | 3         |     3.0 |     3.0 | 3.0                   | None        |         0.00 |         |\n| gamma       | factor | scale     |     0.0 |     1.0 | scale                 | None        |         0.01 |         |\n| coef0       | float  | 0.0       |     0.0 |     0.0 | 0.0                   | None        |         0.00 |         |\n| shrinking   | factor | 0         |     0.0 |     1.0 | 1                     | None        |         0.01 |         |\n| probability | factor | 0         |     0.0 |     0.0 | 0                     | None        |         0.00 |         |\n| tol         | float  | 0.001     |   1e-05 |   0.001 | 2.988661226661179e-05 | None        |         0.01 |         |\n| cache_size  | float  | 200.0     |   100.0 |   400.0 | 174.45504889441855    | None        |         0.01 |         |\n| break_ties  | factor | 0         |     0.0 |     1.0 | 0                     | None        |         0.01 |         |\n\n\nA histogram can be used to visualize the most important hyperparameters.\n\nspot_tuner.plot_importance(threshold=0.0025, filename=\"./figures/\" + experiment_name+\"_importance.pdf\")",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>HPT: sklearn SVC on Moons Data</span>"
    ]
  },
  {
    "objectID": "401_spot_hpt_sklearn_classification.html#get-default-hyperparameters",
    "href": "401_spot_hpt_sklearn_classification.html#get-default-hyperparameters",
    "title": "31  HPT: sklearn SVC on Moons Data",
    "section": "31.10 Get Default Hyperparameters",
    "text": "31.10 Get Default Hyperparameters\nThe default hyperparameters, whihc will be used for a comparion with the tuned hyperparameters, can be obtained with the following commands:\n\nfrom spotpython.hyperparameters.values import get_one_core_model_from_X\nfrom spotpython.hyperparameters.values import get_default_hyperparameters_as_array\nX_start = get_default_hyperparameters_as_array(fun_control)\nmodel_default = get_one_core_model_from_X(X_start, fun_control, default=True)\nmodel_default\n\nSVC(cache_size=200.0, shrinking=False)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  SVC?Documentation for SVCiNot fittedSVC(cache_size=200.0, shrinking=False)",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>HPT: sklearn SVC on Moons Data</span>"
    ]
  },
  {
    "objectID": "401_spot_hpt_sklearn_classification.html#get-spot-results",
    "href": "401_spot_hpt_sklearn_classification.html#get-spot-results",
    "title": "31  HPT: sklearn SVC on Moons Data",
    "section": "31.11 Get SPOT Results",
    "text": "31.11 Get SPOT Results\nIn a similar way, we can obtain the hyperparameters found by spotpython.\n\nfrom spotpython.hyperparameters.values import get_one_core_model_from_X\nX = spot_tuner.to_all_dim(spot_tuner.min_X.reshape(1,-1))\nmodel_spot = get_one_core_model_from_X(X, fun_control)\n\n\n31.11.1 Plot: Compare Predictions\n\nfrom spotpython.plot.validation import plot_roc\nplot_roc(model_list=[model_default, model_spot], fun_control= fun_control, model_names=[\"Default\", \"Spot\"])\n\n\n\n\n\n\n\n\n\nfrom spotpython.plot.validation import plot_confusion_matrix\nplot_confusion_matrix(model=model_default, fun_control=fun_control, title = \"Default\")\n\n\n\n\n\n\n\n\n\nplot_confusion_matrix(model=model_spot, fun_control=fun_control, title=\"SPOT\")\n\n\n\n\n\n\n\n\n\nmin(spot_tuner.y), max(spot_tuner.y)\n\n(np.float64(6.436366676628063), np.float64(10.813096016735146))\n\n\n\n\n31.11.2 Detailed Hyperparameter Plots\n\nspot_tuner.plot_important_hyperparameter_contour(filename=None)\n\nC:  0.006150109450042507\nkernel:  100.0\ngamma:  0.006150109450042507\nshrinking:  0.006150109450042507\ntol:  0.006150109450042507\ncache_size:  0.006150109450042507\nbreak_ties:  0.006150109450042507\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n31.11.3 Parallel Coordinates Plot\n\nspot_tuner.parallel_plot()\n\n                                                \n\n\n\n\n31.11.4 Plot all Combinations of Hyperparameters\n\nWarning: this may take a while.\n\n\nPLOT_ALL = False\nif PLOT_ALL:\n    n = spot_tuner.k\n    for i in range(n-1):\n        for j in range(i+1, n):\n            spot_tuner.plot_contour(i=i, j=j, min_z=min_z, max_z = max_z)",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>HPT: sklearn SVC on Moons Data</span>"
    ]
  },
  {
    "objectID": "401_spot_hpt_sklearn_regression.html",
    "href": "401_spot_hpt_sklearn_regression.html",
    "title": "32  HPT: sklearn SVR on Regression Data",
    "section": "",
    "text": "32.1 Step 1: Setup\nThis chapter is a tutorial for the Hyperparameter Tuning (HPT) of a sklearn SVR model on a regression dataset.\nBefore we consider the detailed experimental setup, we select the parameters that affect run time, initial design size and the device that is used.\nMAX_TIME = 1\nINIT_SIZE = 20\nPREFIX = \"18\"",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>HPT: sklearn SVR on Regression Data</span>"
    ]
  },
  {
    "objectID": "401_spot_hpt_sklearn_regression.html#sec-setup-svr",
    "href": "401_spot_hpt_sklearn_regression.html#sec-setup-svr",
    "title": "32  HPT: sklearn SVR on Regression Data",
    "section": "",
    "text": "Caution: Run time and initial design size should be increased for real experiments\n\n\n\n\nMAX_TIME is set to one minute for demonstration purposes. For real experiments, this should be increased to at least 1 hour.\nINIT_SIZE is set to 5 for demonstration purposes. For real experiments, this should be increased to at least 10.",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>HPT: sklearn SVR on Regression Data</span>"
    ]
  },
  {
    "objectID": "401_spot_hpt_sklearn_regression.html#step-2-initialization-of-the-empty-fun_control-dictionary",
    "href": "401_spot_hpt_sklearn_regression.html#step-2-initialization-of-the-empty-fun_control-dictionary",
    "title": "32  HPT: sklearn SVR on Regression Data",
    "section": "32.2 Step 2: Initialization of the Empty fun_control Dictionary",
    "text": "32.2 Step 2: Initialization of the Empty fun_control Dictionary\nspotpython supports the visualization of the hyperparameter tuning process with TensorBoard. The following example shows how to use TensorBoard with spotpython. The fun_control dictionary is the central data structure that is used to control the optimization process. It is initialized as follows:\n\nfrom spotpython.utils.init import fun_control_init\nfrom spotpython.hyperparameters.values import set_control_key_value\nfrom spotpython.utils.eda import print_res_table\nfun_control = fun_control_init(\n    PREFIX=PREFIX,\n    TENSORBOARD_CLEAN=True,\n    max_time=MAX_TIME,\n    fun_evals=inf,\n    tolerance_x = np.sqrt(np.spacing(1)))\n\nMoving TENSORBOARD_PATH: runs/ to TENSORBOARD_PATH_OLD: runs_OLD/runs_2025_06_15_12_42_09_0\n\n\n\n\n\n\n\n\nTip: TensorBoard\n\n\n\n\nSince the spot_tensorboard_path argument is not None, which is the default, spotpython will log the optimization process in the TensorBoard folder.\nThe TENSORBOARD_CLEAN argument is set to True to archive the TensorBoard folder if it already exists. This is useful if you want to start a hyperparameter tuning process from scratch. If you want to continue a hyperparameter tuning process, set TENSORBOARD_CLEAN to False. Then the TensorBoard folder will not be archived and the old and new TensorBoard files will shown in the TensorBoard dashboard.",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>HPT: sklearn SVR on Regression Data</span>"
    ]
  },
  {
    "objectID": "401_spot_hpt_sklearn_regression.html#sec-data-loading-17",
    "href": "401_spot_hpt_sklearn_regression.html#sec-data-loading-17",
    "title": "32  HPT: sklearn SVR on Regression Data",
    "section": "32.3 Step 3: SKlearn Load Data (Classification)",
    "text": "32.3 Step 3: SKlearn Load Data (Classification)\nRandomly generate classification data. Here, we use similar data as in Comparison of kernel ridge regression and SVR.\n\nimport numpy as np\n\nrng = np.random.RandomState(42)\n\nX = 5 * rng.rand(10, 1)\ny = np.sin(1/X).ravel()*np.cos(X).ravel()\n\n# Add noise to targets\ny[::5] += 3 * (0.5 - rng.rand(X.shape[0] // 5))\n\nX_plot = np.linspace(0, 5, 100000)[:, None]\n\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\nn_features = 1\ntarget_column = \"y\"\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=42\n)\ntrain = pd.DataFrame(np.hstack((X_train, y_train.reshape(-1, 1))))\ntest = pd.DataFrame(np.hstack((X_test, y_test.reshape(-1, 1))))\ntrain.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\ntest.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\ntrain.head()\n\n\n\n\n\n\n\n\nx1\ny\n\n\n\n\n0\n1.872701\n1.286910\n\n\n1\n4.330881\n-0.085207\n\n\n2\n3.659970\n-0.234389\n\n\n3\n3.540363\n-0.256848\n\n\n4\n0.780093\n0.681389\n\n\n\n\n\n\n\n\nn_samples = len(train)\n# add the dataset to the fun_control\nfun_control.update({\"data\": None, # dataset,\n               \"train\": train,\n               \"test\": test,\n               \"n_samples\": n_samples,\n               \"target_column\": target_column})",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>HPT: sklearn SVR on Regression Data</span>"
    ]
  },
  {
    "objectID": "401_spot_hpt_sklearn_regression.html#sec-specification-of-preprocessing-model-17",
    "href": "401_spot_hpt_sklearn_regression.html#sec-specification-of-preprocessing-model-17",
    "title": "32  HPT: sklearn SVR on Regression Data",
    "section": "32.4 Step 4: Specification of the Preprocessing Model",
    "text": "32.4 Step 4: Specification of the Preprocessing Model\nData preprocesssing can be very simple, e.g., you can ignore it. Then you would choose the prep_model “None”:\n\nprep_model = None\nfun_control.update({\"prep_model\": prep_model})\n\nA default approach for numerical data is the StandardScaler (mean 0, variance 1). This can be selected as follows:\n\nfrom sklearn.preprocessing import StandardScaler\nprep_model = StandardScaler\nfun_control.update({\"prep_model\": prep_model})\n\nEven more complicated pre-processing steps are possible, e.g., the follwing pipeline:\ncategorical_columns = []\none_hot_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\nprep_model = ColumnTransformer(\n         transformers=[\n             (\"categorical\", one_hot_encoder, categorical_columns),\n         ],\n         remainder=StandardScaler,\n     )",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>HPT: sklearn SVR on Regression Data</span>"
    ]
  },
  {
    "objectID": "401_spot_hpt_sklearn_regression.html#step-5-select-model-algorithm-and-core_model_hyper_dict",
    "href": "401_spot_hpt_sklearn_regression.html#step-5-select-model-algorithm-and-core_model_hyper_dict",
    "title": "32  HPT: sklearn SVR on Regression Data",
    "section": "32.5 Step 5: Select Model (algorithm) and core_model_hyper_dict",
    "text": "32.5 Step 5: Select Model (algorithm) and core_model_hyper_dict\nThe selection of the algorithm (ML model) that should be tuned is done by specifying the its name from the sklearn implementation. For example, the SVC support vector machine classifier is selected as follows:\n\nfrom spotpython.hyperparameters.values import add_core_model_to_fun_control\nfrom spotpython.hyperdict.sklearn_hyper_dict import SklearnHyperDict\nfrom sklearn.svm import SVR\nadd_core_model_to_fun_control(core_model=SVR,\n                              fun_control=fun_control,\n                              hyper_dict=SklearnHyperDict,\n                              filename=None)\n\nNow fun_control has the information from the JSON file. The corresponding entries for the core_model class are shown below.\n\nfun_control['core_model_hyper_dict']\n\n{'C': {'type': 'float',\n  'default': 1.0,\n  'transform': 'None',\n  'lower': 0.1,\n  'upper': 10.0},\n 'kernel': {'levels': ['linear', 'poly', 'rbf', 'sigmoid'],\n  'type': 'factor',\n  'default': 'rbf',\n  'transform': 'None',\n  'core_model_parameter_type': 'str',\n  'lower': 0,\n  'upper': 3},\n 'degree': {'type': 'int',\n  'default': 3,\n  'transform': 'None',\n  'lower': 3,\n  'upper': 3},\n 'gamma': {'levels': ['scale', 'auto'],\n  'type': 'factor',\n  'default': 'scale',\n  'transform': 'None',\n  'core_model_parameter_type': 'str',\n  'lower': 0,\n  'upper': 1},\n 'coef0': {'type': 'float',\n  'default': 0.0,\n  'transform': 'None',\n  'lower': 0.0,\n  'upper': 0.0},\n 'epsilon': {'type': 'float',\n  'default': 0.1,\n  'transform': 'None',\n  'lower': 0.01,\n  'upper': 1.0},\n 'shrinking': {'levels': [0, 1],\n  'type': 'factor',\n  'default': 0,\n  'transform': 'None',\n  'core_model_parameter_type': 'bool',\n  'lower': 0,\n  'upper': 1},\n 'tol': {'type': 'float',\n  'default': 0.001,\n  'transform': 'None',\n  'lower': 0.0001,\n  'upper': 0.01},\n 'cache_size': {'type': 'float',\n  'default': 200,\n  'transform': 'None',\n  'lower': 100,\n  'upper': 400}}\n\n\n\n\n\n\n\n\nsklearn Model Selection\n\n\n\nThe following sklearn models are supported by default:\n\nRidgeCV\nRandomForestClassifier\nSVC\nSVR\nLogisticRegression\nKNeighborsClassifier\nGradientBoostingClassifier\nGradientBoostingRegressor\nElasticNet\n\nThey can be imported as follows:\n\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.svm import SVR\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.linear_model import ElasticNet",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>HPT: sklearn SVR on Regression Data</span>"
    ]
  },
  {
    "objectID": "401_spot_hpt_sklearn_regression.html#step-6-modify-hyper_dict-hyperparameters-for-the-selected-algorithm-aka-core_model",
    "href": "401_spot_hpt_sklearn_regression.html#step-6-modify-hyper_dict-hyperparameters-for-the-selected-algorithm-aka-core_model",
    "title": "32  HPT: sklearn SVR on Regression Data",
    "section": "32.6 Step 6: Modify hyper_dict Hyperparameters for the Selected Algorithm aka core_model",
    "text": "32.6 Step 6: Modify hyper_dict Hyperparameters for the Selected Algorithm aka core_model\nspotpython provides functions for modifying the hyperparameters, their bounds and factors as well as for activating and de-activating hyperparameters without re-compilation of the Python source code. These functions were described in Section 11.15.1.\n\n32.6.1 Modify hyperparameter of type numeric and integer (boolean)\nNumeric and boolean values can be modified using the modify_hyper_parameter_bounds method.\n\n\n\n\n\n\nsklearn Model Hyperparameters\n\n\n\nThe hyperparameters of the sklearn SVC model are described in the sklearn documentation.\n\n\n\nFor example, to change the tol hyperparameter of the SVC model to the interval [1e-5, 1e-3], the following code can be used:\n\n\nfrom spotpython.hyperparameters.values import modify_hyper_parameter_bounds\nmodify_hyper_parameter_bounds(fun_control, \"tol\", bounds=[1e-5, 1e-3])\nmodify_hyper_parameter_bounds(fun_control, \"epsilon\", bounds=[0.1, 1.0])\n# modify_hyper_parameter_bounds(fun_control, \"degree\", bounds=[2, 5])\nfun_control[\"core_model_hyper_dict\"][\"tol\"]\n\n{'type': 'float',\n 'default': 0.001,\n 'transform': 'None',\n 'lower': 1e-05,\n 'upper': 0.001}\n\n\n\n\n32.6.2 Modify hyperparameter of type factor\nFactors can be modified with the modify_hyper_parameter_levels function. For example, to exclude the sigmoid kernel from the tuning, the kernel hyperparameter of the SVR model can be modified as follows:\n\nfrom spotpython.hyperparameters.values import modify_hyper_parameter_levels\n# modify_hyper_parameter_levels(fun_control, \"kernel\", [\"poly\", \"rbf\"])\nmodify_hyper_parameter_levels(fun_control, \"kernel\", [\"rbf\"])\nfun_control[\"core_model_hyper_dict\"][\"kernel\"]\n\n{'levels': ['rbf'],\n 'type': 'factor',\n 'default': 'rbf',\n 'transform': 'None',\n 'core_model_parameter_type': 'str',\n 'lower': 0,\n 'upper': 0}\n\n\n\n\n32.6.3 Optimizers\nOptimizers are described in Section 14.2.",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>HPT: sklearn SVR on Regression Data</span>"
    ]
  },
  {
    "objectID": "401_spot_hpt_sklearn_regression.html#step-7-selection-of-the-objective-loss-function",
    "href": "401_spot_hpt_sklearn_regression.html#step-7-selection-of-the-objective-loss-function",
    "title": "32  HPT: sklearn SVR on Regression Data",
    "section": "32.7 Step 7: Selection of the Objective (Loss) Function",
    "text": "32.7 Step 7: Selection of the Objective (Loss) Function\nThere are two metrics:\n\nmetric_river is used for the river based evaluation via eval_oml_iter_progressive.\nmetric_sklearn is used for the sklearn based evaluation.\n\n\nfrom sklearn.metrics import mean_absolute_error, accuracy_score, roc_curve, roc_auc_score, log_loss, mean_squared_error\nfun_control.update({\n               \"metric_sklearn\": mean_squared_error,\n               \"weights\": 1.0,\n               })\n\n\n\n\n\n\n\nmetric_sklearn: Minimization and Maximization\n\n\n\n\nBecause the metric_sklearn is used for the sklearn based evaluation, it is important to know whether the metric should be minimized or maximized.\nThe weights parameter is used to indicate whether the metric should be minimized or maximized.\nIf weights is set to -1.0, the metric is maximized.\nIf weights is set to 1.0, the metric is minimized, e.g., weights = 1.0 for mean_absolute_error, or weights = -1.0 for roc_auc_score.\n\n\n\n\n32.7.1 Predict Classes or Class Probabilities\nIf the key \"predict_proba\" is set to True, the class probabilities are predicted. False is the default, i.e., the classes are predicted.\n\nfun_control.update({\n               \"predict_proba\": False,\n               })",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>HPT: sklearn SVR on Regression Data</span>"
    ]
  },
  {
    "objectID": "401_spot_hpt_sklearn_regression.html#step-8-calling-the-spot-function",
    "href": "401_spot_hpt_sklearn_regression.html#step-8-calling-the-spot-function",
    "title": "32  HPT: sklearn SVR on Regression Data",
    "section": "32.8 Step 8: Calling the SPOT Function",
    "text": "32.8 Step 8: Calling the SPOT Function\n\n32.8.1 The Objective Function\nThe objective function is selected next. It implements an interface from sklearn’s training, validation, and testing methods to spotpython.\n\nfrom spotpython.fun.hypersklearn import HyperSklearn\nfun = HyperSklearn().fun_sklearn\n\nThe following code snippet shows how to get the default hyperparameters as an array, so that they can be passed to the Spot function.\n\nfrom spotpython.hyperparameters.values import get_default_hyperparameters_as_array\nX_start = get_default_hyperparameters_as_array(fun_control)\n\n\n\n32.8.2 Run the Spot Optimizer\nThe class Spot [SOURCE] is the hyperparameter tuning workhorse. It is initialized with the following parameters:\n\nfun: the objective function\nfun_control: the dictionary with the control parameters for the objective function\ndesign: the experimental design\ndesign_control: the dictionary with the control parameters for the experimental design\nsurrogate: the surrogate model\nsurrogate_control: the dictionary with the control parameters for the surrogate model\noptimizer: the optimizer\noptimizer_control: the dictionary with the control parameters for the optimizer\n\n\n\n\n\n\n\nNote: Total run time\n\n\n\nThe total run time may exceed the specified max_time, because the initial design (here: init_size = INIT_SIZE as specified above) is always evaluated, even if this takes longer than max_time.\n\n\n\nfrom spotpython.utils.init import design_control_init, surrogate_control_init\ndesign_control = design_control_init()\nset_control_key_value(control_dict=design_control,\n                        key=\"init_size\",\n                        value=INIT_SIZE,\n                        replace=True)\n\nsurrogate_control = surrogate_control_init(method=\"regression\",\n                                           n_theta=2)\nfrom spotpython.spot import Spot\nspot_tuner = Spot(fun=fun,\n                   fun_control=fun_control,\n                   design_control=design_control,\n                   surrogate_control=surrogate_control)\nspot_tuner.run(X_start=X_start)\n\nspotpython tuning: 0.11831336203046443 [----------] 0.76% \nspotpython tuning: 0.11831336203046443 [----------] 1.31% \nspotpython tuning: 0.11831336203046443 [----------] 2.27% \nspotpython tuning: 0.11312522934830822 [----------] 3.03% \nspotpython tuning: 0.11028295967958186 [----------] 3.77% \nspotpython tuning: 0.10549049842162794 [----------] 4.51% \nspotpython tuning: 0.10456925631246643 [#---------] 5.48% \nspotpython tuning: 0.10394150275124696 [#---------] 6.46% \nspotpython tuning: 0.10394150275124696 [#---------] 7.47% \nspotpython tuning: 0.10331600680037849 [#---------] 8.72% \nspotpython tuning: 0.1022579208739993 [#---------] 10.28% \nspotpython tuning: 0.09869979682515821 [#---------] 11.73% \nspotpython tuning: 0.08707238876821873 [#---------] 13.29% \nspotpython tuning: 0.08423427702103133 [#---------] 14.82% \nspotpython tuning: 0.08423427702103133 [##--------] 16.21% \nspotpython tuning: 0.08423427702103133 [##--------] 17.53% \nspotpython tuning: 0.08423427702103133 [##--------] 18.77% \nspotpython tuning: 0.08423427702103133 [##--------] 20.03% \nspotpython tuning: 0.08423427702103133 [##--------] 21.27% \nspotpython tuning: 0.08423427702103133 [##--------] 22.57% \nspotpython tuning: 0.08423427702103133 [##--------] 23.94% \nspotpython tuning: 0.08423427702103133 [###-------] 25.57% \nspotpython tuning: 0.08423427702103133 [###-------] 27.17% \nspotpython tuning: 0.08423427702103133 [###-------] 28.88% \nspotpython tuning: 0.08423427702103133 [###-------] 30.06% \nspotpython tuning: 0.08423427702103133 [###-------] 31.53% \nspotpython tuning: 0.08423427702103133 [###-------] 32.91% \nspotpython tuning: 0.08423427702103133 [###-------] 34.17% \nspotpython tuning: 0.08423427702103133 [####------] 35.47% \nspotpython tuning: 0.08423427702103133 [####------] 36.79% \nspotpython tuning: 0.08423427702103133 [####------] 38.12% \nspotpython tuning: 0.08423427702103133 [####------] 39.37% \nspotpython tuning: 0.08423427702103133 [####------] 40.63% \nspotpython tuning: 0.08423427702103133 [####------] 41.97% \nspotpython tuning: 0.08423427702103133 [####------] 43.30% \nspotpython tuning: 0.08423427702103133 [####------] 44.62% \nspotpython tuning: 0.08423427702103133 [#####-----] 45.87% \nspotpython tuning: 0.08423427702103133 [#####-----] 47.17% \nspotpython tuning: 0.08423427702103133 [#####-----] 48.49% \nspotpython tuning: 0.08423427702103133 [#####-----] 50.02% \nspotpython tuning: 0.08423427702103133 [#####-----] 51.50% \nspotpython tuning: 0.08423427702103133 [#####-----] 52.74% \nspotpython tuning: 0.08423427702103133 [#####-----] 53.98% \nspotpython tuning: 0.08423427702103133 [######----] 55.27% \nspotpython tuning: 0.08423427702103133 [######----] 56.71% \nspotpython tuning: 0.08423427702103133 [######----] 58.08% \nspotpython tuning: 0.08423427702103133 [######----] 59.41% \nspotpython tuning: 0.08423427702103133 [######----] 60.82% \nspotpython tuning: 0.08423427702103133 [######----] 62.13% \nspotpython tuning: 0.08423427702103133 [######----] 63.43% \nspotpython tuning: 0.08423427702103133 [######----] 64.84% \nspotpython tuning: 0.08423427702103133 [#######---] 66.31% \nspotpython tuning: 0.08423427702103133 [#######---] 67.66% \nspotpython tuning: 0.08423427702103133 [#######---] 69.08% \nspotpython tuning: 0.08423427702103133 [#######---] 70.43% \nspotpython tuning: 0.08423427702103133 [#######---] 71.67% \nspotpython tuning: 0.08423427702103133 [#######---] 72.93% \nspotpython tuning: 0.08423427702103133 [#######---] 74.25% \nspotpython tuning: 0.08423427702103133 [########--] 75.69% \nspotpython tuning: 0.08423427702103133 [########--] 77.00% \nspotpython tuning: 0.08423427702103133 [########--] 78.36% \nspotpython tuning: 0.08423427702103133 [########--] 79.78% \nspotpython tuning: 0.08423427702103133 [########--] 81.20% \nspotpython tuning: 0.08423427702103133 [########--] 82.76% \nspotpython tuning: 0.08423427702103133 [########--] 84.24% \nspotpython tuning: 0.08423427702103133 [#########-] 85.56% \nspotpython tuning: 0.08423427702103133 [#########-] 86.85% \nspotpython tuning: 0.08423427702103133 [#########-] 88.17% \nspotpython tuning: 0.08423427702103133 [#########-] 89.47% \nspotpython tuning: 0.08423427702103133 [#########-] 90.83% \nspotpython tuning: 0.08423427702103133 [#########-] 92.08% \nspotpython tuning: 0.08423427702103133 [#########-] 93.47% \nspotpython tuning: 0.08423427702103133 [#########-] 94.82% \nspotpython tuning: 0.08423427702103133 [##########] 96.14% \nspotpython tuning: 0.08423427702103133 [##########] 97.46% \nspotpython tuning: 0.08423427702103133 [##########] 98.90% \nspotpython tuning: 0.08423427702103133 [##########] 100.00% Done...\n\nExperiment saved to 18_res.pkl\n\n\n&lt;spotpython.spot.spot.Spot at 0x14df68fb0&gt;\n\n\n\n\n32.8.3 TensorBoard\nNow we can start TensorBoard in the background with the following command, where ./runs is the default directory for the TensorBoard log files:\ntensorboard --logdir=\"./runs\"\n\nfrom spotpython.utils.init import get_tensorboard_path\nget_tensorboard_path(fun_control)\n\n'runs/'\n\n\nAfter the hyperparameter tuning run is finished, the progress of the hyperparameter tuning can be visualized. The black points represent the performace values (score or metric) of hyperparameter configurations from the initial design, whereas the red points represents the hyperparameter configurations found by the surrogate model based optimization.\n\nspot_tuner.plot_progress(log_y=True)\n\n\n\n\n\n\n\n\nResults can also be printed in tabular form.\n\nprint_res_table(spot_tuner)\n\n| name       | type   | default   |   lower |   upper | tuned             | transform   |   importance | stars   |\n|------------|--------|-----------|---------|---------|-------------------|-------------|--------------|---------|\n| C          | float  | 1.0       |     0.1 |    10.0 | 4.441505058124631 | None        |         1.35 | *       |\n| kernel     | factor | rbf       |     0.0 |     0.0 | rbf               | None        |         0.00 |         |\n| degree     | int    | 3         |     3.0 |     3.0 | 3.0               | None        |         0.00 |         |\n| gamma      | factor | scale     |     0.0 |     1.0 | scale             | None        |       100.00 | ***     |\n| coef0      | float  | 0.0       |     0.0 |     0.0 | 0.0               | None        |         0.00 |         |\n| epsilon    | float  | 0.1       |     0.1 |     1.0 | 0.1               | None        |         0.01 |         |\n| shrinking  | factor | 0         |     0.0 |     1.0 | 1                 | None        |         0.01 |         |\n| tol        | float  | 0.001     |   1e-05 |   0.001 | 0.001             | None        |         0.01 |         |\n| cache_size | float  | 200.0     |   100.0 |   400.0 | 342.2075507599466 | None        |         0.01 |         |\n\n\nA histogram can be used to visualize the most important hyperparameters.\n\nspot_tuner.plot_importance(threshold=0.0025)",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>HPT: sklearn SVR on Regression Data</span>"
    ]
  },
  {
    "objectID": "401_spot_hpt_sklearn_regression.html#get-default-hyperparameters",
    "href": "401_spot_hpt_sklearn_regression.html#get-default-hyperparameters",
    "title": "32  HPT: sklearn SVR on Regression Data",
    "section": "32.9 Get Default Hyperparameters",
    "text": "32.9 Get Default Hyperparameters\nThe default hyperparameters, which will be used for a comparion with the tuned hyperparameters, can be obtained with the following commands:\n\nfrom spotpython.hyperparameters.values import get_one_core_model_from_X\nfrom spotpython.hyperparameters.values import get_default_hyperparameters_as_array\nX_start = get_default_hyperparameters_as_array(fun_control)\nmodel_default = get_one_core_model_from_X(X_start, fun_control, default=True)\nmodel_default\n\nSVR(cache_size=200.0, shrinking=False)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  SVR?Documentation for SVRiNot fittedSVR(cache_size=200.0, shrinking=False)",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>HPT: sklearn SVR on Regression Data</span>"
    ]
  },
  {
    "objectID": "401_spot_hpt_sklearn_regression.html#get-spot-results",
    "href": "401_spot_hpt_sklearn_regression.html#get-spot-results",
    "title": "32  HPT: sklearn SVR on Regression Data",
    "section": "32.10 Get SPOT Results",
    "text": "32.10 Get SPOT Results\nIn a similar way, we can obtain the hyperparameters found by spotpython.\n\nfrom spotpython.hyperparameters.values import get_one_core_model_from_X\nX_tuned = spot_tuner.to_all_dim(spot_tuner.min_X.reshape(1,-1))\nmodel_spot = get_one_core_model_from_X(X_tuned, fun_control)\n\n\n32.10.1 Plot: Compare Predictions\n\nmodel_default.fit(X_train, y_train)\ny_default = model_default.predict(X_plot)\n\n\nmodel_spot.fit(X_train, y_train)\ny_spot = model_spot.predict(X_plot)\n\n\nimport matplotlib.pyplot as plt\nplt.scatter(X[:100], y[:100], c=\"orange\", label=\"data\", zorder=1, edgecolors=(0, 0, 0))\nplt.plot(\n    X_plot,\n    y_default,\n    c=\"red\",\n    label=\"Default SVR\")\n\nplt.plot(\n    X_plot, y_spot, c=\"blue\", label=\"SPOT SVR\")\n\nplt.xlabel(\"data\")\nplt.ylabel(\"target\")\nplt.title(\"SVR\")\n_ = plt.legend()\n\n\n\n\n\n\n\n\n\n\n32.10.2 Detailed Hyperparameter Plots\n\nspot_tuner.plot_important_hyperparameter_contour(filename=None)\n\nC:  1.354886773490393\ngamma:  100.0\nepsilon:  0.0052745045126161615\nshrinking:  0.0052745045126161615\ntol:  0.007080907154019355\ncache_size:  0.0052745045126161615\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n32.10.3 Parallel Coordinates Plot\n\nspot_tuner.parallel_plot()",
    "crumbs": [
      "Hyperparameter Tuning with Sklearn",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>HPT: sklearn SVR on Regression Data</span>"
    ]
  },
  {
    "objectID": "500_spot_hpt_river.html",
    "href": "500_spot_hpt_river.html",
    "title": "33  HPT: River",
    "section": "",
    "text": "33.1 Introduction to River",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>HPT: River</span>"
    ]
  },
  {
    "objectID": "501_spot_river_gui.html",
    "href": "501_spot_river_gui.html",
    "title": "34  Simplifying Hyperparameter Tuning in Online Machine Learning—The spotRiverGUI",
    "section": "",
    "text": "34.1 Introduction\nBatch Machine Learning (BML) often encounters limitations when processing substantial volumes of streaming data (Keller-McNulty 2004; Gaber, Zaslavsky, and Krishnaswamy 2005; Aggarwal 2007). These limitations become particularly evident in terms of available memory, managing drift in data streams (Bifet and Gavaldà 2007, 2009; Gama et al. 2004; Bartz-Beielstein 2024c), and processing novel, unclassified data (Bifet 2010), (Dredze, Oates, and Piatko 2010). As a solution, Online Machine Learning (OML) serves as an effective alternative to BML, adeptly addressing these constraints. OML’s ability to sequentially process data proves especially beneficial for handling data streams (Bifet et al. 2010a; Masud et al. 2011; Gama, Sebastião, and Rodrigues 2013; Putatunda 2021; Bartz-Beielstein and Hans 2024).\nThe Online Machine Learning (OML) methods provided by software packages such as river (Montiel et al. 2021) or MOA (Bifet et al. 2010b) require the specification of many hyperparameters. To give an example, Hoeffding trees (Hoeglinger and Pears 2007), which are very popular in OML, offer a variety of “splitters” to generate subtrees. There are also several methods to limit the tree size, ensuring time and memory requirements remain manageable. Given the multitude of parameters, manually searching for the optimal hyperparameter setting can be a daunting and often futile task due to the complexity of possible combinations. This article elucidates how automatic hyperparameter optimization, or “tuning”, can be achieved. Beyond optimizing the OML process, Hyperparameter Tuning (HPT) executed with the Sequential Parameter Optimization Toolbox (SPOT) enhances the explainability and interpretability of OML procedures. This can result in a more efficient, resource-conserving algorithm, contributing to the concept of “Green AI”.\nThis article describes the spotRiverGUI, which is a graphical user interface for the spotriver package. The GUI allows the user to select the task, the data set, the preprocessing model, the metric, and the online machine learning model. The user can specify the experiment duration, the initial design, and the evaluation options. The GUI provides information about the data set and allows the user to save and load experiments. It also starts and stops a tensorboard process to observe the tuning online and provides an analysis of the hyperparameter tuning process. The spotRiverGUI releases the user from the burden of manually searching for the optimal hyperparameter setting. After providing the data, users can compare different OML algorithms from the powerful river package in a convenient way and tune the selected algorithm very efficiently.\nThis article is structured as follows:\nSection 34.2 describes how to install the software. It also explains how the spotRiverGUI can be started. Section 34.3 describes the binary classification task and the options available in the spotRiverGUI. Section 34.4 provides information about the planned regression task. Section 34.5 describes how the data can be visualized in the spotRiverGUI. Section 34.6 provides information about saving and loading experiments. Section 34.7 describes how to start an experiment and how the associated tensorboard process can be started and stopped. Section 34.8 provides information about the analysis of the results from the hyperparameter tuning process. Section 34.9 concludes the article and provides an outlook.",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Simplifying Hyperparameter Tuning in Online Machine Learning---The spotRiverGUI</span>"
    ]
  },
  {
    "objectID": "501_spot_river_gui.html#introduction",
    "href": "501_spot_river_gui.html#introduction",
    "title": "34  Simplifying Hyperparameter Tuning in Online Machine Learning—The spotRiverGUI",
    "section": "",
    "text": "Note\n\n\n\nNote: This document refers to spotRiverGUI version 0.0.26 which was released on Feb 18, 2024 on GitHub, see: https://github.com/sequential-parameter-optimization/spotGUI/tree/main. The GUI is under active development and new features will be added soon.",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Simplifying Hyperparameter Tuning in Online Machine Learning---The spotRiverGUI</span>"
    ]
  },
  {
    "objectID": "501_spot_river_gui.html#sec-starting-gui",
    "href": "501_spot_river_gui.html#sec-starting-gui",
    "title": "34  Simplifying Hyperparameter Tuning in Online Machine Learning—The spotRiverGUI",
    "section": "34.2 Installation and Starting",
    "text": "34.2 Installation and Starting\n\n34.2.1 Installation\nWe strongly recommend using a virtual environment for the installation of the river, spotriver, build and spotRiverGUI packages.\nMiniforge, which holds the minimal installers for Conda, is a good starting point. Please follow the instructions on https://github.com/conda-forge/miniforge. Using Conda, the following commands can be used to create a virtual environment (Python 3.11 is recommended):\n&gt;&gt; conda create -n myenv python=3.11\n&gt;&gt; conda activate myenv\nNow the river and spotriver packages can be installed:\n&gt;&gt; (myenv) pip install river spotriver build\nAlthough the spotGUI package is available on PyPI, we recommend an installation from the GitHub repository https://github.com/sequential-parameter-optimization/spotGUI, because the spotGUI package is under active development and new features will be added soon. The installation from the GitHub repository is done by executing the following command:\n&gt;&gt; (myenv) git clone git@github.com:sequential-parameter-optimization/spotGUI.git\nBuilding the spotGUI package is done by executing the following command:\n&gt;&gt; (myenv) cd spotGUI\n&gt;&gt; (myenv) python -m build\nNow the spotRiverGUI package can be installed:\n&gt;&gt; (myenv) pip install dist/spotGUI-0.0.26.tar.gz\n\n\n34.2.2 Starting the GUI\nThe GUI can be started by executing the spotRiverGUI.py file in the spotGUI/spotRiverGUI directory. Change to the spotRiverGUI directory and start the GUI:\n&gt;&gt; (myenv) cd spotGUI/spotRiverGUI\n&gt;&gt; (myenv) python spotRiverGUI.py\nThe GUI window will open, as shown in Figure 34.1.\n\n\n\n\n\n\nFigure 34.1: spotriver GUI\n\n\n\nAfter the GUI window has opened, the user can select the task. Currently, Binary Classification is available. Further tasks like Regression will be available soon.\nDepending on the task, the user can select the data set, the preprocessing model, the metric, and the online machine learning model.",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Simplifying Hyperparameter Tuning in Online Machine Learning---The spotRiverGUI</span>"
    ]
  },
  {
    "objectID": "501_spot_river_gui.html#sec-binary-classification",
    "href": "501_spot_river_gui.html#sec-binary-classification",
    "title": "34  Simplifying Hyperparameter Tuning in Online Machine Learning—The spotRiverGUI",
    "section": "34.3 Binary Classification",
    "text": "34.3 Binary Classification\n\n34.3.1 Binary Classification Options\nIf the Binary Classification task is selected, the user can select pre-specified data sets from the Data drop-down menu.\n\n34.3.1.1 River Data Sets\nThe following data sets from the river package are available (the descriptions are taken from the river package):\n\nBananas: An artificial dataset where instances belongs to several clusters with a banana shape.There are two attributes that correspond to the x and y axis, respectively. More: https://riverml.xyz/dev/api/datasets/Bananas/.\nCreditCard: Credit card frauds. The datasets contains transactions made by credit cards in September 2013 by European cardholders. Feature ‘Class’ is the response variable and it takes value 1 in case of fraud and 0 otherwise. More: https://riverml.xyz/dev/api/datasets/CreditCard/.\nElec2: Electricity prices in New South Wales. This is a binary classification task, where the goal is to predict if the price of electricity will go up or down. This data was collected from the Australian New South Wales Electricity Market. In this market, prices are not fixed and are affected by demand and supply of the market. They are set every five minutes. Electricity transfers to/from the neighboring state of Victoria were done to alleviate fluctuations. More: https://riverml.xyz/dev/api/datasets/Elec2/.\nHiggs: The data has been produced using Monte Carlo simulations. The first 21 features (columns 2-22) are kinematic properties measured by the particle detectors in the accelerator. The last seven features are functions of the first 21 features; these are high-level features derived by physicists to help discriminate between the two classes. More: https://riverml.xyz/dev/api/datasets/Higgs/.\nHTTP: HTTP dataset of the KDD 1999 cup. The goal is to predict whether or not an HTTP connection is anomalous or not. The dataset only contains 2,211 (0.4%) positive labels. More: https://riverml.xyz/dev/api/datasets/HTTP/.\nPhishing: Phishing websites. This dataset contains features from web pages that are classified as phishing or not.https://riverml.xyz/dev/api/datasets/Phishing/\n\n\n\n34.3.1.2 User Data Sets\nBesides the river data sets described in Section 34.3.1.1, the user can also select a user-defined data set. Currently, comma-separated values (CSV) files are supported. Further formats will be supported soon. The user-defined CSV data set must be a binary classification task with the target variable in the last column. The first row must contain the column names. If the file is copied to the subdirectory userData, the user can select the data set from the Data drop-down menu.\nAs an example, we have provided a CSV-version of the Phishing data set. The file is located in the userData subdirectory and is called PhishingData.csv. It contains the columns empty_server_form_handler, popup_window, https, request_from_other_domain, anchor_from_other_domain, is_popular, long_url, age_of_domain, ip_in_url, and is_phishing. The first few lines of the file are shown below (modified due to formatting reasons):\nempty_server_form_handler,...,is_phishing\n0.0,0.0,0.0,0.0,0.0,0.5,1.0,1,1,1\n1.0,0.0,0.5,0.5,0.0,0.5,0.0,1,0,1\n0.0,0.0,1.0,0.0,0.5,0.5,0.0,1,0,1\n0.0,0.0,1.0,0.0,0.0,1.0,0.5,0,0,1\nBased on the required format, we can see that is_phishing is the target column, because it is the last column of the data set.\n\n\n34.3.1.3 Stream Data Sets\nForthcoming versions of the GUI will support stream data sets, e.g, the Friedman-Drift generator (Ikonomovska 2012) or the SEA-Drift generator (Street and Kim 2001). The Friedman-Drift generator was also used in the hyperparameter tuning study in Bartz-Beielstein (2024b).\n\n\n34.3.1.4 Data Set Options\nCurrently, the user can select the following parameters for the data sets:\n\nn_total: The total number of instances. Since some data sets are quite large, the user can select a subset of the data set by specifying the n_total value.\ntest_size: The size of the test set in percent (0.0 - 1.0). The training set will be 1.0 - test_size.\n\nThe target column should be the last column of the data set. Future versions of the GUI will support the selection of the target_column from the GUI. Currently, the value from the field target_column has not effect.\nTo compare different data scaling methods, the user can select the preprocessing model from the Preprocessing drop-down menu. Currently, the following preprocessing models are available:\n\nStandardScaler: Standardize features by removing the mean and scaling to unit variance.\nMinMaxScaler: Scale features to a range.\nNone: No scaling is performed.\n\nThe spotRiverGUI will not provide sophisticated data preprocessing methods. We assume that the data was preprocessed before it is copied into the userData subdirectory.\n\n\n\n34.3.2 Experiment Options\nCurrently, the user can select the following options for specifying the experiment duration:\n\nMAX_TIME: The maximum time in minutes for the experiment.\nFUN_EVALS: The number of function evaluations for the experiment. This is the number of OML-models that are built and evaluated.\n\nIf the MAX_TIME is reached or FUN_EVALS OML models are evaluated, the experiment will be stopped.\n\n\n\n\n\n\nInitial design is always evaluated\n\n\n\n\nThe initial design will always be evaluated before one of the stopping criteria is reached.\nIf the initial design is very large or the model evaluations are very time-consuming, the runtime will be larger than the MAX_TIME value.\n\n\n\nBased on the INIT_SIZE, the number of hyperparameter configurations for the initial design can be specified. The initial design is evaluated before the first surrogate model is built. A detailed description of the initial design and the surrogate model based hyperparameter tuning can be found in Bartz-Beielstein (2024a) and in Bartz-Beielstein and Zaefferer (2022). The spotpython package is used for the hyperparameter tuning process. It implements a robust surrogate model based optimization method (Forrester, Sóbester, and Keane 2008).\nThe PREFIX parameter can be used to specify the experiment name.\nThe spotpython hyperparameter tuning program allows the user to specify several options for the hyperparameter tuning process. The spotRiverGUI will support more options in future versions. Currently, the user can specify whether the outcome from the experiment is noisy or deterministic. The corresponding parameter is called NOISE. The reader is referred to Bartz-Beielstein (2024b) and to the chapter “Handling Noise” (https://sequential-parameter-optimization.github.io/Hyperparameter-Tuning-Cookbook/013_num_spot_noisy.html) for further information about the NOISE parameter.\n\n\n34.3.3 Evaluation Options\nThe user can select one of the following evaluation metrics for binary classification tasks from the metric drop-down menu:\n\naccuracy_score\ncohen_kappa_score\nf1_score\nhamming_loss\nhinge_loss\njaccard_score\nmatthews_corrcoef\nprecision_score\nrecall_score\nroc_auc_score\nzero_one_loss\n\nThese metrics are based on the scikit-learn module (Pedregosa et al. 2011), which implements several loss, score, and utility functions to measure classification performance, see https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics. spotRiverGUI supports metrics that are computed from the y_pred and the y_true values. The y_pred values are the predicted target values, and the y_true values are the true target values. The y_pred values are generated by the online machine learning model, and the y_true values are the true target values from the data set.\n\n\n\n\n\n\nEvaluation Metrics: Minimization and Maximization\n\n\n\n\nSome metrics are minimized, and some are maximized. The spotRiverGUI will support the user in selecting the correct metric based on the task. For example, the accuracy_score is maximized, and the hamming_loss is minimized. The user can select the metric and spotRiverGUI will automatically determine whether the metric is minimized or maximized.\n\n\n\nIn addition to the evaluation metric results, spotriver considers the time and memory consumption of the online machine learning model. The spotRiverGUI will support the user in selecting the time and memory consumption as additional evaluation metrics. By modifying the weight vector, which is shown in the weights: y, time, mem field, the user can specify the importance of the evaluation metrics. For example, the weight vector 1,0,0 specifies that only the y metric (e.g., accuracy) is considered. The weight vector 0,1,0 specifies that only the time metric is considered. The weight vector 0,0,1 specifies that only the memory metric is considered. The weight vector 1,1,1 specifies that all metrics are considered. Any real values (also negative ones) are allowed for the weights.\n\n\n\n\n\n\nThe weight vector\n\n\n\n\nThe specification of adequate weights is highly problem dependent.\nThere is no generic setting that fits to all problems.\n\n\n\nAs described in Bartz-Beielstein (2024a), a prediction horizon is used for the comparison of the online-machine learning algorithms. The horizon can be specified in the spotRiverGUI by the user and is highly problem dependent. The spotRiverGUI uses the eval_oml_horizon method from the spotriver package, which evaluates the online-machine learning model on a rolling horizon basis.\nIn addition to the horizon value, the user can specify the oml_grace_period value. During the oml_grace_period, the OML-model is trained on the (small) training data set. No predictions are made during this initial training phase, but the memory and computation time are measured. Then, the OML-model is evaluated on the test data set using a given (sklearn) evaluation metric. The default value of the oml_grace_period is horizon. For convenience, the value horizon is also selected when the user specifies the oml_grace_period value as None.\n\n\n\n\n\n\nThe oml_grace_period\n\n\n\n\nIf the oml_grace_period is set to the size of the training data set, the OML-model is trained on the entire training data set and then evaluated on the test data set using a given (sklearn) evaluation metric.\nThis setting might be “unfair” in some cases, because the OML-model should learn online and not on the entire training data set.\nTherefore, a small data set is recommended for the oml_grace_period setting and the prediction horizon is a recommended value for the oml_grace_period setting. The reader is referred to Bartz-Beielstein (2024a) for further information about the oml_grace_period setting.\n\n\n\n\n\n34.3.4 Online Machine Learning Model Options\nThe user can select one of the following online machine learning models from the coremodel drop-down menu:\n\nforest.AMFClassifier: Aggregated Mondrian Forest classifier for online learning (Mourtada, Gaiffas, and Scornet 2019). This implementation is truly online, in the sense that a single pass is performed, and that predictions can be produced anytime. More: https://riverml.xyz/dev/api/forest/AMFClassifier/.\ntree.ExtremelyFastDecisionTreeClassifier: Extremely Fast Decision Tree (EFDT) classifier (Manapragada, Webb, and Salehi 2018). Also referred to as the Hoeffding AnyTime Tree (HATT) classifier. In practice, despite the name, EFDTs are typically slower than a vanilla Hoeffding Tree to process data. More: https://riverml.xyz/dev/api/tree/ExtremelyFastDecisionTreeClassifier/.\ntree.HoeffdingTreeClassifier: Hoeffding Tree or Very Fast Decision Tree classifier (Bifet et al. 2010a; Domingos and Hulten 2000). More: https://riverml.xyz/dev/api/tree/HoeffdingTreeClassifier/.\ntree.HoeffdingAdaptiveTreeClassifier: Hoeffding Adaptive Tree classifier (Bifet and Gavaldà 2009). More: https://riverml.xyz/dev/api/tree/HoeffdingAdaptiveTreeClassifier/.\nlinear_model.LogisticRegression: Logistic regression classifier. More: hhttps://riverml.xyz/dev/api/linear-model/LogisticRegression/.\n\nThe spotRiverGUI automatically determines the hyperparameters for the selected online machine learning model and adapts the input fields to the model hyperparameters. The user can modify the hyperparameters in the GUI. Figure 34.2 shows the spotRiverGUI when the forest.AMFClassifier is selected and Figure 34.3 shows the spotRiverGUI when the tree.HoeffdingTreeClassifier is selected.\n\n\n\n\n\n\nFigure 34.2: spotRiverGUI when forest.AMFClassifier is selected\n\n\n\n\n\n\n\n\n\nFigure 34.3: spotRiverGUI when tree.HoeffdingAdaptiveTreeClassifier is selected\n\n\n\nNumerical and categorical hyperparameters are treated differently in the spotRiverGUI:\n\nThe user can modify the lower and upper bounds for the numerical hyperparameters.\nThere are no upper or lower bounds for categorical hyperparameters. Instead, hyperparameter values for the categorical hyperparameters are considered as sets of values, e.g., the set of ExhaustiveSplitter, HistogramSplitter, GaussianSplitter is provided for the splitter hyperparameter of the tree.HoeffdingAdaptiveTreeClassifier model as can be seen in Figure 34.3. The user can select the full set or any subset of the set of values for the categorical hyperparameters.\n\nIn addition to the lower and upper bounds (or the set of values for the categorical hyperparameters), the spotRiverGUI provides information about the Default values and the Transformation function. If the Transformation function is set to None, the values of the hyperparameters are passed to the spot tuner as they are. If the Transformation function is set to transform_power_2_int, the value \\(x\\) is transformed to \\(2^x\\) before it is passed to the spot tuner.\nModifications of the Default values and Transformation functions values in the spotRiverGUI have no effect on the hyperparameter tuning process. This is intensional. In future versions, the user will be able to add their own hyperparameter dictionaries to the spotRiverGUI, which allows the modification of Default values and Transformation functions values. Furthermore, the spotRiverGUI will support more online machine learning models in future versions.",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Simplifying Hyperparameter Tuning in Online Machine Learning---The spotRiverGUI</span>"
    ]
  },
  {
    "objectID": "501_spot_river_gui.html#sec-regression",
    "href": "501_spot_river_gui.html#sec-regression",
    "title": "34  Simplifying Hyperparameter Tuning in Online Machine Learning—The spotRiverGUI",
    "section": "34.4 Regression",
    "text": "34.4 Regression\nRegression tasks will be supported soon. The same workflow as for the binary classification task will be used, i.e., the user can select the data set, the preprocessing model, the metric, and the online machine learning model.",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Simplifying Hyperparameter Tuning in Online Machine Learning---The spotRiverGUI</span>"
    ]
  },
  {
    "objectID": "501_spot_river_gui.html#sec-showing-data",
    "href": "501_spot_river_gui.html#sec-showing-data",
    "title": "34  Simplifying Hyperparameter Tuning in Online Machine Learning—The spotRiverGUI",
    "section": "34.5 Showing the Data",
    "text": "34.5 Showing the Data\nThe spotRiverGUI provides the Show Data button, which opens a new window and shows information about the data set. The first figure (Figure 34.4) shows histograms of the target variables in the train and test data sets. The second figure (Figure 34.5) shows scatter plots of the features in the train data set. The third figure (Figure 34.6) shows the corresponding scatter plots of the features in the test data set.\n\n\n\n\n\n\nFigure 34.4: Output from the spotRiverGUI when Bananas data is selected for the Show Data option\n\n\n\n\n\n\n\n\n\nFigure 34.5: Visualization of the train data. Output from the spotRiverGUI when Bananas data is selected for the Show Data option\n\n\n\n\n\n\n\n\n\nFigure 34.6: Visualization of the test data. Output from the spotRiverGUI when Bananas data is selected for the Show Data option\n\n\n\n\n\n\n\n\n\nSize of the Displayed Data Sets\n\n\n\n\nSome data sets are quite large and the display of the data sets might take some time.\nTherefore, a random subset of 1000 instances of the data set is displayed if the data set is larger than 1000 instances.\n\n\n\nShowing the data is important, especially for the new / unknown data sets as can be seen in Figure 34.7, Figure 34.8, and Figure 34.9: The target variable is highly biased. The user can check whether the data set is correctly formatted and whether the target variable is correctly specified.\n\n\n\n\n\n\nFigure 34.7: Output from the spotRiverGUI when HTTP data is selected for the Show Data option. The target variable is biased.\n\n\n\n\n\n\n\n\n\nFigure 34.8: Output from the spotRiverGUI when HTTP data is selected for the Show Data option. A subset of 1000 randomly chosen data points is shown. Only a few positive events are in the data.\n\n\n\n\n\n\n\n\n\nFigure 34.9: Output from the spotRiverGUI when HTTP data is selected for the Show Data option. The test data set shows the same structure as the train data set.\n\n\n\nIn addition to the histograms and scatter plots, the spotRiverGUI provides textual information about the data set in the console window. e.g., for the Bananas data set, the following information is shown:\nTrain data summary:\n                 x1           x2            y\ncount  3710.000000  3710.000000  3710.000000\nmean     -0.016243     0.002430     0.451482\nstd       0.995490     1.001150     0.497708\nmin      -3.089839    -2.385937     0.000000\n25%      -0.764512    -0.914144     0.000000\n50%      -0.027259    -0.033754     0.000000\n75%       0.745066     0.836618     1.000000\nmax       2.754447     2.517112     1.000000\n\nTest data summary:\n                 x1           x2            y\ncount  1590.000000  1590.000000  1590.000000\nmean      0.037900    -0.005670     0.440881\nstd       1.009744     0.997603     0.496649\nmin      -2.980834    -2.199138     0.000000\n25%      -0.718710    -0.911151     0.000000\n50%       0.034858    -0.046502     0.000000\n75%       0.862049     0.806506     1.000000\nmax       2.813360     3.194302     1.000000",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Simplifying Hyperparameter Tuning in Online Machine Learning---The spotRiverGUI</span>"
    ]
  },
  {
    "objectID": "501_spot_river_gui.html#sec-saving-loading",
    "href": "501_spot_river_gui.html#sec-saving-loading",
    "title": "34  Simplifying Hyperparameter Tuning in Online Machine Learning—The spotRiverGUI",
    "section": "34.6 Saving and Loading",
    "text": "34.6 Saving and Loading\n\n34.6.1 Saving the Experiment\nIf the experiment should not be started immediately, the user can save the experiment by clicking on the Save Experiment button. The spotRiverGUI will save the experiment as a pickle file. The file name is generated based on the PREFIX parameter. The pickle file contains a set of dictionaries, which are used to start the experiment.\nspotRiverGUI shows a summary of the selected hyperparameters in the console window as can be seen in Table 34.1.\n\n\n\nTable 34.1: The hyperparameter values for the tree.HoeffdingAdaptiveTreeClassifier model.\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\ntype\ndefault\nlower\nupper\ntransform\n\n\n\n\ngrace_period\nint\n200\n10\n1000\nNone\n\n\nmax_depth\nint\n20\n2\n20\ntransform_power_2_int\n\n\ndelta\nfloat\n1e-07\n1e-08\n1e-06\nNone\n\n\ntau\nfloat\n0.05\n0.01\n0.1\nNone\n\n\nleaf_prediction\nfactor\nnba\n0\n2\nNone\n\n\nnb_threshold\nint\n0\n0\n10\nNone\n\n\nsplitter\nfactor\nGaussianSplitter\n0\n2\nNone\n\n\nbootstrap_sampling\nfactor\n0\n0\n1\nNone\n\n\ndrift_window_threshold\nint\n300\n100\n500\nNone\n\n\ndrift_detector\nfactor\nADWIN\n0\n0\nNone\n\n\nswitch_significance\nfloat\n0.05\n0.01\n0.1\nNone\n\n\nbinary_split\nfactor\n0\n0\n1\nNone\n\n\nmax_size\nfloat\n100.0\n100\n1000\nNone\n\n\nmemory_estimate_period\nint\n1000000\n100000\n1e+06\nNone\n\n\nstop_mem_management\nfactor\n0\n0\n1\nNone\n\n\nremove_poor_attrs\nfactor\n0\n0\n1\nNone\n\n\nmerit_preprune\nfactor\n0\n0\n1\nNone\n\n\n\n\n\n\n\n\n34.6.2 Loading an Experiment\nFuture versions of the spotRiverGUI will support the loading of experiments from the GUI. Currently, the user can load the experiment by executing the command load_experiment, see https://sequential-parameter-optimization.github.io/spotpython/reference/spotpython/utils/file/#spotpython.utils.file.load_experiment.",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Simplifying Hyperparameter Tuning in Online Machine Learning---The spotRiverGUI</span>"
    ]
  },
  {
    "objectID": "501_spot_river_gui.html#sec-running-experiment",
    "href": "501_spot_river_gui.html#sec-running-experiment",
    "title": "34  Simplifying Hyperparameter Tuning in Online Machine Learning—The spotRiverGUI",
    "section": "34.7 Running a New Experiment",
    "text": "34.7 Running a New Experiment\nAn experiment can be started by clicking on the Run Experiment button. The GUI calls run_spot_python_experiment from spotGUI.tuner.spotRun. Output will be shown in the console window from which the GUI was started.\n\n34.7.1 Starting and Stopping Tensorboard\nTensorboard (Abadi et al. 2016) is automatically started when an experiment is started. The tensorboard process can be observed in a browser by opening the http://localhost:6006 page. Tensorboard provides a visual representation of the hyperparameter tuning process. Figure 34.10 and Figure 34.11 show the tensorboard page when the spotRiverGUI is performing the tuning process.\n\n\n\n\n\n\nFigure 34.10: Tensorboard visualization of the hyperparameter tuning process\n\n\n\n\n\n\n\n\n\nFigure 34.11: Tensorboard. Parallel coordinates plot\n\n\n\nspotpython.utils.tensorboard provides the methods start_tensorboard and stop_tensorboard to start and stop tensorboard as a background process. After the experiment is finished, the tensorboard process is stopped automatically.",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Simplifying Hyperparameter Tuning in Online Machine Learning---The spotRiverGUI</span>"
    ]
  },
  {
    "objectID": "501_spot_river_gui.html#sec-analysis",
    "href": "501_spot_river_gui.html#sec-analysis",
    "title": "34  Simplifying Hyperparameter Tuning in Online Machine Learning—The spotRiverGUI",
    "section": "34.8 Performing the Analysis",
    "text": "34.8 Performing the Analysis\nIf the hyperparameter tuning process is finished, the user can analyze the results by clicking on the Analysis button. The following options are available:\n\nProgress plot\nCompare tuned versus default hyperparameters\nImportance of hyperparameters\nContour plot\nParallel coordinates plot\n\nFigure 34.12 shows the progress plot of the hyperparameter tuning process. Black dots denote results from the initial design. Red dots illustrate the improvement found by the surrogate model based optimization. For binary classification tasks, the roc_auc_score can be used as the evaluation metric. The confusion matrix is shown in Figure 34.13. The default versus tuned hyperparameters are shown in Figure 34.14. The surrogate plot is shown in Figure 34.15, Figure 34.16, and Figure 34.17.\n\n\n\n\n\n\nFigure 34.12: Progress plot of the hyperparameter tuning process\n\n\n\n\n\n\n\n\n\nFigure 34.13: Confusion matrix\n\n\n\n\n\n\n\n\n\nFigure 34.14: Default versus tuned hyperparameters\n\n\n\n\n\n\n\n\n\nFigure 34.15: Surrogate plot based on the Kriging model. x0 and x1 plotted against each other.\n\n\n\n\n\n\n\n\n\nFigure 34.16: Surrogate plot based on the Kriging model. x1 and x2 plotted against each other.\n\n\n\n\n\n\n\n\n\nFigure 34.17: Surrogate plot based an the Kriging model. x0 and x2 plotted against each other.\n\n\n\nFurthermore, the tuned hyperparameters are shown in the console window. A typical output is shown below (modified due to formatting reasons):\n|name    |type   |default |low | up |tuned |transf |importance|stars|\n|--------|-------|--------|----|----|------|-------|----------|-----|\n|n_estim |int    |    3.0 |2.0 |7.0 |  3.0 | pow_2 |      0.04|     |\n|step    |float  |    1.0 |0.1 |10.0|  5.12| None  |      0.21| .   |\n|use_agg |factor |    1.0 |0.0 |1.0 |  0.0 | None  |     10.17| *   |\n|dirichl |float  |    0.5 |0.1 |0.75|  0.37| None  |     13.64| *   |\n|split_p |factor |    0.0 |0.0 |1.0 |  0.0 | None  |    100.00| *** |\nIn addition to the tuned parameters that are shown in the column tuned, the columns importance and stars are shown. Both columns show the most important hyperparameters based on information from the surrogate model. The stars column shows the importance of the hyperparameters in a graphical way. It is important to note that the results are based on a demo of the hyperparameter tuning process. The plots are not based on a real hyperparameter tuning process. The reader is referred to Bartz-Beielstein (2024b) for further information about the analysis of the hyperparameter tuning process.",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Simplifying Hyperparameter Tuning in Online Machine Learning---The spotRiverGUI</span>"
    ]
  },
  {
    "objectID": "501_spot_river_gui.html#sec-summary",
    "href": "501_spot_river_gui.html#sec-summary",
    "title": "34  Simplifying Hyperparameter Tuning in Online Machine Learning—The spotRiverGUI",
    "section": "34.9 Summary and Outlook",
    "text": "34.9 Summary and Outlook\nThe spotRiverGUI provides a graphical user interface for the spotriver package. It releases the user from the burden of manually searching for the optimal hyperparameter setting. After copying a data set into the userData folder and starting spotRiverGUI, users can compare different OML algorithms from the powerful river package in a convenient way. Users can generate configurations on their local machines, which can be transferred to a remote machine for execution. Results from the remote machine can be copied back to the local machine for analysis.\n\n\n\n\n\n\nBenefits of the spotRiverGUI:\n\n\n\n\nVery easy to use (only the data must be provided in the correct format).\nReproducible results.\nState-of-the-art hyperparameter tuning methods.\nPowerful analysis tools, e.g., Bayesian optimization (Forrester, Sóbester, and Keane 2008; Gramacy 2020).\nVisual representation of the hyperparameter tuning process with tensorboard.\nMost advanced online machine learning models from the river package.\n\n\n\nThe river package (Montiel et al. 2021), which is very well documented, can be downloaded from https://riverml.xyz/latest/.\nThe spotRiverGUI is under active development and new features will be added soon. It can be downloaded from GitHub: https://github.com/sequential-parameter-optimization/spotGUI.\nInteractive Jupyter Notebooks and further material about OML are provided in the GitHub repository https://github.com/sn-code-inside/online-machine-learning. This material is part of the supplementary material of the book “Online Machine Learning - A Practical Guide with Examples in Python”, see https://link.springer.com/book/9789819970063 and the forthcoming book “Online Machine Learning - Eine praxisorientierte Einführung”, see https://link.springer.com/book/9783658425043.",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Simplifying Hyperparameter Tuning in Online Machine Learning---The spotRiverGUI</span>"
    ]
  },
  {
    "objectID": "501_spot_river_gui.html#sec-appendix",
    "href": "501_spot_river_gui.html#sec-appendix",
    "title": "34  Simplifying Hyperparameter Tuning in Online Machine Learning—The spotRiverGUI",
    "section": "34.10 Appendix",
    "text": "34.10 Appendix\n\n34.10.1 Adding new Tasks\nCurrently, three tasks are supported in the spotRiverGUI: Binary Classification, Regression, and Rules. Rules was added in ver 0.6.0. Here, we document how this task updated was implemented. Adding an additional task requires modifications in the following files:\n\nspotRun.py:\n\nThe riverclass rules must be imported, i.e., from river import forest, tree, linear_model, rules.\nThe method get_river_rules_core_model_names() must be modified.\nThe get_scenario_dict() method must be modified.\n\nCTk.py:\n\nThe task_frame must be extended.\nThe change_task_event() method must be modified.\n\n\nIn addition, the hyperparameter dictionary in spotriver must be updated. This is the only modification required in the spotriverpackage.\n\n\n\n\nAbadi, Martin, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, et al. 2016. “TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems.” arXiv e-Prints, March, arXiv:1603.04467.\n\n\nAggarwal, Charu, ed. 2007. Data Streams – Models and Algorithms. Springer-Verlag.\n\n\nBartz-Beielstein, Thomas. 2024a. “Evaluation and Performance Measurement.” In, edited by Eva Bartz and Thomas Bartz-Beielstein, 47–62. Singapore: Springer Nature Singapore.\n\n\n———. 2024b. “Hyperparameter Tuning.” In, edited by Eva Bartz and Thomas Bartz-Beielstein, 125–40. Singapore: Springer Nature Singapore.\n\n\n———. 2024c. “Introduction: From Batch to Online Machine Learning.” In Online Machine Learning: A Practical Guide with Examples in Python, edited by Eva Bartz and Thomas Bartz-Beielstein, 1–11. Singapore: Springer Nature Singapore. https://doi.org/10.1007/978-981-99-7007-0_1.\n\n\nBartz-Beielstein, Thomas, and Lukas Hans. 2024. “Drift Detection and Handling.” In Online Machine Learning: A Practical Guide with Examples in Python, edited by Eva Bartz and Thomas Bartz-Beielstein, 23–39. Singapore: Springer Nature Singapore. https://doi.org/10.1007/978-981-99-7007-0_3.\n\n\nBartz-Beielstein, Thomas, and Martin Zaefferer. 2022. “Hyperparameter Tuning Approaches.” In Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide, edited by Eva Bartz, Thomas Bartz-Beielstein, Martin Zaefferer, and Olaf Mersmann, 67–114. Springer.\n\n\nBifet, Albert. 2010. Adaptive Stream Mining: Pattern Learning and Mining from Evolving Data Streams. Vol. 207. Frontiers in Artificial Intelligence and Applications. IOS Press.\n\n\nBifet, Albert, and Ricard Gavaldà. 2007. “Learning from Time-Changing Data with Adaptive Windowing.” In Proceedings of the 2007 SIAM International Conference on Data Mining (SDM), 443–48.\n\n\n———. 2009. “Adaptive Learning from Evolving Data Streams.” In Proceedings of the 8th International Symposium on Intelligent Data Analysis: Advances in Intelligent Data Analysis VIII, 249–60. IDA ’09. Berlin, Heidelberg: Springer-Verlag.\n\n\nBifet, Albert, Geoff Holmes, Richard Kirkby, and Bernhard Pfahringer. 2010a. “MOA: Massive Online Analysis.” Journal of Machine Learning Research 99: 1601–4.\n\n\n———. 2010b. “MOA: Massive Online Analysis.” Journal of Machine Learning Research 11: 1601–4.\n\n\nDomingos, Pedro M., and Geoff Hulten. 2000. “Mining High-Speed Data Streams.” In Proceedings of the Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Boston, MA, USA, August 20-23, 2000, edited by Raghu Ramakrishnan, Salvatore J. Stolfo, Roberto J. Bayardo, and Ismail Parsa, 71–80. ACM.\n\n\nDredze, Mark, Tim Oates, and Christine Piatko. 2010. “We’re Not in Kansas Anymore: Detecting Domain Changes in Streams.” In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, 585–95.\n\n\nForrester, Alexander, András Sóbester, and Andy Keane. 2008. Engineering Design via Surrogate Modelling. Wiley.\n\n\nGaber, Mohamed Medhat, Arkady Zaslavsky, and Shonali Krishnaswamy. 2005. “Mining Data Streams: A Review.” SIGMOD Rec. 34: 18–26.\n\n\nGama, João, Pedro Medas, Gladys Castillo, and Pedro Rodrigues. 2004. “Learning with Drift Detection.” In Advances in Artificial Intelligence – SBIA 2004, edited by Ana L. C. Bazzan and Sofiane Labidi, 286–95. Berlin, Heidelberg: Springer Berlin Heidelberg.\n\n\nGama, João, Raquel Sebastião, and Pedro Pereira Rodrigues. 2013. “On Evaluating Stream Learning Algorithms.” Machine Learning 90 (3): 317–46.\n\n\nGramacy, Robert B. 2020. Surrogates. CRC press.\n\n\nHoeglinger, Stefan, and Russel Pears. 2007. “Use of Hoeffding Trees in Concept Based Data Stream Mining.” 2007 Third International Conference on Information and Automation for Sustainability, 57–62.\n\n\nIkonomovska, Elena. 2012. “Algorithms for Learning Regression Trees and Ensembles on Evolving Data Streams.” PhD thesis, Jozef Stefan International Postgraduate School.\n\n\nKeller-McNulty, Sallie, ed. 2004. Statistical Analysis of Massive Data Streams: Proceedings of a Workshop. Washington, DC: Committee on Applied; Theoretical Statistics, National Research Council; National Academies Press.\n\n\nManapragada, Chaitanya, Geoffrey I. Webb, and Mahsa Salehi. 2018. “Extremely Fast Decision Tree.” In KDD’ 2018 - Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, edited by Chih-Jen Lin and Hui Xiong, 1953–62. United States of America: Association for Computing Machinery (ACM). https://doi.org/10.1145/3219819.3220005.\n\n\nMasud, Mohammad, Jing Gao, Latifur Khan, Jiawei Han, and Bhavani M Thuraisingham. 2011. “Classification and Novel Class Detection in Concept-Drifting Data Streams Under Time Constraints.” IEEE Transactions on Knowledge and Data Engineering 23 (6): 859–74.\n\n\nMontiel, Jacob, Max Halford, Saulo Martiello Mastelini, Geoffrey Bolmier, Raphael Sourty, Robin Vaysse, Adil Zouitine, et al. 2021. “River: Machine Learning for Streaming Data in Python.”\n\n\nMourtada, Jaouad, Stephane Gaiffas, and Erwan Scornet. 2019. “AMF: Aggregated Mondrian Forests for Online Learning.” arXiv e-Prints, June, arXiv:1906.10529. https://doi.org/10.48550/arXiv.1906.10529.\n\n\nPedregosa, F., G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, et al. 2011. “Scikit-Learn: Machine Learning in Python.” Journal of Machine Learning Research 12: 2825–30.\n\n\nPutatunda, Sayan. 2021. Practical Machine Learning for Streaming Data with Python. Springer.\n\n\nStreet, W. Nick, and YongSeog Kim. 2001. “A Streaming Ensemble Algorithm (SEA) for Large-Scale Classification.” In Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 377–82. KDD ’01. New York, NY, USA: Association for Computing Machinery.",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Simplifying Hyperparameter Tuning in Online Machine Learning---The spotRiverGUI</span>"
    ]
  },
  {
    "objectID": "502_spot_hpt_river_friedman_htr.html",
    "href": "502_spot_hpt_river_friedman_htr.html",
    "title": "35  river Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data",
    "section": "",
    "text": "35.1 The Friedman Drift Data Set\nThis chapter demonstrates hyperparameter tuning for river’s Hoeffding Tree Regressor (HTR) with the Friedman drift data set [SOURCE]. The Hoeffding Tree Regressor is a regression tree that uses the Hoeffding bound to limit the number of splits evaluated at each node, i.e., it predicts a real value for each sample.\nWe will use the Friedman synthetic dataset with concept drifts, which is described in detail in Section E.2. The following parameters are used to generate and handle the data set:\nWe will use spotriver’s convert_to_df function [SOURCE] to convert the river data set to a pandas data frame. Then we add column names x1 until x10 to the first 10 columns of the dataframe and the column name y to the last column of the dataframe.\nThis data generation is independently repeated for the training and test data sets, because the data sets are generated with concept drifts and the usual train-test split would not work.\nfrom river.datasets import synth\nimport pandas as pd\nimport numpy as np\nfrom spotriver.utils.data_conversion import convert_to_df\n\nn_train = 6_000\nn_test = 4_000\nn_samples = n_train + n_test\ntarget_column = \"y\"\n\ndataset = synth.FriedmanDrift(\n   drift_type='gra',\n   position=(n_train/4, n_train/2),\n   seed=123\n)\n\ntrain = convert_to_df(dataset, n_total=n_train)\ntrain.columns = [f\"x{i}\" for i in range(1, 11)] + [target_column]\ndataset = synth.FriedmanDrift(\n   drift_type='gra',\n   position=(n_test/4, n_test/2),\n   seed=123\n)\ntest = convert_to_df(dataset, n_total=n_test)\ntest.columns = [f\"x{i}\" for i in range(1, 11)] + [target_column]\nWe combine the train and test data sets and save them to a csv file.\ndf = pd.concat([train, test])\ndf.to_csv(\"./userData/friedman.csv\", index=False)\nThe Friedman Drift data set described in this section is avaialble as a csv data file and can be downloaded from github: friedman.csv.",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>`river` Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data</span>"
    ]
  },
  {
    "objectID": "502_spot_hpt_river_friedman_htr.html#sec-the-friedman-drift-data-set-24",
    "href": "502_spot_hpt_river_friedman_htr.html#sec-the-friedman-drift-data-set-24",
    "title": "35  river Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data",
    "section": "",
    "text": "position: The positions of the concept drifts.\nn_train: The number of samples used for training.\nn_test: The number of samples used for testing.\nseed: The seed for the random number generator.\ntarget_column: The name of the target column.\ndrift_type: The type of the concept drift.\n\n\n\n\n\n\n\n\n\n\n\nThe Data Set\n\n\n\nData sets that are available as pandas dataframes can easily be passed to the spot hyperparameter tuner. spotpython requires a train and a test data set, where the column names must be identical.",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>`river` Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data</span>"
    ]
  },
  {
    "objectID": "502_spot_hpt_river_friedman_htr.html#sec-setup-24",
    "href": "502_spot_hpt_river_friedman_htr.html#sec-setup-24",
    "title": "35  river Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data",
    "section": "35.2 Setup",
    "text": "35.2 Setup\n\n35.2.1 General Experiment Setup\nTo keep track of the different experiments, we use a PREFIX for the experiment name. The PREFIX is used to create a unique experiment name. The PREFIX is also used to create a unique TensorBoard folder, which is used to store the TensorBoard log files.\nspotpython allows the specification of two different types of stopping criteria: first, the number of function evaluations (fun_evals), and second, the maximum run time in seconds (max_time). Here, we will set the number of function evaluations to infinity and the maximum run time to one minute.\nFurthermore, we set the initial design size (init_size) to 10. The initial design is used to train the surrogate model. The surrogate model is used to predict the performance of the hyperparameter configurations. The initial design is also used to train the first model. Since the init_size belongs to the experimental design, it is set in the design_control dictionary, see [SOURCE].\nmax_time is set to one minute for demonstration purposes and init_size is set to 10 for demonstration purposes. For real experiments, these values should be increased. Note, the total run time may exceed the specified max_time, because the initial design is always evaluated, even if this takes longer than max_time.\n\n\n\n\n\n\nSummary: General Experiment Setup\n\n\n\nThe following parameters are used to specify the general experiment setup:\n\nPREFIX = \"024\"\nfun_evals = inf\nmax_time = 1\ninit_size = 10\n\n\n\n\n\n35.2.2 Data Setup\nWe use the StandardScaler [SOURCE] from river as the data-preprocessing model. The StandardScaler is used to standardize the data set, i.e., it has zero mean and unit variance.\nThe names of the training and test data sets are train and test, respectively. They are available as pandas dataframes. Both must use the same column names. The column names were set to x1 to x10 for the features and y for the target column during the data set generation in Section 35.1. Therefore, the target_column is set to y (as above).\n\n\n\n\n\n\nSummary: Data Setup\n\n\n\nThe following parameters are used to specify the data setup:\n\nprep_model_name = \"StandardScaler\"\ntest = test\ntrain = train\ntarget_column = \"y\"\n\n\n\n\n\n35.2.3 Evaluation Setup\nHere we use the mean_absolute_error [SOURCE] as the evaluation metric. Internally, this metric is passed to the objective (or loss) function fun_oml_horizon [SOURCE] and further to the evaluation function eval_oml_horizon [SOURCE].\nspotriver also supports additional metrics. For example, the metric_river is used for the river based evaluation via eval_oml_iter_progressive [SOURCE]. The metric_river is implemented to simulate the behaviour of the “original” river metrics.\n\n\n\n\n\n\nSummary: Evaluation Setup\n\n\n\nThe following parameter are used to select the evaluation metric:\n\nmetric_sklearn_name = \"mean_absolute_error\"\n\n\n\n\n\n35.2.4 River-Specific Setup\nIn the online-machine-learning (OML) setup, the model is trained on a fixed number of observations and then evaluated on a fixed number of observations. The horizon defines the number of observations that are used for the evaluation. Here, a horizon of 7*24 is used, which corresponds to one week of data.\nThe oml_grace_period defines the number of observations that are used for the initial training of the model. This value is relatively small, since the online-machine-learning is trained on the incoming data and the model is updated continuously. However, it needs a certain number of observations to start the training process. Therefore, this short training period aka oml_grace_period is set to the horizon, i.e., the number of observations that are used for the evaluation. In this case, we use a horizon of 7*24.\nThe weights provide a flexible way to define specific requirements, e.g., if the memory is more important than the time, the weight for the memory can be increased. spotriver stores information about the model’ s score (metric), memory, and time. The hyperparamter tuner requires a single objective. Therefore, a weighted sum of the metric, memory, and time is computed. The weights are defined in the weights array. The weights provide a flexible way to define specific requirements, e.g., if the memory is more important than the time, the weight for the memory can be increased.\nThe weight_coeff defines a multiplier for the results: results are multiplied by (step/n_steps)**weight_coeff, where n_steps is the total number of iterations. Results from the beginning have a lower weight than results from the end if weight_coeff &gt; 1. If weight_coeff == 0, all results have equal weight. Note, that the weight_coeff is only used internally for the tuner and does not affect the results that are used for the evaluation or comparisons.\n\n\n\n\n\n\nSummary: River-Specific Setup\n\n\n\nThe following parameters are used:\n\nhorizon = 7*24\noml_grace_period = 7*24\nweights = np.array([1, 0.01, 0.01])\nweight_coeff = 0.0\n\n\n\n\n\n35.2.5 Model Setup\nBy using core_model_name = \"tree.HoeffdingTreeRegressor\", the river model class HoeffdingTreeRegressor [SOURCE] from the tree module is selected. For a given core_model_name, the corresponding hyperparameters are automatically loaded from the associated dictionary, which is stored as a JSON file. The JSON file contains hyperparameter type information, names, and bounds. For river models, the hyperparameters are stored in the RiverHyperDict, see [SOURCE]\nAlternatively, you can load a local hyper_dict. Simply set river_hyper_dict.json as the filename. If filenameis set to None, which is the default, the hyper_dict [SOURCE] is loaded from the spotriver package.\nHow hyperparameter levels can be modified is described in Section 11.15.1.\n\n\n\n\n\n\nSummary: Model Setup\n\n\n\nThe following parameters are used for the model setup:\n\nfrom spotriver.fun.hyperriver import HyperRiver\nfrom spotriver.hyperdict.river_hyper_dict import RiverHyperDict\ncore_model_name = \"tree.HoeffdingTreeRegressor\"\nhyperdict = RiverHyperDict\n\n\n\n\n\n35.2.6 Objective Function Setup\nThe loss function (metric) values are passed to the objective function fun_oml_horizon [SOURCE], which combines information about the loss, required memory and time as described in Section 35.2.4.\n\n\n\n\n\n\nSummary: Objective Function Setup\n\n\n\nThe following parameters are used:\n\nfun = HyperRiver().fun_oml_horizon\n\n\n35.2.7 Surrogate Model Setup\nThe default surrogate model is the Kriging model, see [SOURCE]. We specify noise as True to include noise in the model. An anisotropic kernel is used, which allows different length scales for each dimension, by setting n_theta = 2. Furthermore, the interval for the Lambda value is set to [1e-3, 1e2].\nThese parameters are set in the surrogate_control dictionary and therefore passed to the surrogate_control_init function [SOURCE].\n\nnoise = True\nn_theta = 2\nmin_Lambda = 1e-3\nmax_Lambda = 10\n\n\n\n\n\n\n35.2.8 Summary: Setting up the Experiment\nAt this stage, all required information is available to set up the dictionaries for the hyperparameter tuning. Altogether, the fun_control, design_control, surrogate_control, and optimize_control dictionaries are initialized as follows:\n\nfrom spotpython.utils.init import fun_control_init, design_control_init, surrogate_control_init, optimizer_control_init\n\nfun = HyperRiver().fun_oml_horizon\n\nfun_control = fun_control_init(\n    PREFIX=\"024\",\n    fun_evals=inf,\n    max_time=1,\n\n    prep_model_name=\"StandardScaler\",\n    test=test,\n    train=train,\n    target_column=target_column,\n\n    metric_sklearn_name=\"mean_absolute_error\",\n    horizon=7*24,\n    oml_grace_period=7*24,\n    weight_coeff=0.0,\n    weights=np.array([1, 0.01, 0.01]),\n\n    core_model_name=\"tree.HoeffdingTreeRegressor\",\n    hyperdict=RiverHyperDict,\n   )\n\n\ndesign_control = design_control_init(\n    init_size=10,\n)\n\nsurrogate_control = surrogate_control_init(\n    method=\"regression\",\n    n_theta=2,\n    min_Lambda=1e-3,\n    max_Lambda=10,\n)\n\noptimizer_control = optimizer_control_init()\n\n\n\n35.2.9 Run the Spot Optimizer\nThe class Spot [SOURCE] is the hyperparameter tuning workhorse. It is initialized with the following parameters, which were specified above.\n\nfun: the objective function\nfun_control: the dictionary with the control parameters for the objective function\ndesign_control: the dictionary with the control parameters for the experimental design\nsurrogate_control: the dictionary with the control parameters for the surrogate model\noptimizer_control: the dictionary with the control parameters for the optimizer\n\nspotpython allows maximum flexibility in the definition of the hyperparameter tuning setup. Alternative surrogate models, optimizers, and experimental designs can be used. Thus, interfaces for the surrogate model, experimental design, and optimizer are provided. The default surrogate model is the kriging model, the default optimizer is the differential evolution, and default experimental design is the Latin hypercube design.\n\n\n\n\n\n\nSummary: Spot Setup\n\n\n\nThe following parameters are used for the Spot setup. These were specified above:\n\nfun = fun\nfun_control = fun_control\ndesign_control = design_control\nsurrogate_control = surrogate_control\noptimizer_control = optimizer_control\n\n\n\n\nfrom spotpython.spot import Spot\nspot_tuner = Spot(\n    fun=fun,\n    fun_control=fun_control,\n    design_control=design_control,\n    surrogate_control=surrogate_control,\n    optimizer_control=optimizer_control,\n)\nres = spot_tuner.run()\n\nspotpython tuning: 3.196680194313792 [----------] 0.75% \nspotpython tuning: 3.196680194313792 [----------] 2.19% \nspotpython tuning: 3.196680194313792 [----------] 3.93% \nspotpython tuning: 3.196680194313792 [#---------] 5.60% \nspotpython tuning: 3.196680194313792 [#---------] 9.19% \nspotpython tuning: 3.196680194313792 [#---------] 10.97% \nspotpython tuning: 3.196680194313792 [#---------] 12.82% \nspotpython tuning: 3.196680194313792 [#---------] 14.60% \nspotpython tuning: 3.196680194313792 [##--------] 16.41% \nspotpython tuning: 3.196680194313792 [##--------] 19.31% \nspotpython tuning: 3.196680194313792 [###-------] 25.13% \nspotpython tuning: 3.196680194313792 [###-------] 27.32% \nspotpython tuning: 3.196680194313792 [###-------] 33.97% \nspotpython tuning: 3.196680194313792 [####------] 37.69% \nspotpython tuning: 3.196680194313792 [####------] 44.72% \nspotpython tuning: 3.196680194313792 [#####-----] 52.27% \nspotpython tuning: 3.196680194313792 [######----] 59.71% \nspotpython tuning: 3.196680194313792 [######----] 62.42% \nspotpython tuning: 3.196680194313792 [#######---] 67.57% \nspotpython tuning: 3.196680194313792 [########--] 78.51% \nspotpython tuning: 3.196680194313792 [#########-] 85.37% \nspotpython tuning: 3.196680194313792 [##########] 96.40% \nspotpython tuning: 3.196680194313792 [##########] 100.00% Done...\n\nExperiment saved to 024_res.pkl",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>`river` Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data</span>"
    ]
  },
  {
    "objectID": "502_spot_hpt_river_friedman_htr.html#using-the-spotgui",
    "href": "502_spot_hpt_river_friedman_htr.html#using-the-spotgui",
    "title": "35  river Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data",
    "section": "35.3 Using the spotgui",
    "text": "35.3 Using the spotgui\nThe spotgui [github] provides a convenient way to interact with the hyperparameter tuning process. To obtain the settings from Section 35.2.8, the spotgui can be started as shown in Figure 41.1.\n\n\n\n\n\n\nFigure 35.1: spotgui",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>`river` Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data</span>"
    ]
  },
  {
    "objectID": "502_spot_hpt_river_friedman_htr.html#results",
    "href": "502_spot_hpt_river_friedman_htr.html#results",
    "title": "35  river Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data",
    "section": "35.4 Results",
    "text": "35.4 Results\nAfter the hyperparameter tuning run is finished, the progress of the hyperparameter tuning can be visualized with spotpython’s method plot_progress. The black points represent the performace values (score or metric) of hyperparameter configurations from the initial design, whereas the red points represents the hyperparameter configurations found by the surrogate model based optimization.\n\nspot_tuner.plot_progress(log_y=True, filename=None)\n\n\n\n\n\n\n\n\nResults can be printed in tabular form.\n\nfrom spotpython.utils.eda import print_res_table\nprint_res_table(spot_tuner)\n\n| name                   | type   | default          |   lower |   upper | tuned                 | transform              |   importance | stars   |\n|------------------------|--------|------------------|---------|---------|-----------------------|------------------------|--------------|---------|\n| grace_period           | int    | 200              |    10.0 |  1000.0 | 159.0                 | None                   |         0.01 |         |\n| max_depth              | int    | 20               |     2.0 |    20.0 | 10.0                  | transform_power_2_int  |         0.01 |         |\n| delta                  | float  | 1e-07            |   1e-08 |   1e-06 | 7.459571804536548e-07 | None                   |       100.00 | ***     |\n| tau                    | float  | 0.05             |    0.01 |     0.1 | 0.06006303674598468   | None                   |         0.01 |         |\n| leaf_prediction        | factor | mean             |     0.0 |     2.0 | adaptive              | None                   |        70.75 | **      |\n| leaf_model             | factor | LinearRegression |     0.0 |     2.0 | PARegressor           | None                   |         0.01 |         |\n| model_selector_decay   | float  | 0.95             |     0.9 |    0.99 | 0.9317758429064884    | None                   |         0.01 |         |\n| splitter               | factor | EBSTSplitter     |     0.0 |     2.0 | TEBSTSplitter         | None                   |         0.01 |         |\n| min_samples_split      | int    | 5                |     2.0 |    10.0 | 9.0                   | None                   |         0.01 |         |\n| binary_split           | factor | 0                |     0.0 |     1.0 | 1                     | None                   |         0.01 |         |\n| max_size               | float  | 500.0            |   100.0 |  1000.0 | 326.29227372280025    | None                   |         0.01 |         |\n| memory_estimate_period | int    | 6                |     3.0 |     8.0 | 4.0                   | transform_power_10_int |         0.01 |         |\n| stop_mem_management    | factor | 0                |     0.0 |     1.0 | 0                     | None                   |         0.01 |         |\n| remove_poor_attrs      | factor | 0                |     0.0 |     1.0 | 1                     | None                   |         0.01 |         |\n| merit_preprune         | factor | 1                |     0.0 |     1.0 | 0                     | None                   |         0.16 | .       |\n\n\nA histogram can be used to visualize the most important hyperparameters.\n\nspot_tuner.plot_importance(threshold=10.0)",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>`river` Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data</span>"
    ]
  },
  {
    "objectID": "502_spot_hpt_river_friedman_htr.html#performance-of-the-model-with-default-hyperparameters",
    "href": "502_spot_hpt_river_friedman_htr.html#performance-of-the-model-with-default-hyperparameters",
    "title": "35  river Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data",
    "section": "35.5 Performance of the Model with Default Hyperparameters",
    "text": "35.5 Performance of the Model with Default Hyperparameters\n\n35.5.1 Get Default Hyperparameters and Fit the Model\nThe default hyperparameters, which will be used for a comparion with the tuned hyperparameters, can be obtained with the following commands:\n\nfrom spotpython.hyperparameters.values import get_default_hyperparameters_as_array\nX_start = get_default_hyperparameters_as_array(fun_control)\n\nspotpython tunes numpy arrays, i.e., the hyperparameters are stored in a numpy array.\n\nfrom spotpython.hyperparameters.values import get_one_core_model_from_X\nmodel_default = get_one_core_model_from_X(X_start, fun_control, default=True)\n\n\n\n35.5.2 Evaluate the Model with Default Hyperparameters\nThe model with the default hyperparameters can be trained and evaluated. The evaluation function eval_oml_horizon [SOURCE] is the same function that was used for the hyperparameter tuning. During the hyperparameter tuning, the evaluation function was called from the objective (or loss) function fun_oml_horizon [SOURCE].\n\nfrom spotriver.evaluation.eval_bml import eval_oml_horizon\n\ndf_eval_default, df_true_default = eval_oml_horizon(\n                    model=model_default,\n                    train=fun_control[\"train\"],\n                    test=fun_control[\"test\"],\n                    target_column=fun_control[\"target_column\"],\n                    horizon=fun_control[\"horizon\"],\n                    oml_grace_period=fun_control[\"oml_grace_period\"],\n                    metric=fun_control[\"metric_sklearn\"],\n                )\n\nThe three performance criteria, i.e., score (metric), runtime, and memory consumption, can be visualized with the following commands:\n\nfrom spotriver.evaluation.eval_bml import plot_bml_oml_horizon_metrics, plot_bml_oml_horizon_predictions\ndf_labels=[\"default\"]\nplot_bml_oml_horizon_metrics(df_eval = [df_eval_default], log_y=False, df_labels=df_labels, metric=fun_control[\"metric_sklearn\"])\n\n\n\n\n\n\n\n\n\n\n35.5.3 Show Predictions of the Model with Default Hyperparameters\n\nSelect a subset of the data set for the visualization of the predictions:\n\nWe use the mean, \\(m\\), of the data set as the center of the visualization.\nWe use 100 data points, i.e., \\(m \\pm 50\\) as the visualization window.\n\n\n\nm = fun_control[\"test\"].shape[0]\na = int(m/2)-50\nb = int(m/2)+50\nplot_bml_oml_horizon_predictions(df_true = [df_true_default[a:b]], target_column=target_column,  df_labels=df_labels)",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>`river` Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data</span>"
    ]
  },
  {
    "objectID": "502_spot_hpt_river_friedman_htr.html#get-spot-results",
    "href": "502_spot_hpt_river_friedman_htr.html#get-spot-results",
    "title": "35  river Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data",
    "section": "35.6 Get SPOT Results",
    "text": "35.6 Get SPOT Results\nIn a similar way, we can obtain the hyperparameters found by spotpython.\n\nfrom spotpython.hyperparameters.values import get_one_core_model_from_X\nX = spot_tuner.to_all_dim(spot_tuner.min_X.reshape(1,-1))\nmodel_spot = get_one_core_model_from_X(X, fun_control)\n\n\ndf_eval_spot, df_true_spot = eval_oml_horizon(\n                    model=model_spot,\n                    train=fun_control[\"train\"],\n                    test=fun_control[\"test\"],\n                    target_column=fun_control[\"target_column\"],\n                    horizon=fun_control[\"horizon\"],\n                    oml_grace_period=fun_control[\"oml_grace_period\"],\n                    metric=fun_control[\"metric_sklearn\"],\n                )\n\n\ndf_labels=[\"default\", \"spot\"]\nplot_bml_oml_horizon_metrics(df_eval = [df_eval_default, df_eval_spot], log_y=False, df_labels=df_labels, metric=fun_control[\"metric_sklearn\"])\n\n\n\n\n\n\n\n\n\nplot_bml_oml_horizon_predictions(df_true = [df_true_default[a:b], df_true_spot[a:b]], target_column=target_column,  df_labels=df_labels)\n\n\n\n\n\n\n\n\n\nfrom spotpython.plot.validation import plot_actual_vs_predicted\nplot_actual_vs_predicted(y_test=df_true_default[target_column], y_pred=df_true_default[\"Prediction\"], title=\"Default\")\nplot_actual_vs_predicted(y_test=df_true_spot[target_column], y_pred=df_true_spot[\"Prediction\"], title=\"SPOT\")",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>`river` Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data</span>"
    ]
  },
  {
    "objectID": "502_spot_hpt_river_friedman_htr.html#visualize-regression-trees",
    "href": "502_spot_hpt_river_friedman_htr.html#visualize-regression-trees",
    "title": "35  river Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data",
    "section": "35.7 Visualize Regression Trees",
    "text": "35.7 Visualize Regression Trees\n\ndataset_f = dataset.take(n_samples)\nprint(f\"n_samples: {n_samples}\")\nfor x, y in dataset_f:\n    model_default.learn_one(x, y)\n\nn_samples: 10000\n\n\n\n\n\n\n\n\nCaution: Large Trees\n\n\n\n\nSince the trees are large, the visualization is suppressed by default.\nTo visualize the trees, uncomment the following line.\n\n\n\n\n# model_default.draw()\n\n\nmodel_default.summary\n\n{'n_nodes': 23,\n 'n_branches': 11,\n 'n_leaves': 12,\n 'n_active_leaves': 12,\n 'n_inactive_leaves': 0,\n 'height': 7,\n 'total_observed_weight': 14168.0}\n\n\n\n35.7.1 Spot Model\n\nprint(f\"n_samples: {n_samples}\")\ndataset_f = dataset.take(n_samples)\nfor x, y in dataset_f:\n    model_spot.learn_one(x, y)\n\nn_samples: 10000\n\n\n\n\n\n\n\n\nCaution: Large Trees\n\n\n\n\nSince the trees are large, the visualization is suppressed by default.\nTo visualize the trees, uncomment the following line.\n\n\n\n\n# model_spot.draw()\n\n\nmodel_spot.summary\n\n{'n_nodes': 31,\n 'n_branches': 15,\n 'n_leaves': 16,\n 'n_active_leaves': 16,\n 'n_inactive_leaves': 0,\n 'height': 8,\n 'total_observed_weight': 14168.0}\n\n\n\nfrom spotpython.utils.eda import compare_two_tree_models\nprint(compare_two_tree_models(model_default, model_spot))\n\n| Parameter             |   Default |   Spot |\n|-----------------------|-----------|--------|\n| n_nodes               |        23 |     31 |\n| n_branches            |        11 |     15 |\n| n_leaves              |        12 |     16 |\n| n_active_leaves       |        12 |     16 |\n| n_inactive_leaves     |         0 |      0 |\n| height                |         7 |      8 |\n| total_observed_weight |     14168 |  14168 |",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>`river` Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data</span>"
    ]
  },
  {
    "objectID": "502_spot_hpt_river_friedman_htr.html#detailed-hyperparameter-plots",
    "href": "502_spot_hpt_river_friedman_htr.html#detailed-hyperparameter-plots",
    "title": "35  river Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data",
    "section": "35.8 Detailed Hyperparameter Plots",
    "text": "35.8 Detailed Hyperparameter Plots\n\nspot_tuner.plot_important_hyperparameter_contour(max_imp=3)\n\ngrace_period:  0.007957697876272318\nmax_depth:  0.007957697876272318\ndelta:  100.0\ntau:  0.007957697876272318\nleaf_prediction:  70.75125095923516\nleaf_model:  0.007957697876272318\nmodel_selector_decay:  0.007957697876272318\nsplitter:  0.007957697876272318\nmin_samples_split:  0.007957697876272318\nbinary_split:  0.007957697876272318\nmax_size:  0.007957697876272318\nmemory_estimate_period:  0.008107263269554505\nstop_mem_management:  0.007957697876272318\nremove_poor_attrs:  0.007957697876272318\nmerit_preprune:  0.15813828523156645",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>`river` Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data</span>"
    ]
  },
  {
    "objectID": "502_spot_hpt_river_friedman_htr.html#parallel-coordinates-plots",
    "href": "502_spot_hpt_river_friedman_htr.html#parallel-coordinates-plots",
    "title": "35  river Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data",
    "section": "35.9 Parallel Coordinates Plots",
    "text": "35.9 Parallel Coordinates Plots\n\nspot_tuner.parallel_plot()",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>`river` Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data</span>"
    ]
  },
  {
    "objectID": "503_spot_hpt_river_friedman_amfr.html",
    "href": "503_spot_hpt_river_friedman_amfr.html",
    "title": "36  The Friedman Drift Data Set",
    "section": "",
    "text": "36.1 Setup\nThis chapter demonstrates hyperparameter tuning for river’s Mondrian Tree Regressor [SOURCE] with the Friedman drift data set [SOURCE]. The Mondrian Tree Regressor is a regression tree, i.e., it predicts a real value for each sample.\nThe data set was introduced in Section 35.1.\nWe will use a general experiment, data, evaluation, river-specific, objective-function, and surrogate setup similar to the setup from Section 35.2. Only the model setup differs from the setup in Section 35.2. Here we use the Mondrian Tree Regressor from river.\nfrom spotriver.hyperdict.river_hyper_dict import RiverHyperDict\ncore_model_name = \"forest.AMFRegressor\"\nhyperdict = RiverHyperDict\nhyperdict\n\nspotriver.hyperdict.river_hyper_dict.RiverHyperDict",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>The Friedman Drift Data Set</span>"
    ]
  },
  {
    "objectID": "503_spot_hpt_river_friedman_amfr.html#setup",
    "href": "503_spot_hpt_river_friedman_amfr.html#setup",
    "title": "36  The Friedman Drift Data Set",
    "section": "",
    "text": "36.1.1 Select a User Hyperdictionary\nAlternatively, you can load a local hyper_dict from the “userModel” folder. Here, we have selected a copy of the JSON MondrianHyperDict hyperdictionary from [SOURCE] and the MondrianHyperDict class from [SOURCE]. The hyperparameters of the Mondrian Tree Regressor are defined in the MondrianHyperDict class, i.e., there is an key “AMFRegressor” in the hyperdict “mondrian_hyper_dict.json” file.\n\nimport sys\nsys.path.insert(0, './userModel')\nimport mondrian_hyper_dict\nhyperdict = mondrian_hyper_dict.MondrianHyperDict\nhyperdict\n\nmondrian_hyper_dict.MondrianHyperDict\n\n\n\nfrom spotpython.utils.init import fun_control_init, design_control_init, surrogate_control_init, optimizer_control_init\nfrom spotriver.fun.hyperriver import HyperRiver\n\nfun = HyperRiver().fun_oml_horizon\n\nfun_control = fun_control_init(\n    PREFIX=\"503\",\n    fun_evals=inf,\n    max_time=1,\n\n    prep_model_name=\"StandardScaler\",\n    test=test,\n    train=train,\n    target_column=target_column,\n\n    metric_sklearn_name=\"mean_absolute_error\",\n    horizon=7*24,\n    oml_grace_period=7*24,\n    weight_coeff=0.0,\n    weights=np.array([1, 0.01, 0.01]),\n\n    core_model_name=\"forest.AMFRegressor\",\n    hyperdict=hyperdict,\n   )\n\n\ndesign_control = design_control_init(\n    init_size=5,\n)\n\nsurrogate_control = surrogate_control_init(\n    method=\"regression\",\n    n_theta=2,\n    min_Lambda=1e-3,\n    max_Lambda=10,\n)\n\noptimizer_control = optimizer_control_init()",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>The Friedman Drift Data Set</span>"
    ]
  },
  {
    "objectID": "503_spot_hpt_river_friedman_amfr.html#modify-hyper_dict-hyperparameters-for-the-selected-algorithm-aka-core_model",
    "href": "503_spot_hpt_river_friedman_amfr.html#modify-hyper_dict-hyperparameters-for-the-selected-algorithm-aka-core_model",
    "title": "36  The Friedman Drift Data Set",
    "section": "36.2 Modify hyper_dict Hyperparameters for the Selected Algorithm aka core_model",
    "text": "36.2 Modify hyper_dict Hyperparameters for the Selected Algorithm aka core_model\nAfter the core_model and the hyperdict are added to the fun_control dictionary, the hyperparameter tuning can be started. However, in some settings, the user wants to modify the hyperparameters. This can be done with the set_int_hyperparameter_values, set_float_hyperparameter_values, set_boolean_hyperparameter_values, and set_factor_hyperparameter_values functions, which can be imported from from spotpython.hyperparameters.values [SOURCE].\nThe following code shows how hyperparameter of type float and integer can be modified. Additional examples can be found in Section 11.15.1.\n\nprint_exp_table(fun_control)\n\n| name            | type   |   default |   lower |   upper | transform             |\n|-----------------|--------|-----------|---------|---------|-----------------------|\n| n_estimators    | int    |         3 |     2   |      10 | transform_power_2_int |\n| step            | float  |         1 |     0.1 |      10 | None                  |\n| use_aggregation | factor |         1 |     0   |       1 | None                  |\n\n\n\nfrom spotpython.hyperparameters.values import set_int_hyperparameter_values, set_float_hyperparameter_values, set_factor_hyperparameter_values\nset_int_hyperparameter_values(fun_control, \"n_estimators\", 2, 7)\nset_float_hyperparameter_values(fun_control, \"step\", 0.1, 15)\nprint_exp_table(fun_control)\n\nSetting hyperparameter n_estimators to value [2, 7].\nVariable type is int.\nCore type is None.\nCalling modify_hyper_parameter_bounds().\nSetting hyperparameter step to value [0.1, 15].\nVariable type is float.\nCore type is None.\nCalling modify_hyper_parameter_bounds().\n| name            | type   |   default |   lower |   upper | transform             |\n|-----------------|--------|-----------|---------|---------|-----------------------|\n| n_estimators    | int    |         3 |     2   |       7 | transform_power_2_int |\n| step            | float  |         1 |     0.1 |      15 | None                  |\n| use_aggregation | factor |         1 |     0   |       1 | None                  |\n\n\n\n\n\n\n\n\nNote: Active and Inactive Hyperparameters\n\n\n\nHyperparameters can be excluded from the tuning procedure by selecting identical values for the lower and upper bounds.\n\n\n\n36.2.1 Run the Spot Optimizer\n\nfrom spotpython.spot import Spot\nspot_tuner = Spot(\n    fun=fun,\n    fun_control=fun_control,\n    design_control=design_control,\n    surrogate_control=surrogate_control,\n    optimizer_control=optimizer_control,\n)\nres = spot_tuner.run()\n\nspotpython tuning: 2.815119047243942 [####------] 39.73% \nspotpython tuning: 2.807752706284554 [########--] 80.53% \nspotpython tuning: 2.807752706284554 [##########] 100.00% Done...\n\nExperiment saved to 503_res.pkl\n\n\nWe can start TensorBoard in the background with the following command, where ./runs is the default directory for the TensorBoard log files:\ntensorboard --logdir=\"./runs\"We can access the TensorBoard web server with the following URL:\nhttp://localhost:6006/",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>The Friedman Drift Data Set</span>"
    ]
  },
  {
    "objectID": "503_spot_hpt_river_friedman_amfr.html#results",
    "href": "503_spot_hpt_river_friedman_amfr.html#results",
    "title": "36  The Friedman Drift Data Set",
    "section": "36.3 Results",
    "text": "36.3 Results\nAfter the hyperparameter tuning run is finished, the progress of the hyperparameter tuning can be visualized with spotpython’s method plot_progress. The black points represent the performace values (score or metric) of hyperparameter configurations from the initial design, whereas the red points represents the hyperparameter configurations found by the surrogate model based optimization.\n\nspot_tuner.plot_progress()\n\n\n\n\n\n\n\n\nResults can be printed in tabular form.\n\nfrom spotpython.utils.eda import print_res_table\nprint_res_table(spot_tuner)\n\n| name            | type   |   default |   lower |   upper |             tuned | transform             |   importance | stars   |\n|-----------------|--------|-----------|---------|---------|-------------------|-----------------------|--------------|---------|\n| n_estimators    | int    |       3.0 |     2.0 |       7 |               5.0 | transform_power_2_int |       100.00 | ***     |\n| step            | float  |       1.0 |     0.1 |      15 | 6.284304415932409 | None                  |         0.02 |         |\n| use_aggregation | factor |       1.0 |     0.0 |       1 |               1.0 | None                  |         0.31 | .       |\n\n\nA histogram can be used to visualize the most important hyperparameters.\n\nspot_tuner.plot_importance(threshold=10.0)",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>The Friedman Drift Data Set</span>"
    ]
  },
  {
    "objectID": "503_spot_hpt_river_friedman_amfr.html#performance-of-the-model-with-default-hyperparameters",
    "href": "503_spot_hpt_river_friedman_amfr.html#performance-of-the-model-with-default-hyperparameters",
    "title": "36  The Friedman Drift Data Set",
    "section": "36.4 Performance of the Model with Default Hyperparameters",
    "text": "36.4 Performance of the Model with Default Hyperparameters\n\n36.4.1 Get Default Hyperparameters and Fit the Model\nThe default hyperparameters, which will be used for a comparion with the tuned hyperparameters, can be obtained with the following commands:\n\nfrom spotpython.hyperparameters.values import get_default_hyperparameters_as_array\nX_start = get_default_hyperparameters_as_array(fun_control)\n\nspotpython tunes numpy arrays, i.e., the hyperparameters are stored in a numpy array.\n\nfrom spotpython.hyperparameters.values import get_one_core_model_from_X\nmodel_default = get_one_core_model_from_X(X_start, fun_control, default=True)\n\n\n\n36.4.2 Evaluate the Model with Default Hyperparameters\nThe model with the default hyperparameters can be trained and evaluated. The evaluation function eval_oml_horizon [SOURCE] is the same function that was used for the hyperparameter tuning. During the hyperparameter tuning, the evaluation function was called from the objective (or loss) function fun_oml_horizon [SOURCE].\n\nfrom spotriver.evaluation.eval_bml import eval_oml_horizon\n\ndf_eval_default, df_true_default = eval_oml_horizon(\n                    model=model_default,\n                    train=fun_control[\"train\"],\n                    test=fun_control[\"test\"],\n                    target_column=fun_control[\"target_column\"],\n                    horizon=fun_control[\"horizon\"],\n                    oml_grace_period=fun_control[\"oml_grace_period\"],\n                    metric=fun_control[\"metric_sklearn\"],\n                )\n\nThe three performance criteria, i.e., score (metric), runtime, and memory consumption, can be visualized with the following commands:\n\nfrom spotriver.evaluation.eval_bml import plot_bml_oml_horizon_metrics, plot_bml_oml_horizon_predictions\ndf_labels=[\"default\"]\nplot_bml_oml_horizon_metrics(df_eval = [df_eval_default], log_y=False, df_labels=df_labels, metric=fun_control[\"metric_sklearn\"])\n\n\n\n\n\n\n\n\n\n\n36.4.3 Show Predictions of the Model with Default Hyperparameters\n\nSelect a subset of the data set for the visualization of the predictions:\n\nWe use the mean, \\(m\\), of the data set as the center of the visualization.\nWe use 100 data points, i.e., \\(m \\pm 50\\) as the visualization window.\n\n\n\nm = fun_control[\"test\"].shape[0]\na = int(m/2)-50\nb = int(m/2)+50\nplot_bml_oml_horizon_predictions(df_true = [df_true_default[a:b]], target_column=target_column,  df_labels=df_labels)",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>The Friedman Drift Data Set</span>"
    ]
  },
  {
    "objectID": "503_spot_hpt_river_friedman_amfr.html#get-spot-results",
    "href": "503_spot_hpt_river_friedman_amfr.html#get-spot-results",
    "title": "36  The Friedman Drift Data Set",
    "section": "36.5 Get SPOT Results",
    "text": "36.5 Get SPOT Results\nIn a similar way, we can obtain the hyperparameters found by spotpython.\n\nfrom spotpython.hyperparameters.values import get_one_core_model_from_X\nX = spot_tuner.to_all_dim(spot_tuner.min_X.reshape(1,-1))\nmodel_spot = get_one_core_model_from_X(X, fun_control)\n\n\ndf_eval_spot, df_true_spot = eval_oml_horizon(\n                    model=model_spot,\n                    train=fun_control[\"train\"],\n                    test=fun_control[\"test\"],\n                    target_column=fun_control[\"target_column\"],\n                    horizon=fun_control[\"horizon\"],\n                    oml_grace_period=fun_control[\"oml_grace_period\"],\n                    metric=fun_control[\"metric_sklearn\"],\n                )\n\n\ndf_labels=[\"default\", \"spot\"]\nplot_bml_oml_horizon_metrics(df_eval = [df_eval_default, df_eval_spot], log_y=False, df_labels=df_labels, metric=fun_control[\"metric_sklearn\"])\n\n\n\n\n\n\n\n\n\nplot_bml_oml_horizon_predictions(df_true = [df_true_default[a:b], df_true_spot[a:b]], target_column=target_column,  df_labels=df_labels)\n\n\n\n\n\n\n\n\n\nfrom spotpython.plot.validation import plot_actual_vs_predicted\nplot_actual_vs_predicted(y_test=df_true_default[target_column], y_pred=df_true_default[\"Prediction\"], title=\"Default\")\nplot_actual_vs_predicted(y_test=df_true_spot[target_column], y_pred=df_true_spot[\"Prediction\"], title=\"SPOT\")",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>The Friedman Drift Data Set</span>"
    ]
  },
  {
    "objectID": "503_spot_hpt_river_friedman_amfr.html#detailed-hyperparameter-plots",
    "href": "503_spot_hpt_river_friedman_amfr.html#detailed-hyperparameter-plots",
    "title": "36  The Friedman Drift Data Set",
    "section": "36.6 Detailed Hyperparameter Plots",
    "text": "36.6 Detailed Hyperparameter Plots\n\nspot_tuner.plot_important_hyperparameter_contour(max_imp=3)\n\nn_estimators:  100.00000000000001\nstep:  0.019848048974738398\nuse_aggregation:  0.3125741544963343",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>The Friedman Drift Data Set</span>"
    ]
  },
  {
    "objectID": "503_spot_hpt_river_friedman_amfr.html#parallel-coordinates-plots",
    "href": "503_spot_hpt_river_friedman_amfr.html#parallel-coordinates-plots",
    "title": "36  The Friedman Drift Data Set",
    "section": "36.7 Parallel Coordinates Plots",
    "text": "36.7 Parallel Coordinates Plots\n\nspot_tuner.parallel_plot()",
    "crumbs": [
      "Hyperparameter Tuning with River",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>The Friedman Drift Data Set</span>"
    ]
  },
  {
    "objectID": "700_lightning_basic.html",
    "href": "700_lightning_basic.html",
    "title": "37  Basic Lightning Module",
    "section": "",
    "text": "37.1 Introduction\nThis chapter implements a basic Pytorch Lightning module. It is based on the Lightning documentation LIGHTNINGMODULE.\nA LightningModule organizes your PyTorch code into six sections:\nThe Trainer automates every required step in a clear and reproducible way. It is the most important part of PyTorch Lightning. It is responsible for training, testing, and validating the model. The Lightning core structure looks like this:\nThere are no .cuda() or .to(device) calls required. Lightning does these for you.\nA LightningModule is a torch.nn.Module but with added functionality. For example:",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Basic Lightning Module</span>"
    ]
  },
  {
    "objectID": "700_lightning_basic.html#introduction",
    "href": "700_lightning_basic.html#introduction",
    "title": "37  Basic Lightning Module",
    "section": "",
    "text": "Initialization (__init__ and setup()).\nTrain Loop (training_step())\nValidation Loop (validation_step())\nTest Loop (test_step())\nPrediction Loop (predict_step())\nOptimizers and LR Schedulers (configure_optimizers())\n\n\nnet = MyLightningModuleNet()\ntrainer = Trainer()\ntrainer.fit(net)\n\n# don't do in Lightning\nx = torch.Tensor(2, 3)\nx = x.cuda()\nx = x.to(device)\n\n# do this instead\nx = x  # leave it alone!\n\n# or to init a new tensor\nnew_x = torch.Tensor(2, 3)\nnew_x = new_x.to(x)\n\nnet = Net.load_from_checkpoint(PATH)\nnet.freeze()\nout = net(x)",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Basic Lightning Module</span>"
    ]
  },
  {
    "objectID": "700_lightning_basic.html#starter-example-transformer",
    "href": "700_lightning_basic.html#starter-example-transformer",
    "title": "37  Basic Lightning Module",
    "section": "37.2 Starter Example: Transformer",
    "text": "37.2 Starter Example: Transformer\nHere are the only required methods for setting up a transfomer model:\n\nimport lightning as L\nimport torch\n\nfrom lightning.pytorch.demos import Transformer\n\n\nclass LightningTransformer(L.LightningModule):\n    def __init__(self, vocab_size):\n        super().__init__()\n        self.model = Transformer(vocab_size=vocab_size)\n\n    def forward(self, inputs, target):\n        return self.model(inputs, target)\n\n    def training_step(self, batch, batch_idx):\n        inputs, target = batch\n        output = self(inputs, target)\n        loss = torch.nn.functional.nll_loss(output, target.view(-1))\n        return loss\n\n    def configure_optimizers(self):\n        return torch.optim.SGD(self.model.parameters(), lr=0.1)\n\nThe LightningTransformer class is a subclass of LightningModule. It can be trainted as follows:\n\nfrom lightning.pytorch.demos import WikiText2\nfrom torch.utils.data import DataLoader\n\ndataset = WikiText2()\ndataloader = DataLoader(dataset)\nmodel = LightningTransformer(vocab_size=dataset.vocab_size)\n\ntrainer = L.Trainer(fast_dev_run=100)\ntrainer.fit(model=model, train_dataloaders=dataloader)",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Basic Lightning Module</span>"
    ]
  },
  {
    "objectID": "700_lightning_basic.html#lightning-core-methods",
    "href": "700_lightning_basic.html#lightning-core-methods",
    "title": "37  Basic Lightning Module",
    "section": "37.3 Lightning Core Methods",
    "text": "37.3 Lightning Core Methods\nThe LightningModule has many convenient methods, but the core ones you need to know about are shown in Table 37.1.\n\n\n\nTable 37.1: The core methods of a LightningModule\n\n\n\n\n\n\n\n\n\nMethod\nDescription\n\n\n\n\n__init__ and setup\nInitializes the model.\n\n\nforward\nPerforms a forward pass through the model. To run data through your model only (separate from training_step).\n\n\ntraining_step\nPerforms a complete training step.\n\n\nvalidation_step\nPerforms a complete validation step.\n\n\ntest_step\nPerforms a complete test step.\n\n\npredict_step\nPerforms a complete prediction step.\n\n\nconfigure_optimizers\nConfigures the optimizers and learning-rate schedulers.\n\n\n\n\n\n\nWe will take a closer look at thes methods.\n\n37.3.1 Training Step\n\n37.3.1.1 Basics\nTo activate the training loop, override the training_step() method. If you want to calculate epoch-level metrics and log them, use log().\nclass LightningTransformer(L.LightningModule):\n    def __init__(self, vocab_size):\n        super().__init__()\n        self.model = Transformer(vocab_size=vocab_size)\n\n    def training_step(self, batch, batch_idx):\n        inputs, target = batch\n        output = self.model(inputs, target)\n        loss = torch.nn.functional.nll_loss(output, target.view(-1))\n\n        # logs metrics for each training_step,\n        # and the average across the epoch, to the progress bar and logger\n        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n        return loss\nThe log() method automatically reduces the requested metrics across a complete epoch and devices.\n\n\n37.3.1.2 Background\n\nHere is the pseudocode of what the log() method does under the hood: \n\nouts = []\nfor batch_idx, batch in enumerate(train_dataloader):\n    # forward\n    loss = training_step(batch, batch_idx)\n    outs.append(loss.detach())\n\n    # clear gradients\n    optimizer.zero_grad()\n    # backward\n    loss.backward()\n    # update parameters\n    optimizer.step()\n\n# note: in reality, we do this incrementally, instead of keeping all outputs in memory\nepoch_metric = torch.mean(torch.stack(outs))\n\nIn the case that you need to make use of all the outputs from each training_step(), override the on_train_epoch_end() method. \n\nclass LightningTransformer(L.LightningModule):\n    def __init__(self, vocab_size):\n        super().__init__()\n        self.model = Transformer(vocab_size=vocab_size)\n        self.training_step_outputs = []\n\n    def training_step(self, batch, batch_idx):\n        inputs, target = batch\n        output = self.model(inputs, target)\n        loss = torch.nn.functional.nll_loss(output, target.view(-1))\n        preds = ...\n        self.training_step_outputs.append(preds)\n        return loss\n\n    def on_train_epoch_end(self):\n        all_preds = torch.stack(self.training_step_outputs)\n        # do something with all preds\n        ...\n        self.training_step_outputs.clear()  # free memory\n\n\n\n37.3.2 Validation Step\n\n37.3.2.1 Basics\nTo activate the validation loop while training, override the validation_step() method.\n\nclass LightningTransformer(L.LightningModule):\n    def validation_step(self, batch, batch_idx):\n        inputs, target = batch\n        output = self.model(inputs, target)\n        loss = F.cross_entropy(y_hat, y)\n        self.log(\"val_loss\", loss)\n        return loss\n\n\n37.3.2.2 Background\n\nYou can also run just the validation loop on your validation dataloaders by overriding validation_step() and calling validate().\n\n\nmodel = LightningTransformer(vocab_size=dataset.vocab_size)\ntrainer = L.Trainer()\ntrainer.validate(model)\n\nIn the case that you need to make use of all the outputs from each validation_step(), override the on_validation_epoch_end() method. Note that this method is called before on_train_epoch_end().\n\n\nclass LightningTransformer(L.LightningModule):\n    def __init__(self, vocab_size):\n        super().__init__()\n        self.model = Transformer(vocab_size=vocab_size)\n        self.validation_step_outputs = []\n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        inputs, target = batch\n        output = self.model(inputs, target)\n        loss = torch.nn.functional.nll_loss(output, target.view(-1))\n        pred = ...\n        self.validation_step_outputs.append(pred)\n        return pred\n\n    def on_validation_epoch_end(self):\n        all_preds = torch.stack(self.validation_step_outputs)\n        # do something with all preds\n        ...\n        self.validation_step_outputs.clear()  # free memory\n\n\n\n37.3.3 Test Step\nThe process for enabling a test loop is the same as the process for enabling a validation loop. For this you need to override the test_step() method. The only difference is that the test loop is only called when test() is used. \ndef test_step(self, batch, batch_idx):\n    inputs, target = batch\n    output = self.model(inputs, target)\n    loss = F.cross_entropy(y_hat, y)\n    self.log(\"test_loss\", loss)\n    return loss\n\n\n37.3.4 Predict Step\n\n37.3.4.1 Basics\nBy default, the predict_step() method runs the forward() method. In order to customize this behaviour, simply override the predict_step() method.\n\nclass LightningTransformer(L.LightningModule):\n    def __init__(self, vocab_size):\n        super().__init__()\n        self.model = Transformer(vocab_size=vocab_size)\n\n    def predict_step(self, batch):\n        inputs, target = batch\n        return self.model(inputs, target)\n\n\n37.3.4.2 Background\n\nIf you want to perform inference with the system, you can add a forward method to the LightningModule.\nWhen using forward, you are responsible to call eval() and use the no_grad() context manager.\n\nclass LightningTransformer(L.LightningModule):\n    def __init__(self, vocab_size):\n        super().__init__()\n        self.model = Transformer(vocab_size=vocab_size)\n\n    def forward(self, batch):\n        inputs, target = batch\n        return self.model(inputs, target)\n\n    def training_step(self, batch, batch_idx):\n        inputs, target = batch\n        output = self.model(inputs, target)\n        loss = torch.nn.functional.nll_loss(output, target.view(-1))\n        return loss\n\n    def configure_optimizers(self):\n        return torch.optim.SGD(self.model.parameters(), lr=0.1)\n\n\nmodel = LightningTransformer(vocab_size=dataset.vocab_size)\n\nmodel.eval()\nwith torch.no_grad():\n    batch = dataloader.dataset[0]\n    pred = model(batch)",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Basic Lightning Module</span>"
    ]
  },
  {
    "objectID": "700_lightning_basic.html#lightning-extras",
    "href": "700_lightning_basic.html#lightning-extras",
    "title": "37  Basic Lightning Module",
    "section": "37.4 Lightning Extras",
    "text": "37.4 Lightning Extras\nThis section covers some additional features of Lightning.\n\n37.4.1 Lightning: Save Hyperparameters\nOften times we train many versions of a model. You might share that model or come back to it a few months later at which point it is very useful to know how that model was trained (i.e.: what learning rate, neural network, etc.).\nLightning has a standardized way of saving the information for you in checkpoints and YAML files. The goal here is to improve readability and reproducibility.\nUse save_hyperparameters() within your LightningModule’s __init__ method. It will enable Lightning to store all the provided arguments under the self.hparams attribute. These hyperparameters will also be stored within the model checkpoint, which simplifies model re-instantiation after training.\nclass LitMNIST(L.LightningModule):\n    def __init__(self, layer_1_dim=128, learning_rate=1e-2):\n        super().__init__()\n        # call this to save (layer_1_dim=128, learning_rate=1e-4) to the checkpoint\n        self.save_hyperparameters()\n\n        # equivalent\n        self.save_hyperparameters(\"layer_1_dim\", \"learning_rate\")\n\n        # Now possible to access layer_1_dim from hparams\n        self.hparams.layer_1_dim\n\n\n37.4.2 Lightning: Model Loading\nLightningModules that have hyperparameters automatically saved with save_hyperparameters() can conveniently be loaded and instantiated directly from a checkpoint with load_from_checkpoint():\n\n# to load specify the other args\nmodel = LitMNIST.load_from_checkpoint(PATH, loss_fx=torch.nn.SomeOtherLoss, generator_network=MyGenerator())",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Basic Lightning Module</span>"
    ]
  },
  {
    "objectID": "700_lightning_basic.html#starter-example-linear-neural-network",
    "href": "700_lightning_basic.html#starter-example-linear-neural-network",
    "title": "37  Basic Lightning Module",
    "section": "37.5 Starter Example: Linear Neural Network",
    "text": "37.5 Starter Example: Linear Neural Network\nWe will use the LightningModule to create a simple neural network for regression. It will be implemented as the LightningBasic class.\n\n37.5.1 Hidden Layers\nTo specify the number of hidden layers, we will use the hyperparameter l1 and the function get_hidden_sizes() [DOC] from the spotpython package.\n\nfrom spotpython.hyperparameters.architecture import get_hidden_sizes\n_L_in = 10\nl1 = 20\nmax_n = 4\nget_hidden_sizes(_L_in, l1, max_n)\n\n[20, 10, 10, 5]\n\n\n\n\n37.5.2 Hyperparameters\nThe argument l1 will be treated as a hyperparameter, so it will be tuned in the following steps. Besides l1, additonal hyperparameters are act_fn and dropout_prob.\nThe arguments _L_in, _L_out, and _torchmetric are not hyperparameters, but are needed to create the network. The first two are specified by the data and the latter by user preferences (the desired evaluation metric).\n\n\n37.5.3 The LightningBasic Class\n\nimport lightning as L\nimport torch\nimport torch.nn.functional as F\nimport torchmetrics.functional.regression\nfrom torch import nn\nfrom spotpython.hyperparameters.architecture import get_hidden_sizes\n\nclass LightningBasic(L.LightningModule):\n    def __init__(\n    self,\n    l1: int,\n    act_fn: nn.Module,\n    dropout_prob: float,\n    _L_in: int,\n    _L_out: int,\n    _torchmetric: str,\n    *args,\n    **kwargs):\n        super().__init__()\n        self._L_in = _L_in\n        self._L_out = _L_out\n        self._torchmetric = _torchmetric\n        self.metric = getattr(torchmetrics.functional.regression, _torchmetric)\n        # _L_in and _L_out are not hyperparameters, but are needed to create the network\n        # _torchmetric is not a hyperparameter, but is needed to calculate the loss\n        self.save_hyperparameters(ignore=[\"_L_in\", \"_L_out\", \"_torchmetric\"])\n        # set dummy input array for Tensorboard Graphs\n        # set log_graph=True in Trainer to see the graph (in traintest.py)\n        hidden_sizes = get_hidden_sizes(_L_in=self._L_in, l1=l1, max_n=4)\n        # Create the network based on the specified hidden sizes\n        layers = []\n        layer_sizes = [self._L_in] + hidden_sizes\n        layer_size_last = layer_sizes[0]\n        for layer_size in layer_sizes[1:]:\n            layers += [\n                nn.Linear(layer_size_last, layer_size),\n                self.hparams.act_fn,\n                nn.Dropout(self.hparams.dropout_prob),\n            ]\n            layer_size_last = layer_size\n        layers += [nn.Linear(layer_sizes[-1], self._L_out)]\n        # nn.Sequential summarizes a list of modules into a single module,\n        # applying them in sequence\n        self.layers = nn.Sequential(*layers)\n\n    def _calculate_loss(self, batch):\n        x, y = batch\n        y = y.view(len(y), 1)\n        y_hat = self.layers(x)\n        loss = self.metric(y_hat, y)\n        return loss\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        return self.layers(x)\n\n    def training_step(self, batch: tuple) -&gt; torch.Tensor:\n        loss = self._calculate_loss(batch)\n        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n        return loss\n\n    def validation_step(self, batch: tuple) -&gt; torch.Tensor:\n        loss = self._calculate_loss(batch)\n        # logs metrics for each training_step,\n        # and the average across the epoch, to the progress bar and logger\n        self.log(\"val_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n        return loss\n\n    def test_step(self, batch, batch_idx):\n        loss = self._calculate_loss(batch)\n        # logs metrics for each training_step,\n        # and the average across the epoch, to the progress bar and logger\n        self.log(\"test_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n        return loss\n\n    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n        x, _ = batch\n        y_hat = self.layers(x)\n        return y_hat\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.layers.parameters(), lr=0.02)\n\nWe can instantiate the LightningBasic class as follows:\n\nmodel_base = LightningBasic(\n    l1=20,\n    act_fn=nn.ReLU(),\n    dropout_prob=0.01,\n    _L_in=10,\n    _L_out=1,\n    _torchmetric=\"mean_squared_error\")\n\nIt has the following structure:\n\nprint(model_base)\n\nLightningBasic(\n  (layers): Sequential(\n    (0): Linear(in_features=10, out_features=20, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.01, inplace=False)\n    (3): Linear(in_features=20, out_features=10, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.01, inplace=False)\n    (6): Linear(in_features=10, out_features=10, bias=True)\n    (7): ReLU()\n    (8): Dropout(p=0.01, inplace=False)\n    (9): Linear(in_features=10, out_features=5, bias=True)\n    (10): ReLU()\n    (11): Dropout(p=0.01, inplace=False)\n    (12): Linear(in_features=5, out_features=1, bias=True)\n  )\n)\n\n\n\nfrom spotpython.plot.xai import viz_net\nviz_net(net=model_base,\n    device=\"cpu\",\n    filename=\"model_architecture700\", format=\"png\")\n\n\n\n\nModel architecture\n\n\n\n\n37.5.4 The Data Set: Diabetes\nWe will use the Diabetes [DOC] data set from the spotpython package, which is a PyTorch Dataset for regression based on a data set from scikit-learn. It consists of DataFrame entries, which were converted to PyTorch tensors.\nTen baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements were obtained for each of n = 442 diabetes patients, as well as the response of interest, a quantitative measure of disease progression one year after baseline.\nThe Diabetes data set has the following properties:\n\nNumber of Instances: 442\nNumber of Attributes: First 10 columns are numeric predictive values.\nTarget: Column 11 is a quantitative measure of disease progression one year after baseline.\nAttribute Information:\n\nage age in years\nsex\nbmi body mass index\nbp average blood pressure\ns1 tc, total serum cholesterol\ns2 ldl, low-density lipoproteins\ns3 hdl, high-density lipoproteins\ns4 tch, total cholesterol / HDL\ns5 ltg, possibly log of serum triglycerides level\ns6 glu, blood sugar level\n\n\n\nfrom torch.utils.data import DataLoader\nfrom spotpython.data.diabetes import Diabetes\nimport torch\ndataset = Diabetes(feature_type=torch.float32, target_type=torch.float32)\n# Set batch size for DataLoader to 2 for demonstration purposes\nbatch_size = 2\ndataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\nfor batch in dataloader:\n    inputs, targets = batch\n    print(f\"Batch Size: {inputs.size(0)}\")\n    print(\"---------------\")\n    print(f\"Inputs: {inputs}\")\n    print(f\"Targets: {targets}\")\n    break\n\nBatch Size: 2\n---------------\nInputs: tensor([[ 0.0381,  0.0507,  0.0617,  0.0219, -0.0442, -0.0348, -0.0434, -0.0026,\n          0.0199, -0.0176],\n        [-0.0019, -0.0446, -0.0515, -0.0263, -0.0084, -0.0192,  0.0744, -0.0395,\n         -0.0683, -0.0922]])\nTargets: tensor([151.,  75.])\n\n\n\n\n37.5.5 The DataLoaders\nBefore we can call the Trainer to fit, validate, and test the model, we need to create the DataLoaders for each of these steps. The DataLoaders are used to load the data into the model in batches and need the batch_size.\n \n\nimport torch\nfrom spotpython.data.diabetes import Diabetes\nfrom torch.utils.data import DataLoader\n\nbatch_size = 8\n\ndataset = Diabetes(target_type=torch.float)\ntrain1_set, test_set = torch.utils.data.random_split(dataset, [0.6, 0.4])\ntrain_set, val_set = torch.utils.data.random_split(train1_set, [0.6, 0.4])\nprint(f\"Full Data Set: {len(dataset)}\")\nprint(f\"Train Set: {len(train_set)}\")\nprint(f\"Validation Set: {len(val_set)}\")\nprint(f\"Test Set: {len(test_set)}\")\ntrain_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True)\ntest_loader = DataLoader(test_set, batch_size=batch_size)\nval_loader = DataLoader(val_set, batch_size=batch_size)\n\nFull Data Set: 442\nTrain Set: 160\nValidation Set: 106\nTest Set: 176\n\n\n\n\n37.5.6 The Trainer\nNow we are ready to train the model. We will use the Trainer class from the lightning package. For demonstration purposes, we will train the model for 100 epochs only.\n\nepochs = 100\n\ntrainer = L.Trainer(max_epochs=epochs, enable_progress_bar=True)\ntrainer.fit(model=model_base, train_dataloaders=train_loader)\n\n\n\n\n\ntrainer.validate(model_base, val_loader)\n\n\n# automatically loads the best weights for you\nout = trainer.test(model_base, test_loader, verbose=True)\n\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃        Test metric        ┃       DataLoader 0        ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│      test_loss_epoch      │     2963.13427734375      │\n└───────────────────────────┴───────────────────────────┘\n\n\n\n\nyhat = trainer.predict(model_base, test_loader)\n# convert the list of tensors to a numpy array\nyhat = torch.cat(yhat).numpy()\nyhat.shape\n\n\n\n37.5.7 Using a DataModule\nInstead of creating the three DataLoaders manually, we can use the LightDataModule class from the spotpython package.\n\nfrom spotpython.data.lightdatamodule import LightDataModule\ndataset = Diabetes(target_type=torch.float)\ndata_module = LightDataModule(dataset=dataset, batch_size=5, test_size=0.4)\ndata_module.setup()\n\nThere is a minor difference in the sizes of the data sets due to the random split as can be seen in the following code:\n\nprint(f\"Full Data Set: {len(dataset)}\")\nprint(f\"Training set size: {len(data_module.data_train)}\")\nprint(f\"Validation set size: {len(data_module.data_val)}\")\nprint(f\"Test set size: {len(data_module.data_test)}\")\n\nFull Data Set: 442\nTraining set size: 160\nValidation set size: 106\nTest set size: 177\n\n\nThe DataModule can be used to train the model as follows:\n\ntrainer = L.Trainer(max_epochs=epochs, enable_progress_bar=False)\ntrainer.fit(model=model_base, datamodule=data_module)\n\n\ntrainer.validate(model=model_base, datamodule=data_module, verbose=True, ckpt_path=None)\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃      Validate metric      ┃       DataLoader 0        ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│      val_loss_epoch       │       4265.01171875       │\n└───────────────────────────┴───────────────────────────┘\n\n\n\n[{'val_loss_epoch': 4265.01171875}]\n\n\n\ntrainer.test(model=model_base, datamodule=data_module, verbose=True, ckpt_path=None)\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃        Test metric        ┃       DataLoader 0        ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│      test_loss_epoch      │     3981.759521484375     │\n└───────────────────────────┴───────────────────────────┘\n\n\n\n[{'test_loss_epoch': 3981.759521484375}]",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Basic Lightning Module</span>"
    ]
  },
  {
    "objectID": "700_lightning_basic.html#using-spotpython-with-pytorch-lightning",
    "href": "700_lightning_basic.html#using-spotpython-with-pytorch-lightning",
    "title": "37  Basic Lightning Module",
    "section": "37.6 Using spotpython with Pytorch Lightning",
    "text": "37.6 Using spotpython with Pytorch Lightning\n\nimport os\nfrom math import inf\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom spotpython.data.diabetes import Diabetes\nfrom spotpython.hyperdict.light_hyper_dict import LightHyperDict\nfrom spotpython.fun.hyperlight import HyperLight\nfrom spotpython.utils.init import (fun_control_init, surrogate_control_init, design_control_init)\nfrom spotpython.utils.eda import print_exp_table, print_res_table\nfrom spotpython.spot import Spot\nfrom spotpython.utils.file import get_experiment_filename\n\n\nPREFIX=\"700\"\ndata_set = Diabetes()\nfun_control = fun_control_init(\n    PREFIX=PREFIX,\n    save_experiment=True,\n    fun_evals=inf,\n    fun_repeats=2,\n    max_time=1,\n    data_set=data_set,\n    core_model_name=\"light.regression.NNLinearRegressor\",\n    hyperdict=LightHyperDict,\n    _L_in=10,\n    _L_out=1,\n    TENSORBOARD_CLEAN=True,\n    tensorboard_log=True,\n    noise=True,\n    ocba_delta = 1,  )\nfun = HyperLight().fun\nfrom spotpython.hyperparameters.values import set_hyperparameter\nset_hyperparameter(fun_control, \"optimizer\", [ \"Adadelta\", \"Adam\", \"Adamax\"])\nset_hyperparameter(fun_control, \"l1\", [3,4])\nset_hyperparameter(fun_control, \"epochs\", [3,7])\nset_hyperparameter(fun_control, \"batch_size\", [4,11])\nset_hyperparameter(fun_control, \"dropout_prob\", [0.0, 0.025])\nset_hyperparameter(fun_control, \"patience\", [2,3])\n\ndesign_control = design_control_init(init_size=10, repeats=2)\n\nprint_exp_table(fun_control)\n\nspot_tuner = Spot(fun=fun,fun_control=fun_control, design_control=design_control)\nres = spot_tuner.run()\nspot_tuner.plot_progress()\nprint_res_table(spot_tuner)\n\nMoving TENSORBOARD_PATH: runs/ to TENSORBOARD_PATH_OLD: runs_OLD/runs_2025_06_15_12_55_53_0\nCreated spot_tensorboard_path: runs/spot_logs/700_maans08_2025-06-15_12-55-53 for SummaryWriter()\nmodule_name: light\nsubmodule_name: regression\nmodel_name: NNLinearRegressor\n| name           | type   | default   |   lower |   upper | transform             |\n|----------------|--------|-----------|---------|---------|-----------------------|\n| l1             | int    | 3         |     3   |   4     | transform_power_2_int |\n| epochs         | int    | 4         |     3   |   7     | transform_power_2_int |\n| batch_size     | int    | 4         |     4   |  11     | transform_power_2_int |\n| act_fn         | factor | ReLU      |     0   |   5     | None                  |\n| optimizer      | factor | SGD       |     0   |   2     | None                  |\n| dropout_prob   | float  | 0.01      |     0   |   0.025 | None                  |\n| lr_mult        | float  | 1.0       |     0.1 |  10     | None                  |\n| patience       | int    | 2         |     2   |   3     | transform_power_2_int |\n| batch_norm     | factor | 0         |     0   |   1     | None                  |\n| initialization | factor | Default   |     0   |   4     | None                  |\nExperiment saved to 700_exp.pkl\n\n\ntrain_model result: {'val_loss': 23075.09765625, 'hp_metric': 23075.09765625}\n\n\ntrain_model result: {'val_loss': 23175.75, 'hp_metric': 23175.75}\n\n\ntrain_model result: {'val_loss': 3110.947021484375, 'hp_metric': 3110.947021484375}\n\n\ntrain_model result: {'val_loss': 3212.389404296875, 'hp_metric': 3212.389404296875}\n\n\ntrain_model result: {'val_loss': 4957.79296875, 'hp_metric': 4957.79296875}\n\n\ntrain_model result: {'val_loss': 4993.95263671875, 'hp_metric': 4993.95263671875}\n\n\ntrain_model result: {'val_loss': 24098.697265625, 'hp_metric': 24098.697265625}\n\n\ntrain_model result: {'val_loss': 23989.583984375, 'hp_metric': 23989.583984375}\n\n\ntrain_model result: {'val_loss': 22617.146484375, 'hp_metric': 22617.146484375}\n\n\ntrain_model result: {'val_loss': 22949.05859375, 'hp_metric': 22949.05859375}\n\n\ntrain_model result: {'val_loss': 4575.27001953125, 'hp_metric': 4575.27001953125}\n\n\ntrain_model result: {'val_loss': 4273.986328125, 'hp_metric': 4273.986328125}\n\n\ntrain_model result: {'val_loss': 21430.103515625, 'hp_metric': 21430.103515625}\n\n\ntrain_model result: {'val_loss': 21671.5234375, 'hp_metric': 21671.5234375}\n\n\ntrain_model result: {'val_loss': 3811.26171875, 'hp_metric': 3811.26171875}\n\n\ntrain_model result: {'val_loss': 4142.75537109375, 'hp_metric': 4142.75537109375}\n\n\ntrain_model result: {'val_loss': 20498.853515625, 'hp_metric': 20498.853515625}\n\n\ntrain_model result: {'val_loss': 20785.01953125, 'hp_metric': 20785.01953125}\n\n\ntrain_model result: {'val_loss': 24013.759765625, 'hp_metric': 24013.759765625}\ntrain_model result: {'val_loss': 23966.04296875, 'hp_metric': 23966.04296875}\n\n\ntrain_model result: {'val_loss': 4272.42431640625, 'hp_metric': 4272.42431640625}\n\n\ntrain_model result: {'val_loss': 23667.060546875, 'hp_metric': 23667.060546875}\ntrain_model result: {'val_loss': 23240.486328125, 'hp_metric': 23240.486328125}\nspotpython tuning: 3110.947021484375 [#---------] 6.03% \n\n\ntrain_model result: {'val_loss': 4224.5546875, 'hp_metric': 4224.5546875}\n\n\ntrain_model result: {'val_loss': nan, 'hp_metric': nan}\ntrain_model result: {'val_loss': nan, 'hp_metric': nan}\nspotpython tuning: 3110.947021484375 [#---------] 10.77% \n\n\ntrain_model result: {'val_loss': 4110.9140625, 'hp_metric': 4110.9140625}\n\n\ntrain_model result: {'val_loss': 3379.241943359375, 'hp_metric': 3379.241943359375}\ntrain_model result: {'val_loss': 3240.904541015625, 'hp_metric': 3240.904541015625}\nspotpython tuning: 3110.947021484375 [##--------] 17.75% \n\n\ntrain_model result: {'val_loss': 3184.6337890625, 'hp_metric': 3184.6337890625}\n\n\ntrain_model result: {'val_loss': 3268.97607421875, 'hp_metric': 3268.97607421875}\ntrain_model result: {'val_loss': 3201.219970703125, 'hp_metric': 3201.219970703125}\nspotpython tuning: 3110.947021484375 [##--------] 23.94% \n\n\ntrain_model result: {'val_loss': 2953.638916015625, 'hp_metric': 2953.638916015625}\n\n\ntrain_model result: {'val_loss': 22122.26171875, 'hp_metric': 22122.26171875}\n\n\ntrain_model result: {'val_loss': 22847.4296875, 'hp_metric': 22847.4296875}\nspotpython tuning: 2953.638916015625 [###-------] 31.12% \n\n\ntrain_model result: {'val_loss': 3112.65087890625, 'hp_metric': 3112.65087890625}\n\n\ntrain_model result: {'val_loss': 5882.8837890625, 'hp_metric': 5882.8837890625}\ntrain_model result: {'val_loss': 3231.22412109375, 'hp_metric': 3231.22412109375}\nspotpython tuning: 2953.638916015625 [####------] 39.40% \n\n\ntrain_model result: {'val_loss': 3024.216064453125, 'hp_metric': 3024.216064453125}\n\n\ntrain_model result: {'val_loss': 5045.22265625, 'hp_metric': 5045.22265625}\n\n\ntrain_model result: {'val_loss': 5491.28515625, 'hp_metric': 5491.28515625}\nspotpython tuning: 2953.638916015625 [#####-----] 47.33% \n\n\ntrain_model result: {'val_loss': 2919.887451171875, 'hp_metric': 2919.887451171875}\n\n\ntrain_model result: {'val_loss': 3178.40576171875, 'hp_metric': 3178.40576171875}\ntrain_model result: {'val_loss': 3674.564208984375, 'hp_metric': 3674.564208984375}\nspotpython tuning: 2919.887451171875 [#####-----] 54.54% \n\n\ntrain_model result: {'val_loss': 5248.11083984375, 'hp_metric': 5248.11083984375}\n\n\ntrain_model result: {'val_loss': 23896.75, 'hp_metric': 23896.75}\n\n\ntrain_model result: {'val_loss': 23868.7734375, 'hp_metric': 23868.7734375}\nspotpython tuning: 2919.887451171875 [######----] 61.66% \n\n\ntrain_model result: {'val_loss': 3221.319091796875, 'hp_metric': 3221.319091796875}\n\n\ntrain_model result: {'val_loss': 6406.51806640625, 'hp_metric': 6406.51806640625}\n\n\ntrain_model result: {'val_loss': 23078.724609375, 'hp_metric': 23078.724609375}\nspotpython tuning: 2919.887451171875 [#######---] 69.66% \n\n\ntrain_model result: {'val_loss': 3777.274658203125, 'hp_metric': 3777.274658203125}\n\n\ntrain_model result: {'val_loss': 7301.94140625, 'hp_metric': 7301.94140625}\n\n\ntrain_model result: {'val_loss': 3375.69091796875, 'hp_metric': 3375.69091796875}\nspotpython tuning: 2919.887451171875 [########--] 75.87% \n\n\ntrain_model result: {'val_loss': 3103.47314453125, 'hp_metric': 3103.47314453125}\n\n\ntrain_model result: {'val_loss': 24102.3203125, 'hp_metric': 24102.3203125}\n\n\ntrain_model result: {'val_loss': 23656.103515625, 'hp_metric': 23656.103515625}\nspotpython tuning: 2919.887451171875 [########--] 82.47% \n\n\ntrain_model result: {'val_loss': 2990.13037109375, 'hp_metric': 2990.13037109375}\ntrain_model result: {'val_loss': nan, 'hp_metric': nan}\ntrain_model result: {'val_loss': nan, 'hp_metric': nan}\nspotpython tuning: 2919.887451171875 [#########-] 87.06% \n\n\ntrain_model result: {'val_loss': 3054.12451171875, 'hp_metric': 3054.12451171875}\ntrain_model result: {'val_loss': nan, 'hp_metric': nan}\ntrain_model result: {'val_loss': nan, 'hp_metric': nan}\nspotpython tuning: 2919.887451171875 [#########-] 92.00% \n\n\ntrain_model result: {'val_loss': 3321.84375, 'hp_metric': 3321.84375}\ntrain_model result: {'val_loss': nan, 'hp_metric': nan}\ntrain_model result: {'val_loss': nan, 'hp_metric': nan}\nspotpython tuning: 2919.887451171875 [##########] 96.70% \n\n\ntrain_model result: {'val_loss': 3117.81005859375, 'hp_metric': 3117.81005859375}\n\n\ntrain_model result: {'val_loss': 4042.087158203125, 'hp_metric': 4042.087158203125}\ntrain_model result: {'val_loss': 3977.217041015625, 'hp_metric': 3977.217041015625}\nspotpython tuning: 2919.887451171875 [##########] 100.00% Done...\n\nExperiment saved to 700_res.pkl\n\n\n\n\n\n\n\n\n\n| name           | type   | default   |   lower |   upper | tuned              | transform             |   importance | stars   |\n|----------------|--------|-----------|---------|---------|--------------------|-----------------------|--------------|---------|\n| l1             | int    | 3         |     3.0 |     4.0 | 3.0                | transform_power_2_int |       100.00 | ***     |\n| epochs         | int    | 4         |     3.0 |     7.0 | 5.0                | transform_power_2_int |         0.00 |         |\n| batch_size     | int    | 4         |     4.0 |    11.0 | 6.0                | transform_power_2_int |         1.17 | *       |\n| act_fn         | factor | ReLU      |     0.0 |     5.0 | ReLU               | None                  |         0.00 |         |\n| optimizer      | factor | SGD       |     0.0 |     2.0 | Adadelta           | None                  |        15.10 | *       |\n| dropout_prob   | float  | 0.01      |     0.0 |   0.025 | 0.0184251494885258 | None                  |         1.00 | .       |\n| lr_mult        | float  | 1.0       |     0.1 |    10.0 | 3.1418668140600845 | None                  |         0.00 |         |\n| patience       | int    | 2         |     2.0 |     3.0 | 3.0                | transform_power_2_int |         0.04 |         |\n| batch_norm     | factor | 0         |     0.0 |     1.0 | 0                  | None                  |         0.03 |         |\n| initialization | factor | Default   |     0.0 |     4.0 | kaiming_normal     | None                  |         0.11 | .       |",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Basic Lightning Module</span>"
    ]
  },
  {
    "objectID": "701_lightning_details.html",
    "href": "701_lightning_details.html",
    "title": "38  Details of the Lightning Module Integration in spotpython",
    "section": "",
    "text": "38.1 Introduction\nBased on the Diabetes Data set and the NNLinearRegressor model, we will provide details on the integration of the Lightning module in spotpython.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Details of the Lightning Module Integration in spotpython</span>"
    ]
  },
  {
    "objectID": "701_lightning_details.html#introduction",
    "href": "701_lightning_details.html#introduction",
    "title": "38  Details of the Lightning Module Integration in spotpython",
    "section": "",
    "text": "Section 38.2: The Hyperlight class provides the fun method, which takes X and fun_control as arguments. It calls the train_model method.\nSection 38.3: The train_model method trains the model and returns the loss.\nSection 38.4: The Trainer class is used to train the model and validate it. It also uses the LightDataModule class to load the data.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Details of the Lightning Module Integration in spotpython</span>"
    ]
  },
  {
    "objectID": "701_lightning_details.html#sec-hyperlight-fun",
    "href": "701_lightning_details.html#sec-hyperlight-fun",
    "title": "38  Details of the Lightning Module Integration in spotpython",
    "section": "38.2 1. spotpython.fun.hyperlight.HyperLight.fun()",
    "text": "38.2 1. spotpython.fun.hyperlight.HyperLight.fun()\nThe class Hyperlight provides the method fun, which takes X (np.ndarray) and fun_control (dict) as arguments. It calls the\n\nfrom math import inf\nimport numpy as np\nfrom spotpython.data.diabetes import Diabetes\nfrom spotpython.hyperdict.light_hyper_dict import LightHyperDict\nfrom spotpython.fun.hyperlight import HyperLight\nfrom spotpython.utils.init import fun_control_init\nfrom spotpython.utils.eda import print_exp_table\nfrom spotpython.spot import Spot\nfrom spotpython.hyperparameters.values import get_default_hyperparameters_as_array\n\nPREFIX=\"000\"\n\ndata_set = Diabetes()\n\nfun_control = fun_control_init(\n    PREFIX=PREFIX,\n    save_experiment=True,\n    fun_evals=inf,\n    max_time=1,\n    data_set = data_set,\n    core_model_name=\"light.regression.NNLinearRegressor\",\n    hyperdict=LightHyperDict,\n    _L_in=10,\n    _L_out=1,\n    TENSORBOARD_CLEAN=True,\n    tensorboard_log=True,\n    seed=42,)\n\nprint_exp_table(fun_control)\n\nX = get_default_hyperparameters_as_array(fun_control)\n# set epochs to 2^8:\n# X[0, 1] = 8\n# set patience to 2^10:\n# X[0, 7] = 10\n\nprint(f\"X: {X}\")\n# combine X and X to a np.array with shape (2, n_hyperparams)\n# so that two values are returned\nX = np.vstack((X, X, X))\nprint(f\"X: {X}\")\n\n\nhyper_light = HyperLight(seed=125, log_level=50)\nhyper_light.fun(X, fun_control)\n\n\nUsing the same seed:\n\n\nhyper_light = HyperLight(seed=125, log_level=50)\nhyper_light.fun(X, fun_control)\n\n\nUsing a different seed:\n\n\nhyper_light = HyperLight(seed=123, log_level=50)\nhyper_light.fun(X, fun_control)",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Details of the Lightning Module Integration in spotpython</span>"
    ]
  },
  {
    "objectID": "701_lightning_details.html#sec-trainmodel",
    "href": "701_lightning_details.html#sec-trainmodel",
    "title": "38  Details of the Lightning Module Integration in spotpython",
    "section": "38.3 2. spotpython.light.trainmodel.train_model()",
    "text": "38.3 2. spotpython.light.trainmodel.train_model()\n\nfrom math import inf\nimport numpy as np\nfrom spotpython.data.diabetes import Diabetes\nfrom spotpython.hyperdict.light_hyper_dict import LightHyperDict\nfrom spotpython.utils.init import fun_control_init\nfrom spotpython.utils.eda import print_exp_table\nfrom spotpython.hyperparameters.values import get_default_hyperparameters_as_array\nfrom spotpython.hyperparameters.values import assign_values, generate_one_config_from_var_dict, get_var_name\nfrom spotpython.light.trainmodel import train_model\nimport pprint\n\nPREFIX=\"000\"\n\ndata_set = Diabetes()\n\nfun_control = fun_control_init(\n    PREFIX=PREFIX,\n    save_experiment=True,\n    fun_evals=inf,\n    max_time=1,\n    data_set = data_set,\n    core_model_name=\"light.regression.NNLinearRegressor\",\n    hyperdict=LightHyperDict,\n    _L_in=10,\n    _L_out=1,\n    TENSORBOARD_CLEAN=True,\n    tensorboard_log=True,\n    seed=42,)\n\nprint_exp_table(fun_control)\n\nX = get_default_hyperparameters_as_array(fun_control)\n# set epochs to 2^8:\n# X[0, 1] = 8\n# set patience to 2^10:\n# X[0, 7] = 10\n\nprint(f\"X: {X}\")\n# combine X and X to a np.array with shape (2, n_hyperparams)\n# so that two values are returned\nX = np.vstack((X, X))\nvar_dict = assign_values(X, get_var_name(fun_control))\nfor config in generate_one_config_from_var_dict(var_dict, fun_control):\n    pprint.pprint(config)\n    y = train_model(config, fun_control)",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Details of the Lightning Module Integration in spotpython</span>"
    ]
  },
  {
    "objectID": "701_lightning_details.html#sec-trainer",
    "href": "701_lightning_details.html#sec-trainer",
    "title": "38  Details of the Lightning Module Integration in spotpython",
    "section": "38.4 3. Trainer: fit and validate",
    "text": "38.4 3. Trainer: fit and validate\n\nGenerate the config dictionary:\n\n\nfrom math import inf\nimport numpy as np\nfrom spotpython.data.diabetes import Diabetes\nfrom spotpython.hyperdict.light_hyper_dict import LightHyperDict\nfrom spotpython.utils.init import fun_control_init\nfrom spotpython.utils.eda import print_exp_table\nfrom spotpython.hyperparameters.values import get_default_hyperparameters_as_array\nfrom spotpython.hyperparameters.values import assign_values, generate_one_config_from_var_dict, get_var_name\nfrom spotpython.light.trainmodel import train_model\n\nPREFIX=\"000\"\n\ndata_set = Diabetes()\n\nfun_control = fun_control_init(\n    PREFIX=PREFIX,\n    save_experiment=True,\n    fun_evals=inf,\n    max_time=1,\n    data_set = data_set,\n    core_model_name=\"light.regression.NNLinearRegressor\",\n    hyperdict=LightHyperDict,\n    _L_in=10,\n    _L_out=1,\n    TENSORBOARD_CLEAN=True,\n    tensorboard_log=True,\n    seed=42,)\nprint_exp_table(fun_control)\nX = get_default_hyperparameters_as_array(fun_control)\n# set epochs to 2^8:\nX[0, 1] = 10\n# set patience to 2^10:\nX[0, 7] = 10\nprint(f\"X: {X}\")\nvar_dict = assign_values(X, get_var_name(fun_control))\nconfig = list(generate_one_config_from_var_dict(var_dict, fun_control))[0]\nconfig\n\n\n_L_in = 10\n_L_out = 1\n_L_cond = 0\n_torchmetric = \"mean_squared_error\"\n\n\n38.4.1 Commented: Using the fun_control dictionary\n\n# model = fun_control[\"core_model\"](**config, _L_in=_L_in, _L_out=_L_out, _L_cond=_L_cond, _torchmetric=_torchmetric)\n# model\n\n\n\n38.4.2 Using the source code:\n\nimport lightning as L\nimport torch\nfrom torch import nn\nfrom spotpython.hyperparameters.optimizer import optimizer_handler\nimport torchmetrics.functional.regression\nimport torch.optim as optim\nfrom spotpython.hyperparameters.architecture import get_hidden_sizes\n\n\nclass NNLinearRegressor(L.LightningModule):\n    def __init__(\n        self,\n        l1: int,\n        epochs: int,\n        batch_size: int,\n        initialization: str,\n        act_fn: nn.Module,\n        optimizer: str,\n        dropout_prob: float,\n        lr_mult: float,\n        patience: int,\n        batch_norm: bool,\n        _L_in: int,\n        _L_out: int,\n        _torchmetric: str,\n        *args,\n        **kwargs,\n    ):\n        super().__init__()\n        # Attribute 'act_fn' is an instance of `nn.Module` and is already saved during\n        # checkpointing. It is recommended to ignore them\n        # using `self.save_hyperparameters(ignore=['act_fn'])`\n        # self.save_hyperparameters(ignore=[\"act_fn\"])\n        #\n        self._L_in = _L_in\n        self._L_out = _L_out\n        if _torchmetric is None:\n            _torchmetric = \"mean_squared_error\"\n        self._torchmetric = _torchmetric\n        self.metric = getattr(torchmetrics.functional.regression, _torchmetric)\n        # _L_in and _L_out are not hyperparameters, but are needed to create the network\n        # _torchmetric is not a hyperparameter, but is needed to calculate the loss\n        self.save_hyperparameters(ignore=[\"_L_in\", \"_L_out\", \"_torchmetric\"])\n        # set dummy input array for Tensorboard Graphs\n        # set log_graph=True in Trainer to see the graph (in traintest.py)\n        self.example_input_array = torch.zeros((batch_size, self._L_in))\n        if self.hparams.l1 &lt; 4:\n            raise ValueError(\"l1 must be at least 4\")\n        hidden_sizes = get_hidden_sizes(_L_in=self._L_in, l1=l1, n=10)\n\n        if batch_norm:\n            # Add batch normalization layers\n            layers = []\n            layer_sizes = [self._L_in] + hidden_sizes\n            for i in range(len(layer_sizes) - 1):\n                current_layer_size = layer_sizes[i]\n                next_layer_size = layer_sizes[i + 1]\n                layers += [\n                    nn.Linear(current_layer_size, next_layer_size),\n                    nn.BatchNorm1d(next_layer_size),\n                    self.hparams.act_fn,\n                    nn.Dropout(self.hparams.dropout_prob),\n                ]\n            layers += [nn.Linear(layer_sizes[-1], self._L_out)]\n        else:\n            layers = []\n            layer_sizes = [self._L_in] + hidden_sizes\n            for i in range(len(layer_sizes) - 1):\n                current_layer_size = layer_sizes[i]\n                next_layer_size = layer_sizes[i + 1]\n                layers += [\n                    nn.Linear(current_layer_size, next_layer_size),\n                    self.hparams.act_fn,\n                    nn.Dropout(self.hparams.dropout_prob),\n                ]\n            layers += [nn.Linear(layer_sizes[-1], self._L_out)]\n\n        # Wrap the layers into a sequential container\n        self.layers = nn.Sequential(*layers)\n\n        # Initialization (Xavier, Kaiming, or Default)\n        self.apply(self._init_weights)\n\n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            if self.hparams.initialization == \"xavier_uniform\":\n                nn.init.xavier_uniform_(module.weight)\n            elif self.hparams.initialization == \"xavier_normal\":\n                nn.init.xavier_normal_(module.weight)\n            elif self.hparams.initialization == \"kaiming_uniform\":\n                nn.init.kaiming_uniform_(module.weight)\n            elif self.hparams.initialization == \"kaiming_normal\":\n                nn.init.kaiming_normal_(module.weight)\n            else:  # \"Default\"\n                nn.init.uniform_(module.weight)\n            if module.bias is not None:\n                nn.init.zeros_(module.bias)\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Performs a forward pass through the model.\n\n        Args:\n            x (torch.Tensor): A tensor containing a batch of input data.\n\n        Returns:\n            torch.Tensor: A tensor containing the output of the model.\n\n        \"\"\"\n        x = self.layers(x)\n        return x\n\n    def _calculate_loss(self, batch):\n        \"\"\"\n        Calculate the loss for the given batch.\n\n        Args:\n            batch (tuple): A tuple containing a batch of input data and labels.\n            mode (str, optional): The mode of the model. Defaults to \"train\".\n\n        Returns:\n            torch.Tensor: A tensor containing the loss for this batch.\n\n        \"\"\"\n        x, y = batch\n        y = y.view(len(y), 1)\n        y_hat = self(x)\n        loss = self.metric(y_hat, y)\n        return loss\n\n    def training_step(self, batch: tuple) -&gt; torch.Tensor:\n        \"\"\"\n        Performs a single training step.\n\n        Args:\n            batch (tuple): A tuple containing a batch of input data and labels.\n\n        Returns:\n            torch.Tensor: A tensor containing the loss for this batch.\n\n        \"\"\"\n        loss = self._calculate_loss(batch)\n        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=False)\n        return loss\n\n    def validation_step(self, batch: tuple, batch_idx: int, prog_bar: bool = False) -&gt; torch.Tensor:\n        \"\"\"\n        Performs a single validation step.\n\n        Args:\n            batch (tuple): A tuple containing a batch of input data and labels.\n            batch_idx (int): The index of the current batch.\n            prog_bar (bool, optional): Whether to display the progress bar. Defaults to False.\n\n        Returns:\n            torch.Tensor: A tensor containing the loss for this batch.\n\n        \"\"\"\n        loss = self._calculate_loss(batch)\n        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=prog_bar)\n        self.log(\"hp_metric\", loss, on_step=False, on_epoch=True, prog_bar=prog_bar)\n        return loss\n\n    def test_step(self, batch: tuple, batch_idx: int, prog_bar: bool = False) -&gt; torch.Tensor:\n        \"\"\"\n        Performs a single test step.\n\n        Args:\n            batch (tuple): A tuple containing a batch of input data and labels.\n            batch_idx (int): The index of the current batch.\n            prog_bar (bool, optional): Whether to display the progress bar. Defaults to False.\n\n        Returns:\n            torch.Tensor: A tensor containing the loss for this batch.\n        \"\"\"\n        loss = self._calculate_loss(batch)\n        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=prog_bar)\n        self.log(\"hp_metric\", loss, on_step=False, on_epoch=True, prog_bar=prog_bar)\n        return loss\n\n    def predict_step(self, batch: tuple, batch_idx: int, prog_bar: bool = False) -&gt; torch.Tensor:\n        \"\"\"\n        Performs a single prediction step.\n\n        Args:\n            batch (tuple): A tuple containing a batch of input data and labels.\n            batch_idx (int): The index of the current batch.\n            prog_bar (bool, optional): Whether to display the progress bar. Defaults to False.\n\n        Returns:\n            torch.Tensor: A tensor containing the prediction for this batch.\n        \"\"\"\n        x, y = batch\n        yhat = self(x)\n        y = y.view(len(y), 1)\n        yhat = yhat.view(len(yhat), 1)\n        print(f\"Predict step x: {x}\")\n        print(f\"Predict step y: {y}\")\n        print(f\"Predict step y_hat: {yhat}\")\n        # pred_loss = F.mse_loss(y_hat, y)\n        # pred loss not registered\n        # self.log(\"pred_loss\", pred_loss, prog_bar=prog_bar)\n        # self.log(\"hp_metric\", pred_loss, prog_bar=prog_bar)\n        # MisconfigurationException: You are trying to `self.log()`\n        # but the loop's result collection is not registered yet.\n        # This is most likely because you are trying to log in a `predict` hook, but it doesn't support logging.\n        # If you want to manually log, please consider using `self.log_dict({'pred_loss': pred_loss})` instead.\n        return (x, y, yhat)\n\n    def configure_optimizers(self) -&gt; torch.optim.Optimizer:\n        \"\"\"\n        Configures the optimizer for the model.\n\n        Notes:\n            The default Lightning way is to define an optimizer as\n            `optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)`.\n            spotpython uses an optimizer handler to create the optimizer, which\n            adapts the learning rate according to the lr_mult hyperparameter as\n            well as other hyperparameters. See `spotpython.hyperparameters.optimizer.py` for details.\n\n        Returns:\n            torch.optim.Optimizer: The optimizer to use during training.\n\n        \"\"\"\n        # optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n        optimizer = optimizer_handler(optimizer_name=self.hparams.optimizer, params=self.parameters(), lr_mult=self.hparams.lr_mult)\n\n        num_milestones = 3  # Number of milestones to divide the epochs\n        milestones = [int(self.hparams.epochs / (num_milestones + 1) * (i + 1)) for i in range(num_milestones)]\n        scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=0.1)  # Decay factor\n\n        lr_scheduler_config = {\n            \"scheduler\": scheduler,\n            \"interval\": \"epoch\",\n            \"frequency\": 1,\n        }\n\n        return {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler_config}\n\n\nmodel = NNLinearRegressor(**config, _L_in=_L_in, _L_out=_L_out, _L_cond=_L_cond, _torchmetric=_torchmetric)\nmodel\n\n\nfrom spotpython.data.lightdatamodule import LightDataModule\nfrom spotpython.data.diabetes import Diabetes\n\ndata_set = Diabetes()\ndm = LightDataModule(\n    dataset=data_set,\n    batch_size=config[\"batch_size\"],\n    test_size=fun_control[\"test_size\"],\n    test_seed=fun_control[\"test_seed\"],\n    scaler=None,\n)\n\n\nUsing callbacks for early stopping:\n\n\nfrom lightning.pytorch.callbacks.early_stopping import EarlyStopping\ncallbacks = [EarlyStopping(monitor=\"val_loss\", patience=config[\"patience\"], mode=\"min\", strict=False, verbose=False)]\n\n\ntimestamp = True\n\nfrom lightning.pytorch.callbacks import ModelCheckpoint\nif not timestamp:\n    # add ModelCheckpoint only if timestamp is False\n    callbacks.append(ModelCheckpoint(dirpath=os.path.join(fun_control[\"CHECKPOINT_PATH\"], config_id), save_last=True))  # Save the last checkpoint\n\n\nfrom spotpython.utils.eda import generate_config_id\nif timestamp:\n    # config id is unique. Since the model is not loaded from a checkpoint,\n    # the config id is generated here with a timestamp.\n    config_id = generate_config_id(config, timestamp=True)\nelse:\n    # config id is not time-dependent and therefore unique,\n    # so that the model can be loaded from a checkpoint,\n    # the config id is generated here without a timestamp.\n    config_id = generate_config_id(config, timestamp=False) + \"_TRAIN\"\n\n\nfrom pytorch_lightning.loggers import TensorBoardLogger\nimport lightning as L\nimport os\ntrainer = L.Trainer(\n    # Where to save models\n    default_root_dir=os.path.join(fun_control[\"CHECKPOINT_PATH\"], config_id),\n    max_epochs=model.hparams.epochs,\n    accelerator=fun_control[\"accelerator\"],\n    devices=fun_control[\"devices\"],\n    strategy=fun_control[\"strategy\"],\n    num_nodes=fun_control[\"num_nodes\"],\n    precision=fun_control[\"precision\"],\n    logger=TensorBoardLogger(save_dir=fun_control[\"TENSORBOARD_PATH\"], version=config_id, default_hp_metric=True, log_graph=fun_control[\"log_graph\"], name=\"\"),\n    callbacks=callbacks,\n    enable_progress_bar=False,\n    num_sanity_val_steps=fun_control[\"num_sanity_val_steps\"],\n    log_every_n_steps=fun_control[\"log_every_n_steps\"],\n    gradient_clip_val=None,\n    gradient_clip_algorithm=\"norm\",\n)\n\n\ntrainer.fit(model=model, datamodule=dm, ckpt_path=None)\n\n\ntrainer.validate(model=model, datamodule=dm, verbose=True, ckpt_path=None)\n\n\n\n38.4.3 DataModule\n\nfrom spotpython.data.lightdatamodule import LightDataModule\nfrom spotpython.data.csvdataset import CSVDataset\nimport torch\ndataset = CSVDataset(csv_file='data.csv', target_column='prognosis', feature_type=torch.long)\ndata_module = LightDataModule(dataset=dataset, batch_size=5, test_size=0.5)\ndata_module.setup()\nprint(f\"Training set size: {len(data_module.data_train)}\")\n\n\nGenerate the config dictionary:\n\n\nfrom math import inf\nimport lightning as L\nimport numpy as np\nimport os\nfrom spotpython.data.diabetes import Diabetes\nfrom spotpython.hyperdict.light_hyper_dict import LightHyperDict\nfrom spotpython.utils.init import fun_control_init\nfrom spotpython.utils.eda import print_exp_table\nfrom spotpython.hyperparameters.values import get_default_hyperparameters_as_array\nfrom spotpython.hyperparameters.values import assign_values, generate_one_config_from_var_dict, get_var_name\nfrom spotpython.light.trainmodel import train_model, generate_config_id_with_timestamp\nfrom pytorch_lightning.loggers import TensorBoardLogger\nfrom lightning.pytorch.callbacks.early_stopping import EarlyStopping\nfrom spotpython.data.lightdatamodule import LightDataModule\nPREFIX=\"000\"\ndata_set = Diabetes()\nfun_control = fun_control_init(\n    PREFIX=PREFIX,\n    save_experiment=True,\n    fun_evals=inf,\n    max_time=1,\n    data_set = data_set,\n    core_model_name=\"light.regression.NNLinearRegressor\",\n    hyperdict=LightHyperDict,\n    _L_in=10,\n    _L_out=1,\n    TENSORBOARD_CLEAN=True,\n    tensorboard_log=True,\n    seed=42,)\nprint_exp_table(fun_control)\nX = get_default_hyperparameters_as_array(fun_control)\n# set epochs to 2^8:\nX[0, 1] = 10\n# set patience to 2^10:\nX[0, 7] = 10\nprint(f\"X: {X}\")\nvar_dict = assign_values(X, get_var_name(fun_control))\nconfig = list(generate_one_config_from_var_dict(var_dict, fun_control))[0]\n_L_in = fun_control[\"_L_in\"]\n_L_out = fun_control[\"_L_out\"]\n_L_cond = fun_control[\"_L_cond\"]\n_torchmetric = fun_control[\"_torchmetric\"]\nmodel = fun_control[\"core_model\"](**config, _L_in=_L_in, _L_out=_L_out, _L_cond=_L_cond, _torchmetric=_torchmetric)\ndm = LightDataModule(\n    dataset=fun_control[\"data_set\"],\n    batch_size=config[\"batch_size\"],\n    num_workers=fun_control[\"num_workers\"],\n    test_size=fun_control[\"test_size\"],\n    test_seed=fun_control[\"test_seed\"],\n    scaler=fun_control[\"scaler\"],\n)\nconfig_id = generate_config_id_with_timestamp(config, timestamp=True)\ncallbacks = [EarlyStopping(monitor=\"val_loss\", patience=config[\"patience\"], mode=\"min\", strict=False, verbose=False)]\ntrainer = L.Trainer(\n    default_root_dir=os.path.join(fun_control[\"CHECKPOINT_PATH\"], config_id),\n    max_epochs=model.hparams.epochs,\n    accelerator=fun_control[\"accelerator\"],\n    devices=fun_control[\"devices\"],\n    strategy=fun_control[\"strategy\"],\n    num_nodes=fun_control[\"num_nodes\"],\n    precision=fun_control[\"precision\"],\n    logger=TensorBoardLogger(save_dir=fun_control[\"TENSORBOARD_PATH\"], version=config_id, default_hp_metric=True, log_graph=fun_control[\"log_graph\"], name=\"\"),\n    callbacks=callbacks,\n    enable_progress_bar=False,\n    num_sanity_val_steps=fun_control[\"num_sanity_val_steps\"],\n    log_every_n_steps=fun_control[\"log_every_n_steps\"],\n    gradient_clip_val=None,\n    gradient_clip_algorithm=\"norm\",\n)\ntrainer.fit(model=model, datamodule=dm, ckpt_path=None)\n\n\nfrom math import inf\nimport lightning as L\nimport numpy as np\nfrom spotpython.data.diabetes import Diabetes\nfrom spotpython.hyperdict.light_hyper_dict import LightHyperDict\nfrom spotpython.utils.init import fun_control_init\nfrom spotpython.hyperparameters.values import assign_values, generate_one_config_from_var_dict, get_var_name\nfrom spotpython.data.lightdatamodule import LightDataModule\nfrom spotpython.utils.scaler import TorchStandardScaler\nPREFIX=\"000\"\ndata_set = Diabetes()\nfun_control = fun_control_init(\n    PREFIX=PREFIX,\n    fun_evals=inf,\n    max_time=1,\n    data_set = data_set,\n    core_model_name=\"light.regression.NNLinearRegressor\",\n    hyperdict=LightHyperDict,\n    _L_in=10,\n    _L_out=1)\nX = np.array([[3.0e+00, 5.0, 4.0e+00, 2.0e+00, 1.1e+01, 1.0e-02, 1.0e+00, 1.0e+01, 0.0e+00,\n  0.0e+00]])\nvar_dict = assign_values(X, get_var_name(fun_control))\nconfig = list(generate_one_config_from_var_dict(var_dict, fun_control))[0]\n_torchmetric = \"mean_squared_error\"\nmodel = fun_control[\"core_model\"](**config, _L_in=10, _L_out=1, _L_cond=None, _torchmetric=_torchmetric)\ndm = LightDataModule(\n    dataset=data_set,\n    batch_size=16,\n    test_size=0.6,\n    scaler=TorchStandardScaler())\ntrainer = L.Trainer(\n    max_epochs=32,\n    enable_progress_bar=False,\n)\ntrainer.fit(model=model, datamodule=dm, ckpt_path=None)\ntrainer.validate(model=model, datamodule=dm, ckpt_path=None)",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Details of the Lightning Module Integration in spotpython</span>"
    ]
  },
  {
    "objectID": "702_lightning_user_datamodule.html",
    "href": "702_lightning_user_datamodule.html",
    "title": "39  User Specified Basic Lightning Module With spotpython",
    "section": "",
    "text": "39.1 Introduction\nThis chapter implements a user-defined DataModule and a user-defined neural network. Remember, that a LightningModule organizes your PyTorch code into six sections:\nThe Trainer automates every required step in a clear and reproducible way. It is the most important part of PyTorch Lightning. It is responsible for training, testing, and validating the model. The Lightning core structure looks like this:\nimport pandas as pd\ndf = pd.read_pickle(\"./userData/Turbo_Charger_Data.pkl\")\ndf = df.drop(columns=[\"M\", \"R\"])\nprint(f\"Features des DataFrames: {df.columns}\")\nprint(df.shape)",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>User Specified Basic Lightning Module With spotpython</span>"
    ]
  },
  {
    "objectID": "702_lightning_user_datamodule.html#introduction",
    "href": "702_lightning_user_datamodule.html#introduction",
    "title": "39  User Specified Basic Lightning Module With spotpython",
    "section": "",
    "text": "Initialization (__init__ and setup()).\nTrain Loop (training_step())\nValidation Loop (validation_step())\nTest Loop (test_step())\nPrediction Loop (predict_step())\nOptimizers and LR Schedulers (configure_optimizers())\n\n\n\n\n39.1.1 Dataset\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom lightning import LightningDataModule\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, random_split\n\nclass UserDataset(Dataset):\n    def __init__(self, data, y_varname=\"N\", x_varnames=None, dtype=torch.float32):\n        \"\"\"\n        Args:\n            data (pd.DataFrame):\n                The user data. for example,\n                generated by the `preprocess_data` function.\n            y_varname (str):\n                The name of the target variable.\n                Default is \"N\".\n            x_varnames (list):\n                The names of the input variables.\n                Default is `None`, which means all columns\n                except the target variable are used.\n            dtype (torch.dtype):\n                The data type for the tensors.\n                Default is `torch.float32`.\n\n        Examples:\n            &gt;&gt;&gt; dataset = UserDataset(data)\n            &gt;&gt;&gt; x, y = dataset[0]\n        \"\"\"\n        self.data = data.reset_index(drop=True)\n        if x_varnames is not None:\n            self.x_varnames = x_varnames\n        else:\n            self.x_varnames = [col for col in self.data.columns if col != y_varname]\n        print(f\"X variables: {self.x_varnames}\")\n        print(f\"Y variable: {y_varname}\")\n        self.y_varname = y_varname\n        self.dtype = dtype\n        self.encoders = {}\n\n        for var in self.x_varnames:\n            if self.data[var].dtype == \"object\" or isinstance(self.data[var][0], str):\n                le = LabelEncoder()\n                self.data[var] = le.fit_transform(self.data[var])\n                self.encoders[var] = le\n\n        if self.data[self.y_varname].dtype == \"object\" or isinstance(self.data[self.y_varname][0], str):\n            le = LabelEncoder()\n            self.data[self.y_varname] = le.fit_transform(self.data[self.y_varname])\n            self.encoders[self.y_varname] = le\n\n        # Convert entire dataset to tensors\n        self.features = torch.tensor(self.data[self.x_varnames].values, dtype=self.dtype)\n        self.targets = torch.tensor(self.data[self.y_varname].values, dtype=self.dtype)\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        return self.features[idx], self.targets[idx]\n\n\ndataset = UserDataset(df)\nx, y = dataset[0]\nprint(x)\nprint(y)\n\n\n\n39.1.2 DataModule\n\nimport lightning as L\nimport torch\nfrom torch.utils.data import DataLoader, random_split, TensorDataset\nfrom typing import Optional\nfrom math import floor\n\n\nclass LightDataModule(L.LightningDataModule):\n    \"\"\"\n    A LightningDataModule for handling data.\n\n    Args:\n        batch_size (int):\n            The batch size. Required.\n        dataset (torch.utils.data.Dataset, optional):\n            The dataset from the torch.utils.data Dataset class.\n            It must implement three functions: __init__, __len__, and __getitem__.\n        test_size (float, optional):\n            The test size. If test_size is float, then train_size is 1 - test_size.\n            If test_size is int, then train_size is len(data_full) - test_size.\n        test_seed (int):\n            The test seed. Defaults to 42.\n        num_workers (int):\n            The number of workers. Defaults to 0.\n        verbosity (int):\n            The verbosity level. Defaults to 0.\n\n    Examples:\n        &gt;&gt;&gt; from spotpython.data.lightdatamodule import LightDataModule\n            from spotpython.data.csvdataset import CSVDataset\n            from spotpython.utils.scaler import TorchStandardScaler\n            import torch\n            # data.csv is simple csv file with 11 samples\n            dataset = CSVDataset(csv_file='data.csv', target_column='prognosis', feature_type=torch.long)\n            scaler = TorchStandardScaler()\n            data_module = LightDataModule(dataset=dataset, batch_size=5, test_size=0.5, scaler=scaler)\n            data_module.setup()\n            print(f\"Training set size: {len(data_module.data_train)}\")\n            print(f\"Validation set size: {len(data_module.data_val)}\")\n            print(f\"Test set size: {len(data_module.data_test)}\")\n            full_train_size: 0.5\n            val_size: 0.25\n            train_size: 0.25\n            test_size: 0.5\n            Training set size: 3\n            Validation set size: 3\n            Test set size: 6\n\n    References:\n        See https://lightning.ai/docs/pytorch/stable/data/datamodule.html\n\n    \"\"\"\n\n    def __init__(\n        self,\n        batch_size: int,\n        dataset: Optional[object] = None,\n        test_size: Optional[float] = None,\n        test_seed: int = 42,\n        num_workers: int = 0,\n        verbosity: int = 0,\n    ):\n        super().__init__()\n        self.batch_size = batch_size\n        self.data_full = dataset\n        self.test_size = test_size\n        self.test_seed = test_seed\n        self.num_workers = num_workers\n        self.verbosity = verbosity\n\n    def prepare_data(self) -&gt; None:\n        \"\"\"Prepares the data for use.\"\"\"\n        # download\n        pass\n\n    def _setup_full_data_provided(self, stage) -&gt; None:\n        full_size = len(self.data_full)\n        test_size = self.test_size\n\n        # consider the case when test_size is a float\n        if isinstance(self.test_size, float):\n            full_train_size = 1.0 - self.test_size\n            val_size = full_train_size * self.test_size\n            train_size = full_train_size - val_size\n        else:\n            # test_size is an int, training size calculation directly based on it\n            full_train_size = full_size - self.test_size\n            val_size = floor(full_train_size * self.test_size / full_size)\n            train_size = full_size - val_size - test_size\n\n        # Assign train/val datasets for use in dataloaders\n        if stage == \"fit\" or stage is None:\n            generator_fit = torch.Generator().manual_seed(self.test_seed)\n            self.data_train, self.data_val, _ = random_split(self.data_full, [train_size, val_size, test_size], generator=generator_fit)\n            if self.verbosity &gt; 0:\n                print(f\"train_size: {train_size}, val_size: {val_size}, test_sie: {test_size} for splitting train & val data.\")\n                print(f\"train samples: {len(self.data_train)}, val samples: {len(self.data_val)} generated for train & val data.\")\n\n        # Assign test dataset for use in dataloader(s)\n        if stage == \"test\" or stage is None:\n            generator_test = torch.Generator().manual_seed(self.test_seed)\n            self.data_test, _, _ = random_split(self.data_full, [test_size, train_size, val_size], generator=generator_test)\n            if self.verbosity &gt; 0:\n                print(f\"train_size: {train_size}, val_size: {val_size}, test_sie: {test_size} for splitting test data.\")\n                print(f\"test samples: {len(self.data_test)} generated for test data.\")\n\n        # Assign pred dataset for use in dataloader(s)\n        if stage == \"predict\" or stage is None:\n            generator_predict = torch.Generator().manual_seed(self.test_seed)\n            self.data_predict, _, _ = random_split(self.data_full, [test_size, train_size, val_size], generator=generator_predict)\n            if self.verbosity &gt; 0:\n                print(f\"train_size: {train_size}, val_size: {val_size}, test_size (= predict_size): {test_size} for splitting predict data.\")\n                print(f\"predict samples: {len(self.data_predict)} generated for train & val data.\")\n    \n\n    def setup(self, stage: Optional[str] = None) -&gt; None:\n        \"\"\"\n        Splits the data for use in training, validation, and testing.\n        Uses torch.utils.data.random_split() to split the data.\n        Splitting is based on the test_size and test_seed.\n        The test_size can be a float or an int.\n        If a spotpython scaler object is defined, the data will be scaled.\n\n        Args:\n            stage (Optional[str]):\n                The current stage. Can be \"fit\" (for training and validation), \"test\" (testing),\n                or None (for all three stages). Defaults to None.\n\n        Examples:\n            &gt;&gt;&gt; from spotpython.data.lightdatamodule import LightDataModule\n                from spotpython.data.csvdataset import CSVDataset\n                import torch\n                dataset = CSVDataset(csv_file='data.csv', target_column='prognosis', feature_type=torch.long)\n                data_module = LightDataModule(dataset=dataset, batch_size=5, test_size=0.5)\n                data_module.setup()\n                print(f\"Training set size: {len(data_module.data_train)}\")\n                Training set size: 3\n\n        \"\"\"\n        self._setup_full_data_provided(stage)\n\n\n    def train_dataloader(self) -&gt; DataLoader:\n        \"\"\"\n        Returns the training dataloader, i.e., a pytorch DataLoader instance\n        using the training dataset.\n\n        Returns:\n            DataLoader: The training dataloader.\n\n        Examples:\n            &gt;&gt;&gt; from spotpython.data.lightdatamodule import LightDataModule\n                from spotpython.data.csvdataset import CSVDataset\n                import torch\n                dataset = CSVDataset(csv_file='data.csv', target_column='prognosis', feature_type=torch.long)\n                data_module = LightDataModule(dataset=dataset, batch_size=5, test_size=0.5)\n                data_module.setup()\n                print(f\"Training set size: {len(data_module.data_train)}\")\n                Training set size: 3\n\n        \"\"\"\n        if self.verbosity &gt; 0:\n            print(f\"LightDataModule.train_dataloader(). data_train size: {len(self.data_train)}\")\n        return DataLoader(self.data_train, batch_size=self.batch_size, num_workers=self.num_workers)\n\n    def val_dataloader(self) -&gt; DataLoader:\n        \"\"\"\n        Returns the validation dataloader, i.e., a pytorch DataLoader instance\n        using the validation dataset.\n\n        Returns:\n            DataLoader: The validation dataloader.\n\n        Examples:\n            &gt;&gt;&gt; from spotpython.data.lightdatamodule import LightDataModule\n                from spotpython.data.csvdataset import CSVDataset\n                import torch\n                dataset = CSVDataset(csv_file='data.csv', target_column='prognosis', feature_type=torch.long)\n                data_module = LightDataModule(dataset=dataset, batch_size=5, test_size=0.5)\n                data_module.setup()\n                print(f\"Training set size: {len(data_module.data_val)}\")\n                Training set size: 3\n        \"\"\"\n        if self.verbosity &gt; 0:\n            print(f\"LightDataModule.val_dataloader(). Val. set size: {len(self.data_val)}\")\n        return DataLoader(self.data_val, batch_size=self.batch_size, num_workers=self.num_workers)\n\n    def test_dataloader(self) -&gt; DataLoader:\n        \"\"\"\n        Returns the test dataloader, i.e., a pytorch DataLoader instance\n        using the test dataset.\n\n        Returns:\n            DataLoader: The test dataloader.\n\n        Examples:\n            &gt;&gt;&gt; from spotpython.data.lightdatamodule import LightDataModule\n                from spotpython.data.csvdataset import CSVDataset\n                import torch\n                dataset = CSVDataset(csv_file='data.csv', target_column='prognosis', feature_type=torch.long)\n                data_module = LightDataModule(dataset=dataset, batch_size=5, test_size=0.5)\n                data_module.setup()\n                print(f\"Test set size: {len(data_module.data_test)}\")\n                Test set size: 6\n\n        \"\"\"\n        if self.verbosity &gt; 0:\n            print(f\"LightDataModule.test_dataloader(). Test set size: {len(self.data_test)}\")\n        return DataLoader(self.data_test, batch_size=self.batch_size, num_workers=self.num_workers)\n\n    def predict_dataloader(self) -&gt; DataLoader:\n        \"\"\"\n        Returns the predict dataloader, i.e., a pytorch DataLoader instance\n        using the predict dataset.\n\n        Returns:\n            DataLoader: The predict dataloader.\n\n        Examples:\n            &gt;&gt;&gt; from spotpython.data.lightdatamodule import LightDataModule\n                from spotpython.data.csvdataset import CSVDataset\n                import torch\n                dataset = CSVDataset(csv_file='data.csv', target_column='prognosis', feature_type=torch.long)\n                data_module = LightDataModule(dataset=dataset, batch_size=5, test_size=0.5)\n                data_module.setup()\n                print(f\"Predict set size: {len(data_module.data_predict)}\")\n                Predict set size: 6\n\n        \"\"\"\n        if self.verbosity &gt; 0:\n            print(f\"LightDataModule.predict_dataloader(). Predict set size: {len(self.data_predict)}\")\n        return DataLoader(self.data_predict, batch_size=len(self.data_predict), num_workers=self.num_workers)\n\n\ndata_module = LightDataModule(batch_size=2, dataset=dataset, test_size=0.2)\ndata_module.setup()\nfor batch in data_module.train_dataloader():\n    print(batch)\n    print(f\"Number of input features: {batch[0][1].shape}\")\n    break",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>User Specified Basic Lightning Module With spotpython</span>"
    ]
  },
  {
    "objectID": "702_lightning_user_datamodule.html#the-neural-network-myregressor",
    "href": "702_lightning_user_datamodule.html#the-neural-network-myregressor",
    "title": "39  User Specified Basic Lightning Module With spotpython",
    "section": "39.2 The Neural Network: MyRegressor",
    "text": "39.2 The Neural Network: MyRegressor\n\nimport lightning as L\nimport torch\nfrom torch import nn\nfrom spotpython.hyperparameters.optimizer import optimizer_handler\nimport torchmetrics.functional.regression\nfrom math import ceil\n\nclass MyRegressor(L.LightningModule):\n    \"\"\"\n    A LightningModule class for a regression neural network model.\n\n    Attributes:\n        l1 (int):\n            The number of neurons in the first hidden layer.\n        epochs (int):\n            The number of epochs to train the model for.\n        batch_size (int):\n            The batch size to use during training.\n        initialization (str):\n            The initialization method to use for the weights.\n        act_fn (nn.Module):\n            The activation function to use in the hidden layers.\n        optimizer (str):\n            The optimizer to use during training.\n        dropout_prob (float):\n            The probability of dropping out a neuron during training.\n        lr_mult (float):\n            The learning rate multiplier for the optimizer.\n        patience (int):\n            The number of epochs to wait before early stopping.\n        _L_in (int):\n            The number of input features.\n        _L_out (int):\n            The number of output classes.\n        _torchmetric (str):\n            The metric to use for the loss function. If `None`,\n            then \"mean_squared_error\" is used.\n        layers (nn.Sequential):\n            The neural network model.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        l1: int,\n        epochs: int,\n        batch_size: int,\n        initialization: str,\n        act_fn: nn.Module,\n        optimizer: str,\n        dropout_prob: float,\n        lr_mult: float,\n        patience: int,\n        _L_in: int,\n        _L_out: int,\n        _torchmetric: str,\n        *args,\n        **kwargs,\n    ):\n        \"\"\"\n        Initializes the MyRegressor object.\n\n        Args:\n            l1 (int):\n                The number of neurons in the first hidden layer.\n            epochs (int):\n                The number of epochs to train the model for.\n            batch_size (int):\n                The batch size to use during training.\n            initialization (str):\n                The initialization method to use for the weights.\n            act_fn (nn.Module):\n                The activation function to use in the hidden layers.\n            optimizer (str):\n                The optimizer to use during training.\n            dropout_prob (float):\n                The probability of dropping out a neuron during training.\n            lr_mult (float):\n                The learning rate multiplier for the optimizer.\n            patience (int):\n                The number of epochs to wait before early stopping.\n            _L_in (int):\n                The number of input features. Not a hyperparameter, but needed to create the network.\n            _L_out (int):\n                The number of output classes. Not a hyperparameter, but needed to create the network.\n            _torchmetric (str):\n                The metric to use for the loss function. If `None`,\n                then \"mean_squared_error\" is used.\n\n        Returns:\n            (NoneType): None\n\n        Raises:\n            ValueError: If l1 is less than 4.\n\n        \"\"\"\n        super().__init__()\n        self._L_in = _L_in\n        self._L_out = _L_out\n        if _torchmetric is None:\n            _torchmetric = \"mean_squared_error\"\n        self._torchmetric = _torchmetric\n        self.metric = getattr(torchmetrics.functional.regression, _torchmetric)\n        # _L_in and _L_out are not hyperparameters, but are needed to create the network\n        # _torchmetric is not a hyperparameter, but is needed to calculate the loss\n        self.save_hyperparameters(ignore=[\"_L_in\", \"_L_out\", \"_torchmetric\"])\n        # set dummy input array for Tensorboard Graphs\n        # set log_graph=True in Trainer to see the graph (in traintest.py)\n        self.example_input_array = torch.zeros((batch_size, self._L_in))\n        if self.hparams.l1 &lt; 4:\n            raise ValueError(\"l1 must be at least 4\")\n        hidden_sizes = [l1 * 2, l1, ceil(l1/2)]\n        # Create the network based on the specified hidden sizes\n        layers = []\n        layer_sizes = [self._L_in] + hidden_sizes\n        layer_size_last = layer_sizes[0]\n        for layer_size in layer_sizes[1:]:\n            layers += [\n                nn.Linear(layer_size_last, layer_size),\n                self.hparams.act_fn,\n                nn.Dropout(self.hparams.dropout_prob),\n            ]\n            layer_size_last = layer_size\n        layers += [nn.Linear(layer_sizes[-1], self._L_out)]\n        self.layers = nn.Sequential(*layers)\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Performs a forward pass through the model.\n\n        Args:\n            x (torch.Tensor): A tensor containing a batch of input data.\n\n        Returns:\n            torch.Tensor: A tensor containing the output of the model.\n\n        \"\"\"\n        x = self.layers(x)\n        return x\n\n    def _calculate_loss(self, batch):\n        \"\"\"\n        Calculate the loss for the given batch.\n\n        Args:\n            batch (tuple): A tuple containing a batch of input data and labels.\n\n        Returns:\n            torch.Tensor: A tensor containing the loss for this batch.\n\n        \"\"\"\n        x, y = batch\n        y = y.view(len(y), 1)\n        y_hat = self(x)\n        loss = self.metric(y_hat, y)\n        return loss\n\n    def training_step(self, batch: tuple) -&gt; torch.Tensor:\n        \"\"\"\n        Performs a single training step.\n\n        Args:\n            batch (tuple): A tuple containing a batch of input data and labels.\n\n        Returns:\n            torch.Tensor: A tensor containing the loss for this batch.\n\n        \"\"\"\n        val_loss = self._calculate_loss(batch)\n        return val_loss\n\n    def validation_step(self, batch: tuple, batch_idx: int, prog_bar: bool = False) -&gt; torch.Tensor:\n        \"\"\"\n        Performs a single validation step.\n\n        Args:\n            batch (tuple): A tuple containing a batch of input data and labels.\n            batch_idx (int): The index of the current batch.\n            prog_bar (bool, optional): Whether to display the progress bar. Defaults to False.\n\n        Returns:\n            torch.Tensor: A tensor containing the loss for this batch.\n\n        \"\"\"\n        val_loss = self._calculate_loss(batch)\n        self.log(\"val_loss\", val_loss, prog_bar=prog_bar)\n        self.log(\"hp_metric\", val_loss, prog_bar=prog_bar)\n        return val_loss\n\n    def test_step(self, batch: tuple, batch_idx: int, prog_bar: bool = False) -&gt; torch.Tensor:\n        \"\"\"\n        Performs a single test step.\n\n        Args:\n            batch (tuple): A tuple containing a batch of input data and labels.\n            batch_idx (int): The index of the current batch.\n            prog_bar (bool, optional): Whether to display the progress bar. Defaults to False.\n\n        Returns:\n            torch.Tensor: A tensor containing the loss for this batch.\n        \"\"\"\n        val_loss = self._calculate_loss(batch)\n        self.log(\"val_loss\", val_loss, prog_bar=prog_bar)\n        self.log(\"hp_metric\", val_loss, prog_bar=prog_bar)\n        return val_loss\n\n    def predict_step(self, batch: tuple, batch_idx: int, prog_bar: bool = False) -&gt; torch.Tensor:\n        \"\"\"\n        Performs a single prediction step.\n\n        Args:\n            batch (tuple): A tuple containing a batch of input data and labels.\n            batch_idx (int): The index of the current batch.\n            prog_bar (bool, optional): Whether to display the progress bar. Defaults to False.\n\n        Returns:\n            A tuple containing the input data, the true labels, and the predicted values.\n        \"\"\"\n        x, y = batch\n        yhat = self(x)\n        y = y.view(len(y), 1)\n        yhat = yhat.view(len(yhat), 1)\n        print(f\"Predict step x: {x}\")\n        print(f\"Predict step y: {y}\")\n        print(f\"Predict step y_hat: {yhat}\")\n        return (x, y, yhat)\n\n    def configure_optimizers(self) -&gt; torch.optim.Optimizer:\n        \"\"\"\n        Configures the optimizer for the model.\n        Simple examples use the following code here:\n        `optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)`\n\n        Notes:\n            The default Lightning way is to define an optimizer as\n            `optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)`.\n            spotpython uses an optimizer handler to create the optimizer, which\n            adapts the learning rate according to the lr_mult hyperparameter as\n            well as other hyperparameters. See `spotpython.hyperparameters.optimizer.py` for details.\n\n        Returns:\n            torch.optim.Optimizer: The optimizer to use during training.\n\n        \"\"\"\n        # optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n        optimizer = optimizer_handler(\n            optimizer_name=self.hparams.optimizer, params=self.parameters(), lr_mult=self.hparams.lr_mult\n        )\n        return optimizer",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>User Specified Basic Lightning Module With spotpython</span>"
    ]
  },
  {
    "objectID": "702_lightning_user_datamodule.html#calling-the-neural-network-with-spotpython",
    "href": "702_lightning_user_datamodule.html#calling-the-neural-network-with-spotpython",
    "title": "39  User Specified Basic Lightning Module With spotpython",
    "section": "39.3 Calling the Neural Network With spotpython",
    "text": "39.3 Calling the Neural Network With spotpython\n\nPREFIX=\"702_lightning_user_datamodule\"\n\n\nimport sys\nsys.path.insert(0, './userModel')\nimport my_regressor\nimport my_hyper_dict\n\n\nfrom spotpython.hyperparameters.values import add_core_model_to_fun_control\nfrom spotpython.fun.hyperlight import HyperLight\nfrom spotpython.utils.init import (fun_control_init, surrogate_control_init, design_control_init)\nfrom spotpython.hyperparameters.values import set_hyperparameter\nfrom spotpython.spot import Spot\nfrom math import inf\nfun_control = fun_control_init(\n    PREFIX=PREFIX,\n    fun_evals=inf,\n    fun_repeats=1,\n    max_time=5,\n    accelerator=\"cpu\",\n    data_module=data_module,\n    _L_in=dataset[0][0].shape[0],\n    _L_out=1,\n    noise=False,\n    ocba_delta=0,\n    TENSORBOARD_CLEAN=True,\n    tensorboard_log=True,\n    _torchmetric=\"mean_squared_error\",\n    log_level=50,\n    save_experiment=True,\n    verbosity=1)\n\nadd_core_model_to_fun_control(fun_control=fun_control,\n                              core_model=my_regressor.MyRegressor,\n                              hyper_dict=my_hyper_dict.MyHyperDict)\n\nset_hyperparameter(fun_control, \"optimizer\", [ \"Adadelta\", \"Adam\", \"Adamax\"])\nset_hyperparameter(fun_control, \"act_fn\", [ \"ReLU\", \"Swish\", \"LeakyReLU\"])\nset_hyperparameter(fun_control, \"l1\", [3,4])\nset_hyperparameter(fun_control, \"epochs\", [3,5])\nset_hyperparameter(fun_control, \"batch_size\", [1,5])\nset_hyperparameter(fun_control, \"dropout_prob\", [0.0, 0.025])\nset_hyperparameter(fun_control, \"patience\", [2,3])\n# set_hyperparameter(fun_control, \"initialization\", [\"Default\"])\n\ndesign_control = design_control_init(init_size=5, repeats=1)\nsurrogate_control = surrogate_control_init(method=\"regression\")\n\nfun = HyperLight().fun\n\nspot_tuner = Spot(fun=fun,fun_control=fun_control, design_control=design_control, surrogate_control=surrogate_control)\n\n\nimport os\nfrom spotpython.utils.file import load_experiment\nif os.path.exists(\"spot_\" + PREFIX + \"_experiment.pickle\"):\n    (spot_tuner, fun_control, design_control,\n        surrogate_control, optimizer_control) = load_experiment(PREFIX=PREFIX)\nelse:\n    res = spot_tuner.run()",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>User Specified Basic Lightning Module With spotpython</span>"
    ]
  },
  {
    "objectID": "702_lightning_user_datamodule.html#looking-at-the-results",
    "href": "702_lightning_user_datamodule.html#looking-at-the-results",
    "title": "39  User Specified Basic Lightning Module With spotpython",
    "section": "39.4 Looking at the Results",
    "text": "39.4 Looking at the Results\n\n39.4.1 Tuning Progress\nAfter the hyperparameter tuning run is finished, the progress of the hyperparameter tuning can be visualized with spotpython’s method plot_progress. The black points represent the performace values (score or metric) of hyperparameter configurations from the initial design, whereas the red points represents the hyperparameter configurations found by the surrogate model based optimization.\n\nspot_tuner.plot_progress()\n\n\n\n39.4.2 Tuned Hyperparameters and Their Importance\nResults can be printed in tabular form.\n\nfrom spotpython.utils.eda import print_res_table\nprint_res_table(spot_tuner)\n\nA histogram can be used to visualize the most important hyperparameters.\n\nspot_tuner.plot_importance(threshold=1.0)\n\n\nspot_tuner.plot_important_hyperparameter_contour(max_imp=3)\n\n\n\n39.4.3 Get the Tuned Architecture\n\nimport pprint\nfrom spotpython.hyperparameters.values import get_tuned_architecture\nconfig = get_tuned_architecture(spot_tuner)\npprint.pprint(config)",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>User Specified Basic Lightning Module With spotpython</span>"
    ]
  },
  {
    "objectID": "600_spot_lightning_data.html",
    "href": "600_spot_lightning_data.html",
    "title": "40  HPT PyTorch Lightning: Data",
    "section": "",
    "text": "40.1 Setup\nIn this tutorial, we will show how spotpython can be integrated into the PyTorch Lightning training workflow.\nThis chapter describes the data preparation and processing in spotpython. The Diabetes data set is used as an example. This is a PyTorch Dataset for regression. A toy data set from scikit-learn. Ten baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements were obtained for each of n = 442 diabetes patients, as well as the response of interest, a quantitative measure of disease progression one year after baseline.\nimport torch\nfrom spotpython.utils.device import getDevice\nfrom math import inf\nWORKERS = 0\nPREFIX=\"030\"\nDEVICE = getDevice()\nDEVICES = 1\nTEST_SIZE = 0.4",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>HPT PyTorch Lightning: Data</span>"
    ]
  },
  {
    "objectID": "600_spot_lightning_data.html#sec-setup-30",
    "href": "600_spot_lightning_data.html#sec-setup-30",
    "title": "40  HPT PyTorch Lightning: Data",
    "section": "",
    "text": "Before we consider the detailed experimental setup, we select the parameters that affect run time, initial design size, etc.\nThe parameter WORKERS specifies the number of workers.\nThe prefix PREFIX is used for the experiment name and the name of the log file.\nThe parameter DEVICE specifies the device to use for training.\n\n\n\n\n\n\n\n\nNote: Device selection\n\n\n\n\nAlthough there are no .cuda() or .to(device) calls required, because Lightning does these for you, see LIGHTNINGMODULE, we would like to know which device is used. Threrefore, we imitate the LightningModule behaviour which selects the highest device.\nThe method spotpython.utils.device.getDevice() returns the device that is used by Lightning.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>HPT PyTorch Lightning: Data</span>"
    ]
  },
  {
    "objectID": "600_spot_lightning_data.html#initialization-of-the-fun_control-dictionary",
    "href": "600_spot_lightning_data.html#initialization-of-the-fun_control-dictionary",
    "title": "40  HPT PyTorch Lightning: Data",
    "section": "40.2 Initialization of the fun_control Dictionary",
    "text": "40.2 Initialization of the fun_control Dictionary\nspotpython uses a Python dictionary for storing the information required for the hyperparameter tuning process.\n\nfrom spotpython.utils.init import fun_control_init\nimport numpy as np\nfun_control = fun_control_init(\n    _L_in=10,\n    _L_out=1,\n    _torchmetric=\"mean_squared_error\",\n    PREFIX=PREFIX,\n    device=DEVICE,\n    enable_progress_bar=False,\n    num_workers=WORKERS,\n    show_progress=True,\n    test_size=TEST_SIZE,\n    )",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>HPT PyTorch Lightning: Data</span>"
    ]
  },
  {
    "objectID": "600_spot_lightning_data.html#loading-the-diabetes-data-set",
    "href": "600_spot_lightning_data.html#loading-the-diabetes-data-set",
    "title": "40  HPT PyTorch Lightning: Data",
    "section": "40.3 Loading the Diabetes Data Set",
    "text": "40.3 Loading the Diabetes Data Set\nHere, we load the Diabetes data set from spotpython’s data module.\n\nfrom spotpython.data.diabetes import Diabetes\ndataset = Diabetes(target_type=torch.float)\nprint(len(dataset))\n\n442\n\n\n\n40.3.1 Data Set and Data Loader\nAs shown below, a DataLoader from torch.utils.data can be used to check the data.\n\n# Set batch size for DataLoader\nbatch_size = 5\n# Create DataLoader\nfrom torch.utils.data import DataLoader\ndataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n\n# Iterate over the data in the DataLoader\nfor batch in dataloader:\n    inputs, targets = batch\n    print(f\"Batch Size: {inputs.size(0)}\")\n    print(f\"Inputs Shape: {inputs.shape}\")\n    print(f\"Targets Shape: {targets.shape}\")\n    print(\"---------------\")\n    print(f\"Inputs: {inputs}\")\n    print(f\"Targets: {targets}\")\n    break\n\nBatch Size: 5\nInputs Shape: torch.Size([5, 10])\nTargets Shape: torch.Size([5])\n---------------\nInputs: tensor([[ 0.0381,  0.0507,  0.0617,  0.0219, -0.0442, -0.0348, -0.0434, -0.0026,\n          0.0199, -0.0176],\n        [-0.0019, -0.0446, -0.0515, -0.0263, -0.0084, -0.0192,  0.0744, -0.0395,\n         -0.0683, -0.0922],\n        [ 0.0853,  0.0507,  0.0445, -0.0057, -0.0456, -0.0342, -0.0324, -0.0026,\n          0.0029, -0.0259],\n        [-0.0891, -0.0446, -0.0116, -0.0367,  0.0122,  0.0250, -0.0360,  0.0343,\n          0.0227, -0.0094],\n        [ 0.0054, -0.0446, -0.0364,  0.0219,  0.0039,  0.0156,  0.0081, -0.0026,\n         -0.0320, -0.0466]])\nTargets: tensor([151.,  75., 141., 206., 135.])\n\n\n\n\n40.3.2 Preparing Training, Validation, and Test Data\nThe following code shows how to split the data into training, validation, and test sets. Then a Lightning Trainer is used to train (fit) the model, validate it, and test it.\n\nfrom torch.utils.data import DataLoader\nfrom spotpython.data.diabetes import Diabetes\nfrom spotpython.light.regression.netlightregression import NetLightRegression\nfrom torch import nn\nimport lightning as L\nimport torch\nBATCH_SIZE = 8\ndataset = Diabetes(target_type=torch.float)\ntrain1_set, test_set = torch.utils.data.random_split(dataset, [0.6, 0.4])\ntrain_set, val_set = torch.utils.data.random_split(train1_set, [0.6, 0.4])\ntrain_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, pin_memory=True)\ntest_loader = DataLoader(test_set, batch_size=BATCH_SIZE)\nval_loader = DataLoader(val_set, batch_size=BATCH_SIZE)\nbatch_x, batch_y = next(iter(train_loader))\nprint(f\"batch_x.shape: {batch_x.shape}\")\nprint(f\"batch_y.shape: {batch_y.shape}\")\nnet_light_base = NetLightRegression(l1=128,\n                                    epochs=10,\n                                    batch_size=BATCH_SIZE,\n                                    initialization='Default',\n                                    act_fn=nn.ReLU(),\n                                    optimizer='Adam',\n                                    dropout_prob=0.1,\n                                    lr_mult=0.1,\n                                    patience=5,\n                                    _L_in=10,\n                                    _L_out=1,\n                                    _torchmetric=\"mean_squared_error\")\ntrainer = L.Trainer(max_epochs=10,  enable_progress_bar=False)\ntrainer.fit(net_light_base, train_loader)\ntrainer.validate(net_light_base, val_loader)\ntrainer.test(net_light_base, test_loader)\n\nbatch_x.shape: torch.Size([8, 10])\nbatch_y.shape: torch.Size([8])\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃      Validate metric      ┃       DataLoader 0        ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│         hp_metric         │      32421.490234375      │\n│         val_loss          │      32421.490234375      │\n└───────────────────────────┴───────────────────────────┘\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃        Test metric        ┃       DataLoader 0        ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│         hp_metric         │       25781.0234375       │\n│         val_loss          │       25781.0234375       │\n└───────────────────────────┴───────────────────────────┘\n\n\n\n[{'val_loss': 25781.0234375, 'hp_metric': 25781.0234375}]\n\n\n\n\n40.3.3 Dataset for spotpython\nspotpython handles the data set, which is added to the fun_control dictionary with the key data_set as follows:\n\nfrom spotpython.hyperparameters.values import set_control_key_value\nfrom spotpython.data.diabetes import Diabetes\ndataset = Diabetes(target_type=torch.float)\nset_control_key_value(control_dict=fun_control,\n                        key=\"data_set\",\n                        value=dataset,\n                        replace=True)\nprint(len(dataset))\n\n442\n\n\nIf the data set is in the fun_control dictionary, it is used to create a LightDataModule object. This object is used to create the data loaders for the training, validation, and test sets. Therefore, the following information must be provided in the fun_control dictionary:\n\ndata_set: the data set\nbatch_size: the batch size\nnum_workers: the number of workers\ntest_size: the size of the test set\ntest_seed: the seed for the test set\n\n\nfrom spotpython.utils.init import fun_control_init\nimport numpy as np\nfun_control = fun_control_init(\n    data_set=dataset,\n    device=\"cpu\",\n    enable_progress_bar=False,\n    num_workers=0,\n    show_progress=True,\n    test_size=0.4,\n    test_seed=42,    \n    )\n\n\nfrom spotpython.data.lightdatamodule import LightDataModule\ndm = LightDataModule(\n    dataset=fun_control[\"data_set\"],\n    batch_size=8,\n    num_workers=fun_control[\"num_workers\"],\n    test_size=fun_control[\"test_size\"],\n    test_seed=fun_control[\"test_seed\"],\n)\ndm.setup()\nprint(f\"train_model(): Test set size: {len(dm.data_test)}\")\nprint(f\"train_model(): Train set size: {len(dm.data_train)}\")\n\ntrain_model(): Test set size: 177\ntrain_model(): Train set size: 160",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>HPT PyTorch Lightning: Data</span>"
    ]
  },
  {
    "objectID": "600_spot_lightning_data.html#the-lightdatamodule",
    "href": "600_spot_lightning_data.html#the-lightdatamodule",
    "title": "40  HPT PyTorch Lightning: Data",
    "section": "40.4 The LightDataModule",
    "text": "40.4 The LightDataModule\nThe steps described above are handled by the LightDataModule class. This class is used to create the data loaders for the training, validation, and test sets. The LightDataModule class is part of the spotpython package. The LightDataModule class provides the following methods:\n\nprepare_data(): This method is used to prepare the data set.\nsetup(): This method is used to create the data loaders for the training, validation, and test sets.\ntrain_dataloader(): This method is used to return the data loader for the training set.\nval_dataloader(): This method is used to return the data loader for the validation set.\ntest_dataloader(): This method is used to return the data loader for the test set.\npredict_dataloader(): This method is used to return the data loader for the prediction set.\n\n\n40.4.1 The prepare_data() Method\nThe prepare_data() method is used to prepare the data set. This method is called only once and on a single process. It can be used to download the data set. In our case, the data set is already available, so this method uses a simple pass statement.\n\n\n40.4.2 The setup() Method\nSplits the data for use in training, validation, and testing. It uses torch.utils.data.random_split() to split the data. Splitting is based on the test_size and test_seed. The test_size can be a float or an int.\n\n40.4.2.1 Determine the Sizes of the Data Sets\n\nfrom torch.utils.data import random_split\ndata_full = dataset\ntest_size = fun_control[\"test_size\"]\ntest_seed=fun_control[\"test_seed\"]\n# if test_size is float, then train_size is 1 - test_size\nif isinstance(test_size, float):\n    full_train_size = round(1.0 - test_size, 2)\n    val_size = round(full_train_size * test_size, 2)\n    train_size = round(full_train_size - val_size, 2)\nelse:\n    # if test_size is int, then train_size is len(data_full) - test_size\n    full_train_size = len(data_full) - test_size\n    val_size = int(full_train_size * test_size / len(data_full))\n    train_size = full_train_size - val_size\n\nprint(f\"LightDataModule setup(): full_train_size: {full_train_size}\")\nprint(f\"LightDataModule setup(): val_size: {val_size}\")\nprint(f\"LightDataModule setup(): train_size: {train_size}\")\nprint(f\"LightDataModule setup(): test_size: {test_size}\")\n\nLightDataModule setup(): full_train_size: 0.6\nLightDataModule setup(): val_size: 0.24\nLightDataModule setup(): train_size: 0.36\nLightDataModule setup(): test_size: 0.4\n\n\nstage is used to define the data set to be returned. The stage can be None, fit, test, or predict. If stage is None, the method returns the training (fit), testing (test) and prediction (predict) data sets.\n\n\n40.4.2.2 Stage “fit”\n\nstage = \"fit\"\nif stage == \"fit\" or stage is None:\n    generator_fit = torch.Generator().manual_seed(test_seed)\n    data_train, data_val, _ = random_split(data_full, [train_size, val_size, test_size], generator=generator_fit)\nprint(f\"LightDataModule setup(): Train set size: {len(data_train)}\")\nprint(f\"LightDataModule setup(): Validation set size: {len(data_val)}\")\n\nLightDataModule setup(): Train set size: 160\nLightDataModule setup(): Validation set size: 106\n\n\n\n\n40.4.2.3 Stage “test”\n\nstage = \"test\"\nif stage == \"test\" or stage is None:\n    generator_test = torch.Generator().manual_seed(test_seed)\n    data_test, _ = random_split(data_full, [test_size, full_train_size], generator=generator_test)\nprint(f\"LightDataModule setup(): Test set size: {len(data_test)}\")\n# Set batch size for DataLoader\nbatch_size = 5\n# Create DataLoader\nfrom torch.utils.data import DataLoader\ndataloader = DataLoader(data_test, batch_size=batch_size, shuffle=False)\n# Iterate over the data in the DataLoader\nfor batch in dataloader:\n    inputs, targets = batch\n    print(f\"Batch Size: {inputs.size(0)}\")\n    print(f\"Inputs Shape: {inputs.shape}\")\n    print(f\"Targets Shape: {targets.shape}\")\n    print(\"---------------\")\n    print(f\"Inputs: {inputs}\")\n    print(f\"Targets: {targets}\")\n    break\n\nLightDataModule setup(): Test set size: 177\nBatch Size: 5\nInputs Shape: torch.Size([5, 10])\nTargets Shape: torch.Size([5])\n---------------\nInputs: tensor([[ 0.0562, -0.0446, -0.0579, -0.0080,  0.0521,  0.0491,  0.0560, -0.0214,\n         -0.0283,  0.0445],\n        [ 0.0018, -0.0446, -0.0709, -0.0229, -0.0016, -0.0010,  0.0266, -0.0395,\n         -0.0225,  0.0072],\n        [-0.0527, -0.0446,  0.0542, -0.0263, -0.0552, -0.0339, -0.0139, -0.0395,\n         -0.0741, -0.0591],\n        [ 0.0054, -0.0446, -0.0482, -0.0126,  0.0012, -0.0066,  0.0634, -0.0395,\n         -0.0514, -0.0591],\n        [-0.0527, -0.0446, -0.0094, -0.0057,  0.0397,  0.0447,  0.0266, -0.0026,\n         -0.0181, -0.0135]])\nTargets: tensor([158.,  49., 142.,  96.,  59.])\n\n\n\n\n40.4.2.4 Stage “predict”\nPrediction and testing use the same data set.\n\nstage = \"predict\"\nif stage == \"predict\" or stage is None:\n    generator_predict = torch.Generator().manual_seed(test_seed)\n    data_predict, _ = random_split(\n        data_full, [test_size, full_train_size], generator=generator_predict\n    )\nprint(f\"LightDataModule setup(): Predict set size: {len(data_predict)}\")\n# Set batch size for DataLoader\nbatch_size = 5\n# Create DataLoader\nfrom torch.utils.data import DataLoader\ndataloader = DataLoader(data_predict, batch_size=batch_size, shuffle=False)\n# Iterate over the data in the DataLoader\nfor batch in dataloader:\n    inputs, targets = batch\n    print(f\"Batch Size: {inputs.size(0)}\")\n    print(f\"Inputs Shape: {inputs.shape}\")\n    print(f\"Targets Shape: {targets.shape}\")\n    print(\"---------------\")\n    print(f\"Inputs: {inputs}\")\n    print(f\"Targets: {targets}\")\n    break\n\nLightDataModule setup(): Predict set size: 177\nBatch Size: 5\nInputs Shape: torch.Size([5, 10])\nTargets Shape: torch.Size([5])\n---------------\nInputs: tensor([[ 0.0562, -0.0446, -0.0579, -0.0080,  0.0521,  0.0491,  0.0560, -0.0214,\n         -0.0283,  0.0445],\n        [ 0.0018, -0.0446, -0.0709, -0.0229, -0.0016, -0.0010,  0.0266, -0.0395,\n         -0.0225,  0.0072],\n        [-0.0527, -0.0446,  0.0542, -0.0263, -0.0552, -0.0339, -0.0139, -0.0395,\n         -0.0741, -0.0591],\n        [ 0.0054, -0.0446, -0.0482, -0.0126,  0.0012, -0.0066,  0.0634, -0.0395,\n         -0.0514, -0.0591],\n        [-0.0527, -0.0446, -0.0094, -0.0057,  0.0397,  0.0447,  0.0266, -0.0026,\n         -0.0181, -0.0135]])\nTargets: tensor([158.,  49., 142.,  96.,  59.])\n\n\n\n\n\n40.4.3 The train_dataloader() Method\nReturns the training dataloader, i.e., a Pytorch DataLoader instance using the training dataset. It simply returns a DataLoader with the data_train set that was created in the setup() method as described in Section 40.4.2.2.\n\ndef train_dataloader(self) -&gt; DataLoader:\n    return DataLoader(self.data_train, batch_size=self.batch_size, num_workers=self.num_workers)\n\nThe train_dataloader() method can be used as follows:\n\nfrom spotpython.data.lightdatamodule import LightDataModule\nfrom spotpython.data.diabetes import Diabetes\ndataset = Diabetes(target_type=torch.float)\ndata_module = LightDataModule(dataset=dataset, batch_size=5, test_size=0.4)\ndata_module.setup()\nprint(f\"Training set size: {len(data_module.data_train)}\")\ndl = data_module.train_dataloader()\n# Iterate over the data in the DataLoader\nfor batch in dl:\n    inputs, targets = batch\n    print(f\"Batch Size: {inputs.size(0)}\")\n    print(f\"Inputs Shape: {inputs.shape}\")\n    print(f\"Targets Shape: {targets.shape}\")\n    print(\"---------------\")\n    print(f\"Inputs: {inputs}\")\n    print(f\"Targets: {targets}\")\n    break\n\nTraining set size: 160\nBatch Size: 5\nInputs Shape: torch.Size([5, 10])\nTargets Shape: torch.Size([5])\n---------------\nInputs: tensor([[ 0.0708,  0.0507, -0.0310,  0.0219, -0.0373, -0.0470,  0.0339, -0.0395,\n         -0.0150, -0.0011],\n        [ 0.0344,  0.0507, -0.0299,  0.0047,  0.0934,  0.0870,  0.0339, -0.0026,\n          0.0241, -0.0384],\n        [ 0.0090, -0.0446,  0.0552, -0.0057,  0.0576,  0.0447, -0.0029,  0.0232,\n          0.0557,  0.1066],\n        [ 0.0417, -0.0446, -0.0644,  0.0356,  0.0122, -0.0580,  0.1812, -0.0764,\n         -0.0006, -0.0508],\n        [ 0.0381,  0.0507,  0.0164,  0.0219,  0.0397,  0.0450, -0.0434,  0.0712,\n          0.0498,  0.0155]])\nTargets: tensor([ 66.,  69., 173., 170., 212.])\n\n\n\n\n40.4.4 The val_dataloader() Method\nReturns the validation dataloader, i.e., a Pytorch DataLoader instance using the validation dataset. It simply returns a DataLoader with the data_val set that was created in the setup() method as desccribed in Section 40.4.2.2.\n\ndef val_dataloader(self) -&gt; DataLoader:\n    return DataLoader(self.data_val, batch_size=self.batch_size, num_workers=self.num_workers)\n\nThe val_dataloader() method can be used as follows:\n\nfrom spotpython.data.lightdatamodule import LightDataModule\nfrom spotpython.data.diabetes import Diabetes\ndataset = Diabetes(target_type=torch.float)\ndata_module = LightDataModule(dataset=dataset, batch_size=5, test_size=0.4)\ndata_module.setup()\nprint(f\"Validation set size: {len(data_module.data_val)}\")\ndl = data_module.val_dataloader()\n# Iterate over the data in the DataLoader\nfor batch in dl:\n    inputs, targets = batch\n    print(f\"Batch Size: {inputs.size(0)}\")\n    print(f\"Inputs Shape: {inputs.shape}\")\n    print(f\"Targets Shape: {targets.shape}\")\n    print(\"---------------\")\n    print(f\"Inputs: {inputs}\")\n    print(f\"Targets: {targets}\")\n    break\n\nValidation set size: 106\nBatch Size: 5\nInputs Shape: torch.Size([5, 10])\nTargets Shape: torch.Size([5])\n---------------\nInputs: tensor([[ 0.0163, -0.0446,  0.0736, -0.0412, -0.0043, -0.0135, -0.0139, -0.0011,\n          0.0429,  0.0445],\n        [ 0.0453, -0.0446,  0.0714,  0.0012, -0.0098, -0.0010,  0.0155, -0.0395,\n         -0.0412, -0.0715],\n        [ 0.0308,  0.0507,  0.0326,  0.0494, -0.0401, -0.0436, -0.0692,  0.0343,\n          0.0630,  0.0031],\n        [ 0.0235,  0.0507, -0.0396, -0.0057, -0.0484, -0.0333,  0.0118, -0.0395,\n         -0.1016, -0.0674],\n        [-0.0091,  0.0507,  0.0013, -0.0022,  0.0796,  0.0701,  0.0339, -0.0026,\n          0.0267,  0.0818]])\nTargets: tensor([275., 141., 208.,  78., 142.])\n\n\n\n\n40.4.5 The test_dataloader() Method\nReturns the test dataloader, i.e., a Pytorch DataLoader instance using the test dataset. It simply returns a DataLoader with the data_test set that was created in the setup() method as described in Section 40.4.2.3.\n\ndef test_dataloader(self) -&gt; DataLoader:\n    return DataLoader(self.data_test, batch_size=self.batch_size, num_workers=self.num_workers)\n\nThe test_dataloader() method can be used as follows:\n\nfrom spotpython.data.lightdatamodule import LightDataModule\nfrom spotpython.data.diabetes import Diabetes\ndataset = Diabetes(target_type=torch.float)\ndata_module = LightDataModule(dataset=dataset, batch_size=5, test_size=0.4)\ndata_module.setup()\nprint(f\"Test set size: {len(data_module.data_test)}\")\ndl = data_module.test_dataloader()\n# Iterate over the data in the DataLoader\nfor batch in dl:\n    inputs, targets = batch\n    print(f\"Batch Size: {inputs.size(0)}\")\n    print(f\"Inputs Shape: {inputs.shape}\")\n    print(f\"Targets Shape: {targets.shape}\")\n    print(\"---------------\")\n    print(f\"Inputs: {inputs}\")\n    print(f\"Targets: {targets}\")\n    break\n\nTest set size: 177\nBatch Size: 5\nInputs Shape: torch.Size([5, 10])\nTargets Shape: torch.Size([5])\n---------------\nInputs: tensor([[ 0.0562, -0.0446, -0.0579, -0.0080,  0.0521,  0.0491,  0.0560, -0.0214,\n         -0.0283,  0.0445],\n        [ 0.0018, -0.0446, -0.0709, -0.0229, -0.0016, -0.0010,  0.0266, -0.0395,\n         -0.0225,  0.0072],\n        [-0.0527, -0.0446,  0.0542, -0.0263, -0.0552, -0.0339, -0.0139, -0.0395,\n         -0.0741, -0.0591],\n        [ 0.0054, -0.0446, -0.0482, -0.0126,  0.0012, -0.0066,  0.0634, -0.0395,\n         -0.0514, -0.0591],\n        [-0.0527, -0.0446, -0.0094, -0.0057,  0.0397,  0.0447,  0.0266, -0.0026,\n         -0.0181, -0.0135]])\nTargets: tensor([158.,  49., 142.,  96.,  59.])\n\n\n\n\n40.4.6 The predict_dataloader() Method\nReturns the prediction dataloader, i.e., a Pytorch DataLoader instance using the prediction dataset. It simply returns a DataLoader with the data_predict set that was created in the setup() method as described in Section 40.4.2.4.\n\n\n\n\n\n\nWarning\n\n\n\nThe batch_size is set to the length of the data_predict set.\n\n\n\ndef predict_dataloader(self) -&gt; DataLoader:\n    return DataLoader(self.data_predict, batch_size=len(self.data_predict), num_workers=self.num_workers)\n\nThe predict_dataloader() method can be used as follows:\n\nfrom spotpython.data.lightdatamodule import LightDataModule\nfrom spotpython.data.diabetes import Diabetes\ndataset = Diabetes(target_type=torch.float)\ndata_module = LightDataModule(dataset=dataset, batch_size=5, test_size=0.4)\ndata_module.setup()\nprint(f\"Test set size: {len(data_module.data_predict)}\")\ndl = data_module.predict_dataloader()\n# Iterate over the data in the DataLoader\nfor batch in dl:\n    inputs, targets = batch\n    print(f\"Batch Size: {inputs.size(0)}\")\n    print(f\"Inputs Shape: {inputs.shape}\")\n    print(f\"Targets Shape: {targets.shape}\")\n    print(\"---------------\")\n    print(f\"Inputs: {inputs}\")\n    print(f\"Targets: {targets}\")\n    break\n\nTest set size: 177\nBatch Size: 177\nInputs Shape: torch.Size([177, 10])\nTargets Shape: torch.Size([177])\n---------------\nInputs: tensor([[ 0.0562, -0.0446, -0.0579,  ..., -0.0214, -0.0283,  0.0445],\n        [ 0.0018, -0.0446, -0.0709,  ..., -0.0395, -0.0225,  0.0072],\n        [-0.0527, -0.0446,  0.0542,  ..., -0.0395, -0.0741, -0.0591],\n        ...,\n        [ 0.0090, -0.0446, -0.0321,  ..., -0.0764, -0.0119, -0.0384],\n        [-0.0273, -0.0446, -0.0666,  ..., -0.0395, -0.0358, -0.0094],\n        [ 0.0817,  0.0507,  0.0067,  ...,  0.0919,  0.0547,  0.0072]])\nTargets: tensor([158.,  49., 142.,  96.,  59.,  74., 137., 136.,  39.,  66., 310., 198.,\n        235., 116.,  55., 177.,  59., 246.,  53., 135.,  88., 198., 186., 217.,\n         51., 118., 153., 180.,  51., 229.,  84.,  72., 237., 142., 185.,  91.,\n         88., 148., 179., 144.,  25.,  89.,  42.,  60., 124., 170., 215., 263.,\n        178., 245., 202.,  97., 321.,  71., 123., 220., 132., 243.,  61., 102.,\n        187.,  70., 242., 134.,  63.,  72.,  88., 219., 127., 146., 122., 143.,\n        220., 293.,  59., 317.,  60., 140.,  65., 277.,  90.,  96., 109., 190.,\n         90.,  52., 160., 233., 230., 175.,  68., 272., 144.,  70.,  68., 163.,\n         71.,  93., 263., 118., 220.,  90., 232., 120., 163.,  88.,  85.,  52.,\n        181., 232., 212., 332.,  81., 214., 145., 268., 115.,  93.,  64., 156.,\n        128., 200., 281., 103., 220.,  66.,  48., 246.,  42., 150., 125., 109.,\n        129.,  97., 265.,  97., 173., 216., 237., 121.,  42., 151.,  31.,  68.,\n        137., 221., 283., 124., 243., 150.,  69., 306., 182., 252., 132., 258.,\n        121., 110., 292., 101., 275., 141., 208.,  78., 142., 185., 167., 258.,\n        144.,  89., 225., 140., 303., 236.,  87.,  77., 131.])",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>HPT PyTorch Lightning: Data</span>"
    ]
  },
  {
    "objectID": "600_spot_lightning_data.html#using-the-lightdatamodule-in-the-train_model-method",
    "href": "600_spot_lightning_data.html#using-the-lightdatamodule-in-the-train_model-method",
    "title": "40  HPT PyTorch Lightning: Data",
    "section": "40.5 Using the LightDataModule in the train_model() Method",
    "text": "40.5 Using the LightDataModule in the train_model() Method\nFirst, a LightDataModule object is created and the setup() method is called.\n\ndm = LightDataModule(\n    dataset=fun_control[\"data_set\"],\n    batch_size=config[\"batch_size\"],\n    num_workers=fun_control[\"num_workers\"],\n    test_size=fun_control[\"test_size\"],\n    test_seed=fun_control[\"test_seed\"],\n)\ndm.setup()\n\nThen, the Trainer is initialized.\n\n# Init trainer\ntrainer = L.Trainer(\n    default_root_dir=os.path.join(fun_control[\"CHECKPOINT_PATH\"], config_id),\n    max_epochs=model.hparams.epochs,\n    accelerator=fun_control[\"accelerator\"],\n    devices=fun_control[\"devices\"],\n    logger=TensorBoardLogger(\n        save_dir=fun_control[\"TENSORBOARD_PATH\"],\n        version=config_id,\n        default_hp_metric=True,\n        log_graph=fun_control[\"log_graph\"],\n    ),\n    callbacks=[\n        EarlyStopping(monitor=\"val_loss\", patience=config[\"patience\"], mode=\"min\", strict=False, verbose=False)\n    ],\n    enable_progress_bar=enable_progress_bar,\n)\n\nNext, the fit() method is called to train the model.\n\n# Pass the datamodule as arg to trainer.fit to override model hooks :)\ntrainer.fit(model=model, datamodule=dm)\n\nFinally, the validate() method is called to validate the model. The validate() method returns the validation loss.\n\n# Test best model on validation and test set\n# result = trainer.validate(model=model, datamodule=dm, ckpt_path=\"last\")\nresult = trainer.validate(model=model, datamodule=dm)\n# unlist the result (from a list of one dict)\nresult = result[0]\nreturn result[\"val_loss\"]",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>HPT PyTorch Lightning: Data</span>"
    ]
  },
  {
    "objectID": "600_spot_lightning_data.html#further-information",
    "href": "600_spot_lightning_data.html#further-information",
    "title": "40  HPT PyTorch Lightning: Data",
    "section": "40.6 Further Information",
    "text": "40.6 Further Information\n\n40.6.1 Preprocessing\nPreprocessing is handled by Lightning and PyTorch. It is described in the LIGHTNINGDATAMODULE documentation. Here you can find information about the transforms methods.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>HPT PyTorch Lightning: Data</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_diabetes.html",
    "href": "601_spot_hpt_light_diabetes.html",
    "title": "41  Hyperparameter Tuning with spotpython and PyTorch Lightning for the Diabetes Data Set",
    "section": "",
    "text": "41.1 The Basic Setting\nIn this section, we will show how spotpython can be integrated into the PyTorch Lightning training workflow for a regression task. It demonstrates how easy it is to use spotpython to tune hyperparameters for a PyTorch Lightning model.\nimport os\nfrom math import inf\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nAfter importing the necessary libraries, the fun_control dictionary is set up via the fun_control_init function. The fun_control dictionary contains\nThe HyperLight class is used to define the objective function fun. It connects the PyTorch and the spotpython methods and is provided by spotpython.\nfrom spotpython.data.diabetes import Diabetes\nfrom spotpython.hyperdict.light_hyper_dict import LightHyperDict\nfrom spotpython.fun.hyperlight import HyperLight\nfrom spotpython.utils.init import (fun_control_init, surrogate_control_init, design_control_init)\nfrom spotpython.utils.eda import print_exp_table, print_res_table\nfrom spotpython.spot import Spot\nfrom spotpython.utils.file import get_experiment_filename\n\nPREFIX=\"601\"\n\ndata_set = Diabetes()\n\nfun_control = fun_control_init(\n    PREFIX=PREFIX,\n    fun_evals=inf,\n    max_time=1,\n    data_set = data_set,\n    core_model_name=\"light.regression.NNLinearRegressor\",\n    hyperdict=LightHyperDict,\n    _L_in=10,\n    _L_out=1)\n\nfun = HyperLight().fun\n\nmodule_name: light\nsubmodule_name: regression\nmodel_name: NNLinearRegressor\nThe method set_hyperparameter allows the user to modify default hyperparameter settings. Here we modify some hyperparameters to keep the model small and to decrease the tuning time.\nfrom spotpython.hyperparameters.values import set_hyperparameter\nset_hyperparameter(fun_control, \"optimizer\", [ \"Adadelta\", \"Adam\", \"Adamax\"])\nset_hyperparameter(fun_control, \"l1\", [3,4])\nset_hyperparameter(fun_control, \"epochs\", [3,7])\nset_hyperparameter(fun_control, \"batch_size\", [4,11])\nset_hyperparameter(fun_control, \"dropout_prob\", [0.0, 0.025])\nset_hyperparameter(fun_control, \"patience\", [2,3])\n\ndesign_control = design_control_init(init_size=10)\nprint_exp_table(fun_control)\n\n| name           | type   | default   |   lower |   upper | transform             |\n|----------------|--------|-----------|---------|---------|-----------------------|\n| l1             | int    | 3         |     3   |   4     | transform_power_2_int |\n| epochs         | int    | 4         |     3   |   7     | transform_power_2_int |\n| batch_size     | int    | 4         |     4   |  11     | transform_power_2_int |\n| act_fn         | factor | ReLU      |     0   |   5     | None                  |\n| optimizer      | factor | SGD       |     0   |   2     | None                  |\n| dropout_prob   | float  | 0.01      |     0   |   0.025 | None                  |\n| lr_mult        | float  | 1.0       |     0.1 |  10     | None                  |\n| patience       | int    | 2         |     2   |   3     | transform_power_2_int |\n| batch_norm     | factor | 0         |     0   |   1     | None                  |\n| initialization | factor | Default   |     0   |   4     | None                  |\nFinally, a Spot object is created. Calling the method run() starts the hyperparameter tuning process.\nS = Spot(fun=fun,fun_control=fun_control, design_control=design_control)\nS.run()\n\ntrain_model result: {'val_loss': 23075.09765625, 'hp_metric': 23075.09765625}\n\n\ntrain_model result: {'val_loss': 3466.6259765625, 'hp_metric': 3466.6259765625}\n\n\ntrain_model result: {'val_loss': 4775.9482421875, 'hp_metric': 4775.9482421875}\n\n\ntrain_model result: {'val_loss': 23974.962890625, 'hp_metric': 23974.962890625}\n\n\ntrain_model result: {'val_loss': 22921.740234375, 'hp_metric': 22921.740234375}\n\n\ntrain_model result: {'val_loss': 4060.3369140625, 'hp_metric': 4060.3369140625}\n\n\ntrain_model result: {'val_loss': 20739.09375, 'hp_metric': 20739.09375}\n\n\ntrain_model result: {'val_loss': 4064.956298828125, 'hp_metric': 4064.956298828125}\n\n\ntrain_model result: {'val_loss': 20911.953125, 'hp_metric': 20911.953125}\ntrain_model result: {'val_loss': 23951.484375, 'hp_metric': 23951.484375}\n\n\ntrain_model result: {'val_loss': 3396.2470703125, 'hp_metric': 3396.2470703125}\nspotpython tuning: 3396.2470703125 [----------] 1.86% \n\n\ntrain_model result: {'val_loss': nan, 'hp_metric': nan}\ntrain_model result: {'val_loss': nan, 'hp_metric': nan}\nspotpython tuning: 3396.2470703125 [----------] 3.26% \n\n\ntrain_model result: {'val_loss': 3414.830078125, 'hp_metric': 3414.830078125}\nspotpython tuning: 3396.2470703125 [#---------] 6.21% \n\n\ntrain_model result: {'val_loss': 23692.912109375, 'hp_metric': 23692.912109375}\nspotpython tuning: 3396.2470703125 [#---------] 7.69% \n\n\ntrain_model result: {'val_loss': 8255.0693359375, 'hp_metric': 8255.0693359375}\nspotpython tuning: 3396.2470703125 [#---------] 10.66% \n\n\ntrain_model result: {'val_loss': 17554.509765625, 'hp_metric': 17554.509765625}\nspotpython tuning: 3396.2470703125 [#---------] 12.33% \n\n\ntrain_model result: {'val_loss': 8407.7724609375, 'hp_metric': 8407.7724609375}\nspotpython tuning: 3396.2470703125 [##--------] 15.34% \n\n\ntrain_model result: {'val_loss': 2980.89794921875, 'hp_metric': 2980.89794921875}\nspotpython tuning: 2980.89794921875 [##--------] 18.83% \n\n\ntrain_model result: {'val_loss': 3568.241943359375, 'hp_metric': 3568.241943359375}\nspotpython tuning: 2980.89794921875 [##--------] 21.29% \n\n\ntrain_model result: {'val_loss': 3090.523193359375, 'hp_metric': 3090.523193359375}\nspotpython tuning: 2980.89794921875 [##--------] 23.90% \n\n\ntrain_model result: {'val_loss': 12307.81640625, 'hp_metric': 12307.81640625}\nspotpython tuning: 2980.89794921875 [###-------] 26.08% \n\n\ntrain_model result: {'val_loss': 4920.1708984375, 'hp_metric': 4920.1708984375}\nspotpython tuning: 2980.89794921875 [###-------] 29.33% \n\n\ntrain_model result: {'val_loss': 8808.490234375, 'hp_metric': 8808.490234375}\nspotpython tuning: 2980.89794921875 [####------] 39.95% \n\n\ntrain_model result: {'val_loss': 22241.390625, 'hp_metric': 22241.390625}\nspotpython tuning: 2980.89794921875 [####------] 42.92% \n\n\ntrain_model result: {'val_loss': 3245.012939453125, 'hp_metric': 3245.012939453125}\nspotpython tuning: 2980.89794921875 [#####-----] 45.82% \n\n\ntrain_model result: {'val_loss': 3300.112548828125, 'hp_metric': 3300.112548828125}\nspotpython tuning: 2980.89794921875 [#####-----] 49.15% \n\n\ntrain_model result: {'val_loss': 3785.927978515625, 'hp_metric': 3785.927978515625}\nspotpython tuning: 2980.89794921875 [#####-----] 52.65% \n\n\ntrain_model result: {'val_loss': 1.284459928928387e+18, 'hp_metric': 1.284459928928387e+18}\nspotpython tuning: 2980.89794921875 [######----] 55.68% \n\n\ntrain_model result: {'val_loss': 5260.1796875, 'hp_metric': 5260.1796875}\nspotpython tuning: 2980.89794921875 [######----] 57.83% \n\n\ntrain_model result: {'val_loss': 23540.33984375, 'hp_metric': 23540.33984375}\nspotpython tuning: 2980.89794921875 [######----] 61.11% \n\n\ntrain_model result: {'val_loss': 6140.5615234375, 'hp_metric': 6140.5615234375}\nspotpython tuning: 2980.89794921875 [#######---] 67.74% \n\n\ntrain_model result: {'val_loss': 16852.33984375, 'hp_metric': 16852.33984375}\nspotpython tuning: 2980.89794921875 [#######---] 73.57% \n\n\ntrain_model result: {'val_loss': 19499.26171875, 'hp_metric': 19499.26171875}\nspotpython tuning: 2980.89794921875 [########--] 79.79% \n\n\ntrain_model result: {'val_loss': 3554.0283203125, 'hp_metric': 3554.0283203125}\nspotpython tuning: 2980.89794921875 [########--] 84.97% \n\n\ntrain_model result: {'val_loss': 3105.140869140625, 'hp_metric': 3105.140869140625}\nspotpython tuning: 2980.89794921875 [#########-] 89.06% \n\n\ntrain_model result: {'val_loss': 23906.033203125, 'hp_metric': 23906.033203125}\nspotpython tuning: 2980.89794921875 [#########-] 92.57% \n\n\ntrain_model result: {'val_loss': 23956.08984375, 'hp_metric': 23956.08984375}\nspotpython tuning: 2980.89794921875 [##########] 96.75% \n\n\ntrain_model result: {'val_loss': 22778.099609375, 'hp_metric': 22778.099609375}\nspotpython tuning: 2980.89794921875 [##########] 100.00% Done...\n\nExperiment saved to 601_res.pkl\n\n\n&lt;spotpython.spot.spot.Spot at 0x103a24320&gt;",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Hyperparameter Tuning with `spotpython` and `PyTorch` Lightning for the Diabetes Data Set</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_diabetes.html#sec-basic-setup-601",
    "href": "601_spot_hpt_light_diabetes.html#sec-basic-setup-601",
    "title": "41  Hyperparameter Tuning with spotpython and PyTorch Lightning for the Diabetes Data Set",
    "section": "",
    "text": "PREFIX: a unique identifier for the experiment\nfun_evals: the number of function evaluations\nmax_time: the maximum run time in minutes\ndata_set: the data set. Here we use the Diabetes data set that is provided by spotpython.\ncore_model_name: the class name of the neural network model. This neural network model is provided by spotpython.\nhyperdict: the hyperparameter dictionary. This dictionary is used to define the hyperparameters of the neural network model. It is also provided by spotpython.\n_L_in: the number of input features. Since the Diabetes data set has 10 features, _L_in is set to 10.\n_L_out: the number of output features. Since we want to predict a single value, _L_out is set to 1.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Hyperparameter Tuning with `spotpython` and `PyTorch` Lightning for the Diabetes Data Set</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_diabetes.html#looking-at-the-results",
    "href": "601_spot_hpt_light_diabetes.html#looking-at-the-results",
    "title": "41  Hyperparameter Tuning with spotpython and PyTorch Lightning for the Diabetes Data Set",
    "section": "41.2 Looking at the Results",
    "text": "41.2 Looking at the Results\n\n41.2.1 Tuning Progress\nAfter the hyperparameter tuning run is finished, the progress of the hyperparameter tuning can be visualized with spotpython’s method plot_progress. The black points represent the performace values (score or metric) of hyperparameter configurations from the initial design, whereas the red points represents the hyperparameter configurations found by the surrogate model based optimization.\n\nS.plot_progress()\n\n\n\n\n\n\n\n\n\n\n41.2.2 Tuned Hyperparameters and Their Importance\nResults can be printed in tabular form.\n\nprint_res_table(S)\n\n| name           | type   | default   |   lower |   upper | tuned             | transform             |   importance | stars   |\n|----------------|--------|-----------|---------|---------|-------------------|-----------------------|--------------|---------|\n| l1             | int    | 3         |     3.0 |     4.0 | 4.0               | transform_power_2_int |         0.00 |         |\n| epochs         | int    | 4         |     3.0 |     7.0 | 4.0               | transform_power_2_int |         0.00 |         |\n| batch_size     | int    | 4         |     4.0 |    11.0 | 6.0               | transform_power_2_int |         0.00 |         |\n| act_fn         | factor | ReLU      |     0.0 |     5.0 | ReLU              | None                  |         0.00 |         |\n| optimizer      | factor | SGD       |     0.0 |     2.0 | Adamax            | None                  |       100.00 | ***     |\n| dropout_prob   | float  | 0.01      |     0.0 |   0.025 | 0.025             | None                  |         0.00 |         |\n| lr_mult        | float  | 1.0       |     0.1 |    10.0 | 4.935071237769679 | None                  |         0.00 |         |\n| patience       | int    | 2         |     2.0 |     3.0 | 3.0               | transform_power_2_int |         0.00 |         |\n| batch_norm     | factor | 0         |     0.0 |     1.0 | 0                 | None                  |        71.47 | **      |\n| initialization | factor | Default   |     0.0 |     4.0 | xavier_normal     | None                  |       100.00 | ***     |\n\n\nA histogram can be used to visualize the most important hyperparameters.\n\nS.plot_importance(threshold=1.0)\n\n\n\n\n\n\n\n\n\nS.plot_important_hyperparameter_contour(max_imp=3)\n\nl1:  0.001\nepochs:  0.001\nbatch_size:  0.001\nact_fn:  0.001\noptimizer:  100.0\ndropout_prob:  0.001\nlr_mult:  0.001\npatience:  0.001\nbatch_norm:  71.46576951548953\ninitialization:  100.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n41.2.3 Get the Tuned Architecture\n\nimport pprint\nfrom spotpython.hyperparameters.values import get_tuned_architecture\nconfig = get_tuned_architecture(S)\npprint.pprint(config)\n\n{'act_fn': ReLU(),\n 'batch_norm': False,\n 'batch_size': 64,\n 'dropout_prob': 0.025,\n 'epochs': 16,\n 'initialization': 'xavier_normal',\n 'l1': 16,\n 'lr_mult': 4.935071237769679,\n 'optimizer': 'Adamax',\n 'patience': 8}\n\n\n\n\n41.2.4 Test on the full data set\n\n# set the value of the key \"TENSORBOARD_CLEAN\" to True in the fun_control dictionary and use the update() method to update the fun_control dictionary\nfun_control.update({\"TENSORBOARD_CLEAN\": True})\nfun_control.update({\"tensorboard_log\": True})\n\n\nfrom spotpython.light.testmodel import test_model\nfrom spotpython.utils.init import get_feature_names\n\ntest_model(config, fun_control)\nget_feature_names(fun_control)\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃        Test metric        ┃       DataLoader 0        ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│         hp_metric         │     3650.771240234375     │\n│         val_loss          │     3650.771240234375     │\n└───────────────────────────┴───────────────────────────┘\n\n\n\ntest_model result: {'val_loss': 3650.771240234375, 'hp_metric': 3650.771240234375}\n\n\n['age',\n 'sex',\n 'bmi',\n 'bp',\n 's1_tc',\n 's2_ldl',\n 's3_hdl',\n 's4_tch',\n 's5_ltg',\n 's6_glu']",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Hyperparameter Tuning with `spotpython` and `PyTorch` Lightning for the Diabetes Data Set</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_diabetes.html#cross-validation-with-lightning",
    "href": "601_spot_hpt_light_diabetes.html#cross-validation-with-lightning",
    "title": "41  Hyperparameter Tuning with spotpython and PyTorch Lightning for the Diabetes Data Set",
    "section": "41.3 Cross Validation With Lightning",
    "text": "41.3 Cross Validation With Lightning\n\nThe KFold class from sklearn.model_selection is used to generate the folds for cross-validation.\nThese mechanism is used to generate the folds for the final evaluation of the model.\nThe CrossValidationDataModule class [SOURCE] is used to generate the folds for the hyperparameter tuning process.\nIt is called from the cv_model function [SOURCE].\n\n\nconfig\n\n{'l1': 16,\n 'epochs': 16,\n 'batch_size': 64,\n 'act_fn': ReLU(),\n 'optimizer': 'Adamax',\n 'dropout_prob': 0.025,\n 'lr_mult': 4.935071237769679,\n 'patience': 8,\n 'batch_norm': False,\n 'initialization': 'xavier_normal'}\n\n\n\nfrom spotpython.light.cvmodel import cv_model\nfun_control.update({\"k_folds\": 2})\nfun_control.update({\"test_size\": 0.6})\ncv_model(config, fun_control)\n\nk: 0\n\n\ntrain_model result: {'val_loss': 12037.67578125, 'hp_metric': 12037.67578125}\nk: 1\ntrain_model result: {'val_loss': 3403.876953125, 'hp_metric': 3403.876953125}\n\n\n7720.7763671875",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Hyperparameter Tuning with `spotpython` and `PyTorch` Lightning for the Diabetes Data Set</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_diabetes.html#extending-the-basic-setup",
    "href": "601_spot_hpt_light_diabetes.html#extending-the-basic-setup",
    "title": "41  Hyperparameter Tuning with spotpython and PyTorch Lightning for the Diabetes Data Set",
    "section": "41.4 Extending the Basic Setup",
    "text": "41.4 Extending the Basic Setup\nThis basic setup can be adapted to user-specific needs in many ways. For example, the user can specify a custom data set, a custom model, or a custom loss function. The following sections provide more details on how to customize the hyperparameter tuning process. Before we proceed, we will provide an overview of the basic settings of the hyperparameter tuning process and explain the parameters used so far.\n\n41.4.1 General Experiment Setup\nTo keep track of the different experiments, we use a PREFIX for the experiment name. The PREFIX is used to create a unique experiment name. The PREFIX is also used to create a unique TensorBoard folder, which is used to store the TensorBoard log files.\nspotpython allows the specification of two different types of stopping criteria: first, the number of function evaluations (fun_evals), and second, the maximum run time in seconds (max_time). Here, we will set the number of function evaluations to infinity and the maximum run time to one minute.\nmax_time is set to one minute for demonstration purposes. For real experiments, this value should be increased. Note, the total run time may exceed the specified max_time, because the initial design is always evaluated, even if this takes longer than max_time.\n\n\n41.4.2 Data Setup\nHere, we have provided the Diabetes data set class, which is a subclass of torch.utils.data.Dataset. Data preprocessing is handled by Lightning and PyTorch. It is described in the LIGHTNINGDATAMODULE documentation.\nThe data splitting, i.e., the generation of training, validation, and testing data, is handled by Lightning.\n\n\n41.4.3 Objective Function fun\nThe objective function fun from the class HyperLight [SOURCE] is selected next. It implements an interface from PyTorch’s training, validation, and testing methods to spotpython.\n\n\n41.4.4 Core-Model Setup\nBy using core_model_name = \"light.regression.NNLinearRegressor\", the spotpython model class NetLightRegression [SOURCE] from the light.regression module is selected.\n\n\n41.4.5 Hyperdict Setup\nFor a given core_model_name, the corresponding hyperparameters are automatically loaded from the associated dictionary, which is stored as a JSON file. The JSON file contains hyperparameter type information, names, and bounds. For spotpython models, the hyperparameters are stored in the LightHyperDict, see [SOURCE] Alternatively, you can load a local hyper_dict. The hyperdict uses the default hyperparameter settings. These can be modified as described in Section 11.15.1.\n\n\n41.4.6 Other Settings\nThere are several additional parameters that can be specified, e.g., since we did not specify a loss function, mean_squared_error is used, which is the default loss function. These will be explained in more detail in the following sections.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Hyperparameter Tuning with `spotpython` and `PyTorch` Lightning for the Diabetes Data Set</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_diabetes.html#sec-tensorboard-601-diabetes",
    "href": "601_spot_hpt_light_diabetes.html#sec-tensorboard-601-diabetes",
    "title": "41  Hyperparameter Tuning with spotpython and PyTorch Lightning for the Diabetes Data Set",
    "section": "41.5 Tensorboard",
    "text": "41.5 Tensorboard\nThe textual output shown in the console (or code cell) can be visualized with Tensorboard, if the argument tensorboard_log to fun_control_init() is set to True. The Tensorboard log files are stored in the runs folder. To start Tensorboard, run the following command in the terminal:\ntensorboard --logdir=\"runs/\"\nFurther information can be found in the PyTorch Lightning documentation for Tensorboard.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Hyperparameter Tuning with `spotpython` and `PyTorch` Lightning for the Diabetes Data Set</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_diabetes.html#loading-the-saved-experiment-and-getting-the-hyperparameters-of-the-tuned-model",
    "href": "601_spot_hpt_light_diabetes.html#loading-the-saved-experiment-and-getting-the-hyperparameters-of-the-tuned-model",
    "title": "41  Hyperparameter Tuning with spotpython and PyTorch Lightning for the Diabetes Data Set",
    "section": "41.6 Loading the Saved Experiment and Getting the Hyperparameters of the Tuned Model",
    "text": "41.6 Loading the Saved Experiment and Getting the Hyperparameters of the Tuned Model\nTo get the tuned hyperparameters as a dictionary, the get_tuned_architecture function can be used.\n\nfrom spotpython.utils.file import load_result\nspot_tuner = load_result(PREFIX=PREFIX)\nconfig = get_tuned_architecture(spot_tuner)\nconfig\n\nLoaded experiment from 601_res.pkl\n\n\n{'l1': 16,\n 'epochs': 16,\n 'batch_size': 64,\n 'act_fn': ReLU(),\n 'optimizer': 'Adamax',\n 'dropout_prob': 0.025,\n 'lr_mult': 4.935071237769679,\n 'patience': 8,\n 'batch_norm': False,\n 'initialization': 'xavier_normal'}",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Hyperparameter Tuning with `spotpython` and `PyTorch` Lightning for the Diabetes Data Set</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_diabetes.html#using-the-spotgui",
    "href": "601_spot_hpt_light_diabetes.html#using-the-spotgui",
    "title": "41  Hyperparameter Tuning with spotpython and PyTorch Lightning for the Diabetes Data Set",
    "section": "41.7 Using the spotgui",
    "text": "41.7 Using the spotgui\nThe spotgui [github] provides a convenient way to interact with the hyperparameter tuning process. To obtain the settings from Section 41.1, the spotgui can be started as shown in Figure 41.1.\n\n\n\n\n\n\nFigure 41.1: spotgui",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Hyperparameter Tuning with `spotpython` and `PyTorch` Lightning for the Diabetes Data Set</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_diabetes.html#summary",
    "href": "601_spot_hpt_light_diabetes.html#summary",
    "title": "41  Hyperparameter Tuning with spotpython and PyTorch Lightning for the Diabetes Data Set",
    "section": "41.8 Summary",
    "text": "41.8 Summary\nThis section presented an introduction to the basic setup of hyperparameter tuning with spotpython and PyTorch Lightning.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Hyperparameter Tuning with `spotpython` and `PyTorch` Lightning for the Diabetes Data Set</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_user_data.html",
    "href": "601_spot_hpt_light_user_data.html",
    "title": "42  Hyperparameter Tuning with PyTorch Lightning and User Data Sets",
    "section": "",
    "text": "42.1 Loading a User Specified Data Set\nIn this section, we will show how user specfied data can be used for the PyTorch Lightning hyperparameter tuning workflow with spotpython.\nUsing a user-specified data set is straightforward.\nThe user simply needs to provide a data set and loads is as a spotpython CVSDataset() class by specifying the path, filename, and target column.\nConsider the following example, where the user has a data set stored in the userData directory. The data set is stored in a file named data.csv. The target column is named target. To show the data, it is loaded as a pandas data frame and the first 5 rows are displayed. This step is not necessary for the hyperparameter tuning process, but it is useful for understanding the data.\n# load the csv data set as a pandas dataframe and dislay the first 5 rows\nimport pandas as pd\ndata = pd.read_csv(\"./userData/data.csv\")\nprint(data.head())\n\n        age       sex       bmi        bp        s1        s2        s3  \\\n0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n2  0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n\n         s4        s5        s6  target  \n0 -0.002592  0.019907 -0.017646   151.0  \n1 -0.039493 -0.068332 -0.092204    75.0  \n2 -0.002592  0.002861 -0.025930   141.0  \n3  0.034309  0.022688 -0.009362   206.0  \n4 -0.002592 -0.031988 -0.046641   135.0\nNext, the data set is loaded as a spotpython CSVDataset() class. This step is necessary for the hyperparameter tuning process.\nfrom spotpython.data.csvdataset import CSVDataset\nimport torch\ndata_set = CSVDataset(directory=\"./userData/\",\n                     filename=\"data.csv\",\n                     target_column=\"target\",\n                     feature_type=torch.float32,\n                     target_type=torch.float32,\n                     rmNA=True)\nprint(len(data_set))\n\n442\nThe following step is not necessary for the hyperparameter tuning process, but it is useful for understanding the data. The data set is loaded as a DataLoader from torch.utils.data to check the data.\n# Set batch size for DataLoader\nbatch_size = 5\n# Create DataLoader\nfrom torch.utils.data import DataLoader\ndataloader = DataLoader(data_set, batch_size=batch_size, shuffle=False)\n\n# Iterate over the data in the DataLoader\nfor batch in dataloader:\n    inputs, targets = batch\n    print(f\"Batch Size: {inputs.size(0)}\")\n    print(f\"Inputs Shape: {inputs.shape}\")\n    print(f\"Targets Shape: {targets.shape}\")\n    print(\"---------------\")\n    print(f\"Inputs: {inputs}\")\n    print(f\"Targets: {targets}\")\n    break\n\nBatch Size: 5\nInputs Shape: torch.Size([5, 10])\nTargets Shape: torch.Size([5])\n---------------\nInputs: tensor([[ 0.0381,  0.0507,  0.0617,  0.0219, -0.0442, -0.0348, -0.0434, -0.0026,\n          0.0199, -0.0176],\n        [-0.0019, -0.0446, -0.0515, -0.0263, -0.0084, -0.0192,  0.0744, -0.0395,\n         -0.0683, -0.0922],\n        [ 0.0853,  0.0507,  0.0445, -0.0057, -0.0456, -0.0342, -0.0324, -0.0026,\n          0.0029, -0.0259],\n        [-0.0891, -0.0446, -0.0116, -0.0367,  0.0122,  0.0250, -0.0360,  0.0343,\n          0.0227, -0.0094],\n        [ 0.0054, -0.0446, -0.0364,  0.0219,  0.0039,  0.0156,  0.0081, -0.0026,\n         -0.0320, -0.0466]])\nTargets: tensor([151.,  75., 141., 206., 135.])\nSimilar to the setting from Section 41.1, the hyperparameter tuning setup is defined. Instead of using the Diabetes data set, the user data set is used. The data_set parameter is set to the user data set. The fun_control dictionary is set up via the fun_control_init function.\nNote, that we have modified the fun_evals parameter to 12 and the init_size to 7 to reduce the computational time for this example.\nfrom spotpython.hyperdict.light_hyper_dict import LightHyperDict\nfrom spotpython.fun.hyperlight import HyperLight\nfrom spotpython.utils.init import (fun_control_init, surrogate_control_init, design_control_init)\nfrom spotpython.utils.eda import print_res_table\nfrom spotpython.hyperparameters.values import set_hyperparameter\nfrom spotpython.spot import Spot\n\nfun_control = fun_control_init(\n    PREFIX=\"601\",\n    fun_evals=12,\n    max_time=1,\n    data_set = data_set,\n    core_model_name=\"light.regression.NNLinearRegressor\",\n    hyperdict=LightHyperDict,\n    _L_in=10,\n    _L_out=1)\n\ndesign_control = design_control_init(init_size=7)\n\nset_hyperparameter(fun_control, \"initialization\", [\"Default\"])\n\nfun = HyperLight().fun\n\nspot_tuner = Spot(fun=fun,fun_control=fun_control, design_control=design_control)\n\nmodule_name: light\nsubmodule_name: regression\nmodel_name: NNLinearRegressor\nres = spot_tuner.run()\nprint_res_table(spot_tuner)\nspot_tuner.plot_important_hyperparameter_contour(max_imp=3)\n\ntrain_model(): trainer.fit failed with exception: SparseAdam does not support dense gradients, please consider Adam instead\ntrain_model result: {'val_loss': 23320.16015625, 'hp_metric': 23320.16015625}\n\n\ntrain_model result: {'val_loss': nan, 'hp_metric': nan}\n\n\ntrain_model result: {'val_loss': 4052.16845703125, 'hp_metric': 4052.16845703125}\n\n\ntrain_model result: {'val_loss': 3584.89013671875, 'hp_metric': 3584.89013671875}\ntrain_model result: {'val_loss': nan, 'hp_metric': nan}\n\n\ntrain_model result: {'val_loss': nan, 'hp_metric': nan}\n\n\ntrain_model result: {'val_loss': 18160.900390625, 'hp_metric': 18160.900390625}\n\n\ntrain_model(): trainer.fit failed with exception: SparseAdam does not support dense gradients, please consider Adam instead\ntrain_model result: {'val_loss': 180457504.0, 'hp_metric': 180457504.0}\nspotpython tuning: 3584.89013671875 [####------] 41.67% \n\n\ntrain_model result: {'val_loss': nan, 'hp_metric': nan}\n\n\ntrain_model result: {'val_loss': 26572.333984375, 'hp_metric': 26572.333984375}\nspotpython tuning: 3584.89013671875 [#####-----] 50.00% \n\n\ntrain_model result: {'val_loss': 4510.11474609375, 'hp_metric': 4510.11474609375}\nspotpython tuning: 3584.89013671875 [######----] 58.33% \n\n\ntrain_model result: {'val_loss': 2946.150390625, 'hp_metric': 2946.150390625}\nspotpython tuning: 2946.150390625 [#######---] 66.67% \n\n\ntrain_model result: {'val_loss': 4247.826171875, 'hp_metric': 4247.826171875}\nspotpython tuning: 2946.150390625 [########--] 75.00% \n\n\ntrain_model result: {'val_loss': 3915.138916015625, 'hp_metric': 3915.138916015625}\nspotpython tuning: 2946.150390625 [########--] 83.33% \n\n\ntrain_model result: {'val_loss': 4119.43701171875, 'hp_metric': 4119.43701171875}\nspotpython tuning: 2946.150390625 [#########-] 91.67% \nExperiment saved to 601_res.pkl\n| name           | type   | default   |   lower |   upper | tuned              | transform             |   importance | stars   |\n|----------------|--------|-----------|---------|---------|--------------------|-----------------------|--------------|---------|\n| l1             | int    | 3         |     3.0 |     8.0 | 5.0                | transform_power_2_int |         0.00 |         |\n| epochs         | int    | 4         |     4.0 |     9.0 | 5.0                | transform_power_2_int |         0.00 |         |\n| batch_size     | int    | 4         |     1.0 |     4.0 | 3.0                | transform_power_2_int |         0.00 |         |\n| act_fn         | factor | ReLU      |     0.0 |     5.0 | ELU                | None                  |         0.00 |         |\n| optimizer      | factor | SGD       |     0.0 |    11.0 | AdamW              | None                  |       100.00 | ***     |\n| dropout_prob   | float  | 0.01      |     0.0 |    0.25 | 0.1316215890425084 | None                  |         0.00 |         |\n| lr_mult        | float  | 1.0       |     0.1 |    10.0 | 6.381928597834528  | None                  |         0.00 |         |\n| patience       | int    | 2         |     2.0 |     6.0 | 4.0                | transform_power_2_int |         0.00 |         |\n| batch_norm     | factor | 0         |     0.0 |     1.0 | 1                  | None                  |        52.12 | **      |\n| initialization | factor | Default   |     0.0 |     0.0 | Default            | None                  |         0.00 |         |\nl1:  0.0026352560132594494\nepochs:  0.0026352560132594494\nbatch_size:  0.0026352560132594494\nact_fn:  0.0026352560132594494\noptimizer:  100.0\ndropout_prob:  0.0026352560132594494\nlr_mult:  0.0026352560132594494\npatience:  0.0026352560132594494\nbatch_norm:  52.123942468760575",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Hyperparameter Tuning with PyTorch Lightning and User Data Sets</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_user_data.html#summary",
    "href": "601_spot_hpt_light_user_data.html#summary",
    "title": "42  Hyperparameter Tuning with PyTorch Lightning and User Data Sets",
    "section": "42.2 Summary",
    "text": "42.2 Summary\nThis section showed how to use user-specified data sets for the hyperparameter tuning process with spotpython. The user needs to provide the data set and load it as a spotpython CSVDataset() class.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Hyperparameter Tuning with PyTorch Lightning and User Data Sets</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_user_model.html",
    "href": "601_spot_hpt_light_user_model.html",
    "title": "43  Hyperparameter Tuning with PyTorch Lightning and User Models",
    "section": "",
    "text": "43.1 Using a User Specified Model\nIn this section, we will show how a user defined model can be used for the PyTorch Lightning hyperparameter tuning workflow with spotpython.\nAs templates, we provide the following three files that allow the user to specify a model in the /userModel directory:\nThe my_regressor.py file contains the model class, which is a subclass of nn.Module. The my_hyperdict.json file contains the hyperparameter settings as a dictionary, which are loaded via the my_hyperdict.py file.\nNote, that we have to add the path to the userModel directory to the sys.path list as shown below.\nimport sys\nsys.path.insert(0, './userModel')\nimport my_regressor\nimport my_hyper_dict\nfrom spotpython.hyperparameters.values import add_core_model_to_fun_control\n\nfrom spotpython.data.diabetes import Diabetes\nfrom spotpython.hyperdict.light_hyper_dict import LightHyperDict\nfrom spotpython.fun.hyperlight import HyperLight\nfrom spotpython.utils.init import (fun_control_init, design_control_init)\nfrom spotpython.utils.eda import print_res_table\nfrom spotpython.hyperparameters.values import set_hyperparameter\nfrom spotpython.spot import Spot\n\nfun_control = fun_control_init(\n    PREFIX=\"601-user-model\",\n    fun_evals=inf,\n    max_time=1,\n    data_set = Diabetes(),\n    _L_in=10,\n    _L_out=1)\n\nadd_core_model_to_fun_control(fun_control=fun_control,\n                              core_model=my_regressor.MyRegressor,\n                              hyper_dict=my_hyper_dict.MyHyperDict)\n\ndesign_control = design_control_init(init_size=7)\n\nfun = HyperLight().fun\n\nspot_tuner = Spot(fun=fun,fun_control=fun_control, design_control=design_control)\nres = spot_tuner.run()\nprint_res_table(spot_tuner)\nspot_tuner.plot_important_hyperparameter_contour(max_imp=3)\n\ntrain_model(): trainer.fit failed with exception: SparseAdam does not support dense gradients, please consider Adam instead\ntrain_model result: {'val_loss': 23988.361328125, 'hp_metric': 23988.361328125}\n\n\ntrain_model result: {'val_loss': nan, 'hp_metric': nan}\n\n\ntrain_model result: {'val_loss': 3127.356689453125, 'hp_metric': 3127.356689453125}\n\n\ntrain_model result: {'val_loss': 4815.912109375, 'hp_metric': 4815.912109375}\n\n\ntrain_model result: {'val_loss': nan, 'hp_metric': nan}\n\n\ntrain_model result: {'val_loss': 2994.751953125, 'hp_metric': 2994.751953125}\n\n\ntrain_model result: {'val_loss': 2893.5380859375, 'hp_metric': 2893.5380859375}\n\n\ntrain_model result: {'val_loss': 2925.6025390625, 'hp_metric': 2925.6025390625}\nspotpython tuning: 2893.5380859375 [----------] 1.94% \n\n\ntrain_model result: {'val_loss': 4444.89453125, 'hp_metric': 4444.89453125}\nspotpython tuning: 2893.5380859375 [####------] 35.66% \n\n\ntrain_model result: {'val_loss': 4985.4736328125, 'hp_metric': 4985.4736328125}\nspotpython tuning: 2893.5380859375 [####------] 38.02% \n\n\ntrain_model result: {'val_loss': 4903.39306640625, 'hp_metric': 4903.39306640625}\nspotpython tuning: 2893.5380859375 [####------] 40.45% \n\n\ntrain_model result: {'val_loss': 4839.94140625, 'hp_metric': 4839.94140625}\nspotpython tuning: 2893.5380859375 [####------] 42.57% \n\n\ntrain_model result: {'val_loss': 3076.719970703125, 'hp_metric': 3076.719970703125}\nspotpython tuning: 2893.5380859375 [#####-----] 50.12% \n\n\ntrain_model(): trainer.fit failed with exception: SparseAdam does not support dense gradients, please consider Adam instead\ntrain_model result: {'val_loss': 24015.21484375, 'hp_metric': 24015.21484375}\nspotpython tuning: 2893.5380859375 [#####-----] 51.35% \n\n\ntrain_model result: {'val_loss': 3004.9287109375, 'hp_metric': 3004.9287109375}\nspotpython tuning: 2893.5380859375 [#####-----] 53.48% \n\n\ntrain_model result: {'val_loss': nan, 'hp_metric': nan}\n\n\ntrain_model result: {'val_loss': 3433.583740234375, 'hp_metric': 3433.583740234375}\nspotpython tuning: 2893.5380859375 [######----] 60.46% \n\n\ntrain_model result: {'val_loss': nan, 'hp_metric': nan}\n\n\ntrain_model result: {'val_loss': 6609.55078125, 'hp_metric': 6609.55078125}\nspotpython tuning: 2893.5380859375 [#######---] 65.92% \n\n\ntrain_model result: {'val_loss': nan, 'hp_metric': nan}\ntrain_model result: {'val_loss': 3098.64794921875, 'hp_metric': 3098.64794921875}\nspotpython tuning: 2893.5380859375 [##########] 99.70% \n\n\ntrain_model result: {'val_loss': 3154.20654296875, 'hp_metric': 3154.20654296875}\nspotpython tuning: 2893.5380859375 [##########] 100.00% Done...\n\nExperiment saved to 601-user-model_res.pkl\n| name           | type   | default   |   lower |   upper | tuned               | transform             |   importance | stars   |\n|----------------|--------|-----------|---------|---------|---------------------|-----------------------|--------------|---------|\n| l1             | int    | 3         |     3.0 |     8.0 | 5.0                 | transform_power_2_int |         0.00 |         |\n| epochs         | int    | 4         |     4.0 |     9.0 | 4.0                 | transform_power_2_int |       100.00 | ***     |\n| batch_size     | int    | 4         |     1.0 |     4.0 | 4.0                 | transform_power_2_int |         0.00 |         |\n| act_fn         | factor | ReLU      |     0.0 |     5.0 | ReLU                | None                  |         0.00 |         |\n| optimizer      | factor | SGD       |     0.0 |    11.0 | AdamW               | None                  |         0.00 |         |\n| dropout_prob   | float  | 0.01      |     0.0 |    0.25 | 0.14960635316721133 | None                  |         0.00 |         |\n| lr_mult        | float  | 1.0       |     0.1 |    10.0 | 9.293583024571447   | None                  |         0.01 |         |\n| patience       | int    | 2         |     2.0 |     6.0 | 3.0                 | transform_power_2_int |         0.00 |         |\n| initialization | factor | Default   |     0.0 |     4.0 | xavier_uniform      | None                  |         0.00 |         |\nl1:  0.001\nepochs:  100.0\nbatch_size:  0.001\nact_fn:  0.002746660332326428\noptimizer:  0.001\ndropout_prob:  0.001\nlr_mult:  0.008693918870498621\npatience:  0.001\ninitialization:  0.001",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Hyperparameter Tuning with PyTorch Lightning and User Models</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_user_model.html#using-a-user-specified-model",
    "href": "601_spot_hpt_light_user_model.html#using-a-user-specified-model",
    "title": "43  Hyperparameter Tuning with PyTorch Lightning and User Models",
    "section": "",
    "text": "my_regressor.py, see Section 43.2.4\nmy_hyperdict.json, see Section 43.2.3\nmy_hyperdict.py, see Section 43.2.2.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Hyperparameter Tuning with PyTorch Lightning and User Models</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_user_model.html#details",
    "href": "601_spot_hpt_light_user_model.html#details",
    "title": "43  Hyperparameter Tuning with PyTorch Lightning and User Models",
    "section": "43.2 Details",
    "text": "43.2 Details\n\n43.2.1 Model Setup\nBy using core_model_name = \"my_regressor.MyRegressor\", the user specified model class MyRegressor [SOURCE] is selected. For this given core_model_name, the local hyper_dict is loaded using the my_hyper_dict.py file as shown below.\n\n\n43.2.2 The my_hyper_dict.py File\nThe my_hyper_dict.py file must be placed in the /userModel directory. It provides a convenience function to load the hyperparameters from user specified the my_hyper_dict.json file, see Section 43.2.2. The user does not need to modify this file, if the JSON file is stored as my_hyper_dict.json. Alternative filenames can be specified via the filename argument (which is default set to \"my_hyper_dict.json\").\n\n\n43.2.3 The my_hyper_dict.json File\nThe my_hyper_dict.json file contains the hyperparameter settings as a dictionary, which are loaded via the my_hyper_dict.py file. The example below shows the content of the my_hyper_dict.json file.\n{\n    \"MyRegressor\": {\n        \"l1\": {\n            \"type\": \"int\",\n            \"default\": 3,\n            \"transform\": \"transform_power_2_int\",\n            \"lower\": 3,\n            \"upper\": 8\n        },\n        \"epochs\": {\n            \"type\": \"int\",\n            \"default\": 4,\n            \"transform\": \"transform_power_2_int\",\n            \"lower\": 4,\n            \"upper\": 9\n        },\n        \"batch_size\": {\n            \"type\": \"int\",\n            \"default\": 4,\n            \"transform\": \"transform_power_2_int\",\n            \"lower\": 1,\n            \"upper\": 4\n        },\n        \"act_fn\": {\n            \"levels\": [\n                \"Sigmoid\",\n                \"Tanh\",\n                \"ReLU\",\n                \"LeakyReLU\",\n                \"ELU\",\n                \"Swish\"\n            ],\n            \"type\": \"factor\",\n            \"default\": \"ReLU\",\n            \"transform\": \"None\",\n            \"class_name\": \"spotpython.torch.activation\",\n            \"core_model_parameter_type\": \"instance()\",\n            \"lower\": 0,\n            \"upper\": 5\n        },\n        \"optimizer\": {\n            \"levels\": [\n                \"Adadelta\",\n                \"Adagrad\",\n                \"Adam\",\n                \"AdamW\",\n                \"SparseAdam\",\n                \"Adamax\",\n                \"ASGD\",\n                \"NAdam\",\n                \"RAdam\",\n                \"RMSprop\",\n                \"Rprop\",\n                \"SGD\"\n            ],\n            \"type\": \"factor\",\n            \"default\": \"SGD\",\n            \"transform\": \"None\",\n            \"class_name\": \"torch.optim\",\n            \"core_model_parameter_type\": \"str\",\n            \"lower\": 0,\n            \"upper\": 11\n        },\n        \"dropout_prob\": {\n            \"type\": \"float\",\n            \"default\": 0.01,\n            \"transform\": \"None\",\n            \"lower\": 0.0,\n            \"upper\": 0.25\n        },\n        \"lr_mult\": {\n            \"type\": \"float\",\n            \"default\": 1.0,\n            \"transform\": \"None\",\n            \"lower\": 0.1,\n            \"upper\": 10.0\n        },\n        \"patience\": {\n            \"type\": \"int\",\n            \"default\": 2,\n            \"transform\": \"transform_power_2_int\",\n            \"lower\": 2,\n            \"upper\": 6\n        },\n        \"initialization\": {\n            \"levels\": [\n                \"Default\",\n                \"Kaiming\",\n                \"Xavier\"\n            ],\n            \"type\": \"factor\",\n            \"default\": \"Default\",\n            \"transform\": \"None\",\n            \"core_model_parameter_type\": \"str\",\n            \"lower\": 0,\n            \"upper\": 2\n        }\n    }\n}\n\n\n43.2.4 The my_regressor.py File\nThe my_regressor.py file contains [SOURCE] the model class, which is a subclass of nn.Module. It must implement the following methods:\n\n__init__(self, **kwargs): The constructor of the model class. The hyperparameters are passed as keyword arguments.\nforward(self, x: torch.Tensor) -&gt; torch.Tensor: The forward pass of the model. The input x is passed through the model and the output is returned.\ntraining_step(self, batch, batch_idx) -&gt; torch.Tensor: The training step of the model. It takes a batch of data and the batch index as input and returns the loss.\nvalidation_step(self, batch, batch_idx) -&gt; torch.Tensor: The validation step of the model. It takes a batch of data and the batch index as input and returns the loss.\ntest_step(self, batch, batch_idx) -&gt; torch.Tensor: The test step of the model. It takes a batch of data and the batch index as input and returns the loss.\npredict(self, x: torch.Tensor) -&gt; torch.Tensor: The prediction method of the model. It takes an input x and returns the prediction.\nconfigure_optimizers(self) -&gt; torch.optim.Optimizer: The method to configure the optimizer of the model. It returns the optimizer.\n\nThe file my_regressor.py must be placed in the /userModel directory. The user can modify the model class to implement a custom model architecture.\nWe will take a closer look at the methods defined in the my_regressor.py file in the next subsections.\n\n43.2.4.1 The __init__ Method\n__init__() initializes the MyRegressor object. It takes the following arguments:\n\nl1 (int): The number of neurons in the first hidden layer.\nepochs (int): The number of epochs to train the model for.\nbatch_size (int): The batch size to use during training.\ninitialization (str): The initialization method to use for the weights.\nact_fn (nn.Module): The activation function to use in the hidden layers.\noptimizer (str): The optimizer to use during training.\ndropout_prob (float): The probability of dropping out a neuron during training.\nlr_mult (float): The learning rate multiplier for the optimizer.\npatience (int): The number of epochs to wait before early stopping.\n_L_in (int): The number of input features. Not a hyperparameter, but needed to create the network.\n_L_out (int): The number of output classes. Not a hyperparameter, but needed to create the network.\n_torchmetric (str): The metric to use for the loss function. If None, then “mean_squared_error” is used.\n\nIt is implemented as follows:\n\nclass MyRegressor(L.LightningModule):\n        def __init__(\n        self,\n        l1: int,\n        epochs: int,\n        batch_size: int,\n        initialization: str,\n        act_fn: nn.Module,\n        optimizer: str,\n        dropout_prob: float,\n        lr_mult: float,\n        patience: int,\n        _L_in: int,\n        _L_out: int,\n        _torchmetric: str,\n        *args,\n        **kwargs,\n    ):\n        super().__init__()\n        self._L_in = _L_in\n        self._L_out = _L_out\n        if _torchmetric is None:\n            _torchmetric = \"mean_squared_error\"\n        self._torchmetric = _torchmetric\n        self.metric = getattr(torchmetrics.functional.regression, _torchmetric)\n        # _L_in and _L_out are not hyperparameters, but are needed to create the network\n        # _torchmetric is not a hyperparameter, but is needed to calculate the loss\n        self.save_hyperparameters(ignore=[\"_L_in\", \"_L_out\", \"_torchmetric\"])\n        # set dummy input array for Tensorboard Graphs\n        # set log_graph=True in Trainer to see the graph (in traintest.py)\n        self.example_input_array = torch.zeros((batch_size, self._L_in))\n        if self.hparams.l1 &lt; 4:\n            raise ValueError(\"l1 must be at least 4\")\n        hidden_sizes = [l1 * 2, l1, ceil(l1/2)]\n        # Create the network based on the specified hidden sizes\n        layers = []\n        layer_sizes = [self._L_in] + hidden_sizes\n        layer_size_last = layer_sizes[0]\n        for layer_size in layer_sizes[1:]:\n            layers += [\n                nn.Linear(layer_size_last, layer_size),\n                self.hparams.act_fn,\n                nn.Dropout(self.hparams.dropout_prob),\n            ]\n            layer_size_last = layer_size\n        layers += [nn.Linear(layer_sizes[-1], self._L_out)]\n        # nn.Sequential summarizes a list of modules into a single module,\n        # applying them in sequence\n        self.layers = nn.Sequential(*layers)\n\n\n\n43.2.4.2 The hidden_sizes\n__init__() uses the hidden_sizes list to define the sizes of the hidden layers in the network. The hidden sizes are calculated based on the l1 hyperparameter. The hidden sizes can be computed in different ways, depending on the problem and the desired network architecture. We recommend using a separate function to calculate the hidden sizes based on the hyperparameters.\n\n\n43.2.4.3 The forward Method\nThe forward() method defines the forward pass of the model. It takes an input tensor x and passes it through the network layers to produce an output tensor. It is implemented as follows:\n\ndef forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    return self.layers(x)\n\n\n\n43.2.4.4 The _calculate_loss Method\nThe _calculate_loss() method calculates the loss based on the predicted output and the target values. It uses the specified metric to calculate the loss. It takes the following arguments:\n\nbatch (tuple): A tuple containing a batch of input data and labels.\n\nIt is implemented as follows:\n\ndef _calculate_loss(self, batch):\n    x, y = batch\n    y = y.view(len(y), 1)\n    y_hat = self(x)\n    loss = self.metric(y_hat, y)\n    return loss\n\n\n\n43.2.4.5 The training_step Method\nThe training_step() method defines the training step of the model. It takes a batch of data and returns the loss. It is implemented as follows:\n\ndef training_step(self, batch: tuple) -&gt; torch.Tensor:\n    val_loss = self._calculate_loss(batch)\n    return val_loss\n\n\n\n43.2.4.6 The validation_step Method\nThe validation_step() method defines the validation step of the model. It takes a batch of data and returns the loss. It is implemented as follows:\n\ndef validation_step(self, batch: tuple) -&gt; torch.Tensor:\n    val_loss = self._calculate_loss(batch)\n    return val_loss\n\n\n\n43.2.4.7 The test_step Method\nThe test_step() method defines the test step of the model. It takes a batch of data and returns the loss. It is implemented as follows:\n\ndef test_step(self, batch: tuple) -&gt; torch.Tensor:\n    val_loss = self._calculate_loss(batch)\n    return val_loss\n\n\n\n43.2.4.8 The predict Method\nThe predict() method defines the prediction method of the model. It takes an input tensor x and returns a tuple with the input tensor x, the target tensor y, and the predicted tensor y_hat.\nIt is implemented as follows:\n\ndef predict(self, x: torch.Tensor) -&gt; torch.Tensor:\n    x, y = batch\n    yhat = self(x)\n    y = y.view(len(y), 1)\n    yhat = yhat.view(len(yhat), 1)\n    return (x, y, yhat)\n\n\n\n43.2.4.9 The configure_optimizers Method\nThe configure_optimizers() method defines the optimizer to use during training. It uses the optimizer_handler from spotpython.hyperparameter.optimizer to create the optimizer based on the specified optimizer name, parameters, and learning rate multiplier. It is implemented as follows:\n\ndef configure_optimizers(self) -&gt; torch.optim.Optimizer:\n    optimizer = optimizer_handler(\n        optimizer_name=self.hparams.optimizer, params=self.parameters(), lr_mult=self.hparams.lr_mult\n    )\n    return optimizer\n\nNote, the default Lightning way is to define an optimizer as optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate). spotpython uses an optimizer handler to create the optimizer, which adapts the learning rate according to the lr_mult hyperparameter as well as other hyperparameters. See spotpython.hyperparameters.optimizer.py [SOURCE] for details.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Hyperparameter Tuning with PyTorch Lightning and User Models</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_user_model.html#connection-with-the-lightdatamodule",
    "href": "601_spot_hpt_light_user_model.html#connection-with-the-lightdatamodule",
    "title": "43  Hyperparameter Tuning with PyTorch Lightning and User Models",
    "section": "43.3 Connection with the LightDataModule",
    "text": "43.3 Connection with the LightDataModule\nThe steps described in Section 43.2.4 are connected to the LightDataModule class [DOC]. This class is used to create the data loaders for the training, validation, and test sets. The LightDataModule class is part of the spotpython package and class provides the following methods [SOURCE]:\n\nprepare_data(): This method is used to prepare the data set.\nsetup(): This method is used to create the data loaders for the training, validation, and test sets.\ntrain_dataloader(): This method is used to return the data loader for the training set.\nval_dataloader(): This method is used to return the data loader for the validation set.\ntest_dataloader(): This method is used to return the data loader for the test set.\npredict_dataloader(): This method is used to return the data loader for the prediction set.\n\n\n43.3.1 The prepare_data() Method\nThe prepare_data() method is used to prepare the data set. This method is called only once and on a single process. It can be used to download the data set. In our case, the data set is already available, so this method uses a simple pass statement.\n\n\n43.3.2 The setup() Method\nThe stage is used to define the data set to be returned. It can be None, fit, test, or predict. If stage is None, the method returns the training (fit), testing (test), and prediction (predict) data sets.\nThe setup methods splits the data based on the stage setting for use in training, validation, and testing. It uses torch.utils.data.random_split() to split the data.\nSplitting is based on the test_size and test_seed. The test_size can be a float or an int.\nFirst, the data set sizes are determined as described in Section 43.3.2.1. Then, the data sets are split based on the stage setting. spotpython’s LightDataModule class uses the following sizes:\n\nfull_train_size: The size of the full training data set. This data set is splitted into the final training data set and a validation data set.\nval_size: The size of the validation data set. The validation data set is used to validate the model during training.\ntrain_size: The size of the training data set. The training data set is used to train the model.\ntest_size: The size of the test data set. The test data set is used to evaluate the model after training. It is not used during training (“hyperparameter tuning”). Only after everything is finished, the model is evaluated on the test data set.\n\n\n43.3.2.1 Determine the Sizes of the Data Sets\n\nimport torch\nfrom torch.utils.data import random_split\ndata_full = Diabetes()\ntest_size = fun_control[\"test_size\"]\ntest_seed=fun_control[\"test_seed\"]\n# if test_size is float, then train_size is 1 - test_size\nif isinstance(test_size, float):\n    full_train_size = round(1.0 - test_size, 2)\n    val_size = round(full_train_size * test_size, 2)\n    train_size = round(full_train_size - val_size, 2)\nelse:\n    # if test_size is int, then train_size is len(data_full) - test_size\n    full_train_size = len(data_full) - test_size\n    val_size = int(full_train_size * test_size / len(data_full))\n    train_size = full_train_size - val_size\n\nprint(f\"LightDataModule setup(): full_train_size: {full_train_size}\")\nprint(f\"LightDataModule setup(): val_size: {val_size}\")\nprint(f\"LightDataModule setup(): train_size: {train_size}\")\nprint(f\"LightDataModule setup(): test_size: {test_size}\")\n\nLightDataModule setup(): full_train_size: 0.6\nLightDataModule setup(): val_size: 0.24\nLightDataModule setup(): train_size: 0.36\nLightDataModule setup(): test_size: 0.4\n\n\n\n\n43.3.2.2 The “setup” Method: Stage “fit”\nHere, train_size and val_size are used to split the data into training and validation sets.\n\nstage = \"fit\"\nscaler = None\n# Assign train/val datasets for use in dataloaders\nif stage == \"fit\" or stage is None:\n    print(f\"train_size: {train_size}, val_size: {val_size} used for train & val data.\")\n    generator_fit = torch.Generator().manual_seed(test_seed)\n    data_train, data_val, _ = random_split(\n        data_full, [train_size, val_size, test_size], generator=generator_fit\n    )\n    if scaler is not None:\n        # Fit the scaler on training data and transform both train and val data\n        scaler_train_data = torch.stack([data_train[i][0] for i in range(len(data_train))]).squeeze(1)\n        # train_val_data = data_train[:,0]\n        print(scaler_train_data.shape)\n        scaler.fit(scaler_train_data)\n        data_train = [(scaler.transform(data), target) for data, target in data_train]\n        data_tensors_train = [data.clone().detach() for data, target in data_train]\n        target_tensors_train = [target.clone().detach() for data, target in data_train]\n        data_train = TensorDataset(\n            torch.stack(data_tensors_train).squeeze(1), torch.stack(target_tensors_train)\n        )\n        # print(data_train)\n        data_val = [(scaler.transform(data), target) for data, target in data_val]\n        data_tensors_val = [data.clone().detach() for data, target in data_val]\n        target_tensors_val = [target.clone().detach() for data, target in data_val]\n        data_val = TensorDataset(torch.stack(data_tensors_val).squeeze(1), torch.stack(target_tensors_val))\n\ntrain_size: 0.36, val_size: 0.24 used for train & val data.\n\n\nThe data_train and data_val data sets are further used to create the training and validation data loaders as described in Section 43.3.3 and Section 43.3.4, respectively.\n\n\n43.3.2.3 The “setup” Method: Stage “test”\nHere, the test data set, which is based on the test_size, is created.\n\nstage = \"test\"\n# Assign test dataset for use in dataloader(s)\nif stage == \"test\" or stage is None:\n    print(f\"test_size: {test_size} used for test dataset.\")\n    # get test data set as test_abs percent of the full dataset\n    generator_test = torch.Generator().manual_seed(test_seed)\n    data_test, _ = random_split(data_full, [test_size, full_train_size], generator=generator_test)\n    if scaler is not None:\n        data_test = [(scaler.transform(data), target) for data, target in data_test]\n        data_tensors_test = [data.clone().detach() for data, target in data_test]\n        target_tensors_test = [target.clone().detach() for data, target in data_test]\n        data_test = TensorDataset(\n            torch.stack(data_tensors_test).squeeze(1), torch.stack(target_tensors_test)\n        )\nprint(f\"LightDataModule setup(): Test set size: {len(data_test)}\")\n# Set batch size for DataLoader\nbatch_size = 5\n# Create DataLoader\nfrom torch.utils.data import DataLoader\ndataloader = DataLoader(data_test, batch_size=batch_size, shuffle=False)\n# Iterate over the data in the DataLoader\nfor batch in dataloader:\n    inputs, targets = batch\n    print(f\"Batch Size: {inputs.size(0)}\")\n    print(f\"Inputs Shape: {inputs.shape}\")\n    print(f\"Targets Shape: {targets.shape}\")\n    print(\"---------------\")\n    print(f\"Inputs: {inputs}\")\n    print(f\"Targets: {targets}\")\n    break\n\ntest_size: 0.4 used for test dataset.\nLightDataModule setup(): Test set size: 177\nBatch Size: 5\nInputs Shape: torch.Size([5, 10])\nTargets Shape: torch.Size([5])\n---------------\nInputs: tensor([[ 0.0490, -0.0446, -0.0418,  0.1045,  0.0356, -0.0257,  0.1775, -0.0764,\n         -0.0129,  0.0155],\n        [-0.0273,  0.0507, -0.0159, -0.0298,  0.0039, -0.0007,  0.0413, -0.0395,\n         -0.0236,  0.0113],\n        [ 0.0708,  0.0507, -0.0170,  0.0219,  0.0438,  0.0563,  0.0376, -0.0026,\n         -0.0702, -0.0176],\n        [-0.0382,  0.0507,  0.0714, -0.0573,  0.1539,  0.1559,  0.0008,  0.0719,\n          0.0503,  0.0693],\n        [ 0.0453, -0.0446,  0.0391,  0.0460,  0.0067, -0.0242,  0.0081, -0.0126,\n          0.0643,  0.0569]])\nTargets: tensor([103.,  53.,  80., 220., 246.])\n\n\n\n\n43.3.2.4 The “setup” Method: Stage “predict”\nPrediction and testing use the same data set. The prediction data set is created based on the test_size.\n\nstage = \"predict\"\nif stage == \"predict\" or stage is None:\n    print(f\"test_size: {test_size} used for predict dataset.\")\n    # get test data set as test_abs percent of the full dataset\n    generator_predict = torch.Generator().manual_seed(test_seed)\n    data_predict, _ = random_split(\n        data_full, [test_size, full_train_size], generator=generator_predict\n    )\n    if scaler is not None:\n        data_predict = [(scaler.transform(data), target) for data, target in data_predict]\n        data_tensors_predict = [data.clone().detach() for data, target in data_predict]\n        target_tensors_predict = [target.clone().detach() for data, target in data_predict]\n        data_predict = TensorDataset(\n            torch.stack(data_tensors_predict).squeeze(1), torch.stack(target_tensors_predict)\n        )\nprint(f\"LightDataModule setup(): Predict set size: {len(data_predict)}\")\n# Set batch size for DataLoader\nbatch_size = 5\n# Create DataLoader\nfrom torch.utils.data import DataLoader\ndataloader = DataLoader(data_predict, batch_size=batch_size, shuffle=False)\n# Iterate over the data in the DataLoader\nfor batch in dataloader:\n    inputs, targets = batch\n    print(f\"Batch Size: {inputs.size(0)}\")\n    print(f\"Inputs Shape: {inputs.shape}\")\n    print(f\"Targets Shape: {targets.shape}\")\n    print(\"---------------\")\n    print(f\"Inputs: {inputs}\")\n    print(f\"Targets: {targets}\")\n    break\n\ntest_size: 0.4 used for predict dataset.\nLightDataModule setup(): Predict set size: 177\nBatch Size: 5\nInputs Shape: torch.Size([5, 10])\nTargets Shape: torch.Size([5])\n---------------\nInputs: tensor([[ 0.0490, -0.0446, -0.0418,  0.1045,  0.0356, -0.0257,  0.1775, -0.0764,\n         -0.0129,  0.0155],\n        [-0.0273,  0.0507, -0.0159, -0.0298,  0.0039, -0.0007,  0.0413, -0.0395,\n         -0.0236,  0.0113],\n        [ 0.0708,  0.0507, -0.0170,  0.0219,  0.0438,  0.0563,  0.0376, -0.0026,\n         -0.0702, -0.0176],\n        [-0.0382,  0.0507,  0.0714, -0.0573,  0.1539,  0.1559,  0.0008,  0.0719,\n          0.0503,  0.0693],\n        [ 0.0453, -0.0446,  0.0391,  0.0460,  0.0067, -0.0242,  0.0081, -0.0126,\n          0.0643,  0.0569]])\nTargets: tensor([103.,  53.,  80., 220., 246.])\n\n\n\n\n\n43.3.3 The train_dataloader() Method\nThe method `train_dataloader returns the training dataloader, i.e., a Pytorch DataLoader instance using the training dataset. It simply returns a DataLoader with the data_train set that was created in the setup() method as described in Section 43.3.2.2.\n\ndef train_dataloader(self) -&gt; DataLoader:\n    return DataLoader(data_train, batch_size=batch_size, num_workers=num_workers)\n\n\n\n\n\n\n\nUsing the train_dataloader() Method\n\n\n\nThe train_dataloader() method can be used as follows:\n\nfrom spotpython.data.lightdatamodule import LightDataModule\nfrom spotpython.data.diabetes import Diabetes\ndataset = Diabetes(target_type=torch.float)\ndata_module = LightDataModule(dataset=dataset, batch_size=5, test_size=0.4)\ndata_module.setup()\nprint(f\"Training set size: {len(data_module.data_train)}\")\ndl = data_module.train_dataloader()\n# Iterate over the data in the DataLoader\nfor batch in dl:\n    inputs, targets = batch\n    print(f\"Batch Size: {inputs.size(0)}\")\n    print(f\"Inputs Shape: {inputs.shape}\")\n    print(f\"Targets Shape: {targets.shape}\")\n    print(\"---------------\")\n    print(f\"Inputs: {inputs}\")\n    print(f\"Targets: {targets}\")\n    break\n\nTraining set size: 160\nBatch Size: 5\nInputs Shape: torch.Size([5, 10])\nTargets Shape: torch.Size([5])\n---------------\nInputs: tensor([[-0.0055,  0.0507,  0.0013, -0.0849, -0.0112, -0.0167,  0.0486, -0.0395,\n         -0.0412, -0.0881],\n        [ 0.0090, -0.0446, -0.0245, -0.0263,  0.0989,  0.0942,  0.0707, -0.0026,\n         -0.0214,  0.0072],\n        [-0.0200, -0.0446,  0.0046,  0.0976,  0.0053, -0.0207,  0.0634, -0.0395,\n          0.0126,  0.0113],\n        [ 0.0490, -0.0446, -0.0429, -0.0539,  0.0452,  0.0500,  0.0339, -0.0026,\n         -0.0260, -0.0632],\n        [ 0.0381,  0.0507, -0.0094,  0.0024,  0.0012,  0.0375, -0.0544,  0.0502,\n         -0.0260,  0.1066]])\nTargets: tensor([51., 84., 48., 64., 81.])\n\n\n\n\n\n\n43.3.4 The val_dataloader() Method\nReturns the validation dataloader, i.e., a Pytorch DataLoader instance using the validation dataset. It simply returns a DataLoader with the data_val set that was created in the setup() method as desccribed in Section 43.3.2.2.\n\ndef val_dataloader(self) -&gt; DataLoader:\n    return DataLoader(data_val, batch_size=batch_size, num_workers=num_workers)\n\n\n\n\n\n\n\nUsing the val_dataloader() Method\n\n\n\nThe val_dataloader() method can be used as follows:\n\nfrom spotpython.data.lightdatamodule import LightDataModule\nfrom spotpython.data.diabetes import Diabetes\ndataset = Diabetes(target_type=torch.float)\ndata_module = LightDataModule(dataset=dataset, batch_size=5, test_size=0.4)\ndata_module.setup()\nprint(f\"Validation set size: {len(data_module.data_val)}\")\ndl = data_module.val_dataloader()\n# Iterate over the data in the DataLoader\nfor batch in dl:\n    inputs, targets = batch\n    print(f\"Batch Size: {inputs.size(0)}\")\n    print(f\"Inputs Shape: {inputs.shape}\")\n    print(f\"Targets Shape: {targets.shape}\")\n    print(\"---------------\")\n    print(f\"Inputs: {inputs}\")\n    print(f\"Targets: {targets}\")\n    break\n\nValidation set size: 106\nBatch Size: 5\nInputs Shape: torch.Size([5, 10])\nTargets Shape: torch.Size([5])\n---------------\nInputs: tensor([[ 0.0163, -0.0446,  0.0736, -0.0412, -0.0043, -0.0135, -0.0139, -0.0011,\n          0.0429,  0.0445],\n        [ 0.0453, -0.0446,  0.0714,  0.0012, -0.0098, -0.0010,  0.0155, -0.0395,\n         -0.0412, -0.0715],\n        [ 0.0308,  0.0507,  0.0326,  0.0494, -0.0401, -0.0436, -0.0692,  0.0343,\n          0.0630,  0.0031],\n        [ 0.0235,  0.0507, -0.0396, -0.0057, -0.0484, -0.0333,  0.0118, -0.0395,\n         -0.1016, -0.0674],\n        [-0.0091,  0.0507,  0.0013, -0.0022,  0.0796,  0.0701,  0.0339, -0.0026,\n          0.0267,  0.0818]])\nTargets: tensor([275., 141., 208.,  78., 142.])\n\n\n\n\n\n\n43.3.5 The test_dataloader() Method\nReturns the test dataloader, i.e., a Pytorch DataLoader instance using the test dataset. It simply returns a DataLoader with the data_test set that was created in the setup() method as described in Section 40.4.2.3.\n\ndef test_dataloader(self) -&gt; DataLoader:\n    return DataLoader(data_test, batch_size=batch_size, num_workers=num_workers)\n\n\n\n\n\n\n\nUsing the test_dataloader() Method\n\n\n\nThe test_dataloader() method can be used as follows:\n\nfrom spotpython.data.lightdatamodule import LightDataModule\nfrom spotpython.data.diabetes import Diabetes\ndataset = Diabetes(target_type=torch.float)\ndata_module = LightDataModule(dataset=dataset, batch_size=5, test_size=0.4)\ndata_module.setup()\nprint(f\"Test set size: {len(data_module.data_test)}\")\ndl = data_module.test_dataloader()\n# Iterate over the data in the DataLoader\nfor batch in dl:\n    inputs, targets = batch\n    print(f\"Batch Size: {inputs.size(0)}\")\n    print(f\"Inputs Shape: {inputs.shape}\")\n    print(f\"Targets Shape: {targets.shape}\")\n    print(\"---------------\")\n    print(f\"Inputs: {inputs}\")\n    print(f\"Targets: {targets}\")\n    break\n\nTest set size: 177\nBatch Size: 5\nInputs Shape: torch.Size([5, 10])\nTargets Shape: torch.Size([5])\n---------------\nInputs: tensor([[ 0.0562, -0.0446, -0.0579, -0.0080,  0.0521,  0.0491,  0.0560, -0.0214,\n         -0.0283,  0.0445],\n        [ 0.0018, -0.0446, -0.0709, -0.0229, -0.0016, -0.0010,  0.0266, -0.0395,\n         -0.0225,  0.0072],\n        [-0.0527, -0.0446,  0.0542, -0.0263, -0.0552, -0.0339, -0.0139, -0.0395,\n         -0.0741, -0.0591],\n        [ 0.0054, -0.0446, -0.0482, -0.0126,  0.0012, -0.0066,  0.0634, -0.0395,\n         -0.0514, -0.0591],\n        [-0.0527, -0.0446, -0.0094, -0.0057,  0.0397,  0.0447,  0.0266, -0.0026,\n         -0.0181, -0.0135]])\nTargets: tensor([158.,  49., 142.,  96.,  59.])\n\n\n\n\n\n\n43.3.6 The predict_dataloader() Method\nReturns the prediction dataloader, i.e., a Pytorch DataLoader instance using the prediction dataset. It simply returns a DataLoader with the data_predict set that was created in the setup() method as described in Section 40.4.2.4.\n\n\n\n\n\n\nWarning\n\n\n\nThe batch_size is set to the length of the data_predict set.\n\n\n\ndef predict_dataloader(self) -&gt; DataLoader:\n    return DataLoader(data_predict, batch_size=len(data_predict), num_workers=num_workers)\n\n\n\n\n\n\n\nUsing the predict_dataloader() Method\n\n\n\nThe predict_dataloader() method can be used as follows:\n\nfrom spotpython.data.lightdatamodule import LightDataModule\nfrom spotpython.data.diabetes import Diabetes\ndataset = Diabetes(target_type=torch.float)\ndata_module = LightDataModule(dataset=dataset, batch_size=5, test_size=0.4)\ndata_module.setup()\nprint(f\"Test set size: {len(data_module.data_predict)}\")\ndl = data_module.predict_dataloader()\n# Iterate over the data in the DataLoader\nfor batch in dl:\n    inputs, targets = batch\n    print(f\"Batch Size: {inputs.size(0)}\")\n    print(f\"Inputs Shape: {inputs.shape}\")\n    print(f\"Targets Shape: {targets.shape}\")\n    print(\"---------------\")\n    print(f\"Inputs: {inputs}\")\n    print(f\"Targets: {targets}\")\n    break\n\nTest set size: 177\nBatch Size: 177\nInputs Shape: torch.Size([177, 10])\nTargets Shape: torch.Size([177])\n---------------\nInputs: tensor([[ 0.0562, -0.0446, -0.0579,  ..., -0.0214, -0.0283,  0.0445],\n        [ 0.0018, -0.0446, -0.0709,  ..., -0.0395, -0.0225,  0.0072],\n        [-0.0527, -0.0446,  0.0542,  ..., -0.0395, -0.0741, -0.0591],\n        ...,\n        [ 0.0090, -0.0446, -0.0321,  ..., -0.0764, -0.0119, -0.0384],\n        [-0.0273, -0.0446, -0.0666,  ..., -0.0395, -0.0358, -0.0094],\n        [ 0.0817,  0.0507,  0.0067,  ...,  0.0919,  0.0547,  0.0072]])\nTargets: tensor([158.,  49., 142.,  96.,  59.,  74., 137., 136.,  39.,  66., 310., 198.,\n        235., 116.,  55., 177.,  59., 246.,  53., 135.,  88., 198., 186., 217.,\n         51., 118., 153., 180.,  51., 229.,  84.,  72., 237., 142., 185.,  91.,\n         88., 148., 179., 144.,  25.,  89.,  42.,  60., 124., 170., 215., 263.,\n        178., 245., 202.,  97., 321.,  71., 123., 220., 132., 243.,  61., 102.,\n        187.,  70., 242., 134.,  63.,  72.,  88., 219., 127., 146., 122., 143.,\n        220., 293.,  59., 317.,  60., 140.,  65., 277.,  90.,  96., 109., 190.,\n         90.,  52., 160., 233., 230., 175.,  68., 272., 144.,  70.,  68., 163.,\n         71.,  93., 263., 118., 220.,  90., 232., 120., 163.,  88.,  85.,  52.,\n        181., 232., 212., 332.,  81., 214., 145., 268., 115.,  93.,  64., 156.,\n        128., 200., 281., 103., 220.,  66.,  48., 246.,  42., 150., 125., 109.,\n        129.,  97., 265.,  97., 173., 216., 237., 121.,  42., 151.,  31.,  68.,\n        137., 221., 283., 124., 243., 150.,  69., 306., 182., 252., 132., 258.,\n        121., 110., 292., 101., 275., 141., 208.,  78., 142., 185., 167., 258.,\n        144.,  89., 225., 140., 303., 236.,  87.,  77., 131.])",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Hyperparameter Tuning with PyTorch Lightning and User Models</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_user_model.html#using-the-lightdatamodule-in-the-train_model-method",
    "href": "601_spot_hpt_light_user_model.html#using-the-lightdatamodule-in-the-train_model-method",
    "title": "43  Hyperparameter Tuning with PyTorch Lightning and User Models",
    "section": "43.4 Using the LightDataModule in the train_model() Method",
    "text": "43.4 Using the LightDataModule in the train_model() Method\nThe methods discussed so far are used in spotpython’s train_model() method [DOC] to train the model. It is implemented as follows [SOURCE].\nFirst, a LightDataModule object is created and the setup() method is called.\n\ndm = LightDataModule(\n    dataset=fun_control[\"data_set\"],\n    batch_size=config[\"batch_size\"],\n    num_workers=fun_control[\"num_workers\"],\n    test_size=fun_control[\"test_size\"],\n    test_seed=fun_control[\"test_seed\"],\n)\ndm.setup()\n\nThen, the Trainer is initialized.\n\n# Init trainer\ntrainer = L.Trainer(\n    default_root_dir=os.path.join(fun_control[\"CHECKPOINT_PATH\"], config_id),\n    max_epochs=model.hparams.epochs,\n    accelerator=fun_control[\"accelerator\"],\n    devices=fun_control[\"devices\"],\n    logger=TensorBoardLogger(\n        save_dir=fun_control[\"TENSORBOARD_PATH\"],\n        version=config_id,\n        default_hp_metric=True,\n        log_graph=fun_control[\"log_graph\"],\n    ),\n    callbacks=[\n        EarlyStopping(monitor=\"val_loss\", patience=config[\"patience\"], mode=\"min\", strict=False, verbose=False)\n    ],\n    enable_progress_bar=enable_progress_bar,\n)\n\nNext, the fit() method is called to train the model.\n\n# Pass the datamodule as arg to trainer.fit to override model hooks :)\ntrainer.fit(model=model, datamodule=dm)\n\nFinally, the validate() method is called to validate the model. The validate() method returns the validation loss.\n\n# Test best model on validation and test set\nresult = trainer.validate(model=model, datamodule=dm)\n# unlist the result (from a list of one dict)\nresult = result[0]\nreturn result[\"val_loss\"]",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Hyperparameter Tuning with PyTorch Lightning and User Models</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_user_model.html#the-last-connection-the-hyperlight-class",
    "href": "601_spot_hpt_light_user_model.html#the-last-connection-the-hyperlight-class",
    "title": "43  Hyperparameter Tuning with PyTorch Lightning and User Models",
    "section": "43.5 The Last Connection: The HyperLight Class",
    "text": "43.5 The Last Connection: The HyperLight Class\nThe method train_model() is part of the HyperLight class [DOC]. It is called from spotpython as an objective function to train the model and return the validation loss.\nThe HyperLight class is implemented as follows [SOURCE].\n\nclass HyperLight:\n    def fun(self, X: np.ndarray, fun_control: dict = None) -&gt; np.ndarray:\n        z_res = np.array([], dtype=float)\n        self.check_X_shape(X=X, fun_control=fun_control)\n        var_dict = assign_values(X, get_var_name(fun_control))\n        for config in generate_one_config_from_var_dict(var_dict, fun_control):\n            df_eval = train_model(config, fun_control)\n            z_val = fun_control[\"weights\"] * df_eval\n            z_res = np.append(z_res, z_val)\n        return z_res",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Hyperparameter Tuning with PyTorch Lightning and User Models</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_user_model.html#further-information",
    "href": "601_spot_hpt_light_user_model.html#further-information",
    "title": "43  Hyperparameter Tuning with PyTorch Lightning and User Models",
    "section": "43.6 Further Information",
    "text": "43.6 Further Information\n\n43.6.1 Preprocessing\nPreprocessing is handled by Lightning and PyTorch. It is described in the LIGHTNINGDATAMODULE documentation. Here you can find information about the transforms methods.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Hyperparameter Tuning with PyTorch Lightning and User Models</span>"
    ]
  },
  {
    "objectID": "601_resnet.html",
    "href": "601_resnet.html",
    "title": "44  Hyperparameter Tuning with PyTorch Lightning: ResNets",
    "section": "",
    "text": "44.1 Residual Neural Networks\nNeural ODEs are related to Residual Neural Networks (ResNets). We consider ResNets in Section 44.1.\nHe et al. (2015) introduced Residual Neural Networks (ResNets).",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Hyperparameter Tuning with PyTorch Lightning: ResNets</span>"
    ]
  },
  {
    "objectID": "601_resnet.html#sec-resnets",
    "href": "601_resnet.html#sec-resnets",
    "title": "44  Hyperparameter Tuning with PyTorch Lightning: ResNets",
    "section": "",
    "text": "44.1.1 Residual Connections\nResidual connections are a key component of ResNets. They are used to stabilize the training of very deep networks. The idea is to learn a residual mapping instead of the full mapping. The residual mapping is defined as:\n\nDefinition 44.1 (Residual Connection) Let \\(F\\) denote a non-linear mapping (usually a sequence of NN modules likes convolutions, activation functions, and normalizations).\nInstead of modeling \\[\nx_{l+1}=F(x_{l}),\n\\] residual connections model \\[\nx_{l+1}=x_{l}+F(x_{l}).\n\\tag{44.1}\\]\nThis is illustrated in Figure 44.1.\n\n\n\n\n\n\nFigure 44.1: Residual Connection. Figure credit He et al. (2015)\n\n\n\nApplying backpropagation to the residual mapping results in the following gradient calculation:\n\\[\n\\frac{\\partial x_{l+1}}{\\partial x_{l}} = \\mathbf{I} + \\frac{\\partial F(x_{l})}{\\partial x_{l}},\n\\tag{44.2}\\]\nwhere \\(\\mathbf{I}\\) is the identity matrix. The identity matrix is added to the gradient, which helps to stabilize the training of very deep networks. The identity matrix ensures that the gradient is not too small, which can happen if the gradient of \\(F\\) is close to zero. This is especially important for very deep networks, where the gradient can vanish quickly.\n\nThe bias towards the identity matrix guarantees a stable gradient propagation being less effected by \\(F\\) itself.\nThere have been many variants of ResNet proposed, which mostly concern the function \\(F\\), or operations applied on the sum. Figure 44.2 shows two different ResNet blocks:\n\nthe original ResNet block, which applies a non-linear activation function, usually ReLU, after the skip connection. and\nthe pre-activation ResNet block, which applies the non-linearity at the beginning of \\(F\\).\n\n\n\n\n\n\n\nFigure 44.2: ResNet Block. Left: original Residual block in He et al. (2015). Right: pre-activation block. BN describes batch-normalization. Figure credit He et al. (2016)\n\n\n\nFor very deep network the pre-activation ResNet has shown to perform better as the gradient flow is guaranteed to have the identity matrix as shown in Equation 44.2, and is not harmed by any non-linear activation applied to it.\n\n\n44.1.2 Implementation of the Original ResNet Block\nOne special case we have to handle is when we want to reduce the image dimensions in terms of width and height. The basic ResNet block requires \\(F(x_{l})\\) to be of the same shape as \\(x_{l}\\). Thus, we need to change the dimensionality of \\(x_{l}\\) as well before adding to \\(F(x_{l})\\). The original implementation used an identity mapping with stride 2 and padded additional feature dimensions with 0. However, the more common implementation is to use a 1x1 convolution with stride 2 as it allows us to change the feature dimensionality while being efficient in parameter and computation cost. The code for the ResNet block is relatively simple, and shown below:\n\nimport torch\nimport torch.nn as nn\n\nclass ResNetBlock(nn.Module):\n    def __init__(self, c_in, act_fn, subsample=False, c_out=-1):\n        \"\"\"\n        Inputs:\n            c_in - Number of input features\n            act_fn - Activation class constructor (e.g. nn.ReLU)\n            subsample - If True, we need to apply a transformation inside the block to change the feature dimensionality\n            c_out - Number of output features. Note that this is only relevant if subsample is True, as otherwise, c_out = c_in\n        \"\"\"\n        super().__init__()\n        if not subsample:\n            c_out = c_in\n\n        # Network representing F\n        self.net = nn.Sequential(\n            nn.Linear(c_in, c_out, bias=False),  # Linear layer for feature transformation\n            nn.BatchNorm1d(c_out),               # Batch normalization for stable learning\n            act_fn(),                            # Activation function\n            nn.Linear(c_out, c_out, bias=False), # Second linear layer\n            nn.BatchNorm1d(c_out)                # Batch normalization\n        )\n        \n        # If subsampling, adjust the input feature dimensionality using a linear layer\n        self.downsample = nn.Linear(c_in, c_out) if subsample else None\n        self.act_fn = act_fn()\n\n    def forward(self, x):\n        z = self.net(x)  # Apply the main network\n        if self.downsample is not None:\n            x = self.downsample(x)  # Adjust dimensionality if necessary\n        out = z + x  # Residual connection\n        out = self.act_fn(out)  # Apply activation function\n        return out\n\nclass ResNetRegression(nn.Module):\n    def __init__(self, input_dim, output_dim, block, num_blocks=1, hidden_dim=64, act_fn=nn.ReLU):\n        super().__init__()\n        self.input_layer = nn.Linear(input_dim, hidden_dim)  # Input layer transformation\n        self.blocks = nn.ModuleList([block(hidden_dim, act_fn) for _ in range(num_blocks)])  # List of ResNet blocks\n        self.output_layer = nn.Linear(hidden_dim, output_dim)  # Output layer for regression\n        \n    def forward(self, x):\n        x = self.input_layer(x)  # Apply input layer\n        for block in self.blocks:\n            x = block(x)  # Apply each block\n        x = self.output_layer(x)  # Get final output\n        return x\n\n\ninput_dim = 10\noutput_dim = 1\nhidden_dim = 64\nmodel = ResNetRegression(input_dim, output_dim, ResNetBlock, num_blocks=2, hidden_dim=hidden_dim, act_fn=nn.ReLU)\nmodel\n\nResNetRegression(\n  (input_layer): Linear(in_features=10, out_features=64, bias=True)\n  (blocks): ModuleList(\n    (0-1): 2 x ResNetBlock(\n      (net): Sequential(\n        (0): Linear(in_features=64, out_features=64, bias=False)\n        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU()\n        (3): Linear(in_features=64, out_features=64, bias=False)\n        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (act_fn): ReLU()\n    )\n  )\n  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n)\n\n\n\n# Create a sample input tensor with a batch size of 2\nfrom torchviz import make_dot\nsample_input = torch.randn(2, input_dim)\n\n# Generate the visualization\noutput = model(sample_input)\ndot = make_dot(output, params=dict(model.named_parameters()))\n\n# Save and render the visualization\ndot.format = 'png'\ndot.render('./figures_static/resnet_regression')\n\n'figures_static/resnet_regression.png'\n\n\n\n\n\nResNet Regression\n\n\n\n\n44.1.3 Implementation of the Pre-Activation ResNet Block\nThe second block we implement is the pre-activation ResNet block. For this, we have to change the order of layer in self.net, and do not apply an activation function on the output. Additionally, the downsampling operation has to apply a non-linearity as well as the input, \\(x_l\\), has not been processed by a non-linearity yet. Hence, the block looks as follows:\n\nimport torch\nimport torch.nn as nn\n\nclass PreActResNetBlock(nn.Module):\n    def __init__(self, c_in, act_fn, subsample=False, c_out=-1):\n        super().__init__()\n        if not subsample:\n            c_out = c_in\n        self.net = nn.Sequential(\n            nn.LayerNorm(c_in),  # Replacing BatchNorm1d with LayerNorm\n            act_fn(),\n            nn.Linear(c_in, c_out, bias=False),\n            nn.LayerNorm(c_out),\n            act_fn(),\n            nn.Linear(c_out, c_out, bias=False)\n        )\n        self.downsample = nn.Sequential(\n            nn.LayerNorm(c_in),\n            act_fn(),\n            nn.Linear(c_in, c_out, bias=False)\n        ) if subsample else None\n\n    def forward(self, x):\n        z = self.net(x)\n        if self.downsample is not None:\n            x = self.downsample(x)\n        out = z + x\n        return out\n\nclass PreActResNetRegression(nn.Module):\n    def __init__(self, input_dim, output_dim, block, num_blocks=1, hidden_dim=64, act_fn=nn.ReLU):\n        super().__init__()\n        self.input_layer = nn.Linear(input_dim, hidden_dim)\n        self.blocks = nn.ModuleList([block(hidden_dim, act_fn) for _ in range(num_blocks)])\n        self.output_layer = nn.Linear(hidden_dim, output_dim)\n        \n    def forward(self, x):\n        x = self.input_layer(x)\n        for block in self.blocks:\n            x = block(x)\n        x = self.output_layer(x)\n        return x\n\n\ninput_dim = 10\noutput_dim = 1\nhidden_dim = 64\nmodel = PreActResNetRegression(input_dim, output_dim, PreActResNetBlock, num_blocks=2, hidden_dim=hidden_dim, act_fn=nn.ReLU)\nmodel\n\nPreActResNetRegression(\n  (input_layer): Linear(in_features=10, out_features=64, bias=True)\n  (blocks): ModuleList(\n    (0-1): 2 x PreActResNetBlock(\n      (net): Sequential(\n        (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n        (1): ReLU()\n        (2): Linear(in_features=64, out_features=64, bias=False)\n        (3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n        (4): ReLU()\n        (5): Linear(in_features=64, out_features=64, bias=False)\n      )\n    )\n  )\n  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n)\n\n\n\nfrom torchviz import make_dot\n# Create a sample input tensor\nsample_input = torch.randn(1, input_dim)\n\n# Generate the visualization\noutput = model(sample_input)\ndot = make_dot(output, params=dict(model.named_parameters()))\n\n# Save and render the visualization\ndot.format = 'png'\ndot.render('./figures_static/preact_resnet_regression')\n\n'figures_static/preact_resnet_regression.png'\n\n\n\n\n\nPre-Activation ResNet Regression\n\n\n\n\n44.1.4 The Overall ResNet Architecture\nThe overall ResNet architecture for regression consists of stacking multiple ResNet blocks, of which some are downsampling the input. When discussing ResNet blocks within the entire network, they are usually grouped by output shape. If we describe the ResNet as having [3,3,3] blocks, it means there are three groups of ResNet blocks, each containing three blocks, with downsampling occurring in the first block of the second and third groups. The final layer produces continuous outputs suitable for regression tasks.\n\n\n\nResNet Notation. Figure credit Lippe (2022)\n\n\nThe output_dim parameter is used to determine the number of outputs for regression. This is set to 1 for a single regression target by default, but can be adjusted for multiple targets. Note, a final layer without a softmax or similar classification layer has to be added for regression tasks. A similar notation is used by many other implementations such as in the torchvision library from PyTorch.\n\nExample 44.1 (Example ResNet Model)  \n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.datasets import make_regression\nfrom types import SimpleNamespace\n\ndef get_resnet_blocks_by_name():\n    return {\"ResNetBlock\": ResNetBlock}\n\ndef get_act_fn_by_name():\n    return {\"relu\": nn.ReLU}\n\n# Define a simple ResNetBlock for fully connected layers\nclass ResNetBlock(nn.Module):\n    def __init__(self, c_in, act_fn, subsample=False, c_out=-1):\n        super().__init__()\n        if not subsample:\n            c_out = c_in\n\n        self.net = nn.Sequential(\n            nn.Linear(c_in, c_out, bias=False),\n            nn.BatchNorm1d(c_out),\n            act_fn(),\n            nn.Linear(c_out, c_out, bias=False),\n            nn.BatchNorm1d(c_out)\n        )\n        \n        self.downsample = nn.Linear(c_in, c_out) if subsample else None\n        self.act_fn = act_fn()\n\n    def forward(self, x):\n        z = self.net(x)\n        if self.downsample is not None:\n            x = self.downsample(x)\n        out = z + x\n        out = self.act_fn(out)\n        return out\n\n# Generate a simple random dataset for regression\nnum_samples = 100\nnum_features = 20  # Number of features, typical in a regression dataset\nX, y = make_regression(n_samples=num_samples, n_features=num_features, noise=0.1)\n\n# Convert to PyTorch tensors\nX_tensor = torch.tensor(X, dtype=torch.float32)\ny_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(1)  # Add a dimension for compatibility\n\n# Define the ResNet model for regression\nclass ResNet(nn.Module):\n    def __init__(self, input_dim, output_dim, num_blocks=[3, 3, 3], c_hidden=[64, 64, 64], act_fn_name=\"relu\", block_name=\"ResNetBlock\", **kwargs):\n        super().__init__()\n        resnet_blocks_by_name = get_resnet_blocks_by_name()\n        act_fn_by_name = get_act_fn_by_name()\n        assert block_name in resnet_blocks_by_name\n        self.hparams = SimpleNamespace(output_dim=output_dim, \n                                       c_hidden=c_hidden, \n                                       num_blocks=num_blocks, \n                                       act_fn_name=act_fn_name,\n                                       act_fn=act_fn_by_name[act_fn_name],\n                                       block_class=resnet_blocks_by_name[block_name])\n        self._create_network(input_dim)\n        self._init_params()\n\n    def _create_network(self, input_dim):\n        c_hidden = self.hparams.c_hidden\n        self.input_net = nn.Sequential(\n            nn.Linear(input_dim, c_hidden[0]),\n            self.hparams.act_fn()\n        )\n\n        blocks = []\n        for block_idx, block_count in enumerate(self.hparams.num_blocks):\n            for bc in range(block_count):\n                subsample = (bc == 0 and block_idx &gt; 0)\n                blocks.append(\n                    self.hparams.block_class(c_in=c_hidden[block_idx if not subsample else block_idx-1],\n                                             act_fn=self.hparams.act_fn,\n                                             subsample=subsample,\n                                             c_out=c_hidden[block_idx])\n                )\n        self.blocks = nn.Sequential(*blocks)\n\n        self.output_net = nn.Linear(c_hidden[-1], self.hparams.output_dim)\n\n    def _init_params(self):\n        for m in self.modules():\n            if isinstance(m, nn.Linear):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n            elif isinstance(m, nn.BatchNorm1d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n    def forward(self, x):\n        x = self.input_net(x)\n        x = self.blocks(x)\n        x = self.output_net(x)\n        return x\n\n# Instantiate the model\nmodel = ResNet(input_dim=num_features, output_dim=1)\n\n# Define a loss function and optimizer\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\n\n# Example training loop\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    model.train()\n    optimizer.zero_grad()\n    \n    # Forward pass\n    output = model(X_tensor)\n    \n    # Compute loss\n    loss = criterion(output, y_tensor)\n    \n    # Backward pass and optimization\n    loss.backward()\n    optimizer.step()\n    \n    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n\nEpoch 1/10, Loss: 36280.2109375\nEpoch 2/10, Loss: 31894.474609375\nEpoch 3/10, Loss: 29037.599609375\nEpoch 4/10, Loss: 27003.51171875\nEpoch 5/10, Loss: 25189.96484375\nEpoch 6/10, Loss: 23576.0\nEpoch 7/10, Loss: 22063.4765625\nEpoch 8/10, Loss: 20628.0625\nEpoch 9/10, Loss: 19268.8828125\nEpoch 10/10, Loss: 17987.34375\n\n\n\n\n\n\n\nHe, Kaiming, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2015. “Deep Residual Learning for Image Recognition.”\n\n\n———. 2016. “Identity Mappings in Deep Residual Networks.” arXiv e-Prints, March, arXiv:1603.05027.\n\n\nLippe, Phillip. 2022. “UvA Deep Learning Tutorials.” https://github.com/phlippe/uvadlc_notebooks/tree/master.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Hyperparameter Tuning with PyTorch Lightning: ResNets</span>"
    ]
  },
  {
    "objectID": "601_neural_ode.html",
    "href": "601_neural_ode.html",
    "title": "45  Neural ODEs",
    "section": "",
    "text": "45.1 Neural Ordinary Differential Equations\nNeural ODEs are related to Residual Neural Networks (ResNets). We consider ResNets in Section 44.1.\nNeural Ordinary Differential Equations (Neural ODEs) are a class of models that are based on ordinary differential equations (ODEs). They are a generalization of ResNets, where the depth of the network is treated as a continuous parameter. Neural ODEs have been introduced by Chen et al. (2018). We will consider dynamical systems first.\nDefinition 45.1 is a very general definition that includes all sort of dynamical systems. We deal with ODEs where \\(\\Phi\\) plays the role of the general solution: indeed a 1-parameter family of transformations of the state space. \\(\\mathcal{T}=\\mathbb{R}_{+}\\) is the time, and usually, \\(\\mathcal{S}=\\mathbb{R}^{n}\\) is the state space. The evolution takes a point in space (initial value), a point in time, and returns the a point in space. A general solution to an ODE is a function \\(y: I \\times \\mathbb{R}^{n} ⟶ \\mathbb{R}^{n}\\): a 1-parameter (usually time is the parameter) family of transformations of the state space. A 1-parameter family of transformations is often called a flow.\nFirst-order Ordinary Differential Equations (ODEs) can be defined as follows:\nThe solution of the ODE is the function \\(\\mathbf{y}(t)\\) that satisfies the ODE and the initial condition, which can be stated as an initial value problems (IVP), i.e. predict \\(\\mathbf{y}(t_1)\\) given \\(\\mathbf{y}(t_0)\\).\nThe existence and uniqueness of solutions to an IVP is ensured by the Picard-Lindelöf theorem, provided the RHS of the ODE is Lipschitz continuous. Lipschitz continuity is a property that pops up quite often in ODE-related results in ML.\nNote that Lipschitz continuity is a stronger condition than just continuity.\nNumerical solvers can be used to perform the forward pass and solve the IVP. If we use, for example, Euler’s method, we have the following update rule:\n\\[\n\\mathbf{y}(t+h) = \\mathbf{y}(t) + hf(\\mathbf{y}(t), t)\n\\tag{45.2}\\]\nwhere \\(h\\) is the step size. The update rule is applied iteratively to solve the IVP. The solution is a discrete approximation of the continuous function \\(\\mathbf{y}(t)\\).\nEquation 45.2 looks almost identical to a ResNet block (see Equation 44.1). This was one of the main motivations for Neural ODEs (Chen et al. 2018).\nResNets update hidden states by employing residual connections:\n\\[\n\\mathbf{y}_{l+1} = \\mathbf{y}_l + f(\\mathbf{y}_l, \\theta_l)\n\\]\nwhere \\(f\\) is a neural network with parameters \\(\\theta_l\\), and \\(\\mathbf{y}_l\\) and \\(\\mathbf{y}_{l+1}\\) are the hidden states at subsequent layers, \\(l \\in \\{0,\n\\ldots, L\\}\\).\nThese updates can be seen as Euler discretizations of continuous transformations.\n\\[\\begin{align}\n\\mathbf{\\dot{y}} &= f(\\mathbf{y}, t, \\theta)\n\\\\\n&\\Bigg\\downarrow \\ \\textrm{Euler Discretization}\n\\\\\n\\mathbf{y}_{n+1} &= \\mathbf{y}_n + h f(\\mathbf{y}_n, t_n, \\theta)\n\\end{align}\\]\nWhat happens in a residual network (with step sizes \\(h\\)) if we consider the continuous limit of each discrete layer in the network? What happens as we add more layers and take smaller steps? The answer seems rather astounding: instead of having a discrete number of layers between the input and output domains, we allow the evolution of the hidden states to become continuous.\nThe main technical difficulty in training continuous-depth networks is performing backpropagation through the ODE solver. Differentiating through the operations of the forward pass is straightforward, but incurs a high memory cost and introduces additional numerical error.\nPontryagin (1987) treated the ODE solver as a black box, and computed gradients using the adjoint sensitivity method. This approach computes gradients by solving a second, augmented ODE backwards in time, and is applicable to all ODE solvers. It scales linearly with problem size, has low memory cost, and explicitly controls numerical error.\nConsider optimizing a scalar-valued loss function \\(L()\\), whose input is the result of an ODE solver: \\[\nL(y(t_1) = L \\left(y(t_0) + \\int_{t_0}^{t_1} f(y(t), t, \\theta) dt \\right) = L \\left( \\textrm{ODESolve}( y(t_0), f, t_0, t_1, \\theta) \\right)\n\\tag{45.3}\\]\nEquation 45.3 is related to {Equation 45.1}. To optimize \\(L\\), we require gradients with respect to \\(\\theta\\).\nSimilar to standard neural networks, we start with determining how the gradient of the loss depends on the hidden state \\(y(t)\\) at each instant. This quantity is called the adjoint \\(a(t) = \\frac{\\partial{L}}{\\partial y(t)}\\). It satisfies the following IVP:\n\\[\n\\dot{\\mathbf{a}}(t) = -\\mathbf{a}(t)^{\\top} \\frac{\\partial f(\\mathbf{x}(t), t,\n\\theta)}{\\partial \\mathbf{x}}, \\quad \\mathbf{a}(t_1) = \\frac{\\partial L}{\\partial \\mathbf{x}(t_1)}.\n\\]\nIts dynamics are given by another ODE, which can be thought of as the instantaneous analog of the chain rule: \\[\n\\frac{d a(t)}{d t} = - a(t)^{T} \\frac{\\partial f(y(t), t, \\theta)}{\\partial y}.\n\\]\nThus, starting from the initial (remember we are running backwards) value \\(\\mathbf{a}(t_1) = \\frac{\\partial L}{\\partial \\mathbf{x}(t_1)}\\), we can compute \\(\\mathbf{a}(t_0) = \\frac{\\partial L}{\\partial \\mathbf{x}(t_0)}\\) by another call to an ODE solver.\nFinally, computing the gradients with respect to the parameters \\(\\theta\\) requires evaluating a third integral, which depends on both \\(\\mathbf{x}(t)\\) and \\(\\mathbf{a}(t)\\):\n\\[\n\\frac{\\mathrm{d}L}{\\mathrm{d}\\theta} = -\\int_{t_1}^{t_0} \\mathbf{a}(t)^{\\top}\\frac{\\partial f}{\\partial \\theta} \\mathrm{d}t,\n\\]\nSo this method trades off computation for memory—in fact the memory requirement for this gradient calculation is only \\(\\mathcal{O}(1)\\) with respect to the number of layers. The corresponding algorithm is described in Chen et al. (2018), see also Figure 45.3.\nHere you can find a very good explanation of the following result based on Lagrange multipliers.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Neural ODEs</span>"
    ]
  },
  {
    "objectID": "601_neural_ode.html#neural-ordinary-differential-equations",
    "href": "601_neural_ode.html#neural-ordinary-differential-equations",
    "title": "45  Neural ODEs",
    "section": "",
    "text": "Definition 45.1 A dynamical system is a triple \\[\n(\\mathcal{S}, \\mathcal{T}, \\Phi)\n\\] where\n\n\\(\\mathcal{S}\\) is the state space\n\\(\\mathcal{T}\\) is the parameter space, and\n\\(\\Phi: (\\mathcal{T} \\times \\mathcal{S}) \\longrightarrow \\mathcal{S}\\) is the evolution.\n\n\n\n\n\nDefinition 45.2 (First-Order Ordinary Differential Equation (ODE)) \\[\n\\mathbf{\\dot{y}}(t) = f(t, \\mathbf{y}(t)),\\quad \\mathbf{y}(t_0) = y_0,\\quad f: \\mathbb{R} \\times \\mathbb{R}^n \\to \\mathbb{R}^n\n\\]\n\n\n\nDefinition 45.3 (Initial Value Problem (IVP)) \\[\n\\mathbf{y}(t_1) = \\mathbf{y}(t_0) + \\int_{t_0}^{t_1} f(\\mathbf{y}(t), t)\n\\mathrm{d}t = \\textrm{ODESolve}(\\mathbf{y}(t_0), f, t_0, t_1)\n\\tag{45.1}\\]\n\n\n\nDefinition 45.4 (Lipschitz Continuity) A function \\(f: X \\subset \\mathbb{R}^{n} ⟶ \\mathbb{R}^{n}\\) is called Lipschitz continuous (with constant \\(\\lambda\\)) if\n\\[\n|| f(x_{1}) - f(x_{2}) || \\leq \\lambda ||x_{1} - x_{2}|| \\quad \\forall x_{1},x_{2} \\in X.\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 45.1: A residual network defines a discrete sequence of finite transformations. Circles represent evaluation locations. Figure credit Chen et al. (2018).\n\n\n\n\n\n\n\n\n\nFigure 45.2: An ODE network defines a vector field, which continuously transforms the state. Circles represent evaluation locations. Figure credit Chen et al. (2018).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 45.3: Reverse-mode differentiation of an ODE solution. The adjoint sensitivity method solves an augmented ODE backwards in time. The augmented system contains both the original state and the sensitivity of the loss with respect to the state. If the loss depends directly on the state at multiple observation times, the adjoint state must be updated in the direction of the partial derivative of the loss with respect to each observation. Figure credit Chen et al. (2018).",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Neural ODEs</span>"
    ]
  },
  {
    "objectID": "601_neural_ode.html#regression-example",
    "href": "601_neural_ode.html#regression-example",
    "title": "45  Neural ODEs",
    "section": "45.2 Regression Example",
    "text": "45.2 Regression Example\nTo illustrate this concept, we will consider a simple regression example. This example is based on the Neural-ODEs tutorial from Neural Ordinary Differential Equations, which is provided by Chen et al. (2018). We will use the ODE solvers from Torchdiffeq.\nNeural ODEs, or ODE-Nets, build complex models by chaining together simple building blocks, similar to residual networks. Here, our base layer will define the dynamics of an ODE, which will be interconnected using an ODE solver to form the complete neural network model.\n\n45.2.1 Specifying the Dynamics Layer\nThe dynamics of an ODE can be captured by the equation:\n\\[\n\\dot y(t) = f(y(t), t,  \\theta), \\qquad y(0) = y_0,\n\\] where the initial value \\(y_0 \\in \\mathbb{R}^n\\). The \\(\\theta\\) parameters were added to the dynamics, so the dynamics function has the dimensions \\(f : \\mathbb{R}^{n} \\times \\mathbb{R} \\times \\mathbb{R}^{|\\theta|} \\to \\mathbb{R}^n\\), where \\(|\\theta|\\) is the number of parameters we’ve added to \\(f\\).\nWe need the dynamics function to take in the current state \\(y(t)\\) of the ODE, the current time \\(t\\), and some parameters \\(\\theta\\), and output \\(\\frac{\\partial y(t)}{\\partial t}\\), which has the same shape as \\(y(t)\\). They are passed as input to a multi-layer perceptron (MLP). Multiple evaluations of this dynamics layer can be combined using any suitable ODE solver, such as the adaptive-step Dormand-Price solver implemented in the torchdiffeq library’s odeint function.\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torchdiffeq\n\nLet’s start by defining an MLP class to serve as the building block of our models.\n\nclass MLP(nn.Module):\n    def __init__(self, layer_sizes):\n        super(MLP, self).__init__()\n        layers = []\n        for i in range(len(layer_sizes) - 1):\n            layers.append(nn.Linear(layer_sizes[i], layer_sizes[i+1]))\n            if i &lt; len(layer_sizes) - 2:\n                layers.append(nn.Tanh())\n        self.network = nn.Sequential(*layers)\n\n    def forward(self, x):\n        return self.network(x)\n\nNext, we’ll define a ResNet class that uses the MLP as its inner component.\n\nclass ResNet(nn.Module):\n    def __init__(self, layer_sizes, depth):\n        super(ResNet, self).__init__()\n        self.mlp = MLP(layer_sizes)\n        self.depth = depth\n\n    def forward(self, x):\n        for _ in range(self.depth):\n            x = self.mlp(x) + x\n        return x\n\n\nODEFunc defines how the system evolves over time using the MLP to approximate derivatives \\(\\dot{y}(t)\\).\nODEBlock specifies the network structure. It uses torchdiffeq.odeint to integrate these dynamics over time.\n\n\nclass ODEFunc(nn.Module):\n    def __init__(self, layer_sizes):\n        super(ODEFunc, self).__init__()\n        self.mlp = MLP(layer_sizes)\n\n    def forward(self, t, y):\n        t_expanded = t.expand_as(y)\n        state_and_time = torch.cat([y, t_expanded], dim=1)\n        return self.mlp(state_and_time)\n\nclass ODEBlock(nn.Module):\n    def __init__(self, odefunc):\n        super(ODEBlock, self).__init__()\n        self.odefunc = odefunc\n\n    def forward(self, x):\n        t = torch.tensor([0.0, 1.0])\n        out = torchdiffeq.odeint(self.odefunc, x, t, atol=1e-3, rtol=1e-3)\n        return out[1]\n\nGenerate a toy 1D dataset.\n\ninputs = torch.linspace(-2.0, 2.0, 10).reshape(10, 1)\ntargets = inputs**3 +  0.1 * inputs\n\nWe specify the hyperparameters for the ResNet and ODE-Net.\n\nlayer_sizes = [1, 25, 1]\nparam_scale = 1.0\nstep_size = 0.01\ntrain_iters = 1000\nresnet_depth = 3\n\nInitialize and train the ResNet.\n\nresnet = ResNet(layer_sizes, resnet_depth)\ncriterion = nn.MSELoss()\noptimizer = optim.SGD(resnet.parameters(), lr=step_size)\n\nfor _ in range(train_iters):\n    optimizer.zero_grad()\n    outputs = resnet(inputs)\n    loss = criterion(outputs, targets)\n    loss.backward()\n    optimizer.step()\n\n\n# We need to change the input dimension to 2, to allow time-dependent dynamics.\nodenet_layer_sizes = [2, 25, 1]\n\n# Initialize and train ODE-Net.\nodefunc = ODEFunc(odenet_layer_sizes)\nodenet = ODEBlock(odefunc)\noptimizer = optim.SGD(odenet.parameters(), lr=step_size)\n\nfor _ in range(train_iters):\n    optimizer.zero_grad()\n    outputs = odenet(inputs)\n    loss = criterion(outputs, targets)\n    loss.backward()\n    optimizer.step()\n\nFinally, plot the predictions of both models.\n\nfine_inputs = np.linspace(-3.0, 3.0, 100).reshape(-1, 1)\nfine_inputs_tensor = torch.from_numpy(fine_inputs).float()\nplt.figure(figsize=(6, 4), dpi=150)\nplt.scatter(inputs, targets, color='green', label='Targets')\nplt.plot(fine_inputs, resnet(fine_inputs_tensor).detach().numpy(), color='blue', label='ResNet predictions')\n\nplt.plot(fine_inputs, odenet(fine_inputs_tensor).detach().numpy(), color='red', label='ODE Net predictions')\nplt.xlabel('Input')\nplt.ylabel('Output')\nplt.legend()\nplt.show()",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Neural ODEs</span>"
    ]
  },
  {
    "objectID": "601_neural_ode.html#further-reading",
    "href": "601_neural_ode.html#further-reading",
    "title": "45  Neural ODEs",
    "section": "45.3 Further Reading",
    "text": "45.3 Further Reading\nNeural ODEs have received a lot of attention in the past few years, ever since their introduction in Neurips 2018. Some of many many work in this field include:\n\nNeural Stochastic Differential Equations (Neural SDEs),\nNeural Controlled Differential Equations (Neural CDEs),\nGraph ODEs,\nHamiltonial Neural Networks, and\nLagrangian Neural Networks.\n\nMichael Poli maintains the excellent Awesome Neural ODE, a collection of resources regarding the interplay between neural differential equations, dynamical systems, deep learning, control, numerical methods and scientific machine learning.\nTorchdyn is an excellent library for Neural Differential Equations.\nImplicit Layers is a list of tutorials on implicit functions and automatic differentiation, Neural ODEs, and Deep Equilibrium Models.\nUnderstanding Neural ODE’s is an excellent blogpost on ODEs and Neural ODEs.\nPatrick Kidger’s doctoral dissertation is an excellent textbook on Neural Differential Equations, see Kidger (2022).\n\n\n\n\nChen, Ricky T. Q., Yulia Rubanova, Jesse Bettencourt, and David Duvenaud. 2018. “Neural Ordinary Differential Equations.” arXiv e-Prints, June, arXiv:1806.07366.\n\n\nKidger, Patrick. 2022. “On Neural Differential Equations.” arXiv e-Prints, February, arXiv:2202.02435.\n\n\nPontryagin. 1987. Mathematical Theory of Optimal Processes. Routledge.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Neural ODEs</span>"
    ]
  },
  {
    "objectID": "601_neural_ode_example.html",
    "href": "601_neural_ode_example.html",
    "title": "46  Neural ODE Example",
    "section": "",
    "text": "46.1 Implementation of a Neural ODE\nThe following example is based on the “UvA Deep Learning Tutorials” (Lippe 2022).",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Neural ODE Example</span>"
    ]
  },
  {
    "objectID": "601_neural_ode_example.html#implementation-of-a-neural-ode",
    "href": "601_neural_ode_example.html#implementation-of-a-neural-ode",
    "title": "46  Neural ODE Example",
    "section": "",
    "text": "Example 46.1 (Example: Neural ODE)  \n\n%matplotlib inline\nimport time\nimport logging\nimport statistics\nfrom typing import Optional, List\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib.animation import FuncAnimation\nfrom IPython.display import HTML\n\nimport torch\nimport torch.nn as nn\nimport torch.utils.data as data\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset\n\ntry:\n    import torchdiffeq\nexcept ModuleNotFoundError:\n    !pip install --quiet torchdiffeq\n    import torchdiffeq\n\ntry:\n    import rich\nexcept ModuleNotFoundError:\n    !pip install --quiet rich\n    import rich\n\ntry:\n    # import pytorch_lightning as pl\n    import lightning as pl\nexcept ModuleNotFoundError:\n    !pip install --quiet pytorch-lightning&gt;=1.4\n    # import pytorch_lightning as pl\n    import lightning as pl\nfrom torchmetrics.classification import Accuracy\n\npl.seed_everything(42)\n\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Device: {device}\")\n\nfrom torchmetrics.functional import accuracy\n\nDevice: cpu\n\n\nFirst, we define the core of our Neural ODE model.\n\nclass _ODEFunc(nn.Module):\n    def __init__(self, module, autonomous=True):\n        super().__init__()\n        self.module = module\n        self.autonomous = autonomous\n\n    def forward(self, t, x):\n        if not self.autonomous:\n            x = torch.cat([torch.ones_like(x[:, [0]]) * t, x], 1)\n        return self.module(x)\n\n\nclass ODEBlock(nn.Module):\n    def __init__(self, odefunc: nn.Module, solver: str = 'dopri5',\n                 rtol: float = 1e-4, atol: float = 1e-4, adjoint: bool = True,\n                 autonomous: bool = True):\n        super().__init__()\n        self.odefunc = _ODEFunc(odefunc, autonomous=autonomous)\n        self.rtol = rtol\n        self.atol = atol\n        self.solver = solver\n        self.use_adjoint = adjoint\n        self.integration_time = torch.tensor([0, 1], dtype=torch.float32)  \n    \n    @property\n    def ode_method(self):\n        return torchdiffeq.odeint_adjoint if self.use_adjoint else torchdiffeq.odeint\n\n    def forward(self, x: torch.Tensor, adjoint: bool = True, integration_time=None):\n        integration_time = self.integration_time if integration_time is None else integration_time\n        integration_time = integration_time.to(x.device)\n        ode_method =  torchdiffeq.odeint_adjoint if adjoint else torchdiffeq.odeint\n        out = ode_method(\n            self.odefunc, x, integration_time, rtol=self.rtol,\n            atol=self.atol, method=self.solver)\n        return out\n\nNext, we will wrap everything together in a LightningModule.\n\nclass Learner(pl.LightningModule):\n    def __init__(self, model:nn.Module, t_span:torch.Tensor, learning_rate:float=5e-3):\n        super().__init__()\n        self.model = model\n        self.t_span = t_span\n        self.learning_rate = learning_rate\n        # self.accuracy = Accuracy(num_classes=2)\n        self.accuracy = accuracy\n    \n    def forward(self, x):\n        return self.model(x)\n\n    def inference(self, x, time_span):\n        return self.model(x, adjoint=False, integration_time=time_span)\n\n    def inference_no_projection(self, x, time_span):\n        return self.model.forward_no_projection(x, adjoint=False, integration_time=time_span)\n   \n    def training_step(self, batch, batch_idx):\n        x, y = batch      \n        y_pred = self(x)\n        y_pred = y_pred[-1]  # select last point of solution trajectory\n        loss = nn.CrossEntropyLoss()(y_pred, y)\n        self.log('train_loss', loss, prog_bar=True, logger=True)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch      \n        y_pred = self(x)\n        y_pred = y_pred[-1]  # select last point of solution trajectory\n        loss = nn.CrossEntropyLoss()(y_pred, y)\n        self.log('val_loss', loss, prog_bar=True, logger=True)\n        acc = self.accuracy(y_pred.softmax(dim=-1), y, num_classes=2, task=\"MULTICLASS\")\n        self.log('val_accuracy', acc, prog_bar=True, logger=True)\n        return loss\n\n    def test_step(self, batch, batch_idx):\n        x, y = batch      \n        y_pred = self(x)\n        y_pred = y_pred[-1]  # select last point of solution trajectory\n        loss = nn.CrossEntropyLoss()(y_pred, y)\n        self.log('test_loss', loss, prog_bar=True, logger=True)\n        acc = self.accuracy(y_pred.softmax(dim=-1), y, num_classes=2, task=\"MULTICLASS\")\n        self.log('test_accuracy', acc, prog_bar=True, logger=True)\n        return loss\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n        return optimizer\n\nWe will be working will Half Moons Dataset, a non-linearly separable, binary classification dataset. The code is based on the excellent TorchDyn tutorials (https://github.com/DiffEqML/torchdyn), as well as the original TorchDiffEq examples (https://github.com/rtqichen/torchdiffeq).\n\nclass MoonsDataset(Dataset):\n    \"\"\"Half Moons Classification Dataset\n    \n    Adapted from https://github.com/DiffEqML/torchdyn\n    \"\"\"\n    def __init__(self, num_samples=100, noise_std=1e-4):\n        self.num_samples = num_samples\n        self.noise_std = noise_std\n        self.X, self.y = self.generate_moons(num_samples, noise_std)\n\n    @staticmethod\n    def generate_moons(num_samples=100, noise_std=1e-4):\n        \"\"\"Creates a *moons* dataset of `num_samples` data points.\n        :param num_samples: number of data points in the generated dataset\n        :type num_samples: int\n        :param noise_std: standard deviation of noise magnitude added to each data point\n        :type noise_std: float\n        \"\"\"\n        num_samples_out = num_samples // 2\n        num_samples_in = num_samples - num_samples_out\n        theta_out = np.linspace(0, np.pi, num_samples_out)\n        theta_in = np.linspace(0, np.pi, num_samples_in)\n        outer_circ_x = np.cos(theta_out)\n        outer_circ_y = np.sin(theta_out)\n        inner_circ_x = 1 - np.cos(theta_in)\n        inner_circ_y = 1 - np.sin(theta_in) - 0.5\n\n        X = np.vstack([np.append(outer_circ_x, inner_circ_x),\n                       np.append(outer_circ_y, inner_circ_y)]).T\n        y = np.hstack([np.zeros(num_samples_out), np.ones(num_samples_in)])\n\n        if noise_std is not None:\n            X += noise_std * np.random.rand(num_samples, 2)\n\n        X = torch.Tensor(X)\n        y = torch.LongTensor(y)\n        return X, y\n\n    def __len__(self):\n        return self.num_samples\n\n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]\n\n\ndef plot_binary_classification_dataset(X, y, title=None):\n    CLASS_COLORS = ['coral', 'darkviolet']\n    fig, ax = plt.subplots(figsize=(10, 10))\n    ax.scatter(X[:, 0], X[:, 1], color=[CLASS_COLORS[yi.int()] for yi in y], alpha=0.6)\n    ax.set_aspect('equal')\n    if title is not None:\n        ax.set_title(title)\n\n    return fig, ax\n\nLet’s create a sample dataset and visualize it.\n\nsample_dataset = MoonsDataset(num_samples=400, noise_std=1e-1)\nfig, ax = plot_binary_classification_dataset(sample_dataset.X, sample_dataset.y, title='Half Moons Dataset')\n\n\n\n\n\n\n\n\nLet’s now create the train, validation, and test sets, with their corresponding data loaders. We will create a single big dataset and randomly split it in train, val, and test sets.\n\ndef split_dataset(dataset_size:int, split_percentages:List[float]) -&gt; List[int]:\n    split_sizes = [int(pi * dataset_size) for pi in split_percentages]\n    split_sizes[0] += dataset_size - sum(split_sizes)\n    return split_sizes\n\n\nclass ToyDataModule(pl.LightningDataModule):\n    def __init__(self, dataset_size:int, split_percentages:Optional[float]=None):\n        super().__init__()\n        self.dataset_size = dataset_size\n        if split_percentages is None:\n            split_percentages = [0.8, 0.1, 0.1]\n        self.split_sizes = split_dataset(self.dataset_size, split_percentages)\n\n    def prepare_data(self):\n        pass\n\n    def setup(self, stage: Optional[str] = None):\n        pass\n\n    def train_dataloader(self):\n        train_loader = torch.utils.data.DataLoader(self.train_set, batch_size=len(self.train_set), shuffle=True)\n        return train_loader\n\n    def val_dataloader(self):\n        val_loader = torch.utils.data.DataLoader(self.val_set, batch_size=len(self.val_set), shuffle=False)\n        return val_loader\n\n    def test_dataloader(self):\n        test_loader = torch.utils.data.DataLoader(self.test_set, batch_size=len(self.test_set), shuffle=False)\n        return test_loader\n\n\nclass HalfMoonsDataModule(ToyDataModule):\n    def __init__(self, dataset_size:int, split_percentages:Optional[float]=None):\n        super().__init__(dataset_size, split_percentages=split_percentages)\n\n    def setup(self, stage: Optional[str] = None):\n        dataset = MoonsDataset(num_samples=self.dataset_size, noise_std=1e-1)\n        self.train_set, self.val_set, self.test_set = torch.utils.data.random_split(dataset, self.split_sizes)\n\nWe define a Neural ODE and train it. We will use a simple 2-layer MLP with a tanh activation and 64 hidden dimensions. We will train the model using the adjoint method for backpropagation.\nA quick note on the architectural choices for our model. The Picard-Lindelöf theorem (Coddington and Levinson, 1955) states that the solution to an initial value problem exists and is unique if the differential equation is uniformly Lipschitz continuous in \\(\\mathbf{z}\\) and continuous in \\(t\\). It turns out that this theorem holds for our model if the neural network has finite weights and uses Lipschitz nonlinearities, such as tanh or relu. However, not all tools are our deep learning arsenal is c. For example, as shown in The Lipschitz Constant of Self-Attention by Hyunjik Kim et al., standard self-attention is not Lipschitz. The authors propose alternative forms of self-attention that are Lipschitz.\n\nimport torch\nfrom lightning.pytorch import Trainer\nfrom lightning.pytorch.callbacks import ModelCheckpoint, RichProgressBar\n\n\nadjoint = True\ndata_module = HalfMoonsDataModule(1000)\nt_span = torch.linspace(0, 1, 2)\nf = nn.Sequential(\n    nn.Linear(2, 64),\n    nn.Tanh(),\n    nn.Linear(64, 2))\nmodel = ODEBlock(f, adjoint=adjoint)\nlearner = Learner(model, t_span)\n\ntrainer = Trainer(\n    max_epochs=200,\n    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n    devices=1,\n    callbacks=[\n        ModelCheckpoint(mode=\"max\", monitor=\"val_accuracy\"),\n        RichProgressBar(),\n    ],\n    log_every_n_steps=1,\n)\ntrainer.fit(learner, datamodule=data_module)\nval_result = trainer.validate(learner, datamodule=data_module, verbose=True)\ntest_result = trainer.test(learner, datamodule=data_module, verbose=True)\n\n┏━━━┳━━━━━━━┳━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n┃   ┃ Name  ┃ Type     ┃ Params ┃ Mode  ┃\n┡━━━╇━━━━━━━╇━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n│ 0 │ model │ ODEBlock │    322 │ train │\n└───┴───────┴──────────┴────────┴───────┘\n\n\n\nTrainable params: 322                                                                                              \nNon-trainable params: 0                                                                                            \nTotal params: 322                                                                                                  \nTotal estimated model params size (MB): 0                                                                          \nModules in train mode: 6                                                                                           \nModules in eval mode: 0                                                                                            \n\n\n\n\n\n\n/Users/bartz/miniforge3/envs/spot312/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connect\nor.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value\nof the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n\n\n\n/Users/bartz/miniforge3/envs/spot312/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connect\nor.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the \nvalue of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n\n\n\n\n\n\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃      Validate metric      ┃       DataLoader 0        ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│       val_accuracy        │            1.0            │\n│         val_loss          │   0.002127678133547306    │\n└───────────────────────────┴───────────────────────────┘\n\n\n\n\n\n\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃        Test metric        ┃       DataLoader 0        ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│       test_accuracy       │            1.0            │\n│         test_loss         │   0.0018281706143170595   │\n└───────────────────────────┴───────────────────────────┘\n\n\n\n\n\n\nIt seems that in less that 200 epochs we have achieved perfect validation accuracy. Let’s now use the trained model to run inference and visualize the trajectories using a dense time span of 100 timesteps.\n\n@torch.no_grad()\ndef run_inference(learner, data_loader, time_span):\n    learner.to(device)\n    trajectories = []\n    classes = []\n    time_span = torch.from_numpy(time_span).to(device)\n    for data, target in data_loader:\n        data = data.to(device)\n        traj = learner.inference(data, time_span).cpu().numpy()\n        trajectories.append(traj)\n        classes.extend(target.numpy())\n    trajectories = np.concatenate(trajectories, 1)\n    return trajectories, classes\n\ntime_span = np.linspace(0.0, 1.0, 100)\ntrajectories, classes = run_inference(learner, data_module.train_dataloader(), time_span)\n\ncolors = ['coral', 'darkviolet']\nclass_colors = [colors[ci] for ci in classes]\n\nWe will now define a few functions to visualize the learned trajectories, the state-space, and the learned vector field.\nBefore we visualize the trajectories, let’s plot the (training) data once again:\n\nfig, ax = plot_binary_classification_dataset(*data_module.train_set[:], title='Half Moons Dataset')\n\n\n\n\n\n\n\n\nBelow we visualize the evolution for each of the 2 inputs dimensions as a function of time (depth):\n\nplot_trajectories(time_span, trajectories, class_colors)\n\n\n\n\n\n\n\n\nAnd the same evolution combined in a single plot:\n\nplot_trajectories_3d(time_span, trajectories, class_colors)\n\n\n\n\n\n\n\n\nThe 3D plot can be somewhat complicated to decipher. Thus, we also plot an animated version of the evolution. Each timestep of the animation is a slice on the temporal axis of the figure above.\n\nanim = plot_trajectories_animation(time_span, trajectories, colors, classes, lim=8.0)\nHTML(anim.to_html5_video())\n\n\n  \n  Your browser does not support the video tag.\n\n\n\nFinally, we can visualize the state-space diagram and the learned vector field:\n\nfig, ax = plt.subplots(2, 1, figsize=(16, 8))\nplot_state_space(trajectories, class_colors, ax=ax[0])\nplot_static_vector_field(model, trajectories, ax=ax[1], device=device)\n\n\n\n\n\n\n\n\n\n\n\n\n\nLippe, Phillip. 2022. “UvA Deep Learning Tutorials.” https://github.com/phlippe/uvadlc_notebooks/tree/master.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Neural ODE Example</span>"
    ]
  },
  {
    "objectID": "601_pinn.html",
    "href": "601_pinn.html",
    "title": "47  Physics Informed Neural Networks",
    "section": "",
    "text": "47.1 PINNs\nimport torch\nimport numpy as np\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data as thdat\nimport functools\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_theme()\ntorch.manual_seed(42)\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# boundaries for the frequency range\na = 0\nb = 500",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Physics Informed Neural Networks</span>"
    ]
  },
  {
    "objectID": "601_pinn.html#generation-and-visualization-of-the-training-data-and-the-ground-truth-function",
    "href": "601_pinn.html#generation-and-visualization-of-the-training-data-and-the-ground-truth-function",
    "title": "47  Physics Informed Neural Networks",
    "section": "47.2 Generation and Visualization of the Training Data and the Ground Truth (Function)",
    "text": "47.2 Generation and Visualization of the Training Data and the Ground Truth (Function)\n\nDefinition of the (unknown) differential equation:\n\n\ndef ode(frequency, loc, sigma, R):\n    \"\"\"Computes the amplitude. Defining equation, used\n    to generate data and train models.\n    The equation itself is not known to the model.\n\n    Args:\n        frequency: (N,) array-like\n        loc: float\n        sigma: float\n        R: float\n    \n    Returns:\n        (N,) array-like\n    \n    Examples:\n        &gt;&gt;&gt; ode(0, 25, 100, 0.005)\n        100.0\n    \"\"\"\n    A = np.exp(-R * (frequency - loc)**2/sigma**2)\n    return A\n\n\nSetting the parameters for the ode\n\n\nnp.random.seed(10)\nloc = 250\nsigma = 100\nR = 0.5\n\n\nGenerating the data\n\n\nfrequencies = np.linspace(a, b, 1000)\neq = functools.partial(ode, loc=loc, sigma=sigma, R=R)\namplitudes = eq(frequencies)\n\n\nNow we have the ground truth for the full frequency range and can take a look at the first 10 values:\n\n\nimport pandas as pd\ndf = pd.DataFrame({'Frequency': frequencies[:10], 'Amplitude': amplitudes[:10]})\nprint(df)\n\n   Frequency  Amplitude\n0   0.000000   0.043937\n1   0.500501   0.044490\n2   1.001001   0.045048\n3   1.501502   0.045612\n4   2.002002   0.046183\n5   2.502503   0.046759\n6   3.003003   0.047341\n7   3.503504   0.047929\n8   4.004004   0.048524\n9   4.504505   0.049124\n\n\n\nWe generate the training data as a subset of the full frequency range and add some noise:\n\n\nt = np.linspace(a, 2*b/3, 10)\nA = eq(t) +  0.2 * np.random.randn(10)\n\n\nPlot of the training data and the ground truth:\n\n\nplt.plot(frequencies, amplitudes)\nplt.plot(t, A, 'o')\nplt.legend(['Equation (ground truth)', 'Training data'])\nplt.ylabel('Amplitude')\nplt.xlabel('Frequency')\n\n\n\n\n\n\nText(0.5, 0, 'Frequency')\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\nFigure 47.1",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Physics Informed Neural Networks</span>"
    ]
  },
  {
    "objectID": "601_pinn.html#gradient-with-autograd",
    "href": "601_pinn.html#gradient-with-autograd",
    "title": "47  Physics Informed Neural Networks",
    "section": "47.3 Gradient With Autograd",
    "text": "47.3 Gradient With Autograd\n\ndef grad(outputs, inputs):\n    \"\"\"Computes the partial derivative of \n    an output with respect to an input.\n\n    Args:\n        outputs: (N, 1) tensor\n        inputs: (N, D) tensor\n\n    Returns:\n        (N, D) tensor\n    \n    Examples:\n        &gt;&gt;&gt; x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n        &gt;&gt;&gt; y = x**2\n        &gt;&gt;&gt; grad(y, x)\n        tensor([2., 4., 6.])\n    \"\"\"\n    return torch.autograd.grad(\n        outputs, inputs, grad_outputs=torch.ones_like(outputs), create_graph=True\n    )\n\n\nAutograd example:\n\n\nx = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\ny = x**2\ngrad(y, x)\n\n(tensor([2., 4., 6.], grad_fn=&lt;MulBackward0&gt;),)",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Physics Informed Neural Networks</span>"
    ]
  },
  {
    "objectID": "601_pinn.html#network",
    "href": "601_pinn.html#network",
    "title": "47  Physics Informed Neural Networks",
    "section": "47.4 Network",
    "text": "47.4 Network\n\ndef numpy2torch(x):\n    \"\"\"Converts a numpy array to a pytorch tensor.\n\n    Args:\n        x: (N, D) array-like\n\n    Returns:\n        (N, D) tensor\n\n    Examples:\n        &gt;&gt;&gt; numpy2torch(np.array([1,2,3]))\n        tensor([1., 2., 3.])\n    \"\"\"\n    n_samples = len(x)\n    return torch.from_numpy(x).to(torch.float).to(DEVICE).reshape(n_samples, -1)\n\n\nclass Net(nn.Module):\n    def __init__(\n        self,\n        input_dim,\n        output_dim,\n        n_units=100,\n        epochs=1000,\n        loss=nn.MSELoss(),\n        lr=1e-3,\n        loss2=None,\n        loss2_weight=0.1,\n    ) -&gt; None:\n        super().__init__()\n\n        self.epochs = epochs\n        self.loss = loss\n        self.loss2 = loss2\n        self.loss2_weight = loss2_weight\n        self.lr = lr\n        self.n_units = n_units\n\n        self.layers = nn.Sequential(\n            nn.Linear(input_dim, self.n_units),\n            nn.ReLU(),\n            nn.Linear(self.n_units, self.n_units),\n            nn.ReLU(),\n            nn.Linear(self.n_units, self.n_units),\n            nn.ReLU(),\n            nn.Linear(self.n_units, self.n_units),\n            nn.ReLU(),\n        )\n        self.out = nn.Linear(self.n_units, output_dim)\n\n    def forward(self, x):\n        h = self.layers(x)\n        out = self.out(h)\n        return out\n\n    def fit(self, X, y):\n        Xt = numpy2torch(X)\n        yt = numpy2torch(y)\n\n        optimiser = optim.Adam(self.parameters(), lr=self.lr)\n        self.train()\n        losses = []\n        for ep in range(self.epochs):\n            optimiser.zero_grad()\n            outputs = self.forward(Xt)\n            loss = self.loss(yt, outputs)\n            if self.loss2:\n                loss += self.loss2_weight + self.loss2_weight * self.loss2(self)\n            loss.backward()\n            optimiser.step()\n            losses.append(loss.item())\n            if ep % int(self.epochs / 10) == 0:\n                print(f\"Epoch {ep}/{self.epochs}, loss: {losses[-1]:.2f}\")\n        return losses\n\n    def predict(self, X):\n        self.eval()\n        out = self.forward(numpy2torch(X))\n        return out.detach().cpu().numpy()\n\n\nExtended network for parameter estimation of parameter r:\n\n\nclass PINNParam(Net):\n    def __init__(\n        self,\n        input_dim,\n        output_dim,\n        n_units=100,\n        epochs=1000,\n        loss=nn.MSELoss(),\n        lr=0.001,\n        loss2=None,\n        loss2_weight=0.1,\n    ) -&gt; None:\n        super().__init__(\n            input_dim, output_dim, n_units, epochs, loss, lr, loss2, loss2_weight\n        )\n\n        self.r = nn.Parameter(data=torch.tensor([1.]))\n        self.sigma = nn.Parameter(data=torch.tensor([100.]))\n        self.loc = nn.Parameter(data=torch.tensor([100.]))",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Physics Informed Neural Networks</span>"
    ]
  },
  {
    "objectID": "601_pinn.html#basic-neutral-network",
    "href": "601_pinn.html#basic-neutral-network",
    "title": "47  Physics Informed Neural Networks",
    "section": "47.5 Basic Neutral Network",
    "text": "47.5 Basic Neutral Network\n\nNetwork without regularization:\n\n\nnet = Net(1,1, loss2=None, epochs=2000, lr=1e-5).to(DEVICE)\n\nlosses = net.fit(t, A)\n\nplt.plot(losses)\nplt.yscale('log')\n\nEpoch 0/2000, loss: 6.59\nEpoch 200/2000, loss: 0.06\nEpoch 400/2000, loss: 0.05\nEpoch 600/2000, loss: 0.05\nEpoch 800/2000, loss: 0.05\nEpoch 1000/2000, loss: 0.05\nEpoch 1200/2000, loss: 0.05\nEpoch 1400/2000, loss: 0.05\nEpoch 1600/2000, loss: 0.05\nEpoch 1800/2000, loss: 0.05\n\n\n\n\n\n\n\n\nFigure 47.2\n\n\n\n\n\n\nAdding L2 regularization:\n\n\ndef l2_reg(model: torch.nn.Module):\n    \"\"\"L2 regularization for the model parameters.\n\n    Args:\n        model: torch.nn.Module\n\n    Returns:\n        torch.Tensor\n\n    Examples:\n        &gt;&gt;&gt; l2_reg(Net(1,1))\n        tensor(0.0001, grad_fn=&lt;SumBackward0&gt;)\n    \"\"\"\n    return torch.sum(sum([p.pow(2.) for p in model.parameters()]))\n\n\nnetreg = Net(1,1, loss2=l2_reg, epochs=20000, lr=1e-5, loss2_weight=.1).to(DEVICE)\nlosses = netreg.fit(t, A)\nplt.plot(losses)\nplt.yscale('log')\n\nEpoch 0/20000, loss: 662.07\nEpoch 2000/20000, loss: 612.81\nEpoch 4000/20000, loss: 571.31\nEpoch 6000/20000, loss: 533.74\nEpoch 8000/20000, loss: 499.32\nEpoch 10000/20000, loss: 467.44\nEpoch 12000/20000, loss: 437.53\nEpoch 14000/20000, loss: 409.15\nEpoch 16000/20000, loss: 382.10\nEpoch 18000/20000, loss: 356.29\n\n\n\n\n\n\n\n\nFigure 47.3\n\n\n\n\n\n\npredsreg = netreg.predict(frequencies)\npreds = net.predict(frequencies)\nplt.plot(frequencies, amplitudes, alpha=0.8)\nplt.plot(t, A, 'o')\nplt.plot(frequencies, preds, alpha=0.8)\nplt.plot(frequencies, predsreg, alpha=0.8)\n\nplt.legend(labels=['Equation','Training data', 'Network', 'L2 Regularization Network'])\nplt.ylabel('Amplitude')\nplt.xlabel('Frequency')\n\n\n\n\n\n\nText(0.5, 0, 'Frequency')\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\nFigure 47.4",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Physics Informed Neural Networks</span>"
    ]
  },
  {
    "objectID": "601_pinn.html#pinns-1",
    "href": "601_pinn.html#pinns-1",
    "title": "47  Physics Informed Neural Networks",
    "section": "47.6 PINNs",
    "text": "47.6 PINNs\n\nCalculate the physics-informed loss (similar to the L2 regularization):\n\n\ndef physics_loss(model: torch.nn.Module):\n    \"\"\"Computes the physics-informed loss for the model.\n\n    Args:\n        model: torch.nn.Module\n\n    Returns:\n        torch.Tensor\n\n    Examples:\n        &gt;&gt;&gt; physics_loss(Net(1,1))\n        tensor(0.0001, grad_fn=&lt;MeanBackward0&gt;)\n    \"\"\"\n    ts = torch.linspace(a, b, steps=1000).view(-1,1).requires_grad_(True).to(DEVICE)\n    amplitudes = model(ts)\n    dT = grad(amplitudes, ts)[0]\n    ode = -2*R*(ts-loc)/ sigma**2 * amplitudes - dT\n    return torch.mean(ode**2)\n\n\nTrain the network with the physics-informed loss and plot the training error:\n\n\nnet_pinn = Net(1,1, loss2=physics_loss, epochs=2000, loss2_weight=1, lr=1e-5).to(DEVICE)\nlosses = net_pinn.fit(t, A)\nplt.plot(losses)\nplt.yscale('log')\n\nEpoch 0/2000, loss: 12.23\nEpoch 200/2000, loss: 1.05\nEpoch 400/2000, loss: 1.05\nEpoch 600/2000, loss: 1.05\nEpoch 800/2000, loss: 1.05\nEpoch 1000/2000, loss: 1.05\nEpoch 1200/2000, loss: 1.05\nEpoch 1400/2000, loss: 1.05\nEpoch 1600/2000, loss: 1.05\nEpoch 1800/2000, loss: 1.05\n\n\n\n\n\n\n\n\nFigure 47.5\n\n\n\n\n\n\nPredict the amplitude and plot the results:\n\n\npreds_pinn = net_pinn.predict(frequencies)\nplt.plot(frequencies, amplitudes, alpha=0.8)\nplt.plot(t, A, 'o')\nplt.plot(frequencies, preds, alpha=0.8)\nplt.plot(frequencies, predsreg, alpha=0.8)\nplt.plot(frequencies, preds_pinn, alpha=0.8)\nplt.legend(labels=['Equation','Training data', 'NN', \"R2\", 'PINN'])\nplt.ylabel('Amplitude')\nplt.xlabel('Frequency')\n\n\n\n\n\n\nText(0.5, 0, 'Frequency')\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\nFigure 47.6\n\n\n\n\n\n47.6.1 PINNs: Parameter Estimation\n\ndef physics_loss_estimation(model: torch.nn.Module):\n    ts = torch.linspace(a, b, steps=1000,).view(-1,1).requires_grad_(True).to(DEVICE)\n    amplitudes = model(ts)\n    dT = grad(amplitudes, ts)[0]\n    ode = -2*model.r*(ts-model.loc)/ (model.sigma)**2 * amplitudes - dT\n    return torch.mean(ode**2)\n\n\npinn_param = PINNParam(1, 1, loss2=physics_loss_estimation, loss2_weight=1, epochs=4000, lr= 5e-6).to(DEVICE)\nlosses = pinn_param.fit(t, A)\nplt.plot(losses)\nplt.yscale('log')\n\nEpoch 0/4000, loss: 15.06\nEpoch 400/4000, loss: 1.06\nEpoch 800/4000, loss: 1.06\nEpoch 1200/4000, loss: 1.06\nEpoch 1600/4000, loss: 1.05\nEpoch 2000/4000, loss: 1.05\nEpoch 2400/4000, loss: 1.05\nEpoch 2800/4000, loss: 1.05\nEpoch 3200/4000, loss: 1.05\nEpoch 3600/4000, loss: 1.05\n\n\n\n\n\n\n\n\nFigure 47.7\n\n\n\n\n\n\npreds_disc = pinn_param.predict(frequencies)\nprint(f\"Estimated r: {pinn_param.r}\")\nprint(f\"Estimated sigma: {pinn_param.sigma}\")\nprint(f\"Estimated loc: {pinn_param.loc}\")\n\nEstimated r: Parameter containing:\ntensor([0.9893], requires_grad=True)\nEstimated sigma: Parameter containing:\ntensor([100.0067], requires_grad=True)\nEstimated loc: Parameter containing:\ntensor([100.0065], requires_grad=True)\n\n\n\nplt.plot(frequencies, amplitudes, alpha=0.8)\nplt.plot(t, A, 'o')\nplt.plot(frequencies, preds_disc, alpha=0.8)\nplt.legend(labels=['Equation','Training data', 'estimation PINN'])\nplt.ylabel('Amplitude')\nplt.xlabel('Frequency')\n\n\n\n\n\n\nText(0.5, 0, 'Frequency')\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\nFigure 47.8\n\n\n\n\n\nplt.plot(frequencies, amplitudes, alpha=0.8)\nplt.plot(t, A, 'o')\nplt.plot(frequencies, preds, alpha=0.8)\nplt.plot(frequencies, predsreg, alpha=0.8)\nplt.plot(frequencies, preds_pinn, alpha=0.8)\nplt.plot(frequencies, preds_disc, alpha=0.8)\nplt.legend(labels=['Equation','Training data', 'NN', \"R2\", 'PINN', 'paramPINN'])\nplt.ylabel('Amplitude')\nplt.xlabel('Frequency')\n\n\n\n\n\n\nText(0.5, 0, 'Frequency')\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\nFigure 47.9\n\n\n\n\n\nplt.plot(frequencies, amplitudes, alpha=0.8)\nplt.plot(t, A, 'o')\nplt.plot(frequencies, preds, alpha=0.8)\nplt.plot(frequencies, predsreg, alpha=0.8)\nplt.plot(frequencies, preds_disc, alpha=0.8)\nplt.legend(labels=['Equation','Training data', 'NN', \"R2\", 'paramPINN'])\nplt.ylabel('Amplitude')\nplt.xlabel('Frequency')\n\n\n\n\n\n\nText(0.5, 0, 'Frequency')\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\nFigure 47.10\n\n\n\n\n\nplt.plot(frequencies, amplitudes, alpha=0.8)\nplt.plot(t, A, 'o')\nplt.plot(frequencies, preds, alpha=0.8)\nplt.plot(frequencies, predsreg, alpha=0.8)\nplt.plot(frequencies, preds_disc, alpha=0.8)\nplt.legend(labels=['Grundwahrheit','Trainingsdaten', 'NN', \"NN+R2\", 'PINN'])\nplt.ylabel('Amplitude')\nplt.xlabel('Frequenz')\n# save the plot as a pdf\nplt.savefig('pinns.pdf')\nplt.savefig('pinns.png')\n\n\n\n\n\n\n\nFigure 47.11",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Physics Informed Neural Networks</span>"
    ]
  },
  {
    "objectID": "601_pinn.html#summary",
    "href": "601_pinn.html#summary",
    "title": "47  Physics Informed Neural Networks",
    "section": "47.7 Summary",
    "text": "47.7 Summary\n\nResults strongly depend on the parametrization(s)\nPINN parameter estimation not robust\nHyperparameter tuning is crucial\nUse SPOT before further analysis is done",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Physics Informed Neural Networks</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_pinn.html",
    "href": "601_spot_hpt_light_pinn.html",
    "title": "48  Hyperparameter Tuning with PyTorch Lightning: Physics Informed Neural Networks",
    "section": "",
    "text": "48.1 PINNs\nIn this section, we will show how to set up PINN hyperparameter tuner from scratch based on the spotpython programs from Chapter 43.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Hyperparameter Tuning with PyTorch Lightning: Physics Informed Neural Networks</span>"
    ]
  },
  {
    "objectID": "601_spot_hpt_light_pinn.html#pinns",
    "href": "601_spot_hpt_light_pinn.html#pinns",
    "title": "48  Hyperparameter Tuning with PyTorch Lightning: Physics Informed Neural Networks",
    "section": "",
    "text": "48.1.1 The Ground Truth Model\nDefinition of the (unknown) differential equation:\n\nimport torch\nimport numpy as np\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data as thdat\nimport functools\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# boundaries for the frequency range\na = 0\nb = 500\n\ndef ode(frequency, loc, sigma, R):\n    \"\"\"Computes the amplitude. Defining equation, used\n    to generate data and train models.\n    The equation itself is not known to the model.\n\n    Args:\n        frequency: (N,) array-like\n        loc: float\n        sigma: float\n        R: float\n    \n    Returns:\n        (N,) array-like\n    \n    Examples:\n        &gt;&gt;&gt; ode(0, 25, 100, 0.005)\n        100.0\n    \"\"\"\n    A = np.exp(-R * (frequency - loc)**2/sigma**2)\n    return A\n\nSetting the parameters for the ode\n\nnp.random.seed(10)\nloc = 250\nsigma = 100\nR = 0.5\n\n\nGenerating the data\n\n\nfrequencies = np.linspace(a, b, 1000)\neq = functools.partial(ode, loc=loc, sigma=sigma, R=R)\namplitudes = eq(frequencies)\n\n\nNow we have the ground truth for the full frequency range and can take a look at the first 10 values:\n\n\ndf = pd.DataFrame({'Frequency': frequencies[:10], 'Amplitude': amplitudes[:10]})\nprint(df)\n\n   Frequency  Amplitude\n0   0.000000   0.043937\n1   0.500501   0.044490\n2   1.001001   0.045048\n3   1.501502   0.045612\n4   2.002002   0.046183\n5   2.502503   0.046759\n6   3.003003   0.047341\n7   3.503504   0.047929\n8   4.004004   0.048524\n9   4.504505   0.049124\n\n\n\nWe generate the training data as a subset of the full frequency range and add some noise:\n\n\n# Make training data\nt = np.linspace(a, 2*b/3, 10)\nA = eq(t) +  0.2 * np.random.randn(10)\n\n\nPlot of the training data and the ground truth:\n\n\nplt.plot(frequencies, amplitudes)\nplt.plot(t, A, 'o')\nplt.legend(['Equation (ground truth)', 'Training data'])\nplt.ylabel('Amplitude')\nplt.xlabel('Frequency')\n\nText(0.5, 0, 'Frequency')\n\n\n\n\n\n\n\n\n\n\n\n48.1.2 Required Files\nWe use the files from the /userModel directory as templates. They are renamed as follows:\n\nmy_regressor.py \\(\\Rightarrow\\) pinn_regressor.py, see Section 48.1.4\nmy_hyperdict.json \\(\\Rightarrow\\) pinn_hyperdict.py, see Section 48.1.5\nmy_hyperdict.py \\(\\Rightarrow\\) pinn_hyperdict.py, see Section 48.1.3.\n\n\n\n48.1.3 The New pinn_hyperdict.py File\nModifying the pin_hyperdict.py file is very easy. We simply have to change the classname MyHyperDict to PINNHyperDict and the filename from \"my_hyper_dict.json\" to \"pinn_hyper_dict.json\". The file is shown below.\n\nimport json\nfrom spotpython.data import base\nimport pathlib\n\nclass PINNHyperDict(base.FileConfig):\n    def __init__(\n        self,\n        filename: str = \"pinn_hyper_dict.json\",\n        directory: None = None,\n    ) -&gt; None:\n        super().__init__(filename=filename, directory=directory)\n        self.filename = filename\n        self.directory = directory\n        self.hyper_dict = self.load()\n\n    @property\n    def path(self):\n        if self.directory:\n            return pathlib.Path(self.directory).joinpath(self.filename)\n        return pathlib.Path(__file__).parent.joinpath(self.filename)\n\n    def load(self) -&gt; dict:\n        with open(self.path, \"r\") as f:\n            d = json.load(f)\n        return d\n\n\n\n48.1.4 The New pinn_regressor.py File\n\n\n\n\n\n\nWarning\n\n\n\nThe document is not complete. The code below is a template and needs to be modified to work with the PINN model.\n\n\n\nimport lightning as L\nimport torch\nfrom torch import nn\nfrom spotpython.hyperparameters.optimizer import optimizer_handler\nimport torchmetrics.functional.regression\n\nclass PINNRegressor(L.LightningModule):\n    \"\"\"\n    A LightningModule class for a regression neural network model.\n\n    Attributes:\n        l1 (int):\n            The number of neurons in the first hidden layer.\n        epochs (int):\n            The number of epochs to train the model for.\n        batch_size (int):\n            The batch size to use during training.\n        initialization (str):\n            The initialization method to use for the weights.\n        act_fn (nn.Module):\n            The activation function to use in the hidden layers.\n        optimizer (str):\n            The optimizer to use during training.\n        dropout_prob (float):\n            The probability of dropping out a neuron during training.\n        lr_mult (float):\n            The learning rate multiplier for the optimizer.\n        patience (int):\n            The number of epochs to wait before early stopping.\n        _L_in (int):\n            The number of input features.\n        _L_out (int):\n            The number of output classes.\n        _torchmetric (str):\n            The metric to use for the loss function. If `None`,\n            then \"mean_squared_error\" is used.\n        layers (nn.Sequential):\n            The neural network model.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        l1: int,\n        epochs: int,\n        batch_size: int,\n        initialization: str,\n        act_fn: nn.Module,\n        optimizer: str,\n        dropout_prob: float,\n        lr_mult: float,\n        patience: int,\n        _L_in: int,\n        _L_out: int,\n        _torchmetric: str,\n    ):\n        \"\"\"\n        Initializes the MyRegressor object.\n\n        Args:\n            l1 (int):\n                The number of neurons in the first hidden layer.\n            epochs (int):\n                The number of epochs to train the model for.\n            batch_size (int):\n                The batch size to use during training.\n            initialization (str):\n                The initialization method to use for the weights.\n            act_fn (nn.Module):\n                The activation function to use in the hidden layers.\n            optimizer (str):\n                The optimizer to use during training.\n            dropout_prob (float):\n                The probability of dropping out a neuron during training.\n            lr_mult (float):\n                The learning rate multiplier for the optimizer.\n            patience (int):\n                The number of epochs to wait before early stopping.\n            _L_in (int):\n                The number of input features. Not a hyperparameter, but needed to create the network.\n            _L_out (int):\n                The number of output classes. Not a hyperparameter, but needed to create the network.\n            _torchmetric (str):\n                The metric to use for the loss function. If `None`,\n                then \"mean_squared_error\" is used.\n\n        Returns:\n            (NoneType): None\n\n        Raises:\n            ValueError: If l1 is less than 4.\n\n        \"\"\"\n        super().__init__()\n        # Attribute 'act_fn' is an instance of `nn.Module` and is already saved during\n        # checkpointing. It is recommended to ignore them\n        # using `self.save_hyperparameters(ignore=['act_fn'])`\n        # self.save_hyperparameters(ignore=[\"act_fn\"])\n        #\n        self._L_in = _L_in\n        self._L_out = _L_out\n        if _torchmetric is None:\n            _torchmetric = \"mean_squared_error\"\n        self._torchmetric = _torchmetric\n        self.metric = getattr(torchmetrics.functional.regression, _torchmetric)\n        # _L_in and _L_out are not hyperparameters, but are needed to create the network\n        # _torchmetric is not a hyperparameter, but is needed to calculate the loss\n        self.save_hyperparameters(ignore=[\"_L_in\", \"_L_out\", \"_torchmetric\"])\n        # set dummy input array for Tensorboard Graphs\n        # set log_graph=True in Trainer to see the graph (in traintest.py)\n        self.example_input_array = torch.zeros((batch_size, self._L_in))\n        if self.hparams.l1 &lt; 4:\n            raise ValueError(\"l1 must be at least 4\")\n        hidden_sizes = self._get_hidden_sizes()\n        # Create the network based on the specified hidden sizes\n        layers = []\n        layer_sizes = [self._L_in] + hidden_sizes\n        layer_size_last = layer_sizes[0]\n        for layer_size in layer_sizes[1:]:\n            layers += [\n                nn.Linear(layer_size_last, layer_size),\n                self.hparams.act_fn,\n                nn.Dropout(self.hparams.dropout_prob),\n            ]\n            layer_size_last = layer_size\n        layers += [nn.Linear(layer_sizes[-1], self._L_out)]\n        # nn.Sequential summarizes a list of modules into a single module, applying them in sequence\n        self.layers = nn.Sequential(*layers)\n\n    def _generate_div2_list(self, n, n_min) -&gt; list:\n        \"\"\"\n        Generate a list of numbers from n to n_min (inclusive) by dividing n by 2\n        until the result is less than n_min.\n        This function starts with n and keeps dividing it by 2 until n_min is reached.\n        The number of times each value is added to the list is determined by n // current.\n        No more than 4 repeats of the same value (`max_repeats` below) are added to the list.\n\n        Args:\n            n (int): The number to start with.\n            n_min (int): The minimum number to stop at.\n\n        Returns:\n            list: A list of numbers from n to n_min (inclusive).\n\n        Examples:\n            _generate_div2_list(10, 1)\n            [10, 5, 5, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n            _ generate_div2_list(10, 2)\n            [10, 5, 5, 2, 2, 2, 2, 2]\n        \"\"\"\n        result = []\n        current = n\n        repeats = 1\n        max_repeats = 4\n        while current &gt;= n_min:\n            result.extend([current] * min(repeats, max_repeats))\n            current = current // 2\n            repeats = repeats + 1\n        return result\n\n    def _get_hidden_sizes(self):\n        \"\"\"\n        Generate the hidden layer sizes for the network.\n\n        Returns:\n            list: A list of hidden layer sizes.\n\n        \"\"\"\n        n_low = self._L_in // 4\n        n_high = max(self.hparams.l1, 2 * n_low)\n        hidden_sizes = self._generate_div2_list(n_high, n_low)\n        return hidden_sizes\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Performs a forward pass through the model.\n\n        Args:\n            x (torch.Tensor): A tensor containing a batch of input data.\n\n        Returns:\n            torch.Tensor: A tensor containing the output of the model.\n\n        \"\"\"\n        x = self.layers(x)\n        return x\n\n    def _calculate_loss(self, batch):\n        \"\"\"\n        Calculate the loss for the given batch.\n\n        Args:\n            batch (tuple): A tuple containing a batch of input data and labels.\n\n        Returns:\n            torch.Tensor: A tensor containing the loss for this batch.\n\n        \"\"\"\n        x, y = batch\n        y = y.view(len(y), 1)\n        y_hat = self(x)\n        loss = self.metric(y_hat, y)\n        return loss\n\n    def training_step(self, batch: tuple) -&gt; torch.Tensor:\n        \"\"\"\n        Performs a single training step.\n\n        Args:\n            batch (tuple): A tuple containing a batch of input data and labels.\n\n        Returns:\n            torch.Tensor: A tensor containing the loss for this batch.\n\n        \"\"\"\n        val_loss = self._calculate_loss(batch)\n        # self.log(\"train_loss\", val_loss, on_step=True, on_epoch=True, prog_bar=True)\n        # self.log(\"train_mae_loss\", mae_loss, on_step=True, on_epoch=True, prog_bar=True)\n        return val_loss\n\n    def validation_step(self, batch: tuple, batch_idx: int, prog_bar: bool = False) -&gt; torch.Tensor:\n        \"\"\"\n        Performs a single validation step.\n\n        Args:\n            batch (tuple): A tuple containing a batch of input data and labels.\n            batch_idx (int): The index of the current batch.\n            prog_bar (bool, optional): Whether to display the progress bar. Defaults to False.\n\n        Returns:\n            torch.Tensor: A tensor containing the loss for this batch.\n\n        \"\"\"\n        val_loss = self._calculate_loss(batch)\n        # self.log(\"val_loss\", val_loss, on_step=False, on_epoch=True, prog_bar=prog_bar)\n        self.log(\"val_loss\", val_loss, prog_bar=prog_bar)\n        self.log(\"hp_metric\", val_loss, prog_bar=prog_bar)\n        return val_loss\n\n    def test_step(self, batch: tuple, batch_idx: int, prog_bar: bool = False) -&gt; torch.Tensor:\n        \"\"\"\n        Performs a single test step.\n\n        Args:\n            batch (tuple): A tuple containing a batch of input data and labels.\n            batch_idx (int): The index of the current batch.\n            prog_bar (bool, optional): Whether to display the progress bar. Defaults to False.\n\n        Returns:\n            torch.Tensor: A tensor containing the loss for this batch.\n        \"\"\"\n        val_loss = self._calculate_loss(batch)\n        self.log(\"val_loss\", val_loss, prog_bar=prog_bar)\n        self.log(\"hp_metric\", val_loss, prog_bar=prog_bar)\n        return val_loss\n\n    def predict_step(self, batch: tuple, batch_idx: int, prog_bar: bool = False) -&gt; torch.Tensor:\n        \"\"\"\n        Performs a single prediction step.\n\n        Args:\n            batch (tuple): A tuple containing a batch of input data and labels.\n            batch_idx (int): The index of the current batch.\n            prog_bar (bool, optional): Whether to display the progress bar. Defaults to False.\n\n        Returns:\n            A tuple containing the input data, the true labels, and the predicted values.\n        \"\"\"\n        x, y = batch\n        yhat = self(x)\n        y = y.view(len(y), 1)\n        yhat = yhat.view(len(yhat), 1)\n        print(f\"Predict step x: {x}\")\n        print(f\"Predict step y: {y}\")\n        print(f\"Predict step y_hat: {yhat}\")\n        # pred_loss = F.mse_loss(y_hat, y)\n        # pred loss not registered\n        # self.log(\"pred_loss\", pred_loss, prog_bar=prog_bar)\n        # self.log(\"hp_metric\", pred_loss, prog_bar=prog_bar)\n        # MisconfigurationException: You are trying to `self.log()`\n        # but the loop's result collection is not registered yet.\n        # This is most likely because you are trying to log in a `predict` hook, but it doesn't support logging.\n        # If you want to manually log, please consider using `self.log_dict({'pred_loss': pred_loss})` instead.\n        return (x, y, yhat)\n\n    def configure_optimizers(self) -&gt; torch.optim.Optimizer:\n        \"\"\"\n        Configures the optimizer for the model.\n\n        Notes:\n            The default Lightning way is to define an optimizer as\n            `optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)`.\n            spotpython uses an optimizer handler to create the optimizer, which\n            adapts the learning rate according to the lr_mult hyperparameter as\n            well as other hyperparameters. See `spotpython.hyperparameters.optimizer.py` for details.\n\n        Returns:\n            torch.optim.Optimizer: The optimizer to use during training.\n\n        \"\"\"\n        # optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n        optimizer = optimizer_handler(\n            optimizer_name=self.hparams.optimizer, params=self.parameters(), lr_mult=self.hparams.lr_mult\n        )\n        return optimizer\n\n\n\n48.1.5 The New pinn_hyperdict.json File",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Hyperparameter Tuning with PyTorch Lightning: Physics Informed Neural Networks</span>"
    ]
  },
  {
    "objectID": "602_spot_lightning_xai.html",
    "href": "602_spot_lightning_xai.html",
    "title": "49  Explainable AI with SpotPython and Pytorch",
    "section": "",
    "text": "49.1 Running the Hyperparameter Tuning or Loading the Existing Model\nS.run()\n\ntrain_model result: {'val_loss': nan, 'hp_metric': nan}\n\n\ntrain_model result: {'val_loss': 3785.54541015625, 'hp_metric': 3785.54541015625}\n\n\ntrain_model result: {'val_loss': 3005.0224609375, 'hp_metric': 3005.0224609375}\n\n\ntrain_model result: {'val_loss': 4960.9326171875, 'hp_metric': 4960.9326171875}\n\n\ntrain_model result: {'val_loss': 3578.1474609375, 'hp_metric': 3578.1474609375}\n\n\ntrain_model result: {'val_loss': 5508.482421875, 'hp_metric': 5508.482421875}\ntrain_model result: {'val_loss': 4394.2734375, 'hp_metric': 4394.2734375}\n\n\ntrain_model result: {'val_loss': 3010.92236328125, 'hp_metric': 3010.92236328125}\nspotpython tuning: 3005.0224609375 [----------] 2.42% \n\n\ntrain_model result: {'val_loss': 3692.31640625, 'hp_metric': 3692.31640625}\nspotpython tuning: 3005.0224609375 [#---------] 7.88% \n\n\ntrain_model result: {'val_loss': 3565.788818359375, 'hp_metric': 3565.788818359375}\nspotpython tuning: 3005.0224609375 [#---------] 9.35% \n\n\ntrain_model result: {'val_loss': 3632.890869140625, 'hp_metric': 3632.890869140625}\nspotpython tuning: 3005.0224609375 [##--------] 17.48% \n\n\ntrain_model result: {'val_loss': 3270.799560546875, 'hp_metric': 3270.799560546875}\nspotpython tuning: 3005.0224609375 [##--------] 20.80% \n\n\ntrain_model result: {'val_loss': 4029.51416015625, 'hp_metric': 4029.51416015625}\nspotpython tuning: 3005.0224609375 [##--------] 23.60% \n\n\ntrain_model result: {'val_loss': 3130.77783203125, 'hp_metric': 3130.77783203125}\nspotpython tuning: 3005.0224609375 [###-------] 26.33% \n\n\ntrain_model result: {'val_loss': 4266.46484375, 'hp_metric': 4266.46484375}\nspotpython tuning: 3005.0224609375 [###-------] 28.19% \n\n\ntrain_model result: {'val_loss': 5275.7763671875, 'hp_metric': 5275.7763671875}\nspotpython tuning: 3005.0224609375 [####------] 36.99% \n\n\ntrain_model result: {'val_loss': 2935.796875, 'hp_metric': 2935.796875}\nspotpython tuning: 2935.796875 [####------] 39.50% \n\n\ntrain_model result: {'val_loss': 3109.743408203125, 'hp_metric': 3109.743408203125}\nspotpython tuning: 2935.796875 [####------] 41.69% \n\n\ntrain_model result: {'val_loss': 3526.829833984375, 'hp_metric': 3526.829833984375}\nspotpython tuning: 2935.796875 [######----] 59.03% \n\n\ntrain_model result: {'val_loss': 3361.64794921875, 'hp_metric': 3361.64794921875}\nspotpython tuning: 2935.796875 [######----] 62.65% \n\n\ntrain_model result: {'val_loss': 5165.126953125, 'hp_metric': 5165.126953125}\nspotpython tuning: 2935.796875 [#######---] 65.12% \n\n\ntrain_model result: {'val_loss': 2924.69921875, 'hp_metric': 2924.69921875}\nspotpython tuning: 2924.69921875 [#######---] 67.99% \n\n\ntrain_model result: {'val_loss': 4374.9560546875, 'hp_metric': 4374.9560546875}\nspotpython tuning: 2924.69921875 [#######---] 70.24% \n\n\ntrain_model result: {'val_loss': 3835.705078125, 'hp_metric': 3835.705078125}\nspotpython tuning: 2924.69921875 [#######---] 72.79% \n\n\ntrain_model result: {'val_loss': 3773.844970703125, 'hp_metric': 3773.844970703125}\nspotpython tuning: 2924.69921875 [########--] 75.32% \n\n\ntrain_model result: {'val_loss': 2939.6162109375, 'hp_metric': 2939.6162109375}\nspotpython tuning: 2924.69921875 [########--] 77.98% \n\n\ntrain_model result: {'val_loss': 3410.932861328125, 'hp_metric': 3410.932861328125}\nspotpython tuning: 2924.69921875 [########--] 83.02% \n\n\ntrain_model result: {'val_loss': 3396.709228515625, 'hp_metric': 3396.709228515625}\nspotpython tuning: 2924.69921875 [#########-] 89.06% \n\n\ntrain_model result: {'val_loss': 3335.02001953125, 'hp_metric': 3335.02001953125}\nspotpython tuning: 2924.69921875 [##########] 95.06% \n\n\ntrain_model result: {'val_loss': 3649.60791015625, 'hp_metric': 3649.60791015625}\nspotpython tuning: 2924.69921875 [##########] 100.00% Done...\n\nExperiment saved to 602_12_1_res.pkl\n\n\n&lt;spotpython.spot.spot.Spot at 0x1503fe780&gt;",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Explainable AI with SpotPython and Pytorch</span>"
    ]
  },
  {
    "objectID": "602_spot_lightning_xai.html#results-from-the-hyperparameter-tuning-experiment",
    "href": "602_spot_lightning_xai.html#results-from-the-hyperparameter-tuning-experiment",
    "title": "49  Explainable AI with SpotPython and Pytorch",
    "section": "49.2 Results from the Hyperparameter Tuning Experiment",
    "text": "49.2 Results from the Hyperparameter Tuning Experiment\n\nAfter the hyperparameter tuning is finished, the following information is available:\n\nthe S object and the associated\nfun_control dictionary\n\n\n\nS.print_results(print_screen=True)\n\nmin y: 2924.69921875\nl1: 4.0\nepochs: 12.0\nbatch_size: 11.0\nact_fn: 2.0\noptimizer: 1.0\ndropout_prob: 0.010496789685251895\nlr_mult: 3.789080686036231\npatience: 4.0\nbatch_norm: 0.0\ninitialization: 1.0\n\n\n[['l1', np.float64(4.0)],\n ['epochs', np.float64(12.0)],\n ['batch_size', np.float64(11.0)],\n ['act_fn', np.float64(2.0)],\n ['optimizer', np.float64(1.0)],\n ['dropout_prob', np.float64(0.010496789685251895)],\n ['lr_mult', np.float64(3.789080686036231)],\n ['patience', np.float64(4.0)],\n ['batch_norm', np.float64(0.0)],\n ['initialization', np.float64(1.0)]]\n\n\n\nS.plot_progress()\n\n\n\n\n\n\n\n\n\n49.2.1 Getting the Best Model, i.e, the Tuned Architecture\n\nThe method get_tuned_architecture [DOC] returns the best model architecture found during the hyperparameter tuning.\nIt returns the transformed values, i.e., batch_size = 2^x if the hyperparameter batch_size was transformed with the transform_power_2_int function.\n\n\nfrom spotpython.hyperparameters.values import get_tuned_architecture\nimport pprint\nconfig = get_tuned_architecture(S)\npprint.pprint(config)\n\n{'act_fn': ReLU(),\n 'batch_norm': False,\n 'batch_size': 2048,\n 'dropout_prob': 0.010496789685251895,\n 'epochs': 4096,\n 'initialization': 'kaiming_uniform',\n 'l1': 16,\n 'lr_mult': 3.789080686036231,\n 'optimizer': 'Adam',\n 'patience': 16}\n\n\n\nNote: get_tuned_architecture has the option force_minX which does not have any effect in this case.\n\n\nfrom spotpython.hyperparameters.values import get_tuned_architecture\nconfig = get_tuned_architecture(S, force_minX=True)\npprint.pprint(config)\n\n{'act_fn': ReLU(),\n 'batch_norm': False,\n 'batch_size': 2048,\n 'dropout_prob': 0.010496789685251895,\n 'epochs': 4096,\n 'initialization': 'kaiming_uniform',\n 'l1': 16,\n 'lr_mult': 3.789080686036231,\n 'optimizer': 'Adam',\n 'patience': 16}",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Explainable AI with SpotPython and Pytorch</span>"
    ]
  },
  {
    "objectID": "602_spot_lightning_xai.html#training-the-tuned-architecture-on-the-test-data",
    "href": "602_spot_lightning_xai.html#training-the-tuned-architecture-on-the-test-data",
    "title": "49  Explainable AI with SpotPython and Pytorch",
    "section": "49.3 Training the Tuned Architecture on the Test Data",
    "text": "49.3 Training the Tuned Architecture on the Test Data\n\nSince we are interested in the explainability of the model, we will train the tuned architecture on the test data.\nspotpythons’s test_model function [DOC] is used to train the model on the test data.\nNote: Until now, we do not use any information about the NN’s weights and biases. Only the architecture, which is available as the config, is used.\nspotpython used the TensorBoard logger to save the training process in the ./runs directory. Therefore, we have to enable the TensorBoard logger in the fun_control dictionary. To get a clean start, we remove an existing runs folder.\n\n\nfrom spotpython.light.testmodel import test_model\nfrom spotpython.light.loadmodel import load_light_from_checkpoint\nfun_control.update({\"tensorboard_log\": True})\ntest_model(config, fun_control)\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃        Test metric        ┃       DataLoader 0        ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│         hp_metric         │     3187.16748046875      │\n│         val_loss          │     3187.16748046875      │\n└───────────────────────────┴───────────────────────────┘\n\n\n\ntest_model result: {'val_loss': 3187.16748046875, 'hp_metric': 3187.16748046875}\n\n\n(3187.16748046875, 3187.16748046875)\n\n\n\nmodel = load_light_from_checkpoint(config, fun_control)\n\nconfig: {'l1': 16, 'epochs': 4096, 'batch_size': 2048, 'act_fn': ReLU(), 'optimizer': 'Adam', 'dropout_prob': 0.010496789685251895, 'lr_mult': 3.789080686036231, 'patience': 16, 'batch_norm': False, 'initialization': 'kaiming_uniform'}\nLoading model with 16_4096_2048_ReLU_Adam_0.0105_3.7891_16_False_kaiming_uniform_TEST from runs/saved_models/16_4096_2048_ReLU_Adam_0.0105_3.7891_16_False_kaiming_uniform_TEST/last.ckpt\nModel: NNLinearRegressor(\n  (layers): Sequential(\n    (0): Linear(in_features=10, out_features=320, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.010496789685251895, inplace=False)\n    (3): Linear(in_features=320, out_features=160, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.010496789685251895, inplace=False)\n    (6): Linear(in_features=160, out_features=320, bias=True)\n    (7): ReLU()\n    (8): Dropout(p=0.010496789685251895, inplace=False)\n    (9): Linear(in_features=320, out_features=160, bias=True)\n    (10): ReLU()\n    (11): Dropout(p=0.010496789685251895, inplace=False)\n    (12): Linear(in_features=160, out_features=160, bias=True)\n    (13): ReLU()\n    (14): Dropout(p=0.010496789685251895, inplace=False)\n    (15): Linear(in_features=160, out_features=80, bias=True)\n    (16): ReLU()\n    (17): Dropout(p=0.010496789685251895, inplace=False)\n    (18): Linear(in_features=80, out_features=80, bias=True)\n    (19): ReLU()\n    (20): Dropout(p=0.010496789685251895, inplace=False)\n    (21): Linear(in_features=80, out_features=1, bias=True)\n  )\n)\n\n\n\n49.3.0.1 Details of the Training Process on the Test Data\n\nThe test_model method initializes the model with the tuned architecture as follows:\n\nmodel = fun_control[\"core_model\"](**config, _L_in=_L_in, _L_out=_L_out, _torchmetric=_torchmetric)\n\nThen, the Lightning Trainer is initialized with the fun_control dictionary and the model as follows:\n    trainer = L.Trainer(\n    default_root_dir=os.path.join(fun_control[\"CHECKPOINT_PATH\"], config_id),\n    max_epochs=model.hparams.epochs,\n    accelerator=fun_control[\"accelerator\"],\n    devices=fun_control[\"devices\"],\n    logger=TensorBoardLogger(\n        save_dir=fun_control[\"TENSORBOARD_PATH\"],\n        version=config_id,\n        default_hp_metric=True,\n        log_graph=fun_control[\"log_graph\"],\n    ),\n    callbacks=[\n        EarlyStopping(monitor=\"val_loss\", patience=config[\"patience\"], mode=\"min\", strict=False, verbose=False),\n        ModelCheckpoint(\n            dirpath=os.path.join(fun_control[\"CHECKPOINT_PATH\"], config_id), save_last=True\n        ), \n    ],\n    enable_progress_bar=enable_progress_bar,\n)\ntrainer.fit(model=model, datamodule=dm)    \ntest_result = trainer.test(datamodule=dm, ckpt_path=\"last\")\nAs shown in the code above, the last checkpoint ist saved.\nspotpython’s method load_light_from_checkpoint is used to load the last checkpoint and to get the model’s weights and biases. It requires the fun_control dictionary and the config_id as input to find the correct checkpoint.\nNow, the model is trained and the weights and biases are available.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Explainable AI with SpotPython and Pytorch</span>"
    ]
  },
  {
    "objectID": "602_spot_lightning_xai.html#visualizing-the-neural-network-architecture",
    "href": "602_spot_lightning_xai.html#visualizing-the-neural-network-architecture",
    "title": "49  Explainable AI with SpotPython and Pytorch",
    "section": "49.4 Visualizing the Neural Network Architecture",
    "text": "49.4 Visualizing the Neural Network Architecture\n\n# get the device\nfrom spotpython.utils.device import getDevice\ndevice = getDevice()\n\n\nfrom spotpython.plot.xai import viz_net\nviz_net(model, device=device)\n\n\n\n\narchitecture",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Explainable AI with SpotPython and Pytorch</span>"
    ]
  },
  {
    "objectID": "602_spot_lightning_xai.html#xai-methods",
    "href": "602_spot_lightning_xai.html#xai-methods",
    "title": "49  Explainable AI with SpotPython and Pytorch",
    "section": "49.5 XAI Methods",
    "text": "49.5 XAI Methods\n\nspotpython provides methods to explain the model’s predictions. The following neural network elements can be analyzed:\n\n\n49.5.1 Weights\n\nWeights are the parameters of the neural network that are learned from the data during training. They connect neurons between layers and determine the strength and direction of the signal sent from one neuron to another. The network adjusts the weights during training to minimize the error between the predicted output and the actual output.\nInterpretation of the weights: A high weight value indicates a strong influence of the input neuron on the output. Positive weights suggest a positive correlation, whereas negative weights suggest an inverse relationship between neurons.\n\n\n\n49.5.2 Activations\n\nActivations are the outputs produced by neurons after applying an activation function to the weighted sum of inputs. The activation function (e.g., ReLU, sigmoid, tanh) adds non-linearity to the model, allowing it to learn more complex relationships.\nInterpretation of the activations: The value of activations indicates the intensity of the signal passed to the next layer. Certain activation patterns can highlight which features or parts of the data the network is focusing on.\n\n\n\n49.5.3 Gradients\n\nGradients are the partial derivatives of the loss function with respect to different parameters (weights) of the network. During backpropagation, gradients are used to update the weights in the direction that reduces the loss by methods like gradient descent.\nInterpretation of the gradients: The magnitude of the gradient indicates how much a parameter should change to reduce the error. A large gradient implies a steeper slope and a bigger update, while a small gradient suggests that the parameter is near an optimal point. If gradients are too small (vanishing gradient problem), the network may learn slowly or stop learning. If they are too large (exploding gradient problem), the updates may be unstable.\nsptpython provides the method get_gradients to get the gradients of the model.\n\n\nfrom spotpython.plot.xai import (get_activations, get_gradients, get_weights, visualize_weights, visualize_gradients, visualize_mean_activations, visualize_gradient_distributions, visualize_weights_distributions, visualize_activations_distributions)\nbatch_size = config[\"batch_size\"]\n\n\n\n49.5.4 Getting the Weights\n\nfrom spotpython.plot.xai import sort_layers\nweights, _ = get_weights(model)\n# sort_layers(weights)\n\n\nvisualize_weights(model, absolute=True, cmap=\"GreenYellowRed\", figsize=(6, 6))\n\n3200 values in Layer Layer 0. Geometry: (320, 10)\n\n\n\n\n\n\n\n\n\n51200 values in Layer Layer 3. Geometry: (160, 320)\n\n\n\n\n\n\n\n\n\n51200 values in Layer Layer 6. Geometry: (320, 160)\n\n\n\n\n\n\n\n\n\n51200 values in Layer Layer 9. Geometry: (160, 320)\n\n\n\n\n\n\n\n\n\n25600 values in Layer Layer 12. Geometry: (160, 160)\n\n\n\n\n\n\n\n\n\n12800 values in Layer Layer 15. Geometry: (80, 160)\n\n\n\n\n\n\n\n\n\n6400 values in Layer Layer 18. Geometry: (80, 80)\n\n\n\n\n\n\n\n\n\n80 values in Layer Layer 21. Geometry: (1, 80)\n\n\n\n\n\n\n\n\n\n\nvisualize_weights_distributions(model, color=f\"C{0}\", columns=4)\n\nn:8\n\n\n\n\n\n\n\n\n\n\n\n49.5.5 Getting the Activations\n\nfrom spotpython.plot.xai import get_activations\nactivations, mean_activations, layer_sizes = get_activations(net=model, fun_control=fun_control, batch_size=batch_size, device=device)\n\ntrain_size: 0.36, val_size: 0.24, test_sie: 0.4 for splitting train & val data.\ntrain samples: 160, val samples: 106 generated for train & val data.\nLightDataModule.train_dataloader(). data_train size: 160\n\n\n\nvisualize_mean_activations(mean_activations, layer_sizes=layer_sizes, absolute=True, cmap=\"GreenYellowRed\", figsize=(6, 6))\n\n320 values in Layer 0. Geometry: (1, 320)\n\n\n\n\n\n\n\n\n\n160 values in Layer 3. Geometry: (1, 160)\n\n\n\n\n\n\n\n\n\n320 values in Layer 6. Geometry: (1, 320)\n\n\n\n\n\n\n\n\n\n160 values in Layer 9. Geometry: (1, 160)\n\n\n\n\n\n\n\n\n\n160 values in Layer 12. Geometry: (1, 160)\n\n\n\n\n\n\n\n\n\n80 values in Layer 15. Geometry: (1, 80)\n\n\n\n\n\n\n\n\n\n80 values in Layer 18. Geometry: (1, 80)\n\n\n\n\n\n\n\n\n\n\nvisualize_activations_distributions(activations=activations,\n                                    net=model, color=\"C0\", columns=4)\n\n\n\n\n\n\n\n\n\n\n49.5.6 Getting the Gradients\n\ngradients, _ = get_gradients(net=model, fun_control=fun_control, batch_size=batch_size, device=device)\n\ntrain_size: 0.36, val_size: 0.24, test_sie: 0.4 for splitting train & val data.\ntrain samples: 160, val samples: 106 generated for train & val data.\nLightDataModule.train_dataloader(). data_train size: 160\n\n\n\nvisualize_gradients(model, fun_control, batch_size, absolute=True, cmap=\"GreenYellowRed\", figsize=(6, 6), device=device)\n\ntrain_size: 0.36, val_size: 0.24, test_sie: 0.4 for splitting train & val data.\ntrain samples: 160, val samples: 106 generated for train & val data.\nLightDataModule.train_dataloader(). data_train size: 160\n3200 values in Layer layers.0.weight. Geometry: (320, 10)\n\n\n\n\n\n\n\n\n\n51200 values in Layer layers.3.weight. Geometry: (160, 320)\n\n\n\n\n\n\n\n\n\n51200 values in Layer layers.6.weight. Geometry: (320, 160)\n\n\n\n\n\n\n\n\n\n51200 values in Layer layers.9.weight. Geometry: (160, 320)\n\n\n\n\n\n\n\n\n\n25600 values in Layer layers.12.weight. Geometry: (160, 160)\n\n\n\n\n\n\n\n\n\n12800 values in Layer layers.15.weight. Geometry: (80, 160)\n\n\n\n\n\n\n\n\n\n6400 values in Layer layers.18.weight. Geometry: (80, 80)\n\n\n\n\n\n\n\n\n\n80 values in Layer layers.21.weight. Geometry: (1, 80)\n\n\n\n\n\n\n\n\n\n\nvisualize_gradient_distributions(model, fun_control, batch_size=batch_size, color=f\"C{0}\", device=device, columns=3)\n\ntrain_size: 0.36, val_size: 0.24, test_sie: 0.4 for splitting train & val data.\ntrain samples: 160, val samples: 106 generated for train & val data.\nLightDataModule.train_dataloader(). data_train size: 160\nn:8",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Explainable AI with SpotPython and Pytorch</span>"
    ]
  },
  {
    "objectID": "602_spot_lightning_xai.html#feature-attributions",
    "href": "602_spot_lightning_xai.html#feature-attributions",
    "title": "49  Explainable AI with SpotPython and Pytorch",
    "section": "49.6 Feature Attributions",
    "text": "49.6 Feature Attributions\n\n49.6.1 Integrated Gradients\n\nfrom spotpython.plot.xai import get_attributions, plot_attributions\ndf_att = get_attributions(S, fun_control, attr_method=\"IntegratedGradients\", n_rel=10)\nplot_attributions(df_att, attr_method=\"IntegratedGradients\")\n\ntrain_model result: {'val_loss': 3462.836669921875, 'hp_metric': 3462.836669921875}\nconfig: {'l1': 16, 'epochs': 4096, 'batch_size': 2048, 'act_fn': ReLU(), 'optimizer': 'Adam', 'dropout_prob': 0.010496789685251895, 'lr_mult': 3.789080686036231, 'patience': 16, 'batch_norm': False, 'initialization': 'kaiming_uniform'}\nLoading model with 16_4096_2048_ReLU_Adam_0.0105_3.7891_16_False_kaiming_uniform_TRAIN from runs/saved_models/16_4096_2048_ReLU_Adam_0.0105_3.7891_16_False_kaiming_uniform_TRAIN/last.ckpt\nModel: NNLinearRegressor(\n  (layers): Sequential(\n    (0): Linear(in_features=10, out_features=320, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.010496789685251895, inplace=False)\n    (3): Linear(in_features=320, out_features=160, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.010496789685251895, inplace=False)\n    (6): Linear(in_features=160, out_features=320, bias=True)\n    (7): ReLU()\n    (8): Dropout(p=0.010496789685251895, inplace=False)\n    (9): Linear(in_features=320, out_features=160, bias=True)\n    (10): ReLU()\n    (11): Dropout(p=0.010496789685251895, inplace=False)\n    (12): Linear(in_features=160, out_features=160, bias=True)\n    (13): ReLU()\n    (14): Dropout(p=0.010496789685251895, inplace=False)\n    (15): Linear(in_features=160, out_features=80, bias=True)\n    (16): ReLU()\n    (17): Dropout(p=0.010496789685251895, inplace=False)\n    (18): Linear(in_features=80, out_features=80, bias=True)\n    (19): ReLU()\n    (20): Dropout(p=0.010496789685251895, inplace=False)\n    (21): Linear(in_features=80, out_features=1, bias=True)\n  )\n)\ntrain_size: 0.36, val_size: 0.24, test_sie: 0.4 for splitting test data.\ntest samples: 177 generated for test data.\nLightDataModule.test_dataloader(). Test set size: 177\n\n\n\n\n\n\n\n\n\n\n\n49.6.2 Deep Lift\n\ndf_lift = get_attributions(S, fun_control, attr_method=\"DeepLift\",n_rel=10)\nprint(df_lift)\nplot_attributions(df_lift,  attr_method=\"DeepLift\")\n\ntrain_model result: {'val_loss': 3343.678466796875, 'hp_metric': 3343.678466796875}\nconfig: {'l1': 16, 'epochs': 4096, 'batch_size': 2048, 'act_fn': ReLU(), 'optimizer': 'Adam', 'dropout_prob': 0.010496789685251895, 'lr_mult': 3.789080686036231, 'patience': 16, 'batch_norm': False, 'initialization': 'kaiming_uniform'}\nLoading model with 16_4096_2048_ReLU_Adam_0.0105_3.7891_16_False_kaiming_uniform_TRAIN from runs/saved_models/16_4096_2048_ReLU_Adam_0.0105_3.7891_16_False_kaiming_uniform_TRAIN/last.ckpt\nModel: NNLinearRegressor(\n  (layers): Sequential(\n    (0): Linear(in_features=10, out_features=320, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.010496789685251895, inplace=False)\n    (3): Linear(in_features=320, out_features=160, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.010496789685251895, inplace=False)\n    (6): Linear(in_features=160, out_features=320, bias=True)\n    (7): ReLU()\n    (8): Dropout(p=0.010496789685251895, inplace=False)\n    (9): Linear(in_features=320, out_features=160, bias=True)\n    (10): ReLU()\n    (11): Dropout(p=0.010496789685251895, inplace=False)\n    (12): Linear(in_features=160, out_features=160, bias=True)\n    (13): ReLU()\n    (14): Dropout(p=0.010496789685251895, inplace=False)\n    (15): Linear(in_features=160, out_features=80, bias=True)\n    (16): ReLU()\n    (17): Dropout(p=0.010496789685251895, inplace=False)\n    (18): Linear(in_features=80, out_features=80, bias=True)\n    (19): ReLU()\n    (20): Dropout(p=0.010496789685251895, inplace=False)\n    (21): Linear(in_features=80, out_features=1, bias=True)\n  )\n)\ntrain_size: 0.36, val_size: 0.24, test_sie: 0.4 for splitting test data.\ntest samples: 177 generated for test data.\nLightDataModule.test_dataloader(). Test set size: 177\n   Feature Index Feature  DeepLiftAttribution\n0              0     age           239.176514\n1              1     sex           234.168716\n2              3      bp           213.472198\n3              2     bmi           192.978683\n4              9  s6_glu           156.818741\n5              6  s3_hdl           145.971436\n6              8  s5_ltg           132.569016\n7              4   s1_tc           116.392235\n8              5  s2_ldl            78.888840\n9              7  s4_tch            69.878174\n\n\n\n\n\n\n\n\n\n\n\n49.6.3 Feature Ablation\n\ndf_fl = get_attributions(S, fun_control, attr_method=\"FeatureAblation\",n_rel=10)\n\ntrain_model result: {'val_loss': 3188.953369140625, 'hp_metric': 3188.953369140625}\nconfig: {'l1': 16, 'epochs': 4096, 'batch_size': 2048, 'act_fn': ReLU(), 'optimizer': 'Adam', 'dropout_prob': 0.010496789685251895, 'lr_mult': 3.789080686036231, 'patience': 16, 'batch_norm': False, 'initialization': 'kaiming_uniform'}\nLoading model with 16_4096_2048_ReLU_Adam_0.0105_3.7891_16_False_kaiming_uniform_TRAIN from runs/saved_models/16_4096_2048_ReLU_Adam_0.0105_3.7891_16_False_kaiming_uniform_TRAIN/last.ckpt\nModel: NNLinearRegressor(\n  (layers): Sequential(\n    (0): Linear(in_features=10, out_features=320, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.010496789685251895, inplace=False)\n    (3): Linear(in_features=320, out_features=160, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.010496789685251895, inplace=False)\n    (6): Linear(in_features=160, out_features=320, bias=True)\n    (7): ReLU()\n    (8): Dropout(p=0.010496789685251895, inplace=False)\n    (9): Linear(in_features=320, out_features=160, bias=True)\n    (10): ReLU()\n    (11): Dropout(p=0.010496789685251895, inplace=False)\n    (12): Linear(in_features=160, out_features=160, bias=True)\n    (13): ReLU()\n    (14): Dropout(p=0.010496789685251895, inplace=False)\n    (15): Linear(in_features=160, out_features=80, bias=True)\n    (16): ReLU()\n    (17): Dropout(p=0.010496789685251895, inplace=False)\n    (18): Linear(in_features=80, out_features=80, bias=True)\n    (19): ReLU()\n    (20): Dropout(p=0.010496789685251895, inplace=False)\n    (21): Linear(in_features=80, out_features=1, bias=True)\n  )\n)\ntrain_size: 0.36, val_size: 0.24, test_sie: 0.4 for splitting test data.\ntest samples: 177 generated for test data.\nLightDataModule.test_dataloader(). Test set size: 177\n\n\n\nprint(df_fl)\nplot_attributions(df_fl, attr_method=\"FeatureAblation\")\n\n   Feature Index Feature  FeatureAblationAttribution\n0              0     age                  147.619675\n1              3      bp                  132.608917\n2              1     sex                  129.695129\n3              2     bmi                  110.809540\n4              6  s3_hdl                   77.670723\n5              9  s6_glu                   72.859764\n6              8  s5_ltg                   68.457718\n7              4   s1_tc                   46.000454\n8              5  s2_ldl                   20.679939\n9              7  s4_tch                    4.354902",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Explainable AI with SpotPython and Pytorch</span>"
    ]
  },
  {
    "objectID": "602_spot_lightning_xai.html#conductance",
    "href": "602_spot_lightning_xai.html#conductance",
    "title": "49  Explainable AI with SpotPython and Pytorch",
    "section": "49.7 Conductance",
    "text": "49.7 Conductance\n\nfrom spotpython.plot.xai import plot_conductance_last_layer, get_weights_conductance_last_layer\nweights_last, layer_conductance_last = get_weights_conductance_last_layer(S, fun_control)\nplot_conductance_last_layer(weights_last, layer_conductance_last, figsize=(6, 6))\n\ntrain_model result: {'val_loss': 3019.501708984375, 'hp_metric': 3019.501708984375}\nconfig: {'l1': 16, 'epochs': 4096, 'batch_size': 2048, 'act_fn': ReLU(), 'optimizer': 'Adam', 'dropout_prob': 0.010496789685251895, 'lr_mult': 3.789080686036231, 'patience': 16, 'batch_norm': False, 'initialization': 'kaiming_uniform'}\nLoading model with 16_4096_2048_ReLU_Adam_0.0105_3.7891_16_False_kaiming_uniform_TRAIN from runs/saved_models/16_4096_2048_ReLU_Adam_0.0105_3.7891_16_False_kaiming_uniform_TRAIN/last.ckpt\nModel: NNLinearRegressor(\n  (layers): Sequential(\n    (0): Linear(in_features=10, out_features=320, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.010496789685251895, inplace=False)\n    (3): Linear(in_features=320, out_features=160, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.010496789685251895, inplace=False)\n    (6): Linear(in_features=160, out_features=320, bias=True)\n    (7): ReLU()\n    (8): Dropout(p=0.010496789685251895, inplace=False)\n    (9): Linear(in_features=320, out_features=160, bias=True)\n    (10): ReLU()\n    (11): Dropout(p=0.010496789685251895, inplace=False)\n    (12): Linear(in_features=160, out_features=160, bias=True)\n    (13): ReLU()\n    (14): Dropout(p=0.010496789685251895, inplace=False)\n    (15): Linear(in_features=160, out_features=80, bias=True)\n    (16): ReLU()\n    (17): Dropout(p=0.010496789685251895, inplace=False)\n    (18): Linear(in_features=80, out_features=80, bias=True)\n    (19): ReLU()\n    (20): Dropout(p=0.010496789685251895, inplace=False)\n    (21): Linear(in_features=80, out_features=1, bias=True)\n  )\n)\ntrain_model result: {'val_loss': 3446.660888671875, 'hp_metric': 3446.660888671875}\nconfig: {'l1': 16, 'epochs': 4096, 'batch_size': 2048, 'act_fn': ReLU(), 'optimizer': 'Adam', 'dropout_prob': 0.010496789685251895, 'lr_mult': 3.789080686036231, 'patience': 16, 'batch_norm': False, 'initialization': 'kaiming_uniform'}\nLoading model with 16_4096_2048_ReLU_Adam_0.0105_3.7891_16_False_kaiming_uniform_TRAIN from runs/saved_models/16_4096_2048_ReLU_Adam_0.0105_3.7891_16_False_kaiming_uniform_TRAIN/last.ckpt\nModel: NNLinearRegressor(\n  (layers): Sequential(\n    (0): Linear(in_features=10, out_features=320, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.010496789685251895, inplace=False)\n    (3): Linear(in_features=320, out_features=160, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.010496789685251895, inplace=False)\n    (6): Linear(in_features=160, out_features=320, bias=True)\n    (7): ReLU()\n    (8): Dropout(p=0.010496789685251895, inplace=False)\n    (9): Linear(in_features=320, out_features=160, bias=True)\n    (10): ReLU()\n    (11): Dropout(p=0.010496789685251895, inplace=False)\n    (12): Linear(in_features=160, out_features=160, bias=True)\n    (13): ReLU()\n    (14): Dropout(p=0.010496789685251895, inplace=False)\n    (15): Linear(in_features=160, out_features=80, bias=True)\n    (16): ReLU()\n    (17): Dropout(p=0.010496789685251895, inplace=False)\n    (18): Linear(in_features=80, out_features=80, bias=True)\n    (19): ReLU()\n    (20): Dropout(p=0.010496789685251895, inplace=False)\n    (21): Linear(in_features=80, out_features=1, bias=True)\n  )\n)\nConductance analysis for layer:  Linear(in_features=80, out_features=1, bias=True)",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Explainable AI with SpotPython and Pytorch</span>"
    ]
  },
  {
    "objectID": "603_spot_lightning_transformer_introduction.html",
    "href": "603_spot_lightning_transformer_introduction.html",
    "title": "50  HPT PyTorch Lightning Transformer: Introduction",
    "section": "",
    "text": "50.1 Transformer Basics\nIn this chapter, we will introduce transformer. The transformer architecture is a neural network architecture that is based on the attention mechanism (Vaswani et al. 2017). It is particularly well suited for sequence-to-sequence tasks, such as machine translation, text summarization, and more. The transformer architecture has been a breakthrough in the field of natural language processing (NLP) and has been the basis for many state-of-the-art models in the field.\nWe start with a description of the transformer basics in Section 50.1. Section 50.2 provides a detailed description of the implementation of the transformer architecture. Finally, an example of a transformer implemented in PyTorch Lightning in presented in Section 50.3.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>HPT PyTorch Lightning Transformer: Introduction</span>"
    ]
  },
  {
    "objectID": "603_spot_lightning_transformer_introduction.html#sec-transformer-basics",
    "href": "603_spot_lightning_transformer_introduction.html#sec-transformer-basics",
    "title": "50  HPT PyTorch Lightning Transformer: Introduction",
    "section": "",
    "text": "50.1.1 Embedding\nWord embedding is a technique where words or phrases (so-called tokens) from the vocabulary are mapped to vectors of real numbers. These vectors capture the semantic properties of the words. Words that are similar in meaning are mapped to vectors that are close to each other in the vector space, and words that are dissimilar are mapped to vectors that are far apart. Word embeddings are needed for transformers for several reasons:\n\nDimensionality reduction: Word embeddings reduce the dimensionality of the data. Instead of dealing with high-dimensional sparse vectors (like one-hot encoded vectors), we deal with dense vectors of much lower dimensionality.\nCapturing semantic similarities: Word embeddings capture semantic similarities between words. This is crucial for tasks like text classification, sentiment analysis, etc., where the meaning of the words is important.\nHandling unknown words: If a word is not present in the training data but appears in the test data, one-hot encoding cannot handle it. But word embeddings can handle such situations by mapping the unknown word to a vector that is similar to known words.\nInput to neural networks: Transformers, like other neural networks, work with numerical data. Word embeddings provide a way to convert text data into numerical form that can be fed into these networks.\n\nIn the context of transformers, word embeddings are used as the initial input representation. The transformer then learns more complex representations by considering the context in which each token appears.\n\n50.1.1.1 Neural Network for Embeddings\nIdea for word embeddings: use a relatively simple NN that has one input for every token (word, symbol) in the vocabulary. The output of the NN is a vector of a fixed size, which is the word embedding. The network that is used in this chapter is visualized in Figure 50.1. For simplicity, a 2-dimensional output vector is used in this visualization. The weights of the NN are randomly initialized, and are learned during training.\n\n\n\n\n\n\nFigure 50.1: Transformer. Computation of the self attention. In this example, we consider two inputs, i.e., (1,0) and (0,1). For each input, there are two values, which results in a \\(2 \\times 2\\) matrix. In general, when there are \\(T\\) inputs, a \\(T \\times T\\) matrix will be generated. Figure credits: Starmer, Josh: Decoder-Only Transformers, ChatGPTs specific Transformer, Clearly Explained.\n\n\n\nAll tokens are embedded in this way. For each token there are two numerical values, the embedding vector. The same network is used for embedding all tokens. If a longer input is added, it can be embedded with the same net.\n\n\n50.1.1.2 Positional Encoding for the Embeddings\nPositional encoding is added to the input embeddings to give the model some information about the relative or absolute position of the tokens in the sequence. The positional encodings have the same dimension as the embeddings so that the two can be summed.\nIf a token occurs several times, it is embedded several times and receives different embedding vectors, as the position is taken into account by the positional encoding.\n\n\n\n50.1.2 Attention\nAttention describes how similar is each token to itself and to all other tokens in the input, e.g., in a sentence. The attention mechanism can be implemented as a set of layers in neural networks. There are a lot of different possible definitions of “attention” in the literature, but the one we will use here is the following: the attention mechanism describes a weighted average of (sequence) elements with the weights dynamically computed based on an input query and elements’ keys (Lippe 2022).\nThe goal is to take an average over the features of multiple elements. However, instead of weighting each element equally, we want to weight them depending on their actual values. In other words, we want to dynamically decide on which inputs we want to “attend” more than others.\nCalculation of the self-attention:\n\nQueries: Calculate two new values from the (two) values of the embedding vector using an NN, which are referred to as query values.\nKeys: Calculate two new values, called key values, from the (two) values of the embedding vector using an NN.\nDot product: Calculate the dot product of the query values and the key values. This is a measure of the similarity of the query and key values.\nSoftmax: Apply the softmax function to the outputs from the dot product. This is a measure of the attention that a token pays to other tokens.\nValues: Calculate two new values from the (two) values of the embedding vector using an NN, which are referred to as value values.\nThe values are multiplied (weighted) by the values of the softmax function.\nThe weighted values are summed. Now we have the self attention value for the token.\n\n\n\n50.1.3 Self-Attention\nMost attention mechanisms differ in terms of what queries they use, how the key and value vectors are defined, and what score function is used. The attention applied inside the Transformer architecture is called “self-attention”. In self-attention, each sequence element provides a key, value, and query. For each element, we perform an attention layer where based on its query, we check the similarity of the all sequence elements’ keys, and returned a different, averaged value vector for each element.\n\n\n50.1.4 Masked Self-Attention\nMasked self-attention is a variant of the self-attention method described in Section 50.1.3. It asks the question: How similar is each token to itself and to all preceding tokens in the input (sentence)? Masked self-attention is an autoregressive mechanism, which means that the attention mechanism is only allowed to look at the tokens that have already been processed. Calculation of the mask self-attention is identical to the self-attention, but the attention is only calculated for the tokens that have already been processed. If the masked self-attention method is applied to the first token, the masked self-attention value is exactly the value of the first token, as it only takes itself into account. For the other tokens, the masked self-attention value is a weighted sum of the values of the previous tokens. The weighting is determined by the similarity of the query values and the key values (dot product and softmax).\n\n\n50.1.5 Generation of Outputs\nTo calculate the output, we use a residual connector that adds the output of the neural network and the output of the masked self-attention method. We thus obtain the residual connection values. The residual connector is used to facilitate training.\nTo generate the next token, we use another neural network that calculates the output from the (two) residual connection values. The input layer of the neural network has the size of the residual connection values, the output layer has the number of tokens in the vocabulary as a dimension.\nIf we now enter the residual connection value of the first token, we receive the token (or the probabilities using Softmax) that is to come next as the output of the neural network. This makes sense even if we already know the second token (as with the first token): We can use it to calculate the error of the neural network and train the network. In addition, the decoder-transformer uses the masked self-attention method to calculate the output, i.e. the encoding and generation of new tokens is done with exactly the same elements of the network.\nNote: ChatGPT does not use a new neural network, but the same network that was already used to calculate the embedding. The network is therefore used for embedding, masked self-attention and calculating the output. In the last calculation, the network is inverted, i.e. it is run in the opposite direction to obtain the tokens and not the embeddings as in the original run.\n\n\n50.1.6 End-Of-Sequence-Token\nThe end-of-sequence token is used to signal the end of the input and also to start generating new tokens after the input. The EOS token recognizes all other tokens, as it comes after all tokens. When generating tokens, it is important to consider the relationships between the input tokens and the generation of new tokens.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>HPT PyTorch Lightning Transformer: Introduction</span>"
    ]
  },
  {
    "objectID": "603_spot_lightning_transformer_introduction.html#sec-details-implementation",
    "href": "603_spot_lightning_transformer_introduction.html#sec-details-implementation",
    "title": "50  HPT PyTorch Lightning Transformer: Introduction",
    "section": "50.2 Details of the Implementation",
    "text": "50.2 Details of the Implementation\nWe will now go into a bit more detail by first looking at the specific implementation of the attention mechanism which is in the Transformer case the (scaled) dot product attention. The variables shown in Table 50.1 are used in the Transformer architecture.\n\n\n\nTable 50.1: Variables used in the Transformer architecture.\n\n\n\n\n\n\n\n\n\n\nSymbol\nVariable\nDescription\n\n\n\n\n\\(Q\\)\nquery\nThe query vectors.\n\n\n\\(K\\)\nkey\nThe key vectors.\n\n\n\\(V\\)\nvalue\nThe value vectors.\n\n\n\\(d_{\\text{model}}\\)\nd_model\nThe dimensionality of the input and output features of the Transformer.\n\n\n\\(d_k\\)\nd_k\nThe hidden dimensionality of the key and query vectors.\n\n\n\\(d_v\\)\nd_v\nThe hidden dimensionality of the value vectors.\n\n\n\\(h\\)\nnum_heads\nThe number of heads in the Multi-Head Attention layer.\n\n\n\\(B\\)\nbatch_size\nThe batch size.\n\n\n\\(T\\)\nseq_length\nThe sequence length.\n\n\n\\(X\\)\nx\nThe input features (input elements in the sequence).\n\n\n\\(W^{Q}\\)\nqkv_proj\nThe weight matrix to transform the input to the query vectors.\n\n\n\\(W^{K}\\)\nqkv_proj\nThe weight matrix to transform the input to the key vectors.\n\n\n\\(W^{V}\\)\nqkv_proj\nThe weight matrix to transform the input to the value vectors.\n\n\n\\(W^{O}\\)\no_proj\nThe weight matrix to transform the concatenated output of the Multi-Head Attention layer to the final output.\n\n\n\\(N\\)\nnum_layers\nThe number of layers in the Transformer.\n\n\n\\(PE_{(pos,i)}\\)\npositional_encoding\nThe positional encoding for position \\(pos\\) and hidden dimensionality \\(i\\).\n\n\n\n\n\n\nSummarizing the ideas from Section 50.1, an attention mechanism has usually four parts we need to specify (Lippe 2022):\n\nQuery: The query is a feature vector that describes what we are looking for in the sequence, i.e., what would we maybe want to pay attention to.\nKeys: For each input element, we have a key which is again a feature vector. This feature vector roughly describes what the element is “offering”, or when it might be important. The keys should be designed such that we can identify the elements we want to pay attention to based on the query.\nScore function: To rate which elements we want to pay attention to, we need to specify a score function \\(f_{attn}\\). The score function takes the query and a key as input, and output the score/attention weight of the query-key pair. It is usually implemented by simple similarity metrics like a dot product, or a small MLP.\nValues: For each input element, we also have a value vector. This feature vector is the one we want to average over.\n\nThe weights of the average are calculated by a softmax over all score function outputs. Hence, we assign those value vectors a higher weight whose corresponding key is most similar to the query. If we try to describe it with pseudo-math, we can write:\n\\[\n\\alpha_i = \\frac{\\exp\\left(f_{attn}\\left(\\text{key}_i, \\text{query}\\right)\\right)}{\\sum_j \\exp\\left(f_{attn}\\left(\\text{key}_j, \\text{query}\\right)\\right)}, \\hspace{5mm} \\text{out} = \\sum_i \\alpha_i \\cdot \\text{value}_i\n\\]\nVisually, we can show the attention over a sequence of words as follows:\n\n\n\nAttention over a sequence of words. For every word, we have one key and one value vector. The query is compared to all keys with a score function (in this case the dot product) to determine the weights. The softmax is not visualized for simplicity. Finally, the value vectors of all words are averaged using the attention weights. Figure taken from Lippe (2022)\n\n\n\n50.2.1 Dot Product Attention\nOur goal is to have an attention mechanism with which any element in a sequence can attend to any other while still being efficient to compute. The dot product attention takes as input a set of queries \\(Q\\in\\mathbb{R}^{T\\times d_k}\\), keys \\(K\\in\\mathbb{R}^{T\\times d_k}\\) and values \\(V\\in\\mathbb{R}^{T\\times d_v}\\) where \\(T\\) is the sequence length, and \\(d_k\\) and \\(d_v\\) are the hidden dimensionality for queries/keys and values respectively. For simplicity, we neglect the batch dimension for now. The attention value from element \\(i\\) to \\(j\\) is based on its similarity of the query \\(Q_i\\) and key \\(K_j\\), using the dot product as the similarity metric (in Figure 50.1, we considered \\(Q_2\\) and \\(K_1\\) as well as \\(Q_2\\) and \\(K_2\\)). The dot product attention is calculated as follows:\n\\[\n\\text{Attention}(Q,K,V)=\\text{softmax}\\left(QK^T\\right) V\n\\tag{50.1}\\]\nThe matrix multiplication \\(QK^T\\) performs the dot product for every possible pair of queries and keys, resulting in a matrix of the shape \\(T\\times T\\). Each row represents the attention logits for a specific element \\(i\\) to all other elements in the sequence. On these, we apply a softmax and multiply with the value vector to obtain a weighted mean (the weights being determined by the attention).\n\n\n50.2.2 Scaled Dot Product Attention\nAn additional aspect is the scaling of the dot product using a scaling factor of \\(1/\\sqrt{d_k}\\). This scaling factor is crucial to maintain an appropriate variance of attention values after initialization. We initialize our layers with the intention of having equal variance throughout the model, and hence, \\(Q\\) and \\(K\\) might also have a variance close to \\(1\\). However, performing a dot product over two vectors with a variance \\(\\sigma^2\\) results in a scalar having \\(d_k\\)-times higher variance:\n\\[\nq_i \\sim \\mathcal{N}(0,\\sigma^2), k_i \\sim \\mathcal{N}(0,\\sigma^2) \\to \\text{Var}\\left(\\sum_{i=1}^{d_k} q_i\\cdot k_i\\right) = \\sigma^4\\cdot d_k\n\\]\nIf we do not scale down the variance back to \\(\\sim\\sigma^2\\), the softmax over the logits will already saturate to \\(1\\) for one random element and \\(0\\) for all others. The gradients through the softmax will be close to zero so that we can’t learn the parameters appropriately. Note that the extra factor of \\(\\sigma^2\\), i.e., having \\(\\sigma^4\\) instead of \\(\\sigma^2\\), is usually not an issue, since we keep the original variance \\(\\sigma^2\\) close to \\(1\\) anyways. Equation 50.1 can be modified as follows to calculate the dot product attention:\n\\[\n\\text{Attention}(Q,K,V)=\\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right) V.\n\\]\nAnother perspective on this scaled dot product attention mechanism offers the computation graph which is visualized in Figure 50.2.\n\n\n\n\n\n\nFigure 50.2: Scaled dot product attention. Figure credit Vaswani et al. (2017)\n\n\n\nThe block Mask (opt.) in the diagram above represents the optional masking of specific entries in the attention matrix. This is for instance used if we stack multiple sequences with different lengths into a batch. To still benefit from parallelization in PyTorch, we pad the sentences to the same length and mask out the padding tokens during the calculation of the attention values. This is usually done by setting the respective attention logits to a very low value.\nAfter we have discussed the details of the scaled dot product attention block, we can write a function below which computes the output features given the triple of queries, keys, and values:",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>HPT PyTorch Lightning Transformer: Introduction</span>"
    ]
  },
  {
    "objectID": "603_spot_lightning_transformer_introduction.html#sec-transformer-in-lightning",
    "href": "603_spot_lightning_transformer_introduction.html#sec-transformer-in-lightning",
    "title": "50  HPT PyTorch Lightning Transformer: Introduction",
    "section": "50.3 Example: Transformer in Lightning",
    "text": "50.3 Example: Transformer in Lightning\nThe following code is based on https://github.com/phlippe/uvadlc_notebooks/tree/master (Author: Phillip Lippe)\nFirst, we import the necessary libraries and download the pretrained models.\n\nimport os\nimport numpy as np\nimport random\nimport math\nimport json\nfrom functools import partial\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import to_rgb\nimport matplotlib\nimport seaborn as sns\n\n## tqdm for loading bars\nfrom tqdm.notebook import tqdm\n\n## PyTorch\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data as data\nimport torch.optim as optim\n\n# PyTorch Lightning\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n\n\n# Path to the folder where the pretrained models are saved\nCHECKPOINT_PATH = \"../saved_models/tutorial6\"\n\n# Ensure that all operations are deterministic on GPU (if used) for reproducibility\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\n\nfrom spotpython.utils.device import getDevice\ndevice = getDevice()\nprint(\"Device:\", device)\n\nDevice: mps\n\n\n\n# Setting the seed\npl.seed_everything(42)\n\n42\n\n\nTwo pre-trained models are downloaded below. Make sure to have adjusted your CHECKPOINT_PATH before running this code if not already done.\n\nimport urllib.request\nfrom urllib.error import HTTPError\n# Github URL where saved models are stored for this tutorial\nbase_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial6/\"\n# Files to download\npretrained_files = [\"ReverseTask.ckpt\", \"SetAnomalyTask.ckpt\"]\n\n# Create checkpoint path if it doesn't exist yet\nos.makedirs(CHECKPOINT_PATH, exist_ok=True)\n\n\n50.3.1 Downloading the Pretrained Models\n\n# For each file, check whether it already exists. If not, try downloading it.\nfor file_name in pretrained_files:\n    file_path = os.path.join(CHECKPOINT_PATH, file_name)\n    if \"/\" in file_name:\n        os.makedirs(file_path.rsplit(\"/\",1)[0], exist_ok=True)\n    if not os.path.isfile(file_path):\n        file_url = base_url + file_name\n        print(f\"Downloading {file_url}...\")\n        try:\n            urllib.request.urlretrieve(file_url, file_path)\n        except HTTPError as e:\n            print(\"Error:\\n\", e)\n\n\n\n50.3.2 The Transformer Architecture\nWe will implement the Transformer architecture by hand. As the architecture is so popular, there already exists a Pytorch module nn.Transformer (documentation) and a tutorial on how to use it for next token prediction. However, we will implement it here ourselves, to get through to the smallest details.\n\n\n50.3.3 Attention Mechanism\n\ndef scaled_dot_product(q, k, v, mask=None):\n    \"\"\"\n    Compute scaled dot product attention.\n    Args:\n        q: Queries\n        k: Keys\n        v: Values\n        mask: Mask to apply to the attention logits\n\n    Returns:\n        Tuple of (Values, Attention weights)\n\n    Examples:\n    &gt;&gt;&gt; seq_len, d_k = 1, 2\n        pl.seed_everything(42)\n        q = torch.randn(seq_len, d_k)\n        k = torch.randn(seq_len, d_k)\n        v = torch.randn(seq_len, d_k)\n        values, attention = scaled_dot_product(q, k, v)\n        print(\"Q\\n\", q)\n        print(\"K\\n\", k)\n        print(\"V\\n\", v)\n        print(\"Values\\n\", values)\n        print(\"Attention\\n\", attention)\n    \"\"\"\n    d_k = q.size()[-1]\n    attn_logits = torch.matmul(q, k.transpose(-2, -1))\n    attn_logits = attn_logits / math.sqrt(d_k)\n    if mask is not None:\n        attn_logits = attn_logits.masked_fill(mask == 0, -9e15)\n    attention = F.softmax(attn_logits, dim=-1)\n    values = torch.matmul(attention, v)\n    return values, attention\n\nNote that our code above supports any additional dimensionality in front of the sequence length so that we can also use it for batches. However, for a better understanding, let’s generate a few random queries, keys, and value vectors, and calculate the attention outputs:\n\nseq_len, d_k = 1, 2\npl.seed_everything(42)\nq = torch.randn(seq_len, d_k)\nk = torch.randn(seq_len, d_k)\nv = torch.randn(seq_len, d_k)\nvalues, attention = scaled_dot_product(q, k, v)\nprint(\"Q\\n\", q)\nprint(\"K\\n\", k)\nprint(\"V\\n\", v)\nprint(\"Values\\n\", values)\nprint(\"Attention\\n\", attention)\n\nQ\n tensor([[0.3367, 0.1288]])\nK\n tensor([[0.2345, 0.2303]])\nV\n tensor([[-1.1229, -0.1863]])\nValues\n tensor([[-1.1229, -0.1863]])\nAttention\n tensor([[1.]])\n\n\n\n\n50.3.4 Multi-Head Attention\nThe scaled dot product attention allows a network to attend over a sequence. However, often there are multiple different aspects a sequence element wants to attend to, and a single weighted average is not a good option for it. This is why we extend the attention mechanisms to multiple heads, i.e. multiple different query-key-value triplets on the same features. Specifically, given a query, key, and value matrix, we transform those into \\(h\\) sub-queries, sub-keys, and sub-values, which we pass through the scaled dot product attention independently. Afterward, we concatenate the heads and combine them with a final weight matrix. Mathematically, we can express this operation as:\n\\[\n\\begin{split}\n    \\text{Multihead}(Q,K,V) & = \\text{Concat}(\\text{head}_1,...,\\text{head}_h)W^{O}\\\\\n    \\text{where } \\text{head}_i & = \\text{Attention}(QW_i^Q,KW_i^K, VW_i^V)\n\\end{split}\n\\]\nWe refer to this as Multi-Head Attention layer with the learnable parameters \\(W_{1...h}^{Q}\\in\\mathbb{R}^{D\\times d_k}\\), \\(W_{1...h}^{K}\\in\\mathbb{R}^{D\\times d_k}\\), \\(W_{1...h}^{V}\\in\\mathbb{R}^{D\\times d_v}\\), and \\(W^{O}\\in\\mathbb{R}^{h\\cdot d_v\\times d_{out}}\\) (\\(D\\) being the input dimensionality). Expressed in a computational graph, we can visualize it as in Figure 50.3.\n\n\n\n\n\n\nFigure 50.3: Multi-Head Attention. Figure taken from Vaswani et al. (2017)\n\n\n\nHow are we applying a Multi-Head Attention layer in a neural network, where we do not have an arbitrary query, key, and value vector as input? Looking at the computation graph in Figure 50.3, a simple but effective implementation is to set the current feature map in a NN, \\(X\\in\\mathbb{R}^{B\\times T\\times d_{\\text{model}}}\\), as \\(Q\\), \\(K\\) and \\(V\\) (\\(B\\) being the batch size, \\(T\\) the sequence length, \\(d_{\\text{model}}\\) the hidden dimensionality of \\(X\\)). The consecutive weight matrices \\(W^{Q}\\), \\(W^{K}\\), and \\(W^{V}\\) can transform \\(X\\) to the corresponding feature vectors that represent the queries, keys, and values of the input. Using this approach, we can implement the Multi-Head Attention module below.\nAs a consequence, if the embedding dimension is 4, then 1, 2 or 4 heads can be used, but not 3. If 4 heads are used, then the dimension of the query, key and value vectors is 1. If 2 heads are used, then the dimension of the query, key and value vectors is \\(D=2\\). If 1 head is used, then the dimension of the query, key and value vectors is \\(D=4\\). The number of heads is a hyperparameter that can be adjusted. The number of heads is usually 8 or 16.\n\n# Helper function to support different mask shapes.\n# Output shape supports (batch_size, number of heads, seq length, seq length)\n# If 2D: broadcasted over batch size and number of heads\n# If 3D: broadcasted over number of heads\n# If 4D: leave as is\ndef expand_mask(mask):\n    assert mask.ndim &gt;= 2, \"Mask must be &gt;= 2-dim. with seq_length x seq_length\"\n    if mask.ndim == 3:\n        mask = mask.unsqueeze(1)\n    while mask.ndim &lt; 4:\n        mask = mask.unsqueeze(0)\n    return mask\n\n\nclass MultiheadAttention(nn.Module):\n    \n    def __init__(self, input_dim, embed_dim, num_heads):\n        super().__init__()\n        assert embed_dim % num_heads == 0, \"Embedding dim. must be 0 modulo number of heads.\"\n        \n        self.embed_dim = embed_dim\n        self.num_heads = num_heads\n        self.head_dim = embed_dim // num_heads\n        \n        # Stack all weight matrices 1...h together for efficiency\n        # Note that in many implementations you see \"bias=False\" which is optional\n        self.qkv_proj = nn.Linear(input_dim, 3*embed_dim)\n        self.o_proj = nn.Linear(embed_dim, embed_dim)\n        \n        self._reset_parameters()\n\n    def _reset_parameters(self):\n        # Original Transformer initialization, see PyTorch documentation\n        nn.init.xavier_uniform_(self.qkv_proj.weight)\n        self.qkv_proj.bias.data.fill_(0)\n        nn.init.xavier_uniform_(self.o_proj.weight)\n        self.o_proj.bias.data.fill_(0)\n\n    def forward(self, x, mask=None, return_attention=False):\n        batch_size, seq_length, _ = x.size()\n        if mask is not None:\n            mask = expand_mask(mask)\n        qkv = self.qkv_proj(x)\n        \n        # Separate Q, K, V from linear output\n        qkv = qkv.reshape(batch_size, seq_length, self.num_heads, 3*self.head_dim)\n        qkv = qkv.permute(0, 2, 1, 3) # [Batch, Head, SeqLen, Dims]\n        q, k, v = qkv.chunk(3, dim=-1)\n        \n        # Determine value outputs\n        values, attention = scaled_dot_product(q, k, v, mask=mask)\n        values = values.permute(0, 2, 1, 3) # [Batch, SeqLen, Head, Dims]\n        values = values.reshape(batch_size, seq_length, self.embed_dim)\n        o = self.o_proj(values)\n        \n        if return_attention:\n            return o, attention\n        else:\n            return o\n\n\n\n50.3.5 Permutation Equivariance\nOne crucial characteristic of the multi-head attention is that it is permutation-equivariant with respect to its inputs. This means that if we switch two input elements in the sequence, e.g. \\(X_1\\leftrightarrow X_2\\) (neglecting the batch dimension for now), the output is exactly the same besides the elements 1 and 2 switched. Hence, the multi-head attention is actually looking at the input not as a sequence, but as a set of elements. This property makes the multi-head attention block and the Transformer architecture so powerful and widely applicable! But what if the order of the input is actually important for solving the task, like language modeling? The answer is to encode the position in the input features, which we will take a closer look in Section 50.3.8.\n\n\n50.3.6 Transformer Encoder\nNext, we will look at how to apply the multi-head attention block inside the Transformer architecture. Originally, the Transformer model was designed for machine translation. Hence, it got an encoder-decoder structure where the encoder takes as input the sentence in the original language and generates an attention-based representation. On the other hand, the decoder attends over the encoded information and generates the translated sentence in an autoregressive manner, as in a standard RNN. While this structure is extremely useful for Sequence-to-Sequence tasks with the necessity of autoregressive decoding, we will focus here on the encoder part. Many advances in NLP have been made using pure encoder-based Transformer models (if interested, models include the BERT-family (Devlin et al. 2018), the Vision Transformer (Dosovitskiy et al. 2020), and more). We will also mainly focus on the encoder part. If you have understood the encoder architecture, the decoder is a very small step to implement as well. The full Transformer architecture looks as shown in Figure 50.4.\n\n\n\n\n\n\nFigure 50.4: Transformer architecture. Figure credit: Vaswani et al. (2017)\n\n\n\nThe encoder consists of \\(N\\) identical blocks that are applied in sequence. Taking as input \\(x\\), it is first passed through a Multi-Head Attention block as we have implemented above. The output is added to the original input using a residual connection, and we apply a consecutive Layer Normalization on the sum. Overall, it calculates \\[\n\\text{LayerNorm}(x+\\text{Multihead}(x,x,x))\n\\] (\\(x\\) being \\(Q\\), \\(K\\) and \\(V\\) input to the attention layer). The residual connection is crucial in the Transformer architecture for two reasons:\n\nSimilar to ResNets, Transformers are designed to be very deep. Some models contain more than 24 blocks in the encoder. Hence, the residual connections are crucial for enabling a smooth gradient flow through the model.\nWithout the residual connection, the information about the original sequence is lost. Remember that the Multi-Head Attention layer ignores the position of elements in a sequence, and can only learn it based on the input features. Removing the residual connections would mean that this information is lost after the first attention layer (after initialization), and with a randomly initialized query and key vector, the output vectors for position \\(i\\) has no relation to its original input. All outputs of the attention are likely to represent similar/same information, and there is no chance for the model to distinguish which information came from which input element. An alternative option to residual connection would be to fix at least one head to focus on its original input, but this is very inefficient and does not have the benefit of the improved gradient flow.\n\n\n\n50.3.7 Layer Normalization and Feed-Forward Network\nThe Layer Normalization also plays an important role in the Transformer architecture as it enables faster training and provides small regularization. Additionally, it ensures that the features are in a similar magnitude among the elements in the sequence.\nWe are not using Batch Normalization because it depends on the batch size which is often small with Transformers (they require a lot of GPU memory), and BatchNorm has shown to perform particularly bad in language as the features of words tend to have a much higher variance (there are many, very rare words which need to be considered for a good distribution estimate).\nAdditionally to the Multi-Head Attention, a small fully connected feed-forward network is added to the model, which is applied to each position separately and identically. Specifically, the model uses a Linear\\(\\to\\)ReLU\\(\\to\\)Linear MLP. The full transformation including the residual connection can be expressed as:\n\\[\n\\begin{split}\n    \\text{FFN}(x) & = \\max(0, xW_1+b_1)W_2 + b_2\\\\\n    x & = \\text{LayerNorm}(x + \\text{FFN}(x))\n\\end{split}\n\\]\nThis MLP adds extra complexity to the model and allows transformations on each sequence element separately. You can imagine as this allows the model to “post-process” the new information added by the previous Multi-Head Attention, and prepare it for the next attention block. Usually, the inner dimensionality of the MLP is 2-8\\(\\times\\) larger than \\(d_{\\text{model}}\\), i.e. the dimensionality of the original input \\(x\\). The general advantage of a wider layer instead of a narrow, multi-layer MLP is the faster, parallelizable execution.\nFinally, after looking at all parts of the encoder architecture, we can start implementing it below. We first start by implementing a single encoder block. Additionally to the layers described above, we will add dropout layers in the MLP and on the output of the MLP and Multi-Head Attention for regularization.\n\nclass EncoderBlock(nn.Module):\n    \n    def __init__(self, input_dim, num_heads, dim_feedforward, dropout=0.0):\n        \"\"\"\n        Inputs:\n            input_dim - Dimensionality of the input\n            num_heads - Number of heads to use in the attention block\n            dim_feedforward - Dimensionality of the hidden layer in the MLP\n            dropout - Dropout probability to use in the dropout layers\n        \"\"\"\n        super().__init__()\n        \n        # Attention layer\n        self.self_attn = MultiheadAttention(input_dim, input_dim, num_heads)\n        \n        # Two-layer MLP\n        self.linear_net = nn.Sequential(\n            nn.Linear(input_dim, dim_feedforward),\n            nn.Dropout(dropout),\n            nn.ReLU(inplace=True),\n            nn.Linear(dim_feedforward, input_dim)\n        )\n        \n        # Layers to apply in between the main layers\n        self.norm1 = nn.LayerNorm(input_dim)\n        self.norm2 = nn.LayerNorm(input_dim)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x, mask=None):\n        # Attention part\n        attn_out = self.self_attn(x, mask=mask)\n        x = x + self.dropout(attn_out)\n        x = self.norm1(x)\n        \n        # MLP part\n        linear_out = self.linear_net(x)\n        x = x + self.dropout(linear_out)\n        x = self.norm2(x)\n        \n        return x\n\nBased on this block, we can implement a module for the full Transformer encoder. Additionally to a forward function that iterates through the sequence of encoder blocks, we also provide a function called get_attention_maps. The idea of this function is to return the attention probabilities for all Multi-Head Attention blocks in the encoder. This helps us in understanding, and in a sense, explaining the model. However, the attention probabilities should be interpreted with a grain of salt as it does not necessarily reflect the true interpretation of the model (there is a series of papers about this, including Jain and Wallace (2019) and Wiegreffe and Pinter (2019)).\n\nclass TransformerEncoder(nn.Module):\n    \n    def __init__(self, num_layers, **block_args):\n        super().__init__()\n        self.layers = nn.ModuleList(\n            [EncoderBlock(**block_args) for _ in range(num_layers)])\n\n    def forward(self, x, mask=None):\n        for l in self.layers:\n            x = l(x, mask=mask)\n        return x\n\n    def get_attention_maps(self, x, mask=None):\n        attention_maps = []\n        for l in self.layers:\n            _, attn_map = l.self_attn(x, mask=mask, return_attention=True)\n            attention_maps.append(attn_map)\n            x = l(x)\n        return attention_maps\n\n\n\n50.3.8 Positional Encoding\nWe have discussed before that the Multi-Head Attention block is permutation-equivariant, and cannot distinguish whether an input comes before another one in the sequence or not. In tasks like language understanding, however, the position is important for interpreting the input words. The position information can therefore be added via the input features. We could learn a embedding for every possible position, but this would not generalize to a dynamical input sequence length. Hence, the better option is to use feature patterns that the network can identify from the features and potentially generalize to larger sequences. The specific pattern chosen by Vaswani et al. (2017) are sine and cosine functions of different frequencies, as follows:\n\\[\nPE_{(pos,i)} = \\begin{cases}\n    \\sin\\left(\\frac{pos}{10000^{i/d_{\\text{model}}}}\\right) & \\text{if}\\hspace{3mm} i \\text{ mod } 2=0\\\\\n    \\cos\\left(\\frac{pos}{10000^{(i-1)/d_{\\text{model}}}}\\right) & \\text{otherwise}\\\\\n\\end{cases}\n\\]\n\\(PE_{(pos,i)}\\) represents the position encoding at position \\(pos\\) in the sequence, and hidden dimensionality \\(i\\). These values, concatenated for all hidden dimensions, are added to the original input features (in the Transformer visualization above, see “Positional encoding”), and constitute the position information. We distinguish between even (\\(i \\text{ mod } 2=0\\)) and uneven (\\(i \\text{ mod } 2=1\\)) hidden dimensionalities where we apply a sine/cosine respectively. The intuition behind this encoding is that you can represent \\(PE_{(pos+k,:)}\\) as a linear function of \\(PE_{(pos,:)}\\), which might allow the model to easily attend to relative positions. The wavelengths in different dimensions range from \\(2\\pi\\) to \\(10000\\cdot 2\\pi\\).\nThe positional encoding is implemented below. The code is taken from the PyTorch tutorial https://pytorch.org/tutorials/beginner/transformer_tutorial.html#define-the-model about Transformers on NLP and adjusted for our purposes.\n\nclass PositionalEncoding(nn.Module):\n\n    def __init__(self, d_model, max_len=5000):\n        \"\"\"\n        Inputs\n            d_model - Hidden dimensionality of the input.\n            max_len - Maximum length of a sequence to expect.\n        \"\"\"\n        super().__init__()\n\n        # Create matrix of [SeqLen, HiddenDim] representing \n        # the positional encoding for max_len inputs\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0)\n        \n        # register_buffer =&gt; Tensor which is not a parameter,\n        # but should be part of the modules state.\n        # Used for tensors that need to be on the same device as the module.\n        # persistent=False tells PyTorch to not add the buffer to the \n        # state dict (e.g. when we save the model) \n        self.register_buffer('pe', pe, persistent=False)\n\n    def forward(self, x):\n        x = x + self.pe[:, :x.size(1)]\n        return x\n\nTo understand the positional encoding, we can visualize it below. We will generate an image of the positional encoding over hidden dimensionality and position in a sequence. Each pixel, therefore, represents the change of the input feature we perform to encode the specific position. Let’s do it below.\n\nmatplotlib.rcParams['lines.linewidth'] = 2.0\nplt.set_cmap('cividis')\nencod_block = PositionalEncoding(d_model=48, max_len=96)\npe = encod_block.pe.squeeze().T.cpu().numpy()\n\nfig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8,3))\npos = ax.imshow(pe, cmap=\"RdGy\", extent=(1,pe.shape[1]+1,pe.shape[0]+1,1))\nfig.colorbar(pos, ax=ax)\nax.set_xlabel(\"Position in sequence\")\nax.set_ylabel(\"Hidden dimension\")\nax.set_title(\"Positional encoding over hidden dimensions\")\nax.set_xticks([1]+[i*10 for i in range(1,1+pe.shape[1]//10)])\nax.set_yticks([1]+[i*10 for i in range(1,1+pe.shape[0]//10)])\nplt.show()\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\nYou can clearly see the sine and cosine waves with different wavelengths that encode the position in the hidden dimensions. Specifically, we can look at the sine/cosine wave for each hidden dimension separately, to get a better intuition of the pattern. Below we visualize the positional encoding for the hidden dimensions \\(1\\), \\(2\\), \\(3\\) and \\(4\\).\n\nsns.set_theme()\nfig, ax = plt.subplots(2, 2, figsize=(12,4))\nax = [a for a_list in ax for a in a_list]\nfor i in range(len(ax)):\n    ax[i].plot(np.arange(1,17), pe[i,:16], color=f'C{i}', marker=\"o\",\n                markersize=6, markeredgecolor=\"black\")\n    ax[i].set_title(f\"Encoding in hidden dimension {i+1}\")\n    ax[i].set_xlabel(\"Position in sequence\", fontsize=10)\n    ax[i].set_ylabel(\"Positional encoding\", fontsize=10)\n    ax[i].set_xticks(np.arange(1,17))\n    ax[i].tick_params(axis='both', which='major', labelsize=10)\n    ax[i].tick_params(axis='both', which='minor', labelsize=8)\n    ax[i].set_ylim(-1.2, 1.2)\nfig.subplots_adjust(hspace=0.8)\nsns.reset_orig()\nplt.show()\n\n\n\n\n\n\n\n\nAs we can see, the patterns between the hidden dimension \\(1\\) and \\(2\\) only differ in the starting angle. The wavelength is \\(2\\pi\\), hence the repetition after position \\(6\\). The hidden dimensions \\(2\\) and \\(3\\) have about twice the wavelength.\n\n\n50.3.9 Learning Rate Warm-up\nOne commonly used technique for training a Transformer is learning rate warm-up. This means that we gradually increase the learning rate from 0 on to our originally specified learning rate in the first few iterations. Thus, we slowly start learning instead of taking very large steps from the beginning. In fact, training a deep Transformer without learning rate warm-up can make the model diverge and achieve a much worse performance on training and testing. Take for instance the following plot by Liu et al. (2019) comparing Adam-vanilla (i.e. Adam without warm-up) vs Adam with a warm-up:\n\n\n\nWarm-up comparison. Figure taken from Liu et al. (2019)\n\n\nClearly, the warm-up is a crucial hyperparameter in the Transformer architecture. Why is it so important? There are currently two common explanations. Firstly, Adam uses the bias correction factors which however can lead to a higher variance in the adaptive learning rate during the first iterations. Improved optimizers like RAdam have been shown to overcome this issue, not requiring warm-up for training Transformers. Secondly, the iteratively applied Layer Normalization across layers can lead to very high gradients during the first iterations, which can be solved by using Pre-Layer Normalization (similar to Pre-Activation ResNet), or replacing Layer Normalization by other techniques (Adaptive Normalization, Power Normalization).\nNevertheless, many applications and papers still use the original Transformer architecture with Adam, because warm-up is a simple, yet effective way of solving the gradient problem in the first iterations. There are many different schedulers we could use. For instance, the original Transformer paper used an exponential decay scheduler with a warm-up. However, the currently most popular scheduler is the cosine warm-up scheduler, which combines warm-up with a cosine-shaped learning rate decay. We can implement it below, and visualize the learning rate factor over epochs.\n\nclass CosineWarmupScheduler(optim.lr_scheduler._LRScheduler):\n    \n    def __init__(self, optimizer, warmup, max_iters):\n        self.warmup = warmup\n        self.max_num_iters = max_iters\n        super().__init__(optimizer)\n        \n    def get_lr(self):\n        lr_factor = self.get_lr_factor(epoch=self.last_epoch)\n        return [base_lr * lr_factor for base_lr in self.base_lrs]\n    \n    def get_lr_factor(self, epoch):\n        lr_factor = 0.5 * (1 + np.cos(np.pi * epoch / self.max_num_iters))\n        if epoch &lt;= self.warmup:\n            lr_factor *= epoch * 1.0 / self.warmup\n        return lr_factor\n\n\n# Needed for initializing the lr scheduler\np = nn.Parameter(torch.empty(4,4))\noptimizer = optim.Adam([p], lr=1e-3)\nlr_scheduler = CosineWarmupScheduler(optimizer=optimizer, warmup=100, max_iters=2000)\n\n# Plotting\nepochs = list(range(2000))\nsns.set()\nplt.figure(figsize=(8,3))\nplt.plot(epochs, [lr_scheduler.get_lr_factor(e) for e in epochs])\nplt.ylabel(\"Learning rate factor\")\nplt.xlabel(\"Iterations (in batches)\")\nplt.title(\"Cosine Warm-up Learning Rate Scheduler\")\nplt.show()\nsns.reset_orig()\n\n\n\n\n\n\n\n\nIn the first 100 iterations, we increase the learning rate factor from 0 to 1, whereas for all later iterations, we decay it using the cosine wave. Pre-implementations of this scheduler can be found in the popular NLP Transformer library huggingface.\n\n\n50.3.10 PyTorch Lightning Module\nFinally, we can embed the Transformer architecture into a PyTorch lightning module. PyTorch Lightning simplifies our training and test code, as well as structures the code nicely in separate functions. We will implement a template for a classifier based on the Transformer encoder. Thereby, we have a prediction output per sequence element. If we would need a classifier over the whole sequence, the common approach is to add an additional [CLS] token to the sequence (CLS stands for classification, i.e., the first token of every sequence is always a special classification token, CLS). However, here we focus on tasks where we have an output per element.\nAdditionally to the Transformer architecture, we add a small input network (maps input dimensions to model dimensions), the positional encoding, and an output network (transforms output encodings to predictions). We also add the learning rate scheduler, which takes a step each iteration instead of once per epoch. This is needed for the warmup and the smooth cosine decay. The training, validation, and test step is left empty for now and will be filled for our task-specific models.\n\nclass TransformerPredictor(pl.LightningModule):\n\n    def __init__(self, input_dim, model_dim, num_classes, num_heads, num_layers, lr, warmup, max_iters, dropout=0.0, input_dropout=0.0):\n        \"\"\"\n        Inputs:\n            input_dim - Hidden dimensionality of the input\n            model_dim - Hidden dimensionality to use inside the Transformer\n            num_classes - Number of classes to predict per sequence element\n            num_heads - Number of heads to use in the Multi-Head Attention blocks\n            num_layers - Number of encoder blocks to use.\n            lr - Learning rate in the optimizer\n            warmup - Number of warmup steps. Usually between 50 and 500\n            max_iters - Number of maximum iterations the model is trained for. This is needed for the CosineWarmup scheduler\n            dropout - Dropout to apply inside the model\n            input_dropout - Dropout to apply on the input features\n        \"\"\"\n        super().__init__()\n        self.save_hyperparameters()\n        self._create_model()\n\n    def _create_model(self):\n        # Input dim -&gt; Model dim\n        self.input_net = nn.Sequential(\n            nn.Dropout(self.hparams.input_dropout),\n            nn.Linear(self.hparams.input_dim, self.hparams.model_dim)\n        )\n        # Positional encoding for sequences\n        self.positional_encoding = PositionalEncoding(d_model=self.hparams.model_dim)\n        # Transformer\n        self.transformer = TransformerEncoder(num_layers=self.hparams.num_layers,\n                                              input_dim=self.hparams.model_dim,\n                                              dim_feedforward=2*self.hparams.model_dim,\n                                              num_heads=self.hparams.num_heads,\n                                              dropout=self.hparams.dropout)\n        # Output classifier per sequence lement\n        self.output_net = nn.Sequential(\n            nn.Linear(self.hparams.model_dim, self.hparams.model_dim),\n            nn.LayerNorm(self.hparams.model_dim),\n            nn.ReLU(inplace=True),\n            nn.Dropout(self.hparams.dropout),\n            nn.Linear(self.hparams.model_dim, self.hparams.num_classes)\n        ) \n\n    def forward(self, x, mask=None, add_positional_encoding=True):\n        \"\"\"\n        Inputs:\n            x - Input features of shape [Batch, SeqLen, input_dim]\n            mask - Mask to apply on the attention outputs (optional)\n            add_positional_encoding - If True, we add the positional encoding to the input.\n                                      Might not be desired for some tasks.\n        \"\"\"\n        x = self.input_net(x)\n        if add_positional_encoding:\n            x = self.positional_encoding(x)\n        x = self.transformer(x, mask=mask)\n        x = self.output_net(x)\n        return x\n\n    @torch.no_grad()\n    def get_attention_maps(self, x, mask=None, add_positional_encoding=True):\n        \"\"\"\n        Function for extracting the attention matrices of the whole Transformer for a single batch.\n        Input arguments same as the forward pass.\n        \"\"\"\n        x = self.input_net(x)\n        if add_positional_encoding:\n            x = self.positional_encoding(x)\n        attention_maps = self.transformer.get_attention_maps(x, mask=mask)\n        return attention_maps\n\n    def configure_optimizers(self):\n        optimizer = optim.Adam(self.parameters(), lr=self.hparams.lr)\n        \n        # Apply lr scheduler per step\n        lr_scheduler = CosineWarmupScheduler(optimizer, \n                                             warmup=self.hparams.warmup, \n                                             max_iters=self.hparams.max_iters)\n        return [optimizer], [{'scheduler': lr_scheduler, 'interval': 'step'}]\n\n    def training_step(self, batch, batch_idx):\n        raise NotImplementedError\n\n    def validation_step(self, batch, batch_idx):\n        raise NotImplementedError    \n\n    def test_step(self, batch, batch_idx):\n        raise NotImplementedError",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>HPT PyTorch Lightning Transformer: Introduction</span>"
    ]
  },
  {
    "objectID": "603_spot_lightning_transformer_introduction.html#experiment-sequence-to-sequence",
    "href": "603_spot_lightning_transformer_introduction.html#experiment-sequence-to-sequence",
    "title": "50  HPT PyTorch Lightning Transformer: Introduction",
    "section": "50.4 Experiment: Sequence to Sequence",
    "text": "50.4 Experiment: Sequence to Sequence\nAfter having finished the implementation of the Transformer architecture, we can start experimenting and apply it to various tasks. We will focus on parallel Sequence-to-Sequence.\nA Sequence-to-Sequence task represents a task where the input and the output is a sequence, not necessarily of the same length. Popular tasks in this domain include machine translation and summarization. For this, we usually have a Transformer encoder for interpreting the input sequence, and a decoder for generating the output in an autoregressive manner. Here, however, we will go back to a much simpler example task and use only the encoder. Given a sequence of \\(N\\) numbers between \\(0\\) and \\(M\\), the task is to reverse the input sequence. In Numpy notation, if our input is \\(x\\), the output should be \\(x\\)[::-1]. Although this task sounds very simple, RNNs can have issues with such because the task requires long-term dependencies. Transformers are built to support such, and hence, we expect it to perform very well.\n\n50.4.1 Dataset and Data Loaders\nFirst, let’s create a dataset class below.\n\nclass ReverseDataset(data.Dataset):\n\n    def __init__(self, num_categories, seq_len, size):\n        super().__init__()\n        self.num_categories = num_categories\n        self.seq_len = seq_len\n        self.size = size\n        \n        self.data = torch.randint(self.num_categories, size=(self.size, self.seq_len))\n  \n    def __len__(self):\n        return self.size\n\n    def __getitem__(self, idx):\n        inp_data = self.data[idx]\n        labels = torch.flip(inp_data, dims=(0,))\n        return inp_data, labels\n\nWe create an arbitrary number of random sequences of numbers between 0 and num_categories-1. The label is simply the tensor flipped over the sequence dimension. We can create the corresponding data loaders below.\n\ndataset = partial(ReverseDataset, 10, 16)\ntrain_loader = data.DataLoader(dataset(50000),\n                                batch_size=128,\n                                shuffle=True,\n                                drop_last=True,\n                                pin_memory=True)\nval_loader   = data.DataLoader(dataset(1000), batch_size=128)\ntest_loader  = data.DataLoader(dataset(10000), batch_size=128)\n\n\ninp_data, labels = train_loader.dataset[0]\nprint(\"Input data:\", inp_data)\nprint(\"Labels:    \", labels)\n\nInput data: tensor([0, 4, 1, 2, 5, 5, 7, 6, 9, 6, 3, 1, 9, 3, 1, 9])\nLabels:     tensor([9, 1, 3, 9, 1, 3, 6, 9, 6, 7, 5, 5, 2, 1, 4, 0])\n\n\nDuring training, we pass the input sequence through the Transformer encoder and predict the output for each input token. We use the standard Cross-Entropy loss to perform this. Every number is represented as a one-hot vector. Remember that representing the categories as single scalars decreases the expressiveness of the model extremely as \\(0\\) and \\(1\\) are not closer related than \\(0\\) and \\(9\\) in our example. An alternative to a one-hot vector is using a learned embedding vector as it is provided by the PyTorch module nn.Embedding. However, using a one-hot vector with an additional linear layer as in our case has the same effect as an embedding layer (self.input_net maps one-hot vector to a dense vector, where each row of the weight matrix represents the embedding for a specific category).\n\n\n50.4.2 The Reverse Predictor Class\nTo implement the training dynamic, we create a new class inheriting from TransformerPredictor and overwriting the training, validation and test step functions, which were left empty in the base class. We also add a _calculate_loss function to calculate the loss and accuracy for a batch.\n\nclass ReversePredictor(TransformerPredictor):\n    \n    def _calculate_loss(self, batch, mode=\"train\"):\n        # Fetch data and transform categories to one-hot vectors\n        inp_data, labels = batch\n        inp_data = F.one_hot(inp_data, num_classes=self.hparams.num_classes).float()\n        \n        # Perform prediction and calculate loss and accuracy\n        preds = self.forward(inp_data, add_positional_encoding=True)\n        loss = F.cross_entropy(preds.view(-1,preds.size(-1)), labels.view(-1))\n        acc = (preds.argmax(dim=-1) == labels).float().mean()\n        \n        # Logging\n        self.log(f\"{mode}_loss\", loss)\n        self.log(f\"{mode}_acc\", acc)\n        return loss, acc\n        \n    def training_step(self, batch, batch_idx):\n        loss, _ = self._calculate_loss(batch, mode=\"train\")\n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        _ = self._calculate_loss(batch, mode=\"val\")\n    \n    def test_step(self, batch, batch_idx):\n        _ = self._calculate_loss(batch, mode=\"test\")\n\nFinally, we can create a training function. We create a pl.Trainer object, running for \\(N\\) epochs, logging in TensorBoard, and saving our best model based on the validation. Afterward, we test our models on the test set.\n\n\n50.4.3 Gradient Clipping\nAn additional parameter we pass to the trainer here is gradient_clip_val. This clips the norm of the gradients for all parameters before taking an optimizer step and prevents the model from diverging if we obtain very high gradients at, for instance, sharp loss surfaces (see many good blog posts on gradient clipping, like DeepAI glossary). For Transformers, gradient clipping can help to further stabilize the training during the first few iterations, and also afterward. In plain PyTorch, you can apply gradient clipping via torch.nn.utils.clip_grad_norm_(...) (see documentation). The clip value is usually between 0.5 and 10, depending on how harsh you want to clip large gradients.\n\n\n50.4.4 Implementation of the Lightning Trainer\nThe Lightning trainer can be implemented as follows:\n\ndef train_reverse(**kwargs):\n    # Create a PyTorch Lightning trainer with the generation callback\n    root_dir = os.path.join(CHECKPOINT_PATH, \"ReverseTask\")\n    os.makedirs(root_dir, exist_ok=True)\n    trainer = pl.Trainer(default_root_dir=root_dir, \n                         callbacks=[ModelCheckpoint(save_weights_only=True,\n                                    mode=\"max\", monitor=\"val_acc\")],\n                         accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n                         devices=1,\n                         max_epochs=10,\n                         gradient_clip_val=5)\n    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n    \n    # Check whether pretrained model exists. If yes, load it and skip training\n    pretrained_filename = os.path.join(CHECKPOINT_PATH, \"ReverseTask.ckpt\")\n    if os.path.isfile(pretrained_filename):\n        print(\"Found pretrained model, loading...\")\n        model = ReversePredictor.load_from_checkpoint(pretrained_filename)\n    else:\n        model = ReversePredictor(max_iters=trainer.max_epochs*len(train_loader), **kwargs)\n        trainer.fit(model, train_loader, val_loader)\n        \n    # Test best model on validation and test set\n    val_result = trainer.test(model, val_loader, verbose=False)\n    test_result = trainer.test(model, test_loader, verbose=False)\n    result = {\"test_acc\": test_result[0][\"test_acc\"], \"val_acc\": val_result[0][\"test_acc\"]}\n    \n    model = model.to(device)\n    return model, result\n\n\n\n50.4.5 Training the Model\nFinally, we can train the model. In this setup, we will use a single encoder block and a single head in the Multi-Head Attention. This is chosen because of the simplicity of the task, and in this case, the attention can actually be interpreted as an “explanation” of the predictions (compared to the other papers above dealing with deep Transformers).\n\nreverse_model, reverse_result = train_reverse(input_dim=train_loader.dataset.num_categories,\n                                              model_dim=32,\n                                              num_heads=1,\n                                              num_classes=train_loader.dataset.num_categories,\n                                              num_layers=1,\n                                              dropout=0.0,\n                                              lr=5e-4,\n                                              warmup=50)\n\nFound pretrained model, loading...\n\n\n\n\n\n\n\n\nThe warning of PyTorch Lightning regarding the number of workers can be ignored for now. As the data set is so simple and the __getitem__ finishes a neglectable time, we don’t need subprocesses to provide us the data (in fact, more workers can slow down the training as we have communication overhead among processes/threads). First, let’s print the results:\n\nprint(f\"Val accuracy:  {(100.0 * reverse_result['val_acc']):4.2f}%\")\nprint(f\"Test accuracy: {(100.0 * reverse_result['test_acc']):4.2f}%\")\n\nVal accuracy:  100.00%\nTest accuracy: 100.00%\n\n\nAs we would have expected, the Transformer can correctly solve the task.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>HPT PyTorch Lightning Transformer: Introduction</span>"
    ]
  },
  {
    "objectID": "603_spot_lightning_transformer_introduction.html#visualizing-attention-maps",
    "href": "603_spot_lightning_transformer_introduction.html#visualizing-attention-maps",
    "title": "50  HPT PyTorch Lightning Transformer: Introduction",
    "section": "50.5 Visualizing Attention Maps",
    "text": "50.5 Visualizing Attention Maps\nHow does the attention in the Multi-Head Attention block looks like for an arbitrary input? Let’s try to visualize it below.\n\ndata_input, labels = next(iter(val_loader))\ninp_data = F.one_hot(data_input, num_classes=reverse_model.hparams.num_classes).float()\ninp_data = inp_data.to(device)\nattention_maps = reverse_model.get_attention_maps(inp_data)\n\nThe object attention_maps is a list of length \\(N\\) where \\(N\\) is the number of layers. Each element is a tensor of shape [Batch, Heads, SeqLen, SeqLen], which we can verify below.\n\nattention_maps[0].shape\n\ntorch.Size([128, 1, 16, 16])\n\n\nNext, we will write a plotting function that takes as input the sequences, attention maps, and an index indicating for which batch element we want to visualize the attention map. We will create a plot where over rows, we have different layers, while over columns, we show the different heads. Remember that the softmax has been applied for each row separately.\n\ndef plot_attention_maps(input_data, attn_maps, idx=0):\n    if input_data is not None:\n        input_data = input_data[idx].detach().cpu().numpy()\n    else:\n        input_data = np.arange(attn_maps[0][idx].shape[-1])\n    attn_maps = [m[idx].detach().cpu().numpy() for m in attn_maps]\n    \n    num_heads = attn_maps[0].shape[0]\n    num_layers = len(attn_maps)\n    seq_len = input_data.shape[0]\n    fig_size = 4 if num_heads == 1 else 3\n    fig, ax = plt.subplots(num_layers, num_heads, figsize=(num_heads*fig_size, num_layers*fig_size))\n    if num_layers == 1:\n        ax = [ax]\n    if num_heads == 1:\n        ax = [[a] for a in ax]\n    for row in range(num_layers):\n        for column in range(num_heads):\n            ax[row][column].imshow(attn_maps[row][column], origin='lower', vmin=0)\n            ax[row][column].set_xticks(list(range(seq_len)))\n            ax[row][column].set_xticklabels(input_data.tolist())\n            ax[row][column].set_yticks(list(range(seq_len)))\n            ax[row][column].set_yticklabels(input_data.tolist())\n            ax[row][column].set_title(f\"Layer {row+1}, Head {column+1}\")\n    fig.subplots_adjust(hspace=0.5)\n    cax = fig.add_axes([0.95, 0.15, 0.01, 0.7])\n    cbar = fig.colorbar(ax[0][0].imshow(attn_maps[0][0], origin='lower', vmin=0), cax=cax)\n    cbar.set_label('Attention')\n    plt.show()\n\nFinally, we can plot the attention map of our trained Transformer on the reverse task:\n\nplot_attention_maps(data_input, attention_maps, idx=0)\n\n\n\n\n\n\n\n\nThe model has learned to attend to the token that is on the flipped index of itself. Hence, it actually does what we intended it to do. We see that it however also pays some attention to values close to the flipped index. This is because the model doesn’t need the perfect, hard attention to solve this problem, but is fine with this approximate, noisy attention map. The close-by indices are caused by the similarity of the positional encoding, which we also intended with the positional encoding.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>HPT PyTorch Lightning Transformer: Introduction</span>"
    ]
  },
  {
    "objectID": "603_spot_lightning_transformer_introduction.html#conclusion",
    "href": "603_spot_lightning_transformer_introduction.html#conclusion",
    "title": "50  HPT PyTorch Lightning Transformer: Introduction",
    "section": "50.6 Conclusion",
    "text": "50.6 Conclusion\nIn this chapter, we took a closer look at the Multi-Head Attention layer which uses a scaled dot product between queries and keys to find correlations and similarities between input elements. The Transformer architecture is based on the Multi-Head Attention layer and applies multiple of them in a ResNet-like block. The Transformer is a very important, recent architecture that can be applied to many tasks and datasets. Although it is best known for its success in NLP, there is so much more to it. We have seen its application on sequence-to-sequence tasks. Its property of being permutation-equivariant if we do not provide any positional encodings, allows it to generalize to many settings. Hence, it is important to know the architecture, but also its possible issues such as the gradient problem during the first iterations solved by learning rate warm-up. If you are interested in continuing with the study of the Transformer architecture, please have a look at the blog posts listed in the “Further Reading” section below.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>HPT PyTorch Lightning Transformer: Introduction</span>"
    ]
  },
  {
    "objectID": "603_spot_lightning_transformer_introduction.html#additional-considerations",
    "href": "603_spot_lightning_transformer_introduction.html#additional-considerations",
    "title": "50  HPT PyTorch Lightning Transformer: Introduction",
    "section": "50.7 Additional Considerations",
    "text": "50.7 Additional Considerations\n\n50.7.1 Complexity and Path Length\nWe can compare the self-attention operation with our other common layer competitors for sequence data: convolutions and recurrent neural networks. In Figure 50.5 you can find a table by Vaswani et al. (2017) on the complexity per layer, the number of sequential operations, and maximum path length. The complexity is measured by the upper bound of the number of operations to perform, while the maximum path length represents the maximum number of steps a forward or backward signal has to traverse to reach any other position. The lower this length, the better gradient signals can backpropagate for long-range dependencies. Let’s take a look at the table in Figure 50.5.\n\n\n\n\n\n\nFigure 50.5: Comparison of complexity and path length of different sequence layers. Table taken from Lippe (2022)\n\n\n\n\\(n\\) is the sequence length, \\(d\\) is the representation dimension and \\(k\\) is the kernel size of convolutions. In contrast to recurrent networks, the self-attention layer can parallelize all its operations making it much faster to execute for smaller sequence lengths. However, when the sequence length exceeds the hidden dimensionality, self-attention becomes more expensive than RNNs. One way of reducing the computational cost for long sequences is by restricting the self-attention to a neighborhood of inputs to attend over, denoted by \\(r\\). Nevertheless, there has been recently a lot of work on more efficient Transformer architectures that still allow long dependencies, of which you can find an overview in the paper by Tay et al. (2020) if interested.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>HPT PyTorch Lightning Transformer: Introduction</span>"
    ]
  },
  {
    "objectID": "603_spot_lightning_transformer_introduction.html#further-reading",
    "href": "603_spot_lightning_transformer_introduction.html#further-reading",
    "title": "50  HPT PyTorch Lightning Transformer: Introduction",
    "section": "50.8 Further Reading",
    "text": "50.8 Further Reading\nThere are of course many more tutorials out there about attention and Transformers. Below, we list a few that are worth exploring if you are interested in the topic and might want yet another perspective on the topic after this one:\n\nTransformer: A Novel Neural Network Architecture for Language Understanding (Jakob Uszkoreit, 2017) - The original Google blog post about the Transformer paper, focusing on the application in machine translation.\nThe Illustrated Transformer (Jay Alammar, 2018) - A very popular and great blog post intuitively explaining the Transformer architecture with many nice visualizations. The focus is on NLP.\nAttention? Attention! (Lilian Weng, 2018) - A nice blog post summarizing attention mechanisms in many domains including vision.\nIllustrated: Self-Attention (Raimi Karim, 2019) - A nice visualization of the steps of self-attention. Recommended going through if the explanation below is too abstract for you.\nThe Transformer family (Lilian Weng, 2020) - A very detailed blog post reviewing more variants of Transformers besides the original one.\n\n\n\n\n\nDevlin, Jacob, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.” arXiv e-Prints, October, arXiv:1810.04805.\n\n\nDosovitskiy, Alexey, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, et al. 2020. “An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale.” arXiv e-Prints, October, arXiv:2010.11929.\n\n\nJain, Sarthak, and Byron C. Wallace. 2019. “Attention is not Explanation.” arXiv e-Prints, February, arXiv:1902.10186.\n\n\nLippe, Phillip. 2022. “UvA Deep Learning Tutorials.” https://github.com/phlippe/uvadlc_notebooks/tree/master.\n\n\nLiu, Liyuan, Haoming Jiang, Pengcheng He, Weizhu Chen, Xiaodong Liu, Jianfeng Gao, and Jiawei Han. 2019. “On the Variance of the Adaptive Learning Rate and Beyond.” arXiv e-Prints, August, arXiv:1908.03265.\n\n\nTay, Yi, Mostafa Dehghani, Dara Bahri, and Donald Metzler. 2020. “Efficient Transformers: A Survey.” arXiv e-Prints, September, arXiv:2009.06732.\n\n\nVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. “Attention Is All You Need.” arXiv e-Prints, June, 1–15.\n\n\nWiegreffe, Sarah, and Yuval Pinter. 2019. “Attention is not not Explanation.” arXiv e-Prints, August, arXiv:1908.04626.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>HPT PyTorch Lightning Transformer: Introduction</span>"
    ]
  },
  {
    "objectID": "603_spot_lightning_transformer_hpt.html",
    "href": "603_spot_lightning_transformer_hpt.html",
    "title": "51  Hyperparameter Tuning of a Transformer Network with PyTorch Lightning",
    "section": "",
    "text": "51.1 Basic Setup\nThis section provides an overview of the hyperparameter tuning process using spotpython and PyTorch Lightning. It uses the Diabetes data set (see Section E.1) for a regression task.\nIn this section, we will show how spotpython can be integrated into the PyTorch Lightning training workflow for a regression task. It demonstrates how easy it is to use spotpython to tune hyperparameters for a PyTorch Lightning model.\nAfter importing the necessary libraries, the fun_control dictionary is set up via the fun_control_init function. The fun_control dictionary contains\nThe method set_hyperparameter allows the user to modify default hyperparameter settings. Here we set the initialization method to [\"Default\"]. No other initializations are used in this experiment. The HyperLight class is used to define the objective function fun. It connects the PyTorch and the spotpython methods and is provided by spotpython. Finally, a Spot object is created.\nfrom spotpython.data.diabetes import Diabetes\nfrom spotpython.hyperdict.light_hyper_dict import LightHyperDict\nfrom spotpython.fun.hyperlight import HyperLight\nfrom spotpython.utils.init import (fun_control_init, surrogate_control_init, design_control_init)\nfrom spotpython.utils.eda import print_exp_table\nfrom spotpython.hyperparameters.values import set_hyperparameter\nfrom spotpython.spot import Spot\nfrom spotpython.utils.file import get_experiment_filename\nfrom spotpython.utils.scaler import TorchStandardScaler\n\nfun_control = fun_control_init(\n    PREFIX=\"603\",\n    TENSORBOARD_CLEAN=True,\n    tensorboard_log=True,\n    fun_evals=inf,\n    max_time=1,\n    data_set = Diabetes(),\n    scaler=TorchStandardScaler(),\n    core_model_name=\"light.regression.NNTransformerRegressor\",\n    hyperdict=LightHyperDict,\n    _L_in=10,\n    _L_out=1)\n\nset_hyperparameter(fun_control, \"optimizer\", [\n                \"Adadelta\",\n                \"Adagrad\",\n                \"Adam\",\n                \"AdamW\",\n                \"Adamax\",\n            ])\nset_hyperparameter(fun_control, \"epochs\", [5, 7])\nset_hyperparameter(fun_control, \"nhead\", [1, 2])\nset_hyperparameter(fun_control, \"dim_feedforward_mult\", [1, 1])\n\ndesign_control = design_control_init(init_size=5)\nsurrogate_control = surrogate_control_init(\n    method=\"regression\",\n    min_Lambda=1e-3,\n    max_Lambda=10,\n)\n\nfun = HyperLight().fun\n\nspot_tuner = Spot(fun=fun,fun_control=fun_control, design_control=design_control, surrogate_control=surrogate_control)\n\nMoving TENSORBOARD_PATH: runs/ to TENSORBOARD_PATH_OLD: runs_OLD/runs_2025_06_15_13_18_30_0\nCreated spot_tensorboard_path: runs/spot_logs/603_maans08_2025-06-15_13-18-30 for SummaryWriter()\nmodule_name: light\nsubmodule_name: regression\nmodel_name: NNTransformerRegressor\nWe can take a look at the design table to see the initial design.\nprint_exp_table(fun_control)\n\n| name                 | type   | default        |   lower |   upper | transform             |\n|----------------------|--------|----------------|---------|---------|-----------------------|\n| d_model_mult         | int    | 4              |    1    |     5   | transform_power_2_int |\n| nhead                | int    | 3              |    1    |     2   | transform_power_2_int |\n| num_encoder_layers   | int    | 1              |    1    |     4   | transform_power_2_int |\n| dim_feedforward_mult | int    | 1              |    1    |     1   | transform_power_2_int |\n| epochs               | int    | 7              |    5    |     7   | transform_power_2_int |\n| batch_size           | int    | 5              |    5    |     8   | transform_power_2_int |\n| optimizer            | factor | Adam           |    0    |     4   | None                  |\n| dropout              | float  | 0.1            |    0.01 |     0.1 | None                  |\n| lr_mult              | float  | 0.1            |    0.01 |     0.3 | None                  |\n| patience             | int    | 5              |    4    |     7   | transform_power_2_int |\n| initialization       | factor | xavier_uniform |    0    |     3   | None                  |\nCalling the method run() starts the hyperparameter tuning process on the local machine.\nres = spot_tuner.run()\n\nd_model: 8, dim_feedforward: 16\n\n\ntrain_model result: {'val_loss': 23955.66015625, 'hp_metric': 23955.66015625}\nd_model: 128, dim_feedforward: 256\n\n\ntrain_model result: {'val_loss': 20858.498046875, 'hp_metric': 20858.498046875}\nd_model: 32, dim_feedforward: 64\n\n\ntrain_model result: {'val_loss': 23231.283203125, 'hp_metric': 23231.283203125}\nd_model: 16, dim_feedforward: 32\n\n\ntrain_model result: {'val_loss': 23903.546875, 'hp_metric': 23903.546875}\nd_model: 8, dim_feedforward: 16\n\n\ntrain_model result: {'val_loss': 23954.796875, 'hp_metric': 23954.796875}\nd_model: 128, dim_feedforward: 256\n\n\ntrain_model result: {'val_loss': 20722.6171875, 'hp_metric': 20722.6171875}\nspotpython tuning: 20722.6171875 [###-------] 29.54% \n\n\nd_model: 128, dim_feedforward: 256\n\n\ntrain_model result: {'val_loss': 19918.572265625, 'hp_metric': 19918.572265625}\nspotpython tuning: 19918.572265625 [#####-----] 48.70% \n\n\nd_model: 128, dim_feedforward: 256\n\n\ntrain_model result: {'val_loss': 19282.2734375, 'hp_metric': 19282.2734375}\nspotpython tuning: 19282.2734375 [#######---] 65.79% \nd_model: 128, dim_feedforward: 256\n\n\n\ntrain_model result: {'val_loss': 5284.65283203125, 'hp_metric': 5284.65283203125}\nspotpython tuning: 5284.65283203125 [#######---] 73.35% \n\n\nd_model: 128, dim_feedforward: 256\n\n\ntrain_model result: {'val_loss': 5471.34375, 'hp_metric': 5471.34375}\nspotpython tuning: 5284.65283203125 [########--] 79.24% \n\n\nd_model: 128, dim_feedforward: 256\n\n\ntrain_model result: {'val_loss': 5555.70068359375, 'hp_metric': 5555.70068359375}\nspotpython tuning: 5284.65283203125 [#########-] 85.06% \n\n\nd_model: 128, dim_feedforward: 256\ntrain_model result: {'val_loss': 5511.9443359375, 'hp_metric': 5511.9443359375}\nspotpython tuning: 5284.65283203125 [##########] 99.12% \n\n\nd_model: 128, dim_feedforward: 256\ntrain_model result: {'val_loss': 5484.96533203125, 'hp_metric': 5484.96533203125}\nspotpython tuning: 5284.65283203125 [##########] 100.00% Done...\n\nExperiment saved to 603_res.pkl\nNote that we have enabled Tensorboard-Logging, so we can visualize the results with Tensorboard. Execute the following command in the terminal to start Tensorboard.\ntensorboard --logdir=\"runs/\"",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Hyperparameter Tuning of a Transformer Network with PyTorch Lightning</span>"
    ]
  },
  {
    "objectID": "603_spot_lightning_transformer_hpt.html#sec-basic-setup-603",
    "href": "603_spot_lightning_transformer_hpt.html#sec-basic-setup-603",
    "title": "51  Hyperparameter Tuning of a Transformer Network with PyTorch Lightning",
    "section": "",
    "text": "PREFIX: a unique identifier for the experiment\nfun_evals: the number of function evaluations\nmax_time: the maximum run time in minutes\ndata_set: the data set. Here we use the Diabetes data set that is provided by spotpython.\ncore_model_name: the class name of the neural network model. This neural network model is provided by spotpython.\nhyperdict: the hyperparameter dictionary. This dictionary is used to define the hyperparameters of the neural network model. It is also provided by spotpython.\n_L_in: the number of input features. Since the Diabetes data set has 10 features, _L_in is set to 10.\n_L_out: the number of output features. Since we want to predict a single value, _L_out is set to 1.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Hyperparameter Tuning of a Transformer Network with PyTorch Lightning</span>"
    ]
  },
  {
    "objectID": "603_spot_lightning_transformer_hpt.html#looking-at-the-results",
    "href": "603_spot_lightning_transformer_hpt.html#looking-at-the-results",
    "title": "51  Hyperparameter Tuning of a Transformer Network with PyTorch Lightning",
    "section": "51.2 Looking at the Results",
    "text": "51.2 Looking at the Results\n\n51.2.1 Tuning Progress\nAfter the hyperparameter tuning run is finished, the progress of the hyperparameter tuning can be visualized with spotpython’s method plot_progress. The black points represent the performace values (score or metric) of hyperparameter configurations from the initial design, whereas the red points represents the hyperparameter configurations found by the surrogate model based optimization.\n\nspot_tuner.plot_progress(log_y=True, filename=None)\n\n\n\n\n\n\n\n\n\n\n51.2.2 Tuned Hyperparameters and Their Importance\nResults can be printed in tabular form.\n\nfrom spotpython.utils.eda import print_res_table\nprint_res_table(spot_tuner)\n\n| name                 | type   | default        |   lower |   upper | tuned                | transform             |   importance | stars   |\n|----------------------|--------|----------------|---------|---------|----------------------|-----------------------|--------------|---------|\n| d_model_mult         | int    | 4              |     1.0 |     5.0 | 5.0                  | transform_power_2_int |        16.63 | *       |\n| nhead                | int    | 3              |     1.0 |     2.0 | 2.0                  | transform_power_2_int |       100.00 | ***     |\n| num_encoder_layers   | int    | 1              |     1.0 |     4.0 | 1.0                  | transform_power_2_int |         0.00 |         |\n| dim_feedforward_mult | int    | 1              |     1.0 |     1.0 | 1.0                  | transform_power_2_int |         0.00 |         |\n| epochs               | int    | 7              |     5.0 |     7.0 | 7.0                  | transform_power_2_int |         0.06 |         |\n| batch_size           | int    | 5              |     5.0 |     8.0 | 5.0                  | transform_power_2_int |         0.01 |         |\n| optimizer            | factor | Adam           |     0.0 |     4.0 | Adadelta             | None                  |        38.77 | *       |\n| dropout              | float  | 0.1            |    0.01 |     0.1 | 0.010474648409984919 | None                  |         0.00 |         |\n| lr_mult              | float  | 0.1            |    0.01 |     0.3 | 0.3                  | None                  |         1.85 | *       |\n| patience             | int    | 5              |     4.0 |     7.0 | 4.0                  | transform_power_2_int |         1.07 | *       |\n| initialization       | factor | xavier_uniform |     0.0 |     3.0 | xavier_normal        | None                  |         0.03 |         |",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Hyperparameter Tuning of a Transformer Network with PyTorch Lightning</span>"
    ]
  },
  {
    "objectID": "603_spot_lightning_transformer_hpt.html#hyperparameter-considerations",
    "href": "603_spot_lightning_transformer_hpt.html#hyperparameter-considerations",
    "title": "51  Hyperparameter Tuning of a Transformer Network with PyTorch Lightning",
    "section": "51.3 Hyperparameter Considerations",
    "text": "51.3 Hyperparameter Considerations\n\nd_model (or d_embedding):\n\nThis is the dimension of the embedding space or the number of expected features in the input.\nAll input features are projected into this dimensional space before entering the transformer encoder.\nThis dimension must be divisible by nhead since each head in the multi-head attention mechanism will process a subset of d_model/nhead features.\n\nnhead:\n\nThis is the number of attention heads in the multi-head attention mechanism.\nIt allows the transformer to jointly attend to information from different representation subspaces.\nIt’s important that d_model % nhead == 0 to ensure the dimensions are evenly split among the heads.\n\nnum_encoder_layers:\n\nThis specifies the number of transformer encoder layers stacked together.\nEach layer contains a multi-head attention mechanism followed by position-wise feedforward layers.\n\ndim_feedforward:\n\nThis is the dimension of the feedforward network model within the transformer encoder layer.\nTypically, this dimension is larger than d_model (e.g., 2048 for a Transformer model with d_model=512).\n\n\n\n51.3.1 Important: Constraints and Interconnections:\n\nd_model and nhead:\n\nAs mentioned, d_model must be divisible by nhead. This is critical because each attention head operates simultaneously on a part of the embedding, so d_model/nhead should be an integer.\n\nnum_encoder_layers and dim_feedforward**:\n\nThese parameters are more flexible and can be chosen independently of d_model and nhead.\nHowever, the choice of dim_feedforward does influence the computational cost and model capacity, as larger dimensions allow learning more complex representations.\n\nOne hyperparameter does not strictly need to be a multiple of others except for ensuring d_model % nhead == 0.\n\n\n\n51.3.2 Practical Considerations:\n\nSetting d_model:\n\nCommon choices for d_model are powers of 2 (e.g., 256, 512, 1024).\nEnsure that it matches the size of the input data after the linear projection layer.\n\nSetting nhead:\n\nTypically, values are 1, 2, 4, 8, etc., depending on the d_model value.\nEach head works on a subset of features, so d_model / nhead should be large enough to be meaningful.\n\nSetting num_encoder_layers:\n\nPractical values range from 1 to 12 or more depending on the depth desired.\nDeeper models can capture more complex patterns but are also more computationally intensive.\n\nSetting dim_feedforward:\n\nOften set to a multiple of d_model, such as 2048 when d_model is 512.\nEnsures sufficient capacity in the intermediate layers for complex feature transformations.\n\n\n\n\n\n\n\n\nNote: d_model Calculation\n\n\n\nSince d_model % nhead == 0 is a critical constraint to ensure that the multi-head attention mechanism can operate effectively, spotpython computes the value of d_model based on the nhead value provided by the user. This ensures that the hyperparameter configuration is valid. So, the final value of d_model is a multiple of nhead. spotpython uses the hyperparameter d_model_mult to determine the multiple of nhead to use for d_model, i.e., d_model = nhead * d_model_mult.\n\n\n\n\n\n\n\n\nNote: dim_feedforward Calculation\n\n\n\nSince this dimension is typically larger than d_model (e.g., 2048 for a Transformer model with d_model=512), spotpython uses the hyperparameter dim_feedforward_mult to determine the multiple of d_model to use for dim_feedforward, i.e., dim_feedforward = d_model * dim_feedforward_mult.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Hyperparameter Tuning of a Transformer Network with PyTorch Lightning</span>"
    ]
  },
  {
    "objectID": "603_spot_lightning_transformer_hpt.html#summary",
    "href": "603_spot_lightning_transformer_hpt.html#summary",
    "title": "51  Hyperparameter Tuning of a Transformer Network with PyTorch Lightning",
    "section": "51.4 Summary",
    "text": "51.4 Summary\nThis section presented an introduction to the basic setup of hyperparameter tuning of a transformer with spotpython and PyTorch Lightning.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Hyperparameter Tuning of a Transformer Network with PyTorch Lightning</span>"
    ]
  },
  {
    "objectID": "604_spot_lightning_save_load_models.html",
    "href": "604_spot_lightning_save_load_models.html",
    "title": "52  Saving and Loading",
    "section": "",
    "text": "52.1 spotpython: Saving and Loading Optimization Experiments\nThis tutorial shows how to save and load objects in spotpython. It is split into the following parts:\nIn this section, we will show how results from spotpython can be saved and reloaded. Here, spotpython can be used as an optimizer. If spotpython is used as an optimizer, no dictionary of hyperparameters has be specified. The fun_control dictionary is sufficient.\nimport os\nimport pprint\nfrom spotpython.utils.file import load_experiment\nfrom spotpython.utils.file import get_experiment_filename\nimport numpy as np\nfrom math import inf\nfrom spotpython.spot import Spot\nfrom spotpython.utils.init import (\n    fun_control_init,\n    design_control_init,\n    surrogate_control_init,\n    optimizer_control_init)\nfrom spotpython.fun.objectivefunctions import Analytical\nfun = Analytical().fun_branin\nfun_control = fun_control_init(\n            PREFIX=\"branin\",            \n            lower = np.array([0, 0]),\n            upper = np.array([10, 10]),\n            fun_evals=8,\n            fun_repeats=1,\n            max_time=inf,\n            noise=False,\n            tolerance_x=0,\n            ocba_delta=0,\n            var_type=[\"num\", \"num\"],\n            infill_criterion=\"ei\",\n            n_points=1,\n            seed=123,\n            log_level=20,\n            show_models=False,\n            show_progress=True)\ndesign_control = design_control_init(\n            init_size=5,\n            repeats=1)\nsurrogate_control = surrogate_control_init(\n            model_fun_evals=10000,\n            min_theta=-3,\n            max_theta=3,\n            n_theta=2,\n            theta_init_zero=True,\n            n_p=1,\n            optim_p=False,\n            var_type=[\"num\", \"num\"],\n            seed=124)\noptimizer_control = optimizer_control_init(\n            max_iter=1000,\n            seed=125)\nspot_tuner = Spot(fun=fun,\n            fun_control=fun_control,\n            design_control=design_control,\n            surrogate_control=surrogate_control,\n            optimizer_control=optimizer_control)\nspot_tuner.run()\nPREFIX = fun_control[\"PREFIX\"]\nfilename = get_experiment_filename(PREFIX)\nspot_tuner.save_experiment(filename=filename)\nprint(f\"filename: {filename}\")\n(spot_tuner_1, fun_control_1, design_control_1,\n    surrogate_control_1, optimizer_control_1) = load_experiment(filename)\nThe progress of the original experiment is shown in Figure 52.1 and the reloaded experiment in Figure 52.2.\nspot_tuner.plot_progress(log_y=True)\n\n\nFigure 52.1\nspot_tuner_1.plot_progress(log_y=True)\n\n\nFigure 52.2\nThe results from the original experiment are shown in Table 52.1 and the reloaded experiment in Table 52.2.\nTable 52.1\n\n\nspot_tuner.print_results()\nTable 52.2\n\n\nspot_tuner_1.print_results()",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Saving and Loading</span>"
    ]
  },
  {
    "objectID": "604_spot_lightning_save_load_models.html#sec-spotpython-saving-and-loading",
    "href": "604_spot_lightning_save_load_models.html#sec-spotpython-saving-and-loading",
    "title": "52  Saving and Loading",
    "section": "",
    "text": "52.1.1 Getting the Tuned Hyperparameters\nThe tuned hyperparameters can be obtained as a dictionary with the following code. Since spotpython is used as an optimizer, the numerical levels of the hyperparameters are identical to the optimized values of the underlying optimization problem, here: the Branin function.\n\nfrom spotpython.hyperparameters.values import get_tuned_hyperparameters\nget_tuned_hyperparameters(spot_tuner=spot_tuner)\n\n\n\n\n\n\n\nSummary: Saving and Loading Optimization Experiments\n\n\n\n\nIf spotpython is used as an optimizer (without an hyperparameter dictionary), experiments can be saved and reloaded with the save_experiment and load_experiment functions.\nThe tuned hyperparameters can be obtained with the get_tuned_hyperparameters function.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Saving and Loading</span>"
    ]
  },
  {
    "objectID": "604_spot_lightning_save_load_models.html#sec-spotpython-as-a-hyperparameter-tuner-604",
    "href": "604_spot_lightning_save_load_models.html#sec-spotpython-as-a-hyperparameter-tuner-604",
    "title": "52  Saving and Loading",
    "section": "52.2 spotpython as a Hyperparameter Tuner",
    "text": "52.2 spotpython as a Hyperparameter Tuner\nIf spotpython is used as a hyperparameter tuner, in addition to the fun_control dictionary a core_model dictionary has to be specified. Furthermore, a data set has to be selected and added to the fun_control dictionary. Here, we will use the Diabetes data set.\n\n52.2.1 The Diabetes Data Set\nThe hyperparameter tuning of a PyTorch Lightning network on the Diabetes data set is used as an example. The Diabetes data set is a PyTorch Dataset for regression, which originates from the scikit-learn package, see https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes.\nTen baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements were obtained for each of n = 442 diabetes patients, as well as the response of interest, a quantitative measure of disease progression one year after baseline. The Diabetes data set is has the following properties:\n\nSamples total: 442\nDimensionality: 10\nFeatures: real, \\(-.2 &lt; x &lt; .2\\)\nTargets: integer \\(25 - 346\\)\n\n\nfrom spotpython.data.diabetes import Diabetes\ndata_set = Diabetes()\n\n\nfrom spotpython.hyperdict.light_hyper_dict import LightHyperDict\nfrom spotpython.fun.hyperlight import HyperLight\nfrom spotpython.utils.init import (fun_control_init, surrogate_control_init, design_control_init)\nfrom spotpython.utils.eda import print_exp_table\nfrom spotpython.spot import Spot\nfrom spotpython.utils.file import get_experiment_filename\n\nPREFIX=\"604\"\nfun_control = fun_control_init(\n    save_experiment=True,\n    PREFIX=PREFIX,\n    fun_evals=inf,\n    max_time=1,\n    data_set = data_set,\n    core_model_name=\"light.regression.NNLinearRegressor\",\n    hyperdict=LightHyperDict,\n    _L_in=10,\n    _L_out=1)\n\nfun = HyperLight().fun\n\nfrom spotpython.hyperparameters.values import set_hyperparameter\nset_hyperparameter(fun_control, \"optimizer\", [ \"Adadelta\", \"Adam\", \"Adamax\"])\nset_hyperparameter(fun_control, \"l1\", [3,4])\nset_hyperparameter(fun_control, \"epochs\", [3,5])\nset_hyperparameter(fun_control, \"batch_size\", [4,11])\nset_hyperparameter(fun_control, \"dropout_prob\", [0.0, 0.025])\nset_hyperparameter(fun_control, \"patience\", [2,3])\n\ndesign_control = design_control_init(init_size=10)\n\nprint_exp_table(fun_control)\n\nIn contrast to the default setttin, where sava_experiment is set to False, here the fun_control dictionary is initialized save_experiment=True. Alternatively, an existing fun_control dictionary can be updated with {\"save_experiment\": True} as shown in the following code.\n\nfun_control.update({\"save_experiment\": True})\n\nIf save_experiment is set to True, the results of the hyperparameter tuning experiment are stored in a pickle file with the name PREFIX after the tuning is finished in the current directory.\nAlternatively, the spot object and the corresponding dictionaries can be saved with the save_experiment method, which is part of the spot object. Therefore, the spot object has to be created as shown in the following code.\n\nspot_tuner = Spot(fun=fun,fun_control=fun_control, design_control=design_control)\nspot_tuner.save_experiment(path=\"userExperiment\", overwrite=False)\n\nHere, we have added a path argument to specify the directory where the experiment is saved. The resulting pickle file can be copied to another directory or computer and reloaded with the load_experiment function. It can also be used for performing the tuning run. Here, we will execute the tuning run on the local machine, which can be done with the following code.\n\nres = spot_tuner.run()\n\nAfter the tuning run is finished, a pickle file with the name spot_604_experiment.pickle is stored in the local directory. This is a result of setting the save_experiment argument to True in the fun_control dictionary. We can load the experiment with the following code. Here, we have specified the PREFIX as an argument to the load_experiment function. Alternatively, the filename (filename) can be used as an argument.\n\nfrom spotpython.utils.file import load_experiment\n(spot_tuner_1, fun_control_1, design_control_1,\n    surrogate_control_1, optimizer_control_1) = load_experiment(PREFIX=PREFIX)\n\nFor comparison, the tuned hyperparameters of the original experiment are shown first:\n\nget_tuned_hyperparameters(spot_tuner, fun_control)\n\nSecond, the tuned hyperparameters of the reloaded experiment are shown:\n\nget_tuned_hyperparameters(spot_tuner_1, fun_control_1)\n\nNote: The numerical levels of the hyperparameters are used as keys in the dictionary. If the fun_control dictionary is used, the names of the hyperparameters are used as keys in the dictionary.\n\nget_tuned_hyperparameters(spot_tuner_1, fun_control_1)\n\nPlot the progress of the original experiment are identical to the reloaded experiment.\n\n\n\nspot_tuner.plot_progress()\n\n\nFigure 52.3\n\n\n\n\n\n\nspot_tuner_1.plot_progress()\n\n\nFigure 52.4\n\n\n\n\n\n\n\n\n\nSummary: Saving and Loading Hyperparameter-Tuning Experiments\n\n\n\n\nIf spotpython is used as an hyperparameter tuner (with an hyperparameter dictionary), experiments can be saved and reloaded with the save_experiment and load_experiment functions.\nThe tuned hyperparameters can be obtained with the get_tuned_hyperparameters function.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Saving and Loading</span>"
    ]
  },
  {
    "objectID": "604_spot_lightning_save_load_models.html#sec-saving-and-loading-pytorch-lightning-models-604",
    "href": "604_spot_lightning_save_load_models.html#sec-saving-and-loading-pytorch-lightning-models-604",
    "title": "52  Saving and Loading",
    "section": "52.3 Saving and Loading PyTorch Lightning Models",
    "text": "52.3 Saving and Loading PyTorch Lightning Models\nSection 52.1 and Section 52.2 explained how to save and load optimization and hyperparameter tuning experiments and how to get the tuned hyperparameters as a dictionary. This section shows how to save and load PyTorch Lightning models.\n\n52.3.1 Get the Tuned Architecture\nIn contrast to the function get_tuned_hyperparameters, the function get_tuned_architecture returns the tuned architecture of the model as a dictionary. Here, the transformations are already applied to the numerical levels of the hyperparameters and the encoding (and types) are the original types of the hyperparameters used by the model. Important: The config dictionary from get_tuned_architecture can be passed to the model without any modifications.\n\nfrom spotpython.hyperparameters.values import get_tuned_architecture\nconfig = get_tuned_architecture(spot_tuner)\npprint.pprint(config)\n\nAfter getting the tuned architecture, the model can be created and tested with the following code.\n\nfrom spotpython.light.testmodel import test_model\ntest_model(config, fun_control)\n\n\n\n52.3.2 Load a Model from Checkpoint\nThe method load_light_from_checkpoint loads a model from a checkpoint file. Important: The model has to be trained before the checkpoint is loaded. As shown here, loading a model with trained weights is possible, but requires two steps:\n\nThe model weights have to be learned using test_model. The test_model method writes a checkpoint file.\nThe model has to be loaded from the checkpoint file.\n\n\n52.3.2.1 Details About the load_light_from_checkpoint Method\n\nThe test_model method saves the last checkpoint to a file using the following code:\n\nModelCheckpoint(\n    dirpath=os.path.join(fun_control[\"CHECKPOINT_PATH\"], config_id), save_last=True\n), \nThe filename of the last checkpoint has a specific structure:\n\nA config_id is generated from the config dictionary. It does not use a timestamp. This differs from the config id generated in cvmodel.py and trainmodel.py, which provide time information for the TensorBoard logging.\nFurthermore, the postfix _TEST is added to the config_id to indicate that the model is tested.\nFor example: runs/saved_models/16_16_64_LeakyReLU_Adadelta_0.0014_8.5895_8_False_kaiming_uniform_TEST/last.ckpt\n\n\nfrom spotpython.light.loadmodel import load_light_from_checkpoint\nmodel_loaded = load_light_from_checkpoint(config, fun_control)\n\n\nvars(model_loaded)\n\n\nimport torch\ntorch.save(model_loaded, \"model.pt\")\n\n\nmymodel = torch.load(\"model.pt\")\n\n\n# show all attributes of the model\nvars(mymodel)",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Saving and Loading</span>"
    ]
  },
  {
    "objectID": "604_spot_lightning_save_load_models.html#sec-converting-a-lightning-model-to-a-plain-torch-model-604",
    "href": "604_spot_lightning_save_load_models.html#sec-converting-a-lightning-model-to-a-plain-torch-model-604",
    "title": "52  Saving and Loading",
    "section": "52.4 Converting a Lightning Model to a Plain Torch Model",
    "text": "52.4 Converting a Lightning Model to a Plain Torch Model\n\n52.4.1 The Function get_removed_attributes_and_base_net\nspotpython provides a function to covert a PyTorch Lightning model to a plain PyTorch model. The function get_removed_attributes_and_base_net returns a tuple with the removed attributes and the base net. The base net is a plain PyTorch model. The removed attributes are the attributes of the PyTorch Lightning model that are not part of the base net.\nThis conversion can be reverted.\n\nimport numpy as np\nimport torch\nfrom spotpython.utils.device import getDevice\nfrom torch.utils.data import random_split\nfrom spotpython.utils.classes import get_removed_attributes_and_base_net\nfrom spotpython.hyperparameters.optimizer import optimizer_handler\nremoved_attributes, torch_net = get_removed_attributes_and_base_net(net=mymodel)\n\n\nprint(removed_attributes)\n\n\nprint(torch_net)\n\n\n\n52.4.2 An Example how to use the Plain Torch Net\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.datasets import load_diabetes\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\n# Load the Diabetes dataset from sklearn\ndiabetes = load_diabetes()\nX = diabetes.data\ny = diabetes.target\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Scale the features\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Convert the data to PyTorch tensors\nX_train_tensor = torch.tensor(X_train, dtype=torch.float32)\ny_train_tensor = torch.tensor(y_train, dtype=torch.float32)\nX_test_tensor = torch.tensor(X_test, dtype=torch.float32)\ny_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n\n# Create a PyTorch dataset\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\ntest_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n\n# Create a PyTorch dataloader\nbatch_size = 32\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n\ntorch_net.to(getDevice(\"cpu\"))\n\n# train the net\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(torch_net.parameters(), lr=0.01)\nn_epochs = 100\nlosses = []\nfor epoch in range(n_epochs):\n    for inputs, targets in train_dataloader:\n        targets = targets.view(-1, 1)\n        optimizer.zero_grad()\n        outputs = torch_net(inputs)\n        loss = criterion(outputs, targets)\n        losses.append(loss.item())\n        loss.backward()\n        optimizer.step()\n# visualize the network training\nplt.plot(losses)\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.show()",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Saving and Loading</span>"
    ]
  },
  {
    "objectID": "605_spot_hpt_light_diabetes_resnet.html",
    "href": "605_spot_hpt_light_diabetes_resnet.html",
    "title": "53  Hyperparameter Tuning with spotpython and PyTorch Lightning for the Diabetes Data Set Using a ResNet Model",
    "section": "",
    "text": "53.1 Looking at the Results\nIn this section, we will show how spotpython can be integrated into the PyTorch Lightning training workflow for a regression task. It demonstrates how easy it is to use spotpython to tune hyperparameters for a PyTorch Lightning model.\nAfter importing the necessary libraries, the fun_control dictionary is set up via the fun_control_init function. The fun_control dictionary contains\nThe HyperLight class is used to define the objective function fun. It connects the PyTorch and the spotpython methods and is provided by spotpython.\nThe method set_hyperparameter allows the user to modify default hyperparameter settings. Here we modify some hyperparameters to keep the model small and to decrease the tuning time.\nFinally, a Spot object is created. Calling the method run() starts the hyperparameter tuning process.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Hyperparameter Tuning with `spotpython` and `PyTorch` Lightning for the Diabetes Data Set Using a ResNet Model</span>"
    ]
  },
  {
    "objectID": "605_spot_hpt_light_diabetes_resnet.html#looking-at-the-results",
    "href": "605_spot_hpt_light_diabetes_resnet.html#looking-at-the-results",
    "title": "53  Hyperparameter Tuning with spotpython and PyTorch Lightning for the Diabetes Data Set Using a ResNet Model",
    "section": "",
    "text": "53.1.1 Tuning Progress\nAfter the hyperparameter tuning run is finished, the progress of the hyperparameter tuning can be visualized with spotpython’s method plot_progress. The black points represent the performace values (score or metric) of hyperparameter configurations from the initial design, whereas the red points represents the hyperparameter configurations found by the surrogate model based optimization.\n\nspot_tuner.plot_progress()\n\n\n\n\n\n\n\n\n\n\n53.1.2 Tuned Hyperparameters and Their Importance\nResults can be printed in tabular form.\n\nfrom spotpython.utils.eda import print_res_table\nprint_res_table(spot_tuner)\n\n| name           | type   | default   |   lower |   upper | tuned                | transform             |   importance | stars   |\n|----------------|--------|-----------|---------|---------|----------------------|-----------------------|--------------|---------|\n| l1             | int    | 3         |     3.0 |     4.0 | 3.0                  | transform_power_2_int |        54.95 | **      |\n| epochs         | int    | 4         |     3.0 |     7.0 | 7.0                  | transform_power_2_int |         0.79 | .       |\n| batch_size     | int    | 4         |     4.0 |    11.0 | 11.0                 | transform_power_2_int |         0.37 | .       |\n| act_fn         | factor | ReLU      |     0.0 |     5.0 | ReLU                 | None                  |         0.01 |         |\n| optimizer      | factor | SGD       |     0.0 |     2.0 | Adadelta             | None                  |        70.96 | **      |\n| dropout_prob   | float  | 0.01      |     0.0 |   0.025 | 0.018944610786155315 | None                  |         0.10 |         |\n| lr_mult        | float  | 1.0       |     0.1 |    20.0 | 17.787675379409905   | None                  |         8.45 | *       |\n| patience       | int    | 2         |     2.0 |     3.0 | 3.0                  | transform_power_2_int |         4.41 | *       |\n| initialization | factor | Default   |     0.0 |     4.0 | kaiming_uniform      | None                  |       100.00 | ***     |\n\n\nA histogram can be used to visualize the most important hyperparameters.\n\nspot_tuner.plot_importance(threshold=1.0)\n\n\n\n\n\n\n\n\n\nspot_tuner.plot_important_hyperparameter_contour(max_imp=3)\n\nl1:  54.948989972832315\nepochs:  0.7910336032578257\nbatch_size:  0.37023065044288384\nact_fn:  0.007559924566997962\noptimizer:  70.95638647025385\ndropout_prob:  0.09584198169452227\nlr_mult:  8.44754813284851\npatience:  4.406014002087552\ninitialization:  100.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n53.1.3 Get the Tuned Architecture\n\nimport pprint\nfrom spotpython.hyperparameters.values import get_tuned_architecture\nconfig = get_tuned_architecture(spot_tuner)\npprint.pprint(config)\n\n{'act_fn': ReLU(),\n 'batch_size': 2048,\n 'dropout_prob': 0.018944610786155315,\n 'epochs': 128,\n 'initialization': 'kaiming_uniform',\n 'l1': 8,\n 'lr_mult': 17.787675379409905,\n 'optimizer': 'Adadelta',\n 'patience': 8}\n\n\n\n\n53.1.4 Test on the full data set\n\n# set the value of the key \"TENSORBOARD_CLEAN\" to True in the fun_control dictionary and use the update() method to update the fun_control dictionary\nimport os\n# if the directory \"./runs\" exists, delete it\nif os.path.exists(\"./runs\"):\n    os.system(\"rm -r ./runs\")\nfun_control.update({\"tensorboard_log\": True})\n\n\nfrom spotpython.light.testmodel import test_model\nfrom spotpython.utils.init import get_feature_names\n\ntest_model(config, fun_control)\nget_feature_names(fun_control)\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃        Test metric        ┃       DataLoader 0        ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│         hp_metric         │     2644.842529296875     │\n│         val_loss          │     2644.842529296875     │\n└───────────────────────────┴───────────────────────────┘\n\n\n\ntest_model result: {'val_loss': 2644.842529296875, 'hp_metric': 2644.842529296875}\n\n\n['age',\n 'sex',\n 'bmi',\n 'bp',\n 's1_tc',\n 's2_ldl',\n 's3_hdl',\n 's4_tch',\n 's5_ltg',\n 's6_glu']\n\n\n\n\n53.1.5 Cross Validation With Lightning\n\nThe KFold class from sklearn.model_selection is used to generate the folds for cross-validation.\nThese mechanism is used to generate the folds for the final evaluation of the model.\nThe CrossValidationDataModule class [SOURCE] is used to generate the folds for the hyperparameter tuning process.\nIt is called from the cv_model function [SOURCE].\n\n\nconfig\n\n{'l1': 8,\n 'epochs': 128,\n 'batch_size': 2048,\n 'act_fn': ReLU(),\n 'optimizer': 'Adadelta',\n 'dropout_prob': 0.018944610786155315,\n 'lr_mult': 17.787675379409905,\n 'patience': 8,\n 'initialization': 'kaiming_uniform'}\n\n\n\nfrom spotpython.light.cvmodel import cv_model\nfun_control.update({\"k_folds\": 2})\nfun_control.update({\"test_size\": 0.6})\ncv_model(config, fun_control)\n\nk: 0\n\n\ntrain_model result: {'val_loss': 6829.279296875, 'hp_metric': 6829.279296875}\nk: 1\ntrain_model result: {'val_loss': 18799.26171875, 'hp_metric': 18799.26171875}\n\n\n12814.2705078125",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Hyperparameter Tuning with `spotpython` and `PyTorch` Lightning for the Diabetes Data Set Using a ResNet Model</span>"
    ]
  },
  {
    "objectID": "605_spot_hpt_light_diabetes_resnet.html#summary",
    "href": "605_spot_hpt_light_diabetes_resnet.html#summary",
    "title": "53  Hyperparameter Tuning with spotpython and PyTorch Lightning for the Diabetes Data Set Using a ResNet Model",
    "section": "53.2 Summary",
    "text": "53.2 Summary\nThis section presented an introduction to the basic setup of hyperparameter tuning with spotpython and PyTorch Lightning using a ResNet model for the Diabetes data set.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Hyperparameter Tuning with `spotpython` and `PyTorch` Lightning for the Diabetes Data Set Using a ResNet Model</span>"
    ]
  },
  {
    "objectID": "606_spot_hpt_light_diabetes_user_resnet.html",
    "href": "606_spot_hpt_light_diabetes_user_resnet.html",
    "title": "54  Hyperparameter Tuning with spotpython and PyTorch Lightning for the Diabetes Data Set Using a User Specified ResNet Model",
    "section": "",
    "text": "54.1 Looking at the Results\nAfter importing the necessary libraries, the fun_control dictionary is set up via the fun_control_init function. The fun_control dictionary contains\nThe HyperLight class is used to define the objective function fun. It connects the PyTorch and the spotpython methods and is provided by spotpython.\nTo access the user specified ResNet model, the path to the user model must be added to the Python path:\nIn the following code, we do not specify the ResNet model in the fun_control dictionary. It will be added in a second step as the user specified model.\nIn a second step, we can add the user specified ResNet model to the fun_control dictionary:\nThe method set_hyperparameter allows the user to modify default hyperparameter settings. Here we modify some hyperparameters to keep the model small and to decrease the tuning time.\nFinally, a Spot object is created. Calling the method run() starts the hyperparameter tuning process.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Hyperparameter Tuning with `spotpython` and `PyTorch` Lightning for the Diabetes Data Set Using a User Specified ResNet Model</span>"
    ]
  },
  {
    "objectID": "606_spot_hpt_light_diabetes_user_resnet.html#looking-at-the-results",
    "href": "606_spot_hpt_light_diabetes_user_resnet.html#looking-at-the-results",
    "title": "54  Hyperparameter Tuning with spotpython and PyTorch Lightning for the Diabetes Data Set Using a User Specified ResNet Model",
    "section": "",
    "text": "54.1.1 Tuning Progress\nAfter the hyperparameter tuning run is finished, the progress of the hyperparameter tuning can be visualized with spotpython’s method plot_progress. The black points represent the performace values (score or metric) of hyperparameter configurations from the initial design, whereas the red points represents the hyperparameter configurations found by the surrogate model based optimization.\n\nspot_tuner.plot_progress()\n\n\n\n\n\n\n\n\n\n\n54.1.2 Tuned Hyperparameters and Their Importance\nResults can be printed in tabular form.\n\nfrom spotpython.utils.eda import print_res_table\nprint_res_table(spot_tuner)\n\n| name           | type   | default   |   lower |   upper | tuned                | transform             |   importance | stars   |\n|----------------|--------|-----------|---------|---------|----------------------|-----------------------|--------------|---------|\n| l1             | int    | 3         |     3.0 |     4.0 | 3.0                  | transform_power_2_int |        54.95 | **      |\n| epochs         | int    | 4         |     3.0 |     7.0 | 7.0                  | transform_power_2_int |         0.79 | .       |\n| batch_size     | int    | 4         |     4.0 |    11.0 | 11.0                 | transform_power_2_int |         0.37 | .       |\n| act_fn         | factor | ReLU      |     0.0 |     5.0 | ReLU                 | None                  |         0.01 |         |\n| optimizer      | factor | SGD       |     0.0 |     2.0 | Adadelta             | None                  |        70.96 | **      |\n| dropout_prob   | float  | 0.01      |     0.0 |   0.025 | 0.018944610786155315 | None                  |         0.10 |         |\n| lr_mult        | float  | 1.0       |     0.1 |    20.0 | 17.787675379409905   | None                  |         8.45 | *       |\n| patience       | int    | 2         |     2.0 |     3.0 | 3.0                  | transform_power_2_int |         4.41 | *       |\n| initialization | factor | Default   |     0.0 |     4.0 | kaiming_uniform      | None                  |       100.00 | ***     |\n\n\nA histogram can be used to visualize the most important hyperparameters.\n\nspot_tuner.plot_importance(threshold=1.0)\n\n\n\n\n\n\n\n\n\nspot_tuner.plot_important_hyperparameter_contour(max_imp=3)\n\nl1:  54.948989972832315\nepochs:  0.7910336032578257\nbatch_size:  0.37023065044288384\nact_fn:  0.007559924566997962\noptimizer:  70.95638647025385\ndropout_prob:  0.09584198169452227\nlr_mult:  8.44754813284851\npatience:  4.406014002087552\ninitialization:  100.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n54.1.3 Get the Tuned Architecture\n\nimport pprint\nfrom spotpython.hyperparameters.values import get_tuned_architecture\nconfig = get_tuned_architecture(spot_tuner)\npprint.pprint(config)\n\n{'act_fn': ReLU(),\n 'batch_size': 2048,\n 'dropout_prob': 0.018944610786155315,\n 'epochs': 128,\n 'initialization': 'kaiming_uniform',\n 'l1': 8,\n 'lr_mult': 17.787675379409905,\n 'optimizer': 'Adadelta',\n 'patience': 8}",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Hyperparameter Tuning with `spotpython` and `PyTorch` Lightning for the Diabetes Data Set Using a User Specified ResNet Model</span>"
    ]
  },
  {
    "objectID": "606_spot_hpt_light_diabetes_user_resnet.html#details-of-the-user-specified-resnet-model",
    "href": "606_spot_hpt_light_diabetes_user_resnet.html#details-of-the-user-specified-resnet-model",
    "title": "54  Hyperparameter Tuning with spotpython and PyTorch Lightning for the Diabetes Data Set Using a User Specified ResNet Model",
    "section": "54.2 Details of the User-Specified ResNet Model",
    "text": "54.2 Details of the User-Specified ResNet Model\nThe specification of a user model requires three files:\n\nmy_resnet.py: the Python file containing the user specified ResNet model\nmy_hyperdict.py: the Python file for loading the hyperparameter dictionary my_hyperdict.json for the user specified ResNet model\nmy_hyperdict.json: the JSON file containing the hyperparameter dictionary for the user specified ResNet model\n\n\n54.2.1 my_resnet.py\nimport lightning as L\nimport torch\nfrom torch import nn\nfrom spotpython.hyperparameters.optimizer import optimizer_handler\nimport torchmetrics.functional.regression\nimport torch.optim as optim\n\nclass ResidualBlock(nn.Module):\n    def __init__(self, input_dim, output_dim, act_fn, dropout_prob):\n        super(ResidualBlock, self).__init__()\n        self.fc1 = nn.Linear(input_dim, output_dim)\n        self.bn1 = nn.BatchNorm1d(output_dim)\n        self.ln1 = nn.LayerNorm(output_dim)  \n        self.fc2 = nn.Linear(output_dim, output_dim)\n        self.bn2 = nn.BatchNorm1d(output_dim)\n        self.ln2 = nn.LayerNorm(output_dim)\n        self.act_fn = act_fn\n        self.dropout = nn.Dropout(dropout_prob)\n        self.shortcut = nn.Sequential()\n\n        if input_dim != output_dim:\n            self.shortcut = nn.Sequential(\n                nn.Linear(input_dim, output_dim),\n                nn.BatchNorm1d(output_dim)\n            )\n    \n    def forward(self, x):\n        identity = self.shortcut(x)\n        \n        out = self.fc1(x)\n        out = self.bn1(out)\n        out = self.ln1(out)\n        out = self.act_fn(out)\n        out = self.dropout(out)\n        out = self.fc2(out)\n        out = self.bn2(out)\n        out = self.ln2(out)\n        out += identity  # Residual connection\n        out = self.act_fn(out)\n        return out\n\nclass MyResNet(L.LightningModule):\n    def __init__(\n        self,\n        l1: int,\n        epochs: int,\n        batch_size: int,\n        initialization: str,\n        act_fn: nn.Module,\n        optimizer: str,\n        dropout_prob: float,\n        lr_mult: float,\n        patience: int,\n        _L_in: int,\n        _L_out: int,\n        _torchmetric: str,\n    ):\n        super().__init__()\n        self._L_in = _L_in\n        self._L_out = _L_out\n        if _torchmetric is None:\n            _torchmetric = \"mean_squared_error\"\n        self._torchmetric = _torchmetric\n        self.metric = getattr(torchmetrics.functional.regression, _torchmetric)\n        self.save_hyperparameters(ignore=[\"_L_in\", \"_L_out\", \"_torchmetric\"])\n        self.example_input_array = torch.zeros((batch_size, self._L_in))\n        \n        if self.hparams.l1 &lt; 4:\n            raise ValueError(\"l1 must be at least 4\")\n        \n        # Get hidden sizes\n        hidden_sizes = self._get_hidden_sizes()\n        layer_sizes = [self._L_in] + hidden_sizes\n\n        # Construct the layers with Residual Blocks and Linear Layer at the end\n        layers = []\n        for i in range(len(layer_sizes) - 1):\n            layers.append(\n                ResidualBlock(\n                    layer_sizes[i], \n                    layer_sizes[i + 1], \n                    self.hparams.act_fn, \n                    self.hparams.dropout_prob\n                )\n            )\n        layers.append(nn.Linear(layer_sizes[-1], self._L_out))\n        \n        self.layers = nn.Sequential(*layers)\n\n        # Initialization (Xavier, Kaiming, or Default)\n        self.apply(self._init_weights)\n\n    def _init_weights(self, module):        \n        if isinstance(module, nn.Linear):\n            if self.hparams.initialization == \"xavier_uniform\":\n                nn.init.xavier_uniform_(module.weight)\n            elif self.hparams.initialization == \"xavier_normal\":\n                nn.init.xavier_normal_(module.weight)\n            elif self.hparams.initialization == \"kaiming_uniform\":\n                nn.init.kaiming_uniform_(module.weight)\n            elif self.hparams.initialization == \"kaiming_normal\":\n                nn.init.kaiming_normal_(module.weight)\n            else: # \"Default\"\n                nn.init.uniform_(module.weight)\n            if module.bias is not None:\n                nn.init.zeros_(module.bias)\n    \n    def _generate_div2_list(self, n, n_min) -&gt; list:\n        result = []\n        current = n\n        repeats = 1\n        max_repeats = 4\n        while current &gt;= n_min:\n            result.extend([current] * min(repeats, max_repeats))\n            current = current // 2\n            repeats = repeats + 1\n        return result\n\n    def _get_hidden_sizes(self):\n        n_low = max(2, int(self._L_in / 4))  # Ensure minimum reasonable size\n        n_high = max(self.hparams.l1, 2 * n_low)\n        hidden_sizes = self._generate_div2_list(n_high, n_low)\n        return hidden_sizes\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        x = self.layers(x)\n        return x\n\n    def _calculate_loss(self, batch):\n        x, y = batch\n        y = y.view(len(y), 1)\n        y_hat = self(x)\n        loss = self.metric(y_hat, y)\n        return loss\n\n    def training_step(self, batch: tuple) -&gt; torch.Tensor:\n        val_loss = self._calculate_loss(batch)\n        return val_loss\n\n    def validation_step(self, batch: tuple, batch_idx: int, prog_bar: bool = False) -&gt; torch.Tensor:\n        val_loss = self._calculate_loss(batch)\n        self.log(\"val_loss\", val_loss, prog_bar=prog_bar)\n        self.log(\"hp_metric\", val_loss, prog_bar=prog_bar)\n        return val_loss\n\n    def test_step(self, batch: tuple, batch_idx: int, prog_bar: bool = False) -&gt; torch.Tensor:\n        val_loss = self._calculate_loss(batch)\n        self.log(\"val_loss\", val_loss, prog_bar=prog_bar)\n        self.log(\"hp_metric\", val_loss, prog_bar=prog_bar)\n        return val_loss\n\n    def predict_step(self, batch: tuple, batch_idx: int, prog_bar: bool = False) -&gt; torch.Tensor:\n        x, y = batch\n        yhat = self(x)\n        y = y.view(len(y), 1)\n        yhat = yhat.view(len(yhat), 1)\n        return (x, y, yhat)\n\n    def configure_optimizers(self):\n        optimizer = optimizer_handler(\n            optimizer_name=self.hparams.optimizer,\n            params=self.parameters(),\n            lr_mult=self.hparams.lr_mult\n        )\n\n        # Dynamic creation of milestones based on the number of epochs.\n        num_milestones = 3  # Number of milestones to divide the epochs\n        milestones = [int(self.hparams.epochs / (num_milestones + 1) * (i + 1)) for i in range(num_milestones)]\n\n        # Print milestones for debug purposes\n        print(f\"Milestones: {milestones}\")\n\n        # Create MultiStepLR scheduler with dynamic milestones and learning rate multiplier.\n        scheduler = optim.lr_scheduler.MultiStepLR(\n            optimizer, \n            milestones=milestones, \n            gamma=0.1  # Decay factor\n        )\n\n        # Learning rate scheduler configuration\n        lr_scheduler_config = {\n            \"scheduler\": scheduler,\n            \"interval\": \"epoch\",  # Adjust learning rate per epoch\n            \"frequency\": 1,      # Apply the scheduler at every epoch\n        }\n        \n        return {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler_config}\n\n\n54.2.2 my_hyperdict.py\nimport json\nfrom spotpython.data import base\nimport pathlib\n\n\nclass MyHyperDict(base.FileConfig):\n    \"\"\"User specified hyperparameter dictionary.\n\n    This class extends the FileConfig class to provide a dictionary for storing hyperparameters.\n\n    Attributes:\n        filename (str):\n            The name of the file where the hyperparameters are stored.\n    \"\"\"\n\n    def __init__(\n        self,\n        filename: str = \"my_hyper_dict.json\",\n        directory: None = None,\n    ) -&gt; None:\n        super().__init__(filename=filename, directory=directory)\n        self.filename = filename\n        self.directory = directory\n        self.hyper_dict = self.load()\n\n    @property\n    def path(self):\n        if self.directory:\n            return pathlib.Path(self.directory).joinpath(self.filename)\n        return pathlib.Path(__file__).parent.joinpath(self.filename)\n\n    def load(self) -&gt; dict:\n        \"\"\"Load the hyperparameters from the file.\n\n        Returns:\n            dict: A dictionary containing the hyperparameters.\n\n        Examples:\n            # Assume the user specified file `my_hyper_dict.json` is in the `./hyperdict/` directory.\n            &gt;&gt;&gt; user_lhd = MyHyperDict(filename='my_hyper_dict.json', directory='./hyperdict/')\n        \"\"\"\n        with open(self.path, \"r\") as f:\n            d = json.load(f)\n        return d\n\n\n54.2.3 my_hyperdict.json\n \"MyResNet\": {\n        \"l1\": {\n            \"type\": \"int\",\n            \"default\": 3,\n            \"transform\": \"transform_power_2_int\",\n            \"lower\": 3,\n            \"upper\": 10\n        },\n        \"epochs\": {\n            \"type\": \"int\",\n            \"default\": 4,\n            \"transform\": \"transform_power_2_int\",\n            \"lower\": 4,\n            \"upper\": 9\n        },\n        \"batch_size\": {\n            \"type\": \"int\",\n            \"default\": 4,\n            \"transform\": \"transform_power_2_int\",\n            \"lower\": 1,\n            \"upper\": 6\n        },\n        \"act_fn\": {\n            \"levels\": [\n                \"Sigmoid\",\n                \"Tanh\",\n                \"ReLU\",\n                \"LeakyReLU\",\n                \"ELU\",\n                \"Swish\"\n            ],\n            \"type\": \"factor\",\n            \"default\": \"ReLU\",\n            \"transform\": \"None\",\n            \"class_name\": \"spotpython.torch.activation\",\n            \"core_model_parameter_type\": \"instance()\",\n            \"lower\": 0,\n            \"upper\": 5\n        },\n        \"optimizer\": {\n            \"levels\": [\n                \"Adadelta\",\n                \"Adagrad\",\n                \"Adam\",\n                \"AdamW\",\n                \"SparseAdam\",\n                \"Adamax\",\n                \"ASGD\",\n                \"NAdam\",\n                \"RAdam\",\n                \"RMSprop\",\n                \"Rprop\",\n                \"SGD\"\n            ],\n            \"type\": \"factor\",\n            \"default\": \"SGD\",\n            \"transform\": \"None\",\n            \"class_name\": \"torch.optim\",\n            \"core_model_parameter_type\": \"str\",\n            \"lower\": 0,\n            \"upper\": 11\n        },\n        \"dropout_prob\": {\n            \"type\": \"float\",\n            \"default\": 0.01,\n            \"transform\": \"None\",\n            \"lower\": 0.0,\n            \"upper\": 0.25\n        },\n        \"lr_mult\": {\n            \"type\": \"float\",\n            \"default\": 1.0,\n            \"transform\": \"None\",\n            \"lower\": 0.1,\n            \"upper\": 10.0\n        },\n        \"patience\": {\n            \"type\": \"int\",\n            \"default\": 2,\n            \"transform\": \"transform_power_2_int\",\n            \"lower\": 2,\n            \"upper\": 6\n        },\n        \"initialization\": {\n            \"levels\": [\n                \"Default\",\n                \"kaiming_uniform\",\n                \"kaiming_normal\",\n                \"xavier_uniform\",\n                \"xavier_normal\"\n            ],\n            \"type\": \"factor\",\n            \"default\": \"Default\",\n            \"transform\": \"None\",\n            \"core_model_parameter_type\": \"str\",\n            \"lower\": 0,\n            \"upper\": 4\n        }\n    }",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Hyperparameter Tuning with `spotpython` and `PyTorch` Lightning for the Diabetes Data Set Using a User Specified ResNet Model</span>"
    ]
  },
  {
    "objectID": "606_spot_hpt_light_diabetes_user_resnet.html#summary",
    "href": "606_spot_hpt_light_diabetes_user_resnet.html#summary",
    "title": "54  Hyperparameter Tuning with spotpython and PyTorch Lightning for the Diabetes Data Set Using a User Specified ResNet Model",
    "section": "54.3 Summary",
    "text": "54.3 Summary\nThis section presented an introduction to the basic setup of hyperparameter tuning with spotpython and PyTorch Lightning using a ResNet model for the Diabetes data set.",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Hyperparameter Tuning with `spotpython` and `PyTorch` Lightning for the Diabetes Data Set Using a User Specified ResNet Model</span>"
    ]
  },
  {
    "objectID": "608_spot_hpt_light_condnet.html",
    "href": "608_spot_hpt_light_condnet.html",
    "title": "55  Hyperparameter Tuning with spotpython and PyTorch Lightning Using a CondNet Model",
    "section": "",
    "text": "55.1 Looking at the Results",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Hyperparameter Tuning with `spotpython` and `PyTorch` Lightning Using a CondNet Model</span>"
    ]
  },
  {
    "objectID": "608_spot_hpt_light_condnet.html#looking-at-the-results",
    "href": "608_spot_hpt_light_condnet.html#looking-at-the-results",
    "title": "55  Hyperparameter Tuning with spotpython and PyTorch Lightning Using a CondNet Model",
    "section": "",
    "text": "55.1.1 Tuning Progress\nAfter the hyperparameter tuning run is finished, the progress of the hyperparameter tuning can be visualized with spotpython’s method plot_progress. The black points represent the performace values (score or metric) of hyperparameter configurations from the initial design, whereas the red points represents the hyperparameter configurations found by the surrogate model based optimization.\n\nspot_tuner.plot_progress()\n\n\n\n\n\n\n\n\n\n\n55.1.2 Tuned Hyperparameters and Their Importance\nResults can be printed in tabular form.\n\nfrom spotpython.utils.eda import print_res_table\nprint_res_table(spot_tuner)\n\n| name           | type   | default   |   lower |   upper | tuned                 | transform             |   importance | stars   |\n|----------------|--------|-----------|---------|---------|-----------------------|-----------------------|--------------|---------|\n| l1             | int    | 3         |     3.0 |     4.0 | 3.0                   | transform_power_2_int |         0.00 |         |\n| epochs         | int    | 4         |     3.0 |     7.0 | 7.0                   | transform_power_2_int |         0.00 |         |\n| batch_size     | int    | 4         |     4.0 |     5.0 | 4.0                   | transform_power_2_int |         0.00 |         |\n| act_fn         | factor | ReLU      |     0.0 |     5.0 | Swish                 | None                  |         0.00 |         |\n| optimizer      | factor | SGD       |     0.0 |     2.0 | Adadelta              | None                  |         0.00 |         |\n| dropout_prob   | float  | 0.01      |     0.0 |   0.025 | 0.0012653320827643374 | None                  |         0.08 |         |\n| lr_mult        | float  | 1.0       |     0.1 |    20.0 | 4.855819388527004     | None                  |         0.03 |         |\n| patience       | int    | 2         |     2.0 |     3.0 | 2.0                   | transform_power_2_int |         0.00 |         |\n| batch_norm     | factor | 0         |     0.0 |     1.0 | 1                     | None                  |         0.00 |         |\n| initialization | factor | Default   |     0.0 |     4.0 | kaiming_uniform       | None                  |       100.00 | ***     |\n\n\nA histogram can be used to visualize the most important hyperparameters.\n\nspot_tuner.plot_importance(threshold=1.0)\n\n\n\n\n\n\n\n\n\nspot_tuner.plot_important_hyperparameter_contour(max_imp=3)\n\nl1:  0.004029153451543868\nepochs:  0.004029153451543868\nbatch_size:  0.004029153451543868\nact_fn:  0.004029153451543868\noptimizer:  0.004029153451543868\ndropout_prob:  0.08077498325537841\nlr_mult:  0.03414707537824906\npatience:  0.004029153451543868\nbatch_norm:  0.004029153451543868\ninitialization:  100.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n55.1.3 Get the Tuned Architecture\n\nimport pprint\nfrom spotpython.hyperparameters.values import get_tuned_architecture\nconfig = get_tuned_architecture(spot_tuner)\npprint.pprint(config)\n\n{'act_fn': Swish(),\n 'batch_norm': True,\n 'batch_size': 16,\n 'dropout_prob': 0.0012653320827643374,\n 'epochs': 128,\n 'initialization': 'kaiming_uniform',\n 'l1': 8,\n 'lr_mult': 4.855819388527004,\n 'optimizer': 'Adadelta',\n 'patience': 4}",
    "crumbs": [
      "Hyperparameter Tuning with PyTorch Lightning",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Hyperparameter Tuning with `spotpython` and `PyTorch` Lightning Using a CondNet Model</span>"
    ]
  },
  {
    "objectID": "bart25a-desirability-latest.html",
    "href": "bart25a-desirability-latest.html",
    "title": "56  Introduction to Desirability Functions",
    "section": "",
    "text": "56.1 The Python Packages Used in This Article\nThe desirability function approach is a widely adopted method in industry for optimizing multiple response processes (“NIST/SEMATECH e-Handbook of Statistical Methods” 2021). It operates on the principle that the overall “quality” of a product or process with multiple quality characteristics is deemed unacceptable if any characteristic falls outside the “desired” limits. This approach identifies operating conditions that yield the most “desirable” response values, effectively balancing multiple objectives to achieve optimal outcomes.\nOften, different scales are used for various objectives. When combining these objectives into a single new one, the challenge arises of how to compare the scales with each other. The fundamental idea of the desirability index is to transform the deviations of the objective value from its target value into comparable desirabilities, i.e., onto a common scale. For this, a target value as well as a lower and/or upper specification limit must be known for each objective involved. A result outside the specification limits is assigned a desirability of 0, while a result at the target value is assigned a desirability of 1. Linear or nonlinear transformation, such as a power transformation, can be chosen as the transformation between the specification limits. The desirability index according to Derringer and Suich (1980) is then the geometric mean of the desirabilities of the various objectives (Weihe et al. 1999).\nThe desirability package (Kuhn 2016), which is written in the statistical programming language R, contains S3 classes for multivariate optimization using the desirability function approach of Harington (1965) with functional forms described by Derringer and Suich (1980). It is available on CRAN, see https://cran.r-project.org/package=desirability.\nHyperparameter Tuning (or Hyperparameter Optimization) is crucial for configuring machine learning algorithms, as hyperparameters significantly impact performance (Bartz et al. 2022; Bischl et al. 2023) To avoid manual, time-consuming, and irreproducible trial-and-error processes, these tuning methods can be used. They include simple techniques like grid and random search, as well as advanced approaches such as evolution strategies, surrogate optimization, Hyperband, and racing. The tuning process has to consider several objectives, such as maximizing the model’s performance while minimizing the training time or model complexity. The desirability function approach is a suitable method for multi-objective optimization, as it allows for the simultaneous optimization of multiple objectives by combining them into a single desirability score.\nThis paper is structured as follows: After presenting the desirability function approach in Section 56.2, we introduce the Python package spotdesirability, which is a Python implementation of the R package desirability. The introduction is based on several “hands-on” examples. Section 56.3 provides an overview of related work in the field of multi-objective optimization and hyperparameter tuning. Section 56.4 presents an example of a chemical reaction with two objectives: conversion and activity. The example is based on a response surface experiment described by Myers, Montgomery, and Anderson-Cook (2016) and also used by Kuhn (2016). It allows a direct comparison of the results obtained with the R package desirability and the Python package spotdesirability. Section 56.5 describes how to maximize the desirability function using the Nelder-Mead algorithm from the scipy.optimize.minimize function. This approach is common in RSM (Box and Wilson 1951; Myers, Montgomery, and Anderson-Cook 2016). The optimization process is illustrated using the chemical reaction example from Section 56.4. This example is based on the example presented in Kuhn (2016), so that, similar to the comparison in Section 56.4, a comparison of the results obtained with the R and Python packages is possible. Section 56.6 presents an example of surrogate model-based optimization (Gramacy 2020; Forrester, Sóbester, and Keane 2008) using the spotdesirability package. Results from the RSM optimization can be compared with the results from surrogate model-based optimization. The surrogate model is based on the spotpython package (Bartz-Beielstein 2023). Section 56.7 presents an example of hyperparameter tuning of a neural network implemented in PyTorch using the spotdesirability package. The goal of this example is to demonstrate how to use the desirability function approach for hyperparameter tuning in a machine learning context. The article concludes with a summary and outlook in Section 56.8.\nThe following Python packages, classes, and functions are used in this article:\nimport os\nfrom math import inf\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import minimize\nfrom spotpython.hyperparameters.values import set_hyperparameter\nfrom spotpython.data.diabetes import Diabetes\nfrom spotpython.fun.mohyperlight import MoHyperLight\nfrom spotpython.hyperdict.light_hyper_dict import LightHyperDict\nfrom spotpython.hyperparameters.values import set_hyperparameter\nfrom spotpython.mo.functions import fun_myer16a\nfrom spotpython.mo.plot import plot_mo\nfrom spotpython.plot.contour import (mo_generate_plot_grid, contour_plot,\n                                     contourf_plot)\nfrom spotpython.utils.eda import print_exp_table, print_res_table\nfrom spotpython.utils.file import get_experiment_filename\nfrom spotpython.spot import Spot\nfrom spotpython.utils.init import (fun_control_init, surrogate_control_init,\n                                   design_control_init)\nfrom spotdesirability.utils.desirability import (DOverall, DMax, DCategorical, DMin,\n                                                 DTarget, DArb, DBox)\nfrom spotdesirability.plot.ccd import plotCCD\nfrom spotdesirability.functions.rsm import rsm_opt, conversion_pred, activity_pred\nwarnings.filterwarnings(\"ignore\")",
    "crumbs": [
      "Multi Objective Optimization",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Introduction to Desirability Functions</span>"
    ]
  },
  {
    "objectID": "bart25a-desirability-latest.html#sec-desirability",
    "href": "bart25a-desirability-latest.html#sec-desirability",
    "title": "56  Introduction to Desirability Functions",
    "section": "56.2 Desirability",
    "text": "56.2 Desirability\n\n56.2.1 Basic Desirability Functions\nThe desirability function approach to simultaneously optimizing multiple equations was originally proposed by Harington (1965). The approach translates the functions to a common scale (\\([0, 1]\\)), combines them using the geometric mean, and optimizes the overall metric. The equations can represent model predictions or other equations. Kuhn (2016) notes that desirability functions are popular in response surface methodology (RSM) (Box and Wilson 1951; Myers, Montgomery, and Anderson-Cook 2016) to simultaneously optimize a series of quadratic models. A response surface experiment may use measurements on a set of outcomes, where instead of optimizing each outcome separately, settings for the predictor variables are sought to satisfy all outcomes at once.\nKuhn (2016) explains that originally, Harrington used exponential functions to quantify desirability. In our Python implementation, which is based on the R package desirablity from Kuhn (2016), the simple discontinuous functions of Derringer and Suich (1980) are adopted. For simultaneous optimization of equations, individual “desirability” functions are constructed for each function, and Derringer and Suich (1980) proposed three forms of these functions corresponding to the optimization goal type. Kuhn (2016) describes the R implementation as follows:\n\nSuppose there are \\(R\\) equations or functions to simultaneously optimize, denoted \\(f_r(\\vec{x})\\) (\\(r = 1 \\ldots R\\)). For each of the \\(R\\) functions, an individual “desirability” function is constructed that is high when \\(f_r(\\vec{x})\\) is at the desirable level (such as a maximum, minimum, or target) and low when \\(f_r(\\vec{x})\\) is at an undesirable value. Derringer and Suich (1980) proposed three forms of these functions, corresponding to the type of optimization goal, namely maximization, minimization, or target optimization. The associated desirability functions are denoted \\(d_r^{\\text{max}}\\), \\(d_r^{\\text{min}}\\), and \\(d_r^{\\text{target}}\\).\n\n\n56.2.1.1 Maximization\nFor maximization of \\(f_r(\\vec{x})\\) (“larger-is-better”), the following function is used:\n\\[\nd_r^{\\text{max}} =\n\\begin{cases}\n    0 & \\text{if } f_r(\\vec{x}) &lt; A \\\\\n    \\left(\\frac{f_r(\\vec{x}) - A}{B - A}\\right)^s & \\text{if } A \\leq f_r(\\vec{x}) \\leq B \\\\\n    1 & \\text{if } f_r(\\vec{x}) &gt; B,\n\\end{cases}\n\\]\nwhere \\(A\\), \\(B\\), and \\(s\\) are chosen by the investigator.\n\n\n56.2.1.2 Minimization\nFor minimization (“smaller-is-better”), the following function is proposed:\n\\[\nd_r^{\\text{min}} =\n\\begin{cases}\n    0 & \\text{if } f_r(\\vec{x}) &gt; B \\\\\n    \\left(\\frac{f_r(\\vec{x}) - B}{A - B}\\right)^s & \\text{if } A \\leq f_r(\\vec{x}) \\leq B \\\\\n    1 & \\text{if } f_r(\\vec{x}) &lt; A\n\\end{cases}\n\\]\n\n\n56.2.1.3 Target Optimization\nIn “target-is-best” situations, the following function is used:\n\\[\nd_r^{\\text{target}} =\n\\begin{cases}\n    \\left(\\frac{f_r(\\vec{x}) - A}{t_0 - A}\\right)^{s_1} & \\text{if } A \\leq f_r(\\vec{x}) \\leq t_0 \\\\\n    \\left(\\frac{f_r(\\vec{x}) - B}{t_0 - B}\\right)^{s_2} & \\text{if } t_0 \\leq f_r(\\vec{x}) \\leq B \\\\\n    0 & \\text{otherwise.}\n\\end{cases}\n\\]\nKuhn (2016) explains that these functions, which are shown in Figure 56.1, share the same scale and are discontinuous at specific points \\(A\\), \\(B\\), and \\(t_0\\). The values of \\(s\\), \\(s_1\\), or \\(s_2\\) can be chosen so that the desirability criterion is easier or more difficult to satisfy. For example:\n\nIf \\(s\\) is chosen to be less than 1 in \\(d_r^{\\text{min}}\\), \\(d_r^{\\text{min}}\\) is near 1 even if the model \\(f_r(\\vec{x})\\) is not low.\nAs values of \\(s\\) move closer to 0, the desirability reflected by \\(d_r^{\\text{min}}\\) becomes higher.\nValues of \\(s\\) greater than 1 will make \\(d_r^{\\text{min}}\\) harder to satisfy in terms of desirability.\n\nKuhn notes that these scaling factors are useful when one equation holds more importance than others. He emphasizes that any function can reflect model desirability; Del Castillo, Montgomery, and McCarville (1996) developed alternative functions suitable for gradient-based optimizations.\n\n\n\n\n\n\n\n\n\n\ndCategorical_obj = DCategorical(missing=0.2, values={\"A\": 0.8, \"B\": 0.6, \"C\": 0.4})\ndCategorical_obj.plot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 56.1: Examples of the three primary desirability functions. Panel (a) shows an example of a larger–is–better function, panel (b) shows a smaller–is–better desirability function and panel (c) shows a function where the optimal value corresponds to a target value. Not that increasing the scale parameter makes it more difficult to achieve higher desirability, while values smaller than 1 make it easier to achieve good results.\n\n\n\n\n\nFor each of these three desirability functions (and the others discussed in Section 56.2.3), there are print_class_attributes, plot, and predict methods similar to the R implementation (Kuhn 2016). The print_attributes method prints the class attributes, the plot method plots the desirability function, and the predict method predicts the desirability for a given input.\n\n\n\n56.2.2 Overall Desirability\nGiven the \\(R\\) desirability functions \\(d_1 \\ldots d_r\\) are on the [0,1] scale, they can be combined to achieve an overall desirability function, \\(D\\). One method of doing this is by the geometric mean:\n\\[\nD = \\left(\\prod_{r=1}^R d_r\\right)^{1/R}.\n\\]\nThe geometric mean has the property that if any one model is undesirable (\\(d_r = 0\\)), the overall desirability is also unacceptable (\\(D = 0\\)). Once \\(D\\) has been defined and the prediction equations for each of the \\(R\\) equations have been computed, it can be used to optimize or rank the predictors.\n\n\n56.2.3 Non-Standard Features\nThe R package desirability (Kuhn 2016) offers a few non-standard features. These non-standard features are also included in the Python implementation and will be discussed in the following. First, we will consider the non-informative desirability and missing values, followed by zero-desirability tolerances, and finally non-standard desirability functions.\n\n56.2.3.1 Non-Informative Desirability and Missing Values\nAccording to Kuhn, if inputs to desirability functions are uncomputable, the package estimates a non-informative value by computing desirabilities over the possible range and taking the mean.\nIf an input to a desirability function is NA, by default, it is replaced by this non-informative value. Setting object$missing to NA (in R) changes the calculation to return an NA for the result, where object is the result of a call to one of the desirability functions.A similar procedure is implemented in the Python package. The non-informative value is plotted as a broken line in default plot methods.\n\n\n56.2.3.2 Zero-Desirability Tolerances\nKuhn (2016) highlights that in high-dimensional outcomes, finding feasible solutions where every desirability value is acceptable can be challenging. Each desirability R function has a tol argument, which can be set between [0, 1] (default is NULL). If not null, zero desirability values are replaced by tol.\n\n\n56.2.3.3 Non-Standard Desirability Functions\nKuhn mentions scenarios where the three discussed desirability functions are inadequate for user requirements.\n\n56.2.3.3.1 Custom or Arbitary Desirability Functions\nIn this case, the dArb function (Arb stands for “Arbitary”) can be used to create a custom desirability function. dArb accepts numeric vector inputs with matching desirabilities to approximate other functional forms. For instance, a logistic function can be used as a desirability function. The logistic function is defined as \\(d(\\vec{x}) = \\frac{1}{1+\\exp(-\\vec{x})}\\). For inputs outside the range \\(\\pm5\\), desirability values remain near zero and one. The desirability function is defined using 20 computation points on this range, and these values establish the desirability function.\n\n# Define the logistic function\ndef foo(u):\n    return 1 / (1 + np.exp(-u))\n\n# Generate input values\nx_input = np.linspace(-5, 5, 20)\n\n# Create the DArb object\nlogistic_d = DArb(x_input, foo(x_input))\nlogistic_d.print_class_attributes()\n\n\nClass: DArb\nx: [-5.         -4.47368421 -3.94736842 -3.42105263 -2.89473684 -2.36842105\n -1.84210526 -1.31578947 -0.78947368 -0.26315789  0.26315789  0.78947368\n  1.31578947  1.84210526  2.36842105  2.89473684  3.42105263  3.94736842\n  4.47368421  5.        ]\nd: [0.00669285 0.01127661 0.0189398  0.03164396 0.05241435 0.08561266\n 0.1368025  0.21151967 0.31228169 0.43458759 0.56541241 0.68771831\n 0.78848033 0.8631975  0.91438734 0.94758565 0.96835604 0.9810602\n 0.98872339 0.99330715]\ntol: None\nmissing: 0.5\n\n\nInputs in-between these grid points are linearly interpolated. Using this method, extreme values are applied outside the input range. Figure 56.2 displays a plot of the logisticD object.\n\nlogistic_d.plot()\n\n\n\n\n\n\n\nFigure 56.2: An example of a desirability function created using the DArb function. The desirability function is a logistic curve that is defined by 20 points on the range [-5, 5].\n\n\n\n\n\n\n\n56.2.3.3.2 Desirabilty Function for Box Constraints\nKuhn also adds that there is a desirability function for implementing box constraints on an equation. For example, assigning zero desirability to values beyond \\(\\pm 1.682\\) in the design region, instead of penalizing. Figure 56.3 demonstrates an example function.\n\nbox_desirability = DBox(low=-1.682, high=1.682)\nbox_desirability.plot(non_inform=False)\n\n\n\n\n\n\n\nFigure 56.3: An example of a box-like desirability function that assigns zero desirability to values outside of the range [-1.682, 1.682].\n\n\n\n\n\n\n\n56.2.3.3.3 Desirability Function for Categorical Inputs\nKuhn concludes by mentioning another non-standard application involving categorical inputs. Desirabilities are assigned to each value. For example:\n\n# Define desirability values for categorical inputs\nvalues = {\"value1\": 0.1, \"value2\": 0.9, \"value3\": 0.2}\n\n# Create a DCategorical object\ngrouped_desirabilities = DCategorical(values)\n\n# Print the desirability values\nprint(\"Desirability values for categories:\")\nfor category, desirability in grouped_desirabilities.values.items():\n    print(f\"{category}: {desirability}\")\n\n# Example usage: Predict desirability for a specific category\ncategory = \"value2\"\npredicted_desirability = grouped_desirabilities.predict([category])\nprint(f\"\\nPredicted desirability for '{category}': {predicted_desirability[0]}\")\n\nDesirability values for categories:\nvalue1: 0.1\nvalue2: 0.9\nvalue3: 0.2\n\nPredicted desirability for 'value2': 0.9\n\n\nFigure 56.4 visualizes a plot of desirability profiles for this setup.\n\ngrouped_desirabilities.plot(non_inform=False)\n\n\n\n\n\n\n\nFigure 56.4: Desirability function for categorical values. The desirability values are assigned to three categories: ‘value1’, ‘value2’, and ‘value3’.",
    "crumbs": [
      "Multi Objective Optimization",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Introduction to Desirability Functions</span>"
    ]
  },
  {
    "objectID": "bart25a-desirability-latest.html#sec-related-work",
    "href": "bart25a-desirability-latest.html#sec-related-work",
    "title": "56  Introduction to Desirability Functions",
    "section": "56.3 Related Work",
    "text": "56.3 Related Work\nMultiobjective approaches are established optimization tools (Emmerich and Deutz 2018). The weighted-sum approach is a simple and widely used method for multi-objective optimization, but probably only, because its disadvantages are unknown. Compared to the weighted-sum approach, the desirability-function approach is a better choice for multi-objective optimization. The desirability function approach also allows for more flexibility in defining the objectives and their trade-offs.\nNino et al. (2015) discuss the use of Experimental Designs and RSM to optimize conflicting responses in the development of a 3D printer prototype. Specifically, they focus on an interlocking device designed to recycle polyethylene terephthalate water bottles. The optimization involves two conflicting goals: maximizing load capacity and minimizing mass. A Box Behnken Design (BBD) was used for the experimental setup, and desirability functions were applied to identify the best trade-offs.\nKarl et al. (2023) describe multi-objective optimization in maschine learning. Coello et al. (2021) give an overview of Multi-Objective Evolutionary Algorithms.",
    "crumbs": [
      "Multi Objective Optimization",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Introduction to Desirability Functions</span>"
    ]
  },
  {
    "objectID": "bart25a-desirability-latest.html#sec-example-chemical-reaction",
    "href": "bart25a-desirability-latest.html#sec-example-chemical-reaction",
    "title": "56  Introduction to Desirability Functions",
    "section": "56.4 An Example With Two Objectives: Chemical Reaction",
    "text": "56.4 An Example With Two Objectives: Chemical Reaction\nSimilar to the presentation in Kuhn (2016), we will use the example of a chemical reaction to illustrate the desirability function approach. The example is based on a response surface experiment described by Myers, Montgomery, and Anderson-Cook (2016). The goal is to maximize the percent conversion of a chemical reaction while keeping the thermal activity within a specified range.\nThe central composite design (CCD) is the most popular class of designs used for fitting second-order response surface models (Montgomery 2001). Since the location of the optimum is unknown before the RSM starts, Box and Hunter (1957) suggested that the design should be rotatable (it provides equal precision of estimation in all directions or stated differently, the variance of the predicted response is the same at all points that are the same distance from the center of the design space). A CCD is made rotable by using an axis distance value of \\(\\alpha = (n_F)^{1/4}\\), where \\(n_F\\) is the number of points (here \\(2^3 = 8\\)) (Montgomery 2001). Figure 56.5 shows the design space for the chemical reaction example. The design space is defined by three variables: reaction time, reaction temperature, and percent catalyst. This rotable CCD consists of a full factorial design with three factors, each at two levels, plus a center point and six (\\(2\\times k\\)) axial points. The axial points are located at a distance of \\(\\pm \\alpha\\) from the center point in each direction.\n\nplotCCD(figsize=(8, 6), title=None)\n\n\n\n\n\n\n\nFigure 56.5: Central composite design (CCD) for the chemical reaction example.\n\n\n\n\n\nMontgomery (2001) note that it is not important to have exact rotability. From a prediction variance point of view, the best choice is to set \\(\\alpha = \\sqrt{k}\\), which results in a so-called spherical CCD.\n\n56.4.1 The Two Objective Functions: Conversion and Activity\nMyers, Montgomery, and Anderson-Cook (2016) present two equations for the fitted quadratic response surface models.\n\\[\\begin{align*}\nf_{\\text{con}}(x) =\n&\n81.09\n+\n1.0284 \\cdot x_1\n+\n4.043 \\cdot x_2\n+\n6.2037 \\cdot x_3\n+\n1.8366 \\cdot x_1^2\n+\n2.9382 \\cdot x_2^2 \\\\\n&\n+\n5.1915 \\cdot x_3^2\n+\n2.2150 \\cdot x_1 \\cdot x_2\n+\n11.375 \\cdot x_1 \\cdot x_3\n+\n3.875 \\cdot x_2 \\cdot x_3\n\\end{align*}\\] and \\[\\begin{align*}\nf_{\\text{act}}(x) =\n&\n59.85\n+ 3.583 \\cdot x_1\n+ 0.2546 \\cdot x_2\n+ 2.2298 \\cdot x_3\n+ 0.83479 \\cdot x_1^2\n+ 0.07484 \\cdot x_2^2\n\\\\\n&\n+ 0.05716 \\cdot x_3^2\n+ 0.3875 \\cdot x_1 \\cdot x_2\n+ 0.375 \\cdot x_1 \\cdot x_3\n+ 0.3125 \\cdot x_2 \\cdot x_3.\n\\end{align*}\\]\nThey are implemented as Python functions that take a vector of three parameters (reaction time, reaction temperature, and percent catalyst) and return the predicted values for the percent conversion and thermal activity and available in the spotdesirability package.\nThe goal of the analysis in Myers, Montgomery, and Anderson-Cook (2016) was to\n\nmaximize conversion while\nkeeping the thermal activity between 55 and 60 units. An activity target of 57.5 was used in the analysis.\n\nPlots of the response surface models are shown in Figure 56.6 and Figure 56.7, where reaction time and percent catalyst are plotted while the reaction temperature was varied at four different levels. Both quadratic models, as pointed out by Kuhn, are saddle surfaces, and the stationary points are outside of the experimental region. To determine predictor settings for these models, a constrained optimization can be used to stay inside the experimental region. Kuhn notes:\n\nIn practice, we would just use the predict method for the linear model objects to get the prediction equation. Our results are slightly different from those given by Myers and Montgomery because they used prediction equations with full floating-point precision.\n\n\n\n56.4.2 Contour Plot Generation\n\n56.4.2.1 Contour Plots for the Response Surface Models\nWe will generate contour plots for the percent conversion and thermal activity models. The contour-plot generation comprehends the following steps:\n\ngenerating a grid of points in the design space and evaluating the response surface models at these points, and\nplotting the contour plots for the response surface models\n\nWe will use the function mo_generate_plot_grid to generate the grid and the function mo_contourf_plots for creating the contour plots for the response surface models. Both functions are available in the spotpython package.\nFirst we define the variables, their ranges, the resolutions for the grid, and the objective functions. The variables dictionary contains the variable names as keys and their ranges as values. The resolutions dictionary contains the variable names as keys and their resolutions as values. The functions dictionary contains the function names as keys and the corresponding functions as values. Next we can generate the Pandas DataFrame plot_grid. It has the columns time, temperature, catalyst, conversionPred, and activityPred.\n\nvariables = {\n    \"time\": (-1.7, 1.7),\n    \"temperature\": (-1.7, 1.7),\n    \"catalyst\": (-1.7, 1.7)\n}\nresolutions = {\n    \"time\": 50,\n    \"temperature\": 4,\n    \"catalyst\": 50\n}\nfunctions = {\n    \"conversionPred\": conversion_pred,\n    \"activityPred\": activity_pred\n}\nplot_grid = mo_generate_plot_grid(variables, resolutions, functions)\n\nFigure 56.6 shows the response surface for the percent conversion model. To plot the model contours, the temperature variable was fixed at four diverse levels. The largest effects in the fitted model are due to the time \\(\\times\\) catalyst interaction and the linear and quadratic effects of catalyst. Figure 56.7 shows the response surface for the thermal activity model. To plot the model contours, the temperature variable was fixed at four diverse levels. The main effects of time and catalyst have the largest effect on the fitted model.\n\ncontourf_plot(\n    plot_grid,\n    x_col=\"time\",\n    y_col=\"catalyst\",\n    z_col=\"conversionPred\",\n    facet_col=\"temperature\",    \n)\n\n\n\n\n\n\n\nFigure 56.6: The response surface for the percent conversion model. To plot the model contours, the temperature variable was fixed at four diverse levels.\n\n\n\n\n\n\ncontourf_plot(\n    plot_grid,\n    x_col=\"time\",\n    y_col=\"catalyst\",\n    z_col=\"activityPred\",\n    facet_col=\"temperature\",\n)\n\n\n\n\n\n\n\nFigure 56.7: The response surface for the thermal activity model. To plot the model contours, the temperature variable was fixed at four diverse levels.\n\n\n\n\n\n\n\n56.4.2.2 Defining the Desirability Functions\nFollowing the steps described in Kuhn (2016), translating the experimental goals to desirability functions, a larger-is-better function (\\(d_r^{\\text{max}}\\)) is used for percent conversion with values \\(A = 80\\) and \\(B = 97\\). A target-oriented desirability function (\\(d_r^{\\text{target}}\\)) was used for thermal activity with \\(t_0 = 57.5\\), \\(A = 55\\), and \\(B = 60\\).\nKuhn emphasizes that to construct the overall desirability functions, objects must be created for the individual functions. In the following, we will use classes of the Python package spotdesirability to create the desirability objects. The spotdesirability package is part of the sequential parameter optimization framework (Bartz-Beielstein 2023). It is available on GitHub [https://github.com/sequential-parameter-optimization/spotdesirability] and on PyPi https://pypi.org/project/spotdesirability and can be installed via pip install spotdesirability.\nThe desirability objects can be created as follows:\n\nconversionD = DMax(80, 97)\nactivityD = DTarget(55, 57.5, 60)\n\nAlthough the original analysis in Myers, Montgomery, and Anderson-Cook (2016) used numerous combinations of scaling parameters, following the presentation in Kuhn (2016), we will only show analyses with the default scaling factor values.\n\nExample 56.1 (Computing Desirability at the Center Point) Using these desirability objects conversionDand activityD, the following code segment shows how to predict the desirability for the center point of the experimental design. The center point is defined as [0, 0, 0].\n\npred_outcomes = [\n    conversion_pred([0, 0, 0]),\n    activity_pred([0, 0, 0])\n]\nprint(\"Predicted Outcomes:\", pred_outcomes)\n\nPredicted Outcomes: [81.09, 59.85]\n\n\n\n# Predict desirability for each outcome\nconversion_desirability = conversionD.predict(pred_outcomes[0])\nactivity_desirability = activityD.predict(pred_outcomes[1])\nprint(\"Conversion Desirability:\", conversion_desirability)\nprint(\"Activity Desirability:\", activity_desirability)\n\nConversion Desirability: [0.06411765]\nActivity Desirability: [0.06]\n\n\nSimilar to the implementation in Kuhn (2016), to get the overall score for these settings of the experimental factors, the dOverall function is used to combine the objects and predict is used to get the final score. The print_class_attributes method prints the class attributes of the DOverall object.\n\noverallD = DOverall(conversionD, activityD)\noverallD.print_class_attributes()\n\n\nClass: DOverall\nd_objs: [\n\n  Class: DMax\n  low: 80\n  high: 97\n  scale: 1\n  tol: None\n  missing: 0.5\n\n  Class: DTarget\n  low: 55\n  target: 57.5\n  high: 60\n  low_scale: 1\n  high_scale: 1\n  tol: None\n  missing: 0.4949494949494951\n]\n\n\nNote: The attribute missing is explained in Section 56.2.3.1.\nFinally, we can print the overall desirability for the center point of the experimental design.\n\n#] echo: true\noverall_desirability = overallD.predict(pred_outcomes, all=True)\nprint(\"Conversion Desirability:\", overall_desirability[0][0])\nprint(\"Activity Desirability:\", overall_desirability[0][1])\nprint(\"Overall Desirability:\", overall_desirability[1])\n\nConversion Desirability: [0.06411765]\nActivity Desirability: [0.06]\nOverall Desirability: [0.06202466]\n\n\n\n\n\n56.4.2.3 Generating the Desirability DataFrame\nA DataFrame d_values_df is created to store the individual desirability values for each outcome, and the overall desirability value is added as a new column. First, we predict desirability values and extract the individual and overall desirability values.\nNote: The all=True argument indicates that both individual and overall desirability values should be returned.\nWe add the individual and overall desirability values to the plot_grid DataFrame, that was created earlier in Section 56.4.2.\n\nd_values = overallD.predict(plot_grid.iloc[:, [3, 4]].values, all=True)\nindividual_desirabilities = d_values[0]\noverall_desirability = d_values[1]\nd_values_df = pd.DataFrame(individual_desirabilities).T  \nd_values_df.columns = [\"D1\", \"D2\"]\nd_values_df[\"Overall\"] = overall_desirability\nplot_grid = pd.concat([plot_grid, d_values_df], axis=1)\n\n\n\n56.4.2.4 Contour Plots for the Desirability Surfaces\nWe will use spotpython’s contourf_plot function to create the contour plots for the individual desirability surfaces and the overall desirability surface. The plot_grid DataFrame contains the predicted values for the conversion and activity models, which are used to create the contour plots.\nFigure 56.8, Figure 56.9, and Figure 56.10 show contour plots of the individual desirability function surfaces and the overall surface. These plots are in correspondence with the figures in Kuhn (2016), but the color schemes are different. The plot_grid DataFrame contains the predicted values for the conversion and activity models, which are used to create the contour plots.\nThe individual desirability surface for the percent conversion outcome is shown in Figure 56.8 and the individual desirability surface for the thermal activity outcome is shown in Figure 56.9. Finally, the overall desirability surface is shown in Figure 56.10.\n\ncontourf_plot(\n    data=plot_grid,\n    x_col='time',\n    y_col='catalyst',\n    z_col='D1',\n    facet_col='temperature',\n    aspect=1,\n    as_table=True,\n    figsize=(3,3)    \n)\n\n\n\n\n\n\n\nFigure 56.8: The individual desirability surface for the percent conversion outcome using dMax(80, 97)\n\n\n\n\n\n\ncontourf_plot(\n    data=plot_grid,\n    x_col='time',\n    y_col='catalyst',\n    z_col='D2',\n    facet_col='temperature',\n    aspect=1,\n    as_table=True,\n    figsize=(3,3)\n)\n\n\n\n\n\n\n\nFigure 56.9: The individual desirability surface for the thermal activity outcome using dTarget(55, 57.5, 60)\n\n\n\n\n\n\ncontourf_plot(\n    data=plot_grid,\n    x_col='time',\n    y_col='catalyst',\n    z_col='Overall',\n    facet_col='temperature',\n    aspect=1,\n    as_table=True,\n    figsize=(3,3)\n)\n\n\n\n\n\n\n\nFigure 56.10: The overall desirability surface for the combined outcomes of percent conversion and thermal activity",
    "crumbs": [
      "Multi Objective Optimization",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Introduction to Desirability Functions</span>"
    ]
  },
  {
    "objectID": "bart25a-desirability-latest.html#sec-maximizing-desirability",
    "href": "bart25a-desirability-latest.html#sec-maximizing-desirability",
    "title": "56  Introduction to Desirability Functions",
    "section": "56.5 Multi-Objective Optimization and Maximizing Desirability",
    "text": "56.5 Multi-Objective Optimization and Maximizing Desirability\nKuhn indicates that as described by Myers, Montgomery, and Anderson-Cook (2016), desirability can be maximized within a cuboidal region defined by the axial point values. The objective function (rsmOpt) utilizes a penalty approach: if a candidate point extends beyond the cuboidal design region, desirability is set to zero. These penalties are implemented in the rsm_opt function, which is used to optimize the desirability function. An \\(\\alpha\\) value of 1.682 (\\(\\approx (2^k)^(1/4)\\) with \\(k=3\\) in our case), see Montgomery (2001), is used as the limit for both circular and square spaces. After checking the bounds, predictions for all provided functions are calculated, and the overall desirability is predicted using the predict method of the DOverall object. The negative desirability is returned to maximize the desirability function.\n\ndef rsm_opt(x, d_object, prediction_funcs, space=\"square\", alpha=1.682) -&gt; float:\n    if space == \"circular\":\n        if np.sqrt(np.sum(np.array(x) ** 2)) &gt; alpha:\n            return 0.0\n    elif space == \"square\":\n        if np.any(np.abs(np.array(x)) &gt; alpha):\n            return 0.0\n    else:\n        raise ValueError(\"space must be 'square' or 'circular'\")\n    predictions = [func(x) for func in prediction_funcs]\n    desirability = d_object.predict(np.array([predictions]))\n    return -desirability\n\nNote: Instead of using the penatlty approach, alternatively the desirability function for box-constraints can be used, see Section 56.2.3.3.2. Furthermore, scipy.optimize provides a bounds argument for some optimizers to restrict the search space.\nKuhn (2016) used R’s optim function to implement the Nelder-Mead simplex method (Nelder and Mead 1965; Olsson and Nelson 1975). This direct search method relies on function evaluations without using gradient information. Although this method may converge to a local optimum, it is fast with efficient functions, allowing for multiple feasible region restarts to find the best result. Alternatively, methods like simulated annealing (Bohachevsky 1986), also available in R’s optim function, might better suit global optimum searches, though they might need parameter tuning for effective performance. We will use the scipy.optimize.minimize function to implement the Nelder-Mead simplex method in Python.\nPutting the pieces together, the following code segment shows how to create the desirability objects and use them in the optimization process. First, a search_grid is created using numpy’s meshgrid function to generate a grid of restarts points in the design space. For each (restart) point in the search grid, the rsm_opt function is called to calculate the desirability for that point. The conversion_pred and activity_pred functions are used as prediction functions, and the DOverall object is created using the individual desirability objects for conversion and activity. The overallD (overall desirability) is passed to tne rsm_opt function. The minimize function from scipy.optimize is used to find the optimal parameters that minimize the negative desirability.\n\ntime = np.linspace(-1.5, 1.5, 5)\ntemperature = np.linspace(-1.5, 1.5, 5)\ncatalyst = np.linspace(-1.5, 1.5, 5)\n\nsearch_grid = pd.DataFrame(\n    np.array(np.meshgrid(time, temperature, catalyst)).T.reshape(-1, 3),\n    columns=[\"time\", \"temperature\", \"catalyst\"]\n)\n\n# List of prediction functions\nprediction_funcs = [conversion_pred, activity_pred]\n\n# Individual desirability objects\nconversionD = DMax(80, 97)\nactivityD = DTarget(55, 57.5, 60)\n\n# Desirability object (DOverall)\noverallD = DOverall(conversionD, activityD)\n\n# Initialize the best result\nbest = None\n\n# Perform optimization for each point in the search grid\nfor i, row in search_grid.iterrows():\n    initial_guess = row.values  # Initial guess for optimization\n\n    # Perform optimization using scipy's minimize function\n    result = minimize(\n        rsm_opt,\n        initial_guess,\n        args=(overallD, prediction_funcs, \"square\"), \n        method=\"Nelder-Mead\",\n        options={\"maxiter\": 1000, \"disp\": False}\n    )\n\n    # Update the best result if necessary\n    # Compare based on the negative desirability\n    if best is None or result.fun &lt; best.fun:\n        best = result\nprint(\"Best Parameters:\", best.x)\nprint(\"Best Desirability:\", -best.fun)\n\nBest Parameters: [-0.51207663  1.68199987 -0.58609664]\nBest Desirability: 0.9425092694688632\n\n\nUsing these best parameters, the predicted values for conversion and activity can be calculated as follows:\n\nprint(f\"Conversion pred(x): {conversion_pred(best.x)}\")\nprint(f\"Activity pred(x): {activity_pred(best.x)}\")\n\nConversion pred(x): 95.10150374903237\nActivity pred(x): 57.49999992427212\n\n\nWe extract the best temperature from the best parameters and remove it from the best parameters for plotting. The best.x array contains the best parameters found by the optimizer, where the second element corresponds to the temperature variable.\n\nbest_temperature = best.x[1]\nbest_point = np.delete(best.x, 1)\n\nThen we set the values of temperature to the best temperature in the plot_grid_df and recalculate the predicted values for conversion and activity using the conversion_pred and activity_pred functions. A copy of the plot_grid DataFrame is created, and the temperature column is updated with the best temperature value.\n\nplot_grid_best = plot_grid.copy()\nplot_grid_best[\"temperature\"] = best_temperature\nplot_grid_best[\"conversionPred\"] = conversion_pred(plot_grid_best[[\"time\",\n     \"temperature\", \"catalyst\"]].values.T)\nplot_grid_best[\"activityPred\"] = activity_pred(plot_grid_best[[\"time\",\n    \"temperature\", \"catalyst\"]].values.T)\n\nNow we are ready to plot the response surfaces for the best parameters found by the optimizer. The contourf_plot function is used to create the contour plots for the response surface models. The highlight_point argument is used to highlight the best point found by the optimizer in the contour plots. First, the response surface for the percent conversion model is plotted. The temperature variable is fixed at the best value found by the optimizer, see Figure 56.11.\n\ncontourf_plot(\n    plot_grid_best,\n    x_col=\"time\",\n    y_col=\"catalyst\",\n    z_col=\"conversionPred\",\n    facet_col=\"temperature\",\n    highlight_point=best_point,\n)\n\n\n\n\n\n\n\nFigure 56.11: The response surface for the percent conversion model. To plot the model contours, the temperature variable was fixed at the best value found by the optimizer.\n\n\n\n\n\nSecond, the response surface for the thermal activity model is plotted. The temperature variable is fixed at the best value found by the optimizer, see Figure 56.12.\n\ncontourf_plot(\n    plot_grid_best,\n    x_col=\"time\",\n    y_col=\"catalyst\",\n    z_col=\"activityPred\",\n    facet_col=\"temperature\",\n    highlight_point=best_point,\n)\n\n\n\n\n\n\n\nFigure 56.12: The response surface for the thermal activity model. To plot the model contours, the temperature variable was fixed at the best value found by the optimizer.\n\n\n\n\n\n\n\n\n\n\n\nAnalysing the Best Values From the Nelder-Mead Optimizer\n\n\n\n\nObjective function values for the best parameters found by the optimizer are:\n\nconversion = 95.1\nactivity = 57.5\n\nThe best value for the percent conversion should be maximized, as defined in conversionD = DMax(80, 97). Here, we have obtained a value of 95.1, which is close to the maximum value of 97.\nSince we are using the desirabilty function DTarget, the values for the thermal activity should not be maximized, but should be close to the target. The setting activityD = DTarget(55, 57.5, 60), as defined in Section 56.4.2.2, states that the best value for the thermal activity should be close to 57.5 as specified by the user (and not at its maximum). Here, we have obtained a value of 57.5, which is exactly the target value.\n\n\n\nAn alternative approach to the optimization process is to use a circular design region instead of a cuboidal design region can be found in the Appendix.",
    "crumbs": [
      "Multi Objective Optimization",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Introduction to Desirability Functions</span>"
    ]
  },
  {
    "objectID": "bart25a-desirability-latest.html#sec-surrogate",
    "href": "bart25a-desirability-latest.html#sec-surrogate",
    "title": "56  Introduction to Desirability Functions",
    "section": "56.6 Surrogate-Model Based Optimization Using Desirability",
    "text": "56.6 Surrogate-Model Based Optimization Using Desirability\nspotpython implements a vectorized function fun_myer16a() that computes the two objective functions for conversion and activity. To illustrate the vectorized evaluation, we will use two input points: the center point of the design space and the best point found by the optimizer from Section 56.5. The fun_myer16a() function takes a 2D array as input, where each row corresponds to a different set of parameters. The function returns a 2D array with the predicted values for conversion and activity.\n\nX = np.array([[0, 0, 0], best.x])\ny = fun_myer16a(X)\nprint(\"Objective function values:\")\nprint(y)\n\nObjective function values:\n[[81.09       59.85      ]\n [95.10150375 57.49999992]]\n\n\nNext, we define the desirability objects. This step is identical to the previous one, where we defined the desirability functions for conversion and activity. The DMax function is used for the conversion function, and the DTarget function is used for the activity function. The DOverall function is used to combine the two desirability functions into an overall desirability function. The DOverall function takes two arguments: the desirability object for conversion and the desirability object for activity.\n\nfrom spotdesirability.utils.desirability import DOverall, DMax, DTarget\nconversionD = DMax(80, 97)\nactivityD = DTarget(55, 57.5, 60)\noverallD = DOverall(conversionD, activityD)\n\n\nconversionD.plot()\n\n\n\n\n\n\n\nFigure 56.13: The desirability function for the conversion outcome.\n\n\n\n\n\n\nactivityD.plot()\n\n\n\n\n\n\n\nFigure 56.14: The desirability function for the activity outcome.\n\n\n\n\n\nPredicting the desirability for each outcome can also be vectorized. The predict method of the desirability objects can take a 2D array as input, where each row corresponds to a different set of parameters. The method returns a 1D array with the predicted desirability values for each set of parameters.\n\nconversion_desirability = conversionD.predict(y[:,0])\nactivity_desirability = activityD.predict(y[:,1])\n\n\nprint(f\"Conversion Desirability: {conversion_desirability}\")\nprint(f\"Activity Desirability: {activity_desirability}\")\n\nConversion Desirability: [0.06411765 0.88832375]\nActivity Desirability: [0.06       0.99999997]\n\n\nThe overall_desirability variable contains the overall desirability values for each set of parameters. The all=True argument indicates that we want to return both the individual desirability values and the overall desirability value.\n\noverall_desirability = overallD.predict(y, all=True)\n\n\nprint(f\"OverallD: {overall_desirability}\")\n\nOverallD: ([array([0.06411765, 0.88832375]), array([0.06      , 0.99999997])], array([0.06202466, 0.94250927]))\n\n\nDuring the surrogate-model based optimization, the argument all is set to False, because spotpython does not need the individual desirability values.\nNow we have introduced all elements needed to perform surrogate-model based optimization using desirability functions and the spotpython package.\n\n\n\n\n\n\nMaximization and Minimization\n\n\n\n\nSince spotpython uses minimization, but desirability should be maximized, fun_desirability is defined to return 1 - overall_desirability.\n\n\n\n\ndef fun_desirability(X, **kwargs):\n    y = fun_myer16a(X)\n    conversionD = DMax(80, 97)\n    activityD = DTarget(55, 57.5, 60)\n    overallD = DOverall(conversionD, activityD)\n    overall_desirability = overallD.predict(y, all=False)\n    return 1.0 - overall_desirability\n\nWe can test the function:\n\nX = np.array([[0, 0, 0], best.x])\ny = fun_desirability(X)\nprint(\"Objective function values:\")\nprint(y)\n\nObjective function values:\n[0.93797534 0.05749073]\n\n\nAs expected, the output contains the two overall “1 minus desirability” function values for the center point of the design space and the best point found by the optimizer.\nWe are now ready to perform the surrogate-model based optimization using desirability functions. The spotpython package provides a class Spot that implements the surrogate-model based optimization algorithm. The Spot class takes the objective function and the control parameters as input. The control parameters define the search space and other settings for the optimization process.\n\nfun_control = fun_control_init(\n              lower = np.array( [-1.7, -1.7, -1.7]),\n              upper = np.array([1.7, 1.7, 1.7]),\n              var_name = [\"time\", \"temperature\", \"catalyst\"],\n              fun_evals= 50\n)\nsurrogate_control = surrogate_control_init(n_theta=3)\ndesign_control=design_control_init(init_size=15)\nS = Spot(fun=fun_desirability,         \n         fun_control=fun_control,\n         surrogate_control=surrogate_control,\n         design_control=design_control)\nS.run()\n\nspotpython tuning: 0.16080910335362375 [###-------] 32.00% \nspotpython tuning: 0.16080910335362375 [###-------] 34.00% \nspotpython tuning: 0.15281120812431714 [####------] 36.00% \nspotpython tuning: 0.15281120812431714 [####------] 38.00% \nspotpython tuning: 0.11242908322548573 [####------] 40.00% \nspotpython tuning: 0.11242908322548573 [####------] 42.00% \nspotpython tuning: 0.06984744743002758 [####------] 44.00% \nspotpython tuning: 0.06984744743002758 [#####-----] 46.00% \nspotpython tuning: 0.060454619901722295 [#####-----] 48.00% \nspotpython tuning: 0.057463170449749246 [#####-----] 50.00% \nspotpython tuning: 0.05575605401032391 [#####-----] 52.00% \nspotpython tuning: 0.053811328711583006 [#####-----] 54.00% \nspotpython tuning: 0.05231885350770027 [######----] 56.00% \nspotpython tuning: 0.05231885350770027 [######----] 58.00% \nspotpython tuning: 0.0515537446788461 [######----] 60.00% \nspotpython tuning: 0.0515537446788461 [######----] 62.00% \nspotpython tuning: 0.0515537446788461 [######----] 64.00% \nspotpython tuning: 0.0515537446788461 [#######---] 66.00% \nspotpython tuning: 0.0515537446788461 [#######---] 68.00% \nspotpython tuning: 0.0515537446788461 [#######---] 70.00% \nspotpython tuning: 0.0515537446788461 [#######---] 72.00% \nspotpython tuning: 0.0515537446788461 [#######---] 74.00% \nspotpython tuning: 0.0515537446788461 [########--] 76.00% \nspotpython tuning: 0.0515537446788461 [########--] 78.00% \nspotpython tuning: 0.0515537446788461 [########--] 80.00% \nspotpython tuning: 0.0515537446788461 [########--] 82.00% \nspotpython tuning: 0.0515537446788461 [########--] 84.00% \nspotpython tuning: 0.0515537446788461 [#########-] 86.00% \nspotpython tuning: 0.0515537446788461 [#########-] 88.00% \nspotpython tuning: 0.0515537446788461 [#########-] 90.00% \nspotpython tuning: 0.0515537446788461 [#########-] 92.00% \nspotpython tuning: 0.0515537446788461 [#########-] 94.00% \nspotpython tuning: 0.0515537446788461 [##########] 96.00% \nspotpython tuning: 0.0515537446788461 [##########] 98.00% \nspotpython tuning: 0.0515537446788461 [##########] 100.00% Done...\n\nExperiment saved to 000_res.pkl\n\n\n&lt;spotpython.spot.spot.Spot at 0x30bf95550&gt;\n\n\nThe progress of the optimization process can be visualized using the plot_progress method (Figure 56.15).\n\nS.plot_progress(log_y=True)\n\n\n\n\n\n\n\nFigure 56.15: The progress of the surrogate-model based optimization using desirability functions. The y-axis is on a logarithmic scale.\n\n\n\n\n\nWe can analyze the results in detail by accessing the attributes of the Spot object directly. The min_X attribute contains the best parameters found by the optimizer, and the min_y attribute contains the best desirability value. First, we take a look at the desirability values for the best parameters found by the optimizer. The min_y attribute contains the best desirability value. Note, we have to compute 1 minus the min_y value, because the fun_desirability function returns 1 - overall_desirability. This results in the following best desirability value:\n\n\nBest Desirability: 0.9484462553211539\n\n\nWe can use the min_X attribute to calculate the predicted values for conversion and activity for the best parameters found by the optimizer. Using the fun_myer16a function, we can calculate these predicted values.\n\nprint(f\"Best Parameters: {S.min_X}\")\nprint(f\"Best Conversion: {best_conversion}\")\nprint(f\"Best Activity: {best_activity}\")\n\nBest Parameters: [-0.58701584  1.7        -0.53228512]\nBest Conversion: 95.29515994576552\nBest Activity: 57.49954154470773\n\n\n\n\n\n\n\n\nAnalysing the Best Values from the spotpython Optimizer\n\n\n\n\nObjective function values for the best parameters found by the optimizer are very close to the values found by the Nelder-Mead optimizer.\n\n\n\nBased on the information from the surrogate, which is by default a Kriging model in spotpython, we can analyze the importance of the parameters in the optimization process. The plot_importance method plots the importance of each parameter, see Figure 56.16.\n\n\n\n\n\n\n\n\nFigure 56.16: The importance of the parameters in the optimization process\n\n\n\n\n\nThe plot_important_hyperparameter_contour method plots the contour plots for the important parameters. The results are shown in Figure 56.17. The contour plots show the importance of the parameters in the optimization process, which tries to minimize the 1 minus desirability values. Regions with low values present high desirability. Note: These surface plots illustrate how the Kriging surrogate “sees the world” and decides where to sample next. The Kriging model computes the following importance values:\n\n\ntime:  100.00000000000001\ntemperature:  2.8977946407851523\ncatalyst:  99.11238108829903\n\n\n\n\n\n\n\n\n\n\n\n(a) The contour plots for the important parameters\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\n\n\n\n\n(c)\n\n\n\n\n\n\nFigure 56.17\n\n\n\n\nFinally, we show a comparison with the response-surface model. Similar to the procedure above, we generate the plot_grid DataFrame for the response surface models.\n\nbest_x = S.min_X\nbest_point = np.delete(best_x, 1)\nbest_temperature = best_x[1]\n\nvariables = {\n    \"time\": (-1.7, 1.7),\n    \"temperature\": (best_temperature, best_temperature),\n    \"catalyst\": (-1.7, 1.7)\n}\n\nresolutions = {\n    \"time\": 50,\n    \"temperature\": 1,\n    \"catalyst\": 50\n}\n\nfunctions = {\n    \"conversionPred\": conversion_pred,\n    \"activityPred\": activity_pred\n}\n\nplot_grid = mo_generate_plot_grid(variables, resolutions, functions)\n\nUsintg the plot_grid DataFrame, we generate contour plots shown in Figure 56.18 and Figure 56.19. The largest effects in the fitted model are due to the time \\(\\\\times\\) catalyst interaction and the linear and quadratic effects of catalyst. The Figure 56.19 shows the response surface for the thermal activity model. To plot the model contours, the temperature variable was fixed at four diverse levels. The main effects of time and catalyst have the largest effect on the fitted model.\n\ncontourf_plot(\n    plot_grid,\n    x_col=\"time\",\n    y_col=\"catalyst\",\n    z_col=\"conversionPred\",\n    facet_col=\"temperature\",\n    highlight_point=best_point,    \n)\n\n\n\n\n\n\n\nFigure 56.18: The response surface for the percent conversion model. To plot the model contours, the temperature variable was fixed at four diverse levels.\n\n\n\n\n\n\ncontourf_plot(\n    plot_grid,\n    x_col=\"time\",\n    y_col=\"catalyst\",\n    z_col=\"activityPred\",\n    facet_col=\"temperature\",\n    highlight_point=best_point,\n)\n\n\n\n\n\n\n\nFigure 56.19: The response surface for the thermal activity model. To plot the model contours, the temperature variable was fixed at four diverse levels.",
    "crumbs": [
      "Multi Objective Optimization",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Introduction to Desirability Functions</span>"
    ]
  },
  {
    "objectID": "bart25a-desirability-latest.html#sec-hyperparameter-tuning",
    "href": "bart25a-desirability-latest.html#sec-hyperparameter-tuning",
    "title": "56  Introduction to Desirability Functions",
    "section": "56.7 Surrogate Model Hyperparameter Tuning",
    "text": "56.7 Surrogate Model Hyperparameter Tuning\nThis section compares three different approaches to hyperparameter tuning using the spotpython package. The first approach is a single-objective approach, where only the first objective function is used for hyperparameter tuning. The second approach is a weighted multi-objective approach, where a weighted mean of both objective functions is used for hyperparameter tuning. The third approach uses a desirability function to combine the two objective functions into a single objective function. The desirability function is used to maximize the desirability of the two objective functions.\nThe spotpython package provides a method for hyperparameter tuning using a surrogate model. We will extend the single-objective example “Hyperparameter Tuning with spotpython and PyTorch Lightning for the Diabetes Data Set” from the hyperparameter tuning cookbook (Bartz-Beielstein 2023) in the follwoing way:\nInstead of using a single-objective function, which returns the validation loss from the neural-network training, we will use a multi-objective function that returns two objectives:\n\nvalidation loss and\nnumber of epochs.\n\nClearly, both objectives should be minimized. The validation loss should be minimized to get the best model, and the number of epochs should be minimized to reduce the training time. However, if the number of training epochs is too small, the model will not be trained properly. Therefore, we will adopt the desirability function for the number of epochs accordingly.\n\nimport os\nfrom math import inf\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nThe following process can be used for the hyperparameter tuning of the Diabetes data set using the spotpython package. The Diabetes data set is a regression data set that contains 10 input features and a single output feature. The goal is to predict the output feature based on the input features.\nAfter importing the necessary libraries, the fun_control dictionary is set up via the fun_control_init function. The fun_control dictionary contains\n\nPREFIX: a unique identifier for the experiment\nfun_evals: the number of function evaluations\nmax_time: the maximum run time in minutes\ndata_set: the data set. Here we use the Diabetes data set that is provided by spotpython.\ncore_model_name: the class name of the neural network model. This neural network model is provided by spotpython.\nhyperdict: the hyperparameter dictionary. This dictionary is used to define the hyperparameters of the neural network model. It is also provided by spotpython.\n_L_in: the number of input features. Since the Diabetes data set has 10 features, _L_in is set to 10.\n_L_out: the number of output features. Since we want to predict a single value, _L_out is set to 1.\n\nThe HyperLight class is used to define the objective function fun. It connects the PyTorch and the spotpython methods and is provided by spotpython. Details can be found in the hyperparameter tuning cookbook (Bartz-Beielstein 2023) or online https://sequential-parameter-optimization.github.io/Hyperparameter-Tuning-Cookbook/.\n\n56.7.1 The Single-Objective Approach\nThe simplest way for handling multi-objective results is to simply ignore all but the first objective function. This is done by setting the fun_mo2so argument in the fun_control_init function to None. The fun_mo2so argument is used to convert the multi-objective function to a single-objective function. If it is set to None, the first objective function is used as the single-objective function. Since the None is also the default, no argument is needed for the single-objective approach.\n\nPREFIX=\"0000_no_mo\"\ndata_set = Diabetes()\nfun_control = fun_control_init(\n    # do not run, if a result file exists\n    force_run=False,    \n    PREFIX=PREFIX,\n    fun_evals=inf,\n    max_time=10,\n    data_set = data_set,\n    core_model_name=\"light.regression.NNLinearRegressor\",\n    hyperdict=LightHyperDict,\n    _L_in=10,\n    _L_out=1)\nfun = MoHyperLight().fun\n\nmodule_name: light\nsubmodule_name: regression\nmodel_name: NNLinearRegressor\n\n\nThe method set_hyperparameter allows the user to modify default hyperparameter settings. Here we modify some hyperparameters to keep the model small and to decrease the tuning time.\n\nset_hyperparameter(fun_control, \"optimizer\", [ \"Adadelta\", \"Adam\", \"Adamax\"])\nset_hyperparameter(fun_control, \"l1\", [3,4])\nset_hyperparameter(fun_control, \"epochs\", [3,10])\nset_hyperparameter(fun_control, \"batch_size\", [4,11])\nset_hyperparameter(fun_control, \"dropout_prob\", [0.0, 0.025])\nset_hyperparameter(fun_control, \"patience\", [2, 7])\n\ndesign_control = design_control_init(init_size=20)\nprint_exp_table(fun_control)\n\n| name           | type   | default   |   lower |   upper | transform             |\n|----------------|--------|-----------|---------|---------|-----------------------|\n| l1             | int    | 3         |     3   |   4     | transform_power_2_int |\n| epochs         | int    | 4         |     3   |  10     | transform_power_2_int |\n| batch_size     | int    | 4         |     4   |  11     | transform_power_2_int |\n| act_fn         | factor | ReLU      |     0   |   5     | None                  |\n| optimizer      | factor | SGD       |     0   |   2     | None                  |\n| dropout_prob   | float  | 0.01      |     0   |   0.025 | None                  |\n| lr_mult        | float  | 1.0       |     0.1 |  10     | None                  |\n| patience       | int    | 2         |     2   |   7     | transform_power_2_int |\n| batch_norm     | factor | 0         |     0   |   1     | None                  |\n| initialization | factor | Default   |     0   |   4     | None                  |\n\n\nFinally, a Spot object is created. Calling the method run() starts the hyperparameter tuning process.\n\nS = Spot(fun=fun,fun_control=fun_control, design_control=design_control)\nS.run()\n\nResult file 0000_no_mo_res.pkl exists. Loading the result.\nLoaded experiment from 0000_no_mo_res.pkl\n\n\n&lt;spotpython.spot.spot.Spot at 0x30c3747a0&gt;\n\n\nFigure 56.20 shows the hyperparameter tuning process. The loss and epochs are plotted versus the function evaluations. The x-axis shows the number of function evaluations, and the y-axis shows the loss and epochs. The loss is plotted in blue, and the epochs are plotted in red. The y-axis is set to a logarithmic scale for better visualization.\n\nloss = S.y_mo[:, 0]\nepochs = S.y_mo[:, 1]\niterations = np.arange(1, len(loss) + 1)  # Iterations (x-axis)\nplt.figure(figsize=(10, 6))\nplt.plot(iterations, loss, label=\"Loss\", color=\"blue\", marker=\"o\")\nplt.plot(iterations, epochs, label=\"Epochs\", color=\"red\", marker=\"x\")\nplt.xlabel(\"Iterations\")\nplt.ylabel(\"Values\")\nplt.title(\"Loss and Epochs vs. Iterations\")\nplt.yscale(\"log\")\nplt.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\nFigure 56.20: Results of the hyperparameter tuning process. Loss and epochs are plotted versus the function evaluations.\n\n\n\n\n\n\n_ = S.print_results()\n\nmin y: 2965.705078125\nl1: 3.0\nepochs: 9.0\nbatch_size: 6.0\nact_fn: 3.0\noptimizer: 1.0\ndropout_prob: 0.014940301372259645\nlr_mult: 8.554331694855211\npatience: 3.0\nbatch_norm: 0.0\ninitialization: 3.0\n\n\n\n\n\n\n\n\nResults from the Single-Objective Approach\n\n\n\n\nThe single-objective approach reulsted in a validation loss of 2890 and 1024 (\\(=2^{10}\\)) epochs.\n\n\n\n\n\n56.7.2 Weighted Multi-Objective Function\nThe second approach is to use a weighted mean of both objective functions. This is done by setting the fun_mo2so argument in the fun_control_init function to a custom function that computes the weighted mean of both objective functions. The weights can be adjusted to give more importance to one objective function over the other. Here, we define the function aggregate that computes the weighted mean of both objective functions. The first objective function is weighted with 2 and the second objective function is weighted with 0.1.\n\nPREFIX=\"0001_aggregate\"\n\n# Weight first objective with 2, second with 1/10\ndef aggregate(y):\n    import numpy as np\n    return np.sum(y*np.array([2, 0.1]), axis=1)\nfun_control = fun_control_init(\n    # do not run, if a result file exists\n    force_run=False,\n    fun_mo2so=aggregate,\n    PREFIX=PREFIX,\n    fun_evals=inf,\n    max_time=10,\n    data_set = data_set,\n    core_model_name=\"light.regression.NNLinearRegressor\",\n    hyperdict=LightHyperDict,\n    _L_in=10,\n    _L_out=1)\n\nmodule_name: light\nsubmodule_name: regression\nmodel_name: NNLinearRegressor\n\n\nThe remaining code is identical to the single-objective approach. The only difference is that the fun_mo2so argument is set to the aggregate function.\n\nset_hyperparameter(fun_control, \"optimizer\", [ \"Adadelta\", \"Adam\", \"Adamax\"])\nset_hyperparameter(fun_control, \"l1\", [3,4])\nset_hyperparameter(fun_control, \"epochs\", [3,10])\nset_hyperparameter(fun_control, \"batch_size\", [4,11])\nset_hyperparameter(fun_control, \"dropout_prob\", [0.0, 0.025])\nset_hyperparameter(fun_control, \"patience\", [2, 7])\n\ndesign_control = design_control_init(init_size=20)\n\nS = Spot(fun=fun,fun_control=fun_control, design_control=design_control)\nS.run()    \n\nResult file 0001_aggregate_res.pkl exists. Loading the result.\nLoaded experiment from 0001_aggregate_res.pkl\n\n\n&lt;spotpython.spot.spot.Spot at 0x30c353950&gt;\n\n\n\n_ = S.print_results()\n\nmin y: 5756.735546875\nl1: 4.0\nepochs: 7.0\nbatch_size: 8.0\nact_fn: 2.0\noptimizer: 1.0\ndropout_prob: 0.015182309694564699\nlr_mult: 4.398603126890015\npatience: 4.0\nbatch_norm: 0.0\ninitialization: 2.0\n\n\n\n\n\n\n\n\nResults from the Weighted Multi-Objective Function Approach\n\n\n\n\nThe weighted multi-objective approach reulsted in a validation loss of 5824 and 64 (\\(=2^{6}\\)) epochs.\nAlthough the number of epochs is smaller than in the single-objective approach, the validation loss is larger.\nThis is an inherent problem of weighted multi-objective approaches, because the deteriination of “good” weights is non-trivial.\n\n\n\n\n\n56.7.3 Multi-Objective Hyperparameter Tuning With Desirability\n\n56.7.3.1 Setting Up the Desirability Function\nThe third approach is to use a desirability function to combine the two objective functions into a single objective function. The desirability function is used to maximize the desirability of the two objective functions. The desirability function is defined in the fun_control_init function by setting the fun_mo2so argument to a custom function that computes the desirability of both objective functions. The desirability function is defined in the following code segment.\n\nPREFIX=\"0002\"\ndata_set = Diabetes()\nfun = MoHyperLight().fun\n\n\ndef desirability(y):\n    from spotdesirability.utils.desirability import DOverall, DMin\n    lossD = DMin(10, 6000)\n    epochsD = DMin(32, 64)\n    overallD = DOverall(lossD, epochsD)\n    overall_desirability = overallD.predict(y, all=False)\n    return 1.0 - overall_desirability\n\n\nlossD = DMin(10, 6000)\nlossD.plot(xlabel=\"loss\", ylabel=\"desirability\")\n\n\n\n\n\n\n\nFigure 56.21: The desirability function for the loss outcome.\n\n\n\n\n\n\nepochsD = DMin(32, 64)\nepochsD.plot(xlabel=\"epochs\", ylabel=\"desirability\")\n\n\n\n\n\n\n\nFigure 56.22: The desirability function for the epochs outcome.\n\n\n\n\n\nNote: We have chosen simple desirability functions based on DMin for the validation loss and number of epochs. The usage of these functions might result in large plateaus where the optimizer does not find any improvement. Therefore, we will explore more sophisticated desirability functions in the future. These can easily be implemented with the approach shown in {Section 56.2.3.3.1}.\n\nfun_control = fun_control_init(\n    # do not run, if a result file exists\n    force_run=False,\n    fun_mo2so=desirability,\n    device=\"cpu\",\n    PREFIX=PREFIX,\n    fun_evals=inf,\n    max_time=10,\n    data_set = data_set,\n    core_model_name=\"light.regression.NNLinearRegressor\",\n    hyperdict=LightHyperDict,\n    _L_in=10,\n    _L_out=1)\n\nset_hyperparameter(fun_control, \"optimizer\", [ \"Adadelta\", \"Adam\", \"Adamax\"])\nset_hyperparameter(fun_control, \"l1\", [3,4])\nset_hyperparameter(fun_control, \"epochs\", [3,10])\nset_hyperparameter(fun_control, \"batch_size\", [4,11])\nset_hyperparameter(fun_control, \"dropout_prob\", [0.0, 0.025])\nset_hyperparameter(fun_control, \"patience\", [2, 7])\n\ndesign_control = design_control_init(init_size=20)\n\nS = Spot(fun=fun,fun_control=fun_control, design_control=design_control)\nS.run()    \n\nmodule_name: light\nsubmodule_name: regression\nmodel_name: NNLinearRegressor\nResult file 0002_res.pkl exists. Loading the result.\nLoaded experiment from 0002_res.pkl\n\n\n&lt;spotpython.spot.spot.Spot at 0x30c4febd0&gt;\n\n\n\n_ = S.print_results()\n\nmin y: 0.26662821493965283\nl1: 4.0\nepochs: 5.0\nbatch_size: 7.0\nact_fn: 2.0\noptimizer: 1.0\ndropout_prob: 0.0\nlr_mult: 4.341547337583857\npatience: 6.0\nbatch_norm: 0.0\ninitialization: 2.0\n\n\n\nprint(f\"S.y_mo.shape: {S.y_mo.shape}\")\nprint(f\"min loss: {np.nanmin(S.y_mo[:,0]):.2f}\")\nprint(f\"min epochs: {np.nanmin(S.y_mo[:,1])}\")\n# print unique values of S.y_mo[:,1]\nprint(f\"unique epochs values: {np.unique(S.y_mo[:,1])}\")\n\nS.y_mo.shape: (113, 2)\nmin loss: 2778.37\nmin epochs: 8.0\nunique epochs values: [   8.   16.   32.   64.  128.  256.  512. 1024.]\n\n\n\n\n\n\n\n\nResults from the Desirability Function Approach\n\n\n\n\nThe desirability multi-objective approach reulsted in a validation loss of 2960 and 32 (\\(=2^{5}\\)) epochs.\nThe number of epochs is much smaller than in the single-objective approach, and the validation loss is in a similar range.\nThis illustrates the applicability of desirability functions for multi-objective optimization.\n\n\n\n\n\n56.7.3.2 Pareto Front\nThe following two figures show the Pareto front for the multi-objective optimization problem. Figure 56.23 shows the Pareto front for the multi-objective optimization problem. The y-axis uses a logarithmic scal. Figure 56.24 shows the Pareto front for the multi-objective optimization problem. The points with loss &gt; 1e5 are removed from the plot (due to this removal, the indices of the pointsin the plot change). The x-axis uses a double-logarithmic scale, whereas the y-axis is set to a logarithmic scale for better visualization.\nThe best point has the following values:\n\n# generate a dataframe with S.y and S.y_mo\ndf = pd.DataFrame(S.y_mo, columns=[\"loss\", \"epochs\"])\ndf[\"y\"] = S.y\ndf_min = df.loc[df[\"y\"].idxmin()]\nprint(f\"min y: {df_min['y']}\")\nprint(f\"loss: {df_min['loss']}\")\nprint(f\"epochs: {df_min['epochs']}\")\nbest_point = np.array([df_min[\"loss\"], df_min[\"epochs\"]])\nprint(f\"best_point: {best_point}\")\n\nmin y: 0.26662821493965283\nloss: 2778.373291015625\nepochs: 32.0\nbest_point: [2778.37329102   32.        ]\n\n\n\ny_orig = S.y_mo\ndf_z = pd.DataFrame(y_orig, columns=[\"loss\", \"epochs\"])\ndf_z_sel = df_z.dropna()\ntarget_names = [\"loss (log-log)\", \"epochs\"]\ncombinations=[(0,1)]\nplot_mo(y_orig=df_z_sel, target_names=target_names, combinations=combinations, pareto=\"min\", pareto_front_orig=True, title=\"Pareto front (minimization)\", pareto_label=True, x_axis_transformation=\"loglog\")\n\n\n\n\n\n\n\nFigure 56.23: Pareto front for the multi-objective optimization problem.\n\n\n\n\n\n\n# remove loss values larger than 1e5 from the y_orig array\ny_orig = S.y_mo\ndf_z = pd.DataFrame(y_orig, columns=[\"loss\", \"epochs\"])\n# remove rows with loss &gt; 1e5\ndf_z = df_z[df_z[\"loss\"] &lt; 1e5]\ndf_z_sel = df_z.dropna()\ntarget_names = [\"loss\", \"epochs (log)\"]\ncombinations=[(0,1)]\nplot_mo(y_orig=df_z_sel, target_names=target_names, combinations=combinations, pareto=\"min\", pareto_front_orig=True, title=\"Pareto front (min). Points with loss &gt; 1e5 removed\", pareto_label=True, y_axis_transformation=\"log\")\n\n\n\n\n\n\n\nFigure 56.24: Pareto front for the multi-objective optimization problem. Points with loss &gt; 1e5 removed. The Pareto points are identical to the points in the previous plot. Their indices changed due to the removal of points.",
    "crumbs": [
      "Multi Objective Optimization",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Introduction to Desirability Functions</span>"
    ]
  },
  {
    "objectID": "bart25a-desirability-latest.html#sec-conclusion",
    "href": "bart25a-desirability-latest.html#sec-conclusion",
    "title": "56  Introduction to Desirability Functions",
    "section": "56.8 Conclusion",
    "text": "56.8 Conclusion\nIn this article, we have shown how to use the spotdesitability package to perform three different multi-objective optimization tasks using desirability functions: RSM (Myers, Montgomery, and Anderson-Cook 2016), surrogate model based optimization (Santner, Williams, and Notz 2003), and hyperparameter tuning (Bartz et al. 2022). The spotdesirability package is a Python implementation of the R desirability package (Kuhn 2016). We have demonstrated how to define desirability functions for different types of objectives, including maximization, minimization, and target objectives.\nAlthough the desirability function approach is one of the most widely used methods in industry for the optimization of multiple response processes (“NIST/SEMATECH e-Handbook of Statistical Methods” 2021), it is rarely used in hyperparameter tuning. To fill this gap, we have shown how to use the spotdesirability package in combination with the spotpython package to perform hyperparameter tuning using desirability functions. The spotpython package provides a convenient way to perform surrogate model based optimization, and the spotdesirability package allows us to define desirability functions for different types of objectives. First results are promising, but more research is needed to evaluate the performance of the desirability function approach in hyperparameter tuning.",
    "crumbs": [
      "Multi Objective Optimization",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Introduction to Desirability Functions</span>"
    ]
  },
  {
    "objectID": "bart25a-desirability-latest.html#appendix",
    "href": "bart25a-desirability-latest.html#appendix",
    "title": "56  Introduction to Desirability Functions",
    "section": "56.9 Appendix",
    "text": "56.9 Appendix\n\n56.9.1 Alternative Optimization Approach Using a Circular Design Region\nKuhn also suggests alternatively maximizing desirability such that experimental factors are constrained within a spherical design region with a radius equivalent to the axial point distance:\n\n# Initialize the best result\nbest = None\n\n# Perform optimization for each point in the search grid\nfor i, row in search_grid.iterrows():\n    initial_guess = row.values  # Initial guess for optimization\n\n    # Perform optimization using scipy's minimize function\n    result = minimize(\n        rsm_opt,\n        initial_guess,\n        args=(overallD, prediction_funcs, \"circular\"), \n        method=\"Nelder-Mead\",\n        options={\"maxiter\": 1000, \"disp\": False}\n    )\n\n    # Update the best result if necessary\n    # Compare based on the negative desirability\n    if best is None or result.fun &lt; best.fun:  \n        best = result\nprint(\"Best Parameters:\", best.x)\nprint(\"Best Desirability:\", -best.fun)\n\nBest Parameters: [-0.50970524  1.50340746 -0.55595672]\nBest Desirability: 0.8581520815997857\n\n\nUsing these best parameters, the predicted values for conversion and activity can be calculated as follows:\n\nprint(f\"Conversion pred(x): {conversion_pred(best.x)}\")\nprint(f\"Activity pred(x): {activity_pred(best.x)}\")\n\nConversion pred(x): 92.51922540231372\nActivity pred(x): 57.499999903209876\n\n\n\nbest_temperature = best.x[1]\n# remove the temperature variable from the best parameters\nbest_point = np.delete(best.x, 1)\n# set the values of temperature to the best temperature in the df\n# and recalculate the predicted values\nplot_grid_best = plot_grid.copy()\nplot_grid_best[\"temperature\"] = best_temperature\n# Recalculate the predicted values for conversion and activity\nplot_grid_best[\"conversionPred\"] = conversion_pred(plot_grid_best[[\"time\",\n     \"temperature\", \"catalyst\"]].values.T)\nplot_grid_best[\"activityPred\"] = activity_pred(plot_grid_best[[\"time\",\n    \"temperature\", \"catalyst\"]].values.T)\n\n\ncontourf_plot(\n    plot_grid_best,\n    x_col=\"time\",\n    y_col=\"catalyst\",\n    z_col=\"conversionPred\",\n    facet_col=\"temperature\",\n    highlight_point=best_point,\n)\n\n\n\n\n\n\n\nFigure 56.25: The response surface for the percent conversion model. To plot the model contours, the temperature variable was fixed at the best value found by the optimizer.\n\n\n\n\n\n\ncontourf_plot(\n    plot_grid_best,\n    x_col=\"time\",\n    y_col=\"catalyst\",\n    z_col=\"activityPred\",\n    facet_col=\"temperature\",\n    highlight_point=best_point,\n)\n\n\n\n\n\n\n\nFigure 56.26: The response surface for the thermal activity model. To plot the model contours, the temperature variable was fixed at the best value found by the optimizer.\n\n\n\n\n\nKuhn (2016) comments that the process converges to relative sub-optimual values. He suggests that using a radius of 2 achieves an overall desirability equal to one, even if the solution slightly extrapolates beyond the design region.\n\n\n\n\nBartz, Eva, Thomas Bartz-Beielstein, Martin Zaefferer, and Olaf Mersmann, eds. 2022. Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide. Springer.\n\n\nBartz-Beielstein, Thomas. 2023. “Hyperparameter Tuning Cookbook: A guide for scikit-learn, PyTorch, river, and spotpython.” arXiv e-Prints, July. https://doi.org/10.48550/arXiv.2307.10262.\n\n\nBischl, Bernd, Martin Binder, Michel Lang, Tobias Pielok, Jakob Richter, Stefan Coors, Janek Thomas, et al. 2023. “Hyperparameter Optimization: Foundations, Algorithms, Best Practices, and Open Challenges.” WIREs Data Mining and Knowledge Discovery 13 (2): e1484.\n\n\nBohachevsky, I O. 1986. “Generalized Simulated Annealing for Function Optimization.” Technometrics 28 (3): 209–17.\n\n\nBox, G. E. P., and J. S. Hunter. 1957. “Multi-Factor Experimental Designs for Exploring Response Surfaces.” The Annals of Mathematical Statistics 28 (1): 195–241.\n\n\nBox, G. E. P., and K. B. Wilson. 1951. “On the Experimental Attainment of Optimum Conditions.” Journal of the Royal Statistical Society. Series B (Methodological) 13 (1): 1–45.\n\n\nCoello, Carlos A. Coello, Silvia González Brambila, Josué Figueroa Gamboa, and Ma. Guadalupe Castillo Tapia. 2021. “Multi-Objective Evolutionary Algorithms: Past, Present, and Future.” In, edited by Panos M. Pardalos, Varvara Rasskazova, and Michael N. Vrahatis, 137–62. Cham: Springer International Publishing.\n\n\nDel Castillo, E., D. C. Montgomery, and D. R. McCarville. 1996. “Modified Desirability Functions for Multiple Response Optimization.” Journal of Quality Technology 28: 337–45.\n\n\nDerringer, G., and R. Suich. 1980. “Simultaneous Optimization of Several Response Variables.” Journal of Quality Technology 12: 214–19.\n\n\nEmmerich, Michael T. M., and AndréH. Deutz. 2018. “A Tutorial on Multiobjective Optimization: Fundamentals and Evolutionary Methods.” Natural Computing 17 (3): 585–609.\n\n\nForrester, Alexander, András Sóbester, and Andy Keane. 2008. Engineering Design via Surrogate Modelling. Wiley.\n\n\nGramacy, Robert B. 2020. Surrogates. CRC press.\n\n\nHarington, J. 1965. “The Desirability Function.” Industrial Quality Control 21: 494–98.\n\n\nKarl, Florian, Tobias Pielok, Julia Moosbauer, Florian Pfisterer, Stefan Coors, Martin Binder, Lennart Schneider, et al. 2023. “Multi-Objective Hyperparameter Optimization in Machine Learning—an Overview.” ACM Trans. Evol. Learn. Optim. 3 (4).\n\n\nKuhn, Max. 2016. “Desirability: Function Optimization and Ranking via Desirability Functions.”\n\n\nMontgomery, D C. 2001. Design and Analysis of Experiments. 5th ed. New York NY: Wiley.\n\n\nMyers, Raymond H, Douglas C Montgomery, and Christine M Anderson-Cook. 2016. Response Surface Methodology: Process and Product Optimization Using Designed Experiments. John Wiley & Sons.\n\n\nNelder, J. A., and R. Mead. 1965. “A Simplex Method for Function Minimization.” The Computer Journal 7 (4): 308–13.\n\n\nNino, Esmeralda, Juan Rosas Rubio, Samuel Bonet, Nazario Ramirez-Beltran, and Mauricio Cabrera-Rios. 2015. “Multiple Objective Optimization Using Desirability Functions for the Design of a 3D Printer Prototype.” In.\n\n\n“NIST/SEMATECH e-Handbook of Statistical Methods.” 2021.\n\n\nOlsson, Donald M, and Lloyd S Nelson. 1975. “The Nelder-Mead Simplex Procedure for Function Minimization.” Technometrics 17 (1): 45–51.\n\n\nSantner, T J, B J Williams, and W I Notz. 2003. The Design and Analysis of Computer Experiments. Berlin, Heidelberg, New York: Springer.\n\n\nWeihe, Karsten, Ulrik Brandes, Annegret Liebers, Matthias Mı̈ ller-Hannemann, Dorothea Wagner, and Thomas Willhalm. 1999. “Empirical Design of Geometric Algorithms.” In SCG ’99: Proceedings of the Fifteenth Annual Symposium on Computational Geometry, 86–94. New York NY: Association for Computing Machinery.",
    "crumbs": [
      "Multi Objective Optimization",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Introduction to Desirability Functions</span>"
    ]
  },
  {
    "objectID": "de_sampling.html",
    "href": "de_sampling.html",
    "title": "57  Lernmodul: Versuchspläne (Sampling-Plans) für Computerexperimente",
    "section": "",
    "text": "57.1 Einführung\nDieses Dokument beschreibt die grundlegenden Ideen von Versuchsplänen, die in der Konzeption und Analyse von Computerexperimenten verwendet werden. Es stützt sich auf Kapitel 1 aus Forresters Buch “Engineering Design via Surrogate Modelling” (Forrester, Sóbester, und Keane 2008) und Kapitel 4 des “Hyperparameter Tuning Cookbook” (Bartz-Beielstein 2023).\nDefinition: Im Kontext von Computerexperimenten bezieht sich der Begriff Sampling-Plan auf die Menge der Eingabewerte, beispielsweise \\(X\\), an denen der Computercode evaluiert wird.\nDas übergeordnete Ziel eines Sampling-Plans ist es, den Eingaberaum effizient zu erkunden, um das Verhalten eines Computercodes zu verstehen und ein Surrogatmodell zu erstellen, das das Verhalten des Codes genau abbildet. Traditionell wurde die Response Surface Methodology (RSM) zur Gestaltung von Sampling-Plänen für Computerexperimente verwendet, wobei Punkte mittels eines rechteckigen Rasters oder eines faktoriellen Designs generiert wurden.\nIn jüngerer Zeit hat sich jedoch Design and Analysis of Computer Experiments (DACE) als flexiblerer und leistungsfähigerer Ansatz für die Gestaltung von Sampling-Plänen etabliert. Der Prozess umfasst:\nEin Sampling-Plan \\[\nX = \\left\\{ x^{(i)} \\in D | i = 1, \\ldots, n \\right\\}\n\\] bestimmt die räumliche Anordnung der Beobachtungen.",
    "crumbs": [
      "Lernmodule",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Lernmodul: Versuchspläne (Sampling-Plans) für Computerexperimente</span>"
    ]
  },
  {
    "objectID": "de_sampling.html#einführung",
    "href": "de_sampling.html#einführung",
    "title": "57  Lernmodul: Versuchspläne (Sampling-Plans) für Computerexperimente",
    "section": "",
    "text": "Die Abtastung diskreter Beobachtungen.\nDie Verwendung dieser Abtastungen zur Konstruktion einer Approximation \\(\\hat{f}\\).\nDie Sicherstellung, dass das Surrogatmodell wohlformuliert ist, d.h., es ist mathematisch gültig und kann Vorhersagen effektiv verallgemeinern.",
    "crumbs": [
      "Lernmodule",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Lernmodul: Versuchspläne (Sampling-Plans) für Computerexperimente</span>"
    ]
  },
  {
    "objectID": "de_sampling.html#der-fluch-der-dimensionalität",
    "href": "de_sampling.html#der-fluch-der-dimensionalität",
    "title": "57  Lernmodul: Versuchspläne (Sampling-Plans) für Computerexperimente",
    "section": "57.2 Der “Fluch der Dimensionalität”",
    "text": "57.2 Der “Fluch der Dimensionalität”\nEin wesentliches Problem bei der Gestaltung von Sampling-Plänen, insbesondere in hochdimensionalen Räumen, ist der sogenannte “Fluch der Dimensionalität”. Dieses Phänomen beschreibt, wie das Volumen des Eingaberaums exponentiell mit der Anzahl der Dimensionen zunimmt, was es schwierig macht, den Raum ausreichend abzutasten. Wenn eine bestimmte Vorhersagegenauigkeit durch die Abtastung eines eindimensionalen Raums an \\(n\\) Stellen erreicht wird, sind \\(n^k\\) Beobachtungen erforderlich, um die gleiche Abtastdichte in einem \\(k\\)-dimensionalen Raum zu erzielen.\nUm diesem Problem zu begegnen, kann man entweder die Bereiche der Variablen begrenzen, sodass die zu modellierende Form ausreichend einfach ist, um aus sehr spärlichen Daten approximiert zu werden, oder viele Designwerte auf sinnvollen Werten festlegen und jeweils nur mit wenigen Variablen arbeiten.",
    "crumbs": [
      "Lernmodule",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Lernmodul: Versuchspläne (Sampling-Plans) für Computerexperimente</span>"
    ]
  },
  {
    "objectID": "de_sampling.html#entwurf-von-vorab-experimenten-screening",
    "href": "de_sampling.html#entwurf-von-vorab-experimenten-screening",
    "title": "57  Lernmodul: Versuchspläne (Sampling-Plans) für Computerexperimente",
    "section": "57.3 Entwurf von Vorab-Experimenten (Screening)",
    "text": "57.3 Entwurf von Vorab-Experimenten (Screening)\nBevor die Zielfunktion \\(f\\) modelliert wird, ist es entscheidend, die Anzahl der Designvariablen (\\(x_1, x_2, \\dots, x_k\\)) zu minimieren. Dieser Prozess wird als Screening bezeichnet und zielt darauf ab, die Dimensionalität zu reduzieren, ohne die Analyse zu beeinträchtigen. Der Morris-Algorithmus ist hierfür eine beliebte Methode, da er lediglich annimmt, dass die Zielfunktion deterministisch ist.\nMorris’ Methode zielt darauf ab, die Parameter der Verteilung von Elementareffekten zu schätzen, die mit jeder Variablen verbunden sind. Ein großes Maß an zentraler Tendenz (Mittelwert) deutet auf eine Variable mit wichtigem Einfluss auf die Zielfunktion hin, während ein großes Maß an Streuung auf Wechselwirkungen und/oder Nichtlinearität der Funktion in Bezug auf die Variable hinweist.\n\nDefinition 57.1 (Elementareffekt) Für einen gegebenen Basiswert \\(x \\in D\\) bezeichne \\(d_i(x)\\) den Elementareffekt von \\(x_i\\), wobei: \\[\nd_i(x) = \\frac{f(x_1, \\dots, x_i + \\Delta, \\dots, x_k) - f(x_1, \\dots, x_i - \\Delta, \\dots, x_k)}{2\\Delta}, \\quad i = 1, \\dots, k,\n\\] wobei \\(\\Delta\\) die Schrittweite ist, definiert als der Abstand zwischen zwei benachbarten Levels im Raster.\n\nUm die Effizienz zu gewährleisten, sollte der vorläufige Sampling-Plan \\(X\\) so gestaltet sein, dass jede Evaluierung der Zielfunktion \\(f\\) zur Berechnung von zwei Elementareffekten beiträgt. Zusätzlich sollte der Sampling-Plan eine bestimmte Anzahl (z.B. \\(r\\)) von Elementareffekten für jede Variable liefern.\nDie spotpython-Bibliothek bietet eine Python-Implementierung zur Berechnung der Morris-Screening-Pläne. Die Funktion screeningplan() generiert einen Screening-Plan, indem sie die Funktion randorient() \\(r\\)-mal aufruft, um \\(r\\) zufällige Orientierungen zu erstellen.\nEin Beispiel aus dem Hyperparameter-Tuning-Cookbook demonstriert die Analyse der Variablenwichtigkeit für das Aircraft Wing Weight Example.\nimport numpy as np\nfrom spotpython.utils.effects import screeningplan\n\n# Beispielparameter\nk = 3  # Anzahl der Designvariablen (Dimensionen)\np = 3  # Anzahl der Levels im Raster für jede Variable\nxi = 1 # Ein Parameter zur Berechnung der Schrittweite Delta\nr = 25 # Anzahl der Elementareffekte pro Variable\n\n# Generieren des Screening-Plans\nX = screeningplan(k=k, p=p, xi=xi, r=r)\nprint(f\"Form des generierten Screening-Plans: {X.shape}\")\n\n\n\n\n\n\nHinweis\n\n\n\n\nDer Code generiert jedes Mal einen leicht unterschiedlichen Screening-Plan, da er zufällige Orientierungen der Abtastmatrix verwendet*.\n\n\n\nIn der Praxis können durch Screening gewonnene Läufe für den eigentlichen Modellierungsschritt wiederverwendet werden, insbesondere wenn die Zielfunktion sehr teuer zu evaluieren ist. Dies ist am effektivsten, wenn sich Variablen als völlig inaktiv erweisen, doch da dies selten der Fall ist, muss ein Gleichgewicht zwischen der Wiederverwendung teurer Simulationsläufe und der Einführung potenziellen Rauschens in das Modell gefunden werden.",
    "crumbs": [
      "Lernmodule",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Lernmodul: Versuchspläne (Sampling-Plans) für Computerexperimente</span>"
    ]
  },
  {
    "objectID": "de_sampling.html#entwurf-eines-umfassenden-sampling-plans",
    "href": "de_sampling.html#entwurf-eines-umfassenden-sampling-plans",
    "title": "57  Lernmodul: Versuchspläne (Sampling-Plans) für Computerexperimente",
    "section": "57.4 Entwurf eines umfassenden Sampling-Plans",
    "text": "57.4 Entwurf eines umfassenden Sampling-Plans\nZiel ist es, einen Sampling-Plan zu entwerfen, der eine gleichmäßige Verteilung der Punkte gewährleistet, um eine einheitliche Modellgenauigkeit im gesamten Designraum zu erreichen. Ein solcher Plan wird als raumfüllend bezeichnet.\n\n57.4.1 Stratifikation\nDer einfachste Weg, einen Designraum gleichmäßig abzutasten, ist ein rechteckiges Gitter von Punkten, die sogenannte vollfaktorielle Abtasttechnik.\nimport numpy as np\nfrom spotpython.utils.sampling import fullfactorial\n\n# Beispiel: 2D-vollfaktorieller Sampling-Plan\nq = # 3 Levels in Dimension 1, 2 Levels in Dimension 2\nedges = 1 # Punkte sind gleichmäßig von Rand zu Rand verteilt\nX_full_factorial = fullfactorial(q, edges)\nprint(f\"Vollfaktorieller Plan (q={q}, edges={edges}):\\n{X_full_factorial}\")\nprint(f\"Form des vollfaktoriellen Plans: {X_full_factorial.shape}\")\nAllerdings hat dieser Ansatz zwei wesentliche Einschränkungen:\n\nBeschränkte Designgrößen: Die Methode funktioniert nur für Designs, bei denen die Gesamtpunktzahl \\(n\\) als Produkt der Anzahl der Levels in jeder Dimension ausgedrückt werden kann (\\(n = q_1 \\times q_2 \\times \\cdots \\times q_k\\)).\nÜberlappende Projektionen: Wenn die Abtastpunkte auf einzelne Achsen projiziert werden, können sich Punktsätze überlappen, was die Effektivität des Sampling-Plans reduziert und zu einer ungleichmäßigen Abdeckung führen kann.\n\nUm die Gleichmäßigkeit der Projektionen für einzelne Variablen zu verbessern, kann der Bereich dieser Variablen in gleich große “Bins” unterteilt werden, und innerhalb dieser Bins können gleich große zufällige Teilstichproben generiert werden. Dies wird als geschichtete Zufallsstichprobe bezeichnet. Eine Erweiterung dieser Idee auf alle Dimensionen führt zu einem geschichteten Sampling-Plan, der üblicherweise mittels Lateinischer Hyperwürfel-Abtastung (Latin Hypercube Sampling, LHS) implementiert wird.\n\nDefinition 57.2 (Lateinische Quadrate und Hyperwürfel) Im Kontext der statistischen Stichproben ist ein quadratisches Gitter, das Abtastpositionen enthält, ein Lateinisches Quadrat, wenn (und nur wenn) in jeder Zeile und jeder Spalte nur eine Abtastung vorhanden ist. Ein Lateinischer Hyperwürfel ist die Verallgemeinerung dieses Konzepts auf eine beliebige Anzahl von Dimensionen, wobei jede Abtastung die einzige in jeder achsenparallelen Hyperebene ist, die sie enthält.\n\nDas Generieren eines Lateinischen Hyperwürfels führt zu einem randomisierten Sampling-Plan, dessen Projektionen auf die Achsen gleichmäßig verteilt sind (multidimensionale Stratifikation). Dies garantiert jedoch nicht, dass der Plan raumfüllend ist.\n\n\n57.4.2 Maximin-Pläne\nEine weit verbreitete Metrik zur Beurteilung der Gleichmäßigkeit oder “Raumfüllung” eines Sampling-Plans ist die Maximin-Metrik.\n\nDefinition 57.3 (Maximin-Plan) Ein Sampling-Plan \\(X\\) wird als Maximin-Plan betrachtet, wenn er unter allen Kandidatenplänen den kleinsten Zwischenpunktabstand \\(d_1\\) maximiert. Unter den Plänen, die diese Bedingung erfüllen, minimiert er ferner \\(J_1\\), die Anzahl der Paare, die durch diesen minimalen Abstand getrennt sind.\n\nUm die Stratifikationseigenschaften von Lateinischen Hyperwürfeln zu bewahren, konzentriert sich die Anwendung dieser Definition auf diese Klasse von Designs. Um das Problem potenziell mehrerer äquivalenter Maximin-Designs zu lösen, wird eine umfassendere “Tie-Breaker”-Definition nach Morris und Mitchell vorgeschlagen:\n\nDefinition 57.4 (Maximin-Plan mit Tie-Breaker) Ein Sampling-Plan \\(X\\) wird als Maximin-Plan bezeichnet, wenn er sequenziell die folgenden Bedingungen optimiert: Er maximiert \\(d_1\\); unter diesen minimiert er \\(J_1\\); unter diesen maximiert er \\(d_2\\); unter diesen minimiert er \\(J_2\\); und so weiter, bis er \\(J_m\\) minimiert.\n\nFür die Berechnung von Distanzen in diesen Kontexten wird die p-Norm am häufigsten verwendet:\n\nDefinition 57.5 (p-Norm) Die p-Norm eines Vektors \\(\\vec{x} = (x_1, x_2, \\ldots, x_k)\\) ist definiert als: \\[\nd_p(\\vec{x}^{(i_1)}, \\vec{x}^{(i_2)}) = \\left( \\sum_{j=1}^k |x_j^{(i_1)} - x_j^{(i_2)}|^p \\right)^{1/p}.\n\\]\n\nWenn \\(p=1\\), definiert dies die Rechteckdistanz (oder Manhattan-Norm), und wenn \\(p=2\\), die Euklidische Norm. Die Rechteckdistanz ist rechnerisch erheblich weniger aufwendig, was besonders bei großen Sampling-Plänen von Vorteil sein kann.\nDie spotpython Bibliothek bietet Funktionen zur Implementierung dieser Kriterien, wie mm() für paarweise Vergleiche von Sampling-Plänen.\n\n\n57.4.3 Das Morris-Mitchell-Kriterium (Phi_q)\nUm konkurrierende Sampling-Pläne in einer kompakten Form zu bewerten, definierten Morris und Mitchell (1995) die folgende skalarwertige Kriteriumsfunktion, die Morris-Mitchell-Kriterium genannt wird:\n\nDefinition 57.6 (Morris-Mitchell-Kriterium) Das Morris-Mitchell-Kriterium ist definiert als: \\[\n\\Phi_q (X) = \\left(\\sum_{j=1}^m J_j d_j^{-q}\\right)^{1/q},\n\\] wobei \\(X\\) der Sampling-Plan ist, \\(d_j\\) der Abstand zwischen den Punkten, \\(J_j\\) die Vielfachheit dieses Abstands und \\(q\\) ein benutzerdefinierter Exponent ist. Der Parameter \\(q\\) kann angepasst werden, um den Einfluss kleinerer Abstände auf die Gesamtmetrik zu steuern. Ein kleinerer Wert von \\(\\Phi_q\\) deutet auf bessere raumfüllende Eigenschaften des Sampling-Plans hin.\n\nGrößere Werte von \\(q\\) stellen sicher, dass Terme in der Summe, die kleineren Zwischenpunktabständen entsprechen, einen dominanten Einfluss haben, was dazu führt, dass \\(\\Phi_q\\) die Sampling-Pläne in einer Weise ordnet, die der ursprünglichen Maximin-Definition (def-maximin2) sehr genau entspricht. Kleinere \\(q\\)-Werte hingegen erzeugen eine \\(\\Phi_q\\)-Landschaft, die der ursprünglichen Definition zwar nicht perfekt entspricht, aber im Allgemeinen optimierungsfreundlicher ist. Es wird empfohlen, \\(\\Phi_q\\) für eine Reihe von \\(q\\)-Werten (z.B. 1, 2, 5, 10, 20, 50 und 100) zu minimieren und dann den besten Plan aus diesen Ergebnissen anhand der tatsächlichen Maximin-Definition auszuwählen.\nDie Funktionen mmphi() und mmphi_intensive() in spotpython berechnen das Morris-Mitchell-Kriterium, unterscheiden sich jedoch in ihrer Normalisierung. Die mmphi_intensive()-Funktion ist invariant gegenüber der Abtastgröße, da sie die Summe \\(\\sum J_l d_l^{-q}\\) durch \\(M\\) (die Gesamtzahl der Paare, \\(M = N(N-1)/2\\)) teilt, was einen durchschnittlichen Beitrag pro Paar zur \\(-q\\)-ten Potenz des Abstands vor dem Ziehen der \\(q\\)-ten Wurzel berechnet. Dies ermöglicht aussagekräftigere Vergleiche der Raumfüllung zwischen Designs unterschiedlicher Größe. Ein kleinerer Wert zeigt bei beiden Kriterien ein besseres (raumfüllenderes) Design an.\nimport numpy as np\nfrom spotpython.utils.sampling import mmphi, mmphi_intensive, rlh\n\n# Beispiel: Erstellen von zwei Latin Hypercube Designs\nnp.random.seed(42)\nX1 = rlh(n=10, k=2) # 10 Punkte in 2 Dimensionen\nX2 = rlh(n=20, k=2) # 20 Punkte in 2 Dimensionen\n\nq_val = 2.0 # Exponent q\np_val = 2.0 # p-Norm (Euclidean distance)\n\n# Berechne Phi_q für X1 und X2\nphi_q_X1 = mmphi(X1, q_val, p_val)\nphi_q_X2 = mmphi(X2, q_val, p_val)\n\n# Berechne Phi_q_intensive für X1 und X2\nphi_q_intensive_X1 = mmphi_intensive(X1, q_val, p_val)\nphi_q_intensive_X2 = mmphi_intensive(X2, q_val, p_val)\n\nprint(f\"Morris-Mitchell Criterion (Phi_q) für X1 (10 Pts): {phi_q_X1:.3f}\")\nprint(f\"Morris-Mitchell Criterion (Phi_q) für X2 (20 Pts): {phi_q_X2:.3f}\")\nprint(\"-\" * 30)\nprint(f\"Morris-Mitchell Criterion (Phi_q_intensive) für X1 (10 Pts): {phi_q_intensive_X1:.3f}\")\nprint(f\"Morris-Mitchell Criterion (Phi_q_intensive) für X2 (20 Pts): {phi_q_intensive_X2:.3f}\")\nBeobachtung: \\(\\Phi_q\\) steigt tendenziell mit der Anzahl der Punkte (\\(N\\)), während \\(\\Phi_q''\\) (mmphi_intensive) abtastgrößeninvariant ist und daher besser für den Vergleich von Designs unterschiedlicher Größe geeignet ist.",
    "crumbs": [
      "Lernmodule",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Lernmodul: Versuchspläne (Sampling-Plans) für Computerexperimente</span>"
    ]
  },
  {
    "objectID": "de_sampling.html#alternative-sampling-pläne-sobol-sequenzen",
    "href": "de_sampling.html#alternative-sampling-pläne-sobol-sequenzen",
    "title": "57  Lernmodul: Versuchspläne (Sampling-Plans) für Computerexperimente",
    "section": "57.5 Alternative Sampling-Pläne: Sobol-Sequenzen",
    "text": "57.5 Alternative Sampling-Pläne: Sobol-Sequenzen\nWenn die gesamte Rechenzeit budgetiert ist, aber nicht klar ist, wie viele Kandidatendesigns in dieser Zeit evaluiert werden können, bieten sich Sobol-Sequenzen als Alternative an. Diese Sampling-Pläne weisen gute raumfüllende Eigenschaften auf (zumindest für große \\(n\\)) und besitzen die Eigenschaft, dass für jedes \\(n\\) und \\(k &gt; 1\\) die Sequenz für \\(n-1\\) und \\(k\\) eine Untermenge der Sequenz für \\(n\\) und \\(k\\) ist. Aus Sicht der “Raumfüllung” spielt es daher keine Rolle, wann die Zeit abläuft.",
    "crumbs": [
      "Lernmodule",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Lernmodul: Versuchspläne (Sampling-Plans) für Computerexperimente</span>"
    ]
  },
  {
    "objectID": "de_sampling.html#zusammenfassung-und-weiterführende-ressourcen",
    "href": "de_sampling.html#zusammenfassung-und-weiterführende-ressourcen",
    "title": "57  Lernmodul: Versuchspläne (Sampling-Plans) für Computerexperimente",
    "section": "57.6 Zusammenfassung und weiterführende Ressourcen",
    "text": "57.6 Zusammenfassung und weiterführende Ressourcen\nDie Auswahl des richtigen Sampling-Plans ist ein grundlegender Schritt in Computerexperimenten und der Surrogatmodellierung. Von traditionellen RSM-Ansätzen bis hin zu modernen DACE-Methoden, die den “Fluch der Dimensionalität” mildern und effiziente Screenings ermöglichen, entwickeln sich die Techniken ständig weiter. Maximin-Pläne und das Morris-Mitchell-Kriterium bieten robuste Methoden zur Quantifizierung der Raumfüllung, wobei abtastgrößeninvariante Kriterien wie mmphi_intensive() Vergleiche über verschiedene Designgrößen hinweg ermöglichen.\nViele der in diesem Dokument beschriebenen Konzepte sind in den Jupyter Notebooks zum “Hyperparameter Tuning Cookbook” verfügbar und können dort interaktiv erkundet werden. Die Python-Bibliothek spotpython (GitHub Repository) bietet Implementierungen für viele dieser Probenahme- und Optimierungsstrategien.",
    "crumbs": [
      "Lernmodule",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Lernmodul: Versuchspläne (Sampling-Plans) für Computerexperimente</span>"
    ]
  },
  {
    "objectID": "de_sampling.html#zusatzmaterialien",
    "href": "de_sampling.html#zusatzmaterialien",
    "title": "57  Lernmodul: Versuchspläne (Sampling-Plans) für Computerexperimente",
    "section": "57.7 Zusatzmaterialien",
    "text": "57.7 Zusatzmaterialien\n\n\n\n\n\n\nJupyter-Notebook\n\n\n\n\nDas Jupyter-Notebook für dieses Lernmodul ist auf GitHub im Hyperparameter-Tuning-Cookbook Repository verfügbar.\n\n\n\n\n\n\n\nBartz-Beielstein, Thomas. 2023. „Hyperparameter Tuning Cookbook: A guide for scikit-learn, PyTorch, river, and spotpython“. arXiv e-prints, Juli. https://doi.org/10.48550/arXiv.2307.10262.\n\n\nForrester, Alexander, András Sóbester, und Andy Keane. 2008. Engineering Design via Surrogate Modelling. Wiley.",
    "crumbs": [
      "Lernmodule",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Lernmodul: Versuchspläne (Sampling-Plans) für Computerexperimente</span>"
    ]
  },
  {
    "objectID": "de_kriging.html",
    "href": "de_kriging.html",
    "title": "58  Lernmodul: Eine Einführung in Kriging",
    "section": "",
    "text": "58.1 Konzeptionelle Grundlagen des Kriging",
    "crumbs": [
      "Lernmodule",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Lernmodul: Eine Einführung in Kriging</span>"
    ]
  },
  {
    "objectID": "de_kriging.html#konzeptionelle-grundlagen-des-kriging",
    "href": "de_kriging.html#konzeptionelle-grundlagen-des-kriging",
    "title": "58  Lernmodul: Eine Einführung in Kriging",
    "section": "",
    "text": "58.1.1 Von einfachen Modellen zur intelligenten Interpolation\nIn der modernen ingenieur- und naturwissenschaftlichen Forschung werden Praktiker häufig mit „Black-Box“-Funktionen konfrontiert. Dies sind Systeme oder Simulationen, deren interne Funktionsweise entweder unbekannt oder so komplex ist, dass sie praktisch undurchschaubar ist. Ein gängiges Beispiel ist eine hochpräzise Simulation der numerischen Strömungsmechanik (CFD), bei der Eingaben wie die Flügelgeometrie oder die Strömungsgeschwindigkeit Ausgaben wie Auftrieb und Luftwiderstand erzeugen. Jede Auswertung dieser Black Box kann außerordentlich teuer sein und Stunden oder sogar Tage an Supercomputerzeit in Anspruch nehmen. Wenn das Ziel darin besteht, den Designraum zu erkunden oder ein optimales Design zu finden, ist die Durchführung von Tausenden dieser Auswertungen oft nicht durchführbar.\nDiese Herausforderung führt zur Notwendigkeit von Surrogatmodellen, auch bekannt als Metamodelle oder Antwortflächenmodelle “Response-Surface”. Ein Surrogatmodell ist eine rechengünstige Annäherung an eine teure Black-Box-Funktion. Es wird konstruiert, indem eine kleine Anzahl sorgfältig ausgewählter Auswertungen der wahren Funktion durchgeführt und dann ein mathematisches Modell an diese beobachteten Datenpunkte angepasst wird. Dieses „Modell eines Modells“ kann dann Tausende Male zu vernachlässigbaren Kosten ausgewertet werden, was eine effiziente Optimierung, Sensitivitätsanalyse und Erkundung des Designraums ermöglicht.\n\n58.1.1.1 Eine Brücke zum Kriging: Verständnis von Radialen Basisfunktionen (RBFs)\nEine leistungsstarke und intuitive Klasse von Surrogatmodellen ist das Modell der Radialen Basisfunktionen (RBF). Die grundlegende Idee hinter einem RBF ist es, eine komplexe Funktion als gewichtete Summe einfacherer, gut verstandener Basisfunktionen darzustellen. Jede Basisfunktion ist an einem der bekannten Datenpunkte zentriert, und ihr Wert hängt nur vom Abstand zu diesem Zentrum ab.\nMathematisch hat ein RBF-Modell die Form: \\[\n\\hat{f}(\\vec{x}) = \\sum_{i=1}^{n} w_i \\psi(||\\vec{x} - \\vec{c}^{(i)}||)\n\\] wobei \\(\\hat{f}(\\vec{x})\\) der vorhergesagte Wert an einem neuen Punkt \\(\\vec{x}\\) ist, \\(w_i\\) die Gewichte sind, \\(\\vec{c}^{(i)}\\) die Zentren der Basisfunktionen (typischerweise die Standorte der bekannten Datenpunkte, \\(\\vec{x}^{(i)}\\)) und \\(\\psi\\) die radiale Basisfunktion selbst ist, die auf dem euklidischen Abstand \\(||\\vec{x} - \\vec{c}^{(i)}||\\) operiert.\nGängige Wahlen für \\(\\psi\\) umfassen die linearen, kubischen, Gauß’schen oder multiquadratischen Funktionen (Forrester, Sóbester, und Keane 2008). Indem wir fordern, dass das Modell exakt durch alle bekannten Datenpunkte verläuft (ein Prozess, der als Interpolation bezeichnet wird), können wir ein System linearer Gleichungen aufstellen, um die unbekannten Gewichte \\(w_i\\) zu lösen. Dies wird typischerweise in Matrixform geschrieben als: \\[\n\\Psi \\vec{w} = \\vec{y}\n\\] wobei \\(\\Psi\\) eine Matrix der Auswertungen der Basisfunktionen ist, \\(\\vec{w}\\) der Vektor der Gewichte und \\(\\vec{y}\\) der Vektor der beobachteten Antworten ist. Das Lösen nach den Gewichten ist dann eine Frage der Matrixinversion: \\(\\vec{w} = \\Psi^{-1} \\vec{y}\\). Die Schönheit dieses Ansatzes liegt darin, dass er ein potenziell hochgradig nichtlineares Modellierungsproblem in ein unkompliziertes lineares Algebraproblem umwandelt (Forrester, Sóbester, und Keane 2008).\nDiese Struktur weist eine bemerkenswerte Ähnlichkeit mit anderen Modellierungsparadigmen auf. Die RBF-Formulierung ist funktional identisch mit einem einschichtigen künstlichen neuronalen Netz, bei dem die Neuronen eine radiale Aktivierungsfunktion verwenden. In dieser Analogie ist die Eingabe für jedes Neuron der Abstand von einem Zentrum, die Aktivierungsfunktion des Neurons ist die Basisfunktion \\(\\psi\\), und die Ausgabe des Netzwerks ist die gewichtete Summe dieser Aktivierungen. Diese Verbindung bietet ein nützliches mentales Modell für diejenigen, die mit maschinellem Lernen vertraut sind, und rahmt RBFs nicht als esoterische statistische Technik, sondern als nahen Verwandten von neuronalen Netzen ein, die beide leistungsstarke universelle Funktionsapproximatoren sind.\n\n\n58.1.1.2 Einordnung des Kriging\nIn dieser Landschaft tritt das Kriging als eine besonders anspruchsvolle und flexible Art eines RBF-Modells hervor. Ursprünglich aus dem Bereich der Geostatistik durch die Arbeit von Danie G. Krige und Georges Matheron stammend, wurde es entwickelt, um Erzkonzentrationen im Bergbau vorherzusagen (Forrester, Sóbester, und Keane 2008). Seine Anwendung auf deterministische Computerexperimente wurde von Sacks u. a. (1989) vorangetrieben und ist seitdem zu einem Eckpfeiler des Ingenieurdesigns und der Optimierung geworden.\nIm Bereich des maschinellen Lernens ist Kriging besser bekannt als Gauß-Prozess-Regression (GPR). Obwohl sich die Terminologie unterscheidet, ist das zugrunde liegende mathematische Gerüst dasselbe. Kriging unterscheidet sich von einfacheren RBF-Modellen durch seine einzigartige Basisfunktion und seine statistische Grundlage, die nicht nur eine Vorhersage, sondern auch ein Maß für die Unsicherheit dieser Vorhersage liefert.\n\n\n\n58.1.2 Die Kernphilosophie des Kriging: Eine stochastische Prozessperspektive\nUm das Kriging wirklich zu verstehen, muss man einen konzeptionellen Sprung wagen, der zunächst kontraintuitiv sein kann. Selbst bei der Modellierung eines perfekt deterministischen Computercodes – bei dem dieselbe Eingabe immer genau dieselbe Ausgabe erzeugt – behandelt das Kriging die Ausgabe der Funktion als eine einzelne Realisierung eines stochastischen (oder zufälligen) Prozesses.\nDas bedeutet nicht, dass wir annehmen, die Funktion sei zufällig. Stattdessen drücken wir unsere Unsicherheit über den Wert der Funktion an nicht beobachteten Stellen aus. Bevor wir Daten haben, könnte der Wert der Funktion an jedem Punkt alles sein. Nachdem wir einige Punkte beobachtet haben, ist unsere Unsicherheit reduziert, aber sie existiert immer noch überall sonst. Das stochastische Prozessgerüst bietet eine formale mathematische Sprache, um diese Unsicherheit zu beschreiben.\n\n58.1.2.1 Das Prinzip der Lokalität und Korrelation\nDieser angenommene stochastische Prozess ist nicht völlig unstrukturiert. Er wird von einer Korrelationsstruktur bestimmt, die eine grundlegende Annahme über die Welt verkörpert: das Prinzip der Lokalität. Dieses Prinzip besagt, dass Punkte, die im Eingaberaum nahe beieinander liegen, erwartungsgemäß ähnliche Ausgabewerte haben (d. h. sie sind hoch korreliert), während Punkte, die weit voneinander entfernt sind, erwartungsgemäß unähnliche oder unzusammenhängende Ausgabewerte haben (d. h. sie sind unkorreliert). Diese Annahme gilt für die große Mehrheit der physikalischen Phänomene und glatten mathematischen Funktionen, die keine chaotischen, diskontinuierlichen Sprünge aufweisen. Die Korrelation zwischen zwei beliebigen Punkten wird durch eine Kovarianzfunktion oder einen Kernel quantifiziert, der das Herzstück des Kriging-Modells ist.\n\n\n58.1.2.2 Gauß-Prozess-Prior\nSpeziell nimmt das Kriging an, dass dieser stochastische Prozess ein Gauß-Prozess ist. Ein Gauß-Prozess ist eine Sammlung von Zufallsvariablen, von denen jede endliche Anzahl eine gemeinsame multivariate Normalverteilung (MVN) hat. Dies ist eine starke Annahme, da eine multivariate Normalverteilung vollständig durch nur zwei Komponenten definiert ist: einen Mittelwertvektor (\\(\\vec{\\mu}\\)) und eine Kovarianzmatrix (\\(\\Sigma\\)) (Forrester, Sóbester, und Keane 2008).\nDies ist als der Gauß-Prozess-Prior bekannt. Es ist unsere „vorherige Überzeugung“ über die Natur der Funktion, bevor wir Daten gesehen haben. Wir glauben, dass die Funktionswerte an jedem Satz von Punkten gemeinsam gaußverteilt sein werden, zentriert um einen gewissen Mittelwert, mit einer Kovarianzstruktur, die durch den Abstand zwischen den Punkten diktiert wird. Wenn wir Daten beobachten, verwenden wir Bayes’sche Inferenz, um diese vorherige Überzeugung zu aktualisieren, was zu einem Gauß-Prozess-Posterior führt. Dieser Posterior ist ebenfalls ein Gauß-Prozess, aber sein Mittelwert und seine Kovarianz wurden aktualisiert, um mit den beobachteten Daten konsistent zu sein. Der Mittelwert dieses posterioren Prozesses gibt uns die Kriging-Vorhersage, und seine Varianz gibt uns ein Maß für die Unsicherheit über diese Vorhersage. Diese statistische Grundlage ist es, die das Kriging auszeichnet und es ihm ermöglicht, nicht nur zu interpolieren, sondern auch seine eigene Zuverlässigkeit zu quantifizieren.",
    "crumbs": [
      "Lernmodule",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Lernmodul: Eine Einführung in Kriging</span>"
    ]
  },
  {
    "objectID": "de_kriging.html#die-mathematische-architektur-eines-kriging-modells",
    "href": "de_kriging.html#die-mathematische-architektur-eines-kriging-modells",
    "title": "58  Lernmodul: Eine Einführung in Kriging",
    "section": "58.2 Die mathematische Architektur eines Kriging-Modells",
    "text": "58.2 Die mathematische Architektur eines Kriging-Modells\nUm vom konzeptionellen Ansatz des Kriging zur praktischen Umsetzung zu gelangen, ist es unerlässlich, seine mathematischen Komponenten zu verstehen. Dieser Abschnitt analysiert die Architektur des Modells und verbindet konsequent die abstrakte mathematische Notation aus Referenztexten mit den konkreten Variablen, die im bereitgestellten Python-Code verwendet werden.\n\n58.2.1 Glossar der Kriging-Notation\nTabelle 58.1 dient als Glossar, um die Notation aus (Forrester, Sóbester, und Keane 2008), dem Kochbuch (Bartz-Beielstein 2023) und dem in diesem Dokument in Kapitel 58.4 bereitgestellten Python-Code abzugleichen.\n\n\n\nTabelle 58.1: Glossar\n\n\n\n\n\n\n\n\n\n\nMathematisches Symbol\nKonzeptionelle Bedeutung\nPython-Variable\n\n\n\n\n\\(n\\)\nAnzahl der Trainings-/Stichprobenpunkte\nn oder X_train.shape\n\n\n\\(k\\)\nAnzahl der Eingabedimensionen/Variablen\nX_train.shape\n\n\n\\(m\\)\nAnzahl der Punkte für die Vorhersage\nm oder x_predict.shape\n\n\n\\(X\\)\n\\(n \\times k\\) Matrix der Trainingspunkt-Standorte\nX_train\n\n\n\\(y\\)\n\\(n \\times 1\\) Vektor der beobachteten Antworten\ny_train\n\n\n\\(\\vec{x}\\)\nEin neuer Standort für die Vorhersage\nEine Zeile in x_predict\n\n\n\\(\\Psi\\) (Psi)\n\\(n \\times n\\) Korrelationsmatrix der Trainingsdaten\nPsi\n\n\n\\(\\vec{\\psi}\\) (psi)\n\\(n \\times m\\) Vorhersage-Trainings-Korrelationsmatrix\npsi\n\n\n\\(\\vec{\\theta}\\) (theta)\n\\(k \\times 1\\) Vektor der Aktivitäts-/Breiten-Hyperparameter\ntheta\n\n\n\\(\\vec{p}\\)\n\\(k \\times 1\\) Vektor der Glattheits-Hyperparameter\nImplizit \\(p=2\\) im Code\n\n\n\\(\\mu\\) (mu)\nDer globale Mittelwert des stochastischen Prozesses\nmu_hat\n\n\n\\(\\sigma^2\\) (sigma-quadrat)\nDie Varianz des stochastischen Prozesses\nIm Code nicht explizit berechnet\n\n\n\\(\\lambda\\) (lambda)\nDer Regressions-/Nugget-Parameter\neps\n\n\n\\(\\hat{y}(\\vec{x})\\)\nDie Kriging-Vorhersage am Punkt \\(\\vec{x}\\)\nf_predict\n\n\n\n\n\n\n\n\n58.2.2 Der Korrelationskernel: Quantifizierung von Beziehungen\nDer Kern des Kriging-Modells ist seine spezialisierte Basisfunktion, auch als Kernel oder Kovarianzfunktion bekannt. Diese Funktion definiert die Korrelation zwischen zwei beliebigen Punkten im Designraum. Die gebräuchlichste Form, und die in unseren Referenztexten verwendete, ist der Gauß’sche Kernel.\nDie Kriging-Basisfunktion ist definiert als: \\[\\psi(\\vec{x}^{(i)}, \\vec{x}) = \\exp\\left(-\\sum_{j=1}^{k} \\theta_j |x_j^{(i)} - x_j|^{p_j}\\right)\\] Diese Gleichung berechnet die Korrelation zwischen einem bekannten Punkt \\(\\vec{x}^{(i)}\\) und jedem anderen Punkt \\(\\vec{x}\\). Sie wird von zwei Schlüsselsätzen von Hyperparametern gesteuert: \\(\\vec{\\theta}\\) und \\(\\vec{p}\\).\n\n58.2.2.1 Hyperparameter \\(\\vec{\\theta}\\) (Theta): Der Aktivitätsparameter\nDer Parametervektor \\(\\vec{\\theta} = \\{\\theta_1, \\theta_2,..., \\theta_k\\}^T\\) ist wohl der wichtigste Hyperparameter im Kriging-Modell. Jede Komponente \\(\\theta_j\\) steuert, wie schnell die Korrelation mit dem Abstand entlang der \\(j\\)-ten Dimension abfällt. Er wird oft als „Aktivitäts“- oder „Breiten“-Parameter bezeichnet.\n\nEin großes \\(\\theta_j\\) zeigt an, dass die Funktion sehr empfindlich auf Änderungen in der \\(j\\)-ten Variablen reagiert. Die Korrelation wird sehr schnell abfallen, wenn sich die Punkte in dieser Dimension voneinander entfernen, was zu einer „schmalen“ Basisfunktion führt. Dies impliziert, dass die zugrunde liegende Funktion entlang dieser Achse sehr „aktiv“ ist oder sich schnell ändert.\nEin kleines \\(\\theta_j\\) zeigt an, dass die Funktion relativ unempfindlich auf Änderungen in der \\(j\\)-ten Variablen reagiert. Die Korrelation wird langsam abfallen, was zu einer „breiten“ Basisfunktion führt, die ihren Einfluss über einen größeren Bereich ausdehnt.\n\nDie Tatsache, dass \\(\\vec{\\theta}\\) ein Vektor ist – mit einem separaten Wert für jede Eingabedimension – ist ein entscheidendes Merkmal, das dem Kriging immense Leistungsfähigkeit verleiht, insbesondere bei mehrdimensionalen Problemen. Dies ist als anisotrope Modellierung bekannt. Indem die Korrelationslänge für jede Variable unterschiedlich sein kann, kann sich das Modell an Funktionen anpassen, die sich entlang verschiedener Achsen unterschiedlich verhalten. Zum Beispiel könnte eine Funktion sehr schnell auf Temperaturänderungen, aber sehr langsam auf Druckänderungen reagieren. Ein anisotropes Kriging-Modell kann dieses Verhalten erfassen, indem es ein großes \\(\\theta\\) für die Temperatur und ein kleines \\(\\theta\\) für den Druck lernt.\nDiese Fähigkeit hat eine tiefgreifende Konsequenz: automatische Relevanzbestimmung. Während des Modellanpassungsprozesses (den wir in Kapitel 58.2.4 diskutieren werden) findet der Optimierungsalgorithmus die \\(\\vec{\\theta}\\)-Werte, die die Daten am besten erklären. Wenn eine bestimmte Eingangsvariable \\(x_j\\) wenig oder keinen Einfluss auf die Ausgabe \\(y\\) hat, wird das Modell einen sehr kleinen Wert für \\(\\theta_j\\) lernen. Ein kleines \\(\\theta_j\\) macht den Term \\(\\theta_j|x_j^{(i)} - x_j|^{p_j}\\) nahe null, was die Korrelation effektiv unempfindlich gegenüber Änderungen in dieser Dimension macht. Daher kann ein Ingenieur nach der Anpassung des Modells den optimierten \\(\\vec{\\theta}\\)-Vektor inspizieren, um eine Sensitivitätsanalyse durchzuführen. Die Dimensionen mit den größten \\(\\theta_j\\)-Werten sind die einflussreichsten Treiber der Systemantwort. Dies verwandelt das Surrogatmodell von einem einfachen Black-Box-Approximator in ein Werkzeug zur Generierung wissenschaftlicher und technischer Erkenntnisse. Der in Kapitel 9.6.7 bereitgestellte und in Kapitel 58.4 besprochene Python-Code, als eindimensionales Beispiel, vereinfacht dies durch die Verwendung eines einzelnen skalaren theta, aber das Verständnis seiner Rolle als Vektor ist entscheidend, um den Nutzen des Kriging in realen Anwendungen zu schätzen (Bartz-Beielstein 2025).\n\n\n58.2.2.2 Hyperparameter \\(\\vec{p}\\): Der Glattheitsparameter\nDer Parametervektor \\(\\vec{p} = \\{p_1, p_2,..., p_k\\}^T\\) steuert die Glattheit der Funktion an den Datenpunkten. Sein Wert ist typischerweise auf das Intervall \\([1,2]\\) beschränkt (Forrester, Sóbester, und Keane 2008). Die Wahl von \\(p_j\\) hat tiefgreifende Auswirkungen auf die Form der resultierenden Basisfunktion:\n\nWenn \\(p_j = 2\\), ist die resultierende Funktion unendlich differenzierbar, was bedeutet, dass sie sehr glatt ist. Dies ist im bereitgestellten Python-Code der Fall, was durch die Verwendung der sqeuclidean-Distanzmetrik (quadrierter Abstand entspricht \\(p=2\\)) implizit ist. Die sqeuclidean-Metrik ist auf https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.sqeuclidean.html beschrieben.\nWenn \\(p_j = 1\\), ist die resultierende Funktion stetig, aber an den Datenpunkten nicht differenzierbar, was ihr ein „spitzeres“ oder „stacheligeres“ Aussehen verleiht.\n\nDie Wahl von \\(p\\) spiegelt eine Annahme über die Natur der zugrunde liegenden Funktion wider. Die meisten physikalischen Prozesse sind glatt, was \\(p=2\\) zu einer gängigen und robusten Wahl macht. Für Funktionen mit bekannten scharfen Merkmalen kann jedoch die Optimierung von \\(p\\) in Richtung 1 eine bessere Anpassung ermöglichen.\n\n\n\n58.2.3 Aufbau des Systems: Die Korrelationsmatrizen \\(\\Psi\\) und \\(\\vec{\\psi}\\)\nMit dem definierten Korrelationskernel können wir nun die Matrizen konstruieren, die den Kern des Kriging-Systems bilden. Diese Matrizen quantifizieren die Beziehungen zwischen allen Punkten in unserem Problem: den bekannten Trainingspunkten und den neuen Vorhersagepunkten.\n\n58.2.3.1 Die Psi-Matrix (\\(\\Psi\\)): Korrelation der Trainingsdaten\nDie Matrix \\(\\Psi\\) ist die \\(n \\times n\\) Korrelationsmatrix der \\(n\\) Trainingsdaten mit sich selbst. Jedes Element \\(\\Psi_{ij}\\) ist die Korrelation zwischen dem Trainingspunkt \\(\\vec{x}^{(i)}\\) und dem Trainingspunkt \\(\\vec{x}^{(j)}\\), berechnet mit der Basisfunktion. \\[\n\\Psi_{ij} = \\text{corr}(\\vec{x}^{(i)}, \\vec{x}^{(j)}) = \\exp\\left(-\\sum_{l=1}^{k} \\theta_l |x_l^{(i)} - x_l^{(j)}|^{p_l}\\right).\n\\] Da die Korrelation eines Punktes mit sich selbst perfekt ist, sind die diagonalen Elemente \\(\\Psi_{ii}\\) immer gleich 1. Die Matrix ist auch symmetrisch, da der Abstand von Punkt \\(A\\) zu \\(B\\) derselbe ist wie von \\(B\\) zu \\(A\\).\nCode-Analyse (build_Psi): Die bereitgestellte Python-Funktion build_Psi implementiert diese Berechnung effizient.\ndef build_Psi(X, theta, eps=sqrt(spacing(1))):\n    D = squareform(pdist(X, metric='sqeuclidean', out=None, w=theta))\n    Psi = exp(-D)\n    Psi += multiply(eye(X.shape[0]), eps)\n    return Psi\n\nD = squareform(pdist(X, metric='sqeuclidean', out=None, w=theta)): Diese Zeile ist der rechnerische Kern. Die Funktion scipy.spatial.distance.pdist berechnet die paarweisen Abstände zwischen allen Zeilen in der Eingabematrix X_train.\n\nmetric='sqeuclidean' gibt an, dass der quadrierte euklidische Abstand, \\((x_i - x_j)^2\\), verwendet werden soll. Dies setzt implizit den Hyperparameter \\(p=2\\).\nw=theta wendet den Aktivitätsparameter als Gewicht auf den quadrierten Abstand jeder Dimension an und berechnet \\(\\theta_j(x_{ij} - x_{kj})^2\\) für jedes Paar von Punkten \\(i, k\\) und jede Dimension \\(j\\). Für den 1D-Fall im Code ist dies einfach theta * (x_i - x_j)^2.\nsquareform wandelt dann den von pdist zurückgegebenen komprimierten Abstandsvektor in die vollständige, symmetrische \\(n \\times n\\) Abstandsmatrix um, die wir \\(D\\) nennen können.\n\nPsi = exp(-D): Dies führt eine elementweise Potenzierung des Negativen der Abstandsmatrix durch und vervollständigt die Berechnung des Gauß’schen Kernels.\nPsi += multiply(eye(X.shape), eps): Diese Zeile addiert eine kleine Konstante eps zur Diagonale der \\(\\Psi\\)-Matrix. Dies ist der „Nugget“-Term, eine entscheidende Komponente sowohl für die numerische Stabilität als auch für die Rauschmodellierung, die in Kapitel 58.3.2 behandelt wird.\n\n\n\n58.2.3.2 Der psi-Vektor/Matrix (\\(\\vec{\\psi}\\)): Vorhersage-Trainings-Korrelation\nDie Matrix \\(\\vec{\\psi}\\) ist die \\(n \\times m\\) Matrix der Korrelationen zwischen den \\(n\\) bekannten Trainingspunkten und den \\(m\\) neuen Punkten, an denen wir eine Vorhersage machen möchten. Jedes Element \\(\\psi_{ij}\\) ist die Korrelation zwischen dem \\(i\\)-ten Trainingspunkt \\(\\vec{x}^{(i)}\\) und dem \\(j\\)-ten Vorhersagepunkt \\(\\vec{x}_{pred}^{(j)}\\). \\[\\psi_{ij} = \\text{corr}(\\vec{x}^{(i)}, \\vec{x}_{pred}^{(j)})\\]\nCode-Analyse (build_psi): Die Funktion build_psi berechnet diese Matrix.\ndef build_psi(X_train, x_predict, theta):\n    D = cdist(x_predict, X_train, metric='sqeuclidean', out=None, w=theta)\n    psi = exp(-D)\n    return psi.T\n\nD = cdist(x_predict, X_train, metric='sqeuclidean', out=None, w=theta): Hier wird scipy.spatial.distance.cdist verwendet, siehe https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cdist.html, da wir Abstände zwischen Punkten aus zwei verschiedenen Mengen berechnen: den \\(m\\) Vorhersagepunkten in x_predict und den \\(n\\) Trainingspunkten in X_train. Dies führt zu einer \\(m \\times n\\) Matrix gewichteter quadrierter Abstände.\npsi = exp(-D): Wie zuvor vervollständigt dies die Kernel-Berechnung.\nreturn psi.T: Die resultierende Matrix wird transponiert, um die Größe \\(n \\times m\\) zu haben. Dies ist eine Konvention, um mit der in den Vorhersageformeln in Referenztexten wie Forrester, Sóbester, und Keane (2008) dargestellten Matrixalgebra übereinzustimmen.\n\n\n\n\n58.2.4 Modellkalibrierung durch Maximum-Likelihood-Schätzung (MLE)\nSobald die Struktur des Modells durch den Kernel definiert ist, müssen wir die optimalen Werte für seine Hyperparameter, nämlich \\(\\vec{\\theta}\\) und \\(\\vec{p}\\), bestimmen. Der Code in Kapitel 58.4 umgeht diesen Schritt, indem er theta = 1.0 fest codiert, aber in jeder praktischen Anwendung müssen diese Parameter aus den Daten gelernt werden. Eine gebräuchliche Methode hierfür ist die Maximum-Likelihood-Schätzung (MLE).\nDie Kernidee der MLE besteht darin, die Frage zu beantworten: „Welche Werte der Hyperparameter machen bei unseren beobachteten Daten diese Daten am wahrscheinlichsten?“ Wir finden die Parameter, die die Wahrscheinlichkeit maximieren, die Daten beobachtet zu haben, die wir tatsächlich gesammelt haben.\n\n58.2.4.1 Die Likelihood-Funktion\nUnter der Annahme des Gauß-Prozesses wird die gemeinsame Wahrscheinlichkeit, den Antwortvektor \\(\\vec{y}\\) bei gegebenen Parametern zu beobachten, durch die multivariate normale Wahrscheinlichkeitsdichtefunktion beschrieben. Diese Funktion ist unsere Likelihood, \\(L\\): \\[\nL(\\mu, \\sigma^2, \\vec{\\theta}, \\vec{p} | \\vec{y}) = \\frac{1}{(2\\pi\\sigma^2)^{n/2}|\\Psi|^{1/2}} \\exp\\left[ - \\frac{(\\vec{y} - \\vec{1}\\mu)^T \\vec{\\Psi}^{-1}(\\vec{y} - \\vec{1}\\mu) }{2 \\sigma^2}\\right].\n\\tag{58.1}\\] Hier sind \\(\\mu\\) und \\(\\sigma^2\\) der globale Mittelwert und die Varianz des Prozesses, und \\(\\Psi\\) ist die Korrelationsmatrix, die implizit von \\(\\vec{\\theta}\\) und \\(\\vec{p}\\) abhängt. Beachten Sie, dass \\(|\\Psi|\\) die Determinante (also ein reellwertiger Skalar) der Korrelationsmatrix ist.\n\n\n58.2.4.2 Die konzentrierte Log-Likelihood\nDie direkte Maximierung der Likelihood-Funktion (Gleichung 58.1) ist schwierig. Aus Gründen der rechnerischen Stabilität und mathematischen Bequemlichkeit arbeiten wir stattdessen mit ihrem natürlichen Logarithmus, der Log-Likelihood (siehe Gleichung (2.29) in Forrester, Sóbester, und Keane (2008)): \\[\n\\ln(L) = -\\frac{n}{2}\\ln(2\\pi) - \\frac{n}{2}\\ln(\\sigma^2) - \\frac{1}{2}\\ln|\\Psi| - \\frac{(\\vec{y} - \\vec{1}\\mu)^T \\Psi^{-1}(\\vec{y} - \\vec{1}\\mu)}{2\\sigma^2}.\n\\tag{58.2}\\]\nEine wesentliche Vereinfachung ergibt sich, da wir für jedes gegebene \\(\\vec{\\theta}\\) und \\(\\vec{p}\\) (und damit ein festes \\(\\Psi\\)) die optimalen Werte für \\(\\mu\\) und \\(\\sigma^2\\) analytisch finden können, indem wir Ableitungen bilden und sie auf null setzen. Die MLE für den Mittelwert ist (siehe Gleichung (2.30) in Forrester, Sóbester, und Keane (2008)): \\[\n\\hat{\\mu} = \\frac{\\mathbf{1}^T \\Psi^{-1} \\vec{y}}{\\mathbf{1}^T \\Psi^{-1} \\mathbf{1}}.\n\\tag{58.3}\\] Die Berechnung in Gleichung 58.3 kann als Berechung eines verallgemeinerten gewichteten Durchschnitts der beobachteten Antworten interpretiert werden, wobei die Gewichtung die Korrelationsstruktur berücksichtigt.\nEin ähnlicher Ausdruck existiert für die optimale Varianz, \\(\\hat{\\sigma}^2\\) (siehe Gleichung (2.31) in Forrester, Sóbester, und Keane (2008)): \\[\n\\hat{\\sigma}^2 = \\frac{(\\vec{y} - \\mathbf{1}\\hat{\\mu})^T \\Psi^{-1} (\\vec{y} - \\mathbf{1}\\hat{\\mu})}{n}.\n\\]\nIndem wir diese analytischen Ausdrücke für \\(\\hat{\\mu}\\) und \\(\\hat{\\sigma}^2\\) wieder in die Log-Likelihood-Funktion (Gleichung 58.2) einsetzen, erhalten wir die konzentrierte Log-Likelihood-Funktion (siehe Gleichung (2.32) in Forrester, Sóbester, und Keane (2008)): \\[\n\\ln(L) \\approx -\\frac{n}{2}\\ln(\\hat{\\sigma}^2) - \\frac{1}{2}\\ln|\\Psi|.\n\\] Diese vereinfachte Funktion hängt nun nur noch von den Hyperparametern \\(\\vec{\\theta}\\) und \\(\\vec{p}\\) ab, die in \\(\\Psi\\) und \\(\\hat{\\sigma}^2\\) eingebettet sind.\n\n\n58.2.4.3 Numerische Optimierung\nWir können die optimalen \\(\\vec{\\theta}\\) und \\(\\vec{p}\\) nicht analytisch bestimmen. Die konzentrierte Log-Likelihood ist jedoch eine skalare Funktion, die relativ schnell zu berechnen ist. Wir können daher einen numerischen Optimierungsalgorithmus – wie einen genetischen Algorithmus, Nelder-Mead oder Differential Evolution – verwenden, um den Hyperparameterraum zu durchsuchen und die Werte von \\(\\vec{\\theta}\\) und \\(\\vec{p}\\) zu finden, die diese Funktion maximieren. Dieser Suchprozess ist die „Trainings“- oder „Anpassungs“-Phase beim Aufbau eines Kriging-Modells. Sobald die optimalen Hyperparameter gefunden sind, ist das Modell vollständig kalibriert und bereit, Vorhersagen zu treffen.",
    "crumbs": [
      "Lernmodule",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Lernmodul: Eine Einführung in Kriging</span>"
    ]
  },
  {
    "objectID": "de_kriging.html#implementierung-und-vorhersage",
    "href": "de_kriging.html#implementierung-und-vorhersage",
    "title": "58  Lernmodul: Eine Einführung in Kriging",
    "section": "58.3 Implementierung und Vorhersage",
    "text": "58.3 Implementierung und Vorhersage\nNachdem der theoretische und mathematische Rahmen geschaffen wurde, konzentriert sich dieser Teil auf die praktische Anwendung des Kriging-Modells: wie man es zur Erstellung von Vorhersagen verwendet und welche wesentlichen numerischen Techniken sicherstellen, dass der Prozess sowohl effizient als auch robust ist.\n\n58.3.1 Der Kriging-Prädiktor: Generierung neuer Werte\nDas ultimative Ziel beim Aufbau eines Kriging-Modells ist die Vorhersage des Funktionswerts an neuen, unbeobachteten Punkten. Die hierfür verwendete Formel ist als Bester Linearer Unverzerrter Prädiktor (BLUP) bekannt. Sie liefert den Mittelwert des posterioren Gauß-Prozesses am Vorhersageort, was unsere beste Schätzung des Funktionswerts ist.\nDie Vorhersageformel lautet (siehe Gleichung (2.40) in Forrester, Sóbester, und Keane (2008)): \\[\n\\hat{y}(\\vec{x}) = \\hat{\\mu} + \\vec{\\psi}^T \\Psi^{-1} (\\vec{y} - \\mathbf{1}\\hat{\\mu}),\n\\tag{58.4}\\] wobei \\(\\hat{y}(\\vec{x})\\) die Vorhersage an einem neuen Punkt \\(\\vec{x}\\) ist und alle anderen Terme wie im Glossar definiert sind.Im Folgenden beschreiben wir die einzelnen Komponenten dieser Gleichung und ihre Bedeutung:\n\n\\(\\hat{\\mu}\\): Die Vorhersage beginnt mit dem geschätzten globalen Mittelwert des Prozesses. Dies ist unsere Basisvermutung, bevor wir den Einfluss der lokalen Datenpunkte berücksichtigen.\n\\((\\vec{y} - \\mathbf{1}\\hat{\\mu})\\): Dies ist der Vektor der Residuen. Er stellt die Differenz zwischen jedem beobachteten Datenpunkt und dem globalen Mittelwert dar. Dieser Vektor erfasst die spezifischen, lokalen Informationen, die unsere Trainingsdaten liefern.\n\\(\\Psi^{-1} (\\vec{y} - \\mathbf{1}\\hat{\\mu})\\): Dieser Term kann als ein Vektor von Gewichten betrachtet werden, nennen wir ihn \\(\\vec{w}\\). Indem wir die Residuen mit der Inversen der Korrelationsmatrix multiplizieren, berechnen wir einen Satz von Gewichten, der die Interkorrelationen zwischen den Trainingspunkten berücksichtigt. Dieser Schritt sagt im Wesentlichen: „Wie viel sollte jedes Residuum beitragen, wenn man bedenkt, dass die Datenpunkte selbst nicht unabhängig sind?“\n\\(\\vec{\\psi}^T \\vec{w}\\): Die endgültige Vorhersage wird durch eine gewichtete Summe dieser berechneten Gewichte angepasst. Die Gewichte für diese Summe sind die Korrelationen (\\(\\vec{\\psi}\\)) zwischen dem neuen Vorhersagepunkt \\(\\vec{x}\\) und jedem der Trainingspunkte. Im Wesentlichen besagt die Formel: „Beginne mit dem globalen Mittelwert und füge dann eine Korrektur basierend auf den beobachteten Residuen hinzu. Der Einfluss jedes Residuums wird durch die Korrelation des neuen Punktes mit dem entsprechenden Trainingspunkt bestimmt.“\n\nCode-Analyse (mu_hat und f_predict): Der bereitgestellte Python-Code implementiert diesen Vorhersageprozess direkt.\nU = cholesky(Psi).T\none = np.ones(n).reshape(-1, 1)\nmu_hat = (one.T @ solve(U, solve(U.T, y_train))) / (one.T @ solve(U, solve(U.T, one)))\nf_predict = mu_hat * np.ones(m).reshape(-1, 1) + psi.T @ solve(U, solve(U.T, y_train - one * mu_hat))\n\nmu_hat = (one.T @ solve(U, solve(U.T, y_train))) / (one.T @ solve(U, solve(U.T, one))): Dies ist eine direkte und numerisch stabile Implementierung der Formel für \\(\\hat{\\mu}\\), siehe Gleichung 58.3. Anstatt Psi_inv explizit zu berechnen, wird der auf Cholesky basierende Löser verwendet, der im nächsten Abschnitt detailliert wird. Der Ausdruck solve(U, solve(U.T, y_train)) ist äquivalent zu Psi_inv @ y_train.\nf_predict = mu_hat *... + psi.T @ solve(U, solve(U.T, y_train - one * mu_hat)): Diese Zeile ist eine direkte Übersetzung der BLUP-Formel aus Gleichung 58.4. Sie berechnet die Residuen y_train - one * mu_hat, multipliziert sie mit Psi_inv unter Verwendung des Cholesky-Lösers und berechnet dann das Skalarprodukt mit psi.T, bevor das Ergebnis zum Basiswert mu_hat addiert wird.\n\n\n\n58.3.2 Numerische Best Practices und der Nugget-Effekt\nEine direkte Implementierung der Kriging-Gleichungen unter Verwendung der Standard-Matrixinversion kann sowohl langsam als auch numerisch anfällig sein. Professionelle Implementierungen stützen sich auf spezifische numerische Techniken, um Effizienz und Robustheit zu gewährleisten.\n\n58.3.2.1 Effiziente Inversion mit Cholesky-Zerlegung\nDie Berechnung der Matrixinversen \\(\\Psi^{-1}\\) ist der rechenintensivste Schritt sowohl im MLE-Prozess als auch bei der endgültigen Vorhersage. Eine direkte Inversion hat eine Rechenkomplexität von etwa \\(O(n^3)\\). Wenn die Matrix schlecht konditioniert ist (fast singulär), kann die direkte Inversion außerdem zu großen numerischen Fehlern führen.\nEin überlegener Ansatz ist die Verwendung der Cholesky-Zerlegung. Diese Methode gilt für symmetrische, positiv definite Matrizen wie \\(\\Psi\\). Sie zerlegt \\(\\Psi\\) in das Produkt einer unteren Dreiecksmatrix \\(L\\) und ihrer Transponierten \\(L^T\\) (oder einer oberen Dreiecksmatrix \\(U\\) und ihrer Transponierten \\(U^T\\)), sodass \\(\\Psi = LL^T\\). Diese Zerlegung ist schneller als die Inversion, mit einer Komplexität von ungefähr \\(O(n^3/3)\\) (Forrester, Sóbester, und Keane 2008).\nSobald \\(\\Psi\\) zerlegt ist, wird das Lösen eines linearen Systems wie \\(\\Psi \\vec{w} = \\vec{b}\\) zu einem zweistufigen Prozess der Lösung zweier viel einfacherer Dreieckssysteme, ein Verfahren, das als Vorwärts- und Rückwärtssubstitution bekannt ist:\n\nLöse \\(L\\vec{v} = \\vec{b}\\) nach \\(\\vec{v}\\).\nLöse \\(L^T\\vec{w} = \\vec{v}\\) nach \\(\\vec{w}\\).\n\nGenau das macht der Python-Code. Die Zeile U = cholesky(Psi).T führt die Zerlegung durch (NumPys cholesky gibt den unteren Dreiecksfaktor \\(L\\) zurück, also wird er transponiert, um den oberen Dreiecksfaktor \\(U\\) zu erhalten). Anschließend implementieren Ausdrücke wie solve(U, solve(U.T,...)) die effiziente zweistufige Lösung, ohne jemals die vollständige Inverse von \\(\\Psi\\) zu bilden.\n\n\n58.3.2.2 Der Nugget: Von numerischer Stabilität zur Rauschmodellierung\nDie Cholesky-Zerlegung funktioniert nur, wenn die Matrix \\(\\Psi\\) streng positiv definit ist. Ein Problem tritt auf, wenn zwei Trainingspunkte \\(\\vec{x}^{(i)}\\) und \\(\\vec{x}^{(j)}\\) sehr nahe beieinander liegen. In diesem Fall wird ihre Korrelation nahe 1 sein, was die entsprechenden Zeilen und Spalten in \\(\\Psi\\) nahezu identisch macht. Dies führt dazu, dass die Matrix schlecht konditioniert oder fast singulär wird, was zum Scheitern der Cholesky-Zerlegung führen kann.\nDieses Problem wird gelöst, indem ein kleiner positiver Wert zur Diagonale der Korrelationsmatrix addiert wird: \\(\\Psi_{new} = \\Psi + \\lambda I\\), wobei \\(I\\) die Identitätsmatrix ist. Diese kleine Addition, oft als Nugget bezeichnet, stellt sicher, dass die Matrix gut konditioniert und invertierbar bleibt. Im bereitgestellten Code dient die Variable eps diesem Zweck.\nObwohl es als numerischer „Hack“ beginnen mag, hat dieser Nugget-Term eine tiefgreifende und starke statistische Interpretation: Er modelliert Rauschen in den Daten. Dies führt zu zwei unterschiedlichen Arten von Kriging-Modellen:\n\nInterpolierendes Kriging (\\(\\lambda \\approx 0\\)): Wenn der Nugget null oder sehr klein ist (wie eps im Code), wird das Modell gezwungen, exakt durch jeden Trainingsdatenpunkt zu verlaufen. Dies ist für deterministische Computerexperimente geeignet, bei denen die Ausgabe rauschfrei ist.\nRegressives Kriging (\\(\\lambda &gt; 0\\)): Wenn bekannt ist, dass die Daten verrauscht sind (z. B. aus physikalischen Experimenten oder stochastischen Simulationen), würde das Erzwingen der Interpolation jedes Punktes dazu führen, dass das Modell das Rauschen anpasst, was zu einer übermäßig komplexen und „zappeligen“ Oberfläche führt, die schlecht generalisiert. Durch Hinzufügen eines größeren Nugget-Terms \\(\\lambda\\) zur Diagonale teilen wir dem Modell explizit mit, dass es Varianz (Rauschen) in den Beobachtungen gibt. Das Modell ist nicht mehr verpflichtet, exakt durch die Datenpunkte zu verlaufen. Stattdessen wird es eine glattere Regressionskurve erstellen, die den zugrunde liegenden Trend erfasst und gleichzeitig das Rauschen herausfiltert. Die Größe von \\(\\lambda\\) kann als weiterer zu optimierender Hyperparameter behandelt werden, der die Varianz des Rauschens darstellt.\n\nDieselbe mathematische Operation – das Hinzufügen eines Wertes zur Diagonale von \\(\\Psi\\) – dient somit einem doppelten Zweck. Ein winziges, festes eps ist eine pragmatische Lösung für die numerische Stabilität. Ein größeres, potenziell optimiertes \\(\\lambda\\) ist ein formaler statistischer Parameter, der das Verhalten des Modells grundlegend von einem exakten Interpolator zu einem rauschfilternden Regressor ändert.",
    "crumbs": [
      "Lernmodule",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Lernmodul: Eine Einführung in Kriging</span>"
    ]
  },
  {
    "objectID": "de_kriging.html#sec-example-de",
    "href": "de_kriging.html#sec-example-de",
    "title": "58  Lernmodul: Eine Einführung in Kriging",
    "section": "58.4 Eine vollständige exemplarische Vorgehensweise: Kriging der Sinusfunktion",
    "text": "58.4 Eine vollständige exemplarische Vorgehensweise: Kriging der Sinusfunktion\nDieser letzte Teil fasst die gesamte vorangegangene Theorie zusammen, indem er sie auf das bereitgestellte Python-Codebeispiel aus Kapitel 9.6.7 anwendet. Wir werden das Skript Schritt für Schritt durchgehen und die Eingaben, Prozesse und Ausgaben in jeder Phase interpretieren, um eine konkrete Veranschaulichung des Kriging in Aktion zu geben.\n\n58.4.1 Schritt-für-Schritt-Codeausführung und Interpretation\nDas Beispiel zielt darauf ab, die Funktion \\(y = \\sin(x)\\) unter Verwendung einer kleinen Anzahl von Stichprobenpunkten zu modellieren. Dies ist ein klassisches „Spielzeugproblem“, das nützlich ist, um zu visualisieren, wie sich das Modell verhält.\n\n58.4.1.1 Schritt 1: Datengenerierung\nn = 8\nX_train = np.linspace(0, 2 * np.pi, n, endpoint=False).reshape(-1, 1)\ny_train = np.sin(X_train)\nHier generiert das Skript die Trainingsdaten.\n\nn = 8: Wir entscheiden uns, die Funktion an acht verschiedenen Stellen abzutasten.\nX_train: Dies erstellt ein Array von acht gleichmäßig verteilten Punkten im Intervall [0, \\(2\\pi\\)], die als Trainingspunkte dienen.\ny_train = np.sin(X_train): Dies berechnet die Sinuswerte an den Trainingspunkten. Das Ergebnis ist ein \\(8 \\times 1\\) Vektor, der die beobachteten Antworten darstellt.\n\n\n\n58.4.1.2 Schritt 2: Definition der Korrelationsmatrix (\\(\\Psi\\))\ntheta = np.array([1.0])\nPsi = build_Psi(X_train, theta)\nDieser Schritt berechnet die \\(8 \\times 8\\) Korrelationsmatrix \\(\\Psi\\) für die Trainingsdaten.\n\ntheta = np.array([1.0]): Der Aktivitätshyperparameter \\(\\theta\\) wird auf 1.0 gesetzt. In einer realen Anwendung würde dieser Wert durch MLE gefunden, aber hier wird er zur Vereinfachung festgesetzt.\nPsi = build_Psi(X_train, theta): Die Funktion build_Psi wird aufgerufen. Sie berechnet den gewichteten quadrierten Abstand zwischen jedem Paar von Punkten in X_train und wendet dann den exponentiellen Kernel an. Die resultierende Psi-Matrix quantifiziert die angenommene Korrelation zwischen all unseren bekannten Datenpunkten. Die diagonalen Elemente sind 1 (plus ein winziges eps), und die außerdiagonalen Werte nehmen ab, wenn der Abstand zwischen den entsprechenden Punkten zunimmt.\n\n\n\n58.4.1.3 Schritt 3: Definition der Vorhersagepunkte\nm = 100\nx_predict = np.linspace(0, 2 * np.pi, m, endpoint=True).reshape(-1, 1)\nWir definieren nun die Orte, an denen wir neue Vorhersagen machen wollen. Wir erstellen ein dichtes Gitter von m = 100 Punkten, das das gesamte Intervall [0, \\(2\\pi\\)] abdeckt. Dies sind die Punkte, an denen wir unser Surrogatmodell auswerten werden, um eine glatte Kurve zu erzeugen.\n\n\n58.4.1.4 Schritt 4: Berechnung der Vorhersagekorrelation (\\(\\vec{\\psi}\\))\npsi = build_psi(X_train, x_predict, theta)\nDieser Schritt berechnet die \\(8 \\times 100\\) Korrelationsmatrix \\(\\vec{\\psi}\\). Die Funktion build_psi berechnet die Korrelation zwischen jedem der acht Trainingspunkte und jedem der 100 Vorhersagepunkte. Jede Spalte der resultierenden psi-Matrix entspricht einem Vorhersagepunkt und enthält seine acht Korrelationswerte mit dem Trainingssatz. Diese Matrix verbindet die neuen, unbekannten Orte mit unserer bestehenden Wissensbasis.\n\n\n58.4.1.5 Schritt 5: Berechnung der Vorhersage\nU = cholesky(Psi).T\none = np.ones(n).reshape(-1, 1)\nmu_hat = (one.T @ solve(U, solve(U.T, y_train))) / (one.T @ solve(U, solve(U.T, one)))\nf_predict = mu_hat * np.ones(m).reshape(-1, 1) + psi.T @ solve(U, solve(U.T, y_train - one * mu_hat))\nDies ist der entscheidende Schritt, in dem die tatsächlichen Vorhersagen gemacht werden.\n\nU = cholesky(Psi).T: Die numerisch entscheidende Cholesky-Zerlegung von \\(\\Psi\\) wird durchgeführt.\nmu_hat =...: Die Maximum-Likelihood-Schätzung für den globalen Mittelwert \\(\\mu\\) wird unter Verwendung des numerisch stabilen Cholesky-Lösers berechnet. Für diese spezifischen symmetrischen Daten wird mu_hat nahe null sein.\nf_predict =...: Die BLUP-Formel wird implementiert. Sie berechnet die Residuen (y_train - one * mu_hat), findet die gewichteten Residuen unter Verwendung des Cholesky-Lösers (solve(U, solve(U.T,...))) und berechnet dann die endgültige Vorhersage durch eine gewichtete Summe basierend auf den Vorhersagekorrelationen psi.T. Das Ergebnis, f_predict, ist ein \\(100 \\times 1\\) Vektor, der die vorhergesagten Sinuswerte an jedem der x_predict-Orte enthält.\n\n\n\n58.4.1.6 Schritt 6: Visualisierung\nDer letzte Codeblock stellt die Ergebnisse grafisch dar.\n\nMessungen (Blaue Punkte): Die ursprünglichen 8 Datenpunkte werden dargestellt.\nWahre Sinusfunktion (Graue gestrichelte Linie): Die tatsächliche \\(\\sin(x)\\)-Funktion wird als Referenz dargestellt.\nKriging-Vorhersage (Orange Linie): Die vorhergesagten Werte f_predict werden gegen x_predict aufgetragen.\n\nDie Grafik zeigt die Schlüsseleigenschaften des Kriging-Modells. Die orangefarbene Linie verläuft exakt durch jeden der blauen Punkte und demonstriert damit ihre interpolierende Natur (da eps sehr klein war). Wichtiger noch, zwischen den Stichprobenpunkten liefert die Vorhersage eine glatte und bemerkenswert genaue Annäherung an die wahre zugrunde liegende Sinuskurve, obwohl das Modell in diesen Bereichen keine anderen Informationen über die Funktion hatte als die acht Stichprobenpunkte und die angenommene Korrelationsstruktur.\n\n\n\n58.4.2 Fazit und Ausblick\nWir begannen damit, das Kriging als eine anspruchsvolle Form der Modellierung mit radialen Basisfunktionen einzuordnen und seine Kernphilosophie zu übernehmen, deterministische Funktionen als Realisierungen eines stochastischen Prozesses zu behandeln. Anschließend haben wir seine Architektur zerlegt: den leistungsstarken Korrelationskernel mit seinen Aktivitäts- (\\(\\theta\\)) und Glattheits- (\\(p\\)) Hyperparametern, die Konstruktion der Korrelationsmatrizen (\\(\\Psi\\) und \\(\\vec{\\psi}\\)) und den Ansatz der Maximum-Likelihood-Schätzung zur Modellkalibrierung. Schließlich haben wir die numerischen Best Practices wie die Cholesky-Zerlegung untersucht und die doppelte Rolle des Nugget-Terms für die numerische Stabilität und die statistische Rauschmodellierung besprochen. Die schrittweise exemplarische Vorgehensweise des Sinusbeispiels lieferte eine konkrete Demonstration dieser Konzepte und zeigte, wie eine kleine Menge von Datenpunkten verwendet werden kann, um ein genaues, interpolierendes Modell einer unbekannten Funktion zu erzeugen.\nFür den angehenden Praktiker ist dies nur der Anfang. Die Welt des Kriging und der Gauß-Prozess-Regression ist reich an fortgeschrittenen Techniken, die auf diesen Grundlagen aufbauen.\n\nFehlerschätzungen und sequentielles Design: Ein wesentliches Merkmal, das im Beispielcode nicht untersucht wurde, ist, dass das Kriging nicht nur eine mittlere Vorhersage, sondern auch eine Varianz an jedem Punkt liefert, die die Unsicherheit des Modells quantifiziert. Diese Varianz ist in Regionen weit entfernt von Datenpunkten hoch und in deren Nähe niedrig. Diese Fehlerschätzung ist die Grundlage für aktives Lernen oder sequentielles Design, bei dem Infill-Kriterien wie die erwartete Verbesserung (EI) verwendet werden, um den nächsten zu beprobenden Punkt intelligent auszuwählen, wobei ein Gleichgewicht zwischen der Notwendigkeit, vielversprechende Regionen auszunutzen (niedriger vorhergesagter Wert) und der Notwendigkeit, unsichere Regionen zu erkunden (hohe Varianz), hergestellt wird.\nGradienten-erweitertes Kriging: In vielen modernen Simulationsumgebungen ist es möglich, nicht nur den Funktionswert, sondern auch seine Gradienten (Ableitungen) zu geringen zusätzlichen Kosten zu erhalten. Das Gradienten-erweiterte Kriging integriert diese Gradienteninformationen in das Modell, was seine Genauigkeit drastisch verbessert und den Aufbau hochpräziser Modelle mit sehr wenigen Stichprobenpunkten ermöglicht.\nMulti-Fidelity-Modellierung (Co-Kriging): Oft haben Ingenieure Zugang zu mehreren Informationsquellen mit unterschiedlicher Genauigkeit und Kosten – zum Beispiel ein schnelles, aber ungenaues analytisches Modell und eine langsame, aber hochpräzise CFD-Simulation. Co-Kriging ist ein Rahmenwerk, das diese unterschiedlichen Datenquellen verschmilzt, indem es die reichlich vorhandenen billigen Daten verwendet, um einen Basistrend zu etablieren, und die spärlichen teuren Daten, um ihn zu korrigieren, was zu einem Modell führt, das genauer ist als eines, das nur aus einer der Datenquellen allein erstellt wurde.",
    "crumbs": [
      "Lernmodule",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Lernmodul: Eine Einführung in Kriging</span>"
    ]
  },
  {
    "objectID": "de_kriging.html#zusatzmaterialien",
    "href": "de_kriging.html#zusatzmaterialien",
    "title": "58  Lernmodul: Eine Einführung in Kriging",
    "section": "58.5 Zusatzmaterialien",
    "text": "58.5 Zusatzmaterialien\n\n\n\n\n\n\nInteraktive Webseite\n\n\n\n\nEine interaktive Webseite zum Thema Kriging ist hier zu finden: Kriging Interaktiv.\nEine interaktive Webseite zum Thema MLE ist hier zu finden: MLE Interaktiv.\n\n\n\n\n\n\n\n\n\nJupyter-Notebook\n\n\n\n\nDas Jupyter-Notebook für dieses Lernmodul ist auf GitHub im Hyperparameter-Tuning-Cookbook Repository verfügbar.\n\n\n\n\n\n\n\nBartz-Beielstein, Thomas. 2023. „Hyperparameter Tuning Cookbook: A guide for scikit-learn, PyTorch, river, and spotpython“. arXiv e-prints, Juli. https://doi.org/10.48550/arXiv.2307.10262.\n\n\n———. 2025. „Kriging (Gaussian Process Regression): The Complete Python Code for the Example“. https://sequential-parameter-optimization.github.io/Hyperparameter-Tuning-Cookbook/006_num_gp.html.\n\n\nForrester, Alexander, András Sóbester, und Andy Keane. 2008. Engineering Design via Surrogate Modelling. Wiley.\n\n\nSacks, J, W J Welch, T J Mitchell, und H P Wynn. 1989. „Design and analysis of computer experiments“. Statistical Science 4 (4): 409–35.",
    "crumbs": [
      "Lernmodule",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Lernmodul: Eine Einführung in Kriging</span>"
    ]
  },
  {
    "objectID": "de_kriging_optimization.html",
    "href": "de_kriging_optimization.html",
    "title": "59  Lernmodul: Erweiterung des Kriging-Modells: Numerische Optimierung der Hyperparameter",
    "section": "",
    "text": "59.1 Einleitung\nDas vorhergehende Lernmodul hat die konzeptionellen Grundlagen und die mathematische Architektur von Kriging-Modellen vorgestellt, illustriert am Beispiel der Sinusfunktion. In dieser Einführung wurde der Aktivitätsparameter \\(\\theta\\) aus Gründen der Einfachheit auf einen festen Wert (1.0) gesetzt. In realen Anwendungen ist es jedoch entscheidend, diese Parameter optimal aus den vorliegenden Daten zu bestimmen, um die bestmögliche Modellgüte zu erzielen.\nDieses Dokument baut auf dem bestehenden Wissen auf und erläutert, wie die Kriging-Hyperparameter, insbesondere der Aktivitätsparameter \\(\\theta\\), numerisch optimiert werden können. Wir werden uns auf die Maximierung der sogenannten “konzentrierten Log-Likelihood-Funktion” konzentrieren, einem gängigen Ansatz zur Parameterschätzung in Kriging-Modellen. Die gezeigte Python-Code-Erweiterung des Sinusfunktions-Beispiels verdeutlicht die praktische Umsetzung.",
    "crumbs": [
      "Lernmodule",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Lernmodul: Erweiterung des Kriging-Modells: Numerische Optimierung der Hyperparameter</span>"
    ]
  },
  {
    "objectID": "de_kriging_optimization.html#kriging-hyperparameter-theta-vectheta-und-p-vecp",
    "href": "de_kriging_optimization.html#kriging-hyperparameter-theta-vectheta-und-p-vecp",
    "title": "59  Lernmodul: Erweiterung des Kriging-Modells: Numerische Optimierung der Hyperparameter",
    "section": "59.2 Kriging-Hyperparameter: Theta (\\(\\vec{\\theta}\\)) und p (\\(\\vec{p}\\))",
    "text": "59.2 Kriging-Hyperparameter: Theta (\\(\\vec{\\theta}\\)) und p (\\(\\vec{p}\\))\nIm Kriging-Modell steuern zwei wichtige Vektoren von Hyperparametern die Form und die Eigenschaften der Korrelationsfunktion:\n\nAktivitätsparameter \\(\\vec{\\theta} = (\\theta_1, \\theta_2, \\ldots, \\theta_k)^T\\): Dieser Vektor regelt, wie schnell die Korrelation zwischen zwei Punkten mit zunehmendem Abstand in jeder Dimension abfällt. Ein großer Wert für \\(\\theta_j\\) in einer Dimension \\(j\\) bedeutet, dass die Funktion in dieser Dimension sehr “aktiv” ist oder sich schnell ändert, und somit nur Punkte in unmittelbarer Nähe stark korrelieren. Dies ermöglicht eine automatische Relevanzbestimmung, bei der wichtige Variablen durch höhere \\(\\theta\\)-Werte identifiziert werden können.\nGlattheitsparameter \\(\\vec{p} = (p_1, p_2, \\ldots, p_k)^T\\): Dieser Vektor beeinflusst die Glattheit der Vorhersagefunktion in jeder Dimension. Üblicherweise liegen die Werte für \\(p_j\\) zwischen 1 und 2. Im vorherigen Lernmodul wurde implizit \\(p_j=2\\) verwendet (durch die “sqeuclidean”-Distanzmetrik), was zu unendlich differenzierbaren, sehr glatten Funktionen führt. Eine Optimierung von \\(\\vec{p}\\) ist möglich, wird aber in diesem Beispiel aus Gründen der Komplexität ausgeklammert, da \\(p_j=2\\) oft als Standard für glatte Funktionen angenommen wird.",
    "crumbs": [
      "Lernmodule",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Lernmodul: Erweiterung des Kriging-Modells: Numerische Optimierung der Hyperparameter</span>"
    ]
  },
  {
    "objectID": "de_kriging_optimization.html#die-notwendigkeit-der-optimierung-die-konzentrierte-log-likelihood",
    "href": "de_kriging_optimization.html#die-notwendigkeit-der-optimierung-die-konzentrierte-log-likelihood",
    "title": "59  Lernmodul: Erweiterung des Kriging-Modells: Numerische Optimierung der Hyperparameter",
    "section": "59.3 Die Notwendigkeit der Optimierung: Die konzentrierte Log-Likelihood",
    "text": "59.3 Die Notwendigkeit der Optimierung: Die konzentrierte Log-Likelihood\nUm die optimalen Werte für \\(\\vec{\\theta}\\) (und \\(\\vec{p}\\)) zu finden, wird häufig die Maximum-Likelihood-Schätzung (MLE) verwendet. Die Grundidee der MLE besteht darin, diejenigen Parameterwerte zu finden, die die Wahrscheinlichkeit maximieren, die tatsächlich beobachteten Daten zu erhalten.\nDie zu maximierende Funktion ist die Log-Likelihood-Funktion. Für gegebene \\(\\vec{\\theta}\\) und \\(\\vec{p}\\) (und somit eine feste Korrelationsmatrix \\(\\Psi\\)) können die Schätzer für den globalen Mittelwert \\(\\hat{\\mu}\\) und die Prozessvarianz \\(\\hat{\\sigma}^2\\) analytisch abgeleitet werden. Durch Einsetzen dieser Schätzer in die Log-Likelihood-Funktion erhalten wir die sogenannte konzentrierte Log-Likelihood-Funktion:\n\\[\n\\ln(L) \\approx - \\frac{n}{2} \\ln(\\hat{\\sigma}^2) - \\frac{1}{2} \\ln |\\vec{\\Psi}|\n\\]\nHierbei ist:\n\n\\(n\\): Die Anzahl der Beobachtungspunkte.\n\\(\\hat{\\sigma}^2\\): Der Maximum-Likelihood-Schätzer der Prozessvarianz.\n\\(|\\vec{\\Psi}|\\): Die Determinante der Korrelationsmatrix \\(\\vec{\\Psi}\\).\n\nDie direkte Maximierung dieser Funktion ist mathematisch schwierig, da sie bezüglich \\(\\vec{\\theta}\\) und \\(\\vec{p}\\) nicht analytisch differenzierbar ist. Daher wird eine numerische Optimierung eingesetzt, um die Parameter zu finden, die die konzentrierte Log-Likelihood maximieren.",
    "crumbs": [
      "Lernmodule",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Lernmodul: Erweiterung des Kriging-Modells: Numerische Optimierung der Hyperparameter</span>"
    ]
  },
  {
    "objectID": "de_kriging_optimization.html#numerische-optimierungsalgorithmen",
    "href": "de_kriging_optimization.html#numerische-optimierungsalgorithmen",
    "title": "59  Lernmodul: Erweiterung des Kriging-Modells: Numerische Optimierung der Hyperparameter",
    "section": "59.4 Numerische Optimierungsalgorithmen",
    "text": "59.4 Numerische Optimierungsalgorithmen\nFür die numerische Optimierung der Parameter \\(\\vec{\\theta}\\) und \\(\\vec{p}\\) können verschiedene Algorithmen verwendet werden, darunter:\n\nNelder-Mead-Simplex-Verfahren\nKonjugierte Gradienten-Verfahren\nSimulated Annealing\nDifferential Evolution\n\nDie scipy.optimize-Bibliothek in Python bietet eine umfassende Sammlung solcher Optimierungsfunktionen. Da die meisten Optimierungsalgorithmen in scipy.optimize auf Minimierung ausgelegt sind, wird die negative konzentrierte Log-Likelihood-Funktion als Optimierungsziel verwendet.\nEin wichtiger numerischer Aspekt bei der Berechnung der Log-Likelihood ist die Determinante von \\(\\Psi\\). Für schlecht konditionierte Matrizen kann \\(|\\Psi|\\) gegen Null gehen, was zu numerischer Instabilität führen kann. Um dies zu vermeiden, wird der Logarithmus der Determinante \\(\\ln(|\\Psi|)\\) stabiler berechnet, indem man die Cholesky-Zerlegung \\(\\Psi = L L^T\\) nutzt und dann \\(\\ln(|\\Psi|) = 2 \\sum_{i=1}^{n} \\ln(L_{ii})\\) berechnet.\nFür die Suche nach \\(\\theta\\) ist es sinnvoll, Suchbereiche auf einer logarithmischen Skala zu definieren, typischerweise von \\(10^{-3}\\) bis \\(10^2\\). Es ist auch ratsam, die Eingabedaten auf den Bereich zwischen Null und Eins zu skalieren, um die Konsistenz der \\(\\theta\\)-Werte über verschiedene Probleme hinweg zu gewährleisten.",
    "crumbs": [
      "Lernmodule",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Lernmodul: Erweiterung des Kriging-Modells: Numerische Optimierung der Hyperparameter</span>"
    ]
  },
  {
    "objectID": "de_kriging_optimization.html#erweiterung-des-sinusfunktions-beispiels-mit-hyperparameter-optimierung",
    "href": "de_kriging_optimization.html#erweiterung-des-sinusfunktions-beispiels-mit-hyperparameter-optimierung",
    "title": "59  Lernmodul: Erweiterung des Kriging-Modells: Numerische Optimierung der Hyperparameter",
    "section": "59.5 Erweiterung des Sinusfunktions-Beispiels mit Hyperparameter-Optimierung",
    "text": "59.5 Erweiterung des Sinusfunktions-Beispiels mit Hyperparameter-Optimierung\nWir erweitern nun den Beispielcode aus dem “Lernmodul: Eine Einführung in Kriging” (Kriging-Anpassung an eine Sinusfunktion mit 8 Punkten), um den Aktivitätsparameter \\(\\theta\\) numerisch zu optimieren.\nDie Hauptänderung besteht in der Definition einer neuen Zielfunktion, neg_log_likelihood, die von scipy.optimize.minimize minimiert wird. Diese Funktion nimmt die zu optimierenden Parameter (hier theta) entgegen und berechnet die negative konzentrierte Log-Likelihood basierend auf den Trainingsdaten.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom numpy import (exp, multiply, eye, linspace, spacing, sqrt)\nfrom numpy.linalg import cholesky, solve\nfrom scipy.spatial.distance import squareform, pdist, cdist\nfrom scipy.optimize import minimize # Für die Optimierung\n\n\n59.5.1 Kriging-Basisfunktionen (Definition der Korrelation)\nDer Kernel von Kriging verwendet eine spezialisierte Basisfunktion für die Korrelation: \\[\n\\psi(x^{(i)}, x) = \\exp(- \\sum_{j=1}^k \\theta_j |x_j^{(i)} - x_j|^{p_j}).\n\\]\nFür dieses 1D-Beispiel (\\(k=1\\)) und mit \\(p_j=2\\) (quadratische euklidische Distanz implizit durch pdist-Nutzung) und \\(\\theta_j = \\theta\\) (ein einzelner Wert) vereinfacht es sich.\n\ndef build_Psi(X, theta, eps=sqrt(spacing(1))):\n    \"\"\"\n    Berechnet die Korrelationsmatrix Psi basierend auf paarweisen quadratischen\n    euklidischen Distanzen zwischen Eingabelokationen, skaliert mit theta.\n    Fügt ein kleines Epsilon zur Diagonalen für numerische Stabilität hinzu (Nugget-Effekt).\n    Hinweis: p_j ist implizit 2 aufgrund der 'sqeuclidean'-Metrik.\n    \"\"\"\n    # Sicherstellen, dass theta ein 1D-Array für das 'w'-Argument von cdist/pdist ist\n    if not isinstance(theta, np.ndarray) or theta.ndim == 0:\n        theta = np.array([theta])\n\n    D = squareform(pdist(X, metric='sqeuclidean', w=theta))\n    Psi = exp(-D)\n    # Ein kleiner Wert wird zur Diagonalen hinzugefügt für numerische Stabilität (Nugget)\n    # Korrektur: X.shape für die Anzahl der Zeilen der Identitätsmatrix\n    Psi += multiply(eye(X.shape[0]), eps)\n    return Psi\n\ndef build_psi(X_train, x_predict, theta):\n    \"\"\"\n    Berechnet den Korrelationsvektor (oder Matrix) psi zwischen neuen Vorhersageorten\n    und Trainingsdatenlokationen.\n    \"\"\"\n    # Sicherstellen, dass theta ein 1D-Array für das 'w'-Argument von cdist/pdist ist\n    if not isinstance(theta, np.ndarray) or theta.ndim == 0:\n        theta = np.array([theta])\n\n    D = cdist(x_predict, X_train, metric='sqeuclidean', w=theta)\n    psi = exp(-D)\n    return psi.T # Transponieren, um konsistent mit der Literatur zu sein (n x m oder n x 1)\n\n\n\n59.5.2 Zielfunktion für die Hyperparameter-Optimierung (Negative Log-Likelihood)\n\ndef neg_log_likelihood(params, X_train, y_train):\n    \"\"\"\n    Berechnet die negative konzentrierte Log-Likelihood für das Kriging-Modell.\n    params: ein 1D-Numpy-Array, wobei params theta ist.\n            (Falls auch p optimiert würde, wäre es params usw.)\n    X_train: (n, k)-Matrix der Trainings-Eingabelokationen\n    y_train: (n, 1)-Vektor der Trainings-Ausgabewerte\n    \"\"\"\n    theta = params\n    # Für dieses Beispiel ist p implizit auf 2 festgelegt (durch 'sqeuclidean' in build_Psi)\n    # Falls p optimiert würde, müsste es hier aus 'params' extrahiert und an build_Psi übergeben werden\n    n = X_train.shape[0]\n\n    # 1. Korrelationsmatrix Psi aufbauen\n    Psi = build_Psi(X_train, theta)\n\n    # 2. mu_hat berechnen (MLE des Mittelwerts)\n    # Verwendung der Cholesky-Zerlegung für stabile Inversion\n    try:\n        # numpy.cholesky gibt L (untere Dreiecksmatrix) zurück, daher transponieren für U (obere)\n        U = cholesky(Psi).T\n    except np.linalg.LinAlgError:\n        # Bei Fehlern (z.B. wenn Psi nicht positiv definit ist, durch schlechte theta-Werte)\n        # einen sehr großen Wert zurückgeben, um diese Parameter zu bestrafen\n        return 1e15\n\n    one = np.ones(n).reshape(-1, 1)\n    # Stabile Berechnung von Psi_inv @ y und Psi_inv @ one\n    Psi_inv_y = solve(U, solve(U.T, y_train))\n    Psi_inv_one = solve(U, solve(U.T, one))\n\n    # Berechnung von mu_hat\n    mu_hat = (one.T @ Psi_inv_y) / (one.T @ Psi_inv_one)\n    mu_hat = mu_hat.item() # Skalaren Wert extrahieren\n\n    # 3. sigma_hat_sq berechnen (MLE der Prozessvarianz)\n    y_minus_mu_one = y_train - one * mu_hat\n    # Korrekte Berechnung: (y-1*mu_hat).T @ Psi_inv @ (y-1*mu_hat) / n\n    sigma_hat_sq = (y_minus_mu_one.T @ solve(U, solve(U.T, y_minus_mu_one))) / n\n    sigma_hat_sq = sigma_hat_sq.item()\n\n    if sigma_hat_sq &lt; 1e-10: # Sicherstellen, dass sigma_hat_sq nicht-negativ und nicht zu klein ist\n        return 1e15 # Sehr großen Wert zurückgeben zur Bestrafung\n\n    # 4. Log-Determinante von Psi mittels Cholesky-Zerlegung für Stabilität berechnen\n    # ln(|Psi|) = 2 * Summe(ln(L_ii)) wobei L die untere Dreiecksmatrix der Cholesky-Zerlegung ist\n    log_det_Psi = 2 * np.sum(np.log(np.diag(U.T))) # U.T ist L\n\n    # 5. Negative konzentrierte Log-Likelihood berechnen\n    # ln(L) = - (n/2) * ln(sigma_hat_sq) - (1/2) * ln(|Psi|)\n    # Zu minimieren ist -ln(L)\n    nll = 0.5 * n * np.log(sigma_hat_sq) + 0.5 * log_det_Psi\n    return nll\n\n\n\n59.5.3 Datenpunkte für das Sinusfunktions-Beispiel\nDas Beispiel verwendet eine 1D-Sinusfunktion, gemessen an acht gleichmäßig verteilten x-Lokationen.\n\nn_train = 8 # Anzahl der Stichprobenlokationen\nX_train = np.linspace(0, 2 * np.pi, n_train, endpoint=False).reshape(-1, 1) # x-Lokationen generieren\ny_train = np.sin(X_train) # Zugehörige y-Werte (Sinus von x)\n\n# --- Originale Vorhersage-Einrichtung (festes theta=1.0) ---\ntheta_fixed = np.array([1.0])\nPsi_fixed = build_Psi(X_train, theta_fixed)\nU_fixed = cholesky(Psi_fixed).T\none_fixed = np.ones(n_train).reshape(-1, 1)\nmu_hat_fixed = (one_fixed.T @ solve(U_fixed, solve(U_fixed.T, y_train))) / \\\n               (one_fixed.T @ solve(U_fixed, solve(U_fixed.T, one_fixed)))\nmu_hat_fixed = mu_hat_fixed.item()\n\nm_predict = 100 # Anzahl der neuen Lokationen für die Vorhersage\nx_predict = np.linspace(0, 2 * np.pi, m_predict, endpoint=True).reshape(-1, 1)\npsi_fixed = build_psi(X_train, x_predict, theta_fixed)\nf_predict_fixed = mu_hat_fixed * np.ones(m_predict).reshape(-1, 1) + \\\n                  psi_fixed.T @ solve(U_fixed, solve(U_fixed.T, y_train - one_fixed * mu_hat_fixed))\n\n\n\n59.5.4 Optimierung von Theta\n\ninitial_theta_guess = np.array([1.0]) # Startwert für Theta\n# Suchbereiche für Theta (z.B. von 1e-3 bis 1e2 auf linearer Skala, wie in den Quellen empfohlen)\n# SciPy minimize erwartet Suchbereiche als Tupel von (min, max) für jeden Parameter\nbounds = [(0.001, 100.0)] # Für Theta\nprint(\"\\n--- Starte Hyperparameter-Optimierung für Theta ---\")\n# 'L-BFGS-B' wird verwendet, da es Beschränkungen (bounds) unterstützt und gut für kontinuierliche Optimierung ist.\nresult = minimize(neg_log_likelihood, initial_theta_guess, args=(X_train, y_train),\n                  method='L-BFGS-B', bounds=bounds)\n\noptimized_theta = result.x\noptimized_nll = result.fun\n\nprint(f\"Optimierung erfolgreich: {result.success}\")\nprint(f\"Optimales Theta: {optimized_theta[0]:.4f}\")  # Extract the first element if it's a single value\nprint(f\"Minimaler Negativer Log-Likelihood: {optimized_nll:.4f}\")\n\n\n\n59.5.5 Vorhersage mit optimiertem Theta\n\nPsi_optimized = build_Psi(X_train, optimized_theta)\nU_optimized = cholesky(Psi_optimized).T\none_optimized = np.ones(n_train).reshape(-1, 1)\nmu_hat_optimized = (one_optimized.T @ solve(U_optimized, solve(U_optimized.T, y_train))) / \\\n                   (one_optimized.T @ solve(U_optimized, solve(U_optimized.T, one_optimized)))\nmu_hat_optimized = mu_hat_optimized.item()\n\npsi_optimized = build_psi(X_train, x_predict, optimized_theta)\nf_predict_optimized = mu_hat_optimized * np.ones(m_predict).reshape(-1, 1) + \\\n                      psi_optimized.T @ solve(U_optimized, solve(U_optimized.T, y_train - one_optimized * mu_hat_optimized))\n\n\n\n59.5.6 Visualisierung der Ergebnisse\n\nplt.figure(figsize=(10, 6))\nplt.plot(x_predict, np.sin(x_predict), color=\"grey\", linestyle='--', label=\"Wahre Sinusfunktion\")\nplt.plot(X_train, y_train, \"bo\", markersize=8, label=f\"Messpunkte ({n_train} Punkte)\")\nplt.plot(x_predict, f_predict_fixed, color=\"red\", linestyle=':', label=f\"Kriging-Vorhersage (Fixes Theta={theta_fixed[0]:.1f})\")\nplt.plot(x_predict, f_predict_optimized, color=\"orange\", label=f\"Kriging-Vorhersage (Optimiertes Theta={optimized_theta[0]:.2f})\")\nplt.title(f\"Kriging-Vorhersage der Sinusfunktion mit {n_train} Punkten\\nOptimierung des Aktivitätsparameters Theta\")\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.legend(loc='upper right')\nplt.grid(True)\nplt.show()\n\n\n\n59.5.7 6. Ergebnisse und Diskussion\nDie grafische Darstellung der Ergebnisse zeigt die Verbesserung der Kriging-Vorhersage nach der Optimierung des Aktivitätsparameters \\(\\theta\\). Die Kurve, die mit dem optimierten \\(\\theta\\)-Wert generiert wurde, passt sich in der Regel besser an die Trainingsdaten an und bildet den wahren Funktionsverlauf präziser ab, als dies mit einem willkürlich gewählten \\(\\theta\\)-Wert der Fall wäre. Der Optimierungsalgorithmus findet den \\(\\theta\\)-Wert, der die Korrelationsstruktur der Daten am besten erklärt und somit ein “realistischeres” Modell der zugrunde liegenden Funktion liefert.\nIn diesem 1D-Beispiel ist der Unterschied möglicherweise subtil, aber in höherdimensionalen Problemen, wo Variablen unterschiedliche “Aktivitäten” aufweisen, ist die automatische Bestimmung von \\(\\vec{\\theta}\\) entscheidend für die Modellgenauigkeit und die Identifizierung wichtiger Input-Variablen.\n\n\n59.5.8 7. Fazit und Ausblick\nDieses Lernmodul hat gezeigt, wie die Maximum-Likelihood-Schätzung in Verbindung mit numerischen Optimierungsverfahren genutzt werden kann, um die Hyperparameter eines Kriging-Modells optimal an die Daten anzupassen. Die Optimierung der konzentrierten Log-Likelihood-Funktion ist ein Standardansatz, der die Robustheit und Genauigkeit von Kriging-Modellen erheblich verbessert.\nFür fortgeschrittenere Anwendungen könnten weitere Schritte unternommen werden:\n\nOptimierung von \\(\\vec{p}\\): Der Glattheitsparameter \\(\\vec{p}\\) könnte ebenfalls in den Optimierungsprozess einbezogen werden, um noch flexiblere Anpassungen zu ermöglichen.\nKriging-Regression für verrauschte Daten: Falls die Trainingsdaten Rauschen enthalten (z.B. aus physikalischen Experimenten), kann ein zusätzlicher “Nugget”-Parameter \\(\\lambda\\) in der Korrelationsmatrix optimiert werden. Dies transformiert das interpolierende Kriging in ein regressives Kriging, das Rauschen explizit modelliert und eine glattere Vorhersagekurve liefert.\nAktives Lernen und Expected Improvement (EI): Kriging-Modelle liefern nicht nur Vorhersagen, sondern auch Unsicherheitsschätzungen (Varianz) an jedem Punkt. Dies ermöglicht den Einsatz von “Infill-Kriterien” wie Expected Improvement (EI), um den nächsten vielversprechendsten Punkt für eine Funktionsauswertung intelligent auszuwählen, was besonders bei teuren Simulationen effizient ist.\nCo-Kriging (Multi-Fidelity-Modellierung): Wenn Daten aus verschiedenen Quellen mit unterschiedlicher Genauigkeit und Kosten verfügbar sind, kann Co-Kriging (auch Multi-Fidelity-Modellierung genannt) diese Daten integrieren, um genauere Modelle zu erstellen.\n\nDiese erweiterten Konzepte bilden die Grundlage für robuste und effiziente Optimierungsprozesse in vielen technischen und wissenschaftlichen Disziplinen.",
    "crumbs": [
      "Lernmodule",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Lernmodul: Erweiterung des Kriging-Modells: Numerische Optimierung der Hyperparameter</span>"
    ]
  },
  {
    "objectID": "de_kriging_optimization.html#zusatzmaterialien",
    "href": "de_kriging_optimization.html#zusatzmaterialien",
    "title": "59  Lernmodul: Erweiterung des Kriging-Modells: Numerische Optimierung der Hyperparameter",
    "section": "59.6 Zusatzmaterialien",
    "text": "59.6 Zusatzmaterialien\n\n\n\n\n\n\nInteraktive Webseite\n\n\n\n\nEine interaktive Webseite zum Thema Kriging: Optimierung der Hyperparameter ist hier zu finden: Kriging Interaktiv.\n\n\n\n\n\n\n\n\n\nJupyter-Notebook\n\n\n\n\nDas Jupyter-Notebook für dieses Lernmodul ist auf GitHub im Hyperparameter-Tuning-Cookbook Repository verfügbar.",
    "crumbs": [
      "Lernmodule",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Lernmodul: Erweiterung des Kriging-Modells: Numerische Optimierung der Hyperparameter</span>"
    ]
  },
  {
    "objectID": "a_01_intro_to_notebooks.html",
    "href": "a_01_intro_to_notebooks.html",
    "title": "Appendix A — Introduction to Jupyter Notebook",
    "section": "",
    "text": "A.1 Different Notebook cells\nJupyter Notebook is a widely used tool in the Data Science community. It is easy to use and the produced code can be run per cell. This has a huge advantage, because with other tools e.g. (pycharm, vscode, etc.) the whole script is executed. This can be a time consuming process, especially when working with huge data sets.\nThere are different cells that the notebook is currently supporting:\nAs a default, every cells in jupyter is set to “code”",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Introduction to Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "a_01_intro_to_notebooks.html#different-notebook-cells",
    "href": "a_01_intro_to_notebooks.html#different-notebook-cells",
    "title": "Appendix A — Introduction to Jupyter Notebook",
    "section": "",
    "text": "code cells\nmarkdown cells\nraw cells\n\n\n\nA.1.1 Code cells\nThe code cells are used to execute the code. They are following the logic of the choosen kernel. Therefore, it is important to keep in mind which programming language is currently used. Otherwise one might yield an error because of the wrong syntax.\nThe code cells are executed my be ▶ Run button (can be found in the header of the notebook).\n\n\nA.1.2 Markdown cells\nThe markdown cells are a usefull tool to comment the written code. Especially with the help of headers can the code be brought in a more readable format. If you are not familiar with the markdown syntax, you can find a usefull cheat sheet here: Markdown Cheat Sheeet\n\n\nA.1.3 Raw cells\nThe “Raw NBConvert” cell type can be used to render different code formats into HTML or LaTeX by Sphinx. This information is stored in the notebook metadata and converted appropriately.\n\nA.1.3.1 Usage\nTo select a desired format from within Jupyter, select the cell containing your special code and choose options from the following dropdown menus:\n\nSelect “Raw NBConvert”\nSwitch the Cell Toolbar to “Raw Cell Format” (The cell toolbar can be found under View)\nChose the appropriate “Raw NBConvert Format” within the cell\n\nData Science is fun",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Introduction to Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "a_01_intro_to_notebooks.html#install-packages",
    "href": "a_01_intro_to_notebooks.html#install-packages",
    "title": "Appendix A — Introduction to Jupyter Notebook",
    "section": "A.2 Install Packages",
    "text": "A.2 Install Packages\nBecause python is a heavily used programming language, there are many different packags that can make your life easier. Sadly, there are only a few standard packages that are already included in your python enviroment. If you have the need to install a new package in your enviroment, you can simply do that by exectuing the following code snippet in a code cell\n!pip install numpy\n\nThe ! is used to run the cell as a shell command\npip is package manager for python packages.\nnumpy is the the package you want to install\n\nHint: It is often usefull to restart the kernel after installing a package, otherwise loading the package could lead to an error.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Introduction to Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "a_01_intro_to_notebooks.html#load-packages",
    "href": "a_01_intro_to_notebooks.html#load-packages",
    "title": "Appendix A — Introduction to Jupyter Notebook",
    "section": "A.3 Load Packages",
    "text": "A.3 Load Packages\nAfter successfully installing the package it is necessary to import them before you can work with them. The import of the packages is done in the following way:\nimport numpy as np\nThe imported packages are often abbreviated. This is because you need to specify where the function is coming from.\nThe most common abbreviations for data science packages are:\n\nAbbreviations for data science packages\n\n\nAbbreviation\nPackage\nImport\n\n\n\n\nnp\nnumpy\nimport numpy as np\n\n\npd\npandas\nimport pandas as pd\n\n\nplt\nmatplotlib\nimport matplotlib.pyplot as plt\n\n\npx\nplotly\nimport plotly.exprss as px\n\n\ntf\ntensorflow\nimport tensorflow as tf\n\n\nsns\nseaborn\nimport seaborn as sns\n\n\ndt\ndatetime\nimport datetime as dt\n\n\npkl\npickle\nimport pickle as pkl",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Introduction to Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "a_01_intro_to_notebooks.html#functions-in-python",
    "href": "a_01_intro_to_notebooks.html#functions-in-python",
    "title": "Appendix A — Introduction to Jupyter Notebook",
    "section": "A.4 Functions in Python",
    "text": "A.4 Functions in Python\nBecause python is not using Semicolon’s it is import to keep track of indentation in your code. The indentation works as a placeholder for the semicolons. This is especially important if your are defining loops, functions, etc. …\nExample: We are defining a function that calculates the squared sum of its input parameters\n\ndef squared_sum(x,y): \n    z = x**2 + y**2\n    return z\n\nIf you are working with something that needs indentation, it will be already done by the notebook.\nHint: Keep in mind that is good practice to use the return parameter. If you are not using return and a function has multiple paramaters that you would like to return, it will only return the last one defined.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Introduction to Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "a_01_intro_to_notebooks.html#list-of-useful-jupyter-notebook-shortcuts",
    "href": "a_01_intro_to_notebooks.html#list-of-useful-jupyter-notebook-shortcuts",
    "title": "Appendix A — Introduction to Jupyter Notebook",
    "section": "A.5 List of Useful Jupyter Notebook Shortcuts",
    "text": "A.5 List of Useful Jupyter Notebook Shortcuts\n\nList of useful Jupyter Notebook Shortcuts\n\n\n\n\n\n\n\nFunction\nKeyboard Shortcut\nMenu Tools\n\n\n\n\nSave notebook\nEsc + s\nFile → Save and Checkpoint\n\n\nCreate new Cell\nEsc + a (above),  Esc + b (below)\nInsert → Cell above; Insert → Cell below\n\n\nRun Cell\nCtrl + enter\nCell → Run Cell\n\n\nCopy Cell\nc\nCopy Key\n\n\nPaste Cell\nv\nPaste Key\n\n\nInterrupt Kernel\nEsc + i i\nKernel → Interrupt\n\n\nRestart Kernel\nEsc + 0 0\nKernel → Restart\n\n\n\nIf you combine everything you can create beautiful graphics\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Generate 100 random data points along 3 dimensions\nx, y, scale = np.random.randn(3, 100)\nfig, ax = plt.subplots()\n\n# Map each onto a scatterplot we'll create with Matplotlib\nax.scatter(x=x, y=y, c=scale, s=np.abs(scale)*500)\nax.set(title=\"Some random data, created with the Jupyter Notebook!\")\nplt.show()",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Introduction to Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "a_02_git_intro_en.html",
    "href": "a_02_git_intro_en.html",
    "title": "Appendix B — Git Introduction",
    "section": "",
    "text": "B.1 Learning Objectives\nIn this learning unit, you will learn how to set up Git as a version control system for a project. The most important Git commands will be explained. You will learn how to track and manage changes to your projects with Git. Specifically:",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Git Introduction</span>"
    ]
  },
  {
    "objectID": "a_02_git_intro_en.html#learning-objectives",
    "href": "a_02_git_intro_en.html#learning-objectives",
    "title": "Appendix B — Git Introduction",
    "section": "",
    "text": "Initializing a repository: git init\nIgnoring files: .gitignore\nAdding files to the staging area: git add\nChecking status changes: git status\nReviewing history: git log\nCreating a new branch: git branch\nSwitching to the current branch: git switch and git checkout\nMerging two branches: git merge\nResolving conflicts\nReverting changes: git revert\nUploading changes to GitLab: git push\nDownloading changes from GitLab: git pull\nAdvanced: git rebase",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Git Introduction</span>"
    ]
  },
  {
    "objectID": "a_02_git_intro_en.html#basics-of-git",
    "href": "a_02_git_intro_en.html#basics-of-git",
    "title": "Appendix B — Git Introduction",
    "section": "B.2 Basics of Git",
    "text": "B.2 Basics of Git\n\nB.2.1 Initializing a Repository: git init\nTo set up Git as a version control system for your project, you need to initialize a new Git repository at the top-level folder, which is the working directory of your project. This is done using the git init command.\nAll files in this folder and its subfolders will automatically become part of the repository. Creating a Git repository is similar to adding an all-powerful passive observer of all things to your project. Git sits there, observes, and takes note of even the smallest changes, such as a single character in a file within a repository with hundreds of files. And it will tell you where these changes occurred if you forget. Once Git is initialized, it monitors all changes made within the working directory, and it tracks the history of events from that point forward. For this purpose, a historical timeline is created for your project, referred to as a “branch,” and the initial branch is named main. So, when someone says they are on the main branch or working on the main branch, it means they are in the historical main timeline of the project. The Git repository, often abbreviated as repo, is a virtual representation of your project, including its history and branches, a book, if you will, where you can look up and retrieve the entire history of the project: you work in your working directory, and the Git repository tracks and stores your work.\n\n\nB.2.2 Ignoring Files: .gitignore\nIt’s useful that Git watches and keeps an eye on everything in your project. However, in most projects, there are files and folders that you don’t need or want to keep an eye on. These may include system files, local project settings, libraries with dependencies, and so on.\nYou can exclude any file or folder from your Git repository by including them in the .gitignore file. In the .gitignore file, you create a list of file names, folder names, and other items that Git should not track, and Git will ignore these items. Hence the name “gitignore.” Do you want to track a file that you previously ignored? Simply remove the mention of the file in the gitignore file, and Git will start tracking it again.\n\n\nB.2.3 Adding Changes to the Staging Area: git add\nThe interesting thing about Git as an all-powerful, passive observer of all things is that it’s very passive. As long as you don’t tell Git what to remember, it will passively observe the changes in the project folder but do nothing.\nWhen you make a change to your project that you want Git to include in the project’s history to take a snapshot of so you can refer back to it later, your personal checkpoint, if you will, you need to first stage the changes in the staging area. What is the staging area? The staging area is where you collect changes to files that you want to include in the project’s history.\nThis is done using the git add command. You can specify which files you want to add by naming them, or you can add all of them using -A. By doing this, you’re telling Git that you’ve made changes and want it to remember these particular changes so you can recall them later if needed. This is important because you can choose which changes you want to stage, and those are the changes that will eventually be transferred to the history.\nNote: When you run git add, the changes are not transferred to the project’s history. They are only transferred to the staging area.\n\nExample B.1 (Example of git add from the beginning)  \n# Create a new directory for your\n# repository and navigate to that directory:\n\nmkdir my-repo\ncd my-repo\n\n# Initialize the repository with git init:\n\ngit init\n\n# Create a .gitignore file for Python code.\n# You can use a template from GitHub:\n\ncurl https://raw.githubusercontent.com/github/gitignore/master/Python.gitignore -o .gitignore\n\n# Add your files to the repository using git add:\n\ngit add .\nThis adds all files in the current directory to the repository, except for the files listed in the .gitignore file.\n\n\n\nB.2.4 Transferring Changes to Memory: git commit\nThe power of Git becomes evident when you start transferring changes to the project history. This is done using the git commit command. When you run git commit, you inform Git that the changes in the staging area should be added to the history of the project so that they can be referenced or retrieved later.\nAdditionally, you can add a commit message with the -m option to explain what changes were made. So when you look back at the project history, you can see that you added a new feature.\ngit commit creates a snapshot, an image of the current state of your project at that specific time, and adds it to the branch you are currently working on.\nAs you work on your project and transfer more snapshots, the branch grows and forms a timeline of events. This means you can now look back at every transfer in the branch and see what your code looked like at that time.\nYou can compare any phase of your code with any other phase of your code to find errors, restore deleted code, or do things that would otherwise not be possible, such as resetting the project to a previous state or creating a new timeline from any point.\nSo how often should you add these commits? My rule of thumb is not to commit too often. It’s better to have a Git repository with too many commits than one with too few commits.\n\nExample B.2 (Continuing the example from above:) After adding your files with git add, you can create a commit to save your changes. Use the git commit command with the -m option to specify your commit message:\ngit commit -m \"My first commit message\"\nThis creates a new commit with the added files and the specified commit message.\n\n\n\nB.2.5 Check the Status of Your Repository: git status\nIf you’re wondering what you’ve changed in your project since the last commit snapshot, you can always check the Git status. Git will list every modified file and the current status of each file.\nThis status can be either:\n\nUnchanged (unmodified), meaning nothing has changed since you last transferred it, or\nIt’s been changed (changed) but not staged (staged) to be transferred into the history, or\nSomething has been added to staging (staged) and is ready to be transferred into the history.\n\nWhen you run git status, you get an overview of the current state of your project.\n\nExample B.3 (Continuing the example from above:) The git status command displays the status of your working directory and the staging area. It shows you which files have been modified, which files are staged for commit, and which files are not yet being tracked:\ngit status\ngit status is a useful tool to keep track of your changes and ensure that you have added all the desired files for commit.\n\n\n\nB.2.6 Review Your Repository’s History: git log\n\nExample B.4 (Continuing the example from above:) You can view the history of your commits with the git log command. This command displays a list of all the commits in the current branch, along with information such as the author, date, and commit message:\ngit log\nThere are many options to customize the output of git log. For example, you can use the --pretty option to change the format of the output:\ngit log --pretty=oneline\nThis displays each commit in a single line.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Git Introduction</span>"
    ]
  },
  {
    "objectID": "a_02_git_intro_en.html#branches-timelines",
    "href": "a_02_git_intro_en.html#branches-timelines",
    "title": "Appendix B — Git Introduction",
    "section": "B.3 Branches (Timelines)",
    "text": "B.3 Branches (Timelines)\n\nB.3.1 Creating an Alternative Timeline: git branch\nIn the course of developing a project, you often reach a point where you want to add a new feature, but doing so might require changing the existing code in a way that could be challenging to undo later.\nOr maybe you just want to experiment and be able to discard your work if the experiment fails. In such cases, Git allows you to create an alternative timeline called a branch to work in.\nThis new branch has its own name and exists in parallel with the main branch and all other branches in your project.\nDuring development, you can switch between branches and work on different versions of your code concurrently. This way, you can have a stable codebase in the main branch while developing an experimental feature in a separate branch. When you switch from one branch to another, the code you’re working on is automatically reset to the latest commit of the branch you’re currently in.\nIf you’re working in a team, different team members can work on their own branches, creating an entire universe of alternative timelines for your project. When features are completed, they can be seamlessly merged back into the main branch.\n\nExample B.5 (Continuing the example from above:) To create a new branch, you can use the git branch command with the name of the new branch as an argument:\ngit branch my-tests\n\n\n\nB.3.2 The Pointer to the Current Branch: HEAD\nHow does Git know where you are on the timeline, and how can you keep track of your position?\nYou’re always working at the tip (HEAD) of the currently active branch. The HEAD pointer points there quite literally. In a new project archive with just a single main branch and only new commits being added, HEAD always points to the latest commit in the main branch. That’s where you are.\nHowever, if you’re in a repository with multiple branches, meaning multiple alternative timelines, HEAD will point to the latest commit in the branch you’re currently working on.\n\n\nB.3.3 Switching to an Alternative Timeline: git switch\nAs your project grows, and you have multiple branches, you need to be able to switch between these branches. This is where the switch command comes into play.\nAt any time, you can use the git switch command with the name of the branch you want to switch to, and HEAD moves from your current branch to the one you specified.\nIf you’ve made changes to your code before switching, Git will attempt to carry those changes over to the branch you’re switching to. However, if these changes conflict with the target branch, the switch will be canceled.\nTo resolve this issue without losing your changes, return to the original branch, add and commit your recent changes, and then perform the switch.\n\n\nB.3.4 Switching to an Alternative Timeline and Making Changes: git checkout\nTo switch between branches, you can also use the git checkout command. It works similarly to git switch for this purpose: you pass the name of the branch you want to switch to, and HEAD moves to the beginning of that branch.\nBut checkout can do more than just switch to another timeline. With git checkout, you can also move to any commit point in any timeline. In other words, you can travel back in time and work on code from the past.\nTo do this, use git checkout and provide the commit ID. This is an automatically generated, random combination of letters and numbers that identifies each commit. You can retrieve the commit ID using git log. When you run git log, you get a list of all the commits in your repository, starting with the most recent ones.\nWhen you use git checkout with an older commit ID, you check out a commit in the middle of a branch. This disrupts the timeline, as you’re actively attempting to change history. Git doesn’t want you to do that because, much like in a science fiction movie, altering the past might also alter the future. In our case, it would break the version control branch’s coherence.\nTo prevent you from accidentally disrupting time and altering history, checking out an earlier commit in any branch results in the warning “Detached Head,” which sounds rather ominous. The “Detached Head” warning is appropriate because it accurately describes what’s happening. Git literally detaches the head from the branch and sets it aside.\nNow, you’re working outside of time in a space unbound to any timeline, which again sounds rather threatening but is perfectly fine in reality.\nTo continue working on this past code, all you need to do is reattach it to the timeline. You can use git branch to create a new branch, and the detached head will automatically attach to this new branch.\nInstead of breaking the history, you’ve now created a new alternative timeline that starts in the past, allowing you to work safely. You can continue working on the branch as usual.\n\nExample B.6 (Continuing the example from above:) To switch to a new branch, you can use the git checkout command:\ngit checkout meine-tests\nNow you’re using the new branch and can make changes independently from the original branch.\n\n\n\nB.3.5 The Difference Between checkout and switch\nWhat is the difference between git switch and git checkout? git switch and git checkout are two different commands that both serve the purpose of switching between branches. You can use both to switch between branches, but they have an important distinction. git switch is a new command introduced with Git 2.23. git checkout is an older command that has existed since Git 1.6.0. So, git switch and git checkout have different origins. git switch was introduced to separate the purposes of git checkout. git checkout has two different purposes: 1. It can be used to switch between branches, and 2. It can be used to reset files to the state of the last commit.\nHere’s an example: In my project, I made a change since the last commit, but I haven’t staged it yet. Then, I realized that I actually don’t want this change. I want to reset the file to the state before the last commit. As long as I haven’t committed my changes, I can do this with git checkout by targeting the specific file. So, if that file is named main.js, I can say: git checkout main.js. And the file will be reset to the state of the last commit, which makes sense. I’m checking out the file from the last commit.\nBut that’s quite different from switching between the beginning of one branch to another. git switch and git restore were introduced to separate these two operations. git switch is for switching between branches, and git restore is for resetting the specified file to the state of the last commit. If you try to restore a file with git switch, it simply won’t work. It’s not intended for that. As I mentioned earlier, it’s about separating concerns.\n\nExample B.7 (Difference between git switch and git checkout) Here’s an example demonstrating how to initialize a repository and switch between branches:\n# Create a new directory for your repository\n# and navigate to that directory:\nmkdir my-repo\ncd my-repo\n\n# Initialize the repository with git init:\ngit init\n\n# Create a new branch with git branch:\ngit branch my-new-branch\n\n# Switch to the new branch using git switch:\ngit switch my-new-branch\n\n# Alternatively, you can also use git checkout\n# to switch to the new branch:\n\ngit checkout my-new-branch\nBoth commands lead to the same result: You are now on the new branch.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Git Introduction</span>"
    ]
  },
  {
    "objectID": "a_02_git_intro_en.html#merging-branches-and-resolving-conflicts",
    "href": "a_02_git_intro_en.html#merging-branches-and-resolving-conflicts",
    "title": "Appendix B — Git Introduction",
    "section": "B.4 Merging Branches and Resolving Conflicts",
    "text": "B.4 Merging Branches and Resolving Conflicts\n\nB.4.1 git merge: Merging Two Timelines\nGit allows you to split your development work into as many branches or alternative timelines as you like, enabling you to work on many different versions of your code simultaneously without losing or overwriting any of your work.\nThis is all well and good, but at some point, you need to bring those various versions of your code back together into one branch. That’s where git merge comes in.\nConsider an example where you have two branches, a main branch and an experimental branch called experimental-branch. In the experimental branch, there is a new feature. To merge these two branches, you set HEAD to the branch where you want to incorporate the code and execute git merge followed by the name of the branch you want to merge. HEAD is a special pointer that points to the current branch. When you run git merge, it combines the code from the branch associated with HEAD with the code from the branch specified by the branch name you provide.\n# Initialize the repository\ngit init\n\n# Create a new branch called \"experimental-branch\"\ngit branch experimental-branch\n\n# Switch to the \"experimental-branch\"\ngit checkout experimental-branch\n\n# Add the new feature here and\n# make a commit\n# ...\n\n# Switch back to the \"main\" branch\ngit checkout main\n\n# Perform the merge\ngit merge experimental-branch\nDuring the merge, matching pieces of code in the branches overlap, and any new code from the branch being merged is added to the project. So now, the main branch also contains the code from the experimental branch, and the events of the two separate timelines have been merged into a single one. What’s interesting is that even though the experimental branch was merged with the main branch, the last commit of the experimental branch remains intact, allowing you to continue working on the experimental branch separately if you wish.\n\n\nB.4.2 Resolving Conflicts When Merging\nMerging branches where there are no code changes at the same place in both branches is a straightforward process. It’s also a rare process. In most cases, there will be some form of conflict between the branches – the same code or the same code area has been modified differently in the different branches. Merging two branches with such conflicts will not work, at least not automatically.\nIn this case, Git doesn’t know how to merge this code. So, when such a situation occurs, it’s marked as a conflict, and the merging process is halted. This might sound more dramatic than it is. When you get a conflict warning, Git is saying there are two different versions here, and Git needs to know which one you want to keep. To help you figure out the conflict, Git combines all the code into a single file and automatically marks the conflicting code as the current change, which is the original code from the branch you’re working on, or as the incoming change, which is the code from the file you’re trying to merge.\nTo resolve this conflict, you’ll edit the file to literally resolve the code conflict. This might mean accepting either the current or incoming change and discarding the other. It could mean combining both changes or something else entirely. It’s up to you. So, you edit the code to resolve the conflict. Once you’ve resolved the conflict by editing the code, you add the new conflict-free version to the staging area with git add and then commit the merged code with git commit. That’s how the conflict is resolved.\nA merge conflict occurs when Git struggles to automatically merge changes from two different branches. This usually happens when changes were made to the same line in the same file in both branches. To resolve a merge conflict, you must manually edit the affected files and choose the desired changes. Git marks the conflict areas in the file with special markings like &lt;&lt;&lt;&lt;&lt;&lt;&lt;, =======, and &gt;&gt;&gt;&gt;&gt;&gt;&gt;. You can search for these markings and manually select the desired changes. After resolving the conflicts, you can add the changes with git add and create a new commit with git commit to complete the merge.\n\nExample B.8  \n# Perform the merge (this will cause a conflict)\ngit merge experimenteller-branch\n\n# Open the affected file in an editor and manually resolve the conflicts\n# ...\n\n# Add the modified file\ngit add &lt;filename&gt;\n\n# Create a new commit\ngit commit -m \"Resolved conflicts\"\n\n\n\nB.4.3 git revert: Undoing Something\nOne of the most powerful features of any software tool is the “Undo” button. Make a mistake, press “Undo,” and it’s as if it never happened. However, that’s not quite as simple when an all-powerful, passive observer is watching and recording your project’s history. How do you undo something that you’ve added to the history without rewriting the history?\nThe answer is that you can overwrite the history with the git reset command, but that’s quite risky and not a good practice.\nA better solution is to work with the historical timeline and simply place an older version of your code at the top of the branch. This is done with git revert. To make this work, you need to know the commit ID of the commit you want to go back to.\nThe commit ID is a machine-generated set of random numbers and letters, also known as a hash. To get a list of all the commits in the repository, including the commit ID and commit message, you can run git log.\n# Show the list of all operations in the repository\ngit log\nBy the way, it’s a good idea to leave clear and informative commit messages for this reason. This way, you know what happened in your previous commits. Once you’ve found the commit you want to revert to, call that commit ID with git revert, and then the ID. This will create a new commit at the top of the branch with the code from the reference commit. To transfer the code to the branch, add a commit message and save it. Now, the last commit in your branch matches the commit you’re reverting to, and your project’s history remains intact.\n\nExample B.9 (An example with git revert)  \n# Initialize a new repository\ngit init\n\n# Create a new file\necho \"Hello, World\" &gt; file.txt\n\n# Add the file to the repository\ngit add file.txt\n\n# Create a new commit\ngit commit -m \"First commit\"\n\n# Modify the file\necho \"Goodbye, World\" &gt; file.txt\n\n# Add the modified file\ngit add file.txt\n\n# Create a new commit\ngit commit -m \"Second commit\"\n\n# Use git log to find the commit ID of the second commit\ngit log\n\n# Use git revert to undo the changes from the second commit\ngit revert &lt;commit-id&gt;\n\nTo download the students branch from the repository git@git-ce.rwth-aachen.de:spotseven-lab/numerische-mathematik-sommersemester2023.git to your local machine, add a file, and upload the changes, you can follow these steps:\n\nExample B.10 (An example with git clone, git checkout, git add, git commit, git push)  \n# Clone the repository to your local machine:\ngit clone git@git-ce.rwth-aachen.de:spotseven-lab/numerische-mathematik-sommersemester2023.git\n\n# Change to the cloned repository:\ncd numerische-mathematik-sommersemester2023\n\n# Switch to the students branch:\ngit checkout students\n\n# Create the Test folder if it doesn't exist:\nmkdir Test\n\n# Create the Testdatei.txt file in the Test folder:\ntouch Test/Testdatei.txt\n\n# Add the file with git add:\ngit add Test/Testdatei.txt\n\n# Commit the changes with git commit:\ngit commit -m \"Added Testdatei.txt\"\n\n# Push the changes with git push:\ngit push origin students\nThis will upload the changes to the server and update the students branch in the repository.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Git Introduction</span>"
    ]
  },
  {
    "objectID": "a_02_git_intro_en.html#downloading-from-gitlab",
    "href": "a_02_git_intro_en.html#downloading-from-gitlab",
    "title": "Appendix B — Git Introduction",
    "section": "B.5 Downloading from GitLab",
    "text": "B.5 Downloading from GitLab\nTo download changes from a GitLab repository to your local machine, you can use the git pull command. This command downloads the latest changes from the specified remote repository and merges them with your local repository.\nHere is an example:\n\nExample B.11 (An example with git pull)  \n\n# Navigate to the local repository\n# linked to the GitHub repository:\ncd my-local-repository\n\n# Make sure you are in the correct branch:\ngit checkout main\n\n# Download the latest changes from GitHub:\ngit pull origin main\nThis downloads the latest changes from the main branch of the remote repository named “origin” and merges them with your local repository.\n\nIf there are conflicts between the downloaded changes and your local changes, you will need to resolve them manually before proceeding.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Git Introduction</span>"
    ]
  },
  {
    "objectID": "a_02_git_intro_en.html#advanced",
    "href": "a_02_git_intro_en.html#advanced",
    "title": "Appendix B — Git Introduction",
    "section": "B.6 Advanced",
    "text": "B.6 Advanced\n\nB.6.1 git rebase: Moving the Base of a Branch\nIn some cases, you may need to “rewrite history.” A common scenario is that you’ve been working on a new feature in a feature branch, and you realize that the work should have actually happened in the main branch.\nTo resolve this issue and make it appear as if the work occurred in the main branch, you can reset the experimental branch. “Rebase” literally means detaching the base of the experimental branch and moving it to the beginning of another branch, giving the branch a new base, thus “rebasing.”\nThis operation is performed from the branch you want to “rebase.” You use git rebase and specify the branch you want to use as the new base. If there are no conflicts between the experimental branch and the branch you want to rebase onto, this process happens automatically.\nIf there are conflicts, Git will guide you through the conflict resolution process for each commit from the rebase branch.\nThis may sound like a lot, but there’s a good reason for it. You are literally rewriting history by transferring commits from one branch to another. To maintain the coherence of the new version history, there should be no conflicts within the commits. So, you need to resolve them one by one until the history is clean. It goes without saying that this can be a fairly labor-intensive process. Therefore, you should not use git rebase frequently.\n\nExample B.12 (An example with git rebase) git rebase is a command used to change the base of a branch. This means that commits from the branch are applied to a new base, which is usually another branch. It can be used to clean up the repository history and avoid merge conflicts.\nHere is an example showing how to use git rebase:\n\nIn this example, we initialize a new Git repository and create a new file. We add the file to the repository and make an initial commit. Then, we create a new branch called “feature” and switch to that branch. We make changes to the file in the feature branch and create a new commit.\nThen, we switch back to the main branch and make changes to the file again. We add the modified file and make another commit.\nTo rebase the feature branch onto the main branch, we first switch to the feature branch and then use the git rebase command with the name of the main branch as an argument. This applies the commits from the feature branch to the main branch and changes the base of the feature branch.\n\n# Initialize a new repository\ngit init\n# Create a new file\necho \"Hello World\" &gt; file.txt\n# Add the file to the repository\ngit add file.txt\n# Create an initial commit\ngit commit -m \"Initial commit\"\n# Create a new branch called \"feature\"\ngit branch feature\n# Switch to the \"feature\" branch\ngit checkout feature\n# Make changes to the file in the \"feature\" branch\necho \"Hello Feature World\" &gt; file.txt\n# Add the modified file\ngit add file.txt\n# Create a new commit in the \"feature\" branch\ngit commit -m \"Feature commit\"\n# Switch back to the \"main\" branch\ngit checkout main\n# Make changes to the file in the \"main\" branch\necho \"Hello Main World\" &gt; file.txt\n# Add the modified file\ngit add file.txt\n# Create a new commit in the \"main\" branch\ngit commit -m \"Main commit\"\n# Use git rebase to rebase the \"feature\" branch\n# onto the \"main\" branch\ngit checkout feature\ngit rebase main",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Git Introduction</span>"
    ]
  },
  {
    "objectID": "a_02_git_intro_en.html#exercises",
    "href": "a_02_git_intro_en.html#exercises",
    "title": "Appendix B — Git Introduction",
    "section": "B.7 Exercises",
    "text": "B.7 Exercises\nIn order to be able to carry out this exercise, we provide you with a functional working environment. This can be accessed here. You can log in using your GMID. If you do not have one, you can generate one here. Once you have successfully logged in to the server, you must open a terminal instance. You are now in a position to carry out the exercise.\nAlternatively, you can also carry out the exercise locally on your computer, but then you will need to install git.\n\nB.7.1 Create project folder\nFirst create the test-repo folder via the command line and then navigate to this folder using the corresponding command.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Git Introduction</span>"
    ]
  },
  {
    "objectID": "a_02_git_intro_en.html#initialize-repo",
    "href": "a_02_git_intro_en.html#initialize-repo",
    "title": "Appendix B — Git Introduction",
    "section": "B.8 Initialize repo",
    "text": "B.8 Initialize repo\nNow initialize the repository so that the future project, which will be saved in the test-repo folder, and all associated files are versioned.\n\nB.8.1 Do not upload / ignore certain file types\nIn order to carry out this exercise, you must first download a file which you then have git ignore. To do this, download the current examination regulations for the Bachelor’s degree program in Electrical Engineering using the following command curl -o pruefungsordnung.pdf https://www.th-koeln.de/mam/downloads/deutsch/studium/studiengaenge/f07/ordnungen_plaene/f07_bpo_ba_ekb_2021_01_04.pdf.\nThe PDF file has been stored in the root directory of your repo and you must now exclude it from being uploaded so that no changes to this file are tracked. Please note that not only this one PDF file should be ignored, but all PDF files in the repo.\n\n\nB.8.2 Create file and stage it\nIn order to be able to commit a change later and thus make it traceable, it must first be staged. However, as we only have a PDF file so far, which is to be ignored by git, we cannot stage anything. Therefore, in this task, a file test.txt with some string as content is to be created and then staged.\n\n\nB.8.3 Create another file and check status\nTo understand the status function, you should create the file test2.txt and then call the status function of git.\n\n\nB.8.4 Commit changes\nAfter the changes to the test.txt file have been staged and these are now to be transferred to the project process, they must be committed. Therefore, in this step you should perform a corresponding commit in the current branch with the message test-commit. Finally, you should also display the history of the commits.\n\n\nB.8.5 Create a new branch and switch to it\nIn this task, you are to create a new branch with the name change-text in which you will later make changes. You should then switch to this branch.\n\n\nB.8.6 Commit changes in the new branch\nTo be able to merge the new branch into the main branch later, you must first make changes to the test.txt file. To do this, open the file and simply change the character string in this file before saving the changes and closing the file. Before you now commit the file, you should reset the file to the status of the last commit for practice purposes and thus undo the change. After you have done this, open the file test.txt again and change the character string again before saving and closing the file. This time you should commit the file test.txt and then commit it with the message test-commit2.\n\n\nB.8.7 Merge branch into main\nAfter you have committed the change to the test.txt file, you should merge the change-text branch including the change into the main branch so that it is also available there.\n\n\nB.8.8 Resolve merge conflict\nTo simulate a merge conflict, you must first change the content of the test.txt file before you commit the change. Then switch to the branch change-text and change the file test.txt there as well before you commit the change. Now you should try to merge the branch change-text into the main branch and solve the problems that occur in order to be able to perform the merge successfully.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Git Introduction</span>"
    ]
  },
  {
    "objectID": "a_03_python_intro_en.html",
    "href": "a_03_python_intro_en.html",
    "title": "Appendix C — Python",
    "section": "",
    "text": "C.1 Data Types and Precision in Python\nThe float16 data type in numpy represents a half-precision floating point number. It uses 16 bits of memory, which gives it a precision of about 3 decimal digits.\nThe float32 data type in numpy represents a single-precision floating point number. It uses 32 bits of memory, which gives it a precision of about 7 decimal digits. On the other hand, float64 represents a double-precision floating point number. It uses 64 bits of memory, which gives it a precision of about 15 decimal digits.\nThe reason float16 and float32 show fewer digits is because it has less precision due to using less memory. The bits of memory are used to store the sign, exponent, and fraction parts of the floating point number, and with fewer bits, you can represent fewer digits accurately.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Python</span>"
    ]
  },
  {
    "objectID": "a_03_python_intro_en.html#data-types-and-precision-in-python",
    "href": "a_03_python_intro_en.html#data-types-and-precision-in-python",
    "title": "Appendix C — Python",
    "section": "",
    "text": "Example C.1 (16 versus 32 versus 64 bit)  \n\nimport numpy as np\n\n# Define a number\nnum = 0.123456789123456789\n\nnum_float16 = np.float16(num)\nnum_float32 = np.float32(num)\nnum_float64 = np.float64(num)\n\nprint(\"float16: \", num_float16) \nprint(\"float32: \", num_float32)\nprint(\"float64: \", num_float64)\n\nfloat16:  0.1235\nfloat32:  0.12345679\nfloat64:  0.12345678912345678",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Python</span>"
    ]
  },
  {
    "objectID": "a_03_python_intro_en.html#recommendations",
    "href": "a_03_python_intro_en.html#recommendations",
    "title": "Appendix C — Python",
    "section": "C.2 Recommendations",
    "text": "C.2 Recommendations\nBeginner’s Guide to Python",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Python</span>"
    ]
  },
  {
    "objectID": "a_04_gp_background.html",
    "href": "a_04_gp_background.html",
    "title": "Appendix D — Gaussian Processes—Some Background Information",
    "section": "",
    "text": "D.1 Gaussian Process Prior\nThe concept of GP (Gaussian Process) regression can be understood as a simple extension of linear modeling. It is worth noting that this approach goes by various names and acronyms, including “kriging,” a term derived from geostatistics, as introduced by Matheron in 1963. Additionally, it is referred to as Gaussian spatial modeling or a Gaussian stochastic process, and machine learning (ML) researchers often use the term Gaussian process regression (GPR). In all of these instances, the central focus is on regression. This involves training on both inputs and outputs, with the ultimate objective of making predictions and quantifying uncertainty (referred to as uncertainty quantification or UQ).\nHowever, it’s important to emphasize that GPs are not a universal solution for every problem. Specialized tools may outperform GPs in specific, non-generic contexts, and GPs have their own set of limitations that need to be considered.\nIn the context of GP, any finite collection of realizations, which is represented by \\(n\\) observations, is modeled as having a multivariate normal (MVN) distribution. The characteristics of these realizations can be fully described by two key parameters:",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Gaussian Processes---Some Background Information</span>"
    ]
  },
  {
    "objectID": "a_04_gp_background.html#gaussian-process-prior",
    "href": "a_04_gp_background.html#gaussian-process-prior",
    "title": "Appendix D — Gaussian Processes—Some Background Information",
    "section": "",
    "text": "Their mean, denoted as an \\(n\\)-vector \\(\\mu\\).\nThe covariance matrix, denoted as an \\(n \\times n\\) matrix \\(\\Sigma\\). This covariance matrix encapsulates the relationships and variability between the individual realizations within the collection.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Gaussian Processes---Some Background Information</span>"
    ]
  },
  {
    "objectID": "a_04_gp_background.html#covariance-function",
    "href": "a_04_gp_background.html#covariance-function",
    "title": "Appendix D — Gaussian Processes—Some Background Information",
    "section": "D.2 Covariance Function",
    "text": "D.2 Covariance Function\nThe covariance function is defined by inverse exponentiated squared Euclidean distance: \\[\n\\Sigma(\\vec{x}, \\vec{x}') = \\exp\\{ - || \\vec{x} - \\vec{x}'||^2 \\},\n\\] where \\(\\vec{x}\\) and \\(\\vec{x}'\\) are two points in the \\(k\\)-dimensional input space and \\(\\| \\cdot \\|\\) denotes the Euclidean distance, i.e., \\[\n|| \\vec{x} - \\vec{x}'||^2 = \\sum_{i=1}^k (x_i - x_i')^2.\n\\]\nAn 1-d example is shown in Figure D.1.\n\n\n\n\n\n\n\n\nFigure D.1: One-dim inverse exponentiated squared Euclidean distance\n\n\n\n\n\nThe covariance function is also referred to as the kernel function. The Gaussian kernel uses an additional parameter, \\(\\sigma^2\\), to control the rate of decay. This parameter is referred to as the length scale or the characteristic length scale. The covariance function is then defined as\n\\[\n\\Sigma(\\vec{x}, \\vec{x}') = \\exp\\{ - || \\vec{x} - \\vec{x}'||^2 / (2 \\sigma^2) \\}.\n\\tag{D.1}\\]\nThe covariance decays exponentially fast as \\(\\vec{x}\\) and \\(\\vec{x}'\\) become farther apart. Observe that\n\\[\n\\Sigma(\\vec{x},\\vec{x}) = 1\n\\] and\n\\[\n\\Sigma(\\vec{x}, \\vec{x}') &lt; 1\n\\] for \\(\\vec{x} \\neq \\vec{x}'\\). The function \\(\\Sigma(\\vec{x},\\vec{x}')\\) must be positive definite.\n\nRemark D.1 (Kriging and Gaussian Basis Functions). The Kriging basis function (Equation 9.1) is related to the 1-dim Gaussian basis function (Equation D.1), which is defined as \\[\n\\Sigma(\\vec{x}^{(i)}, \\vec{x}^{(j)}) = \\exp\\{ - || \\vec{x}^{(i)} - \\vec{x}^{(j)}||^2 / (2\\sigma^2) \\}.\n\\tag{D.2}\\]\nThere are some differences between Gaussian basis functions and Kriging basis functions:\n\nWhere the Gaussian basis function has \\(1/(2\\sigma^2)\\), the Kriging basis has a vector \\(\\theta = [\\theta_1, \\theta_2, \\ldots, \\theta_k]^T\\).\nThe \\(\\theta\\) vector allows the width of the basis function to vary from dimension to dimension.\nIn the Gaussian basis function, the exponent is fixed at 2, Kriging allows this exponent \\(p_l\\) to vary (typically from 1 to 2).\n\n\n\nD.2.1 Positive Definiteness\nPositive definiteness in the context of the covariance matrix \\(\\Sigma_n\\) is a fundamental requirement. It is determined by evaluating \\(\\Sigma(x_i, x_j)\\) at pairs of \\(n\\) \\(\\vec{x}\\)-values, denoted as \\(\\vec{x}_1, \\vec{x}_2, \\ldots, \\vec{x}_n\\). The condition for positive definiteness is that for all \\(\\vec{x}\\) vectors that are not equal to zero, the expression \\(\\vec{x}^\\top \\Sigma_n \\vec{x}\\) must be greater than zero. This property is essential when intending to use \\(\\Sigma_n\\) as a covariance matrix in multivariate normal (MVN) analysis. It is analogous to the requirement in univariate Gaussian distributions where the variance parameter, \\(\\sigma^2\\), must be positive.\nGaussian Processes (GPs) can be effectively utilized to generate random data that follows a smooth functional relationship. The process involves the following steps:\n\nSelect a set of \\(\\vec{x}\\)-values, denoted as \\(\\vec{x}_1, \\vec{x}_2, \\ldots, \\vec{x}_n\\).\nDefine the covariance matrix \\(\\Sigma_n\\) by evaluating \\(\\Sigma_n^{ij} = \\Sigma(\\vec{x}_i, \\vec{x}_j)\\) for \\(i, j = 1, 2, \\ldots, n\\).\nGenerate an \\(n\\)-variate realization \\(Y\\) that follows a multivariate normal distribution with a mean of zero and a covariance matrix \\(\\Sigma_n\\), expressed as \\(Y \\sim \\mathcal{N}_n(0, \\Sigma_n)\\).\nVisualize the result by plotting it in the \\(x\\)-\\(y\\) plane.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Gaussian Processes---Some Background Information</span>"
    ]
  },
  {
    "objectID": "a_04_gp_background.html#construction-of-the-covariance-matrix",
    "href": "a_04_gp_background.html#construction-of-the-covariance-matrix",
    "title": "Appendix D — Gaussian Processes—Some Background Information",
    "section": "D.3 Construction of the Covariance Matrix",
    "text": "D.3 Construction of the Covariance Matrix\nHere is an one-dimensional example. The process begins by creating an input grid using \\(\\vec{x}\\)-values. This grid consists of 100 elements, providing the basis for further analysis and visualization.\n\nimport numpy as np\nn = 100\nX = np.linspace(0, 10, n, endpoint=False).reshape(-1,1)\n\nIn the context of this discussion, the construction of the covariance matrix, denoted as \\(\\Sigma_n\\), relies on the concept of inverse exponentiated squared Euclidean distances. However, it’s important to note that a modification is introduced later in the process. Specifically, the diagonal of the covariance matrix is augmented with a small value, represented as “eps” or \\(\\epsilon\\).\nThe reason for this augmentation is that while inverse exponentiated distances theoretically ensure the covariance matrix’s positive definiteness, in practical applications, the matrix can sometimes become numerically ill-conditioned. By adding a small value to the diagonal, such as \\(\\epsilon\\), this ill-conditioning issue is mitigated. In this context, \\(\\epsilon\\) is often referred to as “jitter.”\n\nimport numpy as np\nfrom numpy import array, zeros, power, ones, exp, multiply, eye, linspace, spacing, sqrt, arange, append, ravel\nfrom numpy.linalg import cholesky, solve\nfrom numpy.random import multivariate_normal\ndef build_Sigma(X, sigma2):\n    n = X.shape[0]\n    k = X.shape[1]\n    D = zeros((k, n, n))\n    for l in range(k):\n        for i in range(n):\n            for j in range(i, n):\n                D[l, i, j] = 1/(2*sigma2[l])*(X[i,l] - X[j,l])**2\n    D = sum(D)\n    D = D + D.T\n    return exp(-D)  \n\n\nsigma2 = np.array([1.0])\nSigma = build_Sigma(X, sigma2)\nnp.round(Sigma[:3,:], 3)\n\narray([[1.   , 0.995, 0.98 , 0.956, 0.923, 0.882, 0.835, 0.783, 0.726,\n        0.667, 0.607, 0.546, 0.487, 0.43 , 0.375, 0.325, 0.278, 0.236,\n        0.198, 0.164, 0.135, 0.11 , 0.089, 0.071, 0.056, 0.044, 0.034,\n        0.026, 0.02 , 0.015, 0.011, 0.008, 0.006, 0.004, 0.003, 0.002,\n        0.002, 0.001, 0.001, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   ],\n       [0.995, 1.   , 0.995, 0.98 , 0.956, 0.923, 0.882, 0.835, 0.783,\n        0.726, 0.667, 0.607, 0.546, 0.487, 0.43 , 0.375, 0.325, 0.278,\n        0.236, 0.198, 0.164, 0.135, 0.11 , 0.089, 0.071, 0.056, 0.044,\n        0.034, 0.026, 0.02 , 0.015, 0.011, 0.008, 0.006, 0.004, 0.003,\n        0.002, 0.002, 0.001, 0.001, 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   ],\n       [0.98 , 0.995, 1.   , 0.995, 0.98 , 0.956, 0.923, 0.882, 0.835,\n        0.783, 0.726, 0.667, 0.607, 0.546, 0.487, 0.43 , 0.375, 0.325,\n        0.278, 0.236, 0.198, 0.164, 0.135, 0.11 , 0.089, 0.071, 0.056,\n        0.044, 0.034, 0.026, 0.02 , 0.015, 0.011, 0.008, 0.006, 0.004,\n        0.003, 0.002, 0.002, 0.001, 0.001, 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n        0.   ]])\n\n\n\nimport matplotlib.pyplot as plt\nplt.imshow(Sigma, cmap='hot', interpolation='nearest')\nplt.colorbar()\nplt.show()",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Gaussian Processes---Some Background Information</span>"
    ]
  },
  {
    "objectID": "a_04_gp_background.html#sec-random-samples-gp",
    "href": "a_04_gp_background.html#sec-random-samples-gp",
    "title": "Appendix D — Gaussian Processes—Some Background Information",
    "section": "D.4 Generation of Random Samples and Plotting the Realizations of the Random Function",
    "text": "D.4 Generation of Random Samples and Plotting the Realizations of the Random Function\nIn the context of the multivariate normal distribution, the next step is to utilize the previously constructed covariance matrix denoted as Sigma. It is used as an essential component in generating random samples from the multivariate normal distribution.\nThe function multivariate_normal is employed for this purpose. It serves as a random number generator specifically designed for the multivariate normal distribution. In this case, the mean of the distribution is set equal to mean, and the covariance matrix is provided as Psi. The argument size specifies the number of realizations, which, in this specific scenario, is set to one.\nBy default, the mean vector is initialized to zero. To match the number of samples, which is equivalent to the number of rows in the X and Sigma matrices, the argument zeros(n) is used, where n represents the number of samples (here taken from the size of the matrix, e.g.,: Sigma.shape[0]).\n\nrng = np.random.default_rng(seed=12345)\nY = rng.multivariate_normal(zeros(Sigma.shape[0]), Sigma, size = 1, check_valid=\"raise\").reshape(-1,1)\nY.shape\n\n(100, 1)\n\n\nNow we can plot the results, i.e., a finite realization of the random function \\(Y()\\) under a GP prior with a particular covariance structure. We will plot those X and Y pairs as connected points on an \\(x\\)-\\(y\\) plane.\n\nimport matplotlib.pyplot as plt\nplt.plot(X, Y)\nplt.title(\"Realization of Random Functions under a GP prior.\\n sigma2: {}\".format(sigma2[0]))\nplt.show()\n\n\n\n\n\n\n\nFigure D.2: Realization of one random function under a GP prior. sigma2: 1.0\n\n\n\n\n\n\nrng = np.random.default_rng(seed=12345)\nY = rng.multivariate_normal(zeros(Sigma.shape[0]), Sigma, size = 3, check_valid=\"raise\")\nplt.plot(X, Y.T)\nplt.title(\"Realization of Three Random Functions under a GP prior.\\n sigma2: {}\".format(sigma2[0]))\nplt.show()\n\n\n\n\n\n\n\nFigure D.3: Realization of three random functions under a GP prior. sigma2: 1.0",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Gaussian Processes---Some Background Information</span>"
    ]
  },
  {
    "objectID": "a_04_gp_background.html#properties-of-the-1d-example",
    "href": "a_04_gp_background.html#properties-of-the-1d-example",
    "title": "Appendix D — Gaussian Processes—Some Background Information",
    "section": "D.5 Properties of the 1d Example",
    "text": "D.5 Properties of the 1d Example\n\nD.5.1 Several Bumps:\nIn this analysis, we observe several bumps in the \\(x\\)-range of \\([0,10]\\). These bumps in the function occur because shorter distances exhibit high correlation, while longer distances tend to be essentially uncorrelated. This leads to variations in the function’s behavior:\n\nWhen \\(x\\) and \\(x'\\) are one \\(\\sigma\\) unit apart, the correlation is \\(\\exp\\left(-\\sigma^2 / (2\\sigma^2)\\right) = \\exp(-1/2) \\approx 0.61\\), i.e., a relative high correlation.\n\\(2\\sigma\\) apart means correlation \\(\\exp(− 2^2 /2) \\approx 0.14\\), i.e., only small correlation.\n\\(4\\sigma\\) apart means correlation \\(\\exp(− 4^2 /2) \\approx 0.0003\\), i.e., nearly no correlation—variables are considered independent for almost all practical application.\n\n\n\nD.5.2 Smoothness:\nThe function plotted in Figure D.2 represents only a finite realization, which means that we have data for a limited number of pairs, specifically 100 points. These points appear smooth in a tactile sense because they are closely spaced, and the plot function connects the dots with lines to create the appearance of smoothness. The complete surface, which can be conceptually extended to an infinite realization over a compact domain, is exceptionally smooth in a calculus sense due to the covariance function’s property of being infinitely differentiable.\n\n\nD.5.3 Scale of Two:\nRegarding the scale of the \\(Y\\) values, they have a range of approximately \\([-2,2]\\), with a 95% probability of falling within this range. In standard statistical terms, 95% of the data points typically fall within two standard deviations of the mean, which is a common measure of the spread or range of data.\n\nimport numpy as np\nfrom numpy import array, zeros, power, ones, exp, multiply, eye, linspace, spacing, sqrt, arange, append, ravel\nfrom numpy.random import multivariate_normal\n\ndef build_Sigma(X, sigma2):\n    n = X.shape[0]\n    k = X.shape[1]\n    D = zeros((k, n, n))\n    for l in range(k):\n        for i in range(n):\n            for j in range(i, n):\n                D[l, i, j] = 1/(2*sigma2[l])*(X[i,l] - X[j,l])**2\n    D = sum(D)\n    D = D + D.T\n    return exp(-D)\n\ndef plot_mvn( a=0, b=10, sigma2=1.0, size=1, n=100, show=True):    \n    X = np.linspace(a, b, n, endpoint=False).reshape(-1,1)\n    sigma2 = np.array([sigma2])\n    Sigma = build_Sigma(X, sigma2)\n    rng = np.random.default_rng(seed=12345)\n    Y = rng.multivariate_normal(zeros(Sigma.shape[0]), Sigma, size = size, check_valid=\"raise\")\n    plt.plot(X, Y.T)\n    plt.title(\"Realization of Random Functions under a GP prior.\\n sigma2: {}\".format(sigma2[0]))\n    if show:\n        plt.show()\n\n\nplot_mvn(a=0, b=10, sigma2=10.0, size=3, n=250)\n\n\n\n\n\n\n\nFigure D.4: Realization of Random Functions under a GP prior. sigma2: 10\n\n\n\n\n\n\nplot_mvn(a=0, b=10, sigma2=0.1, size=3, n=250)\n\n\n\n\n\n\n\nFigure D.5: Realization of Random Functions under a GP prior. sigma2: 0.1",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Gaussian Processes---Some Background Information</span>"
    ]
  },
  {
    "objectID": "a_04_gp_background.html#jupyter-notebook",
    "href": "a_04_gp_background.html#jupyter-notebook",
    "title": "Appendix D — Gaussian Processes—Some Background Information",
    "section": "D.6 Jupyter Notebook",
    "text": "D.6 Jupyter Notebook\n\n\n\n\n\n\nNote\n\n\n\n\nThe Jupyter-Notebook of this lecture is available on GitHub in the Hyperparameter-Tuning-Cookbook Repository",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Gaussian Processes---Some Background Information</span>"
    ]
  },
  {
    "objectID": "a_05_datasets.html",
    "href": "a_05_datasets.html",
    "title": "Appendix E — Datasets",
    "section": "",
    "text": "E.1 The Diabetes Data Set\nThis section describes the Diabetes data set. This is a PyTorch Dataset for regression, which is derived from the Diabetes data set from scikit-learn (sklearn). Ten baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements were obtained for each of n = 442 diabetes patients, as well as the response of interest, a quantitative measure of disease progression one year after baseline.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Datasets</span>"
    ]
  },
  {
    "objectID": "a_05_datasets.html#sec-a-05-diabetes-data-set",
    "href": "a_05_datasets.html#sec-a-05-diabetes-data-set",
    "title": "Appendix E — Datasets",
    "section": "",
    "text": "E.1.1 Data Exploration of the sklearn Diabetes Data Set\n\nfrom sklearn.datasets import load_diabetes\nfrom spotpython.plot.xy import plot_y_vs_X\ndata = load_diabetes()\nX, y = data.data, data.target\nplot_y_vs_X(X, y, nrows=5, ncols=2, figsize=(20, 15))\n\n\n\n\n\n\n\n\n\nEach of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of n_samples (i.e., the sum of squares of each column totals 1).\ns3_hdl shows a different behavior than the other features. It has a negative slope. HDL (high-density lipoprotein) cholesterol, sometimes called “good” cholesterol, absorbs cholesterol in the blood and carries it back to the liver. The liver then flushes it from the body. High levels of HDL cholesterol can lower your risk for heart disease and stroke.\n\n\n\nE.1.2 Generating the PyTorch Data Set\nspotpython provides a Diabetes class to load the diabetes data set. The Diabetes class is a subclass of torch.utils.data.Dataset. It loads the diabetes data set from sklearn and returns the data set as a torch.utils.data.Dataset object, so that features and targets can be accessed as torch.tensors. [CODE REFERENCE].\n\nfrom spotpython.data.diabetes import Diabetes\ndata_set = Diabetes()\nprint(len(data_set))\nprint(data_set.names)\n\n442\n['age', 'sex', 'bmi', 'bp', 's1_tc', 's2_ldl', 's3_hdl', 's4_tch', 's5_ltg', 's6_glu']",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Datasets</span>"
    ]
  },
  {
    "objectID": "a_05_datasets.html#sec-a-05-friedman",
    "href": "a_05_datasets.html#sec-a-05-friedman",
    "title": "Appendix E — Datasets",
    "section": "E.2 The Friedman Drift Dataset",
    "text": "E.2 The Friedman Drift Dataset\n\nE.2.1 The Friedman Drift Dataset as Implemented in river\nWe will describe the Friedman synthetic dataset with concept drifts [SOURCE], see also Friedman (1991) and Ikonomovska, Gama, and Džeroski (2011). Each observation is composed of ten features. Each feature value is sampled uniformly in [0, 1]. Only the first five features are relevant. The target is defined by different functions depending on the type of the drift. Global Recurring Abrupt drift will be used, i.e., the concept drift appears over the whole instance space.\nThe target is defined by the following function: \\[\ny = 10 \\sin(\\pi x_0 x_1) + 20 (x_2 - 0.5)^2 + 10 x_3 + 5 x_4 + \\epsilon,\n\\] where \\(\\epsilon \\sim \\mathcal{N}(0, 1)\\) is normally distributed noise.\nIf the Global Recurring Abrupt drift variant of the Friedman Drift dataset is used, the target function changes at two points in time, namely \\(p_1\\) and \\(p_2\\). At the first point, the concept changes to: \\[\ny = 10 \\sin(\\pi x_3 x_5) + 20 (x_1 - 0.5)^2 + 10 x_0 + 5 x_2 + \\epsilon,\n\\] At the second point of drift the old concept reoccurs. This can be implemented as follows, see https://riverml.xyz/latest/api/datasets/synth/FriedmanDrift/:\ndef __iter__(self):\n    rng = random.Random(self.seed)\n\n    i = 0\n    while True:\n        x = {i: rng.uniform(a=0, b=1) for i in range(10)}\n        y = self._global_recurring_abrupt_gen(x, i) + rng.gauss(mu=0, sigma=1)\n\n        yield x, y\n        i += 1\ndef _global_recurring_abrupt_gen(self, x, index: int):\n    if index &lt; self._change_point1 or index &gt;= self._change_point2:\n        # The initial concept is recurring\n        return (\n            10 * math.sin(math.pi * x[0] * x[1]) + 20 * (x[2] - 0.5) ** 2 + 10 * x[3] + 5 * x[4]\n        )\n    else:\n        # Drift: the positions of the features are swapped\n        return (\n            10 * math.sin(math.pi * x[3] * x[5]) + 20 * (x[1] - 0.5) ** 2 + 10 * x[0] + 5 * x[2]\n        )\nspotpython requires the specification of a train and test data set. These data sets can be generated as follows:\n\nfrom river.datasets import synth\nimport pandas as pd\nimport numpy as np\nfrom spotriver.utils.data_conversion import convert_to_df\n\nseed = 123\nshuffle = True\nn_train = 6_000\nn_test = 4_000\nn_samples = n_train + n_test\ntarget_column = \"y\"\n\ndataset = synth.FriedmanDrift(\n   drift_type='gra',\n   position=(n_train/4, n_train/2),\n   seed=123\n)\n\ntrain = convert_to_df(dataset, n_total=n_train)\ntrain.columns = [f\"x{i}\" for i in range(1, 11)] + [target_column]\n\n\ndataset = synth.FriedmanDrift(\n   drift_type='gra',\n   position=(n_test/4, n_test/2),\n   seed=123\n)\ntest = convert_to_df(dataset, n_total=n_test)\ntest.columns = [f\"x{i}\" for i in range(1, 11)] + [target_column]\n\n\ndef plot_data_with_drift_points(data, target_column, n_train, title=\"\"):\n    indices = range(len(data))\n    y_values = data[target_column]\n\n    plt.figure(figsize=(10, 6))\n    plt.plot(indices, y_values, label=\"y Value\", color='blue')\n\n    drift_points = [n_train / 4, n_train / 2]\n    for dp in drift_points:\n        plt.axvline(x=dp, color='red', linestyle='--', label=f'Drift Point at {int(dp)}')\n\n    handles, labels = plt.gca().get_legend_handles_labels()\n    by_label = dict(zip(labels, handles))\n    plt.legend(by_label.values(), by_label.keys())\n\n    plt.xlabel('Index')\n    plt.ylabel('Target Value (y)')\n    plt.title(title)\n    plt.grid(True)\n    plt.show()\n\n\nplot_data_with_drift_points(train, target_column, n_train, title=\"Training Data with Drift Points\")\n\n\n\n\n\n\n\n\n\nplot_data_with_drift_points(test, target_column, n_train, title=\"Testing Data with Drift Points\")\n\n\n\n\n\n\n\n\n\n\nE.2.2 The Friedman Drift Data Set from spotpython\nA data generator for the Friedman Drift dataset is implemented in the spotpython package, see friedman.py. The spotpython version is a simplified version of the river implementation. The spotPyton version allows the generation of constant input values for the features. This is useful for visualizing the concept drifts. For the productive use the river version should be used.\nPlotting the first 100 samples of the Friedman Drift dataset, we can not see the concept drifts at \\(p_1\\) and \\(p_2\\). Drift can be visualized by plotting the target values over time for constant features, e,g, if \\(x_0\\) is set to \\(1\\) and all other features are set to \\(0\\). This is illustrated in the following plot.\n\nfrom spotpython.data.friedman import FriedmanDriftDataset\n\ndef plot_friedman_drift_data(n_samples, seed, change_point1, change_point2, constant=True):\n    data_generator = FriedmanDriftDataset(n_samples=n_samples, seed=seed, change_point1=change_point1, change_point2=change_point2, constant=constant)\n    data = [data for data in data_generator]\n    indices = [i for _, _, i in data]\n    values = {f\"x{i}\": [] for i in range(5)}\n    values[\"y\"] = []\n    for x, y, _ in data:\n        for i in range(5):\n            values[f\"x{i}\"].append(x[i])\n        values[\"y\"].append(y)\n\n    plt.figure(figsize=(10, 6))\n    for label, series in values.items():\n        plt.plot(indices, series, label=label)\n    plt.xlabel('Index')\n    plt.ylabel('Value')\n    plt.axvline(x=change_point1, color='k', linestyle='--', label='Drift Point 1')\n    plt.axvline(x=change_point2, color='r', linestyle='--', label='Drift Point 2')\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\nplot_friedman_drift_data(n_samples=100, seed=42, change_point1=50, change_point2=75, constant=False)\nplot_friedman_drift_data(n_samples=100, seed=42, change_point1=50, change_point2=75, constant=True)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFriedman, Jerome H. 1991. “Multivariate Adaptive Regression Splines.” The Annals of Statistics 19 (1): 1–67.\n\n\nIkonomovska, Elena, João Gama, and Sašo Džeroski. 2011. “Learning Model Trees from Evolving Data Streams.” Data Mining and Knowledge Discovery 23 (1): 128–68.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Datasets</span>"
    ]
  },
  {
    "objectID": "a_06_slurm.html",
    "href": "a_06_slurm.html",
    "title": "Appendix F — Using Slurm",
    "section": "",
    "text": "F.1 Introduction\nThis chapter describes how to generate a spotpython configuration on a local machine and run the spotpython code on a remote machine using Slurm.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Using Slurm</span>"
    ]
  },
  {
    "objectID": "a_06_slurm.html#prepare-the-slurm-scripts-on-the-remote-machine",
    "href": "a_06_slurm.html#prepare-the-slurm-scripts-on-the-remote-machine",
    "title": "Appendix F — Using Slurm",
    "section": "F.2 Prepare the Slurm Scripts on the Remote Machine",
    "text": "F.2 Prepare the Slurm Scripts on the Remote Machine\nTwo scripts are required to run the spotpython code on the remote machine:\n\nstartSlurm.sh and\nstartPython.py.\n\nThey should be saved in the same directory as the configuration (pickle) file. These two scripts must be generated only once and can be reused for different configurations.\nThe startSlurm.sh script is a shell script that contains the following code:\n\n#!/bin/bash\n \n### Vergabe von Ressourcen\n#SBATCH --job-name=Test\n#SBATCH --account=Accountname/Projektname  # Hier den gewünschten Account angeben\n#SBATCH --cpus-per-task=20\n#SBATCH --gres=gpu:1\n#SBATCH --time=48:00:00\n#SBATCH --error=job.%J.err\n#SBATCH --output=job.%J.out\n#----\n#SBATCH --partition=gpu\n\nif [ -z \"$1\" ]; then\n    echo \"Usage: $0 &lt;path_to_spot.pkl&gt;\"\n    exit 1\nfi\n\nSPOT_PKL=$1\n\nmodule load conda\n\n### change to your conda environment with spotpython installed via\n### pip install spotpython\nconda activate spot312\n\npython startPython.py \"$SPOT_PKL\"\n\nexit\n\nSave the code in a file named startSlurm.sh and copy the file to the remote machine via scp, i.e.,\n\nscp startSlurm.sh user@144.33.22.1:\n\nThe startPython.py script is a Python script that contains the following code:\n\nimport argparse\nimport pickle\nfrom spotpython.utils.file import load_and_run_spot_python_experiment\nfrom spotpython.data.manydataset import ManyToManyDataset\n\n# Uncomment the following if you want to use a custom model (python source code)\n# import sys\n# sys.path.insert(0, './userModel')\n# import my_regressor\n# import my_hyper_dict\n\n\ndef main(pickle_file):\n    spot_tuner = load_and_run_spot_python_experiment(filename=pickle_file)\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description='Process a pickle file.')\n    parser.add_argument('pickle_file', type=str, help='The path to the pickle file to be processed.')\n\n    args = parser.parse_args()\n    main(args.pickle_file)\n\nSave the code in a file named startPython.py and copy the file to the remote machine via scp, i.e.,\n\nscp startPython.py user@144.33.22.1:",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Using Slurm</span>"
    ]
  },
  {
    "objectID": "a_06_slurm.html#generate-a-spotpython-configuration",
    "href": "a_06_slurm.html#generate-a-spotpython-configuration",
    "title": "Appendix F — Using Slurm",
    "section": "F.3 Generate a spotpython Configuration",
    "text": "F.3 Generate a spotpython Configuration\nThe configuration can be generated on a local machine using the following command:\n\nfrom spotpython.data.diabetes import Diabetes\nfrom spotpython.hyperdict.light_hyper_dict import LightHyperDict\nfrom spotpython.fun.hyperlight import HyperLight\nfrom spotpython.utils.init import (fun_control_init, surrogate_control_init, design_control_init)\nfrom spotpython.spot import Spot\nfrom spotpython.hyperparameters.values import set_hyperparameter, get_tuned_architecture\nfrom math import inf\nimport torch\nfrom torch.utils.data import TensorDataset\n# generate data\nnum_samples = 100_000\ninput_dim = 100\nX = torch.randn(num_samples, input_dim)  # random data for example\nY = torch.randn(num_samples, 1)  # random target for example\ndata_set = TensorDataset(X, Y)\n\nPREFIX=\"42\"\n\n\nfun_control = fun_control_init(\n    accelerator=\"gpu\",\n    devices=\"auto\",\n    num_nodes=1,\n    num_workers=19,\n    precision=\"32\",\n    strategy=\"auto\",\n    save_experiment=True,\n    PREFIX=PREFIX,\n    fun_evals=50,\n    max_time=inf,\n    data_set = data_set,\n    core_model_name=\"light.regression.NNLinearRegressor\",\n    hyperdict=LightHyperDict,\n    _L_in=input_dim,\n    _L_out=1)\n\nfun = HyperLight().fun\n\nset_hyperparameter(fun_control, \"optimizer\", [ \"Adadelta\", \"Adam\", \"Adamax\"])\nset_hyperparameter(fun_control, \"l1\", [5,10])\nset_hyperparameter(fun_control, \"epochs\", [10,12])\nset_hyperparameter(fun_control, \"batch_size\", [4,11])\nset_hyperparameter(fun_control, \"dropout_prob\", [0.0, 0.025])\nset_hyperparameter(fun_control, \"patience\", [2,9])\n\ndesign_control = design_control_init(init_size=10)\n\nS = Spot(fun=fun,fun_control=fun_control, design_control=design_control)\n\nThe configuration is saved as a pickle-file that contains the full information. In our example, the filename is 42_exp.pkl.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Using Slurm</span>"
    ]
  },
  {
    "objectID": "a_06_slurm.html#copy-the-configuration-to-the-remote-machine",
    "href": "a_06_slurm.html#copy-the-configuration-to-the-remote-machine",
    "title": "Appendix F — Using Slurm",
    "section": "F.4 Copy the Configuration to the Remote Machine",
    "text": "F.4 Copy the Configuration to the Remote Machine\nYou can copy the configuration to the remote machine using the scp command. The following command copies the configuration to the remote machine 144.33.22.1:\n\nscp 42_exp.pkl user@144.33.22.1:",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Using Slurm</span>"
    ]
  },
  {
    "objectID": "a_06_slurm.html#run-the-spotpython-code-on-the-remote-machine",
    "href": "a_06_slurm.html#run-the-spotpython-code-on-the-remote-machine",
    "title": "Appendix F — Using Slurm",
    "section": "F.5 Run the spotpython Code on the Remote Machine",
    "text": "F.5 Run the spotpython Code on the Remote Machine\nLogin on the remote machine and run the following command to start the spotpython code:\n\nssh user@144.33.22.1\n# change this to your conda environment!\nconda activate spot312 \nsbatch ./startSlurm.sh 42_exp.pkl",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Using Slurm</span>"
    ]
  },
  {
    "objectID": "a_06_slurm.html#copy-the-results-to-the-local-machine",
    "href": "a_06_slurm.html#copy-the-results-to-the-local-machine",
    "title": "Appendix F — Using Slurm",
    "section": "F.6 Copy the Results to the Local Machine",
    "text": "F.6 Copy the Results to the Local Machine\nAfter the spotpython code has finished, you can copy the results back to the local machine using the scp command. The following command copies the results to the local machine:\n\nscp user@144.33.22.1:42_res.pkl .\n\n\n\n\n\n\n\nExperiment and Result Files\n\n\n\n\nspotpython generates two files:\n\nPREFIX_exp.pkl (experiment file), which stores the information about running the experiment, and\nPREFIX_res.pkl (result file), which stores the results of the experiment.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Using Slurm</span>"
    ]
  },
  {
    "objectID": "a_06_slurm.html#analyze-the-results-on-the-local-machine",
    "href": "a_06_slurm.html#analyze-the-results-on-the-local-machine",
    "title": "Appendix F — Using Slurm",
    "section": "F.7 Analyze the Results on the Local Machine",
    "text": "F.7 Analyze the Results on the Local Machine\nThe file 42_res.pkl contains the results of the spotpython code. You can analyze the results on the local machine using the following code. Note: PREFIX is the same as in the previous steps, i.e., \"42\".\n\nfrom spotpython.utils.file import load_result\nspot_tuner = load_result(PREFIX)\n\n\nF.7.1 Visualizing the Tuning Progress\nNow the spot_tuner object is loaded and you can analyze the results interactively.\n\nspot_tuner.plot_progress(log_y=True, filename=None)\n\n\n\nF.7.2 Design Table with Default and Tuned Hyperparameters\n\nfrom spotpython.utils.eda import print_res_table\nprint_res_table(spot_tuner)\n\n\n\nF.7.3 Plotting Important Hyperparameters\n\nspot_tuner.plot_important_hyperparameter_contour(max_imp=3)\n\n\n\nF.7.4 The Tuned Hyperparameters\n\nget_tuned_architecture(spot_tuner)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Using Slurm</span>"
    ]
  },
  {
    "objectID": "a_07_package.html",
    "href": "a_07_package.html",
    "title": "Appendix G — Python Package Building",
    "section": "",
    "text": "Introduction\nThis notebook will guide you through the process of creating a Python package.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Python Package Building</span>"
    ]
  },
  {
    "objectID": "a_07_package.html#introduction",
    "href": "a_07_package.html#introduction",
    "title": "Appendix G — Python Package Building",
    "section": "",
    "text": "All examples can be found in the userPackage directory, see: userPackage",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Python Package Building</span>"
    ]
  },
  {
    "objectID": "a_07_package.html#create-a-conda-environment",
    "href": "a_07_package.html#create-a-conda-environment",
    "title": "Appendix G — Python Package Building",
    "section": "G.1 Create a Conda Environment",
    "text": "G.1 Create a Conda Environment\n\nconda create -n userpackage python=3.12\nconda activate userpackage\nInstall the following packages:\n\npython -m pip install build flake8 black mkdocs mkdocs-gen-files mkdocs-literate-nav mkdocs-section-index mkdocs-material mkdocs-exclude mkdocstrings mkdocstrings-python tensorflow twine jupyter matplotlib plotly pandas pytest spotpython",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Python Package Building</span>"
    ]
  },
  {
    "objectID": "a_07_package.html#download-the-user-package",
    "href": "a_07_package.html#download-the-user-package",
    "title": "Appendix G — Python Package Building",
    "section": "G.2 Download the User Package",
    "text": "G.2 Download the User Package\nThe user package can be found in the userPackage directory, see: userPackage",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Python Package Building</span>"
    ]
  },
  {
    "objectID": "a_07_package.html#build-the-user-package",
    "href": "a_07_package.html#build-the-user-package",
    "title": "Appendix G — Python Package Building",
    "section": "G.3 Build the User Package",
    "text": "G.3 Build the User Package\n\ncd into the userPackage directory and run the following command:\n\n./makefile.sh\nAlternatively, you can run the following commands:\n\nrm -f dist/userpackage*; python -m build; python -m pip install dist/userpackage*.tar.gz\n\npython -m mkdocs build",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Python Package Building</span>"
    ]
  },
  {
    "objectID": "a_07_package.html#open-the-documentation-of-the-user-package",
    "href": "a_07_package.html#open-the-documentation-of-the-user-package",
    "title": "Appendix G — Python Package Building",
    "section": "G.4 Open the Documentation of the User Package",
    "text": "G.4 Open the Documentation of the User Package\n\nmkdocs serve to view the documentation",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Python Package Building</span>"
    ]
  },
  {
    "objectID": "a_08_parallel.html",
    "href": "a_08_parallel.html",
    "title": "Appendix H — Parallelism in Initial Design",
    "section": "",
    "text": "H.1 Setup\nIn spotpython, we provide a wrapper function, that encapsulates the objective function to enable its parallel execution via multiprocessing or joblib, allowing multiple configurations to be evaluated at the same time.\nTo demonstrate the performance gain enabled by parallelization, we use a similar example to that in Section 47, where we perform hyperparameter tuning with spotpythonand PyTorch Lightning on the Diabetes dataset using a ResNet model. We compare the time required with and without parallelization. First, we import the necessary libraries, including the wrapper function make_parallel. We then define the fun_control and design_control settings. For design_control, we deliberately choose an initial design size of 10 for demonstration purposes.\nimport time\nfrom math import inf\nimport multiprocessing\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom spotpython.data.diabetes import Diabetes\nfrom spotpython.hyperdict.light_hyper_dict import LightHyperDict\nfrom spotpython.fun.hyperlight import HyperLight\nfrom spotpython.utils.init import (fun_control_init, design_control_init)\nfrom spotpython.hyperparameters.values import set_hyperparameter\nfrom spotpython.spot import Spot\nfrom spotpython.utils.parallel import make_parallel\ndataset = Diabetes()\nfun_control = fun_control_init(\n    fun_evals=10,\n    max_time=inf,\n    data_set=dataset,\n    core_model_name=\"light.regression.NNResNetRegressor\",\n    hyperdict=LightHyperDict,\n    _L_in=10,\n    _L_out=1,\n    seed=125,\n    tensorboard_log=False,\n    TENSORBOARD_CLEAN=False,\n)\nset_hyperparameter(fun_control, \"optimizer\", [\"Adadelta\", \"Adam\", \"Adamax\"])\nset_hyperparameter(fun_control, \"l1\", [2, 5])\nset_hyperparameter(fun_control, \"epochs\", [5, 8])\nset_hyperparameter(fun_control, \"batch_size\", [5, 8])\nset_hyperparameter(fun_control, \"dropout_prob\", [0.0, 0.5])\nset_hyperparameter(fun_control, \"patience\", [2, 3])\nset_hyperparameter(fun_control, \"lr_mult\", [0.1, 10.0])\n\ndesign_control = design_control_init(\n    init_size=10\n)\n\nfun = HyperLight().fun\n\nmodule_name: light\nsubmodule_name: regression\nmodel_name: NNResNetRegressor",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Parallelism in Initial Design</span>"
    ]
  },
  {
    "objectID": "a_08_parallel.html#experiments",
    "href": "a_08_parallel.html#experiments",
    "title": "Appendix H — Parallelism in Initial Design",
    "section": "H.2 Experiments",
    "text": "H.2 Experiments\nWe now measure the time required for sequential and parallel evaluation, beginning with the sequential approach.\n\nH.2.1 Sequential Execution\n\ntic = time.perf_counter()\nspot_tuner = Spot(fun=fun, fun_control=fun_control, design_control=design_control)\nres = spot_tuner.run()\ntoc = time.perf_counter()\ntime_seq = toc - tic\nprint(f\"Time taken for sequential execution: {time_seq:.2f} seconds\")\n\ntrain_model result: {'val_loss': 23811.58984375, 'hp_metric': 23811.58984375}\n\n\ntrain_model result: {'val_loss': 25125.443359375, 'hp_metric': 25125.443359375}\n\n\ntrain_model result: {'val_loss': 21832.447265625, 'hp_metric': 21832.447265625}\n\n\ntrain_model result: {'val_loss': 22035.162109375, 'hp_metric': 22035.162109375}\n\n\ntrain_model result: {'val_loss': 23203.830078125, 'hp_metric': 23203.830078125}\n\n\ntrain_model result: {'val_loss': 14768.158203125, 'hp_metric': 14768.158203125}\n\n\ntrain_model result: {'val_loss': 22453.712890625, 'hp_metric': 22453.712890625}\n\n\ntrain_model result: {'val_loss': 24413.876953125, 'hp_metric': 24413.876953125}\n\n\ntrain_model result: {'val_loss': 23999.810546875, 'hp_metric': 23999.810546875}\ntrain_model result: {'val_loss': 24063.423828125, 'hp_metric': 24063.423828125}\nExperiment saved to 000_res.pkl\nTime taken for sequential execution: 128.56 seconds\n\n\n\n\nH.2.2 Parallel Execution\nTo use make_parallel, the number of cores must be specified via the num_cores parameter. By default, the function utilizes multiprocessing, but other parallelization methods can be selected using the method argument. The following two lines of code demonstrate how to set up the parallel function and run the Spot tuner with it.\n\nparallel_fun = make_parallel(fun, num_cores=num_cores)\nspot_parallel_tuner = Spot(fun=parallel_fun, fun_control=fun_control, design_control=design_control)\n\nWe consider parallel efficiency, a metric that measures how effectively additional computational resources (cores/processors) are being utilized in a parallel computation. It’s calculated as: \\[\n\\text{Efficiency} = \\frac{\\text{Speedup}}{\\text{Number of Processors}},\n\\] where:\n\nSpeedup = Time(Sequential) / Time(Parallel)\nNumber of Processors = Number of cores used\n\nIt can be interpreted as follows:\n\n1.0 (100%): Perfect linear scaling - doubling cores halves execution time\n0.8-0.9 (80-90%): Excellent scaling - minimal parallelization overhead\n0.5-0.7 (50-70%): Good scaling - reasonable utilization of additional cores\n&lt;0.5 (&lt;50%): Poor scaling - diminishing returns from adding more cores\n\nWhen efficiency drops significantly as you add cores, it indicates:\n\nCommunication overhead increasing\nSynchronization bottlenecks\nLoad imbalance between cores\nPortions of code that remain sequential (Amdahl’s Law limitation)\n\n\n# Get available cores\navailable_cores = multiprocessing.cpu_count()\nprint(f\"Available cores: {available_cores}\")\n\n# Generate list of cores to test (powers of 2 up to available cores)\ncores_to_test = []\npower = 0\nwhile 2**(power+1) &lt; available_cores:\n    cores_to_test.append(2**power)\n    power += 1\n\n# If the number of available cores is not a power of 2, add it to the list\nif available_cores not in cores_to_test:\n    cores_to_test.append(available_cores)\n\n# Prepare DataFrame to store results\nresults_df = pd.DataFrame(columns=[\"number_of_cores\", \"time\"])\n\n# Run the experiment for each core count\nfor num_cores in cores_to_test:\n    print(f\"\\nTesting with {num_cores} cores...\")\n    tic = time.perf_counter()\n    parallel_fun = make_parallel(fun, num_cores=num_cores)\n    spot_parallel_tuner = Spot(fun=parallel_fun, fun_control=fun_control, design_control=design_control)\n    res = spot_parallel_tuner.run()\n    toc = time.perf_counter()\n    time_taken = toc - tic\n\n    # Add result to DataFrame\n    results_df = pd.concat([results_df, pd.DataFrame({\n        \"number_of_cores\": [num_cores],\n        \"time\": [time_taken]\n    })], ignore_index=True)\n\n    print(f\"Time taken with {num_cores} cores: {time_taken:.2f} seconds\")\n\nAvailable cores: 24\n\nTesting with 1 cores...\n\n\ntrain_model result: {'val_loss': 23811.58984375, 'hp_metric': 23811.58984375}\ntrain_model result: {'val_loss': 22507.580078125, 'hp_metric': 22507.580078125}\ntrain_model result: {'val_loss': 22085.53515625, 'hp_metric': 22085.53515625}\ntrain_model result: {'val_loss': 21815.44140625, 'hp_metric': 21815.44140625}\ntrain_model result: {'val_loss': 23528.212890625, 'hp_metric': 23528.212890625}\ntrain_model result: {'val_loss': 23563.298828125, 'hp_metric': 23563.298828125}\ntrain_model result: {'val_loss': 22435.96875, 'hp_metric': 22435.96875}\ntrain_model result: {'val_loss': 23983.15625, 'hp_metric': 23983.15625}\ntrain_model result: {'val_loss': 23000.837890625, 'hp_metric': 23000.837890625}\ntrain_model result: {'val_loss': 23442.49609375, 'hp_metric': 23442.49609375}\nExperiment saved to 000_res.pkl\nTime taken with 1 cores: 140.96 seconds\n\nTesting with 2 cores...\n\n\ntrain_model result: {'val_loss': 22085.53515625, 'hp_metric': 22085.53515625}\ntrain_model result: {'val_loss': 21815.44140625, 'hp_metric': 21815.44140625}\ntrain_model result: {'val_loss': 23811.58984375, 'hp_metric': 23811.58984375}\ntrain_model result: {'val_loss': 22507.580078125, 'hp_metric': 22507.580078125}\ntrain_model result: {'val_loss': 23528.212890625, 'hp_metric': 23528.212890625}\ntrain_model result: {'val_loss': 23563.298828125, 'hp_metric': 23563.298828125}\ntrain_model result: {'val_loss': 22435.96875, 'hp_metric': 22435.96875}\ntrain_model result: {'val_loss': 23983.15625, 'hp_metric': 23983.15625}\ntrain_model result: {'val_loss': 23000.837890625, 'hp_metric': 23000.837890625}\ntrain_model result: {'val_loss': 23442.49609375, 'hp_metric': 23442.49609375}\nExperiment saved to 000_res.pkl\nTime taken with 2 cores: 96.99 seconds\n\nTesting with 4 cores...\n\n\ntrain_model result: {'val_loss': 22085.53515625, 'hp_metric': 22085.53515625}\ntrain_model result: {'val_loss': 23528.212890625, 'hp_metric': 23528.212890625}\ntrain_model result: {'val_loss': 23442.49609375, 'hp_metric': 23442.49609375}\ntrain_model result: {'val_loss': 23811.58984375, 'hp_metric': 23811.58984375}\ntrain_model result: {'val_loss': 23563.298828125, 'hp_metric': 23563.298828125}\ntrain_model result: {'val_loss': 22435.96875, 'hp_metric': 22435.96875}\ntrain_model result: {'val_loss': 23000.837890625, 'hp_metric': 23000.837890625}\ntrain_model result: {'val_loss': 22507.580078125, 'hp_metric': 22507.580078125}\ntrain_model result: {'val_loss': 23983.15625, 'hp_metric': 23983.15625}\ntrain_model result: {'val_loss': 21815.44140625, 'hp_metric': 21815.44140625}\nExperiment saved to 000_res.pkl\nTime taken with 4 cores: 92.51 seconds\n\nTesting with 8 cores...\n\n\ntrain_model result: {'val_loss': 22085.53515625, 'hp_metric': 22085.53515625}\ntrain_model result: {'val_loss': 23811.58984375, 'hp_metric': 23811.58984375}\ntrain_model result: {'val_loss': 23528.212890625, 'hp_metric': 23528.212890625}\ntrain_model result: {'val_loss': 22435.96875, 'hp_metric': 22435.96875}\ntrain_model result: {'val_loss': 23442.49609375, 'hp_metric': 23442.49609375}\ntrain_model result: {'val_loss': 22507.580078125, 'hp_metric': 22507.580078125}\ntrain_model result: {'val_loss': 23563.298828125, 'hp_metric': 23563.298828125}\ntrain_model result: {'val_loss': 23000.837890625, 'hp_metric': 23000.837890625}\ntrain_model result: {'val_loss': 23983.15625, 'hp_metric': 23983.15625}\ntrain_model result: {'val_loss': 21815.44140625, 'hp_metric': 21815.44140625}\nExperiment saved to 000_res.pkl\nTime taken with 8 cores: 92.76 seconds\n\nTesting with 24 cores...\n\n\ntrain_model result: {'val_loss': 23563.298828125, 'hp_metric': 23563.298828125}\ntrain_model result: {'val_loss': 22435.96875, 'hp_metric': 22435.96875}\ntrain_model result: {'val_loss': 22085.53515625, 'hp_metric': 22085.53515625}\ntrain_model result: {'val_loss': 23442.49609375, 'hp_metric': 23442.49609375}\ntrain_model result: {'val_loss': 23811.58984375, 'hp_metric': 23811.58984375}\ntrain_model result: {'val_loss': 23528.212890625, 'hp_metric': 23528.212890625}\ntrain_model result: {'val_loss': 22507.580078125, 'hp_metric': 22507.580078125}\ntrain_model result: {'val_loss': 23000.837890625, 'hp_metric': 23000.837890625}\ntrain_model result: {'val_loss': 23983.15625, 'hp_metric': 23983.15625}\ntrain_model result: {'val_loss': 21815.44140625, 'hp_metric': 21815.44140625}\nExperiment saved to 000_res.pkl\nTime taken with 24 cores: 90.31 seconds\n\n\n\n\nH.2.3 Results\n\nprint(\"\\nPerformance comparison across different numbers of cores:\")\nresults_df[\"speedup_vs_sequential\"] = time_seq / results_df[\"time\"]\nresults_df[\"efficiency\"] = results_df[\"speedup_vs_sequential\"] / results_df[\"number_of_cores\"]\nprint(results_df)\n\n\nPerformance comparison across different numbers of cores:\n  number_of_cores        time  speedup_vs_sequential efficiency\n0               1  140.963098               0.911980    0.91198\n1               2   96.991986               1.325424   0.662712\n2               4   92.507109               1.389683   0.347421\n3               8   92.757718               1.385928   0.173241\n4              24   90.305889               1.423556   0.059315\n\n\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n\n# Execution time vs number of cores\nax1.plot(results_df[\"number_of_cores\"], results_df[\"time\"], marker='o', linestyle='-')\nax1.set_xlabel(\"Number of cores\")\nax1.set_ylabel(\"Execution time (seconds)\")\nax1.set_title(\"Execution Time vs Number of Cores\")\nax1.grid(True)\n\n# Speedup vs number of cores\nax1.axhline(y=time_seq, color='r', linestyle='--', label=f'Sequential ({time_seq:.2f}s)')\nax1.legend()\n\n# Parallel efficiency\nax2.plot(results_df[\"number_of_cores\"], results_df[\"efficiency\"], marker='o', linestyle='-')\nax2.set_xlabel(\"Number of cores\")\nax2.set_ylabel(\"Parallel efficiency\")\nax2.set_title(\"Parallel Efficiency vs Number of Cores\")\nax2.set_ylim(0, 1.1)\nax2.grid(True)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOperating-system Differences in Parallelization Methods\n\n\n\nLinux uses the fork method by default to start new processes, whereas macOS and Windows use the spawn method. This leads to differences in how processes are handled across operating systems. We use the functionality of set_all_seeds to ensure that the evaluation remains reproducible across all operating systems.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Parallelism in Initial Design</span>"
    ]
  },
  {
    "objectID": "a_99_solutions.html",
    "href": "a_99_solutions.html",
    "title": "Appendix I — Solutions to Selected Exercises",
    "section": "",
    "text": "I.1 Data-Driven Modeling and Optimization",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Solutions to Selected Exercises</span>"
    ]
  },
  {
    "objectID": "a_99_solutions.html#data-driven-modeling-and-optimization",
    "href": "a_99_solutions.html#data-driven-modeling-and-optimization",
    "title": "Appendix I — Solutions to Selected Exercises",
    "section": "",
    "text": "I.1.1 Histograms\n\nSolution I.1 (Density Curve). \n\nWe can calculate propabilities.\nWe only need two parameters (the mean and the sd) to form the curve -&gt; Store data more efficently\nBlanks can be filled\n\n\n\n\nI.1.2 The Normal Distribution\n\nSolution I.2 (TwoSDAnswer). 95%\n\n\nSolution I.3 (OneSDAnswer). 68%\n\n\nSolution I.4 (ThreeSDAnswer). 99,7%\n\n\nSolution I.5 (DataRangeAnswer). 80 - 120\n\n\nSolution I.6 (PeakHeightAnswer). low\n\n\n\nI.1.3 The mean, the media, and the mode\n\n\nI.1.4 The exponential distribution\n\n\nI.1.5 Population and Estimated Parameters\n\nSolution I.7 (ProbabilityAnswer). 50%\n\n\n\nI.1.6 Calculating the Mean, Variance and Standard Deviation\n\nSolution I.8 (MeanDifferenceAnswer). If we have all the data, \\(\\mu\\) is the population mean and x-bar is the sample mean. We don’t have the full information.\n\n\nSolution I.9 (EstimateMeanAnswer). Sum of the values divided by n.\n\n\nSolution I.10 (SigmaSquaredAnswer). Variance\n\n\nSolution I.11 (EstimatedSDAnswer). The same as the normal standard deviation, but using n-1.\n\n\nSolution I.12 (VarianceDifferenceAnswer). \\(n\\) and \\(n-1\\)\n\n\nSolution I.13 (ModelBenefitsAnswer). \n\nApproximation\nPrediction\nUnderstanding\n\n\n\nSolution I.14 (SampleDefinitionAnswer). It’s a subset of the data.\n\n\n\nI.1.7 Hypothesis Testing and the Null-Hypothesis\n\nSolution I.15 (RejectHypothesisAnswer). It means the evidence supports the alternative hypothesis, indicating that the null hypothesis is unlikely to be true.\n\n\nSolution I.16 (NullHypothesisAnswer). It’s a statement that there is no effect or no difference, and it serves as the default or starting assumption in hypothesis testing.\n\n\nSolution I.17 (BetterDrugAnswer). By conducting experiments and statistical tests to compare the new drug’s effectiveness against the current standard and demonstrating a significant improvement.\n\n\n\nI.1.8 Alternative Hypotheses, Main Ideas\n\n\nI.1.9 p-values: What they are and how to interpret them\n\nSolution I.18 (PValueIntroductionAnswer). We can reject the null hypothesis. We can make a decision.\n\n\nSolution I.19 (PValueRangeAnswer). It can only be between 0 and 1.\n\n\nSolution I.20 (PValueRangeAnswer). It can only be between 0 and 1.\n\n\nSolution I.21 (TypicalPValueAnswer). The chance that we wrongly reject the null hypothesis.\n\n\nSolution I.22 (FalsePositiveAnswer). If we have a false-positive, we succeed in rejecting the null hypothesis. But in fact/reality, this is false -&gt; False positive.\n\n\n\nI.1.10 How to calculate p-values\n\nSolution I.23 (CalculatePValueAnswer). Probability of specific result, probability of outcome with the same probability, and probability of events with smaller probability.\n\n\nSolution I.24 (SDCalculationAnswer). 7 is the SD.\n\n\nSolution I.25 (SidedPValueAnswer). If we are not interested in the direction of the change, we use the two-sided. If we want to know about the direction, the one-sided.\n\n\nSolution I.26 (CoinTestAnswer). TBD\n\n\nSolution I.27 (BorderPValueAnswer). TBD\n\n\nSolution I.28 (OneSidedPValueCautionAnswer). If you look in the wrong direction, there is no change.\n\n\nSolution I.29 (BinomialDistributionAnswer). TBD\n\n\n\nI.1.11 p-hacking: What it is and how to avoid it\n\nSolution I.30 (PHackingWaysAnswer). \n\nPerforming repeats until you find one result with a small p-value -&gt; false positive result.\nIncreasing the sample size within one experiment when it is close to the threshold.\n\n\n\nSolution I.31 (AvoidPHackingAnswer). Specify the number of repeats and the sample sizes at the beginning.\n\n\nSolution I.32 (MultipleTestingProblemAnswer). TBD\n\n\n\nI.1.12 Covariance\n\nSolution I.33 (CovarianceDefinitionAnswer). Formula\n\n\nSolution I.34 (CovarianceMeaningAnswer). Large values in the first variable result in large values in the second variable.\n\n\nSolution I.35 (CovarianceVarianceRelationshipAnswer). Formula\n\n\nSolution I.36 (HighCovarianceAnswer). No, size doesn’t matter.\n\n\nSolution I.37 (ZeroCovarianceAnswer). No relationship\n\n\nSolution I.38 (NegativeCovarianceAnswer). Yes\n\n\nSolution I.39 (NegativeVarianceAnswer). No\n\n\n\nI.1.13 Pearson’s Correlation\n\nSolution I.40 (CorrelationValueAnswer). Recalculate\n\n\nSolution I.41 (CorrelationRangeAnswer). From -1 to 1\n\n\nSolution I.42 (CorrelationFormulaAnswer). Formula\n\n\n\nI.1.14 Boxplots\n\nSolution I.43 (UnderstandingStatisticalPower). It is the probability of correctly rejecting the null hypothesis.\n\n\nSolution I.44 (DistributionEffectOnPower). Power analysis is not applicable.\n\n\nSolution I.45 (IncreasingPower). By taking more samples.\n\n\nSolution I.46 (PreventingPHacking). TBD\n\n\nSolution I.47 (SampleSizeAndPower). The power will be low.\n\n\n\nI.1.15 Power Analysis\n\nSolution I.48 (MainFactorsAffectingPower). The overlap (distance of the two means) and sample sizes.\n\n\nSolution I.49 (PowerAnalysisOutcome). The sample size needed.\n\n\nSolution I.50 (RisksInExperiments). Few experiments lead to very low power, and many experiments might result in p-hacking.\n\n\nSolution I.51 (StepsToPerformPowerAnalysis). \n\nSelect power\nSelect threshold for significance (alpha)\nEstimate the overlap (done by the effect size)\n\n\n\n\nI.1.16 The Central Limit Theorem\n\nSolution I.52 (CentralLimitTheoremAnswer). TBD\n\n\n\nI.1.17 Boxplots\n\nSolution I.53 (MedianAnswer). The median.\n\n\nSolution I.54 (BoxContentAnswer). 50% of the data.\n\n\n\nI.1.18 R-squared\n\nSolution I.55 (RSquaredFormulaAnswer). TBD\n\n\nSolution I.56 (NegativeRSquaredAnswer). If you fit a line, no, but there are cases where it could be negative. However, these are usually considered useless.\n\n\nSolution I.57 (RSquaredCalculationAnswer). TBD\n\n\nI.1.18.1 The main ideas of fitting a line to data (The main ideas of least squares and linear regression.)\n\nSolution I.58 (LeastSquaresAnswer). It is the calculation of the smallest sum of residuals when you fit a model to data.\n\n\n\n\nI.1.19 Linear Regression\n\n\nI.1.20 Multiple Regression\n\n\nI.1.21 A Gentle Introduction to Machine Learning\n\nSolution I.59 (RegressionVsClassificationAnswer). Regression involves predicting continuous values (e.g., temperature, size), while classification involves predicting discrete values (e.g., categories like cat, dog).\n\n\n\nI.1.22 Maximum Likelihood\n\nSolution I.60 (LikelihoodConceptAnswer). The distribution that fits the data best.\n\n\n\nI.1.23 Probability is not Likelihood\n\nSolution I.61 (ProbabilityVsLikelihoodAnswer). Likelihood: Finding the curve that best fits the data. Probability: Calculating the probability of an event given a specific curve.\n\n\n\nI.1.24 Cross Validation\n\nSolution I.62 (TrainVsTestDataAnswer). Training data is used to fit the model, while testing data is used to evaluate how well the model fits.\n\n\nSolution I.63 (SingleValidationIssueAnswer). The performance might not be representative because the data may not be equally distributed between training and testing sets.\n\n\nSolution I.64 (FoldDefinitionAnswer). TBD\n\n\nSolution I.65 (LeaveOneOutValidationAnswer). Only one data point is used as the test set, and the rest are used as the training set.\n\n\n\nI.1.25 The Confusion Matrix\n\nSolution I.66 (ConfusionMatrixAnswer). TBD\n\n\n\nI.1.26 Sensitivity and Specificity\n\nSolution I.67 (SensitivitySpecificityAnswer1). TBD\n\n\nSolution I.68 (SensitivitySpecificityAnswer2). TBD\n\n\n\nI.1.27 Bias and Variance\n\nSolution I.69 (BiasAndVarianceAnswer). TBD\n\n\n\nI.1.28 Mutual Information\n\nSolution I.70 (MutualInformationExampleAnswer). TBD\n\n\n\nI.1.29 Principal Component Analysis (PCA)\n\nSolution I.71 (WhatIsPCAAnswer). A dimension reduction technique that helps discover important variables.\n\n\nSolution I.72 (screePlotAnswer). It shows how much variation is defined by the data.\n\n\nSolution I.73 (LeastSquaresInPCAAnswer). No, in the first step it tries to maximize distances.\n\n\nSolution I.74 (PCAStepsAnswer). \n\nCalculate mean\nShift the data to the center of the coordinate system\nFit a line by maximizing the distances\nCalculate the sum of squared distances\nCalculate the slope\nRotate\n\n\n\nSolution I.75 (EigenvaluePC1Answer). Formula (to be specified).\n\n\nSolution I.76 (DifferencesBetweenPointsAnswer). No, because the first difference is measured on the PC1 scale and it is more important.\n\n\nSolution I.77 (ScalingInPCAAnswer). Scaling by dividing by the standard deviation (SD).\n\n\nSolution I.78 (DetermineNumberOfComponentsAnswer). TBD\n\n\nSolution I.79 (LimitingNumberOfComponentsAnswer). \n\nThe dimension of the problem\nNumber of samples\n\n\n\n\nI.1.30 t-SNE\n\nSolution I.80 (WhyUseTSNEAnswer). For dimension reduction and picking out the relevant clusters.\n\n\nSolution I.81 (MainIdeaOfTSNEAnswer). To reduce the dimensions of the data by reconstructing the relationships in a lower-dimensional space.\n\n\nSolution I.82 (BasicConceptOfTSNEAnswer). \n\nFirst, randomly arrange the points in a lower dimension\nDecide whether to move points left or right, depending on distances in the original dimension\nFinally, arrange points in the lower dimension similarly to the original dimension\n\n\n\nSolution I.83 (TSNEStepsAnswer). \n\nProject data to get random points\nSet up a matrix of distances\nCalculate the inner variances of the clusters and the Gaussian distribution\nDo the same with the projected points\nMove projected points so the second matrix gets more similar to the first matrix\n\n\n\n\nI.1.31 K-means clustering\n\nSolution I.84 (HowKMeansWorksAnswer). \n\nSelect the number of clusters\nRandomly select distinct data points as initial cluster centers\nMeasure the distance between each point and the cluster centers\nAssign each point to the nearest cluster\nRepeat the process\n\n\n\nSolution I.85 (QualityOfClustersAnswer). Calculate the within-cluster variation.\n\n\nSolution I.86 (IncreasingKAnswer). If k is too high, each point would be its own cluster. If k is too low, you cannot see the structures.\n\n\n\nI.1.32 DBSCAN\n\nSolution I.87 (CorePointInDBSCANAnswer). A point that is close to at least k other points.\n\n\nSolution I.88 (AddingVsExtendingAnswer). Adding means we add a point and then stop. Extending means we add a point and then look for other neighbors from that point.\n\n\nSolution I.89 (OutliersInDBSCANAnswer). Points that are not core points and do not belong to existing clusters.\n\n\n\nI.1.33 K-nearest neighbors\n\nSolution I.90 (AdvantagesAndDisadvantagesOfKAnswer). \n\nk = 1: Noise can disturb the process because of possibly incorrect measurements of points.\nk = 100: The majority can be wrong for some groups. It is smoother, but there is less chance to discover the structure of the data.\n\n\n\n\nI.1.34 Naive Bayes\n\nSolution I.91 (NaiveBayesFormulaAnswer). TBD\n\n\nSolution I.92 (CalculateProbabilitiesAnswer). TBD\n\n\n\nI.1.35 Gaussian Naive Bayes\n\nSolution I.93 (UnderflowProblemAnswer). Small values multiplied together can become smaller than the limits of computer memory, resulting in zero. Using logarithms (e.g., log(1/2) -&gt; -1, log(1/4) -&gt; -2) helps prevent underflow.\n\n\n\nI.1.36 Trees\n\nSolution I.94 (Tree Usage). Classication, Regression, Clustering\n\n\nSolution I.95 (Tree Usage). TBD\n\n\nSolution I.96 (Tree Feature Importance). The most important feature.\n\n\nSolution I.97 (Regression Tree Limitations). High dimensions\n\n\nSolution I.98 (Regression Tree Score). SSR + alpha * T\n\n\nSolution I.99 (Regression Tree Alpha Value Small). The tree is more complex.\n\n\nSolution I.100 (Regression Tree Increase Alpha Value). We get smaller trees\n\n\nSolution I.101 (Regression Tree Pruning). Decreases the complexity of the tree to enhance performance and reduce overfitting",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Solutions to Selected Exercises</span>"
    ]
  },
  {
    "objectID": "a_99_solutions.html#machine-learning-and-artificial-intelligence",
    "href": "a_99_solutions.html#machine-learning-and-artificial-intelligence",
    "title": "Appendix I — Solutions to Selected Exercises",
    "section": "I.2 Machine Learning and Artificial Intelligence",
    "text": "I.2 Machine Learning and Artificial Intelligence\n\nI.2.1 Backpropagation\n\nSolution I.102 (ChainRuleAndGradientDescentAnswer). Combination of the chain rule and gradient descent.\n\n\nSolution I.103 (BackpropagationNamingAnswer). Because you start at the end and go backwards.\n\n\n\nI.2.2 Gradient Descent\n\nSolution I.104 (GradDescStepSize). learning rate x slope\n\n\nSolution I.105 (GradDescIntercept). Old intercept - step size\n\n\nSolution I.106 (GradDescIntercept). When the step size is small or after a certain number of steps\n\n\n\nI.2.3 ReLU\n\nSolution I.107 (Graph ReLU). Graph of ReLU function: f(x) = max(0, x)\n\n\n\nI.2.4 CNNs\n\nSolution I.108 (CNNImageRecognitionAnswer). \n\ntoo many features for input layer -&gt; high memory consumption\nalways shift in data\nit learns local informations and local correlations\n\n\n\nSolution I.109 (CNNFiltersInitializationAnswer). The filter values in CNNs are randomly initialized and then trained and optimized through the process of backpropagation.\n\n\nSolution I.110 (CNNFilterInitializationAnswer). The filter values in CNNs are initially set by random initialization. These filters undergo training via backpropagation, where gradients are computed and used to adjust the filter values to optimize performance.\n\n\nSolution I.111 (GenNNStockPredictionAnswer). A limitation of using classical neural networks for stock market prediction is their reliance on fixed inputs. Stock market data is dynamic and requires models that can adapt to changing conditions over time.\n\n\n\nI.2.5 RNN\n\nSolution I.112 (RNNUnrollingAnswer). In the unrolling process of RNNs, the network is copied and the output from the inner loop is fed into the second layer of the copied network.\n\n\nSolution I.113 (RNNReliabilityAnswer). RNNs sometimes fail to work reliably due to the vanishing gradient problem (where gradients are less than 1) and the exploding gradient problem (where gradients are greater than 1). Additionally, reliability issues arise because the network and the weights are copied during the unrolling process.\n\n\n\nI.2.6 LSTM\n\nSolution I.114 (LSTMSigmoidTanhAnswer). The sigmoid activation function outputs values between 0 and 1, making it suitable for probability determination, whereas the tanh activation function outputs values between -1 and 1.\n\n\nSolution I.115 (LSTMSigmoidTanhAnswer). State how much of the long term memory should be used.\n\n\nSolution I.116 (LSTMGatesAnswer). An LSTM network has three types of gates: the forget gate, the input gate, and the output gate. The forget gate decides what information to discard from the cell state, the input gate updates the cell state with new information, and the output gate determines what part of the cell state should be output.\n\n\nSolution I.117 (LSTMLongTermInfoAnswer). Long-term information is used in the output gate of an LSTM network.\n\n\nSolution I.118 (LSTMUpdateGatesAnswer). In the input and forget gates.\n\n\n\nI.2.7 Pytorch/Lightning\n\nSolution I.119 (PyTorchRequiresGradAnswer). In PyTorch, requires_grad indicates whether a tensor should be trained. If set to False, the tensor will not be trained.\n\n\n\nI.2.8 Embeddings\n\nSolution I.120 (NN STrings). No, they process numerical values.\n\n\nSolution I.121 (Embedding Definition). Representation of a word as a vector.\n\n\nSolution I.122 (Embedding Dimensions). We can model similarities.\n\n\n\nI.2.9 Sequence to Sequence Models\n\nSolution I.123 (LSTM). Because they are able to consider “far away” information.\n\n\nSolution I.124 (Teacher Forcing). We need to force the correct words for the training.\n\n\nSolution I.125 (Attention). Attention scores compute similarities for one input to the others.\n\n\n\nI.2.10 Transformers\n\nSolution I.126 (ChatGPT). Decoder only.\n\n\nSolution I.127 (Translation). Encoder-Decoder structure.\n\n\nSolution I.128 (Difference Encoder-Decoder and Decoder Only.). \n\nEncoder-Decoder: self-attention.\nDecoder only: masked self-attention.\n\n\n\nSolution I.129 (Weights). \n\na: Randomly\nb: Backpropagation\n\n\n\nSolution I.130 (Order of Words). Positional Encoding\n\n\nSolution I.131 (Relationship Between Words). Masked self-attention which looks at the previous tokens.\n\n\nSolution I.132 (Masked Self Attention). It works by investigating how similar each word is to itself and all of the proceeding words in the sentence.\n\n\nSolution I.133 (Softmax). Transformation to values between 0 and 1.\n\n\nSolution I.134 (Softmax Output). We create two new numbers: Values – like K and Q with different weights. We scale these values by the percentage. -&gt; we get the scaled V´s\n\n\nSolution I.135 (V´s). Lastly, we sum these values together, which combine separate encodings for both words relative to their similarities to “is”, are the masked-self-attention values for “is”.\n\n\nSolution I.136 (Residual Connections). They are bypasses, which combine the position encoded values with masked-self-attention values.\n\n\nSolution I.137 (Generate Known Word in Sequence). \n\nTraining\nBecause it is a Decoder-Only transformer used for prediction and the calculations that you need.\n\n\n\n\nSolution I.138 (Masked-Self-Attention Values and Bypass). We use a simple neural network with two inputs and five outputs for the vocabulary.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Solutions to Selected Exercises</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Abadi, Martin, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen,\nCraig Citro, Greg S. Corrado, et al. 2016. “TensorFlow: Large-Scale Machine Learning on Heterogeneous\nDistributed Systems.” arXiv e-Prints, March,\narXiv:1603.04467.\n\n\nAggarwal, Charu, ed. 2007. Data Streams – Models and\nAlgorithms. Springer-Verlag.\n\n\nArlot, Sylvain, Alain Celisse, et al. 2010. “A Survey of\nCross-Validation Procedures for Model Selection.” Statistics\nSurveys 4: 40–79.\n\n\nBartz, Eva, Thomas Bartz-Beielstein, Martin Zaefferer, and Olaf\nMersmann, eds. 2022. Hyperparameter Tuning for\nMachine and Deep Learning with R - A Practical Guide.\nSpringer.\n\n\nBartz-Beielstein, Thomas. 2023a. “PyTorch\nHyperparameter Tuning with SPOT: Comparison with Ray\nTuner and Default Hyperparameters on\nCIFAR10.” https://github.com/sequential-parameter-optimization/spotpython/blob/main/notebooks/14_spot_ray_hpt_torch_cifar10.ipynb.\n\n\n———. 2023b. “Hyperparameter Tuning Cookbook:\nA guide for scikit-learn, PyTorch, river, and spotpython.”\narXiv e-Prints, July. https://doi.org/10.48550/arXiv.2307.10262.\n\n\n———. 2024a. “Evaluation and Performance Measurement.” In,\nedited by Eva Bartz and Thomas Bartz-Beielstein, 47–62. Singapore:\nSpringer Nature Singapore.\n\n\n———. 2024b. “Hyperparameter Tuning.” In, edited by Eva\nBartz and Thomas Bartz-Beielstein, 125–40. Singapore: Springer Nature\nSingapore.\n\n\n———. 2024c. “Introduction: From Batch to Online Machine\nLearning.” In Online Machine Learning: A Practical Guide with\nExamples in Python, edited by Eva Bartz and Thomas\nBartz-Beielstein, 1–11. Singapore: Springer Nature Singapore. https://doi.org/10.1007/978-981-99-7007-0_1.\n\n\n———. 2025. “Kriging (Gaussian Process Regression): The Complete\nPython Code for the Example.” https://sequential-parameter-optimization.github.io/Hyperparameter-Tuning-Cookbook/006_num_gp.html.\n\n\nBartz-Beielstein, Thomas, Jürgen Branke, Jörn Mehnen, and Olaf Mersmann.\n2014. “Evolutionary Algorithms.” Wiley\nInterdisciplinary Reviews: Data Mining and Knowledge Discovery 4\n(3): 178–95.\n\n\nBartz-Beielstein, Thomas, Martina Friese, Martin Zaefferer, Boris\nNaujoks, Oliver Flasch, Wolfgang Konen, and Patrick Koch. 2011.\n“Noisy optimization with sequential parameter\noptimization and optimal computational budget allocation.”\nIn Proceedings of the 13th Annual Conference Companion on Genetic\nand Evolutionary Computation, 119–20. New York, NY, USA: ACM.\n\n\nBartz-Beielstein, Thomas, and Lukas Hans. 2024. “Drift Detection\nand Handling.” In Online Machine Learning: A Practical Guide\nwith Examples in Python, edited by Eva Bartz and Thomas\nBartz-Beielstein, 23–39. Singapore: Springer Nature Singapore. https://doi.org/10.1007/978-981-99-7007-0_3.\n\n\nBartz-Beielstein, Thomas, Christian Lasarczyk, and Mike Preuss. 2005.\n“Sequential Parameter Optimization.” In\nProceedings 2005 Congress on Evolutionary\nComputation (CEC’05), Edinburgh, Scotland, edited by B McKay\net al., 773–80. Piscataway NJ: IEEE Press.\n\n\nBartz-Beielstein, Thomas, and Martin Zaefferer. 2022.\n“Hyperparameter Tuning Approaches.” In Hyperparameter Tuning for Machine and Deep Learning with\nR - A Practical Guide, edited by Eva Bartz, Thomas\nBartz-Beielstein, Martin Zaefferer, and Olaf Mersmann, 67–114. Springer.\n\n\nBifet, Albert. 2010. Adaptive Stream Mining: Pattern Learning and\nMining from Evolving Data Streams. Vol. 207. Frontiers in\nArtificial Intelligence and Applications. IOS Press.\n\n\nBifet, Albert, and Ricard Gavaldà. 2007. “Learning from\nTime-Changing Data with Adaptive Windowing.” In Proceedings\nof the 2007 SIAM International Conference on Data Mining (SDM),\n443–48.\n\n\n———. 2009. “Adaptive Learning from Evolving Data Streams.”\nIn Proceedings of the 8th International Symposium on Intelligent\nData Analysis: Advances in Intelligent Data Analysis VIII, 249–60.\nIDA ’09. Berlin, Heidelberg: Springer-Verlag.\n\n\nBifet, Albert, Geoff Holmes, Richard Kirkby, and Bernhard Pfahringer.\n2010a. “MOA: Massive Online\nAnalysis.” Journal of Machine Learning Research 99:\n1601–4.\n\n\n———. 2010b. “MOA: Massive Online Analysis.” Journal of\nMachine Learning Research 11: 1601–4.\n\n\nBischl, Bernd, Martin Binder, Michel Lang, Tobias Pielok, Jakob Richter,\nStefan Coors, Janek Thomas, et al. 2023. “Hyperparameter\nOptimization: Foundations, Algorithms, Best Practices, and Open\nChallenges.” WIREs Data Mining and Knowledge Discovery\n13 (2): e1484.\n\n\nBohachevsky, I O. 1986. “Generalized\nSimulated Annealing for Function Optimization.”\nTechnometrics 28 (3): 209–17.\n\n\nBox, G E P. 1957. “Evolutionary operation: A\nmethod for increasing industrial productivity.”\nApplied Statistics 6: 81–101.\n\n\nBox, G. E. P., and J. S. Hunter. 1957. “Multi-Factor Experimental\nDesigns for Exploring Response Surfaces.” The Annals of\nMathematical Statistics 28 (1): 195–241.\n\n\nBox, G. E. P., and K. B. Wilson. 1951. “On\nthe Experimental Attainment of Optimum Conditions.”\nJournal of the Royal Statistical Society. Series B\n(Methodological) 13 (1): 1–45.\n\n\nChen, Chun Hung. 2010. Stochastic simulation\noptimization: an optimal computing budget allocation. World\nScientific.\n\n\nChen, Ricky T. Q., Yulia Rubanova, Jesse Bettencourt, and David\nDuvenaud. 2018. “Neural Ordinary Differential\nEquations.” arXiv e-Prints, June,\narXiv:1806.07366.\n\n\nCoello, Carlos A. Coello, Silvia González Brambila, Josué Figueroa\nGamboa, and Ma. Guadalupe Castillo Tapia. 2021. “Multi-Objective\nEvolutionary Algorithms: Past, Present, and Future.” In, edited\nby Panos M. Pardalos, Varvara Rasskazova, and Michael N. Vrahatis,\n137–62. Cham: Springer International Publishing.\n\n\nDel Castillo, E., D. C. Montgomery, and D. R. McCarville. 1996.\n“Modified Desirability Functions for Multiple Response\nOptimization.” Journal of Quality Technology 28: 337–45.\n\n\nDerringer, G., and R. Suich. 1980. “Simultaneous Optimization of\nSeveral Response Variables.” Journal of Quality\nTechnology 12: 214–19.\n\n\nDevlin, Jacob, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018.\n“BERT: Pre-training of Deep Bidirectional\nTransformers for Language Understanding.” arXiv\ne-Prints, October, arXiv:1810.04805.\n\n\nDomingos, Pedro M., and Geoff Hulten. 2000. “Mining High-Speed\nData Streams.” In Proceedings of the Sixth ACM\nSIGKDD International Conference on Knowledge Discovery and\nData Mining, Boston, MA, USA, August 20-23, 2000, edited by Raghu\nRamakrishnan, Salvatore J. Stolfo, Roberto J. Bayardo, and Ismail Parsa,\n71–80. ACM.\n\n\nDosovitskiy, Alexey, Lucas Beyer, Alexander Kolesnikov, Dirk\nWeissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, et al.\n2020. “An Image is Worth 16x16 Words:\nTransformers for Image Recognition at Scale.” arXiv\ne-Prints, October, arXiv:2010.11929.\n\n\nDredze, Mark, Tim Oates, and Christine Piatko. 2010. “We’re Not in\nKansas Anymore: Detecting Domain Changes in Streams.” In\nProceedings of the 2010 Conference on Empirical Methods in Natural\nLanguage Processing, 585–95.\n\n\nEmmerich, Michael T. M., and AndréH. Deutz. 2018. “A Tutorial on\nMultiobjective Optimization: Fundamentals and Evolutionary\nMethods.” Natural Computing 17 (3): 585–609.\n\n\nForrester, Alexander, András Sóbester, and Andy Keane. 2008. Engineering Design via Surrogate Modelling.\nWiley.\n\n\nFriedman, Jerome H. 1991. “Multivariate Adaptive Regression\nSplines.” The Annals of Statistics 19 (1): 1–67.\n\n\nGaber, Mohamed Medhat, Arkady Zaslavsky, and Shonali Krishnaswamy. 2005.\n“Mining Data Streams: A Review.” SIGMOD\nRec. 34: 18–26.\n\n\nGama, João, Pedro Medas, Gladys Castillo, and Pedro Rodrigues. 2004.\n“Learning with Drift Detection.” In Advances in\nArtificial Intelligence – SBIA 2004, edited by Ana L. C. Bazzan and\nSofiane Labidi, 286–95. Berlin, Heidelberg: Springer Berlin Heidelberg.\n\n\nGama, João, Raquel Sebastião, and Pedro Pereira Rodrigues. 2013.\n“On Evaluating Stream Learning Algorithms.” Machine\nLearning 90 (3): 317–46.\n\n\nGramacy, Robert B. 2020. Surrogates. CRC press.\n\n\nHarington, J. 1965. “The Desirability Function.”\nIndustrial Quality Control 21: 494–98.\n\n\nHartung, Joachim, Bärbel Elpert, and Karl-Heinz Klösener. 1995.\nStatistik. Oldenbourg.\n\n\nHastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2017. The\nElements of Statistical Learning. Second. Springer.\n\n\nHe, Kaiming, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2015.\n“Deep Residual Learning for Image Recognition.”\n\n\n———. 2016. “Identity Mappings in Deep\nResidual Networks.” arXiv e-Prints, March,\narXiv:1603.05027.\n\n\nHoeglinger, Stefan, and Russel Pears. 2007. “Use of Hoeffding\nTrees in Concept Based Data Stream Mining.” 2007 Third\nInternational Conference on Information and Automation for\nSustainability, 57–62.\n\n\nIkonomovska, Elena. 2012. “Algorithms for Learning Regression\nTrees and Ensembles on Evolving Data Streams.” PhD thesis, Jozef\nStefan International Postgraduate School.\n\n\nIkonomovska, Elena, João Gama, and Sašo Džeroski. 2011. “Learning\nModel Trees from Evolving Data Streams.” Data Mining and\nKnowledge Discovery 23 (1): 128–68.\n\n\nJain, Sarthak, and Byron C. Wallace. 2019. “Attention is not Explanation.” arXiv\ne-Prints, February, arXiv:1902.10186.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani.\n2014. An Introduction to Statistical Learning\nwith Applications in R. 7th ed. Springer.\n\n\nJohnson, M. E., L. M. Moore, and D. Ylvisaker. 1990. “Minimax and\nMaximin Distance Designs.” Journal of Statistical Planning\nand Inference 26 (2): 131–48.\n\n\nKarl, Florian, Tobias Pielok, Julia Moosbauer, Florian Pfisterer, Stefan\nCoors, Martin Binder, Lennart Schneider, et al. 2023.\n“Multi-Objective Hyperparameter Optimization in Machine\nLearning—an Overview.” ACM Trans. Evol. Learn. Optim. 3\n(4).\n\n\nKeane, Andrew J, and Prasanth B Nair. 2005. Computational Approaches\nfor Aerospace Design: The Pursuit of Excellence. Wiley.\n\n\nKeller-McNulty, Sallie, ed. 2004. Statistical Analysis of Massive\nData Streams: Proceedings of a Workshop. Washington,\nDC: Committee on Applied; Theoretical Statistics, National Research\nCouncil; National Academies Press.\n\n\nKidger, Patrick. 2022. “On Neural Differential\nEquations.” arXiv e-Prints, February,\narXiv:2202.02435.\n\n\nKohavi, Ron. 1995. “A Study of Cross-Validation and Bootstrap for\nAccuracy Estimation and Model Selection.” In Proceedings of\nthe 14th International Joint Conference on Artificial Intelligence -\nVolume 2, 1137–43. IJCAI’95. San Francisco, CA, USA: Morgan\nKaufmann Publishers Inc.\n\n\nKuhn, Max. 2016. “Desirability: Function Optimization and Ranking\nvia Desirability Functions.”\n\n\nLewis, R M, V Torczon, and M W Trosset. 2000. “Direct search methods: Then and now.”\nJournal of Computational and Applied Mathematics 124 (1–2):\n191–207.\n\n\nLi, Lisha, Kevin Jamieson, Giulia DeSalvo, Afshin Rostamizadeh, and\nAmeet Talwalkar. 2016. “Hyperband: A Novel\nBandit-Based Approach to Hyperparameter Optimization.”\narXiv e-Prints, March, arXiv:1603.06560.\n\n\nLippe, Phillip. 2022. “UvA Deep Learning\nTutorials.” https://github.com/phlippe/uvadlc_notebooks/tree/master.\n\n\nLiu, Liyuan, Haoming Jiang, Pengcheng He, Weizhu Chen, Xiaodong Liu,\nJianfeng Gao, and Jiawei Han. 2019. “On the\nVariance of the Adaptive Learning Rate and Beyond.”\narXiv e-Prints, August, arXiv:1908.03265.\n\n\nManapragada, Chaitanya, Geoffrey I. Webb, and Mahsa Salehi. 2018.\n“Extremely Fast Decision Tree.” In KDD’ 2018 -\nProceedings of the 24th ACM SIGKDD International Conference on Knowledge\nDiscovery and Data Mining, edited by Chih-Jen Lin and Hui Xiong,\n1953–62. United States of America: Association for Computing Machinery\n(ACM). https://doi.org/10.1145/3219819.3220005.\n\n\nMasud, Mohammad, Jing Gao, Latifur Khan, Jiawei Han, and Bhavani M\nThuraisingham. 2011. “Classification and Novel Class Detection in\nConcept-Drifting Data Streams Under Time Constraints.” IEEE\nTransactions on Knowledge and Data Engineering 23 (6): 859–74.\n\n\nMeignan, David, Sigrid Knust, Jean-Marc Frayet, Gilles Pesant, and\nNicolas Gaud. 2015. “A Review and Taxonomy of\nInteractive Optimization Methods in Operations Research.”\nACM Transactions on Interactive Intelligent Systems, September.\n\n\nMicchelli, Charles A. 1986. “Interpolation of Scattered Data:\nDistance Matrices and Conditionally Positive Definite Functions.”\nConstructive Approximation 2 (1): 11–22. https://doi.org/10.1007/BF01893414.\n\n\nMontgomery, D C. 2001. Design and Analysis of\nExperiments. 5th ed. New York NY: Wiley.\n\n\nMontiel, Jacob, Max Halford, Saulo Martiello Mastelini, Geoffrey\nBolmier, Raphael Sourty, Robin Vaysse, Adil Zouitine, et al. 2021.\n“River: Machine Learning for Streaming Data in Python.”\n\n\nMorris, Max D., and Toby J. Mitchell. 1995. “Exploratory Designs\nfor Computational Experiments.” Journal of Statistical\nPlanning and Inference 43 (3): 381–402. https://doi.org/https://doi.org/10.1016/0378-3758(94)00035-T.\n\n\nMourtada, Jaouad, Stephane Gaiffas, and Erwan Scornet. 2019.\n“AMF: Aggregated Mondrian Forests for Online\nLearning.” arXiv e-Prints, June,\narXiv:1906.10529. https://doi.org/10.48550/arXiv.1906.10529.\n\n\nMyers, Raymond H, Douglas C Montgomery, and Christine M Anderson-Cook.\n2016. Response Surface Methodology: Process and Product Optimization\nUsing Designed Experiments. John Wiley & Sons.\n\n\nNelder, J. A., and R. Mead. 1965. “A Simplex\nMethod for Function Minimization.” The Computer\nJournal 7 (4): 308–13.\n\n\nNino, Esmeralda, Juan Rosas Rubio, Samuel Bonet, Nazario\nRamirez-Beltran, and Mauricio Cabrera-Rios. 2015. “Multiple\nObjective Optimization Using Desirability Functions for the Design of a\n3D Printer Prototype.” In.\n\n\n“NIST/SEMATECH e-Handbook of Statistical\nMethods.” 2021.\n\n\nOlsson, Donald M, and Lloyd S Nelson. 1975. “The Nelder-Mead\nSimplex Procedure for Function Minimization.”\nTechnometrics 17 (1): 45–51.\n\n\nPedregosa, F., G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O.\nGrisel, M. Blondel, et al. 2011. “Scikit-Learn: Machine Learning\nin Python.” Journal of Machine Learning\nResearch 12: 2825–30.\n\n\nPoggio, T, and F Girosi. 1990. “Regularization Algorithms for\nLearning That Are Equivalent to Multilayer Networks.”\nScience 247 (4945): 978–82. https://doi.org/10.1126/science.247.4945.978.\n\n\nPontryagin. 1987. Mathematical Theory of Optimal Processes.\nRoutledge.\n\n\nPutatunda, Sayan. 2021. Practical Machine Learning for Streaming\nData with Python. Springer.\n\n\nRaymer, Daniel P. 2006. Aircraft Design: A Conceptual Approach.\nAIAA.\n\n\nRummel, R. J. 1976. “Understanding Correlation.” https://www.hawaii.edu/powerkills/UC.HTM.\n\n\nSacks, J, W J Welch, T J Mitchell, and H P Wynn. 1989. “Design and analysis of computer\nexperiments.” Statistical Science 4 (4): 409–35.\n\n\nSantner, T J, B J Williams, and W I Notz. 2003. The Design and Analysis of Computer\nExperiments. Berlin, Heidelberg, New York: Springer.\n\n\nStreet, W. Nick, and YongSeog Kim. 2001. “A Streaming Ensemble\nAlgorithm (SEA) for Large-Scale Classification.” In\nProceedings of the Seventh ACM SIGKDD International Conference on\nKnowledge Discovery and Data Mining, 377–82. KDD ’01. New York, NY,\nUSA: Association for Computing Machinery.\n\n\nTay, Yi, Mostafa Dehghani, Dara Bahri, and Donald Metzler. 2020.\n“Efficient Transformers: A Survey.” arXiv\ne-Prints, September, arXiv:2009.06732.\n\n\nVapnik, V N. 1998. Statistical learning\ntheory. Wiley; Wiley.\n\n\nVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion\nJones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017.\n“Attention Is All You Need.” arXiv\ne-Prints, June, 1–15.\n\n\nWang, Zhiqiang. 2007. “Two Postestimation Commands for Assessing\nConfounding Effects in Epidemiological Studies.” The Stata\nJournal 7 (2): 183–96.\n\n\nWeihe, Karsten, Ulrik Brandes, Annegret Liebers, Matthias Mı̈\nller-Hannemann, Dorothea Wagner, and Thomas Willhalm. 1999. “Empirical Design of Geometric Algorithms.”\nIn SCG ’99: Proceedings of the Fifteenth Annual Symposium on\nComputational Geometry, 86–94. New York NY: Association for\nComputing Machinery.\n\n\nWiegreffe, Sarah, and Yuval Pinter. 2019. “Attention is not not Explanation.”\narXiv e-Prints, August, arXiv:1908.04626.\n\n\nWikipedia contributors. 2024. “Partial Correlation —\nWikipedia, the Free Encyclopedia.” https://en.wikipedia.org/w/index.php?title=Partial_correlation&oldid=1253637419.",
    "crumbs": [
      "Appendices",
      "References"
    ]
  }
]