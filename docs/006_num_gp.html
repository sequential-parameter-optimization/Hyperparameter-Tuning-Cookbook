<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>9&nbsp; Kriging (Gaussian Process Regression) – Hyperparameter Tuning Cookbook</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./006_matrices.html" rel="next">
<link href="./006_num_rbf.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-23a3edf7f3c1ed1fc827cae2f6dd4de5.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta name="twitter:title" content="9&nbsp; Kriging (Gaussian Process Regression) – Hyperparameter Tuning Cookbook">
<meta name="twitter:description" content="">
<meta name="twitter:image" content="006_num_gp_files/figure-html/fig-pval12-output-1.png">
<meta name="twitter:card" content="summary_large_image">
<meta name="citation_title" content="[9]{.chapter-number}&nbsp; [Kriging (Gaussian Process Regression)]{.chapter-title}">
<meta name="citation_fulltext_html_url" content="https://arxiv.org/abs/2307.10262">
<meta name="citation_doi" content="10.48550/arXiv.2307.10262">
<meta name="citation_language" content="en">
<meta name="citation_journal_title" content="arXiv">
<meta name="citation_reference" content="citation_title=Benchmarking in Optimization: Best Practice and Open Issues;,citation_author=Thomas Bartz-Beielstein;,citation_author=Carola Doerr;,citation_author=Jakob Bossek;,citation_author=Sowmya Chandrasekaran;,citation_author=Tome Eftimov;,citation_author=Andreas Fischbach;,citation_author=Pascal Kerschke;,citation_author=Manuel Lopez-Ibanez;,citation_author=Katherine M. Malan;,citation_author=Jason H. Moore;,citation_author=Boris Naujoks;,citation_author=Patryk Orzechowski;,citation_author=Vanessa Volz;,citation_author=Markus Wagner;,citation_author=Thomas Weise;,citation_publication_date=2020-07;,citation_cover_date=2020-07;,citation_year=2020;,citation_fulltext_html_url=https://arxiv.org/abs/2007.03488;,citation_publisher=arXiv;">
<meta name="citation_reference" content="citation_title=Hyperparameter Tuning With Ray Tune;,citation_author=undefined PyTorch;,citation_publication_date=2023-05;,citation_cover_date=2023-05;,citation_year=2023;,citation_fulltext_html_url=https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html;">
<meta name="citation_reference" content="citation_title=Training a Classifier;,citation_author=undefined PyTorch;,citation_publication_date=2023-05;,citation_cover_date=2023-05;,citation_year=2023;,citation_fulltext_html_url=https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html;">
<meta name="citation_reference" content="citation_title=PyTorch Hyperparameter Tuning with SPOT: Comparison with Ray Tuner and Default Hyperparameters on CIFAR10;,citation_author=Thomas Bartz-Beielstein;,citation_publication_date=2023-04;,citation_cover_date=2023-04;,citation_year=2023;,citation_fulltext_html_url=https://github.com/sequential-parameter-optimization/spotpython/blob/main/notebooks/14_spot_ray_hpt_torch_cifar10.ipynb;">
<meta name="citation_reference" content="citation_title=Machine Learning in Official Statistics;,citation_author=Martin Beck;,citation_author=Florian Dumpert;,citation_author=Joerg Feuerhake;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_doi=10.48550/arXiv.1812.10422;">
<meta name="citation_reference" content="citation_title=Qualitätshandbuch der Statistischen Ämter des Bundes und der Länder;,citation_publication_date=2021-03;,citation_cover_date=2021-03;,citation_year=2021;,citation_fulltext_html_url=https://www.destatis.de/DE/Methoden/Qualitaet/qualitaetshandbuch.pdf;,citation_language=de;">
<meta name="citation_reference" content="citation_title=Quality Assurance Framework of the European Statistical System;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_fulltext_html_url=https://ec.europa.eu/eurostat/documents/64157/4392716/ESS-QAF-V2.0-final.pdf;,citation_language=en;">
<meta name="citation_reference" content="citation_title=Standardisierung der Prozesse: 14 Jahre AG SteP;,citation_author=T. Blumöhr;,citation_author=C. Teichmann;,citation_author=A. Noack;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_fulltext_html_url=https://www.destatis.de/DE/Methoden/
               WISTA-Wirtschaft-und-Statistik/2017/05/standardisierung-prozesse-052017.html;,citation_volume=5;,citation_journal_title=WISTA - Wirtschaft und Statistik;,citation_publisher=Wiesbaden: Statistisches Bundesamt (Destatis);">
<meta name="citation_reference" content="citation_title=Generic Statistical Business Process Model - GSBPM;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_fulltext_html_url=https://statswiki.unece.org/display/
               GSBPM/GSBPM+v5.1;,citation_publisher=United Nations Economic Commission for Europe (UNECE);">
<meta name="citation_reference" content="citation_title=Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide;,citation_editor=Eva Bartz;,citation_editor=Thomas Bartz-Beielstein;,citation_editor=Martin Zaefferer;,citation_editor=Olaf Mersmann;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=Engineering Design via Surrogate Modelling;,citation_author=Alexander Forrester;,citation_author=András Sóbester;,citation_author=Andy Keane;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;">
<meta name="citation_reference" content="citation_title=No Free Lunch Theorems for Optimization;,citation_author=David H Wolpert;,citation_author=William G Macready;,citation_publication_date=1997-04;,citation_cover_date=1997-04;,citation_year=1997;,citation_issue=1;,citation_volume=1;,citation_journal_title=IEEE Transactions on Evolutionary Computation;">
<meta name="citation_reference" content="citation_title=An Introduction to Statistical Learning with Applications in R;,citation_author=Gareth James;,citation_author=Daniela Witten;,citation_author=Trevor Hastie;,citation_author=Robert Tibshirani;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;">
<meta name="citation_reference" content="citation_title=Requirements for papers focusing on new or improved global optimization algorithms;,citation_author=Raphael T. Haftka;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_issue=1;,citation_volume=54;,citation_journal_title=Structural and Multidisciplinary Optimization;">
<meta name="citation_reference" content="citation_title=LightGBM: A Highly Efficient Gradient Boosting Decision Tree;,citation_author=Guolin Ke;,citation_author=Qi Meng;,citation_author=Thomas Finley;,citation_author=Taifeng Wang;,citation_author=Wei Chen;,citation_author=Weidong Ma;,citation_author=Qiwei Ye;,citation_author=Tie-Yan Liu;,citation_editor=I. Guyon;,citation_editor=U. Von Luxburg;,citation_editor=S. Bengio;,citation_editor=H. Wallach;,citation_editor=R. Fergus;,citation_editor=S. Vishwanathan;,citation_editor=R. Garnett;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_volume=30;,citation_conference_title=Advances in Neural Information Processing Systems;,citation_conference=Curran Associates, Inc.;">
<meta name="citation_reference" content="citation_title=Greedy Function Approximation: A Gradient Boosting Machine;,citation_author=Jerome H. Friedman;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_issue=5;,citation_volume=29;,citation_journal_title=The Annals of Statistics;">
<meta name="citation_reference" content="citation_title=Machine Learning in Official Statistics;,citation_author=Martin Beck;,citation_author=Florian Dumpert;,citation_author=Joerg Feuerhake;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_doi=10.48550/arXiv.1812.10422;">
<meta name="citation_reference" content="citation_title=Official statistics in the era of big data opportunities and threats;,citation_author=Walter J. Radermacher;,citation_publication_date=2018-11-01;,citation_cover_date=2018-11-01;,citation_year=2018;,citation_fulltext_html_url=https://doi.org/10.1007/s41060-018-0124-z;,citation_issue=3;,citation_doi=10.1007/s41060-018-0124-z;,citation_volume=6;,citation_language=en;,citation_journal_title=International Journal of Data Science and Analytics;">
<meta name="citation_reference" content="citation_title=Machine Learning in Official Statistics;,citation_author=Martin Beck;,citation_author=Florian Dumpert;,citation_author=Joerg Feuerhake;">
<meta name="citation_reference" content="citation_title=A quality framework for statistical algorithms;,citation_author=Wesley Yung;,citation_author=Siu-Ming Tam;,citation_author=Bart Buelens;,citation_author=Hugh Chipman;,citation_author=Florian Dumpert;,citation_author=Gabriele Ascari;,citation_author=Fabiana Rocci;,citation_author=Joep Burger;,citation_author=InKyung Choi;,citation_publication_date=2022-01-01;,citation_cover_date=2022-01-01;,citation_year=2022;,citation_fulltext_html_url=https://content.iospress.com/articles/statistical-journal-of-the-iaos/sji210875;,citation_issue=1;,citation_doi=10.3233/SJI-210875;,citation_volume=38;,citation_language=en;,citation_journal_title=Statistical Journal of the IAOS;">
<meta name="citation_reference" content="citation_title=A quality framework for statistical algorithms;,citation_author=Wesley Yung;,citation_author=Siu-Ming Tam;,citation_author=Bart Buelens;,citation_author=Hugh Chipman;,citation_author=Florian Dumpert;,citation_author=Gabriele Ascari;,citation_author=Fabiana Rocci;,citation_author=Joep Burger;,citation_author=InKyung Choi;,citation_publication_date=2022-01;,citation_cover_date=2022-01;,citation_year=2022;,citation_issue=1;,citation_volume=38;,citation_journal_title=Statistical Journal of the IAOS;">
<meta name="citation_reference" content="citation_title=Qualitätshandbuch der Statistischen Ämter des Bundes und der Länder;,citation_author=Michael Reichelt;">
<meta name="citation_reference" content="citation_title=Data Science and Official Statistics: Toward a New Data Culture;,citation_author=Stefan Schweinfest;,citation_author=Ronald Jansen;,citation_publication_date=2021-10-28;,citation_cover_date=2021-10-28;,citation_year=2021;,citation_fulltext_html_url=https://hdsr.mitpress.mit.edu/pub/1g514ljw/release/4;,citation_issue=4;,citation_doi=10.1162/99608f92.c1237762;,citation_volume=3;,citation_language=en;,citation_journal_title=Harvard Data Science Review;">
<meta name="citation_reference" content="citation_title=Official Statistics 4.0: Verified Facts for People in the 21st Century;,citation_author=Walter J. Radermacher;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;">
<meta name="citation_reference" content="citation_title=Detecting Covariate Drift with Explanations;,citation_author=Steffen Castle;,citation_author=Robert Schwarzenberg;,citation_author=Mohsen Pourvali;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_conference_title=Natural Language Processing and Chinese Computing: 10th CCF International Conference, NLPCC 2021, Qingdao, China, October 13–17, 2021, Proceedings, Part II;,citation_conference=Springer-Verlag;">
<meta name="citation_reference" content="citation_title=Keras;,citation_author=Francois Chollet;,citation_author=others;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_publisher=https:://keras.io;">
<meta name="citation_reference" content="citation_title=TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems;,citation_author=Martin Abadi;,citation_author=Ashish Agarwal;,citation_author=Paul Barham;,citation_author=Eugene Brevdo;,citation_author=Zhifeng Chen;,citation_author=Craig Citro;,citation_author=Greg S. Corrado;,citation_author=Andy Davis;,citation_author=Jeffrey Dean;,citation_author=Matthieu Devin;,citation_author=Sanjay Ghemawat;,citation_author=Ian Goodfellow;,citation_author=Andrew Harp;,citation_author=Geoffrey Irving;,citation_author=Michael Isard;,citation_author=Yangqing Jia;,citation_author=Rafal Jozefowicz;,citation_author=Lukasz Kaiser;,citation_author=Manjunath Kudlur;,citation_author=Josh Levenberg;,citation_author=Dan Mane;,citation_author=Rajat Monga;,citation_author=Sherry Moore;,citation_author=Derek Murray;,citation_author=Chris Olah;,citation_author=Mike Schuster;,citation_author=Jonathon Shlens;,citation_author=Benoit Steiner;,citation_author=Ilya Sutskever;,citation_author=Kunal Talwar;,citation_author=Paul Tucker;,citation_author=Vincent Vanhoucke;,citation_author=Vijay Vasudevan;,citation_author=Fernanda Viegas;,citation_author=Oriol Vinyals;,citation_author=Pete Warden;,citation_author=Martin Wattenberg;,citation_author=Martin Wicke;,citation_author=Yuan Yu;,citation_author=Xiaoqiang Zheng;,citation_publication_date=2016-03;,citation_cover_date=2016-03;,citation_year=2016;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=statsmodels: Econometric and statistical modeling with python;,citation_author=Skipper Seabold;,citation_author=Josef Perktold;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_conference_title=9th Python in Science Conference;">
<meta name="citation_reference" content="citation_title=Scikit-learn: Machine Learning in Python;,citation_author=F. Pedregosa;,citation_author=G. Varoquaux;,citation_author=A. Gramfort;,citation_author=V. Michel;,citation_author=B. Thirion;,citation_author=O. Grisel;,citation_author=M. Blondel;,citation_author=P. Prettenhofer;,citation_author=R. Weiss;,citation_author=V. Dubourg;,citation_author=J. Vanderplas;,citation_author=A. Passos;,citation_author=D. Cournapeau;,citation_author=M. Brucher;,citation_author=M. Perrot;,citation_author=E. Duchesnay;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_volume=12;,citation_journal_title=Journal of Machine Learning Research;">
<meta name="citation_reference" content="citation_title=Array programming with NumPy;,citation_author=Charles R. Harris;,citation_author=K. Jarrod Millman;,citation_author=Stéfan J. Walt;,citation_author=Ralf Gommers;,citation_author=Pauli Virtanen;,citation_author=David Cournapeau;,citation_author=Eric Wieser;,citation_author=Julian Taylor;,citation_author=Sebastian Berg;,citation_author=Nathaniel J. Smith;,citation_author=Robert Kern;,citation_author=Matti Picus;,citation_author=Stephan Hoyer;,citation_author=Marten H. Kerkwijk;,citation_author=Matthew Brett;,citation_author=Allan Haldane;,citation_author=Jaime Fernández Río;,citation_author=Mark Wiebe;,citation_author=Pearu Peterson;,citation_author=Pierre Gérard-Marchant;,citation_author=Kevin Sheppard;,citation_author=Tyler Reddy;,citation_author=Warren Weckesser;,citation_author=Hameer Abbasi;,citation_author=Christoph Gohlke;,citation_author=Travis E. Oliphant;,citation_publication_date=2020-09;,citation_cover_date=2020-09;,citation_year=2020;,citation_issue=7825;,citation_volume=585;,citation_journal_title=Nature;">
<meta name="citation_reference" content="citation_title=Algorithms for Learning Regression Trees and Ensembles on Evolving Data Streams;,citation_author=Elena Ikonomovska;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_dissertation_institution=Jozef Stefan International Postgraduate School;">
<meta name="citation_reference" content="citation_title=Online Bagging and Boosting;,citation_author=N C Oza;,citation_conference_title=2005 IEEE International Conference on Systems, Man and Cybernetics;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Online bagging and boosting;,citation_author=Nikunj C Oza;,citation_author=Stuart Russell;,citation_editor=T Jaakola;,citation_editor=T Richardson;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_conference_title=8th Insternational Workshop on Artificial Intelligence and Statistics;">
<meta name="citation_reference" content="citation_title=Event labeling combining ensemble detectors and background knowledge;,citation_author=Hadi Fanaee-T;,citation_author=Joao Gama;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=2;,citation_volume=2;,citation_journal_title=Progress in Artificial Intelligence;">
<meta name="citation_reference" content="citation_title=Adaptive random forests for evolving data stream classification;,citation_author=Heitor M. Gomes;,citation_author=Albert Bifet;,citation_author=Jesse Read;,citation_author=Jean Paul Barddal;,citation_author=Fabricio Enembreck;,citation_author=Bernhard Pfharinger;,citation_author=Geoff Holmes;,citation_author=Talel Abdessalem;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=9;,citation_volume=106;,citation_journal_title=Machine Learning;">
<meta name="citation_reference" content="citation_title=Literate Programming;,citation_author=Donald E. Knuth;,citation_publication_date=1984-05;,citation_cover_date=1984-05;,citation_year=1984;,citation_fulltext_html_url=https://doi.org/10.1093/comjnl/27.2.97;,citation_issue=2;,citation_doi=10.1093/comjnl/27.2.97;,citation_issn=0010-4620;,citation_volume=27;,citation_journal_title=Comput. J.;,citation_publisher=Oxford University Press, Inc.;">
<meta name="citation_reference" content="citation_title=A Review and Taxonomy of Interactive Optimization Methods in Operations Research;,citation_author=David Meignan;,citation_author=Sigrid Knust;,citation_author=Jean-Marc Frayet;,citation_author=Gilles Pesant;,citation_author=Nicolas Gaud;,citation_publication_date=2015-09;,citation_cover_date=2015-09;,citation_year=2015;,citation_journal_title=ACM Transactions on Interactive Intelligent Systems;">
<meta name="citation_reference" content="citation_title=Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide;,citation_editor=Eva Bartz;,citation_editor=Thomas Bartz-Beielstein;,citation_editor=Martin Zaefferer;,citation_editor=Olaf Mersmann;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=In a Nutshell – The Sequential Parameter Optimization Toolbox;,citation_author=Thomas Bartz-Beielstein;,citation_author=Martin Zaefferer;,citation_author=Frederik Rehbach;,citation_publication_date=2021-12;,citation_cover_date=2021-12;,citation_year=2021;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Direct search methods: Then and now;,citation_author=R M Lewis;,citation_author=V Torczon;,citation_author=M W Trosset;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_issue=1–2;,citation_volume=124;,citation_journal_title=Journal of Computational and Applied Mathematics;">
<meta name="citation_reference" content="citation_title=Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization;,citation_author=Lisha Li;,citation_author=Kevin Jamieson;,citation_author=Giulia DeSalvo;,citation_author=Afshin Rostamizadeh;,citation_author=Ameet Talwalkar;,citation_publication_date=2016-03;,citation_cover_date=2016-03;,citation_year=2016;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Sequential Parameter Optimization;,citation_author=Thomas Bartz-Beielstein;,citation_author=Christian Lasarczyk;,citation_author=Mike Preuss;,citation_editor=B McKay;,citation_editor=others;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_conference_title=Proceedings 2005 Congress on Evolutionary Computation (CEC’05), Edinburgh, Scotland;,citation_conference=IEEE Press;">
<meta name="citation_reference" content="citation_title=Evolutionary Algorithms;,citation_author=Thomas Bartz-Beielstein;,citation_author=Jürgen Branke;,citation_author=Jörn Mehnen;,citation_author=Olaf Mersmann;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=3;,citation_volume=4;,citation_journal_title=Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery;">
<meta name="citation_reference" content="citation_title=Classification and Regression Trees;,citation_author=L Breiman;,citation_author=J H Friedman;,citation_author=R A Olshen;,citation_author=C J Stone;,citation_publication_date=1984;,citation_cover_date=1984;,citation_year=1984;">
<meta name="citation_reference" content="citation_title=Continuous inspection schemes;,citation_author=E. S. Page;,citation_publication_date=1954-06;,citation_cover_date=1954-06;,citation_year=1954;,citation_issue=1-2;,citation_volume=41;,citation_journal_title=Biometrika;">
<meta name="citation_reference" content="citation_title=Counting Large Numbers of Events in Small Registers;,citation_author=Robert Morris;,citation_publication_date=1978-10;,citation_cover_date=1978-10;,citation_year=1978;,citation_issue=10;,citation_volume=21;,citation_journal_title=Commun. ACM;">
<meta name="citation_reference" content="citation_title=Approximate Counting: A Detailed Analysis;,citation_author=Philippe Flajolet;,citation_publication_date=1985-03;,citation_cover_date=1985-03;,citation_year=1985;,citation_issue=1;,citation_volume=25;,citation_journal_title=BIT;">
<meta name="citation_reference" content="citation_title=Random Sampling with a Reservoir;,citation_author=Jeffrey S. Vitter;,citation_publication_date=1985-03;,citation_cover_date=1985-03;,citation_year=1985;,citation_issue=1;,citation_volume=11;,citation_journal_title=ACM Trans. Math. Softw.;">
<meta name="citation_reference" content="citation_title=Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem;,citation_author=Michael McCloskey;,citation_author=Neal J. Cohen;,citation_publication_date=1989-01;,citation_cover_date=1989-01;,citation_year=1989;,citation_issue=C;,citation_volume=24;,citation_journal_title=Psychology of Learning and Motivation - Advances in Research and Theory;">
<meta name="citation_reference" content="citation_title=Detection of Abrupt Changes - Theory and Application;,citation_author=Michèle Basseville;,citation_author=Igor V. Nikiforov;,citation_publication_date=1993;,citation_cover_date=1993;,citation_year=1993;">
<meta name="citation_reference" content="citation_title=An Introduction to Computational Learning Theory;,citation_author=Michael J. Kearns;,citation_author=Umesh V. Vazirani;,citation_publication_date=1994;,citation_cover_date=1994;,citation_year=1994;">
<meta name="citation_reference" content="citation_title=An Introduction to the Kalman Filter;,citation_author=Greg Welch;,citation_author=Gary Bishop;,citation_publication_date=1995;,citation_cover_date=1995;,citation_year=1995;">
<meta name="citation_reference" content="citation_title=The Space Complexity of Approximating the Frequency Moments;,citation_author=Noga Alon;,citation_author=Yossi Matias;,citation_author=Mario Szegedy;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_conference_title=Proceedings of the Twenty-Eighth Annual ACM Symposium on Theory of Computing;,citation_conference=Association for Computing Machinery;,citation_series_title=STOC ’96;">
<meta name="citation_reference" content="citation_title=SPLICE-2 Comparative Evaluation: Electricity Pricing;,citation_author=Michael Harries;,citation_author=U Nsw-cse-tr;,citation_author=New South Wales;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;">
<meta name="citation_reference" content="citation_title=Mining high-speed data streams;,citation_author=Pedro M. Domingos;,citation_author=Geoff Hulten;,citation_editor=Raghu Ramakrishnan;,citation_editor=Salvatore J. Stolfo;,citation_editor=Roberto J. Bayardo;,citation_editor=Ismail Parsa;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_conference_title=Proceedings of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining, Boston, MA, USA, August 20-23, 2000;,citation_conference=ACM;">
<meta name="citation_reference" content="citation_title=Mining Time-Changing Data Streams;,citation_author=Geoff Hulten;,citation_author=Laurie Spencer;,citation_author=Pedro Domingos;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_conference_title=Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;,citation_conference=Association for Computing Machinery;,citation_series_title=KDD ’01;">
<meta name="citation_reference" content="citation_title=A Streaming Ensemble Algorithm (SEA) for Large-Scale Classification;,citation_author=W. Nick Street;,citation_author=YongSeog Kim;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_conference_title=Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;,citation_conference=Association for Computing Machinery;,citation_series_title=KDD ’01;">
<meta name="citation_reference" content="citation_title=3D Data Management: Controlling Data Volume, Velocity, and Variety;,citation_author=Douglas Laney;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_technical_report_institution=META Group;">
<meta name="citation_reference" content="citation_title=Models and Issues in Data Stream Systems;,citation_author=Brian Babcock;,citation_author=Shivnath Babu;,citation_author=Mayur Datar;,citation_author=Rajeev Motwani;,citation_author=Jennifer Widom;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_conference_title=Proceedings of the 21st ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems;,citation_conference=ACM;,citation_series_title=PODS ’02;">
<meta name="citation_reference" content="citation_title=A New Approximate Maximal Margin Classification Algorithm;,citation_author=Claudio Gentile;,citation_publication_date=2002-03;,citation_cover_date=2002-03;,citation_year=2002;,citation_volume=2;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=The Design and Analysis of Computer Experiments;,citation_author=T J Santner;,citation_author=B J Williams;,citation_author=W I Notz;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;">
<meta name="citation_reference" content="citation_title=Learning with drift detection;,citation_author=João Gama;,citation_author=Pedro Medas;,citation_author=Gladys Castillo;,citation_author=Pedro Rodrigues;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_conference_title=In SBIA Brazilian Symposium on Artificial Intelligence;,citation_conference=Springer Verlag;">
<meta name="citation_reference" content="citation_title=Learning with Drift Detection;,citation_author=João Gama;,citation_author=Pedro Medas;,citation_author=Gladys Castillo;,citation_author=Pedro Rodrigues;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_inbook_title=Parallel Problem Solving from Nature - PPSN XIII - 13th International Conference, Ljubljana, Slovenia, September 13-17, 2014. Proceedings;">
<meta name="citation_reference" content="citation_title=Learning with Drift Detection;,citation_author=João Gama;,citation_author=Pedro Medas;,citation_author=Gladys Castillo;,citation_author=Pedro Rodrigues;,citation_editor=Ana L. C. Bazzan;,citation_editor=Sofiane Labidi;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_conference_title=Advances in Artificial Intelligence – SBIA 2004;,citation_conference=Springer Berlin Heidelberg;">
<meta name="citation_reference" content="citation_title=Statistical Analysis of Massive Data Streams: Proceedings of a Workshop;,citation_editor=Sallie Keller-McNulty;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;">
<meta name="citation_reference" content="citation_title=Data Mining: Practical Machine Learning Tools and Techniques;,citation_author=Ian H. Witten;,citation_author=Eibe Frank;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_series_title=The Morgan Kaufmann Series in Data Management Systems;">
<meta name="citation_reference" content="citation_title=Towards Generic Pattern Mining;,citation_author=Mohammed Javeed Zaki;,citation_author=Nagender Parimi;,citation_author=Nilanjana De;,citation_author=Feng Gao;,citation_author=Benjarath Phoophakdee;,citation_author=Joe Urban;,citation_author=Vineet Chaoji;,citation_author=Mohammad Al Hasan;,citation_author=Saeed Salem;,citation_editor=Bernhard Ganter;,citation_editor=Robert Godin;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_volume=3403;,citation_conference_title=Formal Concept Analysis, Third International Conference, ICFCA 2005, Lens, France, February 14-18, 2005, Proceedings;,citation_conference=Springer;,citation_series_title=Lecture Notes in Computer Science;">
<meta name="citation_reference" content="citation_title=Mining Data Streams: A Review;,citation_author=Mohamed Medhat Gaber;,citation_author=Arkady Zaslavsky;,citation_author=Shonali Krishnaswamy;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_volume=34;,citation_journal_title=SIGMOD Rec.;">
<meta name="citation_reference" content="citation_title=Early drift detection method;,citation_author=Manuel Baena-Garcıa;,citation_author=José Campo-Ávila;,citation_author=Raúl Fidalgo;,citation_author=Albert Bifet;,citation_author=R Gavalda;,citation_author=Rafael Morales-Bueno;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_volume=6;,citation_conference_title=Fourth international workshop on knowledge discovery from data streams;">
<meta name="citation_reference" content="citation_title=Online Passive-Aggressive Algorithms;,citation_author=Koby Crammer;,citation_author=Ofer Dekel;,citation_author=Joseph Keshet;,citation_author=Shai Shalev-Shwartz;,citation_author=Yoram Singer;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=19;,citation_volume=7;,citation_journal_title=Journal of Machine Learning Research;">
<meta name="citation_reference" content="citation_title=Data Streams – Models and Algorithms;,citation_editor=Charu Aggarwal;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;">
<meta name="citation_reference" content="citation_title=Learning from Time-Changing Data with Adaptive Windowing;,citation_author=Albert Bifet;,citation_author=Ricard Gavaldà;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_conference_title=Proceedings of the 2007 SIAM International Conference on Data Mining (SDM);">
<meta name="citation_reference" content="citation_title=Learning from time-changing data with adaptive windowing;,citation_author=Albert Bifet;,citation_author=Ricard Gavalda;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_volume=7;,citation_conference_title=Proceedings of the 2007 SIAM international conference on data mining;,citation_conference=SIAM;">
<meta name="citation_reference" content="citation_title=A Survey of Classification Methods in Data Streams;,citation_author=Mohamed Gaber;,citation_author=Arkady Zaslavsky;,citation_author=Shonali Krishnaswamy;,citation_editor=Charu Aggarwal;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_inbook_title=Data Streams – Models and Algorithms;">
<meta name="citation_reference" content="citation_title=Use of Hoeffding trees in concept based data stream mining;,citation_author=Stefan Hoeglinger;,citation_author=Russel Pears;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_journal_title=2007 Third International Conference on Information and Automation for Sustainability;">
<meta name="citation_reference" content="citation_title=Detecting concept drift using statistical testing;,citation_author=Kyosuke Nishida;,citation_author=Koichiro Yamauchi;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_conference_title=International conference on discovery science;,citation_conference=Springer;">
<meta name="citation_reference" content="citation_title=Olindda: A cluster-based approach for detecting novelty and concept drift in data streams;,citation_author=Eduardo J Spinosa;,citation_author=André Ponce Leon F. de Carvalho;,citation_author=Joao Gama;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_conference_title=Proceedings of the 2007 ACM symposium on Applied computing;">
<meta name="citation_reference" content="citation_title=Statistical Quality Control;,citation_author=Douglas C Montgomery;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;">
<meta name="citation_reference" content="citation_title=Adaptive Learning from Evolving Data Streams;,citation_author=Albert Bifet;,citation_author=Ricard Gavaldà;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=Proceedings of the 8th International Symposium on Intelligent Data Analysis: Advances in Intelligent Data Analysis VIII;,citation_conference=Springer-Verlag;,citation_series_title=IDA ’09;">
<meta name="citation_reference" content="citation_title=New Ensemble Methods for Evolving Data Streams;,citation_author=Albert Bifet;,citation_author=Geoff Holmes;,citation_author=Bernhard Pfahringer;,citation_author=Richard Kirkby;,citation_author=Ricard Gavaldà;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;,citation_conference=Association for Computing Machinery;,citation_series_title=KDD ’09;">
<meta name="citation_reference" content="citation_title=Adaptive concept drift detection;,citation_author=Anton Dries;,citation_author=Ulrich Rückert;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=5-6;,citation_volume=2;,citation_journal_title=Stat. Anal. Data Min.;">
<meta name="citation_reference" content="citation_title=Issues in Evaluation of Stream Learning Algorithms;,citation_author=João Gama;,citation_author=Raquel Sebastião;,citation_author=Pedro Pereira Rodrigues;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;,citation_conference=Association for Computing Machinery;,citation_series_title=KDD ’09;">
<meta name="citation_reference" content="citation_title=Stream Data Processing: A Quality of Service Perspective;,citation_author=Qingchun Jiang;,citation_author=Sharma Chakravarthy;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;">
<meta name="citation_reference" content="citation_title=Probabilistic Counting with Randomized Storage;,citation_author=Benjamin Van Durme;,citation_author=Ashwin Lall;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=Proceedings of the 21st International Joint Conference on Artificial Intelligence;,citation_conference=Morgan Kaufmann Publishers Inc.;,citation_series_title=IJCAI’09;">
<meta name="citation_reference" content="citation_title=Adaptive Stream Mining: Pattern Learning and Mining from Evolving Data Streams;,citation_author=Albert Bifet;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_volume=207;,citation_series_title=Frontiers in Artificial Intelligence and Applications;">
<meta name="citation_reference" content="citation_title=We’re not in kansas anymore: detecting domain changes in streams;,citation_author=Mark Dredze;,citation_author=Tim Oates;,citation_author=Christine Piatko;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_conference_title=Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing;">
<meta name="citation_reference" content="citation_title=Large-Scale Inference: Empirical Bayes Methods for Estimation, Testing, and Prediction (Institute of Mathematical Statistics Monographs);,citation_author=Bradley Efron;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;">
<meta name="citation_reference" content="citation_title=Knowledge Discovery from Data Streams;,citation_author=João Gama;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_series_title=Chapman and Hall / CRC Data Mining and Knowledge Discovery Series;">
<meta name="citation_reference" content="citation_title=A DCT based approach for detecting novelty and concept drift in data streams;,citation_author=Morteza Zi Hayat;,citation_author=Mahmoud Reza Hashemi;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_conference_title=2010 International Conference of Soft Computing and Pattern Recognition;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Benchmarking Stream Clustering Algorithms within the MOA Framework;,citation_author=Philipp Kranen;,citation_author=Hardy Kremer;,citation_author=Timm Jansen;,citation_author=Thomas Seidl;,citation_author=Albert Bifet;,citation_author=Geoff Holmes;,citation_author=Bernhard Pfahringer;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_conference_title=16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD 2010), Washington, DC, USA;">
<meta name="citation_reference" content="citation_title=MOA: Massive Online Analysis;,citation_author=Albert Bifet;,citation_author=Geoff Holmes;,citation_author=Richard Kirkby;,citation_author=Bernhard Pfahringer;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_volume=99;,citation_journal_title=Journal of Machine Learning Research;">
<meta name="citation_reference" content="citation_title=Hellinger distance based drift detection for nonstationary environments;,citation_author=Gregory Ditzler;,citation_author=Robi Polikar;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_conference_title=2011 IEEE symposium on computational intelligence in dynamic and uncertain environments (CIDUE);,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Classification and novel class detection in concept-drifting data streams under time constraints;,citation_author=Mohammad Masud;,citation_author=Jing Gao;,citation_author=Latifur Khan;,citation_author=Jiawei Han;,citation_author=Bhavani M Thuraisingham;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=6;,citation_volume=23;,citation_journal_title=IEEE Transactions on Knowledge and Data Engineering;">
<meta name="citation_reference" content="citation_title=New drift detection method for data streams;,citation_author=Parinaz Sobhani;,citation_author=Hamid Beigy;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_conference_title=International conference on adaptive and intelligent systems;,citation_conference=Springer;">
<meta name="citation_reference" content="citation_title=birch: Dealing With Very Large Datasets Using BIRCH;,citation_author=Lysiane Charest;,citation_author=Justin Harrington;,citation_author=Matias Salibian-Barrera;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;">
<meta name="citation_reference" content="citation_title=Synopses for Massive Data: Samples, Histograms, Wavelets, Sketches;,citation_author=Graham Cormode;,citation_author=Minos Garofalakis;,citation_author=Peter J. Haas;,citation_author=Chris Jermaine;,citation_publication_date=2012-01;,citation_cover_date=2012-01;,citation_year=2012;,citation_issue=1–3;,citation_volume=4;,citation_journal_title=Found. Trends Databases;">
<meta name="citation_reference" content="citation_title=Detection of concept drift for learning from stream data;,citation_author=Jeonghoon Lee;,citation_author=Frederic Magoules;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_conference_title=2012 IEEE 14th International Conference on High Performance Computing and Communication &amp;amp;amp; 2012 IEEE 9th International Conference on Embedded Software and Systems;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=mlbench: Machine Learning Benchmark Problems;,citation_author=Friedrich Leisch;,citation_author=Evgenia Dimitriadou;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;">
<meta name="citation_reference" content="citation_title=A unifying view on dataset shift in classification;,citation_author=Jose G. Moreno-Torres;,citation_author=Troy Raeder;,citation_author=Rocı́o Alaı́z-Rodrı́guez;,citation_author=Nitesh V. Chawla;,citation_author=Francisco Herrera;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=1;,citation_volume=45;,citation_journal_title=Pattern Recognit.;">
<meta name="citation_reference" content="citation_title=HadoopStreaming: Utilities for Using R Scripts in Hadoop Streaming;,citation_author=David S. Rosenberg;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;">
<meta name="citation_reference" content="citation_title=Exponentially weighted moving average charts for detecting concept drift;,citation_author=Gordon J Ross;,citation_author=Niall M Adams;,citation_author=Dimitris K Tasoulis;,citation_author=David J Hand;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=2;,citation_volume=33;,citation_journal_title=Pattern recognition letters;">
<meta name="citation_reference" content="citation_title=An efficient method of building an ensemble of classifiers in streaming data;,citation_author=Joung Woo Ryu;,citation_author=Mehmed M Kantardzic;,citation_author=Myung-Won Kim;,citation_author=A Ra Khil;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_conference_title=International Conference on Big Data Analytics;,citation_conference=Springer;">
<meta name="citation_reference" content="citation_title=rlecuyer: R Interface to RNG With Multiple Streams;,citation_author=Hana Sevcikova;,citation_author=Tony Rossini;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;">
<meta name="citation_reference" content="citation_title=Machine Learning that Matters;,citation_author=Kiri Wagstaff;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;">
<meta name="citation_reference" content="citation_title=CD-MOA: Change Detection Framework for Massive Online Analysis;,citation_author=Albert Bifet;,citation_author=Jesse Read;,citation_author=Bernhard Pfahringer;,citation_author=Geoff Holmes;,citation_author=Indrė Žliobaitė;,citation_editor=Allan Tucker;,citation_editor=Frank Höppner;,citation_editor=Arno Siebes;,citation_editor=Stephen Swift;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_conference_title=Advances in Intelligent Data Analysis XII;,citation_conference=Springer Berlin Heidelberg;">
<meta name="citation_reference" content="citation_title=Novelty detection algorithm for data streams multi-class problems;,citation_author=Elaine R Faria;,citation_author=João Gama;,citation_author=André CPLF Carvalho;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_conference_title=Proceedings of the 28th annual ACM symposium on applied computing;">
<meta name="citation_reference" content="citation_title=Turning Big Data into Tiny Data: Constant-Size Coresets for k-Means, PCA and Projective Clustering;,citation_author=Dan Feldman;,citation_author=Melanie Schmidt;,citation_author=Christian Sohler;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_conference_title=Proceedings of the Twenty-Fourth Annual ACM-SIAM Symposium on Discrete Algorithms;,citation_conference=Society for Industrial; Applied Mathematics;,citation_series_title=SODA ’13;">
<meta name="citation_reference" content="citation_title=On evaluating stream learning algorithms;,citation_author=João Gama;,citation_author=Raquel Sebastião;,citation_author=Pedro Pereira Rodrigues;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=3;,citation_volume=90;,citation_journal_title=Machine Learning;">
<meta name="citation_reference" content="citation_title=Scalable Strategies for Computing with Massive Data;,citation_author=Michael J. Kane;,citation_author=John Emerson;,citation_author=Stephen Weston;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=14;,citation_volume=55;,citation_journal_title=Journal of Statistical Software;">
<meta name="citation_reference" content="citation_title=RStorm: Simulate and Develop Streaming Processing in R;,citation_author=Maurits Kaptein;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;">
<meta name="citation_reference" content="citation_title=Drift detection using uncertainty distribution divergence;,citation_author=Patrick Lindstrom;,citation_author=Brian Mac Namee;,citation_author=Sarah Jane Delany;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=1;,citation_volume=4;,citation_journal_title=Evolving Systems;">
<meta name="citation_reference" content="citation_title=Ad Click Prediction: A View from the Trenches;,citation_author=H. Brendan McMahan;,citation_author=Gary Holt;,citation_author=D. Sculley;,citation_author=Michael Young;,citation_author=Dietmar Ebner;,citation_author=Julian Grady;,citation_author=Lan Nie;,citation_author=Todd Phillips;,citation_author=Eugene Davydov;,citation_author=Daniel Golovin;,citation_author=Sharat Chikkerur;,citation_author=Dan Liu;,citation_author=Martin Wattenberg;,citation_author=Arnar Mar Hrafnkelsson;,citation_author=Tom Boulos;,citation_author=Jeremy Kubica;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_conference_title=Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;,citation_conference=Association for Computing Machinery;,citation_series_title=KDD ’13;">
<meta name="citation_reference" content="citation_title=Data Stream Clustering: A Survey.;,citation_author=Jonathan A. Silva;,citation_author=Elaine R. Faria;,citation_author=Rodrigo C. Barros;,citation_author=Eduardo R. Hruschka;,citation_author=Andre Carvalho;,citation_author=Joao Gama;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=1;,citation_volume=46;,citation_journal_title=ACM Computer Surveys;">
<meta name="citation_reference" content="citation_title=ff: Memory-efficient Storage of Large Data on Disk and Fast Access Functions;,citation_author=Daniel Adler;,citation_author=Christian Gläser;,citation_author=Oleg Nenadic;,citation_author=Jens Oehlschlägel;,citation_author=Walter Zucchini;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=factas: Data Mining Methods for Data Streams;,citation_author=Romain Bar;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=streamR: Access to Twitter Streaming API via R;,citation_author=Pablo Barbera;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=DBI: R Database Interface;,citation_author=R Special Interest Group on Databases;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=Concept drift detection through resampling;,citation_author=Maayan Harel;,citation_author=Shie Mannor;,citation_author=Ran El-Yaniv;,citation_author=Koby Crammer;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_conference_title=International conference on machine learning;,citation_conference=PMLR;">
<meta name="citation_reference" content="citation_title=PCA feature extraction for change detection in multidimensional unlabeled data;,citation_author=Ludmila I Kuncheva;,citation_author=William J Faithfull;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=1;,citation_volume=25;,citation_journal_title=IEEE transactions on neural networks and learning systems;">
<meta name="citation_reference" content="citation_title=Mining of Massive Datasets;,citation_author=Jure Leskovec;,citation_author=Anand Rajaraman;,citation_author=Jeffery D. Ullman;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=RMOA: Connect R with MOA to perform streaming classifications;,citation_author=Jan Wijffels;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=A Survey on Concept Drift Adaptation;,citation_author=João Gama;,citation_author=Indrundefined Žliobaitundefined;,citation_author=Albert Bifet;,citation_author=Mykola Pechenizkiy;,citation_author=Abdelhamid Bouchachia;,citation_publication_date=2014-03;,citation_cover_date=2014-03;,citation_year=2014;,citation_issue=4;,citation_volume=46;,citation_journal_title=ACM Comput. Surv.;">
<meta name="citation_reference" content="citation_title=Graph Stream Algorithms: A Survey;,citation_author=Andrew McGregor;,citation_publication_date=2014-05;,citation_cover_date=2014-05;,citation_year=2014;,citation_issue=1;,citation_volume=43;,citation_journal_title=SIGMOD Rec.;">
<meta name="citation_reference" content="citation_title=RStorm: Developing and Testing Streaming Algorithms in R;,citation_author=Maurits Kaptein;,citation_publication_date=2014-06;,citation_cover_date=2014-06;,citation_year=2014;,citation_issue=1;,citation_volume=6;,citation_journal_title=The R Journal;">
<meta name="citation_reference" content="citation_title=SNAP Datasets: Stanford Large Network Dataset Collection;,citation_author=Jure Leskovec;,citation_author=Andrej Krevl;,citation_publication_date=2014-06;,citation_cover_date=2014-06;,citation_year=2014;,citation_publisher=http://snap.stanford.edu/data;">
<meta name="citation_reference" content="citation_title=Questioning the Lambda Architecture;,citation_author=Jay Kreps;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=Sketching as a Tool for Numerical Linear Algebra;,citation_author=David P. Woodruff;,citation_publication_date=2014-10;,citation_cover_date=2014-10;,citation_year=2014;,citation_issue=1–2;,citation_volume=10;,citation_journal_title=Found. Trends Theor. Comput. Sci.;">
<meta name="citation_reference" content="citation_title=Modeling concept drift: A probabilistic graphical model based approach;,citation_author=Hanen Borchani;,citation_author=Ana Maria Martinez;,citation_author=Andrés R. Masegosa;,citation_author=Helge Langseth;,citation_author=Thomas Dyhre Nielsen;,citation_author=Antonio Salmerón;,citation_author=Antonio Fernández;,citation_author=Anders Læsø Madsen;,citation_author=Ramón Sáez;,citation_editor=Elisa Fromont;,citation_editor=Tijl De Bie;,citation_editor=Matthijs Leeuwen;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=Advances in Intelligent Data Analysis XIV;,citation_conference=Springer;,citation_series_title=Lecture Notes in Computer Science;">
<meta name="citation_reference" content="citation_title=twitteR: R Based Twitter Client;,citation_author=Jeff Gentry;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=rEMM: Extensible Markov Model for Data Stream Clustering in R;,citation_author=Michael Hahsler;,citation_author=Margaret H. Dunham;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=streamMOA: Interface for MOA Stream Clustering Algorithms;,citation_author=Michael Hahsler;,citation_author=Matthew Bolanos;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=rstream: Streams of Random Numbers;,citation_author=Josef Leydold;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=Big Data: Principles and Best Practices of Scalable Realtime Data Systems;,citation_author=Nathan Marz;,citation_author=James Warren;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=A pca-based change detection framework for multidimensional data streams: Change detection in multidimensional data streams;,citation_author=Abdulhakim A Qahtan;,citation_author=Basma Alharbi;,citation_author=Suojin Wang;,citation_author=Xiangliang Zhang;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;">
<meta name="citation_reference" content="citation_title=Concept Drift Detection for Streaming Data;,citation_author=Heng Wang;,citation_author=Zubin Abraham;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=International Joint Conference on Neural Networks (IJCNN);">
<meta name="citation_reference" content="citation_title=koaning.io: Linear Models Solving Non-Linear Problems;,citation_author=Vincent Warmerdam;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=Experimental Algorithmics Applied to On-line Machine Learning;,citation_author=Thomas Bartz-Beielstein;,citation_editor=Gregor Papa;,citation_editor=Marjan Mernik;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_conference_title=Bioinspired Optimization Methods and their Applications;">
<meta name="citation_reference" content="citation_title=quantmod: Quantitative Financial Modelling Framework;,citation_author=Jeffrey A. Ryan;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;">
<meta name="citation_reference" content="citation_title=A grid density based framework for classifying streaming data in the presence of concept drift;,citation_author=Tegjyot Singh Sethi;,citation_author=Mehmed Kantardzic;,citation_author=Hanquing Hu;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_issue=1;,citation_volume=46;,citation_journal_title=Journal of Intelligent Information Systems;">
<meta name="citation_reference" content="citation_title=rJava: Low-level R to Java interface;,citation_author=Simon Urbanek;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;">
<meta name="citation_reference" content="citation_title=SparkR: Scaling R Programs with Spark;,citation_author=Shivaram Venkataraman;,citation_author=Zongheng Yang;,citation_author=Davies Liu;,citation_author=Eric Liang;,citation_author=Hossein Falaki;,citation_author=Xiangrui Meng;,citation_author=Reynold Xin;,citation_author=Ali Ghodsi;,citation_author=Michael Franklin;,citation_author=Ion Stoica;,citation_author=Matei Zaharia;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_conference_title=Proceedings of the 2016 International Conference on Management of Data;,citation_conference=Association for Computing Machinery;,citation_series_title=SIGMOD ’16;">
<meta name="citation_reference" content="citation_title=koaning.io: Bayesian/Streaming Algorithms;,citation_author=Vincent Warmerdam;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;">
<meta name="citation_reference" content="citation_title=Outlier Analysis;,citation_author=Charu C Aggarwal;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;">
<meta name="citation_reference" content="citation_title=Video Popularity Prediction in Data Streams Based on Context-Independent Features;,citation_author=Vitor Silva;,citation_author=Ana Trindade Winck;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_conference_title=Proceedings of the Symposium on Applied Computing;,citation_conference=Association for Computing Machinery;,citation_series_title=SAC ’17;">
<meta name="citation_reference" content="citation_title=Einsatz von Machine-Learning-Verfahren in amtlichen Unternehmensstatistiken;,citation_author=Florian Dumpert;,citation_author=Martin Beck;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=2;,citation_volume=11;,citation_journal_title=AStA Wirtschafts- und Sozialstatistisches Archiv;">
<meta name="citation_reference" content="citation_title=Introduction to stream: An Extensible Framework for Data Stream Clustering Research with R;,citation_author=Michael Hahsler;,citation_author=Matthew Bolaños;,citation_author=John Forrest;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=14;,citation_volume=76;,citation_journal_title=Journal of Statistical Software;">
<meta name="citation_reference" content="citation_title=stream: Infrastructure for Data Stream Mining;,citation_author=Michael Hahsler;,citation_author=Matthew Bolaños;,citation_author=John Forrest;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;">
<meta name="citation_reference" content="citation_title=Design and Analysis of Experiments;,citation_author=D C Montgomery;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;">
<meta name="citation_reference" content="citation_title=Time Series Forecasting in the Presence of Concept Drift: A PSO-based Approach;,citation_author=Gustavo H. F. M. Oliveira;,citation_author=Rodolfo C. Cavalcante;,citation_author=George G. Cabral;,citation_author=Leandro L. Minku;,citation_author=Adriano L. I. Oliveira;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_conference_title=2017 IEEE 29th International Conference on Tools with Artificial Intelligence (ICTAI);">
<meta name="citation_reference" content="citation_title=United Nations Global Pulse. Harnessing big data for development and humanitarian action.;,citation_author=United Nations;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;">
<meta name="citation_reference" content="citation_title=koaning.io: Passive Agressive Algorithms;,citation_author=Vincent Warmerdam;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;">
<meta name="citation_reference" content="citation_title=On the Reliable Detection of Concept Drift from Streaming Unlabeled Data;,citation_author=Tegjyot Singh Sethi;,citation_author=Mehmed Kantardzic;,citation_publication_date=2017-03;,citation_cover_date=2017-03;,citation_year=2017;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Proof of Concept Machine Learning - Abschlussbericht;,citation_author=Martin Beck;,citation_author=Florian Dumpert;,citation_author=Jörg Feuerhake;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_technical_report_institution=Statistisches Bundesamt (Destatis);">
<meta name="citation_reference" content="citation_title=Machine Learning for Data Streams with Practical Examples in MOA;,citation_author=Albert Bifet;,citation_author=Ricard Gavalda;,citation_author=Geoff Holmes;,citation_author=Bernhard Pfahringer;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;">
<meta name="citation_reference" content="citation_title=Lifelong Machine Learning;,citation_author=Zhiyuan Chen;,citation_author=Bing Liu;,citation_author=Ronald Brachman;,citation_author=Peter Stone;,citation_author=Francesca Rossi;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;">
<meta name="citation_reference" content="citation_title=Incremental on-line learning: A review and comparison of state of the art algorithms;,citation_author=Viktor Losing;,citation_author=Barbara Hammer;,citation_author=Heiko Wersing;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_volume=275;,citation_journal_title=Neurocomputing;">
<meta name="citation_reference" content="citation_title=Extremely Fast Decision Tree;,citation_author=Chaitanya Manapragada;,citation_author=Geoffrey I. Webb;,citation_author=Mahsa Salehi;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_conference_title=Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;,citation_conference=Association for Computing Machinery;,citation_series_title=KDD ’18;">
<meta name="citation_reference" content="citation_title=An evaluation of data stream clustering algorithms;,citation_author=Stratos Mansalis;,citation_author=Eirini Ntoutsi;,citation_author=Nikos Pelekis;,citation_author=Yannis Theodoridis;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=4;,citation_volume=11;,citation_journal_title=Statistical Analysis and Data Mining: The ASA Data Science Journal;">
<meta name="citation_reference" content="citation_title=koaning.io: How to win with simple, even linear, models;,citation_author=Vincent Warmerdam;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;">
<meta name="citation_reference" content="citation_title=Anomaly Detection in Manufacturing Systems Using Structured Neural Networks;,citation_author=J. Liu;,citation_author=J. Guo;,citation_author=P. V. Orlik;,citation_author=M. Shibata;,citation_author=D. Nakahara;,citation_author=S. Mii;,citation_author=M. Takac;,citation_publication_date=2018-07;,citation_cover_date=2018-07;,citation_year=2018;,citation_technical_report_institution=MITSUBISHI ELECTRIC RESEARCH LABORATORIES;">
<meta name="citation_reference" content="citation_title=Industrial Internet of Things Based Ransomware Detection Using Stacked Variational Neural Network;,citation_author=Muna Al-Hawawreh;,citation_author=Elena Sitnikova;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_conference_title=Proceedings of the 3rd International Conference on Big Data and Internet of Things;,citation_conference=Association for Computing Machinery;,citation_series_title=BDIOT 2019;">
<meta name="citation_reference" content="citation_title=Evaluation of Cognitive Architectures for Cyber-Physical Production Systems;,citation_author=Andreas Bunte;,citation_author=Andreas Fischbach;,citation_author=Jan Strohschein;,citation_author=Thomas Bartz-Beielstein;,citation_author=Heide Faeskorn-Woyke;,citation_author=Oliver Niggemann;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_conference_title=24th IEEE International Conference on Emerging Technologies and Factory Automation, ETFA 2019, Zaragoza, Spain, September 10-13, 2019;">
<meta name="citation_reference" content="citation_title=Nowcasting: Ein Echtzeit-Indikator für die Konjunkturanalyse;,citation_author=Charlotte Senftleben;,citation_author=Till Strohsal;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;">
<meta name="citation_reference" content="citation_title=koaning.io: The Future of Data Science is Past;,citation_author=Vincent Warmerdam;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;">
<meta name="citation_reference" content="citation_title=Forecasting inflation with online prices;,citation_author=Diego Aparicio;,citation_author=Manuel I. Bertolotto;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_issue=2;,citation_volume=36;,citation_journal_title=International Journal of Forecasting;">
<meta name="citation_reference" content="citation_title=CAAI—a cognitive architecture to introduce artificial intelligence in cyber-physical production systems;,citation_author=Andreas Fischbach;,citation_author=Jan Strohschein;,citation_author=Andreas Bunte;,citation_author=Jörg Stork;,citation_author=Heide Faeskorn-Woyke;,citation_author=Natalia Moriz;,citation_author=Thomas Bartz-Beielstein;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_issue=1;,citation_volume=111;,citation_journal_title=The International Journal of Advanced Manufacturing Technology;">
<meta name="citation_reference" content="citation_title=Delayed labelling evaluation for data streams;,citation_author=Maciej Grzenda;,citation_author=Heitor Murilo Gomes;,citation_author=Albert Bifet;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_issue=5;,citation_volume=34;,citation_journal_title=Data Mining and Knowledge Discovery;">
<meta name="citation_reference" content="citation_title=Stream Data Mining: Algorithms and Their Probabilistic Properties;,citation_editor=Leszek Rutkowski;,citation_editor=Maciej Jaworski;,citation_editor=Piotr Duda;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_series_title=Studies in Big Data;">
<meta name="citation_reference" content="citation_title=Loghub: A Large Collection of System Log Datasets towards Automated Log Analytics;,citation_author=Shilin He;,citation_author=Jieming Zhu;,citation_author=Pinjia He;,citation_author=Michael R. Lyu;,citation_publication_date=2020-08;,citation_cover_date=2020-08;,citation_year=2020;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Nowcasting German GDP: Foreign factors, financial markets, and model averaging;,citation_author=Paolo Andreini;,citation_author=Thomas Hasenzagl;,citation_author=Lucrezia Reichlin;,citation_author=Charlotte Senftleben-König;,citation_author=Till Strohsal;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_journal_title=International Journal of Forecasting;">
<meta name="citation_reference" content="citation_title=Modelling the COVID-19 Virus Evolution With Incremental Machine Learning;,citation_author=Andrés L. Suárez-Cetrulo;,citation_author=Ankit Kumar;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;">
<meta name="citation_reference" content="citation_title=Machine Learning for Time-Series with Python: Forecast, predict, and detect;,citation_author=Den Auffarth;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;">
<meta name="citation_reference" content="citation_title=Machine Learning in der amtlichen Statistik - Ergebnisse und Bewertung eines internationalen Projekts;,citation_author=Florian Dumpert;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_technical_report_institution=Statistisches Bundesamt (Destatis);,citation_technical_report_number=4;">
<meta name="citation_reference" content="citation_title=Recurring concept memory management in data streams: exploiting data stream concept evolution to improve performance and transparency;,citation_author=Ben Halstead;,citation_author=Yun Sing Koh;,citation_author=Patricia Riddle;,citation_author=Russel Pears;,citation_author=Mykola Pechenizkiy;,citation_author=Albert Bifet;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_issue=3;,citation_volume=35;,citation_journal_title=Data Mining and Knowledge Discovery;">
<meta name="citation_reference" content="citation_title=Soziale Marktwirtschaft in der digitalen Zukunft: Foresight-Bericht Strategischer Vorausschauprozess des BMWi;,citation_author=Dirk Holtmannspötter;,citation_author=Ulrich Heimeshoff;,citation_author=Justus Haucap;,citation_author=Ina Loebert;,citation_author=Christoph Busch;,citation_author=Andreas Hoffknecht;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_technical_report_institution=VDI Technologiezentrum GmbH im Auftrag des Bundesministerium für Wirtschaft und Energie;">
<meta name="citation_reference" content="citation_title=River: machine learning for streaming data in Python;,citation_author=Jacob Montiel;,citation_author=Max Halford;,citation_author=Saulo Martiello Mastelini;,citation_author=Geoffrey Bolmier;,citation_author=Raphael Sourty;,citation_author=Robin Vaysse;,citation_author=Adil Zouitine;,citation_author=Heitor Murilo Gomes;,citation_author=Jesse Read;,citation_author=Talel Abdessalem;,citation_author=others;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;">
<meta name="citation_reference" content="citation_title=Practical Machine Learning for Streaming Data with Python;,citation_author=Sayan Putatunda;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;">
<meta name="citation_reference" content="citation_title=Infrerring Concept Drift Without Labeled Data;,citation_author=Andrew Reed;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_technical_report_institution=Cloudera Fast Forward Labs;,citation_technical_report_number=FF21;">
<meta name="citation_reference" content="citation_title=Cognitive capabilities for the CAAI in cyber-physical production systems;,citation_author=Jan Strohschein;,citation_author=Andreas Fischbach;,citation_author=Andreas Bunte;,citation_author=Heide Faeskorn-Woyke;,citation_author=Natalia Moriz;,citation_author=Thomas Bartz-Beielstein;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_journal_title=The International Journal of Advanced Manufacturing Technology;">
<meta name="citation_reference" content="citation_title=FARF: A Fair and Adaptive Random Forests Classifier;,citation_author=Wenbin Zhang;,citation_author=Albert Bifet;,citation_author=Xiangliang Zhang;,citation_author=Jeremy C. Weiss;,citation_author=Wolfgang Nejdl;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_conference_title=Advances in Knowledge Discovery and Data Mining: 25th Pacific-Asia Conference, PAKDD 2021, Virtual Event, May 11–14, 2021, Proceedings, Part II;,citation_conference=Springer-Verlag;">
<meta name="citation_reference" content="citation_title=Modelling the COVID-19 virus evolution with Incremental Machine Learning;,citation_author=Andrés L. Suárez-Cetrulo;,citation_author=Ankit Kumar;,citation_author=Luis Miralles-Pechuán;,citation_publication_date=2021-04;,citation_cover_date=2021-04;,citation_year=2021;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Online Learning and Active Learning: A Comparative Study of Passive-Aggressive Algorithm With Support Vector Machine (SVM);,citation_author=K. I Ezukwoke;,citation_author=S. J Zareian;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_issue=3;,citation_volume=21;,citation_journal_title=Journal of Higher Education Theory and Practice;">
<meta name="citation_reference" content="citation_title=Digitale Ordnungspolitik – Wirtschaftspolitik daten- und evidenzbasiert weiterentwickeln;,citation_author=Philipp Steinberg;,citation_author=Nils Börnsen;,citation_author=Dirk Neumann;,citation_publication_date=2021-09;,citation_cover_date=2021-09;,citation_year=2021;,citation_publisher=Wirtschaftsdienst;">
<meta name="citation_reference" content="citation_title=Incremental Unsupervised Domain-Adversarial Training of Neural Networks;,citation_author=Antonio-Javier Gallego;,citation_author=Jorge Calvo-Zaragoza;,citation_author=Robert B. Fisher;,citation_publication_date=2021-11;,citation_cover_date=2021-11;,citation_year=2021;,citation_issue=11;,citation_volume=32;,citation_journal_title=IEEE Transactions on Neural Networks and Learning Systems;">
<meta name="citation_reference" content="citation_title=Incremental learning for property price estimation using location-based services and open data;,citation_author=Francisco Alvarez;,citation_author=Edgar Roman-Rangel;,citation_author=Luis V. Montiel;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_volume=107;,citation_journal_title=Engineering Applications of Artificial Intelligence;">
<meta name="citation_reference" content="citation_title=Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide;,citation_editor=Eva Bartz;,citation_editor=Thomas Bartz-Beielstein;,citation_editor=Martin Zaefferer;,citation_editor=Olaf Mersmann;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=Interpretable Machine Learning: Moving from Mythos to Diagnostics;,citation_author=Valerie Chen;,citation_author=Jeffrey Li;,citation_author=Joon Sik Kim;,citation_author=Gregory Plumb;,citation_author=Ameet Talwalkar;,citation_publication_date=2022-01;,citation_cover_date=2022-01;,citation_year=2022;,citation_issue=6;,citation_volume=19;,citation_journal_title=Queue;">
<meta name="citation_reference" content="citation_title=Online Time-series Anomaly Detection: A Survey of Modern Model-based Approaches;,citation_author=Lucas Correia;,citation_author=Jan-Christoph Goos;,citation_author=Anna V. Kononova;,citation_author=Thomas Bäck;,citation_author=Philipp Klein;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_technical_report_institution=Mercedes-Benz, Germany;">
<meta name="citation_reference" content="citation_title=Green Accelerated Hoeffding Tree;,citation_author=Eva Garcia-Martin;,citation_author=Albert Bifet;,citation_author=Niklas Lavesson;,citation_author=Rikard König;,citation_author=Henrik Linusson;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=Monitoring the Economy in Real Time: Trends and Gaps in Real Activity and Prices;,citation_author=Thomas Hasenzagl;,citation_author=Filippo Pellegrino;,citation_author=Lucrezia Reichlin;,citation_author=Giovanni Ricco;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=Efficiently Correcting Machine Learning: Considering the Role of Example Ordering in Human-in-the-Loop Training of Image Classification Models;,citation_author=Geoff Holmes;,citation_author=Eibe Frank;,citation_author=Dale Fletcher;,citation_author=Corey Sterling;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_conference_title=27th International Conference on Intelligent User Interfaces;,citation_conference=Association for Computing Machinery;,citation_series_title=IUI ’22;">
<meta name="citation_reference" content="citation_title=TemporalWiki: A Lifelong Benchmark for Training and Evaluating Ever-Evolving Language Models;,citation_author=Joel Jang;,citation_author=Seonghyeon Ye;,citation_author=Changho Lee;,citation_author=Sohee Yang;,citation_author=Joongbo Shin;,citation_author=Janghoon Han;,citation_author=Gyeonghun Kim;,citation_author=Minjoon Seo;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=Fast Mining and Forecasting of Co-Evolving Epidemiological Data Streams;,citation_author=Tasuku Kimura;,citation_author=Yasuko Matsubara;,citation_author=Koki Kawabata;,citation_author=Yasushi Sakurai;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_conference_title=Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining;,citation_conference=Association for Computing Machinery;,citation_series_title=KDD ’22;">
<meta name="citation_reference" content="citation_title=Maschine Learning for Streaming Data with Python;,citation_author=Jan Korstanje;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=The Disagreement Problem in Explainable Machine Learning: A Practitioner’s Perspective;,citation_author=Satyapriya Krishna;,citation_author=Tessa Han;,citation_author=Alex Gu;,citation_author=Javin Pombra;,citation_author=Shahin Jabbari;,citation_author=Steven Wu;,citation_author=Himabindu Lakkaraju;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=SparkR: R Front End for ’Apache Spark’;,citation_author=The Apache Software Foundation;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=Short-term local predictions of COVID-19 in the United Kingdom using dynamic supervised machine learning algorithms;,citation_author=Xin Wang;,citation_author=Yijia Dong;,citation_author=William David Thompson;,citation_author=Harish Nair;,citation_author=You Li;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_issue=1;,citation_volume=2;,citation_journal_title=Communications Medicine;">
<meta name="citation_reference" content="citation_title=Log-based Anomaly Detection with Deep Learning: How Far Are We?;,citation_author=Van-Hoang Le;,citation_author=Hongyu Zhang;,citation_publication_date=2022-02;,citation_cover_date=2022-02;,citation_year=2022;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Reliance on metrics is a fundamental challenge for AI.;,citation_author=Rachel L Thomas;,citation_author=David Uminsky;,citation_publication_date=2022-05;,citation_cover_date=2022-05;,citation_year=2022;,citation_issue=5;,citation_volume=3;,citation_journal_title=Patterns (N Y);">
<meta name="citation_reference" content="citation_title=SMRD.de Benutzerhandbuch;,citation_author=Niyaz Valitov;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_technical_report_institution=Bundesnetzagentur für Elektrizität, Gas, Telekommunikation, Post und Eisenbahnen;">
<meta name="citation_reference" content="citation_title=Use of web scraping and text mining techniques in the Istat survey on “Information and Communication Technology in enterprises”;,citation_author=G. Barcaroli;,citation_author=A. Nurra;,citation_author=M. Scarnò;,citation_author=D. Summa;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=Who Makes Mistakes? Using Data Mining Techniques to Analyze Reporting Errors in Total Acres Operated;,citation_author=Jaki S. McCarthy;,citation_author=Morgan S. Earp;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_fulltext_html_url=https://ideas.repec.org/p/ags/unasrr/234367.html;,citation_doi=10.22004/AG.ECON.234367;,citation_journal_title=NASS Research Reports;,citation_publisher=United States Department of Agriculture, National Agricultural Statistics Service;">
<meta name="citation_reference" content="citation_title=Modeling Non-response in National Agricultural Statistics Service (NASS) Surveys Using Classification Trees;,citation_author=Jaki S Mccarthy;,citation_author=Thomas Jacob;,citation_author=Amanda Mccracken;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;">
<meta name="citation_reference" content="citation_title=2007 Census of Agriculture Non-Response Methodology;,citation_author=Will Cecere;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;">
<meta name="citation_reference" content="citation_title=Exploring Quarterly Agricultural Survey Questionnaire Version Reduction Scenarios;,citation_author=Morgan Earp;,citation_author=Scott Cox;,citation_author=Jody Mcdaniel;,citation_author=Chadd Crouse;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;">
<meta name="citation_reference" content="citation_title=USE OF MACHINE LEARNING METHODS TO IMPUTE CATEGORICAL DATA;,citation_author=P. Rey;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;">
<meta name="citation_reference" content="citation_title=Innovative Uses of Data Mining Techniques in the Production of Official Statistics;,citation_author=Jaki Mccarthy;,citation_author=Thomas Jacob;,citation_author=Dale Atkinson;">
<meta name="citation_reference" content="citation_title=Automatic Coding of Occupations. Using Machine Learning Algorithms for Occupation Coding in Several German Panel Surveys;,citation_fulltext_html_url=https://www.researchgate.net/publication/266259591_Automatic_Coding_of_Occupations_Using_Machine_Learning_Algorithms_for_Occupation_Coding_in_Several_German_Panel_Surveys;">
<meta name="citation_reference" content="citation_title=Evaluating hourly air quality forecasting in Canada with nonlinear updatable machine learning methods;,citation_author=Huiping Peng;,citation_author=Aranildo R. Lima;,citation_author=Andrew Teakles;,citation_author=Jian Jin;,citation_author=Alex J. Cannon;,citation_author=William W. Hsieh;,citation_publication_date=2017-03-01;,citation_cover_date=2017-03-01;,citation_year=2017;,citation_fulltext_html_url=https://doi.org/10.1007/s11869-016-0414-3;,citation_issue=2;,citation_doi=10.1007/s11869-016-0414-3;,citation_issn=1873-9326;,citation_volume=10;,citation_journal_title=Air Quality, Atmosphere &amp;amp;amp; Health;">
<meta name="citation_reference" content="citation_title=Online Machine Learning in Big Data Streams;,citation_author=András A. Benczúr;,citation_author=Levente Kocsis;,citation_author=Róbert Pálovics;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_fulltext_html_url=http://arxiv.org/abs/1802.05872;,citation_volume=abs/1802.05872;,citation_journal_title=CoRR;">
<meta name="citation_reference" content="citation_title=Learn: A Novel incremental learning method for text classification;,citation_author=Guangxu Shan;,citation_author=Shiyao Xu;,citation_author=Li Yang;,citation_author=Shengbin Jia;,citation_author=Yang Xiang;,citation_publication_date=2020-06;,citation_cover_date=2020-06;,citation_year=2020;,citation_doi=10.1016/J.ESWA.2020.113198;,citation_issn=0957-4174;,citation_volume=147;,citation_journal_title=Expert Systems with Applications;,citation_publisher=Pergamon;">
<meta name="citation_reference" content="citation_title=Incremental Real-Time Learning Framework for Sentiment Classification: Indian General Election 2019, A Case Study;,citation_author=Sharmistha Chatterjee;,citation_author=Sushmita Gupta;,citation_publication_date=2021-03;,citation_cover_date=2021-03;,citation_year=2021;,citation_doi=10.1109/ICBDA51983.2021.9402992;,citation_isbn=9780738131672;,citation_journal_title=2021 IEEE 6th International Conference on Big Data Analytics, ICBDA 2021;,citation_publisher=Institute of Electrical; Electronics Engineers Inc.;">
<meta name="citation_reference" content="citation_title=MOA: Massive Online Analysis;,citation_abstract=Massive Online Analysis (MOA) is a software environment for implementing algorithms and running experiments for online learning from evolving data streams. MOA includes a collection of offline and online methods as well as tools for evaluation. In particular, it implements boosting, bagging, and Hoeffding Trees, all with and without Na¨ıveNa¨ıve Bayes classifiers at the leaves. MOA supports bi-directional interaction with WEKA, the Waikato Environment for Knowledge Analysis , and is released under the GNU GPL license.;,citation_author=Albert Bifet;,citation_author=Geoff Holmes;,citation_author=Richard Kirkby;,citation_author=Bernhard Pfahringer;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_volume=11;,citation_journal_title=Journal of Machine Learning Research;">
<meta name="citation_reference" content="citation_title=Evaluation and Performance Measurement;,citation_author=Thomas Bartz-Beielstein;,citation_editor=Eva Bartz;,citation_editor=Thomas Bartz-Beielstein;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_inbook_title=undefined;">
<meta name="citation_reference" content="citation_title=Hyperparameter Tuning;,citation_author=Thomas Bartz-Beielstein;,citation_editor=Eva Bartz;,citation_editor=Thomas Bartz-Beielstein;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_inbook_title=undefined;">
<meta name="citation_reference" content="citation_title=Hyperparameter Tuning Approaches;,citation_author=Thomas Bartz-Beielstein;,citation_author=Martin Zaefferer;,citation_editor=Eva Bartz;,citation_editor=Thomas Bartz-Beielstein;,citation_editor=Martin Zaefferer;,citation_editor=Olaf Mersmann;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_inbook_title=Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide;">
<meta name="citation_reference" content="citation_title=Drift Detection and&nbsp;Handling;,citation_abstract=Structural changes (“drift”) in the data cause problems for many algorithms. Based on the drift definitions given in Chap. 1, methods for drift detection and handling are discussed. For the algorithms presented in Chap. 2, it is clarified to what extent concept drift is reacted to. In turn, the extent to which catastrophic forgetting is an issue is described in Sect. 4.3. Section&nbsp;3.1 describes three architectures for implementing drift detection algorithms. Basic properties of window-based approaches are presented in Sect.&nbsp;3.2. Section&nbsp;3.4 presents commonly used drift detection techniques. Section&nbsp;3.4 describes how the drift detection techniques introduced in Sect.&nbsp;3.3 are used in Online Machine Learning (OML) algorithms and summarizes the tree-based OML techniques implemented in the River package. Section&nbsp;3.5 introduces scaling methods for handling drift.;,citation_author=Thomas Bartz-Beielstein;,citation_author=Lukas Hans;,citation_editor=Eva Bartz;,citation_editor=Thomas Bartz-Beielstein;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://doi.org/10.1007/978-981-99-7007-0_3;,citation_doi=10.1007/978-981-99-7007-0_3;,citation_isbn=978-981-99-7007-0;,citation_inbook_title=Online Machine Learning: A Practical Guide with Examples in Python;">
<meta name="citation_reference" content="citation_title=Introduction: From Batch to&nbsp;Online Machine Learning;,citation_abstract=Batch Machine Learning (BML), which is also referred to as “offline machine learning”, reaches its limits when dealing with very large amounts of data. This is especially true for available memory, handling drift in data streams, and processing new, unknown data. Online Machine Learning (OML) is an alternative to BML that overcomes the limitations of BML. In this chapter, the basic terms and concepts of OML are introduced and the differences to BML are shown.;,citation_author=Thomas Bartz-Beielstein;,citation_editor=Eva Bartz;,citation_editor=Thomas Bartz-Beielstein;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://doi.org/10.1007/978-981-99-7007-0_1;,citation_doi=10.1007/978-981-99-7007-0_1;,citation_isbn=978-981-99-7007-0;,citation_inbook_title=Online Machine Learning: A Practical Guide with Examples in Python;">
<meta name="citation_reference" content="citation_title=AMF: Aggregated Mondrian Forests for Online Learning;,citation_author=Jaouad Mourtada;,citation_author=Stephane Gaiffas;,citation_author=Erwan Scornet;,citation_publication_date=2019-06;,citation_cover_date=2019-06;,citation_year=2019;,citation_fulltext_html_url=https://arxiv.org/abs/1906.10529;,citation_doi=10.48550/arXiv.1906.10529;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Extremely fast decision tree;,citation_abstract=We introduce a novel incremental decision tree learning algorithm, Hoeffding Anytime Tree, that is statistically more efficient than the current state-of-the-art, Hoeffding Tree. We demonstrate that an implementation of Hoeffding Anytime Tree’“Extremely Fast Decision Tree”, a minor modification to the MOA implementation of Hoeffding Tree’obtains significantly superior prequential accuracy on most of the largest classification datasets from the UCI repository. Hoeffding Anytime Tree produces the asymptotic batch tree in the limit, is naturally resilient to concept drift, and can be used as a higher accuracy replacement for Hoeffding Tree in most scenarios, at a small additional computational cost.;,citation_author=Chaitanya Manapragada;,citation_author=Geoffrey I. Webb;,citation_author=Mahsa Salehi;,citation_editor=Chih-Jen  Lin;,citation_editor=Hui  Xiong;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_fulltext_html_url=http://www.kdd.org/kdd2018/, https://dl.acm.org/doi/proceedings/10.1145/3219819;,citation_doi=10.1145/3219819.3220005;,citation_conference_title=KDD’ 2018 - Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;,citation_conference=Association for Computing Machinery (ACM);">
<meta name="citation_reference" content="citation_title=Surrogates;,citation_author=Robert B Gramacy;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;">
<meta name="citation_reference" content="citation_title=UvA Deep Learning Tutorials;,citation_author=Phillip Lippe;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://github.com/phlippe/uvadlc_notebooks/tree/master;">
<meta name="citation_reference" content="citation_title=Attention Is All You Need;,citation_author=Ashish Vaswani;,citation_author=Noam Shazeer;,citation_author=Niki Parmar;,citation_author=Jakob Uszkoreit;,citation_author=Llion Jones;,citation_author=Aidan N. Gomez;,citation_author=Lukasz Kaiser;,citation_author=Illia Polosukhin;,citation_publication_date=2017-06;,citation_cover_date=2017-06;,citation_year=2017;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=On the Variance of the Adaptive Learning Rate and Beyond;,citation_author=Liyuan Liu;,citation_author=Haoming Jiang;,citation_author=Pengcheng He;,citation_author=Weizhu Chen;,citation_author=Xiaodong Liu;,citation_author=Jianfeng Gao;,citation_author=Jiawei Han;,citation_publication_date=2019-08;,citation_cover_date=2019-08;,citation_year=2019;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Efficient Transformers: A Survey;,citation_author=Yi Tay;,citation_author=Mostafa Dehghani;,citation_author=Dara Bahri;,citation_author=Donald Metzler;,citation_publication_date=2020-09;,citation_cover_date=2020-09;,citation_year=2020;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding;,citation_author=Jacob Devlin;,citation_author=Ming-Wei Chang;,citation_author=Kenton Lee;,citation_author=Kristina Toutanova;,citation_publication_date=2018-10;,citation_cover_date=2018-10;,citation_year=2018;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale;,citation_author=Alexey Dosovitskiy;,citation_author=Lucas Beyer;,citation_author=Alexander Kolesnikov;,citation_author=Dirk Weissenborn;,citation_author=Xiaohua Zhai;,citation_author=Thomas Unterthiner;,citation_author=Mostafa Dehghani;,citation_author=Matthias Minderer;,citation_author=Georg Heigold;,citation_author=Sylvain Gelly;,citation_author=Jakob Uszkoreit;,citation_author=Neil Houlsby;,citation_publication_date=2020-10;,citation_cover_date=2020-10;,citation_year=2020;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Attention is not Explanation;,citation_author=Sarthak Jain;,citation_author=Byron C. Wallace;,citation_publication_date=2019-02;,citation_cover_date=2019-02;,citation_year=2019;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Attention is not not Explanation;,citation_author=Sarah Wiegreffe;,citation_author=Yuval Pinter;,citation_publication_date=2019-08;,citation_cover_date=2019-08;,citation_year=2019;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Multivariate adaptive regression splines;,citation_author=Jerome H. Friedman;,citation_publication_date=1991;,citation_cover_date=1991;,citation_year=1991;,citation_issue=1;,citation_volume=19;,citation_journal_title=The annals of statistics;">
<meta name="citation_reference" content="citation_title=Learning model trees from evolving data streams;,citation_author=Elena Ikonomovska;,citation_author=João Gama;,citation_author=Sašo Džeroski;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=1;,citation_volume=23;,citation_journal_title=Data Mining and Knowledge Discovery;">
<meta name="citation_reference" content="citation_title=An Introduction to Statistical Learning with Applications in R;,citation_author=Gareth James;,citation_author=Daniela Witten;,citation_author=Trevor Hastie;,citation_author=Robert Tibshirani;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=Deep Learning with Python;,citation_author=Francoise Chollet;,citation_author=J. J. Allaire;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;">
<meta name="citation_reference" content="citation_title=A survey of cross-validation procedures for model selection;,citation_author=Sylvain Arlot;,citation_author=Alain Celisse;,citation_author=others;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_volume=4;,citation_journal_title=Statistics surveys;">
<meta name="citation_reference" content="citation_title=A cross-validatory method for dependent data;,citation_author=PRABIR BURMAN;,citation_author=EDMOND CHOW;,citation_author=DEBORAH NOLAN;,citation_publication_date=1994;,citation_cover_date=1994;,citation_year=1994;,citation_issue=2;,citation_volume=81;,citation_journal_title=Biometrika;">
<meta name="citation_reference" content="citation_title=A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection;,citation_author=Ron Kohavi;,citation_publication_date=1995;,citation_cover_date=1995;,citation_year=1995;,citation_conference_title=Proceedings of the 14th International Joint Conference on Artificial Intelligence - Volume 2;,citation_conference=Morgan Kaufmann Publishers Inc.;,citation_series_title=IJCAI’95;">
<meta name="citation_reference" content="citation_title=Kriging-based sequential design strategies using fast cross-validation techniques with extensions to multi-fidelity computer codes ;,citation_author=Loic Le Gratiet;,citation_author=Claire Cannamela;,citation_publication_date=2012-10;,citation_cover_date=2012-10;,citation_year=2012;">
<meta name="citation_reference" content="citation_title=Cross-Validation of Regression Models;,citation_author=Richard R. Picard;,citation_author=R. Dennis Cook;,citation_publication_date=1984;,citation_cover_date=1984;,citation_year=1984;,citation_issue=387;,citation_volume=79;,citation_journal_title=Journal of the American Statistical Association;">
<meta name="citation_reference" content="citation_title=The Elements of Statistical Learning;,citation_author=Trevor Hastie;,citation_author=Robert Tibshirani;,citation_author=Jerome Friedman;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;">
<meta name="citation_reference" content="citation_title=Deep Residual Learning for Image Recognition;,citation_author=Kaiming He;,citation_author=Xiangyu Zhang;,citation_author=Shaoqing Ren;,citation_author=Jian Sun;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=Identity Mappings in Deep Residual Networks;,citation_author=Kaiming He;,citation_author=Xiangyu Zhang;,citation_author=Shaoqing Ren;,citation_author=Jian Sun;,citation_publication_date=2016-03;,citation_cover_date=2016-03;,citation_year=2016;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Neural Ordinary Differential Equations;,citation_author=Ricky T. Q. Chen;,citation_author=Yulia Rubanova;,citation_author=Jesse Bettencourt;,citation_author=David Duvenaud;,citation_publication_date=2018-06;,citation_cover_date=2018-06;,citation_year=2018;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Mathematical Theory of Optimal Processes;,citation_author=undefined Pontryagin;,citation_publication_date=1987;,citation_cover_date=1987;,citation_year=1987;">
<meta name="citation_reference" content="citation_title=On Neural Differential Equations;,citation_author=Patrick Kidger;,citation_publication_date=2022-02;,citation_cover_date=2022-02;,citation_year=2022;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Stochastic simulation optimization: an optimal computing budget allocation;,citation_author=Chun Hung Chen;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;">
<meta name="citation_reference" content="citation_title=Sequential Parameter Optimization and Optimal Computational Budget Allocation for Noisy Optimization Problems;,citation_author=Thomas Bartz-Beielstein;,citation_author=Martina Friese;,citation_publication_date=2011-01;,citation_cover_date=2011-01;,citation_year=2011;">
<meta name="citation_reference" content="citation_title=Statistik;,citation_author=Joachim Hartung;,citation_author=Bärbel Elpert;,citation_author=Karl-Heinz Klösener;,citation_publication_date=1995;,citation_cover_date=1995;,citation_year=1995;">
<meta name="citation_reference" content="citation_title=Partial correlation — Wikipedia, The Free Encyclopedia;,citation_author=Wikipedia contributors;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://en.wikipedia.org/w/index.php?title=Partial_correlation&amp;amp;amp;oldid=1253637419;">
<meta name="citation_reference" content="citation_title=Understanding Correlation;,citation_author=R. J. Rummel;,citation_publication_date=1976;,citation_cover_date=1976;,citation_year=1976;,citation_fulltext_html_url=https://www.hawaii.edu/powerkills/UC.HTM;">
<meta name="citation_reference" content="citation_title=Two Postestimation Commands for Assessing Confounding Effects in Epidemiological Studies;,citation_author=Zhiqiang Wang;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=2;,citation_volume=7;,citation_journal_title=The Stata Journal;">
<meta name="citation_reference" content="citation_title=Response surface methodology: process and product optimization using designed experiments;,citation_author=Raymond H Myers;,citation_author=Douglas C Montgomery;,citation_author=Christine M Anderson-Cook;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;">
<meta name="citation_reference" content="citation_title=desirability: Function Optimization and Ranking via Desirability Functions;,citation_author=Max Kuhn;,citation_publication_date=2016-09;,citation_cover_date=2016-09;,citation_year=2016;">
<meta name="citation_reference" content="citation_title=Noisy optimization with sequential parameter optimization and optimal computational budget allocation;,citation_author=Thomas Bartz-Beielstein;,citation_author=Martina Friese;,citation_author=Martin Zaefferer;,citation_author=Boris Naujoks;,citation_author=Oliver Flasch;,citation_author=Wolfgang Konen;,citation_author=Patrick Koch;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_conference_title=Proceedings of the 13th annual conference companion on Genetic and evolutionary computation;,citation_conference=ACM;">
<meta name="citation_reference" content="citation_title=Stochastic simulation optimization: an optimal computing budget allocation;,citation_author=Chun Hung Chen;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;">
<meta name="citation_reference" content="citation_title=Generalized Simulated Annealing for Function Optimization;,citation_author=I O Bohachevsky;,citation_publication_date=1986;,citation_cover_date=1986;,citation_year=1986;,citation_issue=3;,citation_volume=28;,citation_journal_title=Technometrics;">
<meta name="citation_reference" content="citation_title=On the Experimental Attainment of Optimum Conditions;,citation_author=G. E. P. Box;,citation_author=K. B. Wilson;,citation_publication_date=1951;,citation_cover_date=1951;,citation_year=1951;,citation_issue=1;,citation_volume=13;,citation_journal_title=Journal of the Royal Statistical Society. Series B (Methodological);">
<meta name="citation_reference" content="citation_title=Design and Analysis of Experiments;,citation_author=D C Montgomery;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;">
<meta name="citation_reference" content="citation_title=Empirical Design of Geometric Algorithms;,citation_author=Karsten Weihe;,citation_author=Ulrik Brandes;,citation_author=Annegret Liebers;,citation_author=Matthias Mı̈ Hannemann;,citation_author=Dorothea Wagner;,citation_author=Thomas Willhalm;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_conference_title=SCG ’99: Proceedings of the Fifteenth Annual Symposium on Computational Geometry;,citation_conference=Association for Computing Machinery;">
<meta name="citation_reference" content="citation_title=Hyperparameter optimization: Foundations, algorithms, best practices, and open challenges;,citation_author=Bernd Bischl;,citation_author=Martin Binder;,citation_author=Michel Lang;,citation_author=Tobias Pielok;,citation_author=Jakob Richter;,citation_author=Stefan Coors;,citation_author=Janek Thomas;,citation_author=Theresa Ullmann;,citation_author=Marc Becker;,citation_author=Anne-Laure Boulesteix;,citation_author=Difan Deng;,citation_author=Marius Lindauer;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_issue=2;,citation_volume=13;,citation_journal_title=WIREs Data Mining and Knowledge Discovery;">
<meta name="citation_reference" content="citation_title=Multi-Factor Experimental Designs for Exploring Response Surfaces;,citation_author=G. E. P. Box;,citation_author=J. S. Hunter;,citation_publication_date=1957;,citation_cover_date=1957;,citation_year=1957;,citation_issue=1;,citation_volume=28;,citation_journal_title=The Annals of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Multi-Objective Evolutionary Algorithms: Past, Present, and Future;,citation_author=Carlos A. Coello Coello;,citation_author=Silvia González Brambila;,citation_author=Josué Figueroa Gamboa;,citation_author=Ma. Guadalupe Castillo Tapia;,citation_editor=Panos M. Pardalos;,citation_editor=Varvara Rasskazova;,citation_editor=Michael N. Vrahatis;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_inbook_title=undefined;">
<meta name="citation_reference" content="citation_title=Modified Desirability Functions for Multiple Response Optimization;,citation_author=E. Del Castillo;,citation_author=D. C. Montgomery;,citation_author=D. R. McCarville;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_volume=28;,citation_journal_title=Journal of Quality Technology;">
<meta name="citation_reference" content="citation_title=Simultaneous Optimization of Several Response Variables;,citation_author=G. Derringer;,citation_author=R. Suich;,citation_publication_date=1980;,citation_cover_date=1980;,citation_year=1980;,citation_volume=12;,citation_journal_title=Journal of Quality Technology;">
<meta name="citation_reference" content="citation_title=A tutorial on multiobjective optimization: fundamentals and evolutionary methods;,citation_author=Michael T. M. Emmerich;,citation_author=AndréH. Deutz;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=3;,citation_volume=17;,citation_journal_title=Natural Computing;">
<meta name="citation_reference" content="citation_title=The Desirability Function;,citation_author=J Harington;,citation_publication_date=1965;,citation_cover_date=1965;,citation_year=1965;,citation_volume=21;,citation_journal_title=Industrial Quality Control;">
<meta name="citation_reference" content="citation_title=Multi-Objective Hyperparameter Optimization in Machine Learning—An Overview;,citation_author=Florian Karl;,citation_author=Tobias Pielok;,citation_author=Julia Moosbauer;,citation_author=Florian Pfisterer;,citation_author=Stefan Coors;,citation_author=Martin Binder;,citation_author=Lennart Schneider;,citation_author=Janek Thomas;,citation_author=Jakob Richter;,citation_author=Michel Lang;,citation_author=Eduardo C. Garrido-Merchán;,citation_author=Juergen Branke;,citation_author=Bernd Bischl;,citation_publication_date=2023-12;,citation_cover_date=2023-12;,citation_year=2023;,citation_issue=4;,citation_volume=3;,citation_journal_title=ACM Trans. Evol. Learn. Optim.;">
<meta name="citation_reference" content="citation_title=A Simplex Method for Function Minimization;,citation_author=J. A. Nelder;,citation_author=R. Mead;,citation_publication_date=1965-01;,citation_cover_date=1965-01;,citation_year=1965;,citation_issue=4;,citation_volume=7;,citation_journal_title=The Computer Journal;">
<meta name="citation_reference" content="citation_title=Multiple Objective Optimization Using Desirability Functions for the Design of a 3D Printer Prototype;,citation_author=Esmeralda Nino;,citation_author=Juan Rosas Rubio;,citation_author=Samuel Bonet;,citation_author=Nazario Ramirez-Beltran;,citation_author=Mauricio Cabrera-Rios;,citation_publication_date=2015-06;,citation_cover_date=2015-06;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=NIST/SEMATECH e-Handbook of Statistical Methods;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;">
<meta name="citation_reference" content="citation_title=The Nelder-Mead simplex procedure for function minimization;,citation_author=Donald M Olsson;,citation_author=Lloyd S Nelson;,citation_publication_date=1975;,citation_cover_date=1975;,citation_year=1975;,citation_issue=1;,citation_volume=17;,citation_journal_title=Technometrics;">
<meta name="citation_reference" content="citation_title=Hyperparameter Tuning Cookbook: A guide for scikit-learn, PyTorch, river, and spotpython;,citation_author=Thomas Bartz-Beielstein;,citation_publication_date=2023-07;,citation_cover_date=2023-07;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2307.10262;,citation_doi=10.48550/arXiv.2307.10262;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Interpolation of scattered data: Distance matrices and conditionally positive definite functions;,citation_abstract=Among other things, we prove that multiquadric surface interpolation is always solvable, thereby settling a conjecture of R. Franke.;,citation_author=Charles A. Micchelli;,citation_publication_date=1986;,citation_cover_date=1986;,citation_year=1986;,citation_fulltext_html_url=https://doi.org/10.1007/BF01893414;,citation_issue=1;,citation_doi=10.1007/BF01893414;,citation_isbn=1432-0940;,citation_volume=2;,citation_journal_title=Constructive Approximation;">
<meta name="citation_reference" content="citation_title=Computational Approaches for Aerospace Design: The Pursuit of Excellence;,citation_author=Andrew J Keane;,citation_author=Prasanth B Nair;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;">
<meta name="citation_reference" content="citation_title=Statistical learning theory;,citation_author=V N Vapnik;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;">
<meta name="citation_reference" content="citation_title=Regularization algorithms for learning that are equivalent to multilayer networks.;,citation_abstract=Learning an input-output mapping from a set of examples, of the type that many neural networks have been constructed to perform, can be regarded as synthesizing an approximation of a multidimensional function (that is, solving the problem of hypersurface reconstruction). From this point of view, this form of learning is closely related to classical approximation techniques, such as generalized splines and regularization theory. A theory is reported that shows the equivalence between regularization and a class of three-layer networks called regularization networks or hyper basis functions. These networks are not only equivalent to generalized splines but are also closely related to the classical radial basis functions used for interpolation tasks and to several pattern recognition and neural network algorithms. They also have an interesting interpretation in terms of prototypes that are synthesized and optimally combined during the learning stage.;,citation_author=T Poggio;,citation_author=F Girosi;,citation_publication_date=1990-02;,citation_cover_date=1990-02;,citation_year=1990;,citation_issue=4945;,citation_doi=10.1126/science.247.4945.978;,citation_issn=0036-8075 (Print); 0036-8075 (Linking);,citation_pmid=17776454;,citation_volume=247;,citation_journal_title=Science;">
<meta name="citation_reference" content="citation_title=Exploratory designs for computational experiments;,citation_abstract=Recent work by Johnson et al. (J. Statist. Plann. Inference 26 (1990) 131–148) establishes equivalence of the maximin distance design criterion and an entropy criterion motivated by function prediction in a Bayesian setting. The latter criterion has been used by Currin et al. (J. Amer. Statist. Assoc. 86 (1991) 953–963) to design experiments for which the motivating application is approximation of a complex deterministic computer model. Because computer experiments often have a large number of controlled variables (inputs), maximin designs of moderate size are often concentrated in the corners of the cuboidal design region, i.e. each input is represented at only two levels. Here we will examine some maximin distance designs constructed within the class of Latin hypercube arrangements. The goal of this is to find designs which offer a compromise between the entropy/maximin criterion, and good projective properties in each dimension (as guaranteed by Latin hypercubes). A simulated annealing search algorithm is presented for constructing these designs, and patterns apparent in the optimal designs are discussed.;,citation_author=Max D. Morris;,citation_author=Toby J. Mitchell;,citation_publication_date=1995;,citation_cover_date=1995;,citation_year=1995;,citation_fulltext_html_url=https://www.sciencedirect.com/science/article/pii/037837589400035T;,citation_issue=3;,citation_doi=https://doi.org/10.1016/0378-3758(94)00035-T;,citation_issn=0378-3758;,citation_volume=43;,citation_journal_title=Journal of Statistical Planning and Inference;">
<meta name="citation_reference" content="citation_title=Evolutionary operation: A method for increasing industrial productivity.;,citation_author=G E P Box;,citation_publication_date=1957;,citation_cover_date=1957;,citation_year=1957;,citation_volume=6;,citation_journal_title=Applied Statistics;">
<meta name="citation_reference" content="citation_title=Minimax and maximin distance designs;,citation_author=M. E. Johnson;,citation_author=L. M. Moore;,citation_author=D. Ylvisaker;,citation_publication_date=1990;,citation_cover_date=1990;,citation_year=1990;,citation_issue=2;,citation_volume=26;,citation_journal_title=Journal of Statistical Planning and Inference;">
<meta name="citation_reference" content="citation_title=Aircraft Design: A Conceptual Approach;,citation_author=Daniel P. Raymer;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;">
<meta name="citation_reference" content="citation_title=Design and analysis of computer experiments;,citation_author=J Sacks;,citation_author=W J Welch;,citation_author=T J Mitchell;,citation_author=H P Wynn;,citation_publication_date=1989;,citation_cover_date=1989;,citation_year=1989;,citation_issue=4;,citation_volume=4;,citation_journal_title=Statistical Science;">
<meta name="citation_reference" content="citation_title=Kriging (Gaussian Process Regression): The Complete Python Code for the Example;,citation_author=Thomas Bartz-Beielstein;,citation_publication_date=2025-06;,citation_cover_date=2025-06;,citation_year=2025;,citation_fulltext_html_url=https://sequential-parameter-optimization.github.io/Hyperparameter-Tuning-Cookbook/006_num_gp.html;">
<meta name="citation_reference" content="citation_title=Efficient global optimization of expensive black-box functions;,citation_author=Donald R. Jones;,citation_author=Matthias Schonlau;,citation_author=William J. Welch;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_issue=4;,citation_volume=13;,citation_journal_title=Journal of Global Optimization;">
<meta name="citation_reference" content="citation_title=On Bayesian Methods for Seeking the Extremum;,citation_author=J. Močkus;,citation_publication_date=1974;,citation_cover_date=1974;,citation_year=1974;,citation_conference_title=Optimization Techniques IFIP Technical Conference;">
</head>

<body class="nav-sidebar docked quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./001_surrogate.html">Numerical Methods</a></li><li class="breadcrumb-item"><a href="./006_num_gp.html"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Kriging (Gaussian Process Regression)</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Hyperparameter Tuning Cookbook</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/sequential-parameter-optimization/spotpython" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="./Hyperparameter-Tuning-Cookbook.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
              <i class="bi bi-linkedin pe-1"></i>
            LinkedIn
            </a>
          </li>
      </ul>
    </div>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Optimization</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./002_awwe.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Aircraft Wing Weight Example</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./003_scipy_optimize_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction to <code>scipy.optimize</code></span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Numerical Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./001_surrogate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Simulation and Surrogate Modeling</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./001_sampling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Sampling Plans</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./006_constructing_surrogate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Constructing a Surrogate</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./005_num_rsm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Response Surface Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./006_num_poly.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Polynomial Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./006_num_rbf.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Radial Basis Function Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./006_num_gp.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Kriging (Gaussian Process Regression)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./006_matrices.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Matrices</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./006_infill.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Infill Criteria</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Sequential Parameter Optimization Toolbox (SPOT)</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./007_spot_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Introduction to Sequential Parameter Optimization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./008_num_spot_multidim.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Multi-dimensional Functions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./009_num_spot_anisotropic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Isotropic and Anisotropic Kriging</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./004_spot_sklearn_optimization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Sequential Parameter Optimization: Using <code>scipy</code> Optimizers</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./010_num_spot_sklearn_surrogate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Using <code>sklearn</code> Surrogates in <code>spotpython</code></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./011_num_spot_sklearn_gaussian.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Sequential Parameter Optimization: Gaussian Process Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./012_num_spot_ei.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Infill Criteria</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./013_num_spot_noisy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Handling Noise</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./014_num_spot_ocba.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Optimal Computational Budget Allocation in spotpython</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./015_num_spot_correlation_p.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Kriging with Varying Correlation-p</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./016_num_spot_factorial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Factorial Variables</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./017_num_spot_user_function.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">User-Specified Functions: Extending the Analytical Class</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Data-Driven Modeling and Optimization</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./100_ddmo_eda.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Basic Statistics and Data Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./100_ddmo_pca.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Addressing Multicollinearity: Principle Component Analysis (PCA) and Factor Analysis (FA)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./100_ddmo_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./100_ddmo_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Classification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./100_ddmo_clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Clustering</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Machine Learning and AI</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./200_mlai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Machine Learning and Artificial Intelligence</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Introduction to Hyperparameter Tuning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./300_hpt_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Hyperparameter Tuning with Sklearn</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./400_spot_hpt_sklearn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">HPT: sklearn</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./401_spot_hpt_sklearn_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">HPT: sklearn SVC on Moons Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./401_spot_hpt_sklearn_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">HPT: sklearn SVR on Regression Data</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true">
 <span class="menu-text">Hyperparameter Tuning with River</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./500_spot_hpt_river.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">HPT: River</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./501_spot_river_gui.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Simplifying Hyperparameter Tuning in Online Machine Learning—The spotRiverGUI</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./502_spot_hpt_river_friedman_htr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title"><code>river</code> Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./503_spot_hpt_river_friedman_amfr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">The Friedman Drift Data Set</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true">
 <span class="menu-text">Hyperparameter Tuning with PyTorch Lightning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./700_lightning_basic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Basic Lightning Module</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./701_lightning_details.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">Details of the Lightning Module Integration in spotpython</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./702_lightning_user_datamodule.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">User Specified Basic Lightning Module With spotpython</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./600_spot_lightning_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">HPT PyTorch Lightning: Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./601_spot_hpt_light_diabetes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning with <code>spotpython</code> and <code>PyTorch</code> Lightning for the Diabetes Data Set</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./601_spot_hpt_light_early_stopping.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Early Stopping Explained: HPT with <code>spotpython</code> and <code>PyTorch</code> Lightning for the Diabetes Data Set</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./601_spot_hpt_light_user_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning with PyTorch Lightning and User Data Sets</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./601_spot_hpt_light_user_model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">45</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning with PyTorch Lightning and User Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./601_resnet.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">46</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning with PyTorch Lightning: ResNets</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./601_neural_ode.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">47</span>&nbsp; <span class="chapter-title">Neural ODEs</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./601_neural_ode_example.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">48</span>&nbsp; <span class="chapter-title">Neural ODE Example</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./601_pinn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">49</span>&nbsp; <span class="chapter-title">Physics Informed Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./601_spot_hpt_light_pinn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">50</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning with PyTorch Lightning: Physics Informed Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./602_spot_lightning_xai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">51</span>&nbsp; <span class="chapter-title">Explainable AI with SpotPython and Pytorch</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./603_spot_lightning_transformer_introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">52</span>&nbsp; <span class="chapter-title">HPT PyTorch Lightning Transformer: Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./603_spot_lightning_transformer_hpt.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">53</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning of a Transformer Network with PyTorch Lightning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./604_spot_lightning_save_load_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">54</span>&nbsp; <span class="chapter-title">Saving and Loading</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./605_spot_hpt_light_diabetes_resnet.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">55</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning with <code>spotpython</code> and <code>PyTorch</code> Lightning for the Diabetes Data Set Using a ResNet Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./606_spot_hpt_light_diabetes_user_resnet.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">56</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning with <code>spotpython</code> and <code>PyTorch</code> Lightning for the Diabetes Data Set Using a User Specified ResNet Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./608_spot_hpt_light_condnet.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">57</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning with <code>spotpython</code> and <code>PyTorch</code> Lightning Using a CondNet Model</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true">
 <span class="menu-text">Multi Objective Optimization</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bart25a-desirability-latest.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">58</span>&nbsp; <span class="chapter-title">Introduction to Desirability Functions</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true">
 <span class="menu-text">Lernmodule</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./de_awwe.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">59</span>&nbsp; <span class="chapter-title">Lernmodul: Aircraft Wing Weight Example (AWWE)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./de_sampling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">60</span>&nbsp; <span class="chapter-title">Lernmodul: Versuchspläne (Sampling-Pläne) für Computerexperimente</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./de_kriging.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">61</span>&nbsp; <span class="chapter-title">Lernmodul: Eine Einführung in Kriging</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./de_cholesky.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">62</span>&nbsp; <span class="chapter-title">Lernmodul: Die Cholesky-Zerlegung</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./de_kriging_optimization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">63</span>&nbsp; <span class="chapter-title">Lernmodul: Erweiterung des Kriging-Modells: Numerische Optimierung der Hyperparameter</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./de_kriging_optimization_python_class.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">64</span>&nbsp; <span class="chapter-title">Lernmodul: Erweiterung des Kriging-Modells zu einer Klasse (Python Code)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./de_projekt.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">65</span>&nbsp; <span class="chapter-title">Lernmodul: Kriging Projekt</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./de_projekt_ei.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">66</span>&nbsp; <span class="chapter-title">Lernmodul: Kriging Projekt mit Expected Improvement</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_01_intro_to_notebooks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Introduction to Jupyter Notebook</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_02_git_intro_en.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Git Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_03_python_intro_en.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Python</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_04_gp_background.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Gaussian Processes—Some Background Information</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_05_datasets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Datasets</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_06_slurm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Using Slurm</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_07_package.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">G</span>&nbsp; <span class="chapter-title">Python Package Building</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_08_parallel.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">H</span>&nbsp; <span class="chapter-title">Parallelism in Initial Design</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_99_solutions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">I</span>&nbsp; <span class="chapter-title">Solutions to Selected Exercises</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#from-gaussian-rbf-to-kriging-basis-functions" id="toc-from-gaussian-rbf-to-kriging-basis-functions" class="nav-link active" data-scroll-target="#from-gaussian-rbf-to-kriging-basis-functions"><span class="header-section-number">9.1</span> From Gaussian RBF to Kriging Basis Functions</a></li>
  <li><a href="#building-the-kriging-model" id="toc-building-the-kriging-model" class="nav-link" data-scroll-target="#building-the-kriging-model"><span class="header-section-number">9.2</span> Building the Kriging Model</a></li>
  <li><a href="#mle-to-estimate-theta-and-p" id="toc-mle-to-estimate-theta-and-p" class="nav-link" data-scroll-target="#mle-to-estimate-theta-and-p"><span class="header-section-number">9.3</span> MLE to estimate <span class="math inline">\(\theta\)</span> and <span class="math inline">\(p\)</span></a>
  <ul class="collapse">
  <li><a href="#the-log-likelihood" id="toc-the-log-likelihood" class="nav-link" data-scroll-target="#the-log-likelihood"><span class="header-section-number">9.3.1</span> The Log-Likelihood</a></li>
  <li><a href="#differentiation-with-respect-to-mu" id="toc-differentiation-with-respect-to-mu" class="nav-link" data-scroll-target="#differentiation-with-respect-to-mu"><span class="header-section-number">9.3.2</span> Differentiation with Respect to <span class="math inline">\(\mu\)</span></a></li>
  <li><a href="#differentiation-with-respect-to-sigma" id="toc-differentiation-with-respect-to-sigma" class="nav-link" data-scroll-target="#differentiation-with-respect-to-sigma"><span class="header-section-number">9.3.3</span> Differentiation with Respect to <span class="math inline">\(\sigma\)</span></a></li>
  <li><a href="#results-of-the-optimizations" id="toc-results-of-the-optimizations" class="nav-link" data-scroll-target="#results-of-the-optimizations"><span class="header-section-number">9.3.4</span> Results of the Optimizations</a></li>
  <li><a href="#the-concentrated-log-likelihood-function" id="toc-the-concentrated-log-likelihood-function" class="nav-link" data-scroll-target="#the-concentrated-log-likelihood-function"><span class="header-section-number">9.3.5</span> The Concentrated Log-Likelihood Function</a></li>
  <li><a href="#optimizing-the-parameters-vectheta-and-vecp" id="toc-optimizing-the-parameters-vectheta-and-vecp" class="nav-link" data-scroll-target="#optimizing-the-parameters-vectheta-and-vecp"><span class="header-section-number">9.3.6</span> Optimizing the Parameters <span class="math inline">\(\vec{\theta}\)</span> and <span class="math inline">\(\vec{p}\)</span></a></li>
  <li><a href="#correlation-and-covariance-matrices-revisited" id="toc-correlation-and-covariance-matrices-revisited" class="nav-link" data-scroll-target="#correlation-and-covariance-matrices-revisited"><span class="header-section-number">9.3.7</span> Correlation and Covariance Matrices Revisited</a></li>
  </ul></li>
  <li><a href="#implementing-an-mle-of-the-model-parameters" id="toc-implementing-an-mle-of-the-model-parameters" class="nav-link" data-scroll-target="#implementing-an-mle-of-the-model-parameters"><span class="header-section-number">9.4</span> Implementing an MLE of the Model Parameters</a></li>
  <li><a href="#kriging-prediction" id="toc-kriging-prediction" class="nav-link" data-scroll-target="#kriging-prediction"><span class="header-section-number">9.5</span> Kriging Prediction</a></li>
  <li><a href="#kriging-example-sinusoid-function" id="toc-kriging-example-sinusoid-function" class="nav-link" data-scroll-target="#kriging-example-sinusoid-function"><span class="header-section-number">9.6</span> Kriging Example: Sinusoid Function</a>
  <ul class="collapse">
  <li><a href="#calculating-the-correlation-matrix-psi" id="toc-calculating-the-correlation-matrix-psi" class="nav-link" data-scroll-target="#calculating-the-correlation-matrix-psi"><span class="header-section-number">9.6.1</span> Calculating the Correlation Matrix <span class="math inline">\(\Psi\)</span></a></li>
  <li><a href="#computing-the-psi-matrix" id="toc-computing-the-psi-matrix" class="nav-link" data-scroll-target="#computing-the-psi-matrix"><span class="header-section-number">9.6.2</span> Computing the <span class="math inline">\(\Psi\)</span> Matrix</a></li>
  <li><a href="#selecting-the-new-locations" id="toc-selecting-the-new-locations" class="nav-link" data-scroll-target="#selecting-the-new-locations"><span class="header-section-number">9.6.3</span> Selecting the New Locations</a></li>
  <li><a href="#computing-the-psi-vector" id="toc-computing-the-psi-vector" class="nav-link" data-scroll-target="#computing-the-psi-vector"><span class="header-section-number">9.6.4</span> Computing the <span class="math inline">\(\psi\)</span> Vector</a></li>
  <li><a href="#predicting-at-new-locations" id="toc-predicting-at-new-locations" class="nav-link" data-scroll-target="#predicting-at-new-locations"><span class="header-section-number">9.6.5</span> Predicting at New Locations</a></li>
  <li><a href="#visualization" id="toc-visualization" class="nav-link" data-scroll-target="#visualization"><span class="header-section-number">9.6.6</span> Visualization</a></li>
  <li><a href="#sec-kriging-example-006" id="toc-sec-kriging-example-006" class="nav-link" data-scroll-target="#sec-kriging-example-006"><span class="header-section-number">9.6.7</span> The Complete Python Code for the Example</a></li>
  </ul></li>
  <li><a href="#jupyter-notebook" id="toc-jupyter-notebook" class="nav-link" data-scroll-target="#jupyter-notebook"><span class="header-section-number">9.7</span> Jupyter Notebook</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./001_surrogate.html">Numerical Methods</a></li><li class="breadcrumb-item"><a href="./006_num_gp.html"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Kriging (Gaussian Process Regression)</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Kriging (Gaussian Process Regression)</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>This section is based on chapter 2.4 in <span class="citation" data-cites="Forr08a">Forrester, Sóbester, and Keane (<a href="references.html#ref-Forr08a" role="doc-biblioref">2008</a>)</span>.</li>
<li>The following Python packages are imported:</li>
</ul>
<div id="d7c205be" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> (array, zeros, power, ones, exp, multiply,</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>                    eye, linspace, spacing, sqrt, arange,</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>                    append, ravel)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy.linalg <span class="im">import</span> cholesky, solve</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.spatial.distance <span class="im">import</span> squareform, pdist, cdist</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<!-- bart21mSlides2022Lec-05 -->
<section id="from-gaussian-rbf-to-kriging-basis-functions" class="level2" data-number="9.1">
<h2 data-number="9.1" class="anchored" data-anchor-id="from-gaussian-rbf-to-kriging-basis-functions"><span class="header-section-number">9.1</span> From Gaussian RBF to Kriging Basis Functions</h2>
<p>Kriging can be explained using the concept of radial basis functions (RBFs), which were introduced in <a href="006_num_rbf.html" class="quarto-xref"><span>Chapter 8</span></a>. An RBF is a real-valued function whose value depends only on the distance from a certain point, called the center, usually in a multidimensional space. The basis function is a function of the distance between the point <span class="math inline">\(\vec{x}\)</span> and the center <span class="math inline">\(\vec{x}^{(i)}\)</span>. Other names for basis functions are <em>kernel</em> or <em>covariance</em> functions.</p>
<div id="def-kriging-basis-function" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 9.1 (The Kriging Basis Functions)</strong></span> Kriging (also known as Gaussian Process Regression) uses <span class="math inline">\(k\)</span>-dimensional basis functions of the form <span id="eq-krigingbase"><span class="math display">\[
\psi^{(i)}(\vec{x}) =
\psi(\vec{x}^{(i)}, \vec{x}) = \exp \left( - \sum_{j=1}^k \theta_j | x_{j}^{(i)} - x_{j} | ^{p_j} \right),
\tag{9.1}\]</span></span> where <span class="math inline">\(\vec{x}\)</span> and <span class="math inline">\(\vec{x}^{(i)}\)</span> denote the <span class="math inline">\(k\)</span>-dim vector <span class="math inline">\(\vec{x}= (x_1, \ldots, x_k)^T\)</span> and <span class="math inline">\(\vec{x}^{(i)}= (x_1^{(i)}, \ldots, x_k^{(i)})^T\)</span>, respectively.</p>
<p><span class="math inline">\(\Box\)</span></p>
</div>
<p>Kriging uses a specialized basis function that offers greater flexibility than standard RBFs. Examining <a href="#eq-krigingbase" class="quarto-xref">Equation&nbsp;<span>9.1</span></a>, we can observe how Kriging builds upon and extends the Gaussian basis concept. The key enhancements of Kriging over Gaussian RBF can be summarized as follows:</p>
<ul>
<li>Dimension-specific width parameters: While a Gaussian RBF uses a single width parameter <span class="math inline">\(1/\sigma^2\)</span>, Kriging employs a vector <span class="math inline">\(\vec{\theta} = (\theta_1, \theta_2, \ldots, \theta_k)^T\)</span>. This allows the model to automatically adjust its sensitivity to each input dimension, effectively performing automatic feature relevance determination.</li>
<li>Flexible smoothness control: The Gaussian RBF fixes the exponent at 2, producing uniformly smooth functions. In contrast, Kriging’s dimension-specific exponents <span class="math inline">\(\vec{p} = (p_1, p_2, \ldots, p_k)^T\)</span> (typically with <span class="math inline">\(p_j \in [1, 2]\)</span>) enable precise control over smoothness properties in each dimension.</li>
<li>Unifying framework: When all exponents are set to <span class="math inline">\(p_j = 2\)</span> and all width parameters are equal (<span class="math inline">\(\theta_j = 1/\sigma^2\)</span> for all <span class="math inline">\(j\)</span>), the Kriging basis function reduces exactly to the Gaussian RBF. This makes Gaussian RBF a special case within the more general Kriging framework.</li>
</ul>
<p>These enhancements make Kriging particularly well-suited for engineering problems where variables may operate at different scales or exhibit varying degrees of smoothness across dimensions. For now, we will only consider Kriging interpolation. We will cover Kriging regression later.</p>
</section>
<section id="building-the-kriging-model" class="level2" data-number="9.2">
<h2 data-number="9.2" class="anchored" data-anchor-id="building-the-kriging-model"><span class="header-section-number">9.2</span> Building the Kriging Model</h2>
<p>Consider sample data <span class="math inline">\(X\)</span> and <span class="math inline">\(\vec{y}\)</span> from <span class="math inline">\(n\)</span> locations that are available in matrix form: <span class="math inline">\(X\)</span> is a <span class="math inline">\((n \times k)\)</span> matrix, where <span class="math inline">\(k\)</span> denotes the problem dimension and <span class="math inline">\(\vec{y}\)</span> is a <span class="math inline">\((n\times 1)\)</span> vector. We want to find an expression for a predicted values at a new point <span class="math inline">\(\vec{x}\)</span>, denoted as <span class="math inline">\(\hat{y}\)</span>.</p>
<p>We start with an abstract, not really intuitive concept: The observed responses <span class="math inline">\(\vec{y}\)</span> are considered as if they are from a stochastic process, which will be denoted as <span id="eq-yvec-51"><span class="math display">\[
\begin{pmatrix}
Y(\vec{x}^{(1)})\\
\vdots\\
Y(\vec{x}^{(n)})\\
\end{pmatrix}.
\tag{9.2}\]</span></span></p>
<p>The set of random vectors from <a href="#eq-yvec-51" class="quarto-xref">Equation&nbsp;<span>9.2</span></a> (also referred to as a <em>random field</em>) has a mean of <span class="math inline">\(\vec{1} \mu\)</span>, which is a <span class="math inline">\((n\times 1)\)</span> vector. The random vectors are correlated with each other using the basis function expression from <a href="#eq-krigingbase" class="quarto-xref">Equation&nbsp;<span>9.1</span></a>: <span id="eq-corr-kriging-51"><span class="math display">\[
\text{cor} \left(Y(\vec{x}^{(i)}),Y(\vec{x}^{(l)}) \right) = \exp\left(- \sum_{j=1}^k \theta_j |x_j^{(i)} - x_j^{(l)} |^{p_j}\right).
\tag{9.3}\]</span></span> Using <a href="#eq-corr-kriging-51" class="quarto-xref">Equation&nbsp;<span>9.3</span></a>, we can compute the <span class="math inline">\((n \times n)\)</span> correlation matrix <span class="math inline">\(\Psi\)</span> of the observed sample data as shown in <a href="#eq-corr-matrix-kriging-51" class="quarto-xref">Equation&nbsp;<span>9.4</span></a>,</p>
<p><span id="eq-corr-matrix-kriging-51"><span class="math display">\[
\Psi = \begin{pmatrix}
\text{cor}\left(
Y(\vec{x}^{(1)}),
Y(\vec{x}^{(1)})
\right) &amp; \ldots &amp;
\text{cor}\left(
Y(\vec{x}^{(1)}),
Y(\vec{x}^{(n)})
\right)\\
\vdots  &amp; \vdots &amp;  \vdots\\
\text{cor}\left(
Y(\vec{x}^{(n)}),
Y(\vec{x}^{(1)})
\right)&amp;
\ldots &amp;
\text{cor}\left(
Y(\vec{x}^{(n)}),
Y(\vec{x}^{(n)})
\right)
\end{pmatrix},
\tag{9.4}\]</span></span></p>
<p>and a covariance matrix as shown in <a href="#eq-cov-matrix-kriging-52" class="quarto-xref">Equation&nbsp;<span>9.5</span></a>,</p>
<p><span id="eq-cov-matrix-kriging-52"><span class="math display">\[
\text{Cov}(Y, Y ) = \sigma^2\Psi.
\tag{9.5}\]</span></span></p>
<p>This assumed correlation between the sample data reflects our expectation that an engineering function will behave in a certain way and it will be smoothly and continuous.</p>
<div id="rem-stocastic-process" class="proof remark">
<p><span class="proof-title"><em>Remark 9.1</em> (Note on Stochastic Processes). </span>See <a href="a_04_gp_background.html#sec-random-samples-gp" class="quarto-xref"><span>Section D.4</span></a> for a more detailed discussion on realizations of stochastic processes.</p>
<p><span class="math inline">\(\Box\)</span></p>
</div>
<p>We now have a set of <span class="math inline">\(n\)</span> random variables (<span class="math inline">\(\mathbf{Y}\)</span>) that are correlated with each other as described in the <span class="math inline">\((n \times n)\)</span> correlation matrix <span class="math inline">\(\Psi\)</span>, see <a href="#eq-corr-matrix-kriging-51" class="quarto-xref">Equation&nbsp;<span>9.4</span></a>. The correlations depend on the absolute distances in dimension <span class="math inline">\(j\)</span> between the <span class="math inline">\(i\)</span>-th and the <span class="math inline">\(l\)</span>-th sample point <span class="math inline">\(|x_j^{(i)} - x_j^{(l)}|\)</span> and the corresponding parameters <span class="math inline">\(p_j\)</span> and <span class="math inline">\(\theta_j\)</span> for dimension <span class="math inline">\(j\)</span>. The correlation is intuitive, because when</p>
<ul>
<li>two points move close together, then <span class="math inline">\(|x_j^{(i)} - x_j| \to 0\)</span> and <span class="math inline">\(\exp \left(-|x_j^{(i)} - x_j|^{p_j} \right) \to 1\)</span> (these points show very close correlation and <span class="math inline">\(Y(x_j^{(i)}) = Y(x_j)\)</span>).</li>
<li>two points move far apart, then <span class="math inline">\(|x_j^{(i)} - x_j| \to \infty\)</span> and <span class="math inline">\(\exp \left(-|x_j^{(i)} - x_j|^{p_j} \right) \to 0\)</span> (these points show very low correlation).</li>
</ul>
<div id="exm-kriging-corr-1" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.1 (Correlations for different <span class="math inline">\(p_j\)</span>)</strong></span> Three different correlations are shown in <a href="#fig-pval12" class="quarto-xref">Figure&nbsp;<span>9.1</span></a>: <span class="math inline">\(p_j= 0.1, 1, 2\)</span>. The smoothness parameter <span class="math inline">\(p_j\)</span> affects the correlation:</p>
<ul>
<li>With <span class="math inline">\(p_j=0.1\)</span>, there is basicaly no immediate correlation between the points and there is a near discontinuity between the points <span class="math inline">\(Y(\vec{x}_j^{(i)})\)</span> and <span class="math inline">\(Y(\vec{x}_j)\)</span>.</li>
<li>With <span class="math inline">\(p_j=2\)</span>, the correlation is more smooth and we have a continuous gradient through <span class="math inline">\(x_j^{(i)} - x_j\)</span>.</li>
</ul>
<p>Reducing <span class="math inline">\(p_j\)</span> increases the rate at which the correlation initially drops with distance. This is shown in <a href="#fig-pval12" class="quarto-xref">Figure&nbsp;<span>9.1</span></a>.</p>
<div id="cell-fig-pval12" class="cell" data-execution_count="3">
<div class="cell-output cell-output-display">
<div id="fig-pval12" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pval12-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="006_num_gp_files/figure-html/fig-pval12-output-1.png" width="571" height="411" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pval12-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.1: Correlations with varying <span class="math inline">\(p\)</span>. <span class="math inline">\(\theta\)</span> set to 1.
</figcaption>
</figure>
</div>
</div>
</div>
<p><span class="math inline">\(\Box\)</span></p>
</div>
<div id="exm-kriging-corr-2" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.2 (Correlations for different <span class="math inline">\(\theta\)</span>)</strong></span> <a href="#fig-theta12" class="quarto-xref">Figure&nbsp;<span>9.2</span></a> visualizes the correlation between two points <span class="math inline">\(Y(\vec{x}_j^{(i)})\)</span> and <span class="math inline">\(Y(\vec{x}_j)\)</span> for different values of <span class="math inline">\(\theta\)</span>. The parameter <span class="math inline">\(\theta\)</span> can be seen as a <em>width</em> parameter:</p>
<ul>
<li>low <span class="math inline">\(\theta_j\)</span> means that all points will have a high correlation, with <span class="math inline">\(Y(x_j)\)</span> being similar across the sample.</li>
<li>high <span class="math inline">\(\theta_j\)</span> means that there is a significant difference between the <span class="math inline">\(Y(x_j)\)</span>’s.</li>
<li><span class="math inline">\(\theta_j\)</span> is a measure of how <em>active</em> the function we are approximating is.</li>
<li>High <span class="math inline">\(\theta_j\)</span> indicate important parameters, see <a href="#fig-theta12" class="quarto-xref">Figure&nbsp;<span>9.2</span></a>.</li>
</ul>
<div id="cell-fig-theta12" class="cell" data-execution_count="4">
<div class="cell-output cell-output-display">
<div id="fig-theta12" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-theta12-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="006_num_gp_files/figure-html/fig-theta12-output-1.png" width="571" height="411" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-theta12-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.2: Correlations with varying <span class="math inline">\(\theta\)</span>. <span class="math inline">\(p\)</span> set to 2.
</figcaption>
</figure>
</div>
</div>
</div>
<p><span class="math inline">\(\Box\)</span></p>
</div>
<p>Considering the activity parameter <span class="math inline">\(\theta\)</span> is useful in high-dimensional problems where it is difficult to visualize the design landscape and the effect of the variable is unknown. By examining the elements of the vector <span class="math inline">\(\vec{\theta}\)</span>, we can identify the most important variables and focus on them. This is a crucial step in the optimization process, as it allows us to reduce the dimensionality of the problem and focus on the most important variables.</p>
<div id="exm-corr-matrix-detailed" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.3 (The Correlation Matrix (Detailed Computation))</strong></span> Let <span class="math inline">\(n=4\)</span> and <span class="math inline">\(k=3\)</span>. The sample plan is represented by the following matrix <span class="math inline">\(X\)</span>: <span class="math display">\[
X = \begin{pmatrix} x_{11} &amp; x_{12} &amp; x_{13}\\
x_{21} &amp; x_{22} &amp; x_{23}\\
x_{31} &amp; x_{32} &amp; x_{33}\\
x_{41} &amp; x_{42} &amp; x_{43}\\
\end{pmatrix}
\]</span></p>
<p>To compute the elements of the matrix <span class="math inline">\(\Psi\)</span>, the following <span class="math inline">\(k\)</span> (one for each of the <span class="math inline">\(k\)</span> dimensions) <span class="math inline">\((n,n)\)</span>-matrices have to be computed:</p>
<ul>
<li><p>For <span class="math inline">\(k=1\)</span>, i.e., the first column of <span class="math inline">\(X\)</span>: <span class="math display">\[
D_1 = \begin{pmatrix} x_{11} - x_{11} &amp; x_{11} - x_{21} &amp; x_{11} -x_{31} &amp; x_{11} - x_{41} \\  x_{21} - x_{11} &amp; x_{21} - x_{21} &amp; x_{21} -x_{31} &amp; x_{21} - x_{41} \\ x_{31} - x_{11} &amp; x_{31} - x_{21} &amp; x_{31} -x_{31} &amp; x_{31} - x_{41} \\ x_{41} - x_{11} &amp; x_{41} - x_{21} &amp; x_{41} -x_{31} &amp; x_{41} - x_{41} \\
\end{pmatrix}
\]</span></p></li>
<li><p>For <span class="math inline">\(k=2\)</span>, i.e., the second column of <span class="math inline">\(X\)</span>: <span class="math display">\[
D_2 = \begin{pmatrix} x_{12} - x_{12} &amp; x_{12} - x_{22} &amp; x_{12} -x_{32} &amp; x_{12} - x_{42} \\  x_{22} - x_{12} &amp; x_{22} - x_{22} &amp; x_{22} -x_{32} &amp; x_{22} - x_{42} \\ x_{32} - x_{12} &amp; x_{32} - x_{22} &amp; x_{32} -x_{32} &amp; x_{32} - x_{42} \\ x_{42} - x_{12} &amp; x_{42} - x_{22} &amp; x_{42} -x_{32} &amp; x_{42} - x_{42} \\
\end{pmatrix}
\]</span></p></li>
<li><p>For <span class="math inline">\(k=3\)</span>, i.e., the third column of <span class="math inline">\(X\)</span>: <span class="math display">\[
D_3 = \begin{pmatrix} x_{13} - x_{13} &amp; x_{13} - x_{23} &amp; x_{13} -x_{33} &amp; x_{13} - x_{43} \\  x_{23} - x_{13} &amp; x_{23} - x_{23} &amp; x_{23} -x_{33} &amp; x_{23} - x_{43} \\ x_{33} - x_{13} &amp; x_{33} - x_{23} &amp; x_{33} -x_{33} &amp; x_{33} - x_{43} \\ x_{43} - x_{13} &amp; x_{43} - x_{23} &amp; x_{43} -x_{33} &amp; x_{43} - x_{43} \\\end{pmatrix}
\]</span></p></li>
</ul>
<p>Since the matrices are symmetric and the main diagonals are zero, it is sufficient to compute the following matrices: <span class="math display">\[
D_1 = \begin{pmatrix} 0 &amp; x_{11} - x_{21} &amp; x_{11} -x_{31} &amp; x_{11} - x_{41} \\  0 &amp;  0 &amp; x_{21} -x_{31} &amp; x_{21} - x_{41} \\ 0 &amp; 0 &amp; 0 &amp; x_{31} - x_{41} \\ 0 &amp; 0 &amp; 0 &amp; 0 \\\end{pmatrix}
\]</span> <span class="math display">\[
D_2 = \begin{pmatrix} 0 &amp; x_{12} - x_{22} &amp; x_{12} -x_{32} &amp; x_{12} - x_{42} \\  0 &amp; 0 &amp; x_{22} -x_{32} &amp; x_{22} - x_{42} \\ 0 &amp; 0 &amp; 0 &amp; x_{32} - x_{42} \\ 0 &amp; 0 &amp; 0 &amp; 0 \\
\end{pmatrix}
\]</span></p>
<p><span class="math display">\[
D_3 = \begin{pmatrix} 0 &amp; x_{13} - x_{23} &amp; x_{13} -x_{33} &amp; x_{13} - x_{43} \\  0 &amp; 0 &amp; x_{23} -x_{33} &amp; x_{23} - x_{43} \\ 0 &amp; 0 &amp; 0 &amp; x_{33} - x_{43} \\ 0 &amp; 0 &amp; 0 &amp; 0 \\\end{pmatrix}
\]</span></p>
<p>We will consider <span class="math inline">\(p_l=2\)</span>. The differences will be squared and multiplied by <span class="math inline">\(\theta_i\)</span>, i.e.:</p>
<p><span class="math display">\[
D_1 = \theta_1 \begin{pmatrix} 0 &amp; (x_{11} - x_{21})^2 &amp; (x_{11} -x_{31})^2 &amp; (x_{11} - x_{41})^2 \\  0 &amp;  0 &amp; (x_{21} -x_{31})^2 &amp; (x_{21} - x_{41})^2 \\ 0 &amp; 0 &amp; 0 &amp; (x_{31} - x_{41})^2 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\\end{pmatrix}
\]</span></p>
<p><span class="math display">\[
D_2 = \theta_2 \begin{pmatrix} 0 &amp; (x_{12} - x_{22})^2 &amp; (x_{12} -x_{32})^2 &amp; (x_{12} - x_{42})^2 \\  0 &amp; 0 &amp; (x_{22} -x_{32})^2 &amp; (x_{22} - x_{42})^2 \\ 0 &amp; 0 &amp; 0 &amp; (x_{32} - x_{42})^2 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\\end{pmatrix}
\]</span></p>
<p><span class="math display">\[
D_3 = \theta_3 \begin{pmatrix} 0 &amp; (x_{13} - x_{23})^2 &amp; (x_{13} -x_{33})^2 &amp; (x_{13} - x_{43})^2 \\  0 &amp; 0 &amp; (x_{23} -x_{33})^2 &amp; (x_{23} - x_{43})^2 \\ 0 &amp; 0 &amp; 0 &amp; (x_{33} - x_{43})^2 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\\end{pmatrix}
\]</span></p>
<p>The sum of the three matrices <span class="math inline">\(D=D_1+ D_2 + D_3\)</span> will be calculated next:</p>
<p><span class="math display">\[
\begin{pmatrix} 0 &amp;
\theta_1  (x_{11} - x_{21})^2 + \theta_2 (x_{12} - x_{22})^2 + \theta_3  (x_{13} - x_{23})^2  &amp;
\theta_1 (x_{11} -x_{31})^2 + \theta_2  (x_{12} -x_{32})^2 + \theta_3  (x_{13} -x_{33})^2 &amp;
\theta_1  (x_{11} - x_{41})^2 + \theta_2  (x_{12} - x_{42})^2 + \theta_3 (x_{13} - x_{43})^2
\\  0 &amp;  0 &amp;
\theta_1  (x_{21} -x_{31})^2 + \theta_2 (x_{22} -x_{32})^2 + \theta_3  (x_{23} -x_{33})^2 &amp;
\theta_1  x_{21} - x_{41})^2 + \theta_2  (x_{22} - x_{42})^2 + \theta_3 (x_{23} - x_{43})^2
\\ 0 &amp; 0 &amp; 0 &amp;
\theta_1 (x_{31} - x_{41})^2 + \theta_2 (x_{32} - x_{42})^2 + \theta_3 (x_{33} - x_{43})^2
\\ 0 &amp; 0 &amp; 0 &amp; 0 \\\end{pmatrix}
\]</span></p>
<p>Finally, <span class="math display">\[ \Psi = \exp(-D)\]</span> is computed.</p>
<p>Next, we will demonstrate how this computation can be implemented in Python. We will consider four points in three dimensions and compute the correlation matrix <span class="math inline">\(\Psi\)</span> using the basis function from <a href="#eq-krigingbase" class="quarto-xref">Equation&nbsp;<span>9.1</span></a>. These points are placed at the origin, at the unit vectors, and at the points <span class="math inline">\((100, 100, 100)\)</span> and <span class="math inline">\((101, 100, 100)\)</span>. So, they form two clusters: one at the origin and one at <span class="math inline">\((100, 100, 100)\)</span>.</p>
<div id="0ac0210b" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>theta <span class="op">=</span> np.array([<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>])</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array([ [<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>], [<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>], [<span class="dv">100</span>, <span class="dv">100</span>, <span class="dv">100</span>], [<span class="dv">101</span>, <span class="dv">100</span>, <span class="dv">100</span>]])</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>X</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>array([[  1,   0,   0],
       [  0,   1,   0],
       [100, 100, 100],
       [101, 100, 100]])</code></pre>
</div>
</div>
<div id="704a2386" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_Psi(X, theta):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> X.shape[<span class="dv">0</span>]</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    k <span class="op">=</span> X.shape[<span class="dv">1</span>]</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    D <span class="op">=</span> zeros((k, n, n))</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> l <span class="kw">in</span> <span class="bu">range</span>(k):</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n):</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(i, n):</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>                D[l, i, j] <span class="op">=</span> theta[l]<span class="op">*</span>(X[i,l] <span class="op">-</span> X[j,l])<span class="op">**</span><span class="dv">2</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    D <span class="op">=</span> <span class="bu">sum</span>(D)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    D <span class="op">=</span> D <span class="op">+</span> D.T</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> exp(<span class="op">-</span>D)  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cb55ea85" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>Psi <span class="op">=</span> build_Psi(X, theta)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>Psi</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>array([[1.        , 0.04978707, 0.        , 0.        ],
       [0.04978707, 1.        , 0.        , 0.        ],
       [0.        , 0.        , 1.        , 0.36787944],
       [0.        , 0.        , 0.36787944, 1.        ]])</code></pre>
</div>
</div>
<div id="cell-fig-corr-matrix-build_Psi" class="cell" data-execution_count="8">
<div class="cell-output cell-output-display">
<div id="fig-corr-matrix-build_psi" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-corr-matrix-build_psi-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="006_num_gp_files/figure-html/fig-corr-matrix-build_psi-output-1.png" width="505" height="416" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-corr-matrix-build_psi-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.3: Correlation matrix <span class="math inline">\(\Psi\)</span>.
</figcaption>
</figure>
</div>
</div>
</div>
<p><span class="math inline">\(\Box\)</span></p>
</div>
<div id="exm-corr-matrix-existing" class="theorem example">
<p><span class="theorem-title"><strong>Example 9.4 (Example: The Correlation Matrix (Using Existing Functions))</strong></span> The same result as computed in <a href="#exm-corr-matrix-detailed" class="quarto-xref">Example&nbsp;<span>9.3</span></a> can be obtained with existing python functions, e.g., from the package <code>scipy</code>.</p>
<div id="e1625be3" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_Psi(X, theta, eps<span class="op">=</span>sqrt(spacing(<span class="dv">1</span>))):</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> exp(<span class="op">-</span> squareform(pdist(X,</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>                            metric<span class="op">=</span><span class="st">'sqeuclidean'</span>,</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>                            out<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>                            w<span class="op">=</span>theta))) <span class="op">+</span>  multiply(eye(X.shape[<span class="dv">0</span>]),</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>                                                   eps)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>Psi <span class="op">=</span> build_Psi(X, theta, eps<span class="op">=</span><span class="fl">.0</span>)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>Psi</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>array([[1.        , 0.04978707, 0.        , 0.        ],
       [0.04978707, 1.        , 0.        , 0.        ],
       [0.        , 0.        , 1.        , 0.36787944],
       [0.        , 0.        , 0.36787944, 1.        ]])</code></pre>
</div>
</div>
<p>The condition number of the correlation matrix <span class="math inline">\(\Psi\)</span> is a measure of how well the matrix can be inverted. A high condition number indicates that the matrix is close to singular, which can lead to numerical instability in computations involving the inverse of the matrix, see <a href="006_matrices.html#sec-conditon-number" class="quarto-xref"><span>Section 10.2</span></a>.</p>
<div id="0af596e3" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>np.linalg.cond(Psi)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>np.float64(2.163953413738652)</code></pre>
</div>
</div>
<p><span class="math inline">\(\Box\)</span></p>
</div>
</section>
<section id="mle-to-estimate-theta-and-p" class="level2" data-number="9.3">
<h2 data-number="9.3" class="anchored" data-anchor-id="mle-to-estimate-theta-and-p"><span class="header-section-number">9.3</span> MLE to estimate <span class="math inline">\(\theta\)</span> and <span class="math inline">\(p\)</span></h2>
<section id="the-log-likelihood" class="level3" data-number="9.3.1">
<h3 data-number="9.3.1" class="anchored" data-anchor-id="the-log-likelihood"><span class="header-section-number">9.3.1</span> The Log-Likelihood</h3>
<p>Until now, the observed data <span class="math inline">\(\vec{y}\)</span> was not used. We know what the correlations mean, but how do we estimate the values of <span class="math inline">\(\theta_j\)</span> and where does our observed data <span class="math inline">\(y\)</span> come in? To estimate the values of <span class="math inline">\(\vec{\theta}\)</span> and <span class="math inline">\(\vec{p}\)</span>, they are chosen to maximize the likelihood of <span class="math inline">\(\vec{y}\)</span>, <span id="eq-likelihood-55-a"><span class="math display">\[
L = L\left(Y(\vec{x}^{(1)}), \ldots, Y(\vec{x}^{(n)}) | \mu, \sigma \right) = \frac{1}{(2\pi \sigma^2)^{n/2}} \exp\left[ - \frac{\sum_{i=1}^n(Y(\vec{x}^{(i)})-\mu)^2}{2 \sigma^2}\right],
\tag{9.6}\]</span></span> where <span class="math inline">\(\mu\)</span> is the mean of the observed data <span class="math inline">\(\vec{y}\)</span> and <span class="math inline">\(\sigma\)</span> is the standard deviation of the errors <span class="math inline">\(\epsilon\)</span>, which can be expressed in terms of the sample data <span id="eq-likelihood-55"><span class="math display">\[
L = \frac{1}{(2\pi \sigma^2)^{n/2} |\vec{\Psi}|^{1/2}} \exp\left[ - \frac{(\vec{y} - \vec{1}\mu)^T \vec{\Psi}^{-1}(\vec{y} - \vec{1}\mu) }{2 \sigma^2}\right].
\tag{9.7}\]</span></span></p>
<div id="rem-likelihood-55" class="proof remark">
<p><span class="proof-title"><em>Remark 9.2</em>. </span>The transition from <a href="#eq-likelihood-55-a" class="quarto-xref">Equation&nbsp;<span>9.6</span></a> to <a href="#eq-likelihood-55" class="quarto-xref">Equation&nbsp;<span>9.7</span></a> reflects a shift from assuming independent errors in the observed data to explicitly modeling the <em>correlation structure</em> between the observed responses, which is a key aspect of the stochastic process framework used in methods like Kriging. It can be explained as follows:</p>
<ol type="1">
<li><p><strong>Initial Likelihood Expression (assuming independent errors):</strong> <a href="#eq-likelihood-55-a" class="quarto-xref">Equation&nbsp;<span>9.6</span></a> is an expression for the likelihood of the data set, which is based on the assumption that the errors <span class="math inline">\(\epsilon\)</span> are <em>independently randomly distributed according to a normal distribution with standard deviation <span class="math inline">\(\sigma\)</span></em>. This form is characteristic of the likelihood of <span class="math inline">\(n\)</span> independent observations <span class="math inline">\(Y(\vec{x}^{(i)})\)</span>, each following a normal distribution with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>.</p></li>
<li><p><strong>Using Vector Notation.</strong> The sum in the exponent, i.e., <span class="math display">\[
\sum_{i=1}^n(Y(\vec{x}^{(i)})-\mu)^2
\]</span> is equivalent to <span class="math display">\[
(\vec{y} - \vec{1}\mu)^T (\vec{y} - \vec{1}\mu),
\]</span> assuming <span class="math inline">\(Y(\vec{x}^{(i)}) = y^{(i)}\)</span> and using vector notation for <span class="math inline">\(\vec{y}\)</span> and <span class="math inline">\(\vec{1}\mu\)</span>.</p></li>
<li><p><strong>Assuming Independent Observations:</strong> <a href="#eq-likelihood-55-a" class="quarto-xref">Equation&nbsp;<span>9.6</span></a> assumes that the observations are independent, which means that the covariance between any two observations <span class="math inline">\(Y(\vec{x}^{(i)})\)</span> and <span class="math inline">\(Y(\vec{x}^{(l)})\)</span> is zero for <span class="math inline">\(i \neq l\)</span>. In this case, the covariance matrix of the observations would be a diagonal matrix with <span class="math inline">\(\sigma^2\)</span> along the diagonal (i.e., <span class="math inline">\(\sigma^2 I\)</span>), where <span class="math inline">\(I\)</span> is the identity matrix.</p></li>
<li><p><strong>Stochastic Process and Correlation:</strong> In the context of Kriging, the observed responses <span class="math inline">\(\vec{y}\)</span> are considered as if they are from a <em>stochastic process</em> or <em>random field</em>. This means the random variables <span class="math inline">\(Y(\vec{x}^{(i)})\)</span> at different locations <span class="math inline">\(\vec{x}^{(i)}\)</span> are not independent, but they correlated with each other. This correlation is described by an <span class="math inline">\((n \times n)\)</span> <strong>correlation matrix <span class="math inline">\(\Psi\)</span></strong>, which is used instead of <span class="math inline">\(\sigma^2 I\)</span>. The strength of the correlation between two points <span class="math inline">\(Y(\vec{x}^{(i)})\)</span> and <span class="math inline">\(Y(\vec{x}^{(l)})\)</span> depends on the distance between them and model parameters <span class="math inline">\(\theta_j\)</span> and <span class="math inline">\(p_j\)</span>.</p></li>
<li><p><strong>Multivariate Normal Distribution:</strong> When random variables are correlated, their joint probability distribution is generally described by a <em>multivariate distribution</em>. Assuming the stochastic process follows a Gaussian process, the joint distribution of the observed responses <span class="math inline">\(\vec{y}\)</span> is a <strong>multivariate normal distribution</strong>. A multivariate normal distribution for a vector <span class="math inline">\(\vec{Y}\)</span> with mean vector <span class="math inline">\(\vec{\mu}\)</span> and covariance matrix <span class="math inline">\(\Sigma\)</span> has a probability density function given by: <span class="math display">\[
p(\vec{y}) = \frac{1}{\sqrt{(2\pi)^n |\Sigma|}} \exp\left[ -\frac{1}{2}(\vec{y} - \vec{\mu})^T \Sigma^{-1}(\vec{y} - \vec{\mu}) \right].
\]</span></p></li>
<li><p><strong>Connecting the Expressions:</strong> In the stochastic process framework, the following holds:</p>
<ul>
<li>The mean vector of the observed data <span class="math inline">\(\vec{y}\)</span> is <span class="math inline">\(\vec{1}\mu\)</span>.</li>
<li>The covariance matrix <span class="math inline">\(\Sigma\)</span> is constructed by considering both the variance <span class="math inline">\(\sigma^2\)</span> and the correlations <span class="math inline">\(\Psi\)</span>.</li>
<li>The covariance between <span class="math inline">\(Y(\vec{x}^{(i)})\)</span> and <span class="math inline">\(Y(\vec{x}^{(l)})\)</span> is <span class="math inline">\(\sigma^2 \text{cor}(Y(\vec{x}^{(i)}), Y(\vec{x}^{(l)}))\)</span>.</li>
<li>Therefore, the covariance matrix is <span class="math inline">\(\Sigma = \sigma^2 \vec{\Psi}\)</span>.</li>
<li>Substituting <span class="math inline">\(\vec{\mu} = \vec{1}\mu\)</span> and <span class="math inline">\(\Sigma = \sigma^2 \vec{\Psi}\)</span> into the multivariate normal PDF formula, we get: <span class="math display">\[
\Sigma^{-1} = (\sigma^2 \vec{\Psi})^{-1} = \frac{1}{\sigma^2} \vec{\Psi}^{-1}
\]</span> and <span class="math display">\[
|\Sigma| = |\sigma^2 \vec{\Psi}| = (\sigma^2)^n |\vec{\Psi}|.
\]</span> The PDF becomes: <span class="math display">\[
p(\vec{y}) = \frac{1}{\sqrt{(2\pi)^n (\sigma^2)^n |\vec{\Psi}|}} \exp\left[ -\frac{1}{2}(\vec{y} - \vec{1}\mu)^T \left(\frac{1}{\sigma^2} \vec{\Psi}^{-1}\right)(\vec{y} - \vec{1}\mu) \right]
\]</span> and simplifies to: <span class="math display">\[
p(\vec{y}) = \frac{1}{(2\pi \sigma^2)^{n/2} |\vec{\Psi}|^{1/2}} \exp\left[ -\frac{1}{2\sigma^2}(\vec{y} - \vec{1}\mu)^T \vec{\Psi}^{-1}(\vec{y} - \vec{1}\mu) \right].
\]</span> This is the <strong>likelihood of the sample data <span class="math inline">\(\vec{y}\)</span></strong> given the parameters <span class="math inline">\(\mu\)</span>, <span class="math inline">\(\sigma\)</span>, and the correlation structure defined by the parameters within <span class="math inline">\(\vec{\Psi}\)</span> (i.e., <span class="math inline">\(\vec{\theta}\)</span> and <span class="math inline">\(\vec{p}\)</span>).</li>
</ul></li>
</ol>
<p>In summary, the <a href="#eq-likelihood-55-a" class="quarto-xref">Equation&nbsp;<span>9.6</span></a> represents the likelihood under a simplified assumption of independent errors, whereas <a href="#eq-likelihood-55" class="quarto-xref">Equation&nbsp;<span>9.7</span></a> is the likelihood derived from the assumption that the observed data comes from a <strong>multivariate normal distribution</strong> where observations are correlated according to the matrix <span class="math inline">\(\vec{\Psi}\)</span>. <a href="#eq-likelihood-55" class="quarto-xref">Equation&nbsp;<span>9.7</span></a>, using the sample data vector <span class="math inline">\(\vec{y}\)</span> and the correlation matrix <span class="math inline">\(\vec{\Psi}\)</span>, properly accounts for the dependencies between data points inherent in the stochastic process model. Maximizing this likelihood is how the correlation parameters <span class="math inline">\(\vec{\theta}\)</span> and <span class="math inline">\(\vec{p}\)</span> are estimated in Kriging.</p>
<p><span class="math inline">\(\Box\)</span></p>
</div>
<p><a href="#eq-likelihood-55" class="quarto-xref">Equation&nbsp;<span>9.7</span></a> can be formulated as the log-likelihood: <span id="eq-loglikelihood-55"><span class="math display">\[
\ln(L) = - \frac{n}{2} \ln(2\pi \sigma) - \frac{1}{2} \ln |\vec{\Psi}| - \frac{(\vec{y} - \vec{1}\mu)^T \vec{\Psi}^{-1}(\vec{y} - \vec{1}\mu) }{2 \sigma^2}.
\tag{9.8}\]</span></span></p>
</section>
<section id="differentiation-with-respect-to-mu" class="level3" data-number="9.3.2">
<h3 data-number="9.3.2" class="anchored" data-anchor-id="differentiation-with-respect-to-mu"><span class="header-section-number">9.3.2</span> Differentiation with Respect to <span class="math inline">\(\mu\)</span></h3>
<p>Looking at the log-likelihood function, only the last term depends on <span class="math inline">\(\mu\)</span>:</p>
<p><span class="math display">\[
\frac{1}{2 \sigma^2} (\vec{y} - \vec{1}\mu)^T \vec{\Psi}^{-1} (\vec{y} - \vec{1}\mu)
\]</span></p>
<p>To differentiate this with respect to the scalar <span class="math inline">\(\mu\)</span>, we can use matrix calculus rules.</p>
<p>Let <span class="math inline">\(\mathbf{v} = \vec{y} - \vec{1}\mu\)</span>. <span class="math inline">\(\vec{y}\)</span> is a constant vector with respect to <span class="math inline">\(\mu\)</span>, and <span class="math inline">\(\vec{1}\mu\)</span> is a vector whose derivative with respect to the scalar <span class="math inline">\(\mu\)</span> is <span class="math inline">\(\vec{1}\)</span>. So, <span class="math inline">\(\frac{\partial \mathbf{v}}{\partial \mu} = -\vec{1}\)</span>.</p>
<p>The term is in the form <span class="math inline">\(\mathbf{v}^T \mathbf{A} \mathbf{v}\)</span>, where <span class="math inline">\(\mathbf{A} = \vec{\Psi}^{-1}\)</span> is a symmetric matrix. The derivative of <span class="math inline">\(\mathbf{v}^T \mathbf{A} \mathbf{v}\)</span> with respect to <span class="math inline">\(\mathbf{v}\)</span> is <span class="math inline">\(2 \mathbf{A} \mathbf{v}\)</span> as explained in <a href="#rem-derivative-quadratic-form" class="quarto-xref">Remark&nbsp;<span>9.3</span></a>.</p>
<div id="rem-derivative-quadratic-form" class="proof remark">
<p><span class="proof-title"><em>Remark 9.3</em> (Derivative of a Quadratic Form). </span>Consider the derivative of <span class="math inline">\(\mathbf{v}^T \mathbf{A} \mathbf{v}\)</span> with respect to <span class="math inline">\(\mathbf{v}\)</span>:</p>
<ul>
<li>The derivative of a scalar function <span class="math inline">\(f(\mathbf{v})\)</span> with respect to a vector <span class="math inline">\(\mathbf{v}\)</span> is a vector (the gradient).</li>
<li>For a quadratic form <span class="math inline">\(\mathbf{v}^T \mathbf{A} \mathbf{v}\)</span>, where <span class="math inline">\(\mathbf{A}\)</span> is a matrix and <span class="math inline">\(\mathbf{v}\)</span> is a vector, the general formula for the derivative with respect to <span class="math inline">\(\mathbf{v}\)</span> is <span class="math inline">\(\frac{\partial}{\partial \mathbf{v}} (\mathbf{v}^T \mathbf{A} \mathbf{v}) = \mathbf{A} \mathbf{v} + \mathbf{A}^T \mathbf{v}\)</span>. (This is a standard result in matrix calculus and explained in <a href="006_matrices.html#eq-derivative-quadratic-form" class="quarto-xref">Equation&nbsp;<span>10.1</span></a>).</li>
<li>Since <span class="math inline">\(\mathbf{A} = \vec{\Psi}^{-1}\)</span> is a symmetric matrix, its transpose <span class="math inline">\(\mathbf{A}^T\)</span> is equal to <span class="math inline">\(\mathbf{A}\)</span>.</li>
<li>Substituting <span class="math inline">\(\mathbf{A}^T = \mathbf{A}\)</span> into the general derivative formula, we get <span class="math inline">\(\mathbf{A} \mathbf{v} + \mathbf{A} \mathbf{v} = 2 \mathbf{A} \mathbf{v}\)</span>.</li>
</ul>
<p><span class="math inline">\(\Box\)</span></p>
</div>
<p>Using the chain rule for differentiation with respect to the scalar <span class="math inline">\(\mu\)</span>: <span class="math display">\[ \frac{\partial}{\partial \mu} (\mathbf{v}^T \mathbf{A} \mathbf{v}) = 2 \left(\frac{\partial \mathbf{v}}{\partial \mu}\right)^T \mathbf{A} \mathbf{v} \]</span> Substituting <span class="math inline">\(\frac{\partial \mathbf{v}}{\partial \mu} = -\vec{1}\)</span> and <span class="math inline">\(\mathbf{v} = \vec{y} - \vec{1}\mu\)</span>: <span class="math display">\[
\frac{\partial}{\partial \mu} (\vec{y} - \vec{1}\mu)^T \vec{\Psi}^{-1} (\vec{y} - \vec{1}\mu) = 2 (-\vec{1})^T \vec{\Psi}^{-1} (\vec{y} - \vec{1}\mu) = -2 \vec{1}^T \vec{\Psi}^{-1} (\vec{y} - \vec{1}\mu)
\]</span></p>
<p>Now, differentiate the full log-likelihood term depending on <span class="math inline">\(\mu\)</span>:</p>
<p><span class="math display">\[
\frac{\partial}{\partial \mu} \left( - \frac{1}{2 \sigma^2} (\vec{y} - \vec{1}\mu)^T \vec{\Psi}^{-1} (\vec{y} - \vec{1}\mu) \right) = - \frac{1}{2 \sigma^2} \left( -2 \vec{1}^T \vec{\Psi}^{-1} (\vec{y} - \vec{1}\mu) \right) = \frac{1}{\sigma^2} \vec{1}^T \vec{\Psi}^{-1} (\vec{y} - \vec{1}\mu)
\]</span></p>
<p>Setting this to zero for maximization gives:</p>
<p><span class="math display">\[
\frac{1}{\sigma^2} \vec{1}^T \vec{\Psi}^{-1} (\vec{y} - \vec{1}\mu) = 0.
\]</span></p>
<p>Rearranging gives: <span class="math display">\[
\vec{1}^T \vec{\Psi}^{-1} (\vec{y} - \vec{1}\mu) = 0.
\]</span></p>
<p>Solving for <span class="math inline">\(\mu\)</span> gives: <span class="math display">\[
\vec{1}^T \vec{\Psi}^{-1} \vec{y} = \mu \vec{1}^T \vec{\Psi}^{-1} \vec{1}.
\]</span></p>
</section>
<section id="differentiation-with-respect-to-sigma" class="level3" data-number="9.3.3">
<h3 data-number="9.3.3" class="anchored" data-anchor-id="differentiation-with-respect-to-sigma"><span class="header-section-number">9.3.3</span> Differentiation with Respect to <span class="math inline">\(\sigma\)</span></h3>
<p>Let <span class="math inline">\(\nu = \sigma^2\)</span> for simpler differentiation notation. The log-likelihood becomes: <span class="math display">\[
\ln(L) = C_1 - \frac{n}{2} \ln(\nu) - \frac{(\vec{y} - \vec{1}\mu)^T \vec{\Psi}^{-1}(\vec{y} - \vec{1}\mu)}{2\nu},
\]</span> where <span class="math inline">\(C_1 = - \frac{n}{2} \ln(2\pi) - \frac{1}{2} \ln |\vec{\Psi}|\)</span> is a constant with respect to <span class="math inline">\(\nu = \sigma^2\)</span>.</p>
<p>We differentiate with respect to <span class="math inline">\(\nu\)</span>: <span class="math display">\[
\frac{\partial \ln(L)}{\partial \nu} = \frac{\partial}{\partial \nu} \left( -\frac{n}{2} \ln(\nu) \right) + \frac{\partial}{\partial \nu} \left( - \frac{(\vec{y} - \vec{1}\mu)^T \vec{\Psi}^{-1}(\vec{y} - \vec{1}\mu)}{2\nu} \right).
\]</span></p>
<p>The first term’s derivative is straightforward: <span class="math display">\[
\frac{\partial}{\partial \nu} \left( -\frac{n}{2} \ln(\nu) \right) = -\frac{n}{2} \cdot \frac{1}{\nu} = -\frac{n}{2\sigma^2}.
\]</span></p>
<p>For the second term, let <span class="math inline">\(C_2 = (\vec{y} - \vec{1}\mu)^T \vec{\Psi}^{-1}(\vec{y} - \vec{1}\mu)\)</span>. This term is constant with respect to <span class="math inline">\(\sigma^2\)</span>. The derivative is:</p>
<p><span class="math display">\[
\frac{\partial}{\partial \nu} \left( - \frac{C_2}{2\nu} \right) = - \frac{C_2}{2} \frac{\partial}{\partial \nu} (\nu^{-1}) = - \frac{C_2}{2} (-\nu^{-2}) = \frac{C_2}{2\nu^2} = \frac{(\vec{y} - \vec{1}\mu)^T \vec{\Psi}^{-1}(\vec{y} - \vec{1}\mu)}{2(\sigma^2)^2}.
\]</span></p>
<p>Combining the derivatives, the gradient of the log-likelihood with respect to <span class="math inline">\(\sigma^2\)</span> is: <span class="math display">\[
\frac{\partial \ln(L)}{\partial \sigma^2} = -\frac{n}{2\sigma^2} + \frac{(\vec{y} - \vec{1}\mu)^T \vec{\Psi}^{-1}(\vec{y} - \vec{1}\mu)}{2(\sigma^2)^2}.
\]</span></p>
<p>Setting this to zero for maximization gives: <span class="math display">\[
-\frac{n}{2\sigma^2} + \frac{(\vec{y} - \vec{1}\mu)^T \vec{\Psi}^{-1}(\vec{y} - \vec{1}\mu)}{2(\sigma^2)^2} = 0.
\]</span></p>
</section>
<section id="results-of-the-optimizations" class="level3" data-number="9.3.4">
<h3 data-number="9.3.4" class="anchored" data-anchor-id="results-of-the-optimizations"><span class="header-section-number">9.3.4</span> Results of the Optimizations</h3>
<p>Optimization of the log-likelihood by taking derivatives with respect to <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> results in <span id="eq-muhat-55"><span class="math display">\[
\hat{\mu} = \frac{\vec{1}^T \vec{\Psi}^{-1} \vec{y}^T}{\vec{1}^T \vec{\Psi}^{-1} \vec{1}^T}
\tag{9.9}\]</span></span> and <span id="eq-sigmahat-55"><span class="math display">\[
\hat{\sigma}^2 = \frac{(\vec{y} - \vec{1}\mu)^T \vec{\Psi}^{-1}(\vec{y} - \vec{1}\mu)}{n}.
\tag{9.10}\]</span></span></p>
</section>
<section id="the-concentrated-log-likelihood-function" class="level3" data-number="9.3.5">
<h3 data-number="9.3.5" class="anchored" data-anchor-id="the-concentrated-log-likelihood-function"><span class="header-section-number">9.3.5</span> The Concentrated Log-Likelihood Function</h3>
<p>Combining the equations, i.e., substituting <a href="#eq-muhat-55" class="quarto-xref">Equation&nbsp;<span>9.9</span></a> and <a href="#eq-sigmahat-55" class="quarto-xref">Equation&nbsp;<span>9.10</span></a> into <a href="#eq-loglikelihood-55" class="quarto-xref">Equation&nbsp;<span>9.8</span></a> leads to the concentrated log-likelihood function: <span id="eq-concentrated-loglikelihood"><span class="math display">\[
\ln(L) \approx - \frac{n}{2} \ln(\hat{\sigma}) - \frac{1}{2} \ln |\vec{\Psi}|.
\tag{9.11}\]</span></span></p>
<div id="rem-concentrated-loglikelihood" class="proof remark">
<p><span class="proof-title"><em>Remark 9.4</em> (The Concentrated Log-Likelihood). </span></p>
<ul>
<li>The first term in <a href="#eq-concentrated-loglikelihood" class="quarto-xref">Equation&nbsp;<span>9.11</span></a> requires information about the measured point (observations) <span class="math inline">\(y_i\)</span>.</li>
<li>To maximize <span class="math inline">\(\ln(L)\)</span>, optimal values of <span class="math inline">\(\vec{\theta}\)</span> and <span class="math inline">\(\vec{p}\)</span> are determined numerically, because the function (<a href="#eq-concentrated-loglikelihood" class="quarto-xref">Equation&nbsp;<span>9.11</span></a>) is not differentiable.</li>
</ul>
<p><span class="math inline">\(\Box\)</span></p>
</div>
</section>
<section id="optimizing-the-parameters-vectheta-and-vecp" class="level3" data-number="9.3.6">
<h3 data-number="9.3.6" class="anchored" data-anchor-id="optimizing-the-parameters-vectheta-and-vecp"><span class="header-section-number">9.3.6</span> Optimizing the Parameters <span class="math inline">\(\vec{\theta}\)</span> and <span class="math inline">\(\vec{p}\)</span></h3>
<p>The concentrated log-likelihood function is very quick to compute. We do not need a statistical model, because we are only interested in the maximum likelihood estimate (MLE) of <span class="math inline">\(\theta\)</span> and <span class="math inline">\(p\)</span>. Optimizers such as Nelder-Mead, Conjugate Gradient, or Simulated Annealing can be used to determine optimal values for <span class="math inline">\(\theta\)</span> and <span class="math inline">\(p\)</span>. After the optimization, the correlation matrix <span class="math inline">\(\Psi\)</span> is build with the optimized <span class="math inline">\(\theta\)</span> and <span class="math inline">\(p\)</span> values. This is best (most likely) Kriging model for the given data <span class="math inline">\(y\)</span>.</p>
<p>Observing <a href="#fig-theta12" class="quarto-xref">Figure&nbsp;<span>9.2</span></a>, there’s significant change between <span class="math inline">\(\theta = 0.1\)</span> and <span class="math inline">\(\theta = 1\)</span>, just as there is between <span class="math inline">\(\theta = 1\)</span> and <span class="math inline">\(\theta = 10\)</span>. Hence, it is sensible to search for <span class="math inline">\(\theta\)</span> on a logarithmic scale. Suitable search bounds typically range from <span class="math inline">\(10^{-3}\)</span> to <span class="math inline">\(10^2\)</span>, although this is not a stringent requirement. Importantly, the scaling of the observed data does not affect the values of <span class="math inline">\(\hat{\theta}\)</span>, but the scaling of the design space does. Therefore, it is advisable to consistently scale variable ranges between zero and one to ensure consistency in the degree of activity <span class="math inline">\(\hat{\theta}_j\)</span> represents across different problems.</p>
</section>
<section id="correlation-and-covariance-matrices-revisited" class="level3" data-number="9.3.7">
<h3 data-number="9.3.7" class="anchored" data-anchor-id="correlation-and-covariance-matrices-revisited"><span class="header-section-number">9.3.7</span> Correlation and Covariance Matrices Revisited</h3>
<p>The covariance matrix <span class="math inline">\(\Sigma\)</span> is constructed by considering both the variance <span class="math inline">\(\sigma^2\)</span> and the correlation matrix <span class="math inline">\(\Psi\)</span>. They are related as follows:</p>
<ol type="1">
<li><strong>Covariance vs.&nbsp;Correlation:</strong> Covariance is a measure of the joint variability of two random variables, while correlation is a standardized measure of this relationship, ranging from -1 to 1. The relationship between covariance and correlation for two random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is given by <span class="math inline">\(\text{cor}(X, Y) = \text{cov}(X, Y) / (\sigma_X \sigma_Y)\)</span>, where <span class="math inline">\(\sigma_X\)</span> and <span class="math inline">\(\sigma_Y\)</span> are their standard deviations.</li>
<li><strong>The Covariance Matrix <span class="math inline">\(\Sigma\)</span>:</strong> The <strong>covariance matrix <span class="math inline">\(\Sigma\)</span></strong> (or <span class="math inline">\(\text{Cov}(Y, Y)\)</span> for the vector <span class="math inline">\(\vec{Y}\)</span>) captures the <strong>pairwise covariances</strong> between all elements of the vector of observed responses.</li>
<li><strong>Connecting <span class="math inline">\(\sigma^2\)</span> and <span class="math inline">\(\Psi\)</span> to <span class="math inline">\(\Sigma\)</span>:</strong> In the Kriging framework described, the variance of each observation is often assumed to be constant, <span class="math inline">\(\sigma^2\)</span>. The covariance between any two observations <span class="math inline">\(Y(\vec{x}^{(i)})\)</span> and <span class="math inline">\(Y(\vec{x}^{(l)})\)</span> is given by <span class="math inline">\(\sigma^2\)</span> multiplied by their correlation. That is, <span class="math display">\[
\text{cov}(Y(\vec{x}^{(i)}), Y(\vec{x}^{(l)})) = \sigma^2 \text{cor}(Y(\vec{x}^{(i)}), Y(\vec{x}^{(l)})).
\]</span> This relationship holds for <em>all</em> pairs of points. When expressed in matrix form, the covariance matrix <span class="math inline">\(\Sigma\)</span> is the product of the variance <span class="math inline">\(\sigma^2\)</span> (a scalar) and the correlation matrix <span class="math inline">\(\Psi\)</span>: <span class="math display">\[
\Sigma = \sigma^2 \Psi.
\]</span></li>
</ol>
<p>In essence, the correlation matrix <span class="math inline">\(\Psi\)</span> defines the <em>structure</em> or <em>shape</em> of the dependencies between the data points based on their locations. The parameter <span class="math inline">\(\sigma^2\)</span> acts as a <strong>scaling factor</strong> that converts these unitless correlation values (which are between -1 and 1) into actual covariance values with units of variance, setting the overall level of variability in the system.</p>
<p>So, <span class="math inline">\(\sigma^2\)</span> tells us about the general spread or variability of the underlying process, while <span class="math inline">\(\Psi\)</span> tells you <em>how</em> that variability is distributed and how strongly points are related to each other based on their positions. Together, they completely define the covariance structure of your observed data in the multivariate normal distribution used in Kriging.</p>
</section>
</section>
<section id="implementing-an-mle-of-the-model-parameters" class="level2" data-number="9.4">
<h2 data-number="9.4" class="anchored" data-anchor-id="implementing-an-mle-of-the-model-parameters"><span class="header-section-number">9.4</span> Implementing an MLE of the Model Parameters</h2>
<p>The matrix algebra necessary for calculating the likelihood is the most computationally intensive aspect of the Kriging process. It is crucial to ensure that the code implementation is as efficient as possible.</p>
<p>Given that <span class="math inline">\(\Psi\)</span> (our correlation matrix) is symmetric, only half of the matrix needs to be computed before adding it to its transpose. When calculating the log-likelihood, several matrix inversions are required. The fastest approach is to conduct one Cholesky factorization and then apply backward and forward substitution for each inverse.</p>
<p>The Cholesky factorization is applicable only to positive-definite matrices, which <span class="math inline">\(\Psi\)</span> generally is. However, if <span class="math inline">\(\Psi\)</span> becomes nearly singular, such as when the <span class="math inline">\(\vec{x}^{(i)}\)</span>’s are densely packed, the Cholesky factorization might fail. In these cases, one could employ an LU-decomposition, though the result might be unreliable. When <span class="math inline">\(\Psi\)</span> is near singular, the best course of action is to either use regression techniques or, as we do here, assign a poor likelihood value to parameters generating the near singular matrix, thus diverting the MLE search towards better-conditioned <span class="math inline">\(\Psi\)</span> matrices.</p>
<p>When working with correlation matrices, increasing the values on the main diagonal of a matrix will increase the absolute value of its determinant. A critical numerical consideration in calculating the concentrated log-likelihood is that for poorly conditioned matrices, <span class="math inline">\(\det(\Psi)\)</span> approaches zero, leading to potential numerical instability. To address this issue, it is advisable to calculate <span class="math inline">\(\ln(\lvert\Psi\rvert)\)</span> in <a href="#eq-concentrated-loglikelihood" class="quarto-xref">Equation&nbsp;<span>9.11</span></a> using twice the sum of the logarithms of the diagonal elements of the Cholesky factorization. This approach provides a more numerically stable method for computing the log-determinant, as the Cholesky decomposition <span class="math inline">\(\Psi = L L^T\)</span> allows us to express <span class="math inline">\(\ln(\lvert\Psi\rvert) = 2\sum_{i=1}^{n} \ln(L_{ii})\)</span>, avoiding the direct computation of potentially very small determinant values.</p>
</section>
<section id="kriging-prediction" class="level2" data-number="9.5">
<h2 data-number="9.5" class="anchored" data-anchor-id="kriging-prediction"><span class="header-section-number">9.5</span> Kriging Prediction</h2>
<p>We will use the Kriging correlation <span class="math inline">\(\Psi\)</span> to predict new values based on the observed data. The presentation follows the approach described in <span class="citation" data-cites="Forr08a">Forrester, Sóbester, and Keane (<a href="references.html#ref-Forr08a" role="doc-biblioref">2008</a>)</span> and <span class="citation" data-cites="bart21i">Bartz et al. (<a href="references.html#ref-bart21i" role="doc-biblioref">2022</a>)</span>.</p>
<p>Main idea for prediction is that the new <span class="math inline">\(Y(\vec{x})\)</span> should be consistent with the old sample data <span class="math inline">\(X\)</span>. For a new prediction <span class="math inline">\(\hat{y}\)</span> at <span class="math inline">\(\vec{x}\)</span>, the value of <span class="math inline">\(\hat{y}\)</span> is chosen so that it maximizes the likelihood of the sample data <span class="math inline">\(X\)</span> and the prediction, given the (optimized) correlation parameter <span class="math inline">\(\vec{\theta}\)</span> and <span class="math inline">\(\vec{p}\)</span> from above. The observed data <span class="math inline">\(\vec{y}\)</span> is augmented with the new prediction <span class="math inline">\(\hat{y}\)</span> which results in the augmented vector <span class="math inline">\(\vec{\tilde{y}} = ( \vec{y}^T, \hat{y})^T\)</span>. A vector of correlations between the observed data and the new prediction is defined as</p>
<p><span class="math display">\[ \vec{\psi} = \begin{pmatrix}
\text{cor}\left(
Y(\vec{x}^{(1)}),
Y(\vec{x})
\right) \\
\vdots  \\
\text{cor}\left(
Y(\vec{x}^{(n)}),
Y(\vec{x})
\right)
\end{pmatrix}
=
\begin{pmatrix}
\vec{\psi}^{(1)}\\
\vdots\\
\vec{\psi}^{(n)}
\end{pmatrix}.
\]</span></p>
<div id="def-augmented-correlation-matrix" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 9.2 (The Augmented Correlation Matrix)</strong></span> The augmented correlation matrix is constructed as <span class="math display">\[ \tilde{\vec{\Psi}} =
\begin{pmatrix}
\vec{\Psi} &amp; \vec{\psi} \\
\vec{\psi}^T &amp; 1
\end{pmatrix}.
\]</span></p>
<p><span class="math inline">\(\Box\)</span></p>
</div>
<p>The log-likelihood of the augmented data is <span id="eq-loglikelihood-augmented"><span class="math display">\[
\ln(L) = - \frac{n}{2} \ln(2\pi) - \frac{n}{2} \ln(\hat{\sigma}^2) - \frac{1}{2} \ln |\vec{\hat{\Psi}}| -  \frac{(\vec{\tilde{y}} - \vec{1}\hat{\mu})^T \vec{\tilde{\Psi}}^{-1}(\vec{\tilde{y}} - \vec{1}\hat{\mu})}{2 \hat{\sigma}^2},
\tag{9.12}\]</span></span></p>
<p>where <span class="math inline">\(\vec{1}\)</span> is a vector of ones and <span class="math inline">\(\hat{\mu}\)</span> and <span class="math inline">\(\hat{\sigma}^2\)</span> are the MLEs from <a href="#eq-muhat-55" class="quarto-xref">Equation&nbsp;<span>9.9</span></a> and <a href="#eq-sigmahat-55" class="quarto-xref">Equation&nbsp;<span>9.10</span></a>. Only the last term in <a href="#eq-loglikelihood-augmented" class="quarto-xref">Equation&nbsp;<span>9.12</span></a> depends on <span class="math inline">\(\hat{y}\)</span>, so we need only consider this term in the maximization. Details can be found in <span class="citation" data-cites="Forr08a">Forrester, Sóbester, and Keane (<a href="references.html#ref-Forr08a" role="doc-biblioref">2008</a>)</span>. Finally, the MLE for <span class="math inline">\(\hat{y}\)</span> can be calculated as <span id="eq-mle-yhat"><span class="math display">\[
\hat{y}(\vec{x}) = \hat{\mu} + \vec{\psi}^T \vec{\tilde{\Psi}}^{-1} (\vec{y} - \vec{1}\hat{\mu}).
\tag{9.13}\]</span></span></p>
<p><a href="#eq-mle-yhat" class="quarto-xref">Equation&nbsp;<span>9.13</span></a> reveals two important properties of the Kriging predictor:</p>
<ul>
<li>Basis functions: The basis function impacts the vector <span class="math inline">\(\vec{\psi}\)</span>, which contains the <span class="math inline">\(n\)</span> correlations between the new point <span class="math inline">\(\vec{x}\)</span> and the observed locations. Values from the <span class="math inline">\(n\)</span> basis functions are added to a mean base term <span class="math inline">\(\mu\)</span> with weightings <span class="math display">\[
\vec{w} = \vec{\tilde{\Psi}}^{(-1)} (\vec{y} - \vec{1}\hat{\mu}).
\]</span></li>
<li>Interpolation: The predictions interpolate the sample data. When calculating the prediction at the <span class="math inline">\(i\)</span>th sample point, <span class="math inline">\(\vec{x}^{(i)}\)</span>, the <span class="math inline">\(i\)</span>th column of <span class="math inline">\(\vec{\Psi}^{-1}\)</span> is <span class="math inline">\(\vec{\psi}\)</span>, and <span class="math inline">\(\vec{\psi}  \vec{\Psi}^{-1}\)</span> is the <span class="math inline">\(i\)</span>th unit vector. Hence,</li>
</ul>
<p><span class="math display">\[
\hat{y}(\vec{x}^{(i)}) = y^{(i)}.
\]</span></p>
</section>
<section id="kriging-example-sinusoid-function" class="level2" data-number="9.6">
<h2 data-number="9.6" class="anchored" data-anchor-id="kriging-example-sinusoid-function"><span class="header-section-number">9.6</span> Kriging Example: Sinusoid Function</h2>
<p>Toy example in 1d where the response is a simple sinusoid measured at eight equally spaced <span class="math inline">\(x\)</span>-locations in the span of a single period of oscillation.</p>
<section id="calculating-the-correlation-matrix-psi" class="level3" data-number="9.6.1">
<h3 data-number="9.6.1" class="anchored" data-anchor-id="calculating-the-correlation-matrix-psi"><span class="header-section-number">9.6.1</span> Calculating the Correlation Matrix <span class="math inline">\(\Psi\)</span></h3>
<p>The correlation matrix <span class="math inline">\(\Psi\)</span> is based on the pairwise squared distances between the input locations. Here we will use <span class="math inline">\(n=8\)</span> sample locations and <span class="math inline">\(\theta\)</span> is set to 1.0.</p>
<div id="290d757b" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">2</span><span class="op">*</span>np.pi, n, endpoint<span class="op">=</span><span class="va">False</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(np.<span class="bu">round</span>(X, <span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[0.  ]
 [0.79]
 [1.57]
 [2.36]
 [3.14]
 [3.93]
 [4.71]
 [5.5 ]]</code></pre>
</div>
</div>
<p>Evaluate at sample points</p>
<div id="f452f28a" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.sin(X)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(np.<span class="bu">round</span>(y, <span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[ 0.  ]
 [ 0.71]
 [ 1.  ]
 [ 0.71]
 [ 0.  ]
 [-0.71]
 [-1.  ]
 [-0.71]]</code></pre>
</div>
</div>
<p>We have the data points shown in <a href="#tbl-sin-data" class="quarto-xref">Table&nbsp;<span>9.1</span></a>.</p>
<div id="tbl-sin-data" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-sin-data-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;9.1: Data points for the sinusoid function
</figcaption>
<div aria-describedby="tbl-sin-data-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: right;"><span class="math inline">\(x\)</span></th>
<th style="text-align: right;"><span class="math inline">\(y\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0.0</td>
<td style="text-align: right;">0.0</td>
</tr>
<tr class="even">
<td style="text-align: right;">0.79</td>
<td style="text-align: right;">0.71</td>
</tr>
<tr class="odd">
<td style="text-align: right;">1.57</td>
<td style="text-align: right;">1.0</td>
</tr>
<tr class="even">
<td style="text-align: right;">2.36</td>
<td style="text-align: right;">0.71</td>
</tr>
<tr class="odd">
<td style="text-align: right;">3.14</td>
<td style="text-align: right;">0.0</td>
</tr>
<tr class="even">
<td style="text-align: right;">3.93</td>
<td style="text-align: right;">-0.71</td>
</tr>
<tr class="odd">
<td style="text-align: right;">4.71</td>
<td style="text-align: right;">-1.0</td>
</tr>
<tr class="even">
<td style="text-align: right;">5.5</td>
<td style="text-align: right;">-0.71</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>The data points are visualized in <a href="#fig-sin-data" class="quarto-xref">Figure&nbsp;<span>9.4</span></a>.</p>
<div id="cell-fig-sin-data" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>plt.plot(X, y, <span class="st">"bo"</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f"Sin(x) evaluated at </span><span class="sc">{</span>n<span class="sc">}</span><span class="ss"> points"</span>)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div id="fig-sin-data" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sin-data-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="006_num_gp_files/figure-html/fig-sin-data-output-1.png" width="590" height="431" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sin-data-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.4: Sin(x) evaluated at 8 points.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="computing-the-psi-matrix" class="level3" data-number="9.6.2">
<h3 data-number="9.6.2" class="anchored" data-anchor-id="computing-the-psi-matrix"><span class="header-section-number">9.6.2</span> Computing the <span class="math inline">\(\Psi\)</span> Matrix</h3>
<p>We will use the <code>build_Psi</code> function from <a href="#exm-corr-matrix-existing" class="quarto-xref">Example&nbsp;<span>9.4</span></a> to compute the correlation matrix <span class="math inline">\(\Psi\)</span>. <span class="math inline">\(\theta\)</span> should be an array of one value, because we are only working in one dimension (<span class="math inline">\(k=1\)</span>).</p>
<div id="6e44fffc" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>theta <span class="op">=</span> np.array([<span class="fl">1.0</span>])</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>Psi <span class="op">=</span> build_Psi(X, theta)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(np.<span class="bu">round</span>(Psi, <span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[1.   0.54 0.08 0.   0.   0.   0.   0.  ]
 [0.54 1.   0.54 0.08 0.   0.   0.   0.  ]
 [0.08 0.54 1.   0.54 0.08 0.   0.   0.  ]
 [0.   0.08 0.54 1.   0.54 0.08 0.   0.  ]
 [0.   0.   0.08 0.54 1.   0.54 0.08 0.  ]
 [0.   0.   0.   0.08 0.54 1.   0.54 0.08]
 [0.   0.   0.   0.   0.08 0.54 1.   0.54]
 [0.   0.   0.   0.   0.   0.08 0.54 1.  ]]</code></pre>
</div>
</div>
<p><a href="#fig-sin-corr" class="quarto-xref">Figure&nbsp;<span>9.5</span></a> visualizes the <span class="math inline">\((8, 8)\)</span> correlation matrix <span class="math inline">\(\Psi\)</span>.</p>
<div id="cell-fig-sin-corr" class="cell" data-execution_count="15">
<div class="cell-output cell-output-display">
<div id="fig-sin-corr" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sin-corr-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="006_num_gp_files/figure-html/fig-sin-corr-output-1.png" width="482" height="416" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sin-corr-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.5: Correlation matrix <span class="math inline">\(\Psi\)</span> for the sinusoid function.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="selecting-the-new-locations" class="level3" data-number="9.6.3">
<h3 data-number="9.6.3" class="anchored" data-anchor-id="selecting-the-new-locations"><span class="header-section-number">9.6.3</span> Selecting the New Locations</h3>
<p>We would like to predict at <span class="math inline">\(m = 100\)</span> new locations (or testign locations) in the interval <span class="math inline">\([0, 2\pi]\)</span>. The new locations are stored in the variable <code>x</code>.</p>
<div id="d2a6e73b" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">2</span><span class="op">*</span>np.pi, m, endpoint<span class="op">=</span><span class="va">False</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="computing-the-psi-vector" class="level3" data-number="9.6.4">
<h3 data-number="9.6.4" class="anchored" data-anchor-id="computing-the-psi-vector"><span class="header-section-number">9.6.4</span> Computing the <span class="math inline">\(\psi\)</span> Vector</h3>
<p>Distances between testing locations <span class="math inline">\(x\)</span> and training data locations <span class="math inline">\(X\)</span>.</p>
<div id="86efafac" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_psi(X, x, theta, eps<span class="op">=</span>sqrt(spacing(<span class="dv">1</span>))):</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> X.shape[<span class="dv">0</span>]</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    k <span class="op">=</span> X.shape[<span class="dv">1</span>]</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    m <span class="op">=</span> x.shape[<span class="dv">0</span>]</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    psi <span class="op">=</span> zeros((n, m))</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    theta <span class="op">=</span> theta <span class="op">*</span> ones(k)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    D <span class="op">=</span> zeros((n, m))</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    D <span class="op">=</span> cdist(x.reshape(<span class="op">-</span><span class="dv">1</span>, k),</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>              X.reshape(<span class="op">-</span><span class="dv">1</span>, k),</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>              metric<span class="op">=</span><span class="st">'sqeuclidean'</span>,</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>              out<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>              w<span class="op">=</span>theta)    </span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>    psi <span class="op">=</span> exp(<span class="op">-</span>D)</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># return psi transpose to be consistent with the literature</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Dimensions of psi: </span><span class="sc">{</span>psi<span class="sc">.</span>T<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span>(psi.T)</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>psi <span class="op">=</span> build_psi(X, x, theta)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Dimensions of psi: (8, 100)</code></pre>
</div>
</div>
<p><a href="#fig-sin-corr-pred" class="quarto-xref">Figure&nbsp;<span>9.6</span></a> visualizes the <span class="math inline">\((8, 100)\)</span> prediction matrix <span class="math inline">\(\psi\)</span>.</p>
<div id="cell-fig-sin-corr-pred" class="cell" data-execution_count="18">
<div class="cell-output cell-output-display">
<div id="fig-sin-corr-pred" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sin-corr-pred-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="006_num_gp_files/figure-html/fig-sin-corr-pred-output-1.png" width="558" height="86" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sin-corr-pred-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9.6: Visualization of the predition matrix <span class="math inline">\(\psi\)</span>
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="predicting-at-new-locations" class="level3" data-number="9.6.5">
<h3 data-number="9.6.5" class="anchored" data-anchor-id="predicting-at-new-locations"><span class="header-section-number">9.6.5</span> Predicting at New Locations</h3>
<p>Computation of the predictive equations.</p>
<div id="f2ab7c14" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>U <span class="op">=</span> cholesky(Psi).T</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>one <span class="op">=</span> np.ones(n).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>mu <span class="op">=</span> (one.T.dot(solve(U, solve(U.T, y)))) <span class="op">/</span> one.T.dot(solve(U, solve(U.T, one)))</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> mu <span class="op">*</span> ones(m).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>) <span class="op">+</span> psi.T.dot(solve(U, solve(U.T, y <span class="op">-</span> one <span class="op">*</span> mu)))</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Dimensions of f: </span><span class="sc">{</span>f<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Dimensions of f: (100, 1)</code></pre>
</div>
</div>
<p>To compute <span class="math inline">\(f\)</span>, <a href="#eq-mle-yhat" class="quarto-xref">Equation&nbsp;<span>9.13</span></a> is used.</p>
</section>
<section id="visualization" class="level3" data-number="9.6.6">
<h3 data-number="9.6.6" class="anchored" data-anchor-id="visualization"><span class="header-section-number">9.6.6</span> Visualization</h3>
<div id="d7b47216" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>plt.plot(x, f, color <span class="op">=</span> <span class="st">"orange"</span>, label<span class="op">=</span><span class="st">"Fitted"</span>)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>plt.plot(x, np.sin(x), color <span class="op">=</span> <span class="st">"grey"</span>, label<span class="op">=</span><span class="st">"Original"</span>)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>plt.plot(X, y, <span class="st">"bo"</span>, label<span class="op">=</span><span class="st">"Measurements"</span>)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Kriging prediction of sin(x) with </span><span class="sc">{}</span><span class="st"> points.</span><span class="ch">\n</span><span class="st"> theta: </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(n, theta[<span class="dv">0</span>]))</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">'upper right'</span>)</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="006_num_gp_files/figure-html/cell-21-output-1.png" width="590" height="449" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="sec-kriging-example-006" class="level3" data-number="9.6.7">
<h3 data-number="9.6.7" class="anchored" data-anchor-id="sec-kriging-example-006"><span class="header-section-number">9.6.7</span> The Complete Python Code for the Example</h3>
<p>Here is the self-contained Python code for direct use in a notebook:</p>
<div id="25f745af" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> (array, zeros, power, ones, exp, multiply, eye, linspace, spacing, sqrt, arange, append, ravel)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy.linalg <span class="im">import</span> cholesky, solve</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.spatial.distance <span class="im">import</span> squareform, pdist, cdist</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 1. Kriging Basis Functions (Defining the Correlation) ---</span></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a><span class="co"># The core of Kriging uses a specialized basis function for correlation:</span></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a><span class="co"># psi(x^(i), x) = exp(- sum_{j=1}^k theta_j |x_j^(i) - x_j|^p_j)</span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a><span class="co"># For this 1D example (k=1), and with p_j=2 (squared Euclidean distance implicit from pdist usage)</span></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a><span class="co"># and theta_j = theta (a single value), it simplifies.</span></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_Psi(X, theta, eps<span class="op">=</span>sqrt(spacing(<span class="dv">1</span>))):</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a><span class="co">    Computes the correlation matrix Psi based on pairwise squared Euclidean distances</span></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a><span class="co">    between input locations, scaled by theta.</span></span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a><span class="co">    Adds a small epsilon to the diagonal for numerical stability (nugget effect).</span></span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate pairwise squared Euclidean distances (D) between points in X</span></span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>    D <span class="op">=</span> squareform(pdist(X, metric<span class="op">=</span><span class="st">'sqeuclidean'</span>, out<span class="op">=</span><span class="va">None</span>, w<span class="op">=</span>theta))</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute Psi = exp(-D)</span></span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>    Psi <span class="op">=</span> exp(<span class="op">-</span>D)</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add a small value to the diagonal for numerical stability (nugget)</span></span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># This is often done in Kriging implementations, though a regression method</span></span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># with a 'nugget' parameter (Lambda) is explicitly mentioned for noisy data later.</span></span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The source code snippet for build_Psi explicitly includes `multiply(eye(X.shape), eps)`.</span></span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># FIX: Use X.shape to get the number of rows for the identity matrix</span></span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>    Psi <span class="op">+=</span> multiply(eye(X.shape[<span class="dv">0</span>]), eps) <span class="co"># Corrected line</span></span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Psi</span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_psi(X_train, x_predict, theta):</span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a><span class="co">    Computes the correlation vector (or matrix) psi between new prediction locations</span></span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a><span class="co">    and training data locations.</span></span>
<span id="cb24-35"><a href="#cb24-35" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb24-36"><a href="#cb24-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate pairwise squared Euclidean distances (D) between prediction points (x_predict)</span></span>
<span id="cb24-37"><a href="#cb24-37" aria-hidden="true" tabindex="-1"></a>    <span class="co"># and training points (X_train).</span></span>
<span id="cb24-38"><a href="#cb24-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># `cdist` computes distances between each pair of the two collections of inputs.</span></span>
<span id="cb24-39"><a href="#cb24-39" aria-hidden="true" tabindex="-1"></a>    D <span class="op">=</span> cdist(x_predict, X_train, metric<span class="op">=</span><span class="st">'sqeuclidean'</span>, out<span class="op">=</span><span class="va">None</span>, w<span class="op">=</span>theta)</span>
<span id="cb24-40"><a href="#cb24-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute psi = exp(-D)</span></span>
<span id="cb24-41"><a href="#cb24-41" aria-hidden="true" tabindex="-1"></a>    psi <span class="op">=</span> exp(<span class="op">-</span>D)</span>
<span id="cb24-42"><a href="#cb24-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> psi.T <span class="co"># Return transpose to be consistent with literature (n x m or n x 1)</span></span>
<span id="cb24-43"><a href="#cb24-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-44"><a href="#cb24-44" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 2. Data Points for the Sinusoid Function Example ---</span></span>
<span id="cb24-45"><a href="#cb24-45" aria-hidden="true" tabindex="-1"></a><span class="co"># The example uses a 1D sinusoid measured at eight equally spaced x-locations [153, Table 9.1].</span></span>
<span id="cb24-46"><a href="#cb24-46" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">8</span> <span class="co"># Number of sample locations</span></span>
<span id="cb24-47"><a href="#cb24-47" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">2</span> <span class="op">*</span> np.pi, n, endpoint<span class="op">=</span><span class="va">False</span>).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>) <span class="co"># Generate x-locations</span></span>
<span id="cb24-48"><a href="#cb24-48" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> np.sin(X_train) <span class="co"># Corresponding y-values (sine of x)</span></span>
<span id="cb24-49"><a href="#cb24-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-50"><a href="#cb24-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"--- Training Data (X_train, y_train) ---"</span>)</span>
<span id="cb24-51"><a href="#cb24-51" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x values:</span><span class="ch">\n</span><span class="st">"</span>, np.<span class="bu">round</span>(X_train, <span class="dv">2</span>))</span>
<span id="cb24-52"><a href="#cb24-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"y values:</span><span class="ch">\n</span><span class="st">"</span>, np.<span class="bu">round</span>(y_train, <span class="dv">2</span>))</span>
<span id="cb24-53"><a href="#cb24-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">40</span>)</span>
<span id="cb24-54"><a href="#cb24-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-55"><a href="#cb24-55" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the data points</span></span>
<span id="cb24-56"><a href="#cb24-56" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>))</span>
<span id="cb24-57"><a href="#cb24-57" aria-hidden="true" tabindex="-1"></a>plt.plot(X_train, y_train, <span class="st">"bo"</span>, label<span class="op">=</span><span class="ss">f"Measurements (</span><span class="sc">{</span>n<span class="sc">}</span><span class="ss"> points)"</span>)</span>
<span id="cb24-58"><a href="#cb24-58" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f"Sin(x) evaluated at </span><span class="sc">{</span>n<span class="sc">}</span><span class="ss"> points"</span>)</span>
<span id="cb24-59"><a href="#cb24-59" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"x"</span>)</span>
<span id="cb24-60"><a href="#cb24-60" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"sin(x)"</span>)</span>
<span id="cb24-61"><a href="#cb24-61" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb24-62"><a href="#cb24-62" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb24-63"><a href="#cb24-63" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb24-64"><a href="#cb24-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-65"><a href="#cb24-65" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 3. Calculating the Correlation Matrix (Psi) ---</span></span>
<span id="cb24-66"><a href="#cb24-66" aria-hidden="true" tabindex="-1"></a><span class="co"># Psi is based on pairwise squared distances between input locations.</span></span>
<span id="cb24-67"><a href="#cb24-67" aria-hidden="true" tabindex="-1"></a><span class="co"># theta is set to 1.0 for this 1D example.</span></span>
<span id="cb24-68"><a href="#cb24-68" aria-hidden="true" tabindex="-1"></a>theta <span class="op">=</span> np.array([<span class="fl">1.0</span>])</span>
<span id="cb24-69"><a href="#cb24-69" aria-hidden="true" tabindex="-1"></a>Psi <span class="op">=</span> build_Psi(X_train, theta)</span>
<span id="cb24-70"><a href="#cb24-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-71"><a href="#cb24-71" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Computed Correlation Matrix (Psi) ---"</span>)</span>
<span id="cb24-72"><a href="#cb24-72" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Dimensions of Psi:"</span>, Psi.shape) <span class="co"># Should be (8, 8)</span></span>
<span id="cb24-73"><a href="#cb24-73" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"First 5x5 block of Psi:</span><span class="ch">\n</span><span class="st">"</span>, np.<span class="bu">round</span>(Psi[:<span class="dv">5</span>,:<span class="dv">5</span>], <span class="dv">2</span>))</span>
<span id="cb24-74"><a href="#cb24-74" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">40</span>)</span>
<span id="cb24-75"><a href="#cb24-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-76"><a href="#cb24-76" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 4. Selecting New Locations (for Prediction) ---</span></span>
<span id="cb24-77"><a href="#cb24-77" aria-hidden="true" tabindex="-1"></a><span class="co"># We want to predict at m = 100 new locations in the interval [0, 2*pi].</span></span>
<span id="cb24-78"><a href="#cb24-78" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> <span class="dv">100</span> <span class="co"># Number of new locations</span></span>
<span id="cb24-79"><a href="#cb24-79" aria-hidden="true" tabindex="-1"></a>x_predict <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">2</span> <span class="op">*</span> np.pi, m, endpoint<span class="op">=</span><span class="va">True</span>).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb24-80"><a href="#cb24-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-81"><a href="#cb24-81" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- New Locations for Prediction (x_predict) ---"</span>)</span>
<span id="cb24-82"><a href="#cb24-82" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of prediction points: </span><span class="sc">{</span>m<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb24-83"><a href="#cb24-83" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"First 5 prediction points:</span><span class="ch">\n</span><span class="st">"</span>, np.<span class="bu">round</span>(x_predict[:<span class="dv">5</span>], <span class="dv">2</span>).flatten())</span>
<span id="cb24-84"><a href="#cb24-84" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">40</span>)</span>
<span id="cb24-85"><a href="#cb24-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-86"><a href="#cb24-86" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 5. Computing the psi Vector ---</span></span>
<span id="cb24-87"><a href="#cb24-87" aria-hidden="true" tabindex="-1"></a><span class="co"># This vector contains correlations between each of the n observed data points</span></span>
<span id="cb24-88"><a href="#cb24-88" aria-hidden="true" tabindex="-1"></a><span class="co"># and each of the m new prediction locations.</span></span>
<span id="cb24-89"><a href="#cb24-89" aria-hidden="true" tabindex="-1"></a>psi <span class="op">=</span> build_psi(X_train, x_predict, theta)</span>
<span id="cb24-90"><a href="#cb24-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-91"><a href="#cb24-91" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Computed Prediction Correlation Matrix (psi) ---"</span>)</span>
<span id="cb24-92"><a href="#cb24-92" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Dimensions of psi:"</span>, psi.shape) <span class="co"># Should be (8, 100)</span></span>
<span id="cb24-93"><a href="#cb24-93" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"First 5x5 block of psi:</span><span class="ch">\n</span><span class="st">"</span>, np.<span class="bu">round</span>(psi[:<span class="dv">5</span>,:<span class="dv">5</span>], <span class="dv">2</span>))</span>
<span id="cb24-94"><a href="#cb24-94" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">40</span>)</span>
<span id="cb24-95"><a href="#cb24-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-96"><a href="#cb24-96" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 6. Predicting at New Locations (Kriging Prediction) ---</span></span>
<span id="cb24-97"><a href="#cb24-97" aria-hidden="true" tabindex="-1"></a><span class="co"># The Maximum Likelihood Estimate (MLE) for y_hat is calculated using the formula:</span></span>
<span id="cb24-98"><a href="#cb24-98" aria-hidden="true" tabindex="-1"></a><span class="co"># y_hat(x) = mu_hat + psi.T @ Psi_inv @ (y - 1 * mu_hat) [p. 2 of previous response, and 263]</span></span>
<span id="cb24-99"><a href="#cb24-99" aria-hidden="true" tabindex="-1"></a><span class="co"># Matrix inversion is efficiently performed using Cholesky factorization.</span></span>
<span id="cb24-100"><a href="#cb24-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-101"><a href="#cb24-101" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 6a: Cholesky decomposition of Psi</span></span>
<span id="cb24-102"><a href="#cb24-102" aria-hidden="true" tabindex="-1"></a>U <span class="op">=</span> cholesky(Psi).T <span class="co"># Note: `cholesky` in numpy returns lower triangular L, we need U (upper) so transpose L.</span></span>
<span id="cb24-103"><a href="#cb24-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-104"><a href="#cb24-104" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 6b: Calculate mu_hat (estimated mean)</span></span>
<span id="cb24-105"><a href="#cb24-105" aria-hidden="true" tabindex="-1"></a><span class="co"># mu_hat = (one.T @ Psi_inv @ y) / (one.T @ Psi_inv @ one) [p. 2 of previous response]</span></span>
<span id="cb24-106"><a href="#cb24-106" aria-hidden="true" tabindex="-1"></a>one <span class="op">=</span> np.ones(n).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>) <span class="co"># Vector of ones</span></span>
<span id="cb24-107"><a href="#cb24-107" aria-hidden="true" tabindex="-1"></a>mu_hat <span class="op">=</span> (one.T <span class="op">@</span> solve(U, solve(U.T, y_train))) <span class="op">/</span> (one.T <span class="op">@</span> solve(U, solve(U.T, one)))</span>
<span id="cb24-108"><a href="#cb24-108" aria-hidden="true" tabindex="-1"></a>mu_hat <span class="op">=</span> mu_hat.item() <span class="co"># Extract scalar value</span></span>
<span id="cb24-109"><a href="#cb24-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-110"><a href="#cb24-110" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Kriging Prediction Calculation ---"</span>)</span>
<span id="cb24-111"><a href="#cb24-111" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Estimated mean (mu_hat): </span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">round</span>(mu_hat, <span class="dv">4</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb24-112"><a href="#cb24-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-113"><a href="#cb24-113" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 6c: Calculate predictions f (y_hat) at new locations</span></span>
<span id="cb24-114"><a href="#cb24-114" aria-hidden="true" tabindex="-1"></a><span class="co"># f = mu_hat * ones(m) + psi.T @ Psi_inv @ (y - one * mu_hat)</span></span>
<span id="cb24-115"><a href="#cb24-115" aria-hidden="true" tabindex="-1"></a>f_predict <span class="op">=</span> mu_hat <span class="op">*</span> np.ones(m).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>) <span class="op">+</span> psi.T <span class="op">@</span> solve(U, solve(U.T, y_train <span class="op">-</span> one <span class="op">*</span> mu_hat))</span>
<span id="cb24-116"><a href="#cb24-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-117"><a href="#cb24-117" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Dimensions of predicted values (f_predict): </span><span class="sc">{</span>f_predict<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>) <span class="co"># Should be (100, 1)</span></span>
<span id="cb24-118"><a href="#cb24-118" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"First 5 predicted f values:</span><span class="ch">\n</span><span class="st">"</span>, np.<span class="bu">round</span>(f_predict[:<span class="dv">5</span>], <span class="dv">2</span>).flatten())</span>
<span id="cb24-119"><a href="#cb24-119" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">40</span>)</span>
<span id="cb24-120"><a href="#cb24-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-121"><a href="#cb24-121" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 7. Visualization ---</span></span>
<span id="cb24-122"><a href="#cb24-122" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the original sinusoid function, the measured points, and the Kriging predictions.</span></span>
<span id="cb24-123"><a href="#cb24-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-124"><a href="#cb24-124" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb24-125"><a href="#cb24-125" aria-hidden="true" tabindex="-1"></a>plt.plot(x_predict, f_predict, color<span class="op">=</span><span class="st">"orange"</span>, label<span class="op">=</span><span class="st">"Kriging Prediction"</span>)</span>
<span id="cb24-126"><a href="#cb24-126" aria-hidden="true" tabindex="-1"></a>plt.plot(x_predict, np.sin(x_predict), color<span class="op">=</span><span class="st">"grey"</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="st">"True Sinusoid Function"</span>)</span>
<span id="cb24-127"><a href="#cb24-127" aria-hidden="true" tabindex="-1"></a>plt.plot(X_train, y_train, <span class="st">"bo"</span>, markersize<span class="op">=</span><span class="dv">8</span>, label<span class="op">=</span><span class="st">"Measurements"</span>)</span>
<span id="cb24-128"><a href="#cb24-128" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f"Kriging prediction of sin(x) with </span><span class="sc">{</span>n<span class="sc">}</span><span class="ss"> points. (theta: </span><span class="sc">{</span>theta<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb24-129"><a href="#cb24-129" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"x"</span>)</span>
<span id="cb24-130"><a href="#cb24-130" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"y"</span>)</span>
<span id="cb24-131"><a href="#cb24-131" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">'upper right'</span>)</span>
<span id="cb24-132"><a href="#cb24-132" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb24-133"><a href="#cb24-133" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>--- Training Data (X_train, y_train) ---
x values:
 [[0.  ]
 [0.79]
 [1.57]
 [2.36]
 [3.14]
 [3.93]
 [4.71]
 [5.5 ]]
y values:
 [[ 0.  ]
 [ 0.71]
 [ 1.  ]
 [ 0.71]
 [ 0.  ]
 [-0.71]
 [-1.  ]
 [-0.71]]
----------------------------------------</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="006_num_gp_files/figure-html/cell-22-output-2.png" width="683" height="449" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
--- Computed Correlation Matrix (Psi) ---
Dimensions of Psi: (8, 8)
First 5x5 block of Psi:
 [[1.   0.54 0.08 0.   0.  ]
 [0.54 1.   0.54 0.08 0.  ]
 [0.08 0.54 1.   0.54 0.08]
 [0.   0.08 0.54 1.   0.54]
 [0.   0.   0.08 0.54 1.  ]]
----------------------------------------

--- New Locations for Prediction (x_predict) ---
Number of prediction points: 100
First 5 prediction points:
 [0.   0.06 0.13 0.19 0.25]
----------------------------------------

--- Computed Prediction Correlation Matrix (psi) ---
Dimensions of psi: (8, 100)
First 5x5 block of psi:
 [[1.   1.   0.98 0.96 0.94]
 [0.54 0.59 0.65 0.7  0.75]
 [0.08 0.1  0.12 0.15 0.18]
 [0.   0.01 0.01 0.01 0.01]
 [0.   0.   0.   0.   0.  ]]
----------------------------------------

--- Kriging Prediction Calculation ---
Estimated mean (mu_hat): -0.0499
Dimensions of predicted values (f_predict): (100, 1)
First 5 predicted f values:
 [0.   0.05 0.1  0.15 0.21]
----------------------------------------</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="006_num_gp_files/figure-html/cell-22-output-4.png" width="832" height="523" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="jupyter-notebook" class="level2" data-number="9.7">
<h2 data-number="9.7" class="anchored" data-anchor-id="jupyter-notebook"><span class="header-section-number">9.7</span> Jupyter Notebook</h2>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>The Jupyter-Notebook of this lecture is available on GitHub in the <a href="https://github.com/sequential-parameter-optimization/Hyperparameter-Tuning-Cookbook/blob/main/006_num_gp.ipynb">Hyperparameter-Tuning-Cookbook Repository</a></li>
</ul>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-bart21i" class="csl-entry" role="listitem">
Bartz, Eva, Thomas Bartz-Beielstein, Martin Zaefferer, and Olaf Mersmann, eds. 2022. <em><span class="nocase">Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide</span></em>. Springer.
</div>
<div id="ref-Forr08a" class="csl-entry" role="listitem">
Forrester, Alexander, András Sóbester, and Andy Keane. 2008. <em><span class="nocase">Engineering Design via Surrogate Modelling</span></em>. Wiley.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./006_num_rbf.html" class="pagination-link" aria-label="Radial Basis Function Models">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Radial Basis Function Models</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./006_matrices.html" class="pagination-link" aria-label="Matrices">
        <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Matrices</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Copyright 2025, T. Bartz-Beielstein</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://sequential-parameter-optimization.github.io/Hyperparameter-Tuning-Cookbook/">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://x.com/bartzbeielstein">
      <i class="bi bi-twitter" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>