\contentsline {chapter}{Preface: Optimization and Hyperparameter Tuning}{13}{chapter*.2}%
\contentsline {section}{Book Structure}{14}{section*.3}%
\contentsline {section}{Software Used in this Book}{16}{section*.4}%
\contentsline {part}{\numberline {I}Spot as an Optimizer}{17}{part.1}%
\contentsline {chapter}{\numberline {1}Introduction to \texttt {spotPython}}{18}{chapter.1}%
\contentsline {section}{\numberline {1.1}Example: \texttt {Spot} and the Sphere Function}{19}{section.1.1}%
\contentsline {subsection}{\numberline {1.1.1}The Objective Function: Sphere}{19}{subsection.1.1.1}%
\contentsline {section}{\numberline {1.2}\texttt {Spot} Parameters: \texttt {fun\_evals}, \texttt {init\_size} and \texttt {show\_models}}{22}{section.1.2}%
\contentsline {section}{\numberline {1.3}Print the Results}{23}{section.1.3}%
\contentsline {section}{\numberline {1.4}Show the Progress}{24}{section.1.4}%
\contentsline {section}{\numberline {1.5}Visualizing the Optimization and Hyperparameter Tuning Process with TensorBoard}{24}{section.1.5}%
\contentsline {chapter}{\numberline {2}Multi-dimensional Functions}{28}{chapter.2}%
\contentsline {section}{\numberline {2.1}Example: \texttt {Spot} and the 3-dim Sphere Function}{28}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}The Objective Function: 3-dim Sphere}{28}{subsection.2.1.1}%
\contentsline {subsection}{\numberline {2.1.2}Results}{30}{subsection.2.1.2}%
\contentsline {subsection}{\numberline {2.1.3}A Contour Plot}{31}{subsection.2.1.3}%
\contentsline {subsection}{\numberline {2.1.4}TensorBoard}{33}{subsection.2.1.4}%
\contentsline {section}{\numberline {2.2}Conclusion}{33}{section.2.2}%
\contentsline {section}{\numberline {2.3}Exercises}{33}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}The Three Dimensional \texttt {fun\_cubed}}{34}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2}The Ten Dimensional \texttt {fun\_wing\_wt}}{34}{subsection.2.3.2}%
\contentsline {subsection}{\numberline {2.3.3}The Three Dimensional \texttt {fun\_runge}}{35}{subsection.2.3.3}%
\contentsline {subsection}{\numberline {2.3.4}The Three Dimensional \texttt {fun\_linear}}{35}{subsection.2.3.4}%
\contentsline {chapter}{\numberline {3}Isotropic and Anisotropic Kriging}{36}{chapter.3}%
\contentsline {section}{\numberline {3.1}Example: Isotropic \texttt {Spot} Surrogate and the 2-dim Sphere Function}{36}{section.3.1}%
\contentsline {subsection}{\numberline {3.1.1}The Objective Function: 2-dim Sphere}{36}{subsection.3.1.1}%
\contentsline {subsection}{\numberline {3.1.2}Results}{37}{subsection.3.1.2}%
\contentsline {section}{\numberline {3.2}Example With Anisotropic Kriging}{38}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Taking a Look at the \texttt {theta} Values}{40}{subsection.3.2.1}%
\contentsline {subsubsection}{\numberline {3.2.1.1}\texttt {theta} Values from the \texttt {spot} Model}{40}{subsubsection.3.2.1.1}%
\contentsline {subsubsection}{\numberline {3.2.1.2}TensorBoard}{41}{subsubsection.3.2.1.2}%
\contentsline {section}{\numberline {3.3}Exercises}{41}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}\texttt {fun\_branin}}{41}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}\texttt {fun\_sin\_cos}}{42}{subsection.3.3.2}%
\contentsline {subsection}{\numberline {3.3.3}\texttt {fun\_runge}}{42}{subsection.3.3.3}%
\contentsline {subsection}{\numberline {3.3.4}\texttt {fun\_wingwt}}{42}{subsection.3.3.4}%
\contentsline {chapter}{\numberline {4}Using \texttt {sklearn} Surrogates in \texttt {spotPython}}{43}{chapter.4}%
\contentsline {section}{\numberline {4.1}Example: Branin Function with \texttt {spotPython}'s Internal Kriging Surrogate}{43}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1}The Objective Function Branin}{43}{subsection.4.1.1}%
\contentsline {subsection}{\numberline {4.1.2}Running the surrogate model based optimizer \texttt {Spot}:}{44}{subsection.4.1.2}%
\contentsline {subsection}{\numberline {4.1.3}TensorBoard}{45}{subsection.4.1.3}%
\contentsline {subsection}{\numberline {4.1.4}Print the Results}{47}{subsection.4.1.4}%
\contentsline {subsection}{\numberline {4.1.5}Show the Progress and the Surrogate}{47}{subsection.4.1.5}%
\contentsline {section}{\numberline {4.2}Example: Using Surrogates From scikit-learn}{48}{section.4.2}%
\contentsline {subsection}{\numberline {4.2.1}GaussianProcessRegressor as a Surrogate}{49}{subsection.4.2.1}%
\contentsline {section}{\numberline {4.3}Example: One-dimensional Sphere Function With \texttt {spotPython}'s Kriging}{51}{section.4.3}%
\contentsline {subsection}{\numberline {4.3.1}Results}{57}{subsection.4.3.1}%
\contentsline {section}{\numberline {4.4}Example: \texttt {Sklearn} Model GaussianProcess}{58}{section.4.4}%
\contentsline {section}{\numberline {4.5}Exercises}{65}{section.4.5}%
\contentsline {subsection}{\numberline {4.5.1}\texttt {DecisionTreeRegressor}}{65}{subsection.4.5.1}%
\contentsline {subsection}{\numberline {4.5.2}\texttt {RandomForestRegressor}}{66}{subsection.4.5.2}%
\contentsline {subsection}{\numberline {4.5.3}\texttt {linear\_model.LinearRegression}}{66}{subsection.4.5.3}%
\contentsline {subsection}{\numberline {4.5.4}\texttt {linear\_model.Ridge}}{66}{subsection.4.5.4}%
\contentsline {section}{\numberline {4.6}Exercise 2}{66}{section.4.6}%
\contentsline {chapter}{\numberline {5}Sequential Parameter Optimization: Using \texttt {scipy} Optimizers}{67}{chapter.5}%
\contentsline {section}{\numberline {5.1}The Objective Function Branin}{67}{section.5.1}%
\contentsline {section}{\numberline {5.2}The Optimizer}{68}{section.5.2}%
\contentsline {subsection}{\numberline {5.2.1}TensorBoard}{70}{subsection.5.2.1}%
\contentsline {section}{\numberline {5.3}Print the Results}{72}{section.5.3}%
\contentsline {section}{\numberline {5.4}Show the Progress}{72}{section.5.4}%
\contentsline {section}{\numberline {5.5}Exercises}{73}{section.5.5}%
\contentsline {subsection}{\numberline {5.5.1}\texttt {dual\_annealing}}{73}{subsection.5.5.1}%
\contentsline {subsection}{\numberline {5.5.2}\texttt {direct}}{73}{subsection.5.5.2}%
\contentsline {subsection}{\numberline {5.5.3}\texttt {shgo}}{73}{subsection.5.5.3}%
\contentsline {subsection}{\numberline {5.5.4}\texttt {basinhopping}}{74}{subsection.5.5.4}%
\contentsline {subsection}{\numberline {5.5.5}Performance Comparison}{74}{subsection.5.5.5}%
\contentsline {chapter}{\numberline {6}Sequential Parameter Optimization: Gaussian Process Models}{75}{chapter.6}%
\contentsline {section}{\numberline {6.1}Gaussian Processes Regression: Basic Introductory \texttt {scikit-learn} Example}{75}{section.6.1}%
\contentsline {subsection}{\numberline {6.1.1}Train and Test Data}{76}{subsection.6.1.1}%
\contentsline {subsection}{\numberline {6.1.2}Building the Surrogate With \texttt {Sklearn}}{76}{subsection.6.1.2}%
\contentsline {subsection}{\numberline {6.1.3}Plotting the \texttt {Sklearn}Model}{76}{subsection.6.1.3}%
\contentsline {subsection}{\numberline {6.1.4}The \texttt {spotPython} Version}{77}{subsection.6.1.4}%
\contentsline {subsection}{\numberline {6.1.5}Visualizing the Differences Between the \texttt {spotPython} and the \texttt {sklearn} Model Fits}{78}{subsection.6.1.5}%
\contentsline {section}{\numberline {6.2}Exercises}{79}{section.6.2}%
\contentsline {subsection}{\numberline {6.2.1}\texttt {Schonlau\ Example\ Function}}{79}{subsection.6.2.1}%
\contentsline {subsection}{\numberline {6.2.2}\texttt {Forrester\ Example\ Function}}{80}{subsection.6.2.2}%
\contentsline {subsection}{\numberline {6.2.3}\texttt {fun\_runge\ Function\ (1-dim)}}{80}{subsection.6.2.3}%
\contentsline {subsection}{\numberline {6.2.4}\texttt {fun\_cubed\ (1-dim)}}{81}{subsection.6.2.4}%
\contentsline {subsection}{\numberline {6.2.5}The Effect of Noise}{82}{subsection.6.2.5}%
\contentsline {chapter}{\numberline {7}Expected Improvement}{83}{chapter.7}%
\contentsline {section}{\numberline {7.1}Example: \texttt {Spot} and the 1-dim Sphere Function}{83}{section.7.1}%
\contentsline {subsection}{\numberline {7.1.1}The Objective Function: 1-dim Sphere}{83}{subsection.7.1.1}%
\contentsline {subsection}{\numberline {7.1.2}Results}{85}{subsection.7.1.2}%
\contentsline {section}{\numberline {7.2}Same, but with EI as infill\_criterion}{86}{section.7.2}%
\contentsline {section}{\numberline {7.3}Non-isotropic Kriging}{89}{section.7.3}%
\contentsline {section}{\numberline {7.4}Using \texttt {sklearn} Surrogates}{91}{section.7.4}%
\contentsline {subsection}{\numberline {7.4.1}The spot Loop}{91}{subsection.7.4.1}%
\contentsline {subsection}{\numberline {7.4.2}spot: The Initial Model}{93}{subsection.7.4.2}%
\contentsline {subsubsection}{\numberline {7.4.2.1}Example: Modifying the initial design size}{93}{subsubsection.7.4.2.1}%
\contentsline {subsection}{\numberline {7.4.3}Init: Build Initial Design}{94}{subsection.7.4.3}%
\contentsline {subsection}{\numberline {7.4.4}Evaluate}{96}{subsection.7.4.4}%
\contentsline {subsection}{\numberline {7.4.5}Build Surrogate}{96}{subsection.7.4.5}%
\contentsline {subsection}{\numberline {7.4.6}A Simple Predictor}{96}{subsection.7.4.6}%
\contentsline {section}{\numberline {7.5}Gaussian Processes regression: basic introductory example}{97}{section.7.5}%
\contentsline {section}{\numberline {7.6}The Surrogate: Using scikit-learn models}{100}{section.7.6}%
\contentsline {section}{\numberline {7.7}Additional Examples}{102}{section.7.7}%
\contentsline {subsection}{\numberline {7.7.1}Optimize on Surrogate}{106}{subsection.7.7.1}%
\contentsline {subsection}{\numberline {7.7.2}Evaluate on Real Objective}{106}{subsection.7.7.2}%
\contentsline {subsection}{\numberline {7.7.3}Impute / Infill new Points}{106}{subsection.7.7.3}%
\contentsline {section}{\numberline {7.8}Tests}{106}{section.7.8}%
\contentsline {section}{\numberline {7.9}EI: The Famous Schonlau Example}{107}{section.7.9}%
\contentsline {section}{\numberline {7.10}EI: The Forrester Example}{109}{section.7.10}%
\contentsline {section}{\numberline {7.11}Noise}{112}{section.7.11}%
\contentsline {section}{\numberline {7.12}Cubic Function}{116}{section.7.12}%
\contentsline {section}{\numberline {7.13}Factors}{121}{section.7.13}%
\contentsline {chapter}{\numberline {8}Hyperparameter Tuning and Noise}{123}{chapter.8}%
\contentsline {section}{\numberline {8.1}Example: \texttt {Spot} and the Noisy Sphere Function}{123}{section.8.1}%
\contentsline {subsection}{\numberline {8.1.1}The Objective Function: Noisy Sphere}{123}{subsection.8.1.1}%
\contentsline {section}{\numberline {8.2}Print the Results}{130}{section.8.2}%
\contentsline {section}{\numberline {8.3}Noise and Surrogates: The Nugget Effect}{131}{section.8.3}%
\contentsline {subsection}{\numberline {8.3.1}The Noisy Sphere}{131}{subsection.8.3.1}%
\contentsline {subsubsection}{\numberline {8.3.1.1}The Data}{131}{subsubsection.8.3.1.1}%
\contentsline {section}{\numberline {8.4}Exercises}{134}{section.8.4}%
\contentsline {subsection}{\numberline {8.4.1}Noisy \texttt {fun\_cubed}}{134}{subsection.8.4.1}%
\contentsline {subsection}{\numberline {8.4.2}\texttt {fun\_runge}}{135}{subsection.8.4.2}%
\contentsline {subsection}{\numberline {8.4.3}\texttt {fun\_forrester}}{135}{subsection.8.4.3}%
\contentsline {subsection}{\numberline {8.4.4}\texttt {fun\_xsin}}{135}{subsection.8.4.4}%
\contentsline {chapter}{\numberline {9}Handling Noise: Optimal Computational Budget Allocation in \texttt {Spot}}{137}{chapter.9}%
\contentsline {section}{\numberline {9.1}Example: \texttt {Spot}, OCBA, and the Noisy Sphere Function}{137}{section.9.1}%
\contentsline {subsection}{\numberline {9.1.1}The Objective Function: Noisy Sphere}{137}{subsection.9.1.1}%
\contentsline {section}{\numberline {9.2}Print the Results}{143}{section.9.2}%
\contentsline {section}{\numberline {9.3}Noise and Surrogates: The Nugget Effect}{143}{section.9.3}%
\contentsline {subsection}{\numberline {9.3.1}The Noisy Sphere}{143}{subsection.9.3.1}%
\contentsline {subsubsection}{\numberline {9.3.1.1}The Data}{143}{subsubsection.9.3.1.1}%
\contentsline {section}{\numberline {9.4}Exercises}{146}{section.9.4}%
\contentsline {subsection}{\numberline {9.4.1}Noisy \texttt {fun\_cubed}}{146}{subsection.9.4.1}%
\contentsline {subsection}{\numberline {9.4.2}\texttt {fun\_runge}}{147}{subsection.9.4.2}%
\contentsline {subsection}{\numberline {9.4.3}\texttt {fun\_forrester}}{147}{subsection.9.4.3}%
\contentsline {subsection}{\numberline {9.4.4}\texttt {fun\_xsin}}{147}{subsection.9.4.4}%
\contentsline {part}{\numberline {II}Hyperparameter Tuning}{149}{part.2}%
\contentsline {chapter}{\numberline {10}HPT: sklearn SVC on Moons Data}{150}{chapter.10}%
\contentsline {section}{\numberline {10.1}Step 1: Setup}{150}{section.10.1}%
\contentsline {section}{\numberline {10.2}Step 2: Initialization of the Empty \texttt {fun\_control} Dictionary}{150}{section.10.2}%
\contentsline {section}{\numberline {10.3}Step 3: SKlearn Load Data (Classification)}{151}{section.10.3}%
\contentsline {section}{\numberline {10.4}Step 4: Specification of the Preprocessing Model}{153}{section.10.4}%
\contentsline {section}{\numberline {10.5}Step 5: Select Model (\texttt {algorithm}) and \texttt {core\_model\_hyper\_dict}}{154}{section.10.5}%
\contentsline {section}{\numberline {10.6}Step 6: Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{156}{section.10.6}%
\contentsline {subsection}{\numberline {10.6.1}Modify hyperparameter of type numeric and integer (boolean)}{156}{subsection.10.6.1}%
\contentsline {subsection}{\numberline {10.6.2}Modify hyperparameter of type factor}{157}{subsection.10.6.2}%
\contentsline {subsection}{\numberline {10.6.3}Optimizers}{158}{subsection.10.6.3}%
\contentsline {section}{\numberline {10.7}Step 7: Selection of the Objective (Loss) Function}{158}{section.10.7}%
\contentsline {subsection}{\numberline {10.7.1}Predict Classes or Class Probabilities}{158}{subsection.10.7.1}%
\contentsline {section}{\numberline {10.8}Step 8: Calling the SPOT Function}{159}{section.10.8}%
\contentsline {subsection}{\numberline {10.8.1}Preparing the SPOT Call}{159}{subsection.10.8.1}%
\contentsline {subsection}{\numberline {10.8.2}The Objective Function}{159}{subsection.10.8.2}%
\contentsline {subsection}{\numberline {10.8.3}Run the \texttt {Spot} Optimizer}{160}{subsection.10.8.3}%
\contentsline {subsection}{\numberline {10.8.4}Starting the Hyperparameter Tuning}{160}{subsection.10.8.4}%
\contentsline {section}{\numberline {10.9}Step 9: Results}{162}{section.10.9}%
\contentsline {subsection}{\numberline {10.9.1}Show variable importance}{163}{subsection.10.9.1}%
\contentsline {subsection}{\numberline {10.9.2}Get Default Hyperparameters}{164}{subsection.10.9.2}%
\contentsline {subsection}{\numberline {10.9.3}Get SPOT Results}{165}{subsection.10.9.3}%
\contentsline {subsection}{\numberline {10.9.4}Plot: Compare Predictions}{166}{subsection.10.9.4}%
\contentsline {subsection}{\numberline {10.9.5}Detailed Hyperparameter Plots}{168}{subsection.10.9.5}%
\contentsline {subsection}{\numberline {10.9.6}Parallel Coordinates Plot}{169}{subsection.10.9.6}%
\contentsline {subsection}{\numberline {10.9.7}Plot all Combinations of Hyperparameters}{169}{subsection.10.9.7}%
\contentsline {chapter}{\numberline {11}\texttt {river} Hyperparameter Tuning: Hoeffding Adaptive Tree Regressor with Friedman Drift Data}{170}{chapter.11}%
\contentsline {section}{\numberline {11.1}Setup}{170}{section.11.1}%
\contentsline {section}{\numberline {11.2}Initialization of the \texttt {fun\_control} Dictionary}{171}{section.11.2}%
\contentsline {section}{\numberline {11.3}Load Data: The Friedman Drift Data}{172}{section.11.3}%
\contentsline {section}{\numberline {11.4}Specification of the Preprocessing Model}{173}{section.11.4}%
\contentsline {section}{\numberline {11.5}SelectSelect Model (\texttt {algorithm}) and \texttt {core\_model\_hyper\_dict}}{174}{section.11.5}%
\contentsline {section}{\numberline {11.6}Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{174}{section.11.6}%
\contentsline {section}{\numberline {11.7}Selection of the Objective Function}{176}{section.11.7}%
\contentsline {section}{\numberline {11.8}Calling the SPOT Function}{177}{section.11.8}%
\contentsline {subsection}{\numberline {11.8.1}Prepare the SPOT Parameters}{177}{subsection.11.8.1}%
\contentsline {subsection}{\numberline {11.8.2}The Objective Function}{177}{subsection.11.8.2}%
\contentsline {subsection}{\numberline {11.8.3}Run the \texttt {Spot} Optimizer}{178}{subsection.11.8.3}%
\contentsline {subsection}{\numberline {11.8.4}TensorBoard}{179}{subsection.11.8.4}%
\contentsline {subsection}{\numberline {11.8.5}Results}{181}{subsection.11.8.5}%
\contentsline {section}{\numberline {11.9}The Larger Data Set}{183}{section.11.9}%
\contentsline {section}{\numberline {11.10}Get Default Hyperparameters}{183}{section.11.10}%
\contentsline {subsection}{\numberline {11.10.1}Show Predictions}{185}{subsection.11.10.1}%
\contentsline {section}{\numberline {11.11}Get SPOT Results}{186}{section.11.11}%
\contentsline {section}{\numberline {11.12}Visualize Regression Trees}{189}{section.11.12}%
\contentsline {subsection}{\numberline {11.12.1}Spot Model}{189}{subsection.11.12.1}%
\contentsline {section}{\numberline {11.13}Detailed Hyperparameter Plots}{190}{section.11.13}%
\contentsline {section}{\numberline {11.14}Parallel Coordinates Plots}{192}{section.11.14}%
\contentsline {section}{\numberline {11.15}Plot all Combinations of Hyperparameters}{192}{section.11.15}%
\contentsline {chapter}{\numberline {12}HPT: PyTorch With \texttt {spotPython} and Ray Tune on CIFAR10}{193}{chapter.12}%
\contentsline {section}{\numberline {12.1}Step 1: Setup}{194}{section.12.1}%
\contentsline {section}{\numberline {12.2}Step 2: Initialization of the \texttt {fun\_control} Dictionary}{195}{section.12.2}%
\contentsline {section}{\numberline {12.3}Step 3: PyTorch Data Loading}{195}{section.12.3}%
\contentsline {section}{\numberline {12.4}Step 4: Specification of the Preprocessing Model}{196}{section.12.4}%
\contentsline {section}{\numberline {12.5}Step 5: Select Model (\texttt {algorithm}) and \texttt {core\_model\_hyper\_dict}}{197}{section.12.5}%
\contentsline {subsubsection}{\numberline {12.5.0.1}Implementing a Configurable Neural Network With Ray Tune}{197}{subsubsection.12.5.0.1}%
\contentsline {subsubsection}{\numberline {12.5.0.2}Implementing a Configurable Neural Network With spotPython}{198}{subsubsection.12.5.0.2}%
\contentsline {subsection}{\numberline {12.5.1}The \texttt {Net\_Core} class}{199}{subsection.12.5.1}%
\contentsline {subsection}{\numberline {12.5.2}Comparison of the Approach Described in the PyTorch Tutorial With spotPython}{199}{subsection.12.5.2}%
\contentsline {subsection}{\numberline {12.5.3}The Search Space: Hyperparameters}{200}{subsection.12.5.3}%
\contentsline {subsection}{\numberline {12.5.4}Configuring the Search Space With Ray Tune}{200}{subsection.12.5.4}%
\contentsline {subsection}{\numberline {12.5.5}Configuring the Search Space With spotPython}{201}{subsection.12.5.5}%
\contentsline {subsubsection}{\numberline {12.5.5.1}The \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm}{201}{subsubsection.12.5.5.1}%
\contentsline {section}{\numberline {12.6}Step 6: Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{203}{section.12.6}%
\contentsline {subsubsection}{\numberline {12.6.0.1}Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{203}{subsubsection.12.6.0.1}%
\contentsline {subsubsection}{\numberline {12.6.0.2}Modify Hyperparameters of Type numeric and integer (boolean)}{203}{subsubsection.12.6.0.2}%
\contentsline {subsubsection}{\numberline {12.6.0.3}Modify Hyperparameter of Type factor}{204}{subsubsection.12.6.0.3}%
\contentsline {subsection}{\numberline {12.6.1}Optimizers}{204}{subsection.12.6.1}%
\contentsline {section}{\numberline {12.7}Step 7: Selection of the Objective (Loss) Function}{206}{section.12.7}%
\contentsline {subsection}{\numberline {12.7.1}Evaluation: Data Splitting}{206}{subsection.12.7.1}%
\contentsline {subsection}{\numberline {12.7.2}Hold-out Data Split}{206}{subsection.12.7.2}%
\contentsline {subsection}{\numberline {12.7.3}Cross-Validation}{207}{subsection.12.7.3}%
\contentsline {subsection}{\numberline {12.7.4}Overview of the Evaluation Settings}{208}{subsection.12.7.4}%
\contentsline {subsubsection}{\numberline {12.7.4.1}Settings for the Hyperparameter Tuning}{208}{subsubsection.12.7.4.1}%
\contentsline {subsubsection}{\numberline {12.7.4.2}Settings for the Final Evaluation of the Tuned Architecture}{208}{subsubsection.12.7.4.2}%
\contentsline {paragraph}{\numberline {12.7.4.2.1}Training of the Tuned Architecture}{208}{paragraph.12.7.4.2.1}%
\contentsline {paragraph}{\numberline {12.7.4.2.2}Testing of the Tuned Architecture}{208}{paragraph.12.7.4.2.2}%
\contentsline {subsection}{\numberline {12.7.5}Evaluation: Loss Functions and Metrics}{209}{subsection.12.7.5}%
\contentsline {section}{\numberline {12.8}Step 8: Calling the SPOT Function}{210}{section.12.8}%
\contentsline {subsection}{\numberline {12.8.1}Preparing the SPOT Call}{210}{subsection.12.8.1}%
\contentsline {subsection}{\numberline {12.8.2}The Objective Function \texttt {fun\_torch}}{211}{subsection.12.8.2}%
\contentsline {subsection}{\numberline {12.8.3}Using Default Hyperparameters or Results from Previous Runs}{211}{subsection.12.8.3}%
\contentsline {subsection}{\numberline {12.8.4}Starting the Hyperparameter Tuning}{211}{subsection.12.8.4}%
\contentsline {section}{\numberline {12.9}Step 9: Tensorboard}{218}{section.12.9}%
\contentsline {subsection}{\numberline {12.9.1}Tensorboard: Start Tensorboard}{218}{subsection.12.9.1}%
\contentsline {subsection}{\numberline {12.9.2}Saving the State of the Notebook}{218}{subsection.12.9.2}%
\contentsline {section}{\numberline {12.10}Step 10: Results}{220}{section.12.10}%
\contentsline {subsection}{\numberline {12.10.1}Get the Tuned Architecture (SPOT Results)}{222}{subsection.12.10.1}%
\contentsline {subsection}{\numberline {12.10.2}Get Default Hyperparameters}{223}{subsection.12.10.2}%
\contentsline {subsection}{\numberline {12.10.3}Evaluation of the Default Architecture}{223}{subsection.12.10.3}%
\contentsline {subsection}{\numberline {12.10.4}Evaluation of the Tuned Architecture}{225}{subsection.12.10.4}%
\contentsline {subsection}{\numberline {12.10.5}Detailed Hyperparameter Plots}{227}{subsection.12.10.5}%
\contentsline {section}{\numberline {12.11}Summary and Outlook}{230}{section.12.11}%
\contentsline {section}{\numberline {12.12}Appendix}{230}{section.12.12}%
\contentsline {subsection}{\numberline {12.12.1}Sample Output From Ray Tune's Run}{230}{subsection.12.12.1}%
\contentsline {chapter}{\numberline {13}HPT: sklearn RandomForestClassifier VBDP Data}{232}{chapter.13}%
\contentsline {section}{\numberline {13.1}Step 1: Setup}{232}{section.13.1}%
\contentsline {section}{\numberline {13.2}Step 2: Initialization of the Empty \texttt {fun\_control} Dictionary}{233}{section.13.2}%
\contentsline {section}{\numberline {13.3}Step 3: PyTorch Data Loading}{233}{section.13.3}%
\contentsline {subsection}{\numberline {13.3.1}Load Data: Classification VBDP}{233}{subsection.13.3.1}%
\contentsline {subsection}{\numberline {13.3.2}Holdout Train and Test Data}{234}{subsection.13.3.2}%
\contentsline {section}{\numberline {13.4}Step 4: Specification of the Preprocessing Model}{235}{section.13.4}%
\contentsline {section}{\numberline {13.5}Step 5: Select Model (\texttt {algorithm}) and \texttt {core\_model\_hyper\_dict}}{236}{section.13.5}%
\contentsline {section}{\numberline {13.6}Step 6: Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{237}{section.13.6}%
\contentsline {subsection}{\numberline {13.6.1}Modify hyperparameter of type numeric and integer (boolean)}{237}{subsection.13.6.1}%
\contentsline {subsection}{\numberline {13.6.2}Modify hyperparameter of type factor}{238}{subsection.13.6.2}%
\contentsline {subsection}{\numberline {13.6.3}Optimizers}{238}{subsection.13.6.3}%
\contentsline {subsection}{\numberline {13.6.4}Selection of the Objective: Metric and Loss Functions}{238}{subsection.13.6.4}%
\contentsline {section}{\numberline {13.7}Step 7: Selection of the Objective (Loss) Function}{239}{section.13.7}%
\contentsline {subsection}{\numberline {13.7.1}Metric Function}{239}{subsection.13.7.1}%
\contentsline {subsubsection}{\numberline {13.7.1.1}The MAPK Metric}{239}{subsubsection.13.7.1.1}%
\contentsline {subsubsection}{\numberline {13.7.1.2}Other Metrics}{239}{subsubsection.13.7.1.2}%
\contentsline {subsection}{\numberline {13.7.2}Evaluation on Hold-out Data}{240}{subsection.13.7.2}%
\contentsline {subsection}{\numberline {13.7.3}OOB Score}{240}{subsection.13.7.3}%
\contentsline {subsubsection}{\numberline {13.7.3.1}Cross Validation}{241}{subsubsection.13.7.3.1}%
\contentsline {section}{\numberline {13.8}Step 8: Calling the SPOT Function}{241}{section.13.8}%
\contentsline {subsection}{\numberline {13.8.1}Preparing the SPOT Call}{241}{subsection.13.8.1}%
\contentsline {subsection}{\numberline {13.8.2}The Objective Function}{242}{subsection.13.8.2}%
\contentsline {subsection}{\numberline {13.8.3}Run the \texttt {Spot} Optimizer}{242}{subsection.13.8.3}%
\contentsline {section}{\numberline {13.9}Step 9: Tensorboard}{245}{section.13.9}%
\contentsline {section}{\numberline {13.10}Step 10: Results}{245}{section.13.10}%
\contentsline {subsection}{\numberline {13.10.1}Show variable importance}{246}{subsection.13.10.1}%
\contentsline {subsection}{\numberline {13.10.2}Get Default Hyperparameters}{246}{subsection.13.10.2}%
\contentsline {subsection}{\numberline {13.10.3}Get SPOT Results}{247}{subsection.13.10.3}%
\contentsline {subsection}{\numberline {13.10.4}Evaluate SPOT Results}{248}{subsection.13.10.4}%
\contentsline {subsection}{\numberline {13.10.5}Handling Non-deterministic Results}{249}{subsection.13.10.5}%
\contentsline {subsection}{\numberline {13.10.6}Evalution of the Default Hyperparameters}{249}{subsection.13.10.6}%
\contentsline {subsection}{\numberline {13.10.7}Plot: Compare Predictions}{250}{subsection.13.10.7}%
\contentsline {subsection}{\numberline {13.10.8}Cross-validated Evaluations}{252}{subsection.13.10.8}%
\contentsline {subsection}{\numberline {13.10.9}Detailed Hyperparameter Plots}{253}{subsection.13.10.9}%
\contentsline {subsection}{\numberline {13.10.10}Parallel Coordinates Plot}{259}{subsection.13.10.10}%
\contentsline {subsection}{\numberline {13.10.11}Plot all Combinations of Hyperparameters}{259}{subsection.13.10.11}%
\contentsline {chapter}{\numberline {14}HPT: sklearn XGB Classifier VBDP Data}{260}{chapter.14}%
\contentsline {section}{\numberline {14.1}Step 1: Setup}{260}{section.14.1}%
\contentsline {section}{\numberline {14.2}Step 2: Initialization of the Empty \texttt {fun\_control} Dictionary}{261}{section.14.2}%
\contentsline {section}{\numberline {14.3}Step 3: PyTorch Data Loading}{261}{section.14.3}%
\contentsline {subsection}{\numberline {14.3.1}1. Load Data: Classification VBDP}{261}{subsection.14.3.1}%
\contentsline {subsection}{\numberline {14.3.2}Holdout Train and Test Data}{262}{subsection.14.3.2}%
\contentsline {section}{\numberline {14.4}Step 4: Specification of the Preprocessing Model}{263}{section.14.4}%
\contentsline {section}{\numberline {14.5}Step 5: Select Model (\texttt {algorithm}) and \texttt {core\_model\_hyper\_dict}}{264}{section.14.5}%
\contentsline {section}{\numberline {14.6}Step 6: Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{265}{section.14.6}%
\contentsline {subsection}{\numberline {14.6.1}Modify hyperparameter of type numeric and integer (boolean)}{265}{subsection.14.6.1}%
\contentsline {subsection}{\numberline {14.6.2}Modify hyperparameter of type factor}{266}{subsection.14.6.2}%
\contentsline {subsection}{\numberline {14.6.3}Optimizers}{266}{subsection.14.6.3}%
\contentsline {section}{\numberline {14.7}Step 7: Selection of the Objective (Loss) Function}{266}{section.14.7}%
\contentsline {subsection}{\numberline {14.7.1}Evaluation}{266}{subsection.14.7.1}%
\contentsline {subsection}{\numberline {14.7.2}Selection of the Objective: Metric and Loss Functions}{267}{subsection.14.7.2}%
\contentsline {subsection}{\numberline {14.7.3}Loss Function}{267}{subsection.14.7.3}%
\contentsline {subsection}{\numberline {14.7.4}Metric Function}{267}{subsection.14.7.4}%
\contentsline {subsubsection}{\numberline {14.7.4.1}The MAPK Metric}{267}{subsubsection.14.7.4.1}%
\contentsline {subsubsection}{\numberline {14.7.4.2}Other Metrics}{268}{subsubsection.14.7.4.2}%
\contentsline {subsection}{\numberline {14.7.5}Evaluation on Hold-out Data}{268}{subsection.14.7.5}%
\contentsline {subsubsection}{\numberline {14.7.5.1}Cross Validation}{268}{subsubsection.14.7.5.1}%
\contentsline {section}{\numberline {14.8}Step 8: Calling the SPOT Function}{269}{section.14.8}%
\contentsline {subsection}{\numberline {14.8.1}Preparing the SPOT Call}{269}{subsection.14.8.1}%
\contentsline {subsection}{\numberline {14.8.2}The Objective Function}{270}{subsection.14.8.2}%
\contentsline {subsection}{\numberline {14.8.3}Run the \texttt {Spot} Optimizer}{270}{subsection.14.8.3}%
\contentsline {section}{\numberline {14.9}Step 9: Tensorboard}{272}{section.14.9}%
\contentsline {section}{\numberline {14.10}Step 10: Results}{272}{section.14.10}%
\contentsline {subsection}{\numberline {14.10.1}Show variable importance}{273}{subsection.14.10.1}%
\contentsline {subsection}{\numberline {14.10.2}Get Default Hyperparameters}{274}{subsection.14.10.2}%
\contentsline {subsection}{\numberline {14.10.3}Get SPOT Results}{274}{subsection.14.10.3}%
\contentsline {subsection}{\numberline {14.10.4}Evaluate SPOT Results}{275}{subsection.14.10.4}%
\contentsline {subsection}{\numberline {14.10.5}Handling Non-deterministic Results}{276}{subsection.14.10.5}%
\contentsline {subsection}{\numberline {14.10.6}Evalution of the Default Hyperparameters}{277}{subsection.14.10.6}%
\contentsline {subsection}{\numberline {14.10.7}Plot: Compare Predictions}{277}{subsection.14.10.7}%
\contentsline {subsection}{\numberline {14.10.8}Cross-validated Evaluations}{279}{subsection.14.10.8}%
\contentsline {subsection}{\numberline {14.10.9}Detailed Hyperparameter Plots}{280}{subsection.14.10.9}%
\contentsline {subsection}{\numberline {14.10.10}Parallel Coordinates Plot}{284}{subsection.14.10.10}%
\contentsline {subsection}{\numberline {14.10.11}Plot all Combinations of Hyperparameters}{284}{subsection.14.10.11}%
\contentsline {chapter}{\numberline {15}HPT: sklearn SVC VBDP Data}{285}{chapter.15}%
\contentsline {section}{\numberline {15.1}Step 1: Setup}{285}{section.15.1}%
\contentsline {section}{\numberline {15.2}Step 2: Initialization of the Empty \texttt {fun\_control} Dictionary}{286}{section.15.2}%
\contentsline {section}{\numberline {15.3}Step 3: PyTorch Data Loading}{286}{section.15.3}%
\contentsline {subsection}{\numberline {15.3.1}1. Load Data: Classification VBDP}{286}{subsection.15.3.1}%
\contentsline {subsection}{\numberline {15.3.2}Holdout Train and Test Data}{287}{subsection.15.3.2}%
\contentsline {section}{\numberline {15.4}Step 4: Specification of the Preprocessing Model}{288}{section.15.4}%
\contentsline {section}{\numberline {15.5}Step 5: Select Model (\texttt {algorithm}) and \texttt {core\_model\_hyper\_dict}}{289}{section.15.5}%
\contentsline {section}{\numberline {15.6}Step 6: Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{290}{section.15.6}%
\contentsline {subsection}{\numberline {15.6.1}Modify hyperparameter of type numeric and integer (boolean)}{290}{subsection.15.6.1}%
\contentsline {subsection}{\numberline {15.6.2}Modify hyperparameter of type factor}{291}{subsection.15.6.2}%
\contentsline {subsection}{\numberline {15.6.3}Optimizers}{291}{subsection.15.6.3}%
\contentsline {subsection}{\numberline {15.6.4}Selection of the Objective: Metric and Loss Functions}{291}{subsection.15.6.4}%
\contentsline {section}{\numberline {15.7}Step 7: Selection of the Objective (Loss) Function}{291}{section.15.7}%
\contentsline {subsection}{\numberline {15.7.1}Metric Function}{292}{subsection.15.7.1}%
\contentsline {subsubsection}{\numberline {15.7.1.1}The MAPK Metric}{292}{subsubsection.15.7.1.1}%
\contentsline {subsubsection}{\numberline {15.7.1.2}Other Metrics}{292}{subsubsection.15.7.1.2}%
\contentsline {subsection}{\numberline {15.7.2}Evaluation on Hold-out Data}{293}{subsection.15.7.2}%
\contentsline {subsubsection}{\numberline {15.7.2.1}Cross Validation}{293}{subsubsection.15.7.2.1}%
\contentsline {section}{\numberline {15.8}Step 8: Calling the SPOT Function}{293}{section.15.8}%
\contentsline {subsection}{\numberline {15.8.1}Preparing the SPOT Call}{293}{subsection.15.8.1}%
\contentsline {subsection}{\numberline {15.8.2}The Objective Function}{294}{subsection.15.8.2}%
\contentsline {subsection}{\numberline {15.8.3}Run the \texttt {Spot} Optimizer}{294}{subsection.15.8.3}%
\contentsline {section}{\numberline {15.9}Step 9: Tensorboard}{299}{section.15.9}%
\contentsline {section}{\numberline {15.10}Step 10: Results}{299}{section.15.10}%
\contentsline {subsection}{\numberline {15.10.1}Show variable importance}{301}{subsection.15.10.1}%
\contentsline {subsection}{\numberline {15.10.2}Get Default Hyperparameters}{301}{subsection.15.10.2}%
\contentsline {subsection}{\numberline {15.10.3}Get SPOT Results}{302}{subsection.15.10.3}%
\contentsline {subsection}{\numberline {15.10.4}Evaluate SPOT Results}{303}{subsection.15.10.4}%
\contentsline {subsection}{\numberline {15.10.5}Handling Non-deterministic Results}{304}{subsection.15.10.5}%
\contentsline {subsection}{\numberline {15.10.6}Evalution of the Default Hyperparameters}{304}{subsection.15.10.6}%
\contentsline {subsection}{\numberline {15.10.7}Plot: Compare Predictions}{305}{subsection.15.10.7}%
\contentsline {subsection}{\numberline {15.10.8}Cross-validated Evaluations}{307}{subsection.15.10.8}%
\contentsline {subsection}{\numberline {15.10.9}Detailed Hyperparameter Plots}{308}{subsection.15.10.9}%
\contentsline {subsection}{\numberline {15.10.10}Parallel Coordinates Plot}{310}{subsection.15.10.10}%
\contentsline {subsection}{\numberline {15.10.11}Plot all Combinations of Hyperparameters}{310}{subsection.15.10.11}%
\contentsline {chapter}{\numberline {16}HPT: sklearn KNN Classifier VBDP Data}{311}{chapter.16}%
\contentsline {section}{\numberline {16.1}Step 1: Setup}{311}{section.16.1}%
\contentsline {section}{\numberline {16.2}Step 2: Initialization of the Empty \texttt {fun\_control} Dictionary}{312}{section.16.2}%
\contentsline {subsection}{\numberline {16.2.1}Load Data: Classification VBDP}{312}{subsection.16.2.1}%
\contentsline {subsection}{\numberline {16.2.2}Holdout Train and Test Data}{313}{subsection.16.2.2}%
\contentsline {section}{\numberline {16.3}Step 4: Specification of the Preprocessing Model}{314}{section.16.3}%
\contentsline {section}{\numberline {16.4}Step 5: Select Model (\texttt {algorithm}) and \texttt {core\_model\_hyper\_dict}}{315}{section.16.4}%
\contentsline {section}{\numberline {16.5}Step 6: Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{316}{section.16.5}%
\contentsline {subsection}{\numberline {16.5.1}Modify hyperparameter of type numeric and integer (boolean)}{316}{subsection.16.5.1}%
\contentsline {subsection}{\numberline {16.5.2}Modify hyperparameter of type factor}{316}{subsection.16.5.2}%
\contentsline {subsection}{\numberline {16.5.3}Optimizers}{317}{subsection.16.5.3}%
\contentsline {subsection}{\numberline {16.5.4}Selection of the Objective: Metric and Loss Functions}{317}{subsection.16.5.4}%
\contentsline {section}{\numberline {16.6}Step 7: Selection of the Objective (Loss) Function}{317}{section.16.6}%
\contentsline {subsection}{\numberline {16.6.1}Metric Function}{317}{subsection.16.6.1}%
\contentsline {subsubsection}{\numberline {16.6.1.1}The MAPK Metric}{318}{subsubsection.16.6.1.1}%
\contentsline {subsubsection}{\numberline {16.6.1.2}Other Metrics}{318}{subsubsection.16.6.1.2}%
\contentsline {subsection}{\numberline {16.6.2}Evaluation on Hold-out Data}{319}{subsection.16.6.2}%
\contentsline {subsubsection}{\numberline {16.6.2.1}Cross Validation}{319}{subsubsection.16.6.2.1}%
\contentsline {section}{\numberline {16.7}Step 8: Calling the SPOT Function}{319}{section.16.7}%
\contentsline {subsection}{\numberline {16.7.1}Preparing the SPOT Call}{319}{subsection.16.7.1}%
\contentsline {subsection}{\numberline {16.7.2}The Objective Function}{320}{subsection.16.7.2}%
\contentsline {subsection}{\numberline {16.7.3}Run the \texttt {Spot} Optimizer}{320}{subsection.16.7.3}%
\contentsline {section}{\numberline {16.8}Step 9: Tensorboard}{324}{section.16.8}%
\contentsline {section}{\numberline {16.9}Step 10: Results}{325}{section.16.9}%
\contentsline {subsection}{\numberline {16.9.1}Show variable importance}{326}{subsection.16.9.1}%
\contentsline {subsection}{\numberline {16.9.2}Get Default Hyperparameters}{326}{subsection.16.9.2}%
\contentsline {subsection}{\numberline {16.9.3}Get SPOT Results}{327}{subsection.16.9.3}%
\contentsline {subsection}{\numberline {16.9.4}Evaluate SPOT Results}{327}{subsection.16.9.4}%
\contentsline {subsection}{\numberline {16.9.5}Handling Non-deterministic Results}{328}{subsection.16.9.5}%
\contentsline {subsection}{\numberline {16.9.6}Evalution of the Default Hyperparameters}{329}{subsection.16.9.6}%
\contentsline {subsection}{\numberline {16.9.7}Plot: Compare Predictions}{330}{subsection.16.9.7}%
\contentsline {subsection}{\numberline {16.9.8}Cross-validated Evaluations}{331}{subsection.16.9.8}%
\contentsline {subsection}{\numberline {16.9.9}Detailed Hyperparameter Plots}{332}{subsection.16.9.9}%
\contentsline {subsection}{\numberline {16.9.10}Parallel Coordinates Plot}{332}{subsection.16.9.10}%
\contentsline {subsection}{\numberline {16.9.11}Plot all Combinations of Hyperparameters}{333}{subsection.16.9.11}%
\contentsline {chapter}{\numberline {17}HPT PyTorch Lightning: VBDP}{334}{chapter.17}%
\contentsline {section}{\numberline {17.1}Step 1: Setup}{335}{section.17.1}%
\contentsline {section}{\numberline {17.2}Step 2: Initialization of the \texttt {fun\_control} Dictionary}{335}{section.17.2}%
\contentsline {section}{\numberline {17.3}Step 3: PyTorch Data Loading}{336}{section.17.3}%
\contentsline {subsection}{\numberline {17.3.1}Lightning Dataset and DataModule}{336}{subsection.17.3.1}%
\contentsline {section}{\numberline {17.4}Step 4: Preprocessing}{336}{section.17.4}%
\contentsline {section}{\numberline {17.5}Step 5: Select the NN Model (\texttt {algorithm}) and \texttt {core\_model\_hyper\_dict}}{337}{section.17.5}%
\contentsline {section}{\numberline {17.6}Step 6: Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{337}{section.17.6}%
\contentsline {section}{\numberline {17.7}Step 7: Data Splitting, the Objective (Loss) Function and the Metric}{339}{section.17.7}%
\contentsline {subsection}{\numberline {17.7.1}Evaluation}{339}{subsection.17.7.1}%
\contentsline {subsection}{\numberline {17.7.2}Loss Functions and Metrics}{339}{subsection.17.7.2}%
\contentsline {subsection}{\numberline {17.7.3}Metric}{339}{subsection.17.7.3}%
\contentsline {section}{\numberline {17.8}Step 8: Calling the SPOT Function}{340}{section.17.8}%
\contentsline {subsection}{\numberline {17.8.1}Preparing the SPOT Call}{340}{subsection.17.8.1}%
\contentsline {subsection}{\numberline {17.8.2}The Objective Function \texttt {fun}}{340}{subsection.17.8.2}%
\contentsline {subsection}{\numberline {17.8.3}Starting the Hyperparameter Tuning}{340}{subsection.17.8.3}%
\contentsline {section}{\numberline {17.9}Step 9: Tensorboard}{347}{section.17.9}%
\contentsline {section}{\numberline {17.10}Step 10: Results}{348}{section.17.10}%
\contentsline {subsection}{\numberline {17.10.1}Get the Tuned Architecture}{349}{subsection.17.10.1}%
\contentsline {subsection}{\numberline {17.10.2}Cross Validation With Lightning}{350}{subsection.17.10.2}%
\contentsline {subsection}{\numberline {17.10.3}Detailed Hyperparameter Plots}{354}{subsection.17.10.3}%
\contentsline {subsection}{\numberline {17.10.4}Parallel Coordinates Plot}{354}{subsection.17.10.4}%
\contentsline {subsection}{\numberline {17.10.5}Plot all Combinations of Hyperparameters}{355}{subsection.17.10.5}%
\contentsline {subsection}{\numberline {17.10.6}Visualizing the Activation Distribution}{355}{subsection.17.10.6}%
\contentsline {section}{\numberline {17.11}Submission}{357}{section.17.11}%
\contentsline {section}{\numberline {17.12}Appendix}{359}{section.17.12}%
\contentsline {subsection}{\numberline {17.12.1}Differences to the spotPython Approaches for \texttt {torch}, \texttt {sklearn} and \texttt {river}}{359}{subsection.17.12.1}%
\contentsline {subsubsection}{\numberline {17.12.1.1}Specification of the Preprocessing Model}{359}{subsubsection.17.12.1.1}%
\contentsline {subsection}{\numberline {17.12.2}Taking a Look at the Data}{360}{subsection.17.12.2}%
\contentsline {subsection}{\numberline {17.12.3}The MAPK Metric}{361}{subsection.17.12.3}%
\contentsline {part}{Appendices}{362}{section*.176}%
\contentsline {chapter}{\numberline {A}Documentation of the Sequential Parameter Optimization}{362}{appendix.A}%
\contentsline {section}{\numberline {A.1}Example: spot}{362}{section.A.1}%
\contentsline {subsection}{\numberline {A.1.1}The Objective Function}{362}{subsection.A.1.1}%
\contentsline {subsection}{\numberline {A.1.2}External Parameters}{364}{subsection.A.1.2}%
\contentsline {section}{\numberline {A.2}The \texttt {fun\_control} Dictionary}{367}{section.A.2}%
\contentsline {section}{\numberline {A.3}The \texttt {design\_control} Dictionary}{367}{section.A.3}%
\contentsline {section}{\numberline {A.4}The \texttt {surrogate\_control} Dictionary}{368}{section.A.4}%
\contentsline {section}{\numberline {A.5}The \texttt {optimizer\_control} Dictionary}{368}{section.A.5}%
\contentsline {section}{\numberline {A.6}Run}{369}{section.A.6}%
\contentsline {section}{\numberline {A.7}Print the Results}{371}{section.A.7}%
\contentsline {section}{\numberline {A.8}Show the Progress}{371}{section.A.8}%
\contentsline {section}{\numberline {A.9}Visualize the Surrogate}{371}{section.A.9}%
\contentsline {section}{\numberline {A.10}Init: Build Initial Design}{372}{section.A.10}%
\contentsline {section}{\numberline {A.11}Replicability}{373}{section.A.11}%
\contentsline {section}{\numberline {A.12}Surrogates}{374}{section.A.12}%
\contentsline {subsection}{\numberline {A.12.1}A Simple Predictor}{374}{subsection.A.12.1}%
\contentsline {section}{\numberline {A.13}Demo/Test: Objective Function Fails}{374}{section.A.13}%
\contentsline {section}{\numberline {A.14}PyTorch: Detailed Description of the Data Splitting}{377}{section.A.14}%
\contentsline {subsection}{\numberline {A.14.1}Description of the \texttt {"train\_hold\_out"} Setting}{377}{subsection.A.14.1}%
\contentsline {subsubsection}{\numberline {A.14.1.1}Description of the \texttt {"test\_hold\_out"} Setting}{380}{subsubsection.A.14.1.1}%
\contentsline {subsubsection}{\numberline {A.14.1.2}Detailed Description of the \texttt {"train\_cv"} Setting}{381}{subsubsection.A.14.1.2}%
\contentsline {subsubsection}{\numberline {A.14.1.3}Detailed Description of the \texttt {"test\_cv"} Setting}{385}{subsubsection.A.14.1.3}%
\contentsline {subsubsection}{\numberline {A.14.1.4}Detailed Description of the Final Model Training and Evaluation}{385}{subsubsection.A.14.1.4}%
\contentsline {chapter}{References}{388}{chapter*.183}%
\providecommand \tocbasic@end@toc@file {}\tocbasic@end@toc@file 
