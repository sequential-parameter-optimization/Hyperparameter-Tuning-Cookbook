<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>2&nbsp; Introduction to scipy.optimize – Hyperparameter Tuning Cookbook</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./001_surrogate.html" rel="next">
<link href="./002_awwe.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-93074729595c0d1bb0917954c6b21507.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta name="twitter:title" content="2&nbsp; Introduction to scipy.optimize – Hyperparameter Tuning Cookbook">
<meta name="twitter:description" content="">
<meta name="twitter:image" content="003_scipy_optimize_intro_files/figure-html/cell-8-output-1.png">
<meta name="twitter:card" content="summary_large_image">
<meta name="citation_title" content="[2]{.chapter-number}&nbsp; [Introduction to `scipy.optimize`]{.chapter-title}">
<meta name="citation_fulltext_html_url" content="https://arxiv.org/abs/2307.10262">
<meta name="citation_doi" content="10.48550/arXiv.2307.10262">
<meta name="citation_language" content="en">
<meta name="citation_journal_title" content="arXiv">
<meta name="citation_reference" content="citation_title=Benchmarking in Optimization: Best Practice and Open Issues;,citation_author=Thomas Bartz-Beielstein;,citation_author=Carola Doerr;,citation_author=Jakob Bossek;,citation_author=Sowmya Chandrasekaran;,citation_author=Tome Eftimov;,citation_author=Andreas Fischbach;,citation_author=Pascal Kerschke;,citation_author=Manuel Lopez-Ibanez;,citation_author=Katherine M. Malan;,citation_author=Jason H. Moore;,citation_author=Boris Naujoks;,citation_author=Patryk Orzechowski;,citation_author=Vanessa Volz;,citation_author=Markus Wagner;,citation_author=Thomas Weise;,citation_publication_date=2020-07;,citation_cover_date=2020-07;,citation_year=2020;,citation_fulltext_html_url=https://arxiv.org/abs/2007.03488;,citation_publisher=arXiv;">
<meta name="citation_reference" content="citation_title=Hyperparameter Tuning With Ray Tune;,citation_author=undefined PyTorch;,citation_publication_date=2023-05;,citation_cover_date=2023-05;,citation_year=2023;,citation_fulltext_html_url=https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html;">
<meta name="citation_reference" content="citation_title=Training a Classifier;,citation_author=undefined PyTorch;,citation_publication_date=2023-05;,citation_cover_date=2023-05;,citation_year=2023;,citation_fulltext_html_url=https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html;">
<meta name="citation_reference" content="citation_title=PyTorch Hyperparameter Tuning with SPOT: Comparison with Ray Tuner and Default Hyperparameters on CIFAR10;,citation_author=Thomas Bartz-Beielstein;,citation_publication_date=2023-04;,citation_cover_date=2023-04;,citation_year=2023;,citation_fulltext_html_url=https://github.com/sequential-parameter-optimization/spotpython/blob/main/notebooks/14_spot_ray_hpt_torch_cifar10.ipynb;">
<meta name="citation_reference" content="citation_title=Machine Learning in Official Statistics;,citation_author=Martin Beck;,citation_author=Florian Dumpert;,citation_author=Joerg Feuerhake;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_doi=10.48550/arXiv.1812.10422;">
<meta name="citation_reference" content="citation_title=Qualitätshandbuch der Statistischen Ämter des Bundes und der Länder;,citation_publication_date=2021-03;,citation_cover_date=2021-03;,citation_year=2021;,citation_fulltext_html_url=https://www.destatis.de/DE/Methoden/Qualitaet/qualitaetshandbuch.pdf;,citation_language=de;">
<meta name="citation_reference" content="citation_title=Quality Assurance Framework of the European Statistical System;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_fulltext_html_url=https://ec.europa.eu/eurostat/documents/64157/4392716/ESS-QAF-V2.0-final.pdf;,citation_language=en;">
<meta name="citation_reference" content="citation_title=Standardisierung der Prozesse: 14 Jahre AG SteP;,citation_author=T. Blumöhr;,citation_author=C. Teichmann;,citation_author=A. Noack;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_fulltext_html_url=https://www.destatis.de/DE/Methoden/
               WISTA-Wirtschaft-und-Statistik/2017/05/standardisierung-prozesse-052017.html;,citation_volume=5;,citation_journal_title=WISTA - Wirtschaft und Statistik;,citation_publisher=Wiesbaden: Statistisches Bundesamt (Destatis);">
<meta name="citation_reference" content="citation_title=Generic Statistical Business Process Model - GSBPM;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_fulltext_html_url=https://statswiki.unece.org/display/
               GSBPM/GSBPM+v5.1;,citation_publisher=United Nations Economic Commission for Europe (UNECE);">
<meta name="citation_reference" content="citation_title=Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide;,citation_editor=Eva Bartz;,citation_editor=Thomas Bartz-Beielstein;,citation_editor=Martin Zaefferer;,citation_editor=Olaf Mersmann;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=Engineering Design via Surrogate Modelling;,citation_author=Alexander Forrester;,citation_author=András Sóbester;,citation_author=Andy Keane;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;">
<meta name="citation_reference" content="citation_title=No Free Lunch Theorems for Optimization;,citation_author=David H Wolpert;,citation_author=William G Macready;,citation_publication_date=1997-04;,citation_cover_date=1997-04;,citation_year=1997;,citation_issue=1;,citation_volume=1;,citation_journal_title=IEEE Transactions on Evolutionary Computation;">
<meta name="citation_reference" content="citation_title=An Introduction to Statistical Learning with Applications in R;,citation_author=Gareth James;,citation_author=Daniela Witten;,citation_author=Trevor Hastie;,citation_author=Robert Tibshirani;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;">
<meta name="citation_reference" content="citation_title=Requirements for papers focusing on new or improved global optimization algorithms;,citation_author=Raphael T. Haftka;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_issue=1;,citation_volume=54;,citation_journal_title=Structural and Multidisciplinary Optimization;">
<meta name="citation_reference" content="citation_title=LightGBM: A Highly Efficient Gradient Boosting Decision Tree;,citation_author=Guolin Ke;,citation_author=Qi Meng;,citation_author=Thomas Finley;,citation_author=Taifeng Wang;,citation_author=Wei Chen;,citation_author=Weidong Ma;,citation_author=Qiwei Ye;,citation_author=Tie-Yan Liu;,citation_editor=I. Guyon;,citation_editor=U. Von Luxburg;,citation_editor=S. Bengio;,citation_editor=H. Wallach;,citation_editor=R. Fergus;,citation_editor=S. Vishwanathan;,citation_editor=R. Garnett;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_volume=30;,citation_conference_title=Advances in Neural Information Processing Systems;,citation_conference=Curran Associates, Inc.;">
<meta name="citation_reference" content="citation_title=Greedy Function Approximation: A Gradient Boosting Machine;,citation_author=Jerome H. Friedman;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_issue=5;,citation_volume=29;,citation_journal_title=The Annals of Statistics;">
<meta name="citation_reference" content="citation_title=Machine Learning in Official Statistics;,citation_author=Martin Beck;,citation_author=Florian Dumpert;,citation_author=Joerg Feuerhake;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_doi=10.48550/arXiv.1812.10422;">
<meta name="citation_reference" content="citation_title=Official statistics in the era of big data opportunities and threats;,citation_author=Walter J. Radermacher;,citation_publication_date=2018-11-01;,citation_cover_date=2018-11-01;,citation_year=2018;,citation_fulltext_html_url=https://doi.org/10.1007/s41060-018-0124-z;,citation_issue=3;,citation_doi=10.1007/s41060-018-0124-z;,citation_volume=6;,citation_language=en;,citation_journal_title=International Journal of Data Science and Analytics;">
<meta name="citation_reference" content="citation_title=Machine Learning in Official Statistics;,citation_author=Martin Beck;,citation_author=Florian Dumpert;,citation_author=Joerg Feuerhake;">
<meta name="citation_reference" content="citation_title=A quality framework for statistical algorithms;,citation_author=Wesley Yung;,citation_author=Siu-Ming Tam;,citation_author=Bart Buelens;,citation_author=Hugh Chipman;,citation_author=Florian Dumpert;,citation_author=Gabriele Ascari;,citation_author=Fabiana Rocci;,citation_author=Joep Burger;,citation_author=InKyung Choi;,citation_publication_date=2022-01-01;,citation_cover_date=2022-01-01;,citation_year=2022;,citation_fulltext_html_url=https://content.iospress.com/articles/statistical-journal-of-the-iaos/sji210875;,citation_issue=1;,citation_doi=10.3233/SJI-210875;,citation_volume=38;,citation_language=en;,citation_journal_title=Statistical Journal of the IAOS;">
<meta name="citation_reference" content="citation_title=A quality framework for statistical algorithms;,citation_author=Wesley Yung;,citation_author=Siu-Ming Tam;,citation_author=Bart Buelens;,citation_author=Hugh Chipman;,citation_author=Florian Dumpert;,citation_author=Gabriele Ascari;,citation_author=Fabiana Rocci;,citation_author=Joep Burger;,citation_author=InKyung Choi;,citation_publication_date=2022-01;,citation_cover_date=2022-01;,citation_year=2022;,citation_issue=1;,citation_volume=38;,citation_journal_title=Statistical Journal of the IAOS;">
<meta name="citation_reference" content="citation_title=Qualitätshandbuch der Statistischen Ämter des Bundes und der Länder;,citation_author=Michael Reichelt;">
<meta name="citation_reference" content="citation_title=Data Science and Official Statistics: Toward a New Data Culture;,citation_author=Stefan Schweinfest;,citation_author=Ronald Jansen;,citation_publication_date=2021-10-28;,citation_cover_date=2021-10-28;,citation_year=2021;,citation_fulltext_html_url=https://hdsr.mitpress.mit.edu/pub/1g514ljw/release/4;,citation_issue=4;,citation_doi=10.1162/99608f92.c1237762;,citation_volume=3;,citation_language=en;,citation_journal_title=Harvard Data Science Review;">
<meta name="citation_reference" content="citation_title=Official Statistics 4.0: Verified Facts for People in the 21st Century;,citation_author=Walter J. Radermacher;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;">
<meta name="citation_reference" content="citation_title=Detecting Covariate Drift with Explanations;,citation_author=Steffen Castle;,citation_author=Robert Schwarzenberg;,citation_author=Mohsen Pourvali;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_conference_title=Natural Language Processing and Chinese Computing: 10th CCF International Conference, NLPCC 2021, Qingdao, China, October 13–17, 2021, Proceedings, Part II;,citation_conference=Springer-Verlag;">
<meta name="citation_reference" content="citation_title=Keras;,citation_author=Francois Chollet;,citation_author=others;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_publisher=https:://keras.io;">
<meta name="citation_reference" content="citation_title=TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems;,citation_author=Martin Abadi;,citation_author=Ashish Agarwal;,citation_author=Paul Barham;,citation_author=Eugene Brevdo;,citation_author=Zhifeng Chen;,citation_author=Craig Citro;,citation_author=Greg S. Corrado;,citation_author=Andy Davis;,citation_author=Jeffrey Dean;,citation_author=Matthieu Devin;,citation_author=Sanjay Ghemawat;,citation_author=Ian Goodfellow;,citation_author=Andrew Harp;,citation_author=Geoffrey Irving;,citation_author=Michael Isard;,citation_author=Yangqing Jia;,citation_author=Rafal Jozefowicz;,citation_author=Lukasz Kaiser;,citation_author=Manjunath Kudlur;,citation_author=Josh Levenberg;,citation_author=Dan Mane;,citation_author=Rajat Monga;,citation_author=Sherry Moore;,citation_author=Derek Murray;,citation_author=Chris Olah;,citation_author=Mike Schuster;,citation_author=Jonathon Shlens;,citation_author=Benoit Steiner;,citation_author=Ilya Sutskever;,citation_author=Kunal Talwar;,citation_author=Paul Tucker;,citation_author=Vincent Vanhoucke;,citation_author=Vijay Vasudevan;,citation_author=Fernanda Viegas;,citation_author=Oriol Vinyals;,citation_author=Pete Warden;,citation_author=Martin Wattenberg;,citation_author=Martin Wicke;,citation_author=Yuan Yu;,citation_author=Xiaoqiang Zheng;,citation_publication_date=2016-03;,citation_cover_date=2016-03;,citation_year=2016;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=statsmodels: Econometric and statistical modeling with python;,citation_author=Skipper Seabold;,citation_author=Josef Perktold;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_conference_title=9th Python in Science Conference;">
<meta name="citation_reference" content="citation_title=Scikit-learn: Machine Learning in Python;,citation_author=F. Pedregosa;,citation_author=G. Varoquaux;,citation_author=A. Gramfort;,citation_author=V. Michel;,citation_author=B. Thirion;,citation_author=O. Grisel;,citation_author=M. Blondel;,citation_author=P. Prettenhofer;,citation_author=R. Weiss;,citation_author=V. Dubourg;,citation_author=J. Vanderplas;,citation_author=A. Passos;,citation_author=D. Cournapeau;,citation_author=M. Brucher;,citation_author=M. Perrot;,citation_author=E. Duchesnay;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_volume=12;,citation_journal_title=Journal of Machine Learning Research;">
<meta name="citation_reference" content="citation_title=Array programming with NumPy;,citation_author=Charles R. Harris;,citation_author=K. Jarrod Millman;,citation_author=Stéfan J. Walt;,citation_author=Ralf Gommers;,citation_author=Pauli Virtanen;,citation_author=David Cournapeau;,citation_author=Eric Wieser;,citation_author=Julian Taylor;,citation_author=Sebastian Berg;,citation_author=Nathaniel J. Smith;,citation_author=Robert Kern;,citation_author=Matti Picus;,citation_author=Stephan Hoyer;,citation_author=Marten H. Kerkwijk;,citation_author=Matthew Brett;,citation_author=Allan Haldane;,citation_author=Jaime Fernández Río;,citation_author=Mark Wiebe;,citation_author=Pearu Peterson;,citation_author=Pierre Gérard-Marchant;,citation_author=Kevin Sheppard;,citation_author=Tyler Reddy;,citation_author=Warren Weckesser;,citation_author=Hameer Abbasi;,citation_author=Christoph Gohlke;,citation_author=Travis E. Oliphant;,citation_publication_date=2020-09;,citation_cover_date=2020-09;,citation_year=2020;,citation_issue=7825;,citation_volume=585;,citation_journal_title=Nature;">
<meta name="citation_reference" content="citation_title=Algorithms for Learning Regression Trees and Ensembles on Evolving Data Streams;,citation_author=Elena Ikonomovska;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_dissertation_institution=Jozef Stefan International Postgraduate School;">
<meta name="citation_reference" content="citation_title=Online Bagging and Boosting;,citation_author=N C Oza;,citation_conference_title=2005 IEEE International Conference on Systems, Man and Cybernetics;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Online bagging and boosting;,citation_author=Nikunj C Oza;,citation_author=Stuart Russell;,citation_editor=T Jaakola;,citation_editor=T Richardson;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_conference_title=8th Insternational Workshop on Artificial Intelligence and Statistics;">
<meta name="citation_reference" content="citation_title=Event labeling combining ensemble detectors and background knowledge;,citation_author=Hadi Fanaee-T;,citation_author=Joao Gama;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=2;,citation_volume=2;,citation_journal_title=Progress in Artificial Intelligence;">
<meta name="citation_reference" content="citation_title=Adaptive random forests for evolving data stream classification;,citation_author=Heitor M. Gomes;,citation_author=Albert Bifet;,citation_author=Jesse Read;,citation_author=Jean Paul Barddal;,citation_author=Fabricio Enembreck;,citation_author=Bernhard Pfharinger;,citation_author=Geoff Holmes;,citation_author=Talel Abdessalem;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=9;,citation_volume=106;,citation_journal_title=Machine Learning;">
<meta name="citation_reference" content="citation_title=Literate Programming;,citation_author=Donald E. Knuth;,citation_publication_date=1984-05;,citation_cover_date=1984-05;,citation_year=1984;,citation_fulltext_html_url=https://doi.org/10.1093/comjnl/27.2.97;,citation_issue=2;,citation_doi=10.1093/comjnl/27.2.97;,citation_issn=0010-4620;,citation_volume=27;,citation_journal_title=Comput. J.;,citation_publisher=Oxford University Press, Inc.;">
<meta name="citation_reference" content="citation_title=A Review and Taxonomy of Interactive Optimization Methods in Operations Research;,citation_author=David Meignan;,citation_author=Sigrid Knust;,citation_author=Jean-Marc Frayet;,citation_author=Gilles Pesant;,citation_author=Nicolas Gaud;,citation_publication_date=2015-09;,citation_cover_date=2015-09;,citation_year=2015;,citation_journal_title=ACM Transactions on Interactive Intelligent Systems;">
<meta name="citation_reference" content="citation_title=Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide;,citation_editor=Eva Bartz;,citation_editor=Thomas Bartz-Beielstein;,citation_editor=Martin Zaefferer;,citation_editor=Olaf Mersmann;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=In a Nutshell – The Sequential Parameter Optimization Toolbox;,citation_author=Thomas Bartz-Beielstein;,citation_author=Martin Zaefferer;,citation_author=Frederik Rehbach;,citation_publication_date=2021-12;,citation_cover_date=2021-12;,citation_year=2021;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Direct search methods: Then and now;,citation_author=R M Lewis;,citation_author=V Torczon;,citation_author=M W Trosset;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_issue=1–2;,citation_volume=124;,citation_journal_title=Journal of Computational and Applied Mathematics;">
<meta name="citation_reference" content="citation_title=Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization;,citation_author=Lisha Li;,citation_author=Kevin Jamieson;,citation_author=Giulia DeSalvo;,citation_author=Afshin Rostamizadeh;,citation_author=Ameet Talwalkar;,citation_publication_date=2016-03;,citation_cover_date=2016-03;,citation_year=2016;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Sequential Parameter Optimization;,citation_author=Thomas Bartz-Beielstein;,citation_author=Christian Lasarczyk;,citation_author=Mike Preuss;,citation_editor=B McKay;,citation_editor=others;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_conference_title=Proceedings 2005 Congress on Evolutionary Computation (CEC’05), Edinburgh, Scotland;,citation_conference=IEEE Press;">
<meta name="citation_reference" content="citation_title=Evolutionary Algorithms;,citation_author=Thomas Bartz-Beielstein;,citation_author=Jürgen Branke;,citation_author=Jörn Mehnen;,citation_author=Olaf Mersmann;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=3;,citation_volume=4;,citation_journal_title=Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery;">
<meta name="citation_reference" content="citation_title=Classification and Regression Trees;,citation_author=L Breiman;,citation_author=J H Friedman;,citation_author=R A Olshen;,citation_author=C J Stone;,citation_publication_date=1984;,citation_cover_date=1984;,citation_year=1984;">
<meta name="citation_reference" content="citation_title=Continuous inspection schemes;,citation_author=E. S. Page;,citation_publication_date=1954-06;,citation_cover_date=1954-06;,citation_year=1954;,citation_issue=1-2;,citation_volume=41;,citation_journal_title=Biometrika;">
<meta name="citation_reference" content="citation_title=Counting Large Numbers of Events in Small Registers;,citation_author=Robert Morris;,citation_publication_date=1978-10;,citation_cover_date=1978-10;,citation_year=1978;,citation_issue=10;,citation_volume=21;,citation_journal_title=Commun. ACM;">
<meta name="citation_reference" content="citation_title=Approximate Counting: A Detailed Analysis;,citation_author=Philippe Flajolet;,citation_publication_date=1985-03;,citation_cover_date=1985-03;,citation_year=1985;,citation_issue=1;,citation_volume=25;,citation_journal_title=BIT;">
<meta name="citation_reference" content="citation_title=Random Sampling with a Reservoir;,citation_author=Jeffrey S. Vitter;,citation_publication_date=1985-03;,citation_cover_date=1985-03;,citation_year=1985;,citation_issue=1;,citation_volume=11;,citation_journal_title=ACM Trans. Math. Softw.;">
<meta name="citation_reference" content="citation_title=Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem;,citation_author=Michael McCloskey;,citation_author=Neal J. Cohen;,citation_publication_date=1989-01;,citation_cover_date=1989-01;,citation_year=1989;,citation_issue=C;,citation_volume=24;,citation_journal_title=Psychology of Learning and Motivation - Advances in Research and Theory;">
<meta name="citation_reference" content="citation_title=Detection of Abrupt Changes - Theory and Application;,citation_author=Michèle Basseville;,citation_author=Igor V. Nikiforov;,citation_publication_date=1993;,citation_cover_date=1993;,citation_year=1993;">
<meta name="citation_reference" content="citation_title=An Introduction to Computational Learning Theory;,citation_author=Michael J. Kearns;,citation_author=Umesh V. Vazirani;,citation_publication_date=1994;,citation_cover_date=1994;,citation_year=1994;">
<meta name="citation_reference" content="citation_title=An Introduction to the Kalman Filter;,citation_author=Greg Welch;,citation_author=Gary Bishop;,citation_publication_date=1995;,citation_cover_date=1995;,citation_year=1995;">
<meta name="citation_reference" content="citation_title=The Space Complexity of Approximating the Frequency Moments;,citation_author=Noga Alon;,citation_author=Yossi Matias;,citation_author=Mario Szegedy;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_conference_title=Proceedings of the Twenty-Eighth Annual ACM Symposium on Theory of Computing;,citation_conference=Association for Computing Machinery;,citation_series_title=STOC ’96;">
<meta name="citation_reference" content="citation_title=SPLICE-2 Comparative Evaluation: Electricity Pricing;,citation_author=Michael Harries;,citation_author=U Nsw-cse-tr;,citation_author=New South Wales;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;">
<meta name="citation_reference" content="citation_title=Mining high-speed data streams;,citation_author=Pedro M. Domingos;,citation_author=Geoff Hulten;,citation_editor=Raghu Ramakrishnan;,citation_editor=Salvatore J. Stolfo;,citation_editor=Roberto J. Bayardo;,citation_editor=Ismail Parsa;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_conference_title=Proceedings of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining, Boston, MA, USA, August 20-23, 2000;,citation_conference=ACM;">
<meta name="citation_reference" content="citation_title=Mining Time-Changing Data Streams;,citation_author=Geoff Hulten;,citation_author=Laurie Spencer;,citation_author=Pedro Domingos;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_conference_title=Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;,citation_conference=Association for Computing Machinery;,citation_series_title=KDD ’01;">
<meta name="citation_reference" content="citation_title=A Streaming Ensemble Algorithm (SEA) for Large-Scale Classification;,citation_author=W. Nick Street;,citation_author=YongSeog Kim;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_conference_title=Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;,citation_conference=Association for Computing Machinery;,citation_series_title=KDD ’01;">
<meta name="citation_reference" content="citation_title=3D Data Management: Controlling Data Volume, Velocity, and Variety;,citation_author=Douglas Laney;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_technical_report_institution=META Group;">
<meta name="citation_reference" content="citation_title=Models and Issues in Data Stream Systems;,citation_author=Brian Babcock;,citation_author=Shivnath Babu;,citation_author=Mayur Datar;,citation_author=Rajeev Motwani;,citation_author=Jennifer Widom;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_conference_title=Proceedings of the 21st ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems;,citation_conference=ACM;,citation_series_title=PODS ’02;">
<meta name="citation_reference" content="citation_title=A New Approximate Maximal Margin Classification Algorithm;,citation_author=Claudio Gentile;,citation_publication_date=2002-03;,citation_cover_date=2002-03;,citation_year=2002;,citation_volume=2;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=The Design and Analysis of Computer Experiments;,citation_author=T J Santner;,citation_author=B J Williams;,citation_author=W I Notz;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;">
<meta name="citation_reference" content="citation_title=Learning with drift detection;,citation_author=João Gama;,citation_author=Pedro Medas;,citation_author=Gladys Castillo;,citation_author=Pedro Rodrigues;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_conference_title=In SBIA Brazilian Symposium on Artificial Intelligence;,citation_conference=Springer Verlag;">
<meta name="citation_reference" content="citation_title=Learning with Drift Detection;,citation_author=João Gama;,citation_author=Pedro Medas;,citation_author=Gladys Castillo;,citation_author=Pedro Rodrigues;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_inbook_title=Parallel Problem Solving from Nature - PPSN XIII - 13th International Conference, Ljubljana, Slovenia, September 13-17, 2014. Proceedings;">
<meta name="citation_reference" content="citation_title=Learning with Drift Detection;,citation_author=João Gama;,citation_author=Pedro Medas;,citation_author=Gladys Castillo;,citation_author=Pedro Rodrigues;,citation_editor=Ana L. C. Bazzan;,citation_editor=Sofiane Labidi;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_conference_title=Advances in Artificial Intelligence – SBIA 2004;,citation_conference=Springer Berlin Heidelberg;">
<meta name="citation_reference" content="citation_title=Statistical Analysis of Massive Data Streams: Proceedings of a Workshop;,citation_editor=Sallie Keller-McNulty;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;">
<meta name="citation_reference" content="citation_title=Data Mining: Practical Machine Learning Tools and Techniques;,citation_author=Ian H. Witten;,citation_author=Eibe Frank;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_series_title=The Morgan Kaufmann Series in Data Management Systems;">
<meta name="citation_reference" content="citation_title=Towards Generic Pattern Mining;,citation_author=Mohammed Javeed Zaki;,citation_author=Nagender Parimi;,citation_author=Nilanjana De;,citation_author=Feng Gao;,citation_author=Benjarath Phoophakdee;,citation_author=Joe Urban;,citation_author=Vineet Chaoji;,citation_author=Mohammad Al Hasan;,citation_author=Saeed Salem;,citation_editor=Bernhard Ganter;,citation_editor=Robert Godin;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_volume=3403;,citation_conference_title=Formal Concept Analysis, Third International Conference, ICFCA 2005, Lens, France, February 14-18, 2005, Proceedings;,citation_conference=Springer;,citation_series_title=Lecture Notes in Computer Science;">
<meta name="citation_reference" content="citation_title=Mining Data Streams: A Review;,citation_author=Mohamed Medhat Gaber;,citation_author=Arkady Zaslavsky;,citation_author=Shonali Krishnaswamy;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_volume=34;,citation_journal_title=SIGMOD Rec.;">
<meta name="citation_reference" content="citation_title=Early drift detection method;,citation_author=Manuel Baena-Garcıa;,citation_author=José Campo-Ávila;,citation_author=Raúl Fidalgo;,citation_author=Albert Bifet;,citation_author=R Gavalda;,citation_author=Rafael Morales-Bueno;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_volume=6;,citation_conference_title=Fourth international workshop on knowledge discovery from data streams;">
<meta name="citation_reference" content="citation_title=Online Passive-Aggressive Algorithms;,citation_author=Koby Crammer;,citation_author=Ofer Dekel;,citation_author=Joseph Keshet;,citation_author=Shai Shalev-Shwartz;,citation_author=Yoram Singer;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=19;,citation_volume=7;,citation_journal_title=Journal of Machine Learning Research;">
<meta name="citation_reference" content="citation_title=Data Streams – Models and Algorithms;,citation_editor=Charu Aggarwal;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;">
<meta name="citation_reference" content="citation_title=Learning from Time-Changing Data with Adaptive Windowing;,citation_author=Albert Bifet;,citation_author=Ricard Gavaldà;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_conference_title=Proceedings of the 2007 SIAM International Conference on Data Mining (SDM);">
<meta name="citation_reference" content="citation_title=Learning from time-changing data with adaptive windowing;,citation_author=Albert Bifet;,citation_author=Ricard Gavalda;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_volume=7;,citation_conference_title=Proceedings of the 2007 SIAM international conference on data mining;,citation_conference=SIAM;">
<meta name="citation_reference" content="citation_title=A Survey of Classification Methods in Data Streams;,citation_author=Mohamed Gaber;,citation_author=Arkady Zaslavsky;,citation_author=Shonali Krishnaswamy;,citation_editor=Charu Aggarwal;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_inbook_title=Data Streams – Models and Algorithms;">
<meta name="citation_reference" content="citation_title=Use of Hoeffding trees in concept based data stream mining;,citation_author=Stefan Hoeglinger;,citation_author=Russel Pears;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_journal_title=2007 Third International Conference on Information and Automation for Sustainability;">
<meta name="citation_reference" content="citation_title=Detecting concept drift using statistical testing;,citation_author=Kyosuke Nishida;,citation_author=Koichiro Yamauchi;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_conference_title=International conference on discovery science;,citation_conference=Springer;">
<meta name="citation_reference" content="citation_title=Olindda: A cluster-based approach for detecting novelty and concept drift in data streams;,citation_author=Eduardo J Spinosa;,citation_author=André Ponce Leon F. de Carvalho;,citation_author=Joao Gama;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_conference_title=Proceedings of the 2007 ACM symposium on Applied computing;">
<meta name="citation_reference" content="citation_title=Statistical Quality Control;,citation_author=Douglas C Montgomery;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;">
<meta name="citation_reference" content="citation_title=Adaptive Learning from Evolving Data Streams;,citation_author=Albert Bifet;,citation_author=Ricard Gavaldà;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=Proceedings of the 8th International Symposium on Intelligent Data Analysis: Advances in Intelligent Data Analysis VIII;,citation_conference=Springer-Verlag;,citation_series_title=IDA ’09;">
<meta name="citation_reference" content="citation_title=New Ensemble Methods for Evolving Data Streams;,citation_author=Albert Bifet;,citation_author=Geoff Holmes;,citation_author=Bernhard Pfahringer;,citation_author=Richard Kirkby;,citation_author=Ricard Gavaldà;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;,citation_conference=Association for Computing Machinery;,citation_series_title=KDD ’09;">
<meta name="citation_reference" content="citation_title=Adaptive concept drift detection;,citation_author=Anton Dries;,citation_author=Ulrich Rückert;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=5-6;,citation_volume=2;,citation_journal_title=Stat. Anal. Data Min.;">
<meta name="citation_reference" content="citation_title=Issues in Evaluation of Stream Learning Algorithms;,citation_author=João Gama;,citation_author=Raquel Sebastião;,citation_author=Pedro Pereira Rodrigues;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;,citation_conference=Association for Computing Machinery;,citation_series_title=KDD ’09;">
<meta name="citation_reference" content="citation_title=Stream Data Processing: A Quality of Service Perspective;,citation_author=Qingchun Jiang;,citation_author=Sharma Chakravarthy;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;">
<meta name="citation_reference" content="citation_title=Probabilistic Counting with Randomized Storage;,citation_author=Benjamin Van Durme;,citation_author=Ashwin Lall;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=Proceedings of the 21st International Joint Conference on Artificial Intelligence;,citation_conference=Morgan Kaufmann Publishers Inc.;,citation_series_title=IJCAI’09;">
<meta name="citation_reference" content="citation_title=Adaptive Stream Mining: Pattern Learning and Mining from Evolving Data Streams;,citation_author=Albert Bifet;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_volume=207;,citation_series_title=Frontiers in Artificial Intelligence and Applications;">
<meta name="citation_reference" content="citation_title=We’re not in kansas anymore: detecting domain changes in streams;,citation_author=Mark Dredze;,citation_author=Tim Oates;,citation_author=Christine Piatko;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_conference_title=Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing;">
<meta name="citation_reference" content="citation_title=Large-Scale Inference: Empirical Bayes Methods for Estimation, Testing, and Prediction (Institute of Mathematical Statistics Monographs);,citation_author=Bradley Efron;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;">
<meta name="citation_reference" content="citation_title=Knowledge Discovery from Data Streams;,citation_author=João Gama;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_series_title=Chapman and Hall / CRC Data Mining and Knowledge Discovery Series;">
<meta name="citation_reference" content="citation_title=A DCT based approach for detecting novelty and concept drift in data streams;,citation_author=Morteza Zi Hayat;,citation_author=Mahmoud Reza Hashemi;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_conference_title=2010 International Conference of Soft Computing and Pattern Recognition;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Benchmarking Stream Clustering Algorithms within the MOA Framework;,citation_author=Philipp Kranen;,citation_author=Hardy Kremer;,citation_author=Timm Jansen;,citation_author=Thomas Seidl;,citation_author=Albert Bifet;,citation_author=Geoff Holmes;,citation_author=Bernhard Pfahringer;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_conference_title=16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD 2010), Washington, DC, USA;">
<meta name="citation_reference" content="citation_title=MOA: Massive Online Analysis;,citation_author=Albert Bifet;,citation_author=Geoff Holmes;,citation_author=Richard Kirkby;,citation_author=Bernhard Pfahringer;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_volume=99;,citation_journal_title=Journal of Machine Learning Research;">
<meta name="citation_reference" content="citation_title=Hellinger distance based drift detection for nonstationary environments;,citation_author=Gregory Ditzler;,citation_author=Robi Polikar;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_conference_title=2011 IEEE symposium on computational intelligence in dynamic and uncertain environments (CIDUE);,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Classification and novel class detection in concept-drifting data streams under time constraints;,citation_author=Mohammad Masud;,citation_author=Jing Gao;,citation_author=Latifur Khan;,citation_author=Jiawei Han;,citation_author=Bhavani M Thuraisingham;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=6;,citation_volume=23;,citation_journal_title=IEEE Transactions on Knowledge and Data Engineering;">
<meta name="citation_reference" content="citation_title=New drift detection method for data streams;,citation_author=Parinaz Sobhani;,citation_author=Hamid Beigy;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_conference_title=International conference on adaptive and intelligent systems;,citation_conference=Springer;">
<meta name="citation_reference" content="citation_title=birch: Dealing With Very Large Datasets Using BIRCH;,citation_author=Lysiane Charest;,citation_author=Justin Harrington;,citation_author=Matias Salibian-Barrera;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;">
<meta name="citation_reference" content="citation_title=Synopses for Massive Data: Samples, Histograms, Wavelets, Sketches;,citation_author=Graham Cormode;,citation_author=Minos Garofalakis;,citation_author=Peter J. Haas;,citation_author=Chris Jermaine;,citation_publication_date=2012-01;,citation_cover_date=2012-01;,citation_year=2012;,citation_issue=1–3;,citation_volume=4;,citation_journal_title=Found. Trends Databases;">
<meta name="citation_reference" content="citation_title=Detection of concept drift for learning from stream data;,citation_author=Jeonghoon Lee;,citation_author=Frederic Magoules;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_conference_title=2012 IEEE 14th International Conference on High Performance Computing and Communication &amp;amp;amp; 2012 IEEE 9th International Conference on Embedded Software and Systems;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=mlbench: Machine Learning Benchmark Problems;,citation_author=Friedrich Leisch;,citation_author=Evgenia Dimitriadou;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;">
<meta name="citation_reference" content="citation_title=A unifying view on dataset shift in classification;,citation_author=Jose G. Moreno-Torres;,citation_author=Troy Raeder;,citation_author=Rocı́o Alaı́z-Rodrı́guez;,citation_author=Nitesh V. Chawla;,citation_author=Francisco Herrera;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=1;,citation_volume=45;,citation_journal_title=Pattern Recognit.;">
<meta name="citation_reference" content="citation_title=HadoopStreaming: Utilities for Using R Scripts in Hadoop Streaming;,citation_author=David S. Rosenberg;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;">
<meta name="citation_reference" content="citation_title=Exponentially weighted moving average charts for detecting concept drift;,citation_author=Gordon J Ross;,citation_author=Niall M Adams;,citation_author=Dimitris K Tasoulis;,citation_author=David J Hand;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=2;,citation_volume=33;,citation_journal_title=Pattern recognition letters;">
<meta name="citation_reference" content="citation_title=An efficient method of building an ensemble of classifiers in streaming data;,citation_author=Joung Woo Ryu;,citation_author=Mehmed M Kantardzic;,citation_author=Myung-Won Kim;,citation_author=A Ra Khil;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_conference_title=International Conference on Big Data Analytics;,citation_conference=Springer;">
<meta name="citation_reference" content="citation_title=rlecuyer: R Interface to RNG With Multiple Streams;,citation_author=Hana Sevcikova;,citation_author=Tony Rossini;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;">
<meta name="citation_reference" content="citation_title=Machine Learning that Matters;,citation_author=Kiri Wagstaff;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;">
<meta name="citation_reference" content="citation_title=CD-MOA: Change Detection Framework for Massive Online Analysis;,citation_author=Albert Bifet;,citation_author=Jesse Read;,citation_author=Bernhard Pfahringer;,citation_author=Geoff Holmes;,citation_author=Indrė Žliobaitė;,citation_editor=Allan Tucker;,citation_editor=Frank Höppner;,citation_editor=Arno Siebes;,citation_editor=Stephen Swift;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_conference_title=Advances in Intelligent Data Analysis XII;,citation_conference=Springer Berlin Heidelberg;">
<meta name="citation_reference" content="citation_title=Novelty detection algorithm for data streams multi-class problems;,citation_author=Elaine R Faria;,citation_author=João Gama;,citation_author=André CPLF Carvalho;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_conference_title=Proceedings of the 28th annual ACM symposium on applied computing;">
<meta name="citation_reference" content="citation_title=Turning Big Data into Tiny Data: Constant-Size Coresets for k-Means, PCA and Projective Clustering;,citation_author=Dan Feldman;,citation_author=Melanie Schmidt;,citation_author=Christian Sohler;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_conference_title=Proceedings of the Twenty-Fourth Annual ACM-SIAM Symposium on Discrete Algorithms;,citation_conference=Society for Industrial; Applied Mathematics;,citation_series_title=SODA ’13;">
<meta name="citation_reference" content="citation_title=On evaluating stream learning algorithms;,citation_author=João Gama;,citation_author=Raquel Sebastião;,citation_author=Pedro Pereira Rodrigues;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=3;,citation_volume=90;,citation_journal_title=Machine Learning;">
<meta name="citation_reference" content="citation_title=Scalable Strategies for Computing with Massive Data;,citation_author=Michael J. Kane;,citation_author=John Emerson;,citation_author=Stephen Weston;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=14;,citation_volume=55;,citation_journal_title=Journal of Statistical Software;">
<meta name="citation_reference" content="citation_title=RStorm: Simulate and Develop Streaming Processing in R;,citation_author=Maurits Kaptein;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;">
<meta name="citation_reference" content="citation_title=Drift detection using uncertainty distribution divergence;,citation_author=Patrick Lindstrom;,citation_author=Brian Mac Namee;,citation_author=Sarah Jane Delany;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=1;,citation_volume=4;,citation_journal_title=Evolving Systems;">
<meta name="citation_reference" content="citation_title=Ad Click Prediction: A View from the Trenches;,citation_author=H. Brendan McMahan;,citation_author=Gary Holt;,citation_author=D. Sculley;,citation_author=Michael Young;,citation_author=Dietmar Ebner;,citation_author=Julian Grady;,citation_author=Lan Nie;,citation_author=Todd Phillips;,citation_author=Eugene Davydov;,citation_author=Daniel Golovin;,citation_author=Sharat Chikkerur;,citation_author=Dan Liu;,citation_author=Martin Wattenberg;,citation_author=Arnar Mar Hrafnkelsson;,citation_author=Tom Boulos;,citation_author=Jeremy Kubica;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_conference_title=Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;,citation_conference=Association for Computing Machinery;,citation_series_title=KDD ’13;">
<meta name="citation_reference" content="citation_title=Data Stream Clustering: A Survey.;,citation_author=Jonathan A. Silva;,citation_author=Elaine R. Faria;,citation_author=Rodrigo C. Barros;,citation_author=Eduardo R. Hruschka;,citation_author=Andre Carvalho;,citation_author=Joao Gama;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=1;,citation_volume=46;,citation_journal_title=ACM Computer Surveys;">
<meta name="citation_reference" content="citation_title=ff: Memory-efficient Storage of Large Data on Disk and Fast Access Functions;,citation_author=Daniel Adler;,citation_author=Christian Gläser;,citation_author=Oleg Nenadic;,citation_author=Jens Oehlschlägel;,citation_author=Walter Zucchini;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=factas: Data Mining Methods for Data Streams;,citation_author=Romain Bar;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=streamR: Access to Twitter Streaming API via R;,citation_author=Pablo Barbera;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=DBI: R Database Interface;,citation_author=R Special Interest Group on Databases;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=Concept drift detection through resampling;,citation_author=Maayan Harel;,citation_author=Shie Mannor;,citation_author=Ran El-Yaniv;,citation_author=Koby Crammer;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_conference_title=International conference on machine learning;,citation_conference=PMLR;">
<meta name="citation_reference" content="citation_title=PCA feature extraction for change detection in multidimensional unlabeled data;,citation_author=Ludmila I Kuncheva;,citation_author=William J Faithfull;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=1;,citation_volume=25;,citation_journal_title=IEEE transactions on neural networks and learning systems;">
<meta name="citation_reference" content="citation_title=Mining of Massive Datasets;,citation_author=Jure Leskovec;,citation_author=Anand Rajaraman;,citation_author=Jeffery D. Ullman;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=RMOA: Connect R with MOA to perform streaming classifications;,citation_author=Jan Wijffels;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=A Survey on Concept Drift Adaptation;,citation_author=João Gama;,citation_author=Indrundefined Žliobaitundefined;,citation_author=Albert Bifet;,citation_author=Mykola Pechenizkiy;,citation_author=Abdelhamid Bouchachia;,citation_publication_date=2014-03;,citation_cover_date=2014-03;,citation_year=2014;,citation_issue=4;,citation_volume=46;,citation_journal_title=ACM Comput. Surv.;">
<meta name="citation_reference" content="citation_title=Graph Stream Algorithms: A Survey;,citation_author=Andrew McGregor;,citation_publication_date=2014-05;,citation_cover_date=2014-05;,citation_year=2014;,citation_issue=1;,citation_volume=43;,citation_journal_title=SIGMOD Rec.;">
<meta name="citation_reference" content="citation_title=RStorm: Developing and Testing Streaming Algorithms in R;,citation_author=Maurits Kaptein;,citation_publication_date=2014-06;,citation_cover_date=2014-06;,citation_year=2014;,citation_issue=1;,citation_volume=6;,citation_journal_title=The R Journal;">
<meta name="citation_reference" content="citation_title=SNAP Datasets: Stanford Large Network Dataset Collection;,citation_author=Jure Leskovec;,citation_author=Andrej Krevl;,citation_publication_date=2014-06;,citation_cover_date=2014-06;,citation_year=2014;,citation_publisher=http://snap.stanford.edu/data;">
<meta name="citation_reference" content="citation_title=Questioning the Lambda Architecture;,citation_author=Jay Kreps;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=Sketching as a Tool for Numerical Linear Algebra;,citation_author=David P. Woodruff;,citation_publication_date=2014-10;,citation_cover_date=2014-10;,citation_year=2014;,citation_issue=1–2;,citation_volume=10;,citation_journal_title=Found. Trends Theor. Comput. Sci.;">
<meta name="citation_reference" content="citation_title=Modeling concept drift: A probabilistic graphical model based approach;,citation_author=Hanen Borchani;,citation_author=Ana Maria Martinez;,citation_author=Andrés R. Masegosa;,citation_author=Helge Langseth;,citation_author=Thomas Dyhre Nielsen;,citation_author=Antonio Salmerón;,citation_author=Antonio Fernández;,citation_author=Anders Læsø Madsen;,citation_author=Ramón Sáez;,citation_editor=Elisa Fromont;,citation_editor=Tijl De Bie;,citation_editor=Matthijs Leeuwen;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=Advances in Intelligent Data Analysis XIV;,citation_conference=Springer;,citation_series_title=Lecture Notes in Computer Science;">
<meta name="citation_reference" content="citation_title=twitteR: R Based Twitter Client;,citation_author=Jeff Gentry;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=rEMM: Extensible Markov Model for Data Stream Clustering in R;,citation_author=Michael Hahsler;,citation_author=Margaret H. Dunham;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=streamMOA: Interface for MOA Stream Clustering Algorithms;,citation_author=Michael Hahsler;,citation_author=Matthew Bolanos;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=rstream: Streams of Random Numbers;,citation_author=Josef Leydold;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=Big Data: Principles and Best Practices of Scalable Realtime Data Systems;,citation_author=Nathan Marz;,citation_author=James Warren;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=A pca-based change detection framework for multidimensional data streams: Change detection in multidimensional data streams;,citation_author=Abdulhakim A Qahtan;,citation_author=Basma Alharbi;,citation_author=Suojin Wang;,citation_author=Xiangliang Zhang;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;">
<meta name="citation_reference" content="citation_title=Concept Drift Detection for Streaming Data;,citation_author=Heng Wang;,citation_author=Zubin Abraham;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=International Joint Conference on Neural Networks (IJCNN);">
<meta name="citation_reference" content="citation_title=koaning.io: Linear Models Solving Non-Linear Problems;,citation_author=Vincent Warmerdam;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=Experimental Algorithmics Applied to On-line Machine Learning;,citation_author=Thomas Bartz-Beielstein;,citation_editor=Gregor Papa;,citation_editor=Marjan Mernik;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_conference_title=Bioinspired Optimization Methods and their Applications;">
<meta name="citation_reference" content="citation_title=quantmod: Quantitative Financial Modelling Framework;,citation_author=Jeffrey A. Ryan;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;">
<meta name="citation_reference" content="citation_title=A grid density based framework for classifying streaming data in the presence of concept drift;,citation_author=Tegjyot Singh Sethi;,citation_author=Mehmed Kantardzic;,citation_author=Hanquing Hu;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_issue=1;,citation_volume=46;,citation_journal_title=Journal of Intelligent Information Systems;">
<meta name="citation_reference" content="citation_title=rJava: Low-level R to Java interface;,citation_author=Simon Urbanek;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;">
<meta name="citation_reference" content="citation_title=SparkR: Scaling R Programs with Spark;,citation_author=Shivaram Venkataraman;,citation_author=Zongheng Yang;,citation_author=Davies Liu;,citation_author=Eric Liang;,citation_author=Hossein Falaki;,citation_author=Xiangrui Meng;,citation_author=Reynold Xin;,citation_author=Ali Ghodsi;,citation_author=Michael Franklin;,citation_author=Ion Stoica;,citation_author=Matei Zaharia;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_conference_title=Proceedings of the 2016 International Conference on Management of Data;,citation_conference=Association for Computing Machinery;,citation_series_title=SIGMOD ’16;">
<meta name="citation_reference" content="citation_title=koaning.io: Bayesian/Streaming Algorithms;,citation_author=Vincent Warmerdam;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;">
<meta name="citation_reference" content="citation_title=Outlier Analysis;,citation_author=Charu C Aggarwal;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;">
<meta name="citation_reference" content="citation_title=Video Popularity Prediction in Data Streams Based on Context-Independent Features;,citation_author=Vitor Silva;,citation_author=Ana Trindade Winck;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_conference_title=Proceedings of the Symposium on Applied Computing;,citation_conference=Association for Computing Machinery;,citation_series_title=SAC ’17;">
<meta name="citation_reference" content="citation_title=Einsatz von Machine-Learning-Verfahren in amtlichen Unternehmensstatistiken;,citation_author=Florian Dumpert;,citation_author=Martin Beck;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=2;,citation_volume=11;,citation_journal_title=AStA Wirtschafts- und Sozialstatistisches Archiv;">
<meta name="citation_reference" content="citation_title=Introduction to stream: An Extensible Framework for Data Stream Clustering Research with R;,citation_author=Michael Hahsler;,citation_author=Matthew Bolaños;,citation_author=John Forrest;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=14;,citation_volume=76;,citation_journal_title=Journal of Statistical Software;">
<meta name="citation_reference" content="citation_title=stream: Infrastructure for Data Stream Mining;,citation_author=Michael Hahsler;,citation_author=Matthew Bolaños;,citation_author=John Forrest;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;">
<meta name="citation_reference" content="citation_title=Design and Analysis of Experiments;,citation_author=D C Montgomery;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;">
<meta name="citation_reference" content="citation_title=Time Series Forecasting in the Presence of Concept Drift: A PSO-based Approach;,citation_author=Gustavo H. F. M. Oliveira;,citation_author=Rodolfo C. Cavalcante;,citation_author=George G. Cabral;,citation_author=Leandro L. Minku;,citation_author=Adriano L. I. Oliveira;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_conference_title=2017 IEEE 29th International Conference on Tools with Artificial Intelligence (ICTAI);">
<meta name="citation_reference" content="citation_title=United Nations Global Pulse. Harnessing big data for development and humanitarian action.;,citation_author=United Nations;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;">
<meta name="citation_reference" content="citation_title=koaning.io: Passive Agressive Algorithms;,citation_author=Vincent Warmerdam;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;">
<meta name="citation_reference" content="citation_title=On the Reliable Detection of Concept Drift from Streaming Unlabeled Data;,citation_author=Tegjyot Singh Sethi;,citation_author=Mehmed Kantardzic;,citation_publication_date=2017-03;,citation_cover_date=2017-03;,citation_year=2017;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Proof of Concept Machine Learning - Abschlussbericht;,citation_author=Martin Beck;,citation_author=Florian Dumpert;,citation_author=Jörg Feuerhake;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_technical_report_institution=Statistisches Bundesamt (Destatis);">
<meta name="citation_reference" content="citation_title=Machine Learning for Data Streams with Practical Examples in MOA;,citation_author=Albert Bifet;,citation_author=Ricard Gavalda;,citation_author=Geoff Holmes;,citation_author=Bernhard Pfahringer;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;">
<meta name="citation_reference" content="citation_title=Lifelong Machine Learning;,citation_author=Zhiyuan Chen;,citation_author=Bing Liu;,citation_author=Ronald Brachman;,citation_author=Peter Stone;,citation_author=Francesca Rossi;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;">
<meta name="citation_reference" content="citation_title=Incremental on-line learning: A review and comparison of state of the art algorithms;,citation_author=Viktor Losing;,citation_author=Barbara Hammer;,citation_author=Heiko Wersing;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_volume=275;,citation_journal_title=Neurocomputing;">
<meta name="citation_reference" content="citation_title=Extremely Fast Decision Tree;,citation_author=Chaitanya Manapragada;,citation_author=Geoffrey I. Webb;,citation_author=Mahsa Salehi;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_conference_title=Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;,citation_conference=Association for Computing Machinery;,citation_series_title=KDD ’18;">
<meta name="citation_reference" content="citation_title=An evaluation of data stream clustering algorithms;,citation_author=Stratos Mansalis;,citation_author=Eirini Ntoutsi;,citation_author=Nikos Pelekis;,citation_author=Yannis Theodoridis;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=4;,citation_volume=11;,citation_journal_title=Statistical Analysis and Data Mining: The ASA Data Science Journal;">
<meta name="citation_reference" content="citation_title=koaning.io: How to win with simple, even linear, models;,citation_author=Vincent Warmerdam;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;">
<meta name="citation_reference" content="citation_title=Anomaly Detection in Manufacturing Systems Using Structured Neural Networks;,citation_author=J. Liu;,citation_author=J. Guo;,citation_author=P. V. Orlik;,citation_author=M. Shibata;,citation_author=D. Nakahara;,citation_author=S. Mii;,citation_author=M. Takac;,citation_publication_date=2018-07;,citation_cover_date=2018-07;,citation_year=2018;,citation_technical_report_institution=MITSUBISHI ELECTRIC RESEARCH LABORATORIES;">
<meta name="citation_reference" content="citation_title=Industrial Internet of Things Based Ransomware Detection Using Stacked Variational Neural Network;,citation_author=Muna Al-Hawawreh;,citation_author=Elena Sitnikova;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_conference_title=Proceedings of the 3rd International Conference on Big Data and Internet of Things;,citation_conference=Association for Computing Machinery;,citation_series_title=BDIOT 2019;">
<meta name="citation_reference" content="citation_title=Evaluation of Cognitive Architectures for Cyber-Physical Production Systems;,citation_author=Andreas Bunte;,citation_author=Andreas Fischbach;,citation_author=Jan Strohschein;,citation_author=Thomas Bartz-Beielstein;,citation_author=Heide Faeskorn-Woyke;,citation_author=Oliver Niggemann;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_conference_title=24th IEEE International Conference on Emerging Technologies and Factory Automation, ETFA 2019, Zaragoza, Spain, September 10-13, 2019;">
<meta name="citation_reference" content="citation_title=Nowcasting: Ein Echtzeit-Indikator für die Konjunkturanalyse;,citation_author=Charlotte Senftleben;,citation_author=Till Strohsal;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;">
<meta name="citation_reference" content="citation_title=koaning.io: The Future of Data Science is Past;,citation_author=Vincent Warmerdam;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;">
<meta name="citation_reference" content="citation_title=Forecasting inflation with online prices;,citation_author=Diego Aparicio;,citation_author=Manuel I. Bertolotto;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_issue=2;,citation_volume=36;,citation_journal_title=International Journal of Forecasting;">
<meta name="citation_reference" content="citation_title=CAAI—a cognitive architecture to introduce artificial intelligence in cyber-physical production systems;,citation_author=Andreas Fischbach;,citation_author=Jan Strohschein;,citation_author=Andreas Bunte;,citation_author=Jörg Stork;,citation_author=Heide Faeskorn-Woyke;,citation_author=Natalia Moriz;,citation_author=Thomas Bartz-Beielstein;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_issue=1;,citation_volume=111;,citation_journal_title=The International Journal of Advanced Manufacturing Technology;">
<meta name="citation_reference" content="citation_title=Delayed labelling evaluation for data streams;,citation_author=Maciej Grzenda;,citation_author=Heitor Murilo Gomes;,citation_author=Albert Bifet;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_issue=5;,citation_volume=34;,citation_journal_title=Data Mining and Knowledge Discovery;">
<meta name="citation_reference" content="citation_title=Stream Data Mining: Algorithms and Their Probabilistic Properties;,citation_editor=Leszek Rutkowski;,citation_editor=Maciej Jaworski;,citation_editor=Piotr Duda;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_series_title=Studies in Big Data;">
<meta name="citation_reference" content="citation_title=Loghub: A Large Collection of System Log Datasets towards Automated Log Analytics;,citation_author=Shilin He;,citation_author=Jieming Zhu;,citation_author=Pinjia He;,citation_author=Michael R. Lyu;,citation_publication_date=2020-08;,citation_cover_date=2020-08;,citation_year=2020;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Nowcasting German GDP: Foreign factors, financial markets, and model averaging;,citation_author=Paolo Andreini;,citation_author=Thomas Hasenzagl;,citation_author=Lucrezia Reichlin;,citation_author=Charlotte Senftleben-König;,citation_author=Till Strohsal;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_journal_title=International Journal of Forecasting;">
<meta name="citation_reference" content="citation_title=Modelling the COVID-19 Virus Evolution With Incremental Machine Learning;,citation_author=Andrés L. Suárez-Cetrulo;,citation_author=Ankit Kumar;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;">
<meta name="citation_reference" content="citation_title=Machine Learning for Time-Series with Python: Forecast, predict, and detect;,citation_author=Den Auffarth;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;">
<meta name="citation_reference" content="citation_title=Machine Learning in der amtlichen Statistik - Ergebnisse und Bewertung eines internationalen Projekts;,citation_author=Florian Dumpert;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_technical_report_institution=Statistisches Bundesamt (Destatis);,citation_technical_report_number=4;">
<meta name="citation_reference" content="citation_title=Recurring concept memory management in data streams: exploiting data stream concept evolution to improve performance and transparency;,citation_author=Ben Halstead;,citation_author=Yun Sing Koh;,citation_author=Patricia Riddle;,citation_author=Russel Pears;,citation_author=Mykola Pechenizkiy;,citation_author=Albert Bifet;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_issue=3;,citation_volume=35;,citation_journal_title=Data Mining and Knowledge Discovery;">
<meta name="citation_reference" content="citation_title=Soziale Marktwirtschaft in der digitalen Zukunft: Foresight-Bericht Strategischer Vorausschauprozess des BMWi;,citation_author=Dirk Holtmannspötter;,citation_author=Ulrich Heimeshoff;,citation_author=Justus Haucap;,citation_author=Ina Loebert;,citation_author=Christoph Busch;,citation_author=Andreas Hoffknecht;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_technical_report_institution=VDI Technologiezentrum GmbH im Auftrag des Bundesministerium für Wirtschaft und Energie;">
<meta name="citation_reference" content="citation_title=River: machine learning for streaming data in Python;,citation_author=Jacob Montiel;,citation_author=Max Halford;,citation_author=Saulo Martiello Mastelini;,citation_author=Geoffrey Bolmier;,citation_author=Raphael Sourty;,citation_author=Robin Vaysse;,citation_author=Adil Zouitine;,citation_author=Heitor Murilo Gomes;,citation_author=Jesse Read;,citation_author=Talel Abdessalem;,citation_author=others;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;">
<meta name="citation_reference" content="citation_title=Practical Machine Learning for Streaming Data with Python;,citation_author=Sayan Putatunda;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;">
<meta name="citation_reference" content="citation_title=Infrerring Concept Drift Without Labeled Data;,citation_author=Andrew Reed;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_technical_report_institution=Cloudera Fast Forward Labs;,citation_technical_report_number=FF21;">
<meta name="citation_reference" content="citation_title=Cognitive capabilities for the CAAI in cyber-physical production systems;,citation_author=Jan Strohschein;,citation_author=Andreas Fischbach;,citation_author=Andreas Bunte;,citation_author=Heide Faeskorn-Woyke;,citation_author=Natalia Moriz;,citation_author=Thomas Bartz-Beielstein;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_journal_title=The International Journal of Advanced Manufacturing Technology;">
<meta name="citation_reference" content="citation_title=FARF: A Fair and Adaptive Random Forests Classifier;,citation_author=Wenbin Zhang;,citation_author=Albert Bifet;,citation_author=Xiangliang Zhang;,citation_author=Jeremy C. Weiss;,citation_author=Wolfgang Nejdl;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_conference_title=Advances in Knowledge Discovery and Data Mining: 25th Pacific-Asia Conference, PAKDD 2021, Virtual Event, May 11–14, 2021, Proceedings, Part II;,citation_conference=Springer-Verlag;">
<meta name="citation_reference" content="citation_title=Modelling the COVID-19 virus evolution with Incremental Machine Learning;,citation_author=Andrés L. Suárez-Cetrulo;,citation_author=Ankit Kumar;,citation_author=Luis Miralles-Pechuán;,citation_publication_date=2021-04;,citation_cover_date=2021-04;,citation_year=2021;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Online Learning and Active Learning: A Comparative Study of Passive-Aggressive Algorithm With Support Vector Machine (SVM);,citation_author=K. I Ezukwoke;,citation_author=S. J Zareian;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_issue=3;,citation_volume=21;,citation_journal_title=Journal of Higher Education Theory and Practice;">
<meta name="citation_reference" content="citation_title=Digitale Ordnungspolitik – Wirtschaftspolitik daten- und evidenzbasiert weiterentwickeln;,citation_author=Philipp Steinberg;,citation_author=Nils Börnsen;,citation_author=Dirk Neumann;,citation_publication_date=2021-09;,citation_cover_date=2021-09;,citation_year=2021;,citation_publisher=Wirtschaftsdienst;">
<meta name="citation_reference" content="citation_title=Incremental Unsupervised Domain-Adversarial Training of Neural Networks;,citation_author=Antonio-Javier Gallego;,citation_author=Jorge Calvo-Zaragoza;,citation_author=Robert B. Fisher;,citation_publication_date=2021-11;,citation_cover_date=2021-11;,citation_year=2021;,citation_issue=11;,citation_volume=32;,citation_journal_title=IEEE Transactions on Neural Networks and Learning Systems;">
<meta name="citation_reference" content="citation_title=Incremental learning for property price estimation using location-based services and open data;,citation_author=Francisco Alvarez;,citation_author=Edgar Roman-Rangel;,citation_author=Luis V. Montiel;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_volume=107;,citation_journal_title=Engineering Applications of Artificial Intelligence;">
<meta name="citation_reference" content="citation_title=Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide;,citation_editor=Eva Bartz;,citation_editor=Thomas Bartz-Beielstein;,citation_editor=Martin Zaefferer;,citation_editor=Olaf Mersmann;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=Interpretable Machine Learning: Moving from Mythos to Diagnostics;,citation_author=Valerie Chen;,citation_author=Jeffrey Li;,citation_author=Joon Sik Kim;,citation_author=Gregory Plumb;,citation_author=Ameet Talwalkar;,citation_publication_date=2022-01;,citation_cover_date=2022-01;,citation_year=2022;,citation_issue=6;,citation_volume=19;,citation_journal_title=Queue;">
<meta name="citation_reference" content="citation_title=Online Time-series Anomaly Detection: A Survey of Modern Model-based Approaches;,citation_author=Lucas Correia;,citation_author=Jan-Christoph Goos;,citation_author=Anna V. Kononova;,citation_author=Thomas Bäck;,citation_author=Philipp Klein;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_technical_report_institution=Mercedes-Benz, Germany;">
<meta name="citation_reference" content="citation_title=Green Accelerated Hoeffding Tree;,citation_author=Eva Garcia-Martin;,citation_author=Albert Bifet;,citation_author=Niklas Lavesson;,citation_author=Rikard König;,citation_author=Henrik Linusson;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=Monitoring the Economy in Real Time: Trends and Gaps in Real Activity and Prices;,citation_author=Thomas Hasenzagl;,citation_author=Filippo Pellegrino;,citation_author=Lucrezia Reichlin;,citation_author=Giovanni Ricco;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=Efficiently Correcting Machine Learning: Considering the Role of Example Ordering in Human-in-the-Loop Training of Image Classification Models;,citation_author=Geoff Holmes;,citation_author=Eibe Frank;,citation_author=Dale Fletcher;,citation_author=Corey Sterling;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_conference_title=27th International Conference on Intelligent User Interfaces;,citation_conference=Association for Computing Machinery;,citation_series_title=IUI ’22;">
<meta name="citation_reference" content="citation_title=TemporalWiki: A Lifelong Benchmark for Training and Evaluating Ever-Evolving Language Models;,citation_author=Joel Jang;,citation_author=Seonghyeon Ye;,citation_author=Changho Lee;,citation_author=Sohee Yang;,citation_author=Joongbo Shin;,citation_author=Janghoon Han;,citation_author=Gyeonghun Kim;,citation_author=Minjoon Seo;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=Fast Mining and Forecasting of Co-Evolving Epidemiological Data Streams;,citation_author=Tasuku Kimura;,citation_author=Yasuko Matsubara;,citation_author=Koki Kawabata;,citation_author=Yasushi Sakurai;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_conference_title=Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining;,citation_conference=Association for Computing Machinery;,citation_series_title=KDD ’22;">
<meta name="citation_reference" content="citation_title=Maschine Learning for Streaming Data with Python;,citation_author=Jan Korstanje;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=The Disagreement Problem in Explainable Machine Learning: A Practitioner’s Perspective;,citation_author=Satyapriya Krishna;,citation_author=Tessa Han;,citation_author=Alex Gu;,citation_author=Javin Pombra;,citation_author=Shahin Jabbari;,citation_author=Steven Wu;,citation_author=Himabindu Lakkaraju;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=SparkR: R Front End for ’Apache Spark’;,citation_author=The Apache Software Foundation;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=Short-term local predictions of COVID-19 in the United Kingdom using dynamic supervised machine learning algorithms;,citation_author=Xin Wang;,citation_author=Yijia Dong;,citation_author=William David Thompson;,citation_author=Harish Nair;,citation_author=You Li;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_issue=1;,citation_volume=2;,citation_journal_title=Communications Medicine;">
<meta name="citation_reference" content="citation_title=Log-based Anomaly Detection with Deep Learning: How Far Are We?;,citation_author=Van-Hoang Le;,citation_author=Hongyu Zhang;,citation_publication_date=2022-02;,citation_cover_date=2022-02;,citation_year=2022;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Reliance on metrics is a fundamental challenge for AI.;,citation_author=Rachel L Thomas;,citation_author=David Uminsky;,citation_publication_date=2022-05;,citation_cover_date=2022-05;,citation_year=2022;,citation_issue=5;,citation_volume=3;,citation_journal_title=Patterns (N Y);">
<meta name="citation_reference" content="citation_title=SMRD.de Benutzerhandbuch;,citation_author=Niyaz Valitov;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_technical_report_institution=Bundesnetzagentur für Elektrizität, Gas, Telekommunikation, Post und Eisenbahnen;">
<meta name="citation_reference" content="citation_title=Use of web scraping and text mining techniques in the Istat survey on “Information and Communication Technology in enterprises”;,citation_author=G. Barcaroli;,citation_author=A. Nurra;,citation_author=M. Scarnò;,citation_author=D. Summa;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=Who Makes Mistakes? Using Data Mining Techniques to Analyze Reporting Errors in Total Acres Operated;,citation_author=Jaki S. McCarthy;,citation_author=Morgan S. Earp;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_fulltext_html_url=https://ideas.repec.org/p/ags/unasrr/234367.html;,citation_doi=10.22004/AG.ECON.234367;,citation_journal_title=NASS Research Reports;,citation_publisher=United States Department of Agriculture, National Agricultural Statistics Service;">
<meta name="citation_reference" content="citation_title=Modeling Non-response in National Agricultural Statistics Service (NASS) Surveys Using Classification Trees;,citation_author=Jaki S Mccarthy;,citation_author=Thomas Jacob;,citation_author=Amanda Mccracken;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;">
<meta name="citation_reference" content="citation_title=2007 Census of Agriculture Non-Response Methodology;,citation_author=Will Cecere;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;">
<meta name="citation_reference" content="citation_title=Exploring Quarterly Agricultural Survey Questionnaire Version Reduction Scenarios;,citation_author=Morgan Earp;,citation_author=Scott Cox;,citation_author=Jody Mcdaniel;,citation_author=Chadd Crouse;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;">
<meta name="citation_reference" content="citation_title=USE OF MACHINE LEARNING METHODS TO IMPUTE CATEGORICAL DATA;,citation_author=P. Rey;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;">
<meta name="citation_reference" content="citation_title=Innovative Uses of Data Mining Techniques in the Production of Official Statistics;,citation_author=Jaki Mccarthy;,citation_author=Thomas Jacob;,citation_author=Dale Atkinson;">
<meta name="citation_reference" content="citation_title=Automatic Coding of Occupations. Using Machine Learning Algorithms for Occupation Coding in Several German Panel Surveys;,citation_fulltext_html_url=https://www.researchgate.net/publication/266259591_Automatic_Coding_of_Occupations_Using_Machine_Learning_Algorithms_for_Occupation_Coding_in_Several_German_Panel_Surveys;">
<meta name="citation_reference" content="citation_title=Evaluating hourly air quality forecasting in Canada with nonlinear updatable machine learning methods;,citation_author=Huiping Peng;,citation_author=Aranildo R. Lima;,citation_author=Andrew Teakles;,citation_author=Jian Jin;,citation_author=Alex J. Cannon;,citation_author=William W. Hsieh;,citation_publication_date=2017-03-01;,citation_cover_date=2017-03-01;,citation_year=2017;,citation_fulltext_html_url=https://doi.org/10.1007/s11869-016-0414-3;,citation_issue=2;,citation_doi=10.1007/s11869-016-0414-3;,citation_issn=1873-9326;,citation_volume=10;,citation_journal_title=Air Quality, Atmosphere &amp;amp;amp; Health;">
<meta name="citation_reference" content="citation_title=Online Machine Learning in Big Data Streams;,citation_author=András A. Benczúr;,citation_author=Levente Kocsis;,citation_author=Róbert Pálovics;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_fulltext_html_url=http://arxiv.org/abs/1802.05872;,citation_volume=abs/1802.05872;,citation_journal_title=CoRR;">
<meta name="citation_reference" content="citation_title=Learn: A Novel incremental learning method for text classification;,citation_author=Guangxu Shan;,citation_author=Shiyao Xu;,citation_author=Li Yang;,citation_author=Shengbin Jia;,citation_author=Yang Xiang;,citation_publication_date=2020-06;,citation_cover_date=2020-06;,citation_year=2020;,citation_doi=10.1016/J.ESWA.2020.113198;,citation_issn=0957-4174;,citation_volume=147;,citation_journal_title=Expert Systems with Applications;,citation_publisher=Pergamon;">
<meta name="citation_reference" content="citation_title=Incremental Real-Time Learning Framework for Sentiment Classification: Indian General Election 2019, A Case Study;,citation_author=Sharmistha Chatterjee;,citation_author=Sushmita Gupta;,citation_publication_date=2021-03;,citation_cover_date=2021-03;,citation_year=2021;,citation_doi=10.1109/ICBDA51983.2021.9402992;,citation_isbn=9780738131672;,citation_journal_title=2021 IEEE 6th International Conference on Big Data Analytics, ICBDA 2021;,citation_publisher=Institute of Electrical; Electronics Engineers Inc.;">
<meta name="citation_reference" content="citation_title=MOA: Massive Online Analysis;,citation_abstract=Massive Online Analysis (MOA) is a software environment for implementing algorithms and running experiments for online learning from evolving data streams. MOA includes a collection of offline and online methods as well as tools for evaluation. In particular, it implements boosting, bagging, and Hoeffding Trees, all with and without Na¨ıveNa¨ıve Bayes classifiers at the leaves. MOA supports bi-directional interaction with WEKA, the Waikato Environment for Knowledge Analysis , and is released under the GNU GPL license.;,citation_author=Albert Bifet;,citation_author=Geoff Holmes;,citation_author=Richard Kirkby;,citation_author=Bernhard Pfahringer;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_volume=11;,citation_journal_title=Journal of Machine Learning Research;">
<meta name="citation_reference" content="citation_title=Evaluation and Performance Measurement;,citation_author=Thomas Bartz-Beielstein;,citation_editor=Eva Bartz;,citation_editor=Thomas Bartz-Beielstein;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_inbook_title=undefined;">
<meta name="citation_reference" content="citation_title=Hyperparameter Tuning;,citation_author=Thomas Bartz-Beielstein;,citation_editor=Eva Bartz;,citation_editor=Thomas Bartz-Beielstein;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_inbook_title=undefined;">
<meta name="citation_reference" content="citation_title=Hyperparameter Tuning Approaches;,citation_author=Thomas Bartz-Beielstein;,citation_author=Martin Zaefferer;,citation_editor=Eva Bartz;,citation_editor=Thomas Bartz-Beielstein;,citation_editor=Martin Zaefferer;,citation_editor=Olaf Mersmann;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_inbook_title=Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide;">
<meta name="citation_reference" content="citation_title=Drift Detection and&nbsp;Handling;,citation_abstract=Structural changes (“drift”) in the data cause problems for many algorithms. Based on the drift definitions given in Chap. 1, methods for drift detection and handling are discussed. For the algorithms presented in Chap. 2, it is clarified to what extent concept drift is reacted to. In turn, the extent to which catastrophic forgetting is an issue is described in Sect. 4.3. Section&nbsp;3.1 describes three architectures for implementing drift detection algorithms. Basic properties of window-based approaches are presented in Sect.&nbsp;3.2. Section&nbsp;3.4 presents commonly used drift detection techniques. Section&nbsp;3.4 describes how the drift detection techniques introduced in Sect.&nbsp;3.3 are used in Online Machine Learning (OML) algorithms and summarizes the tree-based OML techniques implemented in the River package. Section&nbsp;3.5 introduces scaling methods for handling drift.;,citation_author=Thomas Bartz-Beielstein;,citation_author=Lukas Hans;,citation_editor=Eva Bartz;,citation_editor=Thomas Bartz-Beielstein;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://doi.org/10.1007/978-981-99-7007-0_3;,citation_doi=10.1007/978-981-99-7007-0_3;,citation_isbn=978-981-99-7007-0;,citation_inbook_title=Online Machine Learning: A Practical Guide with Examples in Python;">
<meta name="citation_reference" content="citation_title=Introduction: From Batch to&nbsp;Online Machine Learning;,citation_abstract=Batch Machine Learning (BML), which is also referred to as “offline machine learning”, reaches its limits when dealing with very large amounts of data. This is especially true for available memory, handling drift in data streams, and processing new, unknown data. Online Machine Learning (OML) is an alternative to BML that overcomes the limitations of BML. In this chapter, the basic terms and concepts of OML are introduced and the differences to BML are shown.;,citation_author=Thomas Bartz-Beielstein;,citation_editor=Eva Bartz;,citation_editor=Thomas Bartz-Beielstein;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://doi.org/10.1007/978-981-99-7007-0_1;,citation_doi=10.1007/978-981-99-7007-0_1;,citation_isbn=978-981-99-7007-0;,citation_inbook_title=Online Machine Learning: A Practical Guide with Examples in Python;">
<meta name="citation_reference" content="citation_title=AMF: Aggregated Mondrian Forests for Online Learning;,citation_author=Jaouad Mourtada;,citation_author=Stephane Gaiffas;,citation_author=Erwan Scornet;,citation_publication_date=2019-06;,citation_cover_date=2019-06;,citation_year=2019;,citation_fulltext_html_url=https://arxiv.org/abs/1906.10529;,citation_doi=10.48550/arXiv.1906.10529;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Extremely fast decision tree;,citation_abstract=We introduce a novel incremental decision tree learning algorithm, Hoeffding Anytime Tree, that is statistically more efficient than the current state-of-the-art, Hoeffding Tree. We demonstrate that an implementation of Hoeffding Anytime Tree’“Extremely Fast Decision Tree”, a minor modification to the MOA implementation of Hoeffding Tree’obtains significantly superior prequential accuracy on most of the largest classification datasets from the UCI repository. Hoeffding Anytime Tree produces the asymptotic batch tree in the limit, is naturally resilient to concept drift, and can be used as a higher accuracy replacement for Hoeffding Tree in most scenarios, at a small additional computational cost.;,citation_author=Chaitanya Manapragada;,citation_author=Geoffrey I. Webb;,citation_author=Mahsa Salehi;,citation_editor=Chih-Jen  Lin;,citation_editor=Hui  Xiong;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_fulltext_html_url=http://www.kdd.org/kdd2018/, https://dl.acm.org/doi/proceedings/10.1145/3219819;,citation_doi=10.1145/3219819.3220005;,citation_conference_title=KDD’ 2018 - Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;,citation_conference=Association for Computing Machinery (ACM);">
<meta name="citation_reference" content="citation_title=Surrogates;,citation_author=Robert B Gramacy;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;">
<meta name="citation_reference" content="citation_title=UvA Deep Learning Tutorials;,citation_author=Phillip Lippe;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://github.com/phlippe/uvadlc_notebooks/tree/master;">
<meta name="citation_reference" content="citation_title=Attention Is All You Need;,citation_author=Ashish Vaswani;,citation_author=Noam Shazeer;,citation_author=Niki Parmar;,citation_author=Jakob Uszkoreit;,citation_author=Llion Jones;,citation_author=Aidan N. Gomez;,citation_author=Lukasz Kaiser;,citation_author=Illia Polosukhin;,citation_publication_date=2017-06;,citation_cover_date=2017-06;,citation_year=2017;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=On the Variance of the Adaptive Learning Rate and Beyond;,citation_author=Liyuan Liu;,citation_author=Haoming Jiang;,citation_author=Pengcheng He;,citation_author=Weizhu Chen;,citation_author=Xiaodong Liu;,citation_author=Jianfeng Gao;,citation_author=Jiawei Han;,citation_publication_date=2019-08;,citation_cover_date=2019-08;,citation_year=2019;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Efficient Transformers: A Survey;,citation_author=Yi Tay;,citation_author=Mostafa Dehghani;,citation_author=Dara Bahri;,citation_author=Donald Metzler;,citation_publication_date=2020-09;,citation_cover_date=2020-09;,citation_year=2020;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding;,citation_author=Jacob Devlin;,citation_author=Ming-Wei Chang;,citation_author=Kenton Lee;,citation_author=Kristina Toutanova;,citation_publication_date=2018-10;,citation_cover_date=2018-10;,citation_year=2018;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale;,citation_author=Alexey Dosovitskiy;,citation_author=Lucas Beyer;,citation_author=Alexander Kolesnikov;,citation_author=Dirk Weissenborn;,citation_author=Xiaohua Zhai;,citation_author=Thomas Unterthiner;,citation_author=Mostafa Dehghani;,citation_author=Matthias Minderer;,citation_author=Georg Heigold;,citation_author=Sylvain Gelly;,citation_author=Jakob Uszkoreit;,citation_author=Neil Houlsby;,citation_publication_date=2020-10;,citation_cover_date=2020-10;,citation_year=2020;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Attention is not Explanation;,citation_author=Sarthak Jain;,citation_author=Byron C. Wallace;,citation_publication_date=2019-02;,citation_cover_date=2019-02;,citation_year=2019;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Attention is not not Explanation;,citation_author=Sarah Wiegreffe;,citation_author=Yuval Pinter;,citation_publication_date=2019-08;,citation_cover_date=2019-08;,citation_year=2019;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Multivariate adaptive regression splines;,citation_author=Jerome H. Friedman;,citation_publication_date=1991;,citation_cover_date=1991;,citation_year=1991;,citation_issue=1;,citation_volume=19;,citation_journal_title=The annals of statistics;">
<meta name="citation_reference" content="citation_title=Learning model trees from evolving data streams;,citation_author=Elena Ikonomovska;,citation_author=João Gama;,citation_author=Sašo Džeroski;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=1;,citation_volume=23;,citation_journal_title=Data Mining and Knowledge Discovery;">
<meta name="citation_reference" content="citation_title=An Introduction to Statistical Learning with Applications in R;,citation_author=Gareth James;,citation_author=Daniela Witten;,citation_author=Trevor Hastie;,citation_author=Robert Tibshirani;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=Deep Learning with Python;,citation_author=Francoise Chollet;,citation_author=J. J. Allaire;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;">
<meta name="citation_reference" content="citation_title=A survey of cross-validation procedures for model selection;,citation_author=Sylvain Arlot;,citation_author=Alain Celisse;,citation_author=others;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_volume=4;,citation_journal_title=Statistics surveys;">
<meta name="citation_reference" content="citation_title=A cross-validatory method for dependent data;,citation_author=PRABIR BURMAN;,citation_author=EDMOND CHOW;,citation_author=DEBORAH NOLAN;,citation_publication_date=1994;,citation_cover_date=1994;,citation_year=1994;,citation_issue=2;,citation_volume=81;,citation_journal_title=Biometrika;">
<meta name="citation_reference" content="citation_title=A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection;,citation_author=Ron Kohavi;,citation_publication_date=1995;,citation_cover_date=1995;,citation_year=1995;,citation_conference_title=Proceedings of the 14th International Joint Conference on Artificial Intelligence - Volume 2;,citation_conference=Morgan Kaufmann Publishers Inc.;,citation_series_title=IJCAI’95;">
<meta name="citation_reference" content="citation_title=Kriging-based sequential design strategies using fast cross-validation techniques with extensions to multi-fidelity computer codes ;,citation_author=Loic Le Gratiet;,citation_author=Claire Cannamela;,citation_publication_date=2012-10;,citation_cover_date=2012-10;,citation_year=2012;">
<meta name="citation_reference" content="citation_title=Cross-Validation of Regression Models;,citation_author=Richard R. Picard;,citation_author=R. Dennis Cook;,citation_publication_date=1984;,citation_cover_date=1984;,citation_year=1984;,citation_issue=387;,citation_volume=79;,citation_journal_title=Journal of the American Statistical Association;">
<meta name="citation_reference" content="citation_title=The Elements of Statistical Learning;,citation_author=Trevor Hastie;,citation_author=Robert Tibshirani;,citation_author=Jerome Friedman;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;">
<meta name="citation_reference" content="citation_title=Deep Residual Learning for Image Recognition;,citation_author=Kaiming He;,citation_author=Xiangyu Zhang;,citation_author=Shaoqing Ren;,citation_author=Jian Sun;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=Identity Mappings in Deep Residual Networks;,citation_author=Kaiming He;,citation_author=Xiangyu Zhang;,citation_author=Shaoqing Ren;,citation_author=Jian Sun;,citation_publication_date=2016-03;,citation_cover_date=2016-03;,citation_year=2016;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Neural Ordinary Differential Equations;,citation_author=Ricky T. Q. Chen;,citation_author=Yulia Rubanova;,citation_author=Jesse Bettencourt;,citation_author=David Duvenaud;,citation_publication_date=2018-06;,citation_cover_date=2018-06;,citation_year=2018;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Mathematical Theory of Optimal Processes;,citation_author=undefined Pontryagin;,citation_publication_date=1987;,citation_cover_date=1987;,citation_year=1987;">
<meta name="citation_reference" content="citation_title=On Neural Differential Equations;,citation_author=Patrick Kidger;,citation_publication_date=2022-02;,citation_cover_date=2022-02;,citation_year=2022;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Stochastic simulation optimization: an optimal computing budget allocation;,citation_author=Chun Hung Chen;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;">
<meta name="citation_reference" content="citation_title=Sequential Parameter Optimization and Optimal Computational Budget Allocation for Noisy Optimization Problems;,citation_author=Thomas Bartz-Beielstein;,citation_author=Martina Friese;,citation_publication_date=2011-01;,citation_cover_date=2011-01;,citation_year=2011;">
<meta name="citation_reference" content="citation_title=Statistik;,citation_author=Joachim Hartung;,citation_author=Bärbel Elpert;,citation_author=Karl-Heinz Klösener;,citation_publication_date=1995;,citation_cover_date=1995;,citation_year=1995;">
<meta name="citation_reference" content="citation_title=Partial correlation — Wikipedia, The Free Encyclopedia;,citation_author=Wikipedia contributors;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://en.wikipedia.org/w/index.php?title=Partial_correlation&amp;amp;amp;oldid=1253637419;">
<meta name="citation_reference" content="citation_title=Understanding Correlation;,citation_author=R. J. Rummel;,citation_publication_date=1976;,citation_cover_date=1976;,citation_year=1976;,citation_fulltext_html_url=https://www.hawaii.edu/powerkills/UC.HTM;">
<meta name="citation_reference" content="citation_title=Two Postestimation Commands for Assessing Confounding Effects in Epidemiological Studies;,citation_author=Zhiqiang Wang;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=2;,citation_volume=7;,citation_journal_title=The Stata Journal;">
<meta name="citation_reference" content="citation_title=Response surface methodology: process and product optimization using designed experiments;,citation_author=Raymond H Myers;,citation_author=Douglas C Montgomery;,citation_author=Christine M Anderson-Cook;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;">
<meta name="citation_reference" content="citation_title=desirability: Function Optimization and Ranking via Desirability Functions;,citation_author=Max Kuhn;,citation_publication_date=2016-09;,citation_cover_date=2016-09;,citation_year=2016;">
<meta name="citation_reference" content="citation_title=Noisy optimization with sequential parameter optimization and optimal computational budget allocation;,citation_author=Thomas Bartz-Beielstein;,citation_author=Martina Friese;,citation_author=Martin Zaefferer;,citation_author=Boris Naujoks;,citation_author=Oliver Flasch;,citation_author=Wolfgang Konen;,citation_author=Patrick Koch;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_conference_title=Proceedings of the 13th annual conference companion on Genetic and evolutionary computation;,citation_conference=ACM;">
<meta name="citation_reference" content="citation_title=Stochastic simulation optimization: an optimal computing budget allocation;,citation_author=Chun Hung Chen;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;">
<meta name="citation_reference" content="citation_title=Generalized Simulated Annealing for Function Optimization;,citation_author=I O Bohachevsky;,citation_publication_date=1986;,citation_cover_date=1986;,citation_year=1986;,citation_issue=3;,citation_volume=28;,citation_journal_title=Technometrics;">
<meta name="citation_reference" content="citation_title=On the Experimental Attainment of Optimum Conditions;,citation_author=G. E. P. Box;,citation_author=K. B. Wilson;,citation_publication_date=1951;,citation_cover_date=1951;,citation_year=1951;,citation_issue=1;,citation_volume=13;,citation_journal_title=Journal of the Royal Statistical Society. Series B (Methodological);">
<meta name="citation_reference" content="citation_title=Design and Analysis of Experiments;,citation_author=D C Montgomery;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;">
<meta name="citation_reference" content="citation_title=Empirical Design of Geometric Algorithms;,citation_author=Karsten Weihe;,citation_author=Ulrik Brandes;,citation_author=Annegret Liebers;,citation_author=Matthias Mı̈ Hannemann;,citation_author=Dorothea Wagner;,citation_author=Thomas Willhalm;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_conference_title=SCG ’99: Proceedings of the Fifteenth Annual Symposium on Computational Geometry;,citation_conference=Association for Computing Machinery;">
<meta name="citation_reference" content="citation_title=Hyperparameter optimization: Foundations, algorithms, best practices, and open challenges;,citation_author=Bernd Bischl;,citation_author=Martin Binder;,citation_author=Michel Lang;,citation_author=Tobias Pielok;,citation_author=Jakob Richter;,citation_author=Stefan Coors;,citation_author=Janek Thomas;,citation_author=Theresa Ullmann;,citation_author=Marc Becker;,citation_author=Anne-Laure Boulesteix;,citation_author=Difan Deng;,citation_author=Marius Lindauer;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_issue=2;,citation_volume=13;,citation_journal_title=WIREs Data Mining and Knowledge Discovery;">
<meta name="citation_reference" content="citation_title=Multi-Factor Experimental Designs for Exploring Response Surfaces;,citation_author=G. E. P. Box;,citation_author=J. S. Hunter;,citation_publication_date=1957;,citation_cover_date=1957;,citation_year=1957;,citation_issue=1;,citation_volume=28;,citation_journal_title=The Annals of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Multi-Objective Evolutionary Algorithms: Past, Present, and Future;,citation_author=Carlos A. Coello Coello;,citation_author=Silvia González Brambila;,citation_author=Josué Figueroa Gamboa;,citation_author=Ma. Guadalupe Castillo Tapia;,citation_editor=Panos M. Pardalos;,citation_editor=Varvara Rasskazova;,citation_editor=Michael N. Vrahatis;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_inbook_title=undefined;">
<meta name="citation_reference" content="citation_title=Modified Desirability Functions for Multiple Response Optimization;,citation_author=E. Del Castillo;,citation_author=D. C. Montgomery;,citation_author=D. R. McCarville;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_volume=28;,citation_journal_title=Journal of Quality Technology;">
<meta name="citation_reference" content="citation_title=Simultaneous Optimization of Several Response Variables;,citation_author=G. Derringer;,citation_author=R. Suich;,citation_publication_date=1980;,citation_cover_date=1980;,citation_year=1980;,citation_volume=12;,citation_journal_title=Journal of Quality Technology;">
<meta name="citation_reference" content="citation_title=A tutorial on multiobjective optimization: fundamentals and evolutionary methods;,citation_author=Michael T. M. Emmerich;,citation_author=AndréH. Deutz;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=3;,citation_volume=17;,citation_journal_title=Natural Computing;">
<meta name="citation_reference" content="citation_title=The Desirability Function;,citation_author=J Harington;,citation_publication_date=1965;,citation_cover_date=1965;,citation_year=1965;,citation_volume=21;,citation_journal_title=Industrial Quality Control;">
<meta name="citation_reference" content="citation_title=Multi-Objective Hyperparameter Optimization in Machine Learning—An Overview;,citation_author=Florian Karl;,citation_author=Tobias Pielok;,citation_author=Julia Moosbauer;,citation_author=Florian Pfisterer;,citation_author=Stefan Coors;,citation_author=Martin Binder;,citation_author=Lennart Schneider;,citation_author=Janek Thomas;,citation_author=Jakob Richter;,citation_author=Michel Lang;,citation_author=Eduardo C. Garrido-Merchán;,citation_author=Juergen Branke;,citation_author=Bernd Bischl;,citation_publication_date=2023-12;,citation_cover_date=2023-12;,citation_year=2023;,citation_issue=4;,citation_volume=3;,citation_journal_title=ACM Trans. Evol. Learn. Optim.;">
<meta name="citation_reference" content="citation_title=A Simplex Method for Function Minimization;,citation_author=J. A. Nelder;,citation_author=R. Mead;,citation_publication_date=1965-01;,citation_cover_date=1965-01;,citation_year=1965;,citation_issue=4;,citation_volume=7;,citation_journal_title=The Computer Journal;">
<meta name="citation_reference" content="citation_title=Multiple Objective Optimization Using Desirability Functions for the Design of a 3D Printer Prototype;,citation_author=Esmeralda Nino;,citation_author=Juan Rosas Rubio;,citation_author=Samuel Bonet;,citation_author=Nazario Ramirez-Beltran;,citation_author=Mauricio Cabrera-Rios;,citation_publication_date=2015-06;,citation_cover_date=2015-06;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=NIST/SEMATECH e-Handbook of Statistical Methods;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;">
<meta name="citation_reference" content="citation_title=The Nelder-Mead simplex procedure for function minimization;,citation_author=Donald M Olsson;,citation_author=Lloyd S Nelson;,citation_publication_date=1975;,citation_cover_date=1975;,citation_year=1975;,citation_issue=1;,citation_volume=17;,citation_journal_title=Technometrics;">
<meta name="citation_reference" content="citation_title=Hyperparameter Tuning Cookbook: A guide for scikit-learn, PyTorch, river, and spotpython;,citation_author=Thomas Bartz-Beielstein;,citation_publication_date=2023-07;,citation_cover_date=2023-07;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2307.10262;,citation_doi=10.48550/arXiv.2307.10262;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Interpolation of scattered data: Distance matrices and conditionally positive definite functions;,citation_abstract=Among other things, we prove that multiquadric surface interpolation is always solvable, thereby settling a conjecture of R. Franke.;,citation_author=Charles A. Micchelli;,citation_publication_date=1986;,citation_cover_date=1986;,citation_year=1986;,citation_fulltext_html_url=https://doi.org/10.1007/BF01893414;,citation_issue=1;,citation_doi=10.1007/BF01893414;,citation_isbn=1432-0940;,citation_volume=2;,citation_journal_title=Constructive Approximation;">
<meta name="citation_reference" content="citation_title=Computational Approaches for Aerospace Design: The Pursuit of Excellence;,citation_author=Andrew J Keane;,citation_author=Prasanth B Nair;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;">
<meta name="citation_reference" content="citation_title=Statistical learning theory;,citation_author=V N Vapnik;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;">
<meta name="citation_reference" content="citation_title=Regularization algorithms for learning that are equivalent to multilayer networks.;,citation_abstract=Learning an input-output mapping from a set of examples, of the type that many neural networks have been constructed to perform, can be regarded as synthesizing an approximation of a multidimensional function (that is, solving the problem of hypersurface reconstruction). From this point of view, this form of learning is closely related to classical approximation techniques, such as generalized splines and regularization theory. A theory is reported that shows the equivalence between regularization and a class of three-layer networks called regularization networks or hyper basis functions. These networks are not only equivalent to generalized splines but are also closely related to the classical radial basis functions used for interpolation tasks and to several pattern recognition and neural network algorithms. They also have an interesting interpretation in terms of prototypes that are synthesized and optimally combined during the learning stage.;,citation_author=T Poggio;,citation_author=F Girosi;,citation_publication_date=1990-02;,citation_cover_date=1990-02;,citation_year=1990;,citation_issue=4945;,citation_doi=10.1126/science.247.4945.978;,citation_issn=0036-8075 (Print); 0036-8075 (Linking);,citation_pmid=17776454;,citation_volume=247;,citation_journal_title=Science;">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./002_awwe.html">Optimization</a></li><li class="breadcrumb-item"><a href="./003_scipy_optimize_intro.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction to <code>scipy.optimize</code></span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Hyperparameter Tuning Cookbook</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/sequential-parameter-optimization/spotpython" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="./Hyperparameter-Tuning-Cookbook.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
              <i class="bi bi-linkedin pe-1"></i>
            LinkedIn
            </a>
          </li>
      </ul>
    </div>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Optimization</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./002_awwe.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Aircraft Wing Weight Example</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./003_scipy_optimize_intro.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction to <code>scipy.optimize</code></span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Numerical Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./001_surrogate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Simulation and Surrogate Modeling</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./001_sampling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Sampling Plans</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./006_constructing_surrogate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Constructing a Surrogate</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./005_num_rsm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Response Surface Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./006_num_poly.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Polynomial Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./006_num_rbf.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Radial Basis Function Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./006_num_gp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Kriging (Gaussian Process Regression)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./006_matrices.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Matrices</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Sequential Parameter Optimization Toolbox (SPOT)</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./007_spot_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Introduction to Sequential Parameter Optimization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./008_num_spot_multidim.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Multi-dimensional Functions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./009_num_spot_anisotropic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Isotropic and Anisotropic Kriging</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./004_spot_sklearn_optimization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Sequential Parameter Optimization: Using <code>scipy</code> Optimizers</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./010_num_spot_sklearn_surrogate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Using <code>sklearn</code> Surrogates in <code>spotpython</code></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./011_num_spot_sklearn_gaussian.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Sequential Parameter Optimization: Gaussian Process Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./012_num_spot_ei.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Expected Improvement</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./013_num_spot_noisy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Handling Noise</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./014_num_spot_ocba.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Optimal Computational Budget Allocation in spotpython</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./015_num_spot_correlation_p.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Kriging with Varying Correlation-p</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./016_num_spot_factorial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Factorial Variables</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./017_num_spot_user_function.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">User-Specified Functions: Extending the Analytical Class</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Data-Driven Modeling and Optimization</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./100_ddmo_eda.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Basic Statistics and Data Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./100_ddmo_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./100_ddmo_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Classification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./100_ddmo_clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Clustering</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Machine Learning and AI</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./200_mlai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Machine Learning and Artificial Intelligence</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Introduction to Hyperparameter Tuning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./300_hpt_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Hyperparameter Tuning with Sklearn</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./400_spot_hpt_sklearn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">HPT: sklearn</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./401_spot_hpt_sklearn_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">HPT: sklearn SVC on Moons Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./401_spot_hpt_sklearn_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Step 2: Initialization of the Empty <code>fun_control</code> Dictionary</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true">
 <span class="menu-text">Hyperparameter Tuning with River</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./500_spot_hpt_river.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">HPT: River</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./501_spot_river_gui.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Simplifying Hyperparameter Tuning in Online Machine Learning—The spotRiverGUI</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./502_spot_hpt_river_friedman_htr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title"><code>river</code> Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./503_spot_hpt_river_friedman_amfr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">The Friedman Drift Data Set</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true">
 <span class="menu-text">Hyperparameter Tuning with PyTorch Lightning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./700_lightning_basic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Basic Lightning Module</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./701_lightning_details.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Details of the Lightning Module Integration in spotpython</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./702_lightning_user_datamodule.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">User Specified Basic Lightning Module With spotpython</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./600_spot_lightning_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">HPT PyTorch Lightning: Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./601_spot_hpt_light_diabetes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning with <code>spotpython</code> and <code>PyTorch</code> Lightning for the Diabetes Data Set</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./601_spot_hpt_light_user_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning with PyTorch Lightning and User Data Sets</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./601_spot_hpt_light_user_model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning with PyTorch Lightning and User Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./601_resnet.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning with PyTorch Lightning: ResNets</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./601_neural_ode.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">Neural ODEs</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./601_neural_ode_example.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">45</span>&nbsp; <span class="chapter-title">Neural ODE Example</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./601_pinn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">46</span>&nbsp; <span class="chapter-title">Physics Informed Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./601_spot_hpt_light_pinn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">47</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning with PyTorch Lightning: Physics Informed Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./602_spot_lightning_xai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">48</span>&nbsp; <span class="chapter-title">Explainable AI with SpotPython and Pytorch</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./603_spot_lightning_transformer_introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">49</span>&nbsp; <span class="chapter-title">HPT PyTorch Lightning Transformer: Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./603_spot_lightning_transformer_hpt.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">50</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning of a Transformer Network with PyTorch Lightning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./604_spot_lightning_save_load_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">51</span>&nbsp; <span class="chapter-title">Saving and Loading</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./605_spot_hpt_light_diabetes_resnet.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">52</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning with <code>spotpython</code> and <code>PyTorch</code> Lightning for the Diabetes Data Set Using a ResNet Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./606_spot_hpt_light_diabetes_user_resnet.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">53</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning with <code>spotpython</code> and <code>PyTorch</code> Lightning for the Diabetes Data Set Using a User Specified ResNet Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./608_spot_hpt_light_condnet.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">54</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning with <code>spotpython</code> and <code>PyTorch</code> Lightning Using a CondNet Model</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true">
 <span class="menu-text">Multi Objective Optimization</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bart25a-desirability-latest.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">55</span>&nbsp; <span class="chapter-title">Introduction to Desirability Functions</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_01_intro_to_notebooks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Introduction to Jupyter Notebook</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_02_git_intro_en.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Git Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_03_python_intro_en.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Python</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_04_gp_background.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Gaussian Processes—Some Background Information</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_05_datasets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Datasets</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_06_slurm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Using Slurm</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_07_package.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">G</span>&nbsp; <span class="chapter-title">Python Package Building</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_08_parallel.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">H</span>&nbsp; <span class="chapter-title">Parallelism in Initial Design</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_99_solutions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">I</span>&nbsp; <span class="chapter-title">Solutions to Selected Exercises</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#derivative-free-optimization-algorithms" id="toc-derivative-free-optimization-algorithms" class="nav-link active" data-scroll-target="#derivative-free-optimization-algorithms"><span class="header-section-number">2.1</span> Derivative-free Optimization Algorithms</a>
  <ul class="collapse">
  <li><a href="#sec-nelder-mead-simplex-algorithm" id="toc-sec-nelder-mead-simplex-algorithm" class="nav-link" data-scroll-target="#sec-nelder-mead-simplex-algorithm"><span class="header-section-number">2.1.1</span> Nelder-Mead Simplex Algorithm</a></li>
  <li><a href="#sec-powells-method" id="toc-sec-powells-method" class="nav-link" data-scroll-target="#sec-powells-method"><span class="header-section-number">2.1.2</span> Powell’s Method</a></li>
  </ul></li>
  <li><a href="#gradient-based-optimization-algorithms" id="toc-gradient-based-optimization-algorithms" class="nav-link" data-scroll-target="#gradient-based-optimization-algorithms"><span class="header-section-number">2.2</span> Gradient-based Optimization Algorithms</a>
  <ul class="collapse">
  <li><a href="#sec-bfgs-intro" id="toc-sec-bfgs-intro" class="nav-link" data-scroll-target="#sec-bfgs-intro"><span class="header-section-number">2.2.1</span> An Introductory Example: Broyden-Fletcher-Goldfarb-Shanno Algorithm (BFGS)</a></li>
  <li><a href="#background-and-basics-for-gradient-based-optimization" id="toc-background-and-basics-for-gradient-based-optimization" class="nav-link" data-scroll-target="#background-and-basics-for-gradient-based-optimization"><span class="header-section-number">2.2.2</span> Background and Basics for Gradient-based Optimization</a></li>
  <li><a href="#gradient" id="toc-gradient" class="nav-link" data-scroll-target="#gradient"><span class="header-section-number">2.2.3</span> Gradient</a></li>
  <li><a href="#jacobian-matrix" id="toc-jacobian-matrix" class="nav-link" data-scroll-target="#jacobian-matrix"><span class="header-section-number">2.2.4</span> Jacobian Matrix</a></li>
  <li><a href="#hessian-matrix" id="toc-hessian-matrix" class="nav-link" data-scroll-target="#hessian-matrix"><span class="header-section-number">2.2.5</span> Hessian Matrix</a></li>
  <li><a href="#gradient-descent" id="toc-gradient-descent" class="nav-link" data-scroll-target="#gradient-descent"><span class="header-section-number">2.2.6</span> Gradient Descent</a></li>
  <li><a href="#newton-method" id="toc-newton-method" class="nav-link" data-scroll-target="#newton-method"><span class="header-section-number">2.2.7</span> Newton Method</a></li>
  <li><a href="#bfgs-algorithm" id="toc-bfgs-algorithm" class="nav-link" data-scroll-target="#bfgs-algorithm"><span class="header-section-number">2.2.8</span> BFGS-Algorithm</a></li>
  <li><a href="#procedure" id="toc-procedure" class="nav-link" data-scroll-target="#procedure"><span class="header-section-number">2.2.9</span> Procedure:</a></li>
  <li><a href="#visualization-bfgs-for-rosenbrock" id="toc-visualization-bfgs-for-rosenbrock" class="nav-link" data-scroll-target="#visualization-bfgs-for-rosenbrock"><span class="header-section-number">2.2.10</span> Visualization BFGS for Rosenbrock</a></li>
  </ul></li>
  <li><a href="#global-optimization" id="toc-global-optimization" class="nav-link" data-scroll-target="#global-optimization"><span class="header-section-number">2.3</span> Global Optimization</a>
  <ul class="collapse">
  <li><a href="#local-vs-global-optimization" id="toc-local-vs-global-optimization" class="nav-link" data-scroll-target="#local-vs-global-optimization"><span class="header-section-number">2.3.1</span> Local vs Global Optimization</a></li>
  <li><a href="#dual-annealing-optimization" id="toc-dual-annealing-optimization" class="nav-link" data-scroll-target="#dual-annealing-optimization"><span class="header-section-number">2.3.2</span> Dual Annealing Optimization</a></li>
  <li><a href="#differential-evolution" id="toc-differential-evolution" class="nav-link" data-scroll-target="#differential-evolution"><span class="header-section-number">2.3.3</span> Differential Evolution</a></li>
  <li><a href="#procedure-1" id="toc-procedure-1" class="nav-link" data-scroll-target="#procedure-1"><span class="header-section-number">2.3.4</span> Procedure</a></li>
  <li><a href="#other-global-optimization-algorithms" id="toc-other-global-optimization-algorithms" class="nav-link" data-scroll-target="#other-global-optimization-algorithms"><span class="header-section-number">2.3.5</span> Other global optimization algorithms</a></li>
  <li><a href="#direct" id="toc-direct" class="nav-link" data-scroll-target="#direct"><span class="header-section-number">2.3.6</span> DIRECT</a></li>
  <li><a href="#shgo" id="toc-shgo" class="nav-link" data-scroll-target="#shgo"><span class="header-section-number">2.3.7</span> SHGO</a></li>
  <li><a href="#basin-hopping" id="toc-basin-hopping" class="nav-link" data-scroll-target="#basin-hopping"><span class="header-section-number">2.3.8</span> Basin-hopping</a></li>
  </ul></li>
  <li><a href="#project-one-mass-oscillator-optimization" id="toc-project-one-mass-oscillator-optimization" class="nav-link" data-scroll-target="#project-one-mass-oscillator-optimization"><span class="header-section-number">2.4</span> Project: One-Mass Oscillator Optimization</a>
  <ul class="collapse">
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction"><span class="header-section-number">2.4.1</span> Introduction</a></li>
  <li><a href="#one-mass-oscillator-model" id="toc-one-mass-oscillator-model" class="nav-link" data-scroll-target="#one-mass-oscillator-model"><span class="header-section-number">2.4.2</span> One-Mass Oscillator Model</a></li>
  <li><a href="#the-real-world-data" id="toc-the-real-world-data" class="nav-link" data-scroll-target="#the-real-world-data"><span class="header-section-number">2.4.3</span> The Real-World Data</a></li>
  <li><a href="#objective-function" id="toc-objective-function" class="nav-link" data-scroll-target="#objective-function"><span class="header-section-number">2.4.4</span> Objective Function</a></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results"><span class="header-section-number">2.4.5</span> Results</a></li>
  </ul></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises"><span class="header-section-number">2.5</span> Exercises</a></li>
  <li><a href="#jupyter-notebook" id="toc-jupyter-notebook" class="nav-link" data-scroll-target="#jupyter-notebook"><span class="header-section-number">2.6</span> Jupyter Notebook</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./002_awwe.html">Optimization</a></li><li class="breadcrumb-item"><a href="./003_scipy_optimize_intro.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction to <code>scipy.optimize</code></span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction to <code>scipy.optimize</code></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><a href="https://scipy.org">SciPy</a> provides algorithms for optimization, integration, interpolation, eigenvalue problems, algebraic equations, differential equations, statistics and many other classes of problems. SciPy is a collection of mathematical algorithms and convenience functions built on NumPy. It adds significant power to Python by providing the user with high-level commands and classes for manipulating and visualizing data.</p>
<p><a href="https://docs.scipy.org/doc/scipy/reference/optimize.html#module-scipy.optimize">SciPy optimize</a> provides functions for minimizing (or maximizing) objective functions, possibly subject to constraints. It includes solvers for nonlinear problems (with support for both local and global optimization algorithms), linear programing, constrained and nonlinear least-squares, root finding, and curve fitting.</p>
<p>In this notebook, we will learn how to use the <code>scipy.optimize</code> module to solve optimization problems. See: <a href="https://docs.scipy.org/doc/scipy/tutorial/optimize.html">https://docs.scipy.org/doc/scipy/tutorial/optimize.html</a></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>This content is based on information from the scipy.optimize package.</li>
<li>The <code>scipy.optimize</code> package provides several commonly used optimization algorithms. A detailed listing is available in <code>scipy.optimize</code> (can also be found by <code>help(scipy.optimize)</code>).</li>
</ul>
</div>
</div>
<p>Common functions and objects, shared across different SciPy optimize solvers, are shown in <a href="#tbl-shared-functions" class="quarto-xref">Table&nbsp;<span>2.1</span></a>.</p>
<div id="tbl-shared-functions" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-shared-functions-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;2.1: Common functions and objects, shared across different SciPy optimize solvers
</figcaption>
<div aria-describedby="tbl-shared-functions-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead>
<tr class="header">
<th>Function or Object</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.show_options.html#scipy.optimize.show_options">show_options([solver, method, disp])</a></td>
<td>Show documentation for additional options of optimization solvers.</td>
</tr>
<tr class="even">
<td><a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.OptimizeResult.html#scipy.optimize.OptimizeResult">OptimizeResult</a></td>
<td>Represents the optimization result.</td>
</tr>
<tr class="odd">
<td><a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.OptimizeWarning.html#scipy.optimize.OptimizeWarning">OptimizeWarning</a></td>
<td>Warning issued by solvers.</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>We will introduce unconstrained minimization of multivariate scalar functions in this chapter. The <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize">minimize</a> function provides a common interface to unconstrained and constrained minimization algorithms for multivariate scalar functions in <code>scipy.optimize</code>. To demonstrate the minimization function, consider the problem of minimizing the Rosenbrock function of <em>N</em> variables:</p>
<p><span class="math display">\[
f(J) = \sum_{i=1}^{N-1} 100 (x_{i+1} - x_i^2)^2 + (1 - x_i)^2
\]</span></p>
<p>The minimum value of this function is 0, which is achieved when (x_i = 1).</p>
<p>Note that the Rosenbrock function and its derivatives are included in <code>scipy.optimize</code>. The implementations shown in the following sections provide examples of how to define an objective function as well as its Jacobian and Hessian functions. Objective functions in <code>scipy.optimize</code> expect a numpy array as their first parameter, which is to be optimized and must return a float value. The exact calling signature must be <code>f(x, *args)</code>, where <code>x</code> represents a numpy array, and <code>args</code> is a tuple of additional arguments supplied to the objective function.</p>
<section id="derivative-free-optimization-algorithms" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="derivative-free-optimization-algorithms"><span class="header-section-number">2.1</span> Derivative-free Optimization Algorithms</h2>
<p><a href="#sec-nelder-mead-simplex-algorithm" class="quarto-xref"><span>Section 2.1.1</span></a> and <a href="#sec-powells-method" class="quarto-xref"><span>Section 2.1.2</span></a> present two approaches that do not need gradient information to find the minimum. They use function evaluations to find the minimum.</p>
<section id="sec-nelder-mead-simplex-algorithm" class="level3" data-number="2.1.1">
<h3 data-number="2.1.1" class="anchored" data-anchor-id="sec-nelder-mead-simplex-algorithm"><span class="header-section-number">2.1.1</span> Nelder-Mead Simplex Algorithm</h3>
<p>The Nelder Mead is a simple local optimization algorithm. It requires only function evaluations and is a good choice for simple minimization problems. However, because it does not use any gradient evaluations, it may take longer to find the minimum. It can be devided into the following steps:</p>
<ol type="1">
<li>Initialize the simplex</li>
<li>Evaluate the function at each vertex of the simplex</li>
<li>Order the vertices by function value</li>
<li><strong>Reflect</strong> the worst point through the centroid of the remaining points</li>
<li>If the reflected point is better than the second worst, replace the worst point with the reflected point</li>
<li>If the reflected point is worse than the worst point, try <strong>contracting</strong> the simplex</li>
<li>If the reflected point is better than the best point, try <strong>expanding</strong> the simplex</li>
<li>If none of the above steps improve the simplex, <strong>shrink</strong> the simplex towards the best point</li>
<li>Check for convergence</li>
</ol>
<p><code>method='Nelder-Mead'</code>: In the example below, the <code>minimize</code> routine is used with the <em>Nelder-Mead</em> simplex algorithm (selected through the <code>method</code> parameter):</p>
<div id="7cddb527" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.optimize <span class="im">import</span> minimize</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rosen(x):</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""The Rosenbrock function"""</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">sum</span>(<span class="fl">100.0</span> <span class="op">*</span> (x[<span class="dv">1</span>:] <span class="op">-</span> x[:<span class="op">-</span><span class="dv">1</span>]<span class="op">**</span><span class="fl">2.0</span>)<span class="op">**</span><span class="fl">2.0</span> <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> x[:<span class="op">-</span><span class="dv">1</span>])<span class="op">**</span><span class="fl">2.0</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>x0 <span class="op">=</span> np.array([<span class="fl">1.3</span>, <span class="fl">0.7</span>, <span class="fl">0.8</span>, <span class="fl">1.9</span>, <span class="fl">1.2</span>])</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>res <span class="op">=</span> minimize(rosen, x0, method<span class="op">=</span><span class="st">'nelder-mead'</span>,</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>               options<span class="op">=</span>{<span class="st">'xatol'</span>: <span class="fl">1e-8</span>, <span class="st">'disp'</span>: <span class="va">True</span>})</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(res.x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Optimization terminated successfully.
         Current function value: 0.000000
         Iterations: 339
         Function evaluations: 571
[1. 1. 1. 1. 1.]</code></pre>
</div>
</div>
<p>The simplex algorithm is probably the simplest way to minimize a well-behaved function. It requires only function evaluations and is a good choice for simple minimization problems. However, because it does not use any gradient evaluations, it may take longer to find the minimum.</p>
</section>
<section id="sec-powells-method" class="level3" data-number="2.1.2">
<h3 data-number="2.1.2" class="anchored" data-anchor-id="sec-powells-method"><span class="header-section-number">2.1.2</span> Powell’s Method</h3>
<p>Another optimization algorithm that needs only function calls to find the minimum is <em>Powell</em>’s method, which can be selected by setting the <code>method</code> parameter to <code>'powell'</code> in the <code>minimize</code> function. This algorithm consists of a conjugate direction method. It performs sequential one-dimensional minimizations along each vector of the directions set, which is updated at each iteration of the main minimization loop. It can be described by the following steps:</p>
<ol type="1">
<li>Initialization</li>
<li>Minimization along each direction</li>
<li>Create conjugate direction</li>
<li>Line search along the conjugate direction</li>
<li>Check for convergence</li>
</ol>
<div id="exm-powells-method" class="theorem example">
<p><span class="theorem-title"><strong>Example 2.1</strong></span> To demonstrate how to supply additional arguments to an objective function, let’s consider minimizing the Rosenbrock function with an additional scaling factor <span class="math inline">\(a\)</span> and an offset <span class="math inline">\(b\)</span>:</p>
<p><span class="math display">\[
f(J, a, b) = \sum_{i=1}^{N-1} a (x_{i+1} - x_i^2)^2 + (1 - x_i)^2 + b
\]</span></p>
<p>You can achieve this using the <code>minimize</code> routine with the example parameters <span class="math inline">\(a=0.5\)</span> and <span class="math inline">\(b=1\)</span>:</p>
<div id="2e6182e5" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rosen_with_args(x, a, b):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""The Rosenbrock function with additional arguments"""</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">sum</span>(a <span class="op">*</span> (x[<span class="dv">1</span>:] <span class="op">-</span> x[:<span class="op">-</span><span class="dv">1</span>]<span class="op">**</span><span class="fl">2.0</span>)<span class="op">**</span><span class="fl">2.0</span> <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> x[:<span class="op">-</span><span class="dv">1</span>])<span class="op">**</span><span class="fl">2.0</span>) <span class="op">+</span> b</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>x0 <span class="op">=</span> np.array([<span class="fl">1.3</span>, <span class="fl">0.7</span>, <span class="fl">0.8</span>, <span class="fl">1.9</span>, <span class="fl">1.2</span>])</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>res <span class="op">=</span> minimize(rosen_with_args, x0, method<span class="op">=</span><span class="st">'nelder-mead'</span>,</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>               args<span class="op">=</span>(<span class="fl">0.5</span>, <span class="fl">1.</span>), options<span class="op">=</span>{<span class="st">'xatol'</span>: <span class="fl">1e-8</span>, <span class="st">'disp'</span>: <span class="va">True</span>})</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(res.x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Optimization terminated successfully.
         Current function value: 1.000000
         Iterations: 319
         Function evaluations: 525
[1.         1.         1.         1.         0.99999999]</code></pre>
</div>
</div>
<p>As an alternative to using the <code>args</code> parameter of <code>minimize</code>, you can wrap the objective function in a new function that accepts only <code>x</code>. This approach is also useful when it is necessary to pass additional parameters to the objective function as keyword arguments.</p>
<div id="a11dee9c" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rosen_with_args(x, a, <span class="op">*</span>, b):  <span class="co"># b is a keyword-only argument</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">sum</span>(a <span class="op">*</span> (x[<span class="dv">1</span>:] <span class="op">-</span> x[:<span class="op">-</span><span class="dv">1</span>]<span class="op">**</span><span class="fl">2.0</span>)<span class="op">**</span><span class="fl">2.0</span> <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> x[:<span class="op">-</span><span class="dv">1</span>])<span class="op">**</span><span class="fl">2.0</span>) <span class="op">+</span> b</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> wrapped_rosen_without_args(x):</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> rosen_with_args(x, <span class="fl">0.5</span>, b<span class="op">=</span><span class="fl">1.</span>)  <span class="co"># pass in `a` and `b`</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>x0 <span class="op">=</span> np.array([<span class="fl">1.3</span>, <span class="fl">0.7</span>, <span class="fl">0.8</span>, <span class="fl">1.9</span>, <span class="fl">1.2</span>])</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>res <span class="op">=</span> minimize(wrapped_rosen_without_args, x0, method<span class="op">=</span><span class="st">'nelder-mead'</span>,</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>               options<span class="op">=</span>{<span class="st">'xatol'</span>: <span class="fl">1e-8</span>,})</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(res.x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1.         1.         1.         1.         0.99999999]</code></pre>
</div>
</div>
<p>Another alternative is to use <code>functools.partial</code>.</p>
<div id="9d2db5c1" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> functools <span class="im">import</span> partial</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>partial_rosen <span class="op">=</span> partial(rosen_with_args, a<span class="op">=</span><span class="fl">0.5</span>, b<span class="op">=</span><span class="fl">1.</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>res <span class="op">=</span> minimize(partial_rosen, x0, method<span class="op">=</span><span class="st">'nelder-mead'</span>,</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>               options<span class="op">=</span>{<span class="st">'xatol'</span>: <span class="fl">1e-8</span>,})</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(res.x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1.         1.         1.         1.         0.99999999]</code></pre>
</div>
</div>
</div>
</section>
</section>
<section id="gradient-based-optimization-algorithms" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="gradient-based-optimization-algorithms"><span class="header-section-number">2.2</span> Gradient-based Optimization Algorithms</h2>
<section id="sec-bfgs-intro" class="level3" data-number="2.2.1">
<h3 data-number="2.2.1" class="anchored" data-anchor-id="sec-bfgs-intro"><span class="header-section-number">2.2.1</span> An Introductory Example: Broyden-Fletcher-Goldfarb-Shanno Algorithm (BFGS)</h3>
<p>This section introduces an optimization algorithm that uses gradient information to find the minimum. The Broyden-Fletcher-Goldfarb-Shanno (BFGS) algorithm (selected by setting <code>method='BFGS'</code>) is an optimization algorithm that aims to converge quickly to the solution. This algorithm uses the gradient of the objective function. If the gradient is not provided by the user, it is estimated using first-differences. The BFGS method typically requires fewer function calls compared to the simplex algorithm, even when the gradient needs to be estimated.</p>
<div id="exm-bfgs" class="theorem example">
<p><span class="theorem-title"><strong>Example 2.2 (BFGS)</strong></span> To demonstrate the BFGS algorithm, let’s use the Rosenbrock function again. The gradient of the Rosenbrock function is a vector described by the following mathematical expression:</p>
<p><span class="math display">\[\begin{align}
\frac{\partial f}{\partial x_j} = \sum_{i=1}^{N} 200(x_i - x_{i-1}^2)(\delta_{i,j} - 2x_{i-1}\delta_{i-1,j}) - 2(1 - x_{i-1})\delta_{i-1,j} \\
= 200(x_j - x_{j-1}^2) - 400x_j(x_{j+1} - x_j^2) - 2(1 - x_j)
\end{align}\]</span></p>
<p>This expression is valid for interior derivatives, but special cases are:</p>
<p><span class="math display">\[
\frac{\partial f}{\partial x_0} = -400x_0(x_1 - x_0^2) - 2(1 - x_0)
\]</span></p>
<p><span class="math display">\[
\frac{\partial f}{\partial x_{N-1}} = 200(x_{N-1} - x_{N-2}^2)
\]</span></p>
<p>Here’s a Python function that computes this gradient:</p>
<div id="67045bc7" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rosen_der(x):</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    xm <span class="op">=</span> x[<span class="dv">1</span>:<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    xm_m1 <span class="op">=</span> x[:<span class="op">-</span><span class="dv">2</span>]</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    xm_p1 <span class="op">=</span> x[<span class="dv">2</span>:]</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    der <span class="op">=</span> np.zeros_like(x)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    der[<span class="dv">1</span>:<span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> <span class="dv">200</span><span class="op">*</span>(xm<span class="op">-</span>xm_m1<span class="op">**</span><span class="dv">2</span>) <span class="op">-</span> <span class="dv">400</span><span class="op">*</span>(xm_p1 <span class="op">-</span> xm<span class="op">**</span><span class="dv">2</span>)<span class="op">*</span>xm <span class="op">-</span> <span class="dv">2</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>xm)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    der[<span class="dv">0</span>] <span class="op">=</span> <span class="op">-</span><span class="dv">400</span><span class="op">*</span>x[<span class="dv">0</span>]<span class="op">*</span>(x[<span class="dv">1</span>]<span class="op">-</span>x[<span class="dv">0</span>]<span class="op">**</span><span class="dv">2</span>) <span class="op">-</span> <span class="dv">2</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>x[<span class="dv">0</span>])</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    der[<span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> <span class="dv">200</span><span class="op">*</span>(x[<span class="op">-</span><span class="dv">1</span>]<span class="op">-</span>x[<span class="op">-</span><span class="dv">2</span>]<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> der</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>You can specify this gradient information in the minimize function using the jac parameter as illustrated below:</p>
<div id="213f5938" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>res <span class="op">=</span> minimize(rosen, x0, method<span class="op">=</span><span class="st">'BFGS'</span>, jac<span class="op">=</span>rosen_der,</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>               options<span class="op">=</span>{<span class="st">'disp'</span>: <span class="va">True</span>})</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(res.x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Optimization terminated successfully.
         Current function value: 0.000000
         Iterations: 25
         Function evaluations: 30
         Gradient evaluations: 30
[1.00000004 1.0000001  1.00000021 1.00000044 1.00000092]</code></pre>
</div>
</div>
</div>
</section>
<section id="background-and-basics-for-gradient-based-optimization" class="level3" data-number="2.2.2">
<h3 data-number="2.2.2" class="anchored" data-anchor-id="background-and-basics-for-gradient-based-optimization"><span class="header-section-number">2.2.2</span> Background and Basics for Gradient-based Optimization</h3>
</section>
<section id="gradient" class="level3" data-number="2.2.3">
<h3 data-number="2.2.3" class="anchored" data-anchor-id="gradient"><span class="header-section-number">2.2.3</span> Gradient</h3>
<p>The gradient <span class="math inline">\(\nabla f(J)\)</span> for a scalar function <span class="math inline">\(f(J)\)</span> with <span class="math inline">\(n\)</span> different variables is defined by its partial derivatives:</p>
<p><span class="math display">\[
\nabla f(J) = \left[ \frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, \ldots, \frac{\partial f}{\partial x_n} \right]
\]</span></p>
</section>
<section id="jacobian-matrix" class="level3" data-number="2.2.4">
<h3 data-number="2.2.4" class="anchored" data-anchor-id="jacobian-matrix"><span class="header-section-number">2.2.4</span> Jacobian Matrix</h3>
<p>The Jacobian matrix <span class="math inline">\(J(J)\)</span> for a vector-valued function <span class="math inline">\(F(J) = [f_1(J), f_2(J), \ldots, f_m(J)]\)</span> is defined as:</p>
<p><span class="math inline">\(J(J) = \begin{bmatrix} \frac{\partial f_1}{\partial x_1} &amp; \frac{\partial f_1}{\partial x_2} &amp; \ldots &amp; \frac{\partial f_1}{\partial x_n} \\ \frac{\partial f_2}{\partial x_1} &amp; \frac{\partial f_2}{\partial x_2} &amp; \ldots &amp; \frac{\partial f_2}{\partial x_n} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ \frac{\partial f_m}{\partial x_1} &amp; \frac{\partial f_m}{\partial x_2} &amp; \ldots &amp; \frac{\partial f_m}{\partial x_n} \end{bmatrix}\)</span></p>
<p>It consists of the first order partial derivatives and gives therefore an overview about the gradients of a vector valued function.</p>
<div id="exm-jacobian" class="theorem example">
<p><span class="theorem-title"><strong>Example 2.3 (acobian matrix)</strong></span> Consider a vector-valued function <span class="math inline">\(f : \mathbb{R}^2 \rightarrow \mathbb{R}^3\)</span> defined as follows: <span class="math display">\[f(J) = \begin{bmatrix} x_1^2 + 2x_2 \\ 3x_1 - \sin(x_2) \\ e^{x_1 + x_2} \end{bmatrix}\]</span></p>
<p>Let’s compute the partial derivatives and construct the Jacobian matrix:</p>
<p><span class="math inline">\(\frac{\partial f_1}{\partial x_1} = 2x_1, \quad \frac{\partial f_1}{\partial x_2} = 2\)</span></p>
<p><span class="math inline">\(\frac{\partial f_2}{\partial x_1} = 3, \quad \frac{\partial f_2}{\partial x_2} = -\cos(x_2)\)</span></p>
<p><span class="math inline">\(\frac{\partial f_3}{\partial x_1} = e^{x_1 + x_2}, \quad \frac{\partial f_3}{\partial x_2} = e^{x_1 + x_2}\)</span></p>
<p>So, the Jacobian matrix is:</p>
<p><span class="math display">\[J(J) = \begin{bmatrix} 2x_1 &amp; 2 \\ 3 &amp; -\cos(x_2) \\ e^{x_1 + x_2} &amp; e^{x_1 + x_2} \end{bmatrix}\]</span></p>
<p>This Jacobian matrix provides information about how small changes in the input variables <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> affect the corresponding changes in each component of the output vector.</p>
</div>
</section>
<section id="hessian-matrix" class="level3" data-number="2.2.5">
<h3 data-number="2.2.5" class="anchored" data-anchor-id="hessian-matrix"><span class="header-section-number">2.2.5</span> Hessian Matrix</h3>
<p>The Hessian matrix <span class="math inline">\(H(J)\)</span> for a scalar function <span class="math inline">\(f(J)\)</span> is defined as:</p>
<p><span class="math inline">\(H(J) = \begin{bmatrix} \frac{\partial^2 f}{\partial x_1^2} &amp; \frac{\partial^2 f}{\partial x_1 \partial x_2} &amp; \ldots &amp; \frac{\partial^2 f}{\partial x_1 \partial x_n} \\ \frac{\partial^2 f}{\partial x_2 \partial x_1} &amp; \frac{\partial^2 f}{\partial x_2^2} &amp; \ldots &amp; \frac{\partial^2 f}{\partial x_2 \partial x_n} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ \frac{\partial^2 f}{\partial x_n \partial x_1} &amp; \frac{\partial^2 f}{\partial x_n \partial x_2} &amp; \ldots &amp; \frac{\partial^2 f}{\partial x_n^2} \end{bmatrix}\)</span></p>
<p>The Hessian matrix consists of the second order derivatives of the function. It provides information about the local curvature of the function with respect to changes in the input variables.</p>
<div id="exm-hessian" class="theorem example">
<p><span class="theorem-title"><strong>Example 2.4 (Hessian matrix)</strong></span> Consider a scalar-valued function: <span class="math display">\[f(J) = x_1^2 + 2x_2^2 + \sin(x_1   x_2)\]</span></p>
<p>The Hessian matrix of this scalar-valued function is the matrix of its second-order partial derivatives with respect to the input variables: <span class="math display">\[H(J) = \begin{bmatrix} \frac{\partial^2 f}{\partial x_1^2} &amp; \frac{\partial^2 f}{\partial x_1 \partial x_2} \\ \frac{\partial^2 f}{\partial x_2 \partial x_1} &amp; \frac{\partial^2 f}{\partial x_2^2} \end{bmatrix}\]</span></p>
<p>Let’s compute the second-order partial derivatives and construct the Hessian matrix:</p>
<p><span class="math display">\[\begin{align}
\frac{\partial^2 f}{\partial x_1^2} &amp;= 2 + \cos(x_1 x_2) x_2^2\\
\frac{\partial^2 f}{\partial x_1 \partial x_2} &amp;= 2x_1  x_2 \cos(x_1 x_2) - \sin(x_1  x_2)\\
\frac{\partial^2 f}{\partial x_2 \partial x_1} &amp;= 2x_1  x_2  \cos(x_1  x_2) - \sin(x_1  x_2)\\
\frac{\partial^2 f}{\partial x_2^2} &amp;= 4x_2^2 + \cos(x_1  x_2) x_1^2
\end{align}\]</span></p>
<p>So, the Hessian matrix is:</p>
<p><span class="math display">\[H(J) = \begin{bmatrix} 2 + \cos(x_1   x_2)   x_2^2 &amp; 2x_1   x_2   \cos(x_1   x_2) - \sin(x_1   x_2) \\ 2x_1   x_2   \cos(x_1   x_2) - \sin(x_1   x_2) &amp; 4x_2^2 + \cos(x_1   x_2)   x_1^2 \end{bmatrix}\]</span></p>
</div>
</section>
<section id="gradient-descent" class="level3" data-number="2.2.6">
<h3 data-number="2.2.6" class="anchored" data-anchor-id="gradient-descent"><span class="header-section-number">2.2.6</span> Gradient Descent</h3>
<p>In optimization, the goal is to find the minimum or maximum of a function. Gradient-based optimization methods utilize information about the gradient (or derivative) of the function to guide the search for the optimal solution. This is particularly useful when dealing with complex, high-dimensional functions where an exhaustive search is impractical.</p>
<p>The gradient descent method can be divided in the following steps:</p>
<ul>
<li><strong>Initialize:</strong> start with an initial guess for the parameters of the function to be optimized.</li>
<li><strong>Compute Gradient:</strong> Calculate the gradient (partial derivatives) of the function with respect to each parameter at the current point. The gradient indicates the direction of the steepest increase in the function.</li>
<li><strong>Update Parameters:</strong> Adjust the parameters in the opposite direction of the gradient, scaled by a learning rate. This step aims to move towards the minimum of the function:
<ul>
<li><span class="math inline">\(x_{k+1} = x_k - \alpha \times \nabla f(x_{k})\)</span></li>
<li><span class="math inline">\(x_{x}\)</span> is current parameter vector or point in the parameter space.</li>
<li><span class="math inline">\(\alpha\)</span> is the learning rate, a positive scalar that determines the step size in each iteration.</li>
<li><span class="math inline">\(\nabla f(x)\)</span> is the gradient of the objective function.</li>
</ul></li>
<li><strong>Iterate:</strong> Repeat the above steps until convergence or a predefined number of iterations. Convergence is typically determined when the change in the function value or parameters becomes negligible.</li>
</ul>
<div id="exm-gradient-descent" class="theorem example">
<p><span class="theorem-title"><strong>Example 2.5 (Gradient Descent)</strong></span> We consider a simple quadratic function as an example: <span class="math display">\[
f(x) = x^2 + 4x + y^2 + 2y + 4.
\]</span></p>
<p>We’ll use gradient descent to find the minimum of this function.</p>
<div id="30689c51" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mpl_toolkits.mplot3d <span class="im">import</span> Axes3D</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the quadratic function</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> quadratic_function(x, y):</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> <span class="dv">4</span><span class="op">*</span>x <span class="op">+</span> y<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> <span class="dv">2</span><span class="op">*</span>y <span class="op">+</span> <span class="dv">4</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the gradient of the quadratic function</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gradient_quadratic_function(x, y):</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    grad_x <span class="op">=</span> <span class="dv">2</span><span class="op">*</span>x <span class="op">+</span> <span class="dv">4</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    grad_y <span class="op">=</span> <span class="dv">2</span><span class="op">*</span>y <span class="op">+</span> <span class="dv">2</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array([grad_x, grad_y])</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Gradient Descent for optimization in 2D</span></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gradient_descent(initial_point, learning_rate, num_iterations):</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>    points <span class="op">=</span> [np.array(initial_point)]</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(num_iterations):</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>        current_point <span class="op">=</span> points[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>        gradient <span class="op">=</span> gradient_quadratic_function(<span class="op">*</span>current_point)</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>        new_point <span class="op">=</span> current_point <span class="op">-</span> learning_rate <span class="op">*</span> gradient</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>        points.append(new_point)</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> points</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualization of optimization process with 3D surface and consistent arrow sizes</span></span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_optimization_process_3d_consistent_arrows(points):</span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> fig.add_subplot(<span class="dv">111</span>, projection<span class="op">=</span><span class="st">'3d'</span>)</span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>    x_vals <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">10</span>, <span class="dv">2</span>, <span class="dv">100</span>)</span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>    y_vals <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">10</span>, <span class="dv">2</span>, <span class="dv">100</span>)</span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>    X, Y <span class="op">=</span> np.meshgrid(x_vals, y_vals)</span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> quadratic_function(X, Y)</span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>    ax.plot_surface(X, Y, Z, cmap<span class="op">=</span><span class="st">'viridis'</span>, alpha<span class="op">=</span><span class="fl">0.6</span>)</span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a>    ax.scatter(<span class="op">*</span><span class="bu">zip</span>(<span class="op">*</span>points), [quadratic_function(<span class="op">*</span>p) <span class="cf">for</span> p <span class="kw">in</span> points], c<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">'Optimization Trajectory'</span>)</span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(points) <span class="op">-</span> <span class="dv">1</span>):  </span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a>        x, y <span class="op">=</span> points[i]</span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a>        dx, dy <span class="op">=</span> points[i <span class="op">+</span> <span class="dv">1</span>] <span class="op">-</span> points[i]</span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a>        dz <span class="op">=</span> quadratic_function(<span class="op">*</span>(points[i <span class="op">+</span> <span class="dv">1</span>])) <span class="op">-</span> quadratic_function(<span class="op">*</span>points[i])</span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a>        gradient_length <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-44"><a href="#cb12-44" aria-hidden="true" tabindex="-1"></a>        ax.quiver(x, y, quadratic_function(<span class="op">*</span>points[i]), dx, dy, dz, color<span class="op">=</span><span class="st">'blue'</span>, length<span class="op">=</span>gradient_length, normalize<span class="op">=</span><span class="va">False</span>, arrow_length_ratio<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb12-45"><a href="#cb12-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-46"><a href="#cb12-46" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="st">'Gradient-Based Optimization with 2D Quadratic Function'</span>)</span>
<span id="cb12-47"><a href="#cb12-47" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="st">'x'</span>)</span>
<span id="cb12-48"><a href="#cb12-48" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">'y'</span>)</span>
<span id="cb12-49"><a href="#cb12-49" aria-hidden="true" tabindex="-1"></a>    ax.set_zlabel(<span class="st">'f(x, y)'</span>)</span>
<span id="cb12-50"><a href="#cb12-50" aria-hidden="true" tabindex="-1"></a>    ax.legend()</span>
<span id="cb12-51"><a href="#cb12-51" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb12-52"><a href="#cb12-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-53"><a href="#cb12-53" aria-hidden="true" tabindex="-1"></a><span class="co"># Initial guess and parameters</span></span>
<span id="cb12-54"><a href="#cb12-54" aria-hidden="true" tabindex="-1"></a>initial_guess <span class="op">=</span> [<span class="op">-</span><span class="fl">9.0</span>, <span class="op">-</span><span class="fl">9.0</span>]</span>
<span id="cb12-55"><a href="#cb12-55" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.2</span></span>
<span id="cb12-56"><a href="#cb12-56" aria-hidden="true" tabindex="-1"></a>num_iterations <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb12-57"><a href="#cb12-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-58"><a href="#cb12-58" aria-hidden="true" tabindex="-1"></a><span class="co"># Run gradient descent in 2D and visualize the optimization process with 3D surface and consistent arrow sizes</span></span>
<span id="cb12-59"><a href="#cb12-59" aria-hidden="true" tabindex="-1"></a>trajectory <span class="op">=</span> gradient_descent(initial_guess, learning_rate, num_iterations)</span>
<span id="cb12-60"><a href="#cb12-60" aria-hidden="true" tabindex="-1"></a>plot_optimization_process_3d_consistent_arrows(trajectory)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="003_scipy_optimize_intro_files/figure-html/cell-8-output-1.png" width="621" height="631" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</div>
</section>
<section id="newton-method" class="level3" data-number="2.2.7">
<h3 data-number="2.2.7" class="anchored" data-anchor-id="newton-method"><span class="header-section-number">2.2.7</span> Newton Method</h3>
<p><strong>Initialization:</strong> Start with an initial guess for the optimal solution: <span class="math inline">\(x_0\)</span>.</p>
<p><strong>Iteration:</strong> Repeat the following three steps until convergence or a predefined stopping criterion is met:</p>
<ol type="1">
<li><p>Calculate the gradient (<span class="math inline">\(\nabla\)</span>) and the Hessian matrix (<span class="math inline">\(\nabla^2\)</span>) of the objective function at the current point: <span class="math display">\[\nabla f(x_k) \quad \text{and} \quad \nabla^2 f(x_k)\]</span></p></li>
<li><p>Update the current solution using the Newton-Raphson update formula <span class="math display">\[
x_{k+1} = x_k - [\nabla^2 f(x_k)]^{-1} \nabla f(x_k),
\]</span> where</p>
<pre><code>* $\nabla f(x_k)$ is the gradient (first derivative) of the objective function with respect to the variable $x$, evaluated at the current solution $x_k$.</code></pre>
<ul>
<li><span class="math inline">\(\nabla^2 f(x_k)\)</span>: The Hessian matrix (second derivative) of the objective function with respect to <span class="math inline">\(x\)</span>, evaluated at the current solution <span class="math inline">\(x_k\)</span>.</li>
<li><span class="math inline">\(x_k\)</span>: The current solution or point in the optimization process.</li>
<li><span class="math inline">\(\nabla^2 f(x_k)]^{-1}\)</span>: The inverse of the Hessian matrix at the current point, representing the approximation of the curvature of the objective function.</li>
<li><span class="math inline">\(x_{k+1}\)</span>: The updated solution or point after applying the Newton-Raphson update.</li>
</ul></li>
<li><p>Check for convergence.</p></li>
</ol>
<div id="exm-newton-method" class="theorem example">
<p><span class="theorem-title"><strong>Example 2.6 (Newton Method)</strong></span> We want to optimize the Rosenbrock function and use the Hessian and the Jacobian (which is equal to the gradient vector for scalar objective function) to the <code>minimize</code> function.</p>
<div id="5a99f712" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rosenbrock(x):</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">100</span> <span class="op">*</span> (x[<span class="dv">1</span>] <span class="op">-</span> x[<span class="dv">0</span>]<span class="op">**</span><span class="dv">2</span>)<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> x[<span class="dv">0</span>])<span class="op">**</span><span class="dv">2</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rosenbrock_gradient(x):</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    dfdx0 <span class="op">=</span> <span class="op">-</span><span class="dv">400</span> <span class="op">*</span> x[<span class="dv">0</span>] <span class="op">*</span> (x[<span class="dv">1</span>] <span class="op">-</span> x[<span class="dv">0</span>]<span class="op">**</span><span class="dv">2</span>) <span class="op">-</span> <span class="dv">2</span> <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> x[<span class="dv">0</span>])</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    dfdx1 <span class="op">=</span> <span class="dv">200</span> <span class="op">*</span> (x[<span class="dv">1</span>] <span class="op">-</span> x[<span class="dv">0</span>]<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array([dfdx0, dfdx1])</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rosenbrock_hessian(x):</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>    d2fdx0 <span class="op">=</span> <span class="dv">1200</span> <span class="op">*</span> x[<span class="dv">0</span>]<span class="op">**</span><span class="dv">2</span> <span class="op">-</span> <span class="dv">400</span> <span class="op">*</span> x[<span class="dv">1</span>] <span class="op">+</span> <span class="dv">2</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>    d2fdx1 <span class="op">=</span> <span class="op">-</span><span class="dv">400</span> <span class="op">*</span> x[<span class="dv">0</span>]</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array([[d2fdx0, d2fdx1], [d2fdx1, <span class="dv">200</span>]])</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> classical_newton_optimization_2d(initial_guess, tol<span class="op">=</span><span class="fl">1e-6</span>, max_iter<span class="op">=</span><span class="dv">100</span>):</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> initial_guess.copy()</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(max_iter):</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>        gradient <span class="op">=</span> rosenbrock_gradient(x)</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>        hessian <span class="op">=</span> rosenbrock_hessian(x)</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Solve the linear system H * d = -g for d</span></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>        d <span class="op">=</span> np.linalg.solve(hessian, <span class="op">-</span>gradient)</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Update x</span></span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>        x <span class="op">+=</span> d</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check for convergence</span></span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> np.linalg.norm(gradient, <span class="bu">ord</span><span class="op">=</span>np.inf) <span class="op">&lt;</span> tol:</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x</span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Initial guess</span></span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a>initial_guess_2d <span class="op">=</span> np.array([<span class="fl">0.0</span>, <span class="fl">0.0</span>])</span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Run classical Newton optimization for the 2D Rosenbrock function</span></span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a>result_2d <span class="op">=</span> classical_newton_optimization_2d(initial_guess_2d)</span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the result</span></span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Optimal solution:"</span>, result_2d)</span>
<span id="cb14-41"><a href="#cb14-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Objective value:"</span>, rosenbrock(result_2d))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Optimal solution: [1. 1.]
Objective value: 0.0</code></pre>
</div>
</div>
</div>
</section>
<section id="bfgs-algorithm" class="level3" data-number="2.2.8">
<h3 data-number="2.2.8" class="anchored" data-anchor-id="bfgs-algorithm"><span class="header-section-number">2.2.8</span> BFGS-Algorithm</h3>
<p>BFGS is an optimization algorithm designed for unconstrained optimization problems. It belongs to the class of quasi-Newton methods and is known for its efficiency in finding the minimum of a smooth, unconstrained objective function.</p>
</section>
<section id="procedure" class="level3" data-number="2.2.9">
<h3 data-number="2.2.9" class="anchored" data-anchor-id="procedure"><span class="header-section-number">2.2.9</span> Procedure:</h3>
<ol type="1">
<li><strong>Initialization:</strong>
<ul>
<li>Start with an initial guess for the parameters of the objective function.</li>
<li>Initialize an approximation of the Hessian matrix (inverse) denoted by <span class="math inline">\(H\)</span>.<br>
</li>
</ul></li>
<li><strong>Iterative Update:</strong>
<ul>
<li>At each iteration, compute the gradient vector at the current point.</li>
<li>Update the parameters using the BFGS update formula, which involves the inverse Hessian matrix approximation, the gradient, and the difference in parameter vectors between successive iterations: <span class="math display">\[x_{k+1} = x_k - H_k^{-1} \nabla f(x_k).\]</span></li>
<li>Update the inverse Hessian approximation using the BFGS update formula for the inverse Hessian. <span class="math display">\[H_{k+1} = H_k + \frac{\Delta x_k \Delta x_k^T}{\Delta x_k^T \Delta g_k} - \frac{H_k g_k g_k^T H_k}{g_k^T H_k g_k},\]</span> where:</li>
<li><span class="math inline">\(x_k\)</span> and <span class="math inline">\(x_{k+1}\)</span> are the parameter vectors at the current and updated iterations, respectively.</li>
<li><span class="math inline">\(\nabla f(x_k)\)</span> is the gradient vector at the current iteration.</li>
<li><span class="math inline">\(\Delta x_k = x_{k+1} - x_k\)</span> is the change in parameter vectors.</li>
<li><span class="math inline">\(\Delta g_k = \nabla f(x_{k+1}) - \nabla f(x_k)\)</span> is the change in gradient vectors.</li>
</ul></li>
<li><strong>Convergence:</strong>
<ul>
<li>Repeat the iterative update until the optimization converges. Convergence is typically determined by reaching a sufficiently low gradient or parameter change.</li>
</ul></li>
</ol>
<div id="exm-bfgs" class="theorem example">
<p><span class="theorem-title"><strong>Example 2.7 (BFGS for Rosenbrock)</strong></span> &nbsp;</p>
<div id="102ea17d" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.optimize <span class="im">import</span> minimize</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the 2D Rosenbrock function</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rosenbrock(x):</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (<span class="dv">1</span> <span class="op">-</span> x[<span class="dv">0</span>])<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> <span class="dv">100</span> <span class="op">*</span> (x[<span class="dv">1</span>] <span class="op">-</span> x[<span class="dv">0</span>]<span class="op">**</span><span class="dv">2</span>)<span class="op">**</span><span class="dv">2</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Initial guess</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>initial_guess <span class="op">=</span> np.array([<span class="fl">0.0</span>, <span class="fl">0.0</span>])</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Minimize the Rosenbrock function using BFGS</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>minimize(rosenbrock, initial_guess, method<span class="op">=</span><span class="st">'BFGS'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>  message: Optimization terminated successfully.
  success: True
   status: 0
      fun: 2.8440052847381483e-11
        x: [ 1.000e+00  1.000e+00]
      nit: 19
      jac: [ 3.987e-06 -2.844e-06]
 hess_inv: [[ 4.948e-01  9.896e-01]
            [ 9.896e-01  1.984e+00]]
     nfev: 72
     njev: 24</code></pre>
</div>
</div>
</div>
</section>
<section id="visualization-bfgs-for-rosenbrock" class="level3" data-number="2.2.10">
<h3 data-number="2.2.10" class="anchored" data-anchor-id="visualization-bfgs-for-rosenbrock"><span class="header-section-number">2.2.10</span> Visualization BFGS for Rosenbrock</h3>
<p>A visualization of the BFGS search process on Rosenbrock’s function can be found here: <a href="https://upload.wikimedia.org/wikipedia/de/f/ff/Rosenbrock-bfgs-animation.gif">https://upload.wikimedia.org/wikipedia/de/f/ff/Rosenbrock-bfgs-animation.gif</a></p>
<!-- 
![BFGS search process on Rosenbrock's function. Figure taken from: [https://upload.wikimedia.org/wikipedia/de/f/ff/Rosenbrock-bfgs-animation.gif](https://upload.wikimedia.org/wikipedia/de/f/ff/Rosenbrock-bfgs-animation.gif)](./figures_static/Rosenbrock-bfgs-animation.gif)
 -->
</section>
</section>
<section id="global-optimization" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="global-optimization"><span class="header-section-number">2.3</span> Global Optimization</h2>
<p>Global optimization aims to find the global minimum of a function within given bounds, in the presence of potentially many local minima. Typically, global minimizers efficiently search the parameter space, while using a local minimizer (e.g., minimize) under the hood.</p>
<section id="local-vs-global-optimization" class="level3" data-number="2.3.1">
<h3 data-number="2.3.1" class="anchored" data-anchor-id="local-vs-global-optimization"><span class="header-section-number">2.3.1</span> Local vs Global Optimization</h3>
<section id="local-optimizater" class="level4" data-number="2.3.1.1">
<h4 data-number="2.3.1.1" class="anchored" data-anchor-id="local-optimizater"><span class="header-section-number">2.3.1.1</span> Local Optimizater:</h4>
<ul>
<li>Seeks the optimum in a <strong>specific region</strong> of the search space</li>
<li>Tends to <strong>exploit</strong> the local environment, to find solutions in the immediate area</li>
<li>Highly <strong>sensitive to initial conditions</strong>; may converge to different local optima based on the starting point</li>
<li>Often <strong>computationally efficient for low-dimensional problems</strong> but may struggle with high-dimensional or complex search spaces</li>
<li>Commonly used in situations where the objective is to refine and improve existing solutions</li>
</ul>
</section>
<section id="global-optimizer" class="level4" data-number="2.3.1.2">
<h4 data-number="2.3.1.2" class="anchored" data-anchor-id="global-optimizer"><span class="header-section-number">2.3.1.2</span> Global Optimizer:</h4>
<ul>
<li>Explores the <strong>entire search space</strong> to find the global optimum</li>
<li>Emphasize <strong>exploration over exploitation</strong>, aiming to search broadly and avoid premature convergence to local optima</li>
<li>Aim to <strong>mitigate the risk of premature convergence</strong> to local optima by employing strategies for global exploration</li>
<li><strong>Less sensitive to initial conditions</strong>, designed to navigate diverse regions of the search space</li>
<li>Equipped to handle <strong>high-dimensional</strong> and <strong>complex</strong> problems, though computational demands may vary depending on the specific algorithm</li>
<li>Preferred for applications where a comprehensive search of the solution space is crucial, such as in parameter tuning, machine learning, and complex engineering design</li>
</ul>
<p><img src="./figures_static/globalvslocal.png" alt="Local vs Global Optimum" width="700"></p>
<div id="exm-global-optimization" class="theorem example">
<p><span class="theorem-title"><strong>Example 2.8 (Global Optimizers in SciPy)</strong></span> SciPy contains a number of good global optimizers. Here, we’ll use those on the same objective function, namely the (aptly named) eggholder function:</p>
<div id="06ec2cbf" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> eggholder(x):</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (<span class="op">-</span>(x[<span class="dv">1</span>] <span class="op">+</span> <span class="dv">47</span>) <span class="op">*</span> np.sin(np.sqrt(<span class="bu">abs</span>(x[<span class="dv">0</span>]<span class="op">/</span><span class="dv">2</span> <span class="op">+</span> (x[<span class="dv">1</span>]  <span class="op">+</span> <span class="dv">47</span>))))</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>            <span class="op">-</span>x[<span class="dv">0</span>] <span class="op">*</span> np.sin(np.sqrt(<span class="bu">abs</span>(x[<span class="dv">0</span>] <span class="op">-</span> (x[<span class="dv">1</span>]  <span class="op">+</span> <span class="dv">47</span>)))))</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>bounds <span class="op">=</span> [(<span class="op">-</span><span class="dv">512</span>, <span class="dv">512</span>), (<span class="op">-</span><span class="dv">512</span>, <span class="dv">512</span>)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="0b21669d" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mpl_toolkits.mplot3d <span class="im">import</span> Axes3D</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.arange(<span class="op">-</span><span class="dv">512</span>, <span class="dv">513</span>)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.arange(<span class="op">-</span><span class="dv">512</span>, <span class="dv">513</span>)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>xgrid, ygrid <span class="op">=</span> np.meshgrid(x, y)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>xy <span class="op">=</span> np.stack([xgrid, ygrid])</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure()</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> fig.add_subplot(<span class="dv">111</span>, projection<span class="op">=</span><span class="st">'3d'</span>)</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>ax.view_init(<span class="dv">45</span>, <span class="op">-</span><span class="dv">45</span>)</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>ax.plot_surface(xgrid, ygrid, eggholder(xy), cmap<span class="op">=</span><span class="st">'terrain'</span>)</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'x'</span>)</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'y'</span>)</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>ax.set_zlabel(<span class="st">'eggholder(x, y)'</span>)</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="003_scipy_optimize_intro_files/figure-html/cell-12-output-1.png" width="427" height="398" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>We now use the global optimizers to obtain the minimum and the function value at the minimum. We’ll store the results in a dictionary so we can compare different optimization results later.</p>
<div id="04de3c42" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> optimize</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> <span class="bu">dict</span>()</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>results[<span class="st">'shgo'</span>] <span class="op">=</span> optimize.shgo(eggholder, bounds)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>results[<span class="st">'shgo'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code> message: Optimization terminated successfully.
 success: True
     fun: -935.3379515605789
    funl: [-9.353e+02]
       x: [ 4.395e+02  4.540e+02]
      xl: [[ 4.395e+02  4.540e+02]]
     nit: 1
    nfev: 45
   nlfev: 40
   nljev: 10
   nlhev: 0</code></pre>
</div>
</div>
<div id="2608fb0b" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>results[<span class="st">'DA'</span>] <span class="op">=</span> optimize.dual_annealing(eggholder, bounds)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>results[<span class="st">'DA'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code> message: ['Maximum number of iteration reached']
 success: True
  status: 0
     fun: -956.9182316132503
       x: [ 4.824e+02  4.329e+02]
     nit: 1000
    nfev: 4127
    njev: 42
    nhev: 0</code></pre>
</div>
</div>
<p>All optimizers return an <code>OptimizeResult</code>, which in addition to the solution contains information on the number of function evaluations, whether the optimization was successful, and more. For brevity, we won’t show the full output of the other optimizers:</p>
<div id="1d1e93ca" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>results[<span class="st">'DE'</span>] <span class="op">=</span> optimize.differential_evolution(eggholder, bounds)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>results[<span class="st">'DE'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>             message: Optimization terminated successfully.
             success: True
                 fun: -894.5789003904611
                   x: [-4.657e+02  3.857e+02]
                 nit: 25
                nfev: 798
          population: [[-4.654e+02  3.860e+02]
                       [-4.663e+02  3.836e+02]
                       ...
                       [-4.664e+02  3.823e+02]
                       [-4.665e+02  3.871e+02]]
 population_energies: [-8.946e+02 -8.928e+02 ... -8.903e+02 -8.940e+02]
                 jac: [ 0.000e+00 -2.274e-05]</code></pre>
</div>
</div>
<p><code>shgo</code> has a second method, which returns all local minima rather than only what it thinks is the global minimum:</p>
<div id="58ed3b8e" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>results[<span class="st">'shgo_sobol'</span>] <span class="op">=</span> optimize.shgo(eggholder, bounds, n<span class="op">=</span><span class="dv">200</span>, iters<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>                                      sampling_method<span class="op">=</span><span class="st">'sobol'</span>)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>results[<span class="st">'shgo_sobol'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code> message: Optimization terminated successfully.
 success: True
     fun: -959.640662720831
    funl: [-9.596e+02 -9.353e+02 ... -6.591e+01 -6.387e+01]
       x: [ 5.120e+02  4.042e+02]
      xl: [[ 5.120e+02  4.042e+02]
           [ 4.395e+02  4.540e+02]
           ...
           [ 3.165e+01 -8.523e+01]
           [ 5.865e+01 -5.441e+01]]
     nit: 5
    nfev: 3529
   nlfev: 2327
   nljev: 634
   nlhev: 0</code></pre>
</div>
</div>
<p>We’ll now plot all found minima on a heatmap of the function:</p>
<div id="23617ecb" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure()</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> fig.add_subplot(<span class="dv">111</span>)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>im <span class="op">=</span> ax.imshow(eggholder(xy), interpolation<span class="op">=</span><span class="st">'bilinear'</span>, origin<span class="op">=</span><span class="st">'lower'</span>,</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>               cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'x'</span>)</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'y'</span>)</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_point(res, marker<span class="op">=</span><span class="st">'o'</span>, color<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>    ax.plot(<span class="dv">512</span><span class="op">+</span>res.x[<span class="dv">0</span>], <span class="dv">512</span><span class="op">+</span>res.x[<span class="dv">1</span>], marker<span class="op">=</span>marker, color<span class="op">=</span>color, ms<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>plot_point(results[<span class="st">'DE'</span>], color<span class="op">=</span><span class="st">'c'</span>)  <span class="co"># differential_evolution - cyan</span></span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>plot_point(results[<span class="st">'DA'</span>], color<span class="op">=</span><span class="st">'w'</span>)  <span class="co"># dual_annealing.        - white</span></span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a><span class="co"># SHGO produces multiple minima, plot them all (with a smaller marker size)</span></span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>plot_point(results[<span class="st">'shgo'</span>], color<span class="op">=</span><span class="st">'r'</span>, marker<span class="op">=</span><span class="st">'+'</span>)</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>plot_point(results[<span class="st">'shgo_sobol'</span>], color<span class="op">=</span><span class="st">'r'</span>, marker<span class="op">=</span><span class="st">'x'</span>)</span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(results[<span class="st">'shgo_sobol'</span>].xl.shape[<span class="dv">0</span>]):</span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>    ax.plot(<span class="dv">512</span> <span class="op">+</span> results[<span class="st">'shgo_sobol'</span>].xl[i, <span class="dv">0</span>],</span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a>            <span class="dv">512</span> <span class="op">+</span> results[<span class="st">'shgo_sobol'</span>].xl[i, <span class="dv">1</span>],</span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a>            <span class="st">'ro'</span>, ms<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a>ax.set_xlim([<span class="op">-</span><span class="dv">4</span>, <span class="dv">514</span><span class="op">*</span><span class="dv">2</span>])</span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true" tabindex="-1"></a>ax.set_ylim([<span class="op">-</span><span class="dv">4</span>, <span class="dv">514</span><span class="op">*</span><span class="dv">2</span>])</span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="003_scipy_optimize_intro_files/figure-html/cell-17-output-1.png" width="457" height="429" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="dual-annealing-optimization" class="level3" data-number="2.3.2">
<h3 data-number="2.3.2" class="anchored" data-anchor-id="dual-annealing-optimization"><span class="header-section-number">2.3.2</span> Dual Annealing Optimization</h3>
<p>This function implements the Dual-Annealing optimization, which is a variant of the famous simulated annealing optimization.</p>
<p>Simulated Annealing is a <strong>probabilistic</strong> optimization algorithm inspired by the annealing process in metallurgy. The algorithm is designed to find a good or optimal <strong>global</strong> solution to a problem by exploring the solution space in a controlled and adaptive manner.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Annealing in Metallurgy
</div>
</div>
<div class="callout-body-container callout-body">
<p>Simulated Annealing draws inspiration from the physical process of annealing in metallurgy. Just as metals are gradually cooled to achieve a more stable state, Simulated Annealing uses a similar approach to explore solution spaces in the digital world.</p>
</div>
</div>
<p><strong>Heating Phase</strong>: In metallurgy, a metal is initially heated to a high temperature. At this elevated temperature, the atoms or molecules in the material become more energetic and chaotic, allowing the material to overcome energy barriers and defects.</p>
<p><strong>Analogy Simulated Annealing (Exploration Phase):</strong> In Simulated Annealing, the algorithm starts with a high “temperature,” which encourages exploration of the solution space. At this stage, the algorithm is more likely to accept solutions that are worse than the current one, allowing it to escape local optima and explore a broader region of the solution space.</p>
<p><strong>Cooling Phase:</strong> The material is then gradually cooled at a controlled rate. As the temperature decreases, the atoms or molecules start to settle into more ordered and stable arrangements. The slow cooling rate is crucial to avoid the formation of defects and to ensure the material reaches a well-organized state.</p>
<p><strong>Analogy Simulated Annealing (Exploitation Phase):</strong> As the algorithm progresses, the temperature is gradually reduced over time according to a cooling schedule. This reduction simulates the cooling process in metallurgy. With lower temperatures, the algorithm becomes more selective and tends to accept only better solutions, focusing on refining and exploiting the promising regions discovered during the exploration phase.</p>
<section id="key-concepts" class="level4" data-number="2.3.2.1">
<h4 data-number="2.3.2.1" class="anchored" data-anchor-id="key-concepts"><span class="header-section-number">2.3.2.1</span> Key Concepts</h4>
<p><strong>Temperature:</strong> The temperature is a parameter that controls the likelihood of accepting worse solutions. We start with a high temperature, allowing the algorithm to explore the solution space braodly. The temperature decreases with the iterations of the algorithm.</p>
<p><strong>Cooling Schedule:</strong> The temperature parameter is reduced according to this schedule. The analogy to the annealing of metals: a slower cooling rate allows the material to reach a more stable state.</p>
<p><strong>Neighborhood Exploration:</strong> At each iteration, the algorithm explores the neighborhood of the current solution. The neighborhood is defined by small perturbations or changes to the current solution.</p>
<p><strong>Acceptance Probability:</strong> The algorithm evaluates the objective function for the new solution in the neighborhood. If the new solution is better, it is accepted. If the new solution is worse, it may still be accepted with a certain probability. This probability is determined by both the difference in objective function values and the current temperature.</p>
<p><strong>For minimization:</strong> If: <span class="math display">\[
f(x_{t}) &gt; f(x_{t+1})
\]</span> Then: <span class="math display">\[
P(accept\_new\_point) = 1
\]</span></p>
<p>If: <span class="math display">\[
f(x_{t}) &lt; f(x_{t+1})
\]</span> Then: <span class="math display">\[
P(accept\_new\_point) = e^{-(\frac{f(x_{t+1}) - f(x_{t})}{Tt})}
\]</span></p>
<p><strong>Termination Criterion:</strong> The algorithm continues iterations until a termination condition is met. This could be a fixed number of iterations, reaching a specific temperature threshold, or achieving a satisfactory solution.</p>
</section>
<section id="steps" class="level4" data-number="2.3.2.2">
<h4 data-number="2.3.2.2" class="anchored" data-anchor-id="steps"><span class="header-section-number">2.3.2.2</span> Steps</h4>
<p><strong>1. Initialization:</strong> Set an initial temperature (<span class="math inline">\(T_{0}\)</span>) and an initial solution (<span class="math inline">\(f(x_{0})\)</span>). The temperature is typically set high initially to encourage exploration.</p>
<p><strong>2. Generate a Neighbor:</strong> Perturb the current solution to generate a neighboring solution. The perturbation can be random or follow a specific strategy.</p>
<p><strong>3. Evaluate the Neighbor:</strong> Evaluate the objective function for the new solution in the neighborhood.</p>
<p><strong>4. Accept or Reject the Neighbor:</strong> + If the new solution is better (lower cost for minimization problems or higher for maximization problems), accept it as the new current solution. + If the new solution is worse, accept it with a probability determined by an acceptance probability function as mentioned above. The probability is influenced by the difference in objective function values and the current temperature.</p>
<p><strong>5. Cooling:</strong> Reduce the temperature according to a cooling schedule. The cooling schedule defines how fast the temperature decreases over time. Common cooling schedules include exponential or linear decay.</p>
<p><strong>6. Termination Criterion:</strong> Repeat the iterations (2-5) until a termination condition is met. This could be a fixed number of iterations, reaching a specific temperature threshold, or achieving a satisfactory solution.</p>
</section>
<section id="scipy-implementation-of-the-dual-annealing-algorithm" class="level4 {exm-dual-annealing}" data-number="2.3.2.3">
<h4 data-number="2.3.2.3" class="anchored" data-anchor-id="scipy-implementation-of-the-dual-annealing-algorithm"><span class="header-section-number">2.3.2.3</span> Scipy Implementation of the Dual Annealing Algorithm</h4>
<p>In Scipy, we utilize the Dual Annealing optimizer, an extension of the simulated annealing algorithm that is versatile for both discrete and continuous problems.</p>
<div id="73906368" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.optimize <span class="im">import</span> dual_annealing</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rastrigin_function(x):</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">20</span> <span class="op">+</span> x[<span class="dv">0</span>]<span class="op">**</span><span class="dv">2</span> <span class="op">-</span> <span class="dv">10</span> <span class="op">*</span> np.cos(<span class="dv">2</span> <span class="op">*</span> np.pi <span class="op">*</span> x[<span class="dv">0</span>]) <span class="op">+</span> x[<span class="dv">1</span>]<span class="op">**</span><span class="dv">2</span> <span class="op">-</span> <span class="dv">10</span> <span class="op">*</span> np.cos(<span class="dv">2</span> <span class="op">*</span> np.pi <span class="op">*</span> x[<span class="dv">1</span>])</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the Rastrigin function for visualization</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rastrigin_visualization(x, y):</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">20</span> <span class="op">+</span> x<span class="op">**</span><span class="dv">2</span> <span class="op">-</span> <span class="dv">10</span> <span class="op">*</span> np.cos(<span class="dv">2</span> <span class="op">*</span> np.pi <span class="op">*</span> x) <span class="op">+</span> y<span class="op">**</span><span class="dv">2</span> <span class="op">-</span> <span class="dv">10</span> <span class="op">*</span> np.cos(<span class="dv">2</span> <span class="op">*</span> np.pi <span class="op">*</span> y)</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a meshgrid for visualization</span></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>x_vals <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">100</span>)</span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>y_vals <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">100</span>)</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>x_mesh, y_mesh <span class="op">=</span> np.meshgrid(x_vals, y_vals)</span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>z_mesh <span class="op">=</span> rastrigin_visualization(x_mesh, y_mesh)</span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the Rastrigin function</span></span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a>contour <span class="op">=</span> plt.contour(x_mesh, y_mesh, z_mesh, levels<span class="op">=</span><span class="dv">50</span>, cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a>plt.colorbar(contour, label<span class="op">=</span><span class="st">'Rastrigin Function Value'</span>)</span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Visualization of the 2D Rastrigin Function'</span>)</span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Optimize the Rastrigin function using dual annealing</span></span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> dual_annealing(func <span class="op">=</span> rastrigin_function,</span>
<span id="cb29-26"><a href="#cb29-26" aria-hidden="true" tabindex="-1"></a>                        x0<span class="op">=</span>[<span class="fl">5.0</span>,<span class="fl">3.0</span>],                       <span class="co">#Initial Guess</span></span>
<span id="cb29-27"><a href="#cb29-27" aria-hidden="true" tabindex="-1"></a>                        bounds<span class="op">=</span> [(<span class="op">-</span><span class="dv">10</span>, <span class="dv">10</span>), (<span class="op">-</span><span class="dv">10</span>, <span class="dv">10</span>)],</span>
<span id="cb29-28"><a href="#cb29-28" aria-hidden="true" tabindex="-1"></a>                        initial_temp <span class="op">=</span> <span class="dv">5230</span>,                <span class="co">#Intial Value for temperature</span></span>
<span id="cb29-29"><a href="#cb29-29" aria-hidden="true" tabindex="-1"></a>                        restart_temp_ratio <span class="op">=</span> <span class="fl">2e-05</span>,         <span class="co">#Temperature schedule</span></span>
<span id="cb29-30"><a href="#cb29-30" aria-hidden="true" tabindex="-1"></a>                        seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb29-31"><a href="#cb29-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-32"><a href="#cb29-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the optimized point</span></span>
<span id="cb29-33"><a href="#cb29-33" aria-hidden="true" tabindex="-1"></a>optimal_x, optimal_y <span class="op">=</span> result.x</span>
<span id="cb29-34"><a href="#cb29-34" aria-hidden="true" tabindex="-1"></a>plt.plot(optimal_x, optimal_y, <span class="st">'ro'</span>, label<span class="op">=</span><span class="st">'Optimal Point'</span>)</span>
<span id="cb29-35"><a href="#cb29-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-36"><a href="#cb29-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Set labels and legend</span></span>
<span id="cb29-37"><a href="#cb29-37" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'X'</span>)</span>
<span id="cb29-38"><a href="#cb29-38" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Y'</span>)</span>
<span id="cb29-39"><a href="#cb29-39" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb29-40"><a href="#cb29-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-41"><a href="#cb29-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the plot</span></span>
<span id="cb29-42"><a href="#cb29-42" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb29-43"><a href="#cb29-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-44"><a href="#cb29-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the optimization result</span></span>
<span id="cb29-45"><a href="#cb29-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Optimal parameters:"</span>, result.x)</span>
<span id="cb29-46"><a href="#cb29-46" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Minimum value of the Rastrigin function:"</span>, result.fun)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="003_scipy_optimize_intro_files/figure-html/cell-18-output-1.png" width="803" height="671" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Optimal parameters: [-4.60133247e-09 -4.31928660e-09]
Minimum value of the Rastrigin function: 7.105427357601002e-15</code></pre>
</div>
</div>
</section>
</section>
<section id="differential-evolution" class="level3" data-number="2.3.3">
<h3 data-number="2.3.3" class="anchored" data-anchor-id="differential-evolution"><span class="header-section-number">2.3.3</span> Differential Evolution</h3>
<p>Differential Evolution is an algorithm used for finding the global minimum of multivariate functions. It is stochastic in nature (does not use gradient methods), and can search large areas of candidate space, but often requires larger numbers of function evaluations than conventional gradient based techniques.</p>
<p>Differential Evolution (DE) is a versatile and global optimization algorithm inspired by natural selection and evolutionary processes. Introduced by Storn and Price in 1997, DE mimics the survival-of-the-fittest principle by evolving a population of candidate solutions through iterative mutation, crossover, and selection operations. This nature-inspired approach enables DE to efficiently explore complex and non-linear solution spaces, making it a widely adopted optimization technique in diverse fields such as engineering, finance, and machine learning.</p>
</section>
<section id="procedure-1" class="level3" data-number="2.3.4">
<h3 data-number="2.3.4" class="anchored" data-anchor-id="procedure-1"><span class="header-section-number">2.3.4</span> Procedure</h3>
<p>The procedure boils down to the following steps:</p>
<ol type="1">
<li><strong>Initialization:</strong>
<ul>
<li>Create a population of candidate solutions randomly within the specified search space.</li>
</ul></li>
<li><strong>Mutation:</strong>
<ul>
<li>For each individual in the population, select three distinct individuals (vectors) randomly.</li>
<li>Generate a mutant vector <code>V</code> by combining these three vectors with a scaling factor.</li>
</ul></li>
<li><strong>Crossover:</strong>
<ul>
<li>Perform the crossover operation between the target vector <code>U</code> and the mutant vector <code>V</code>. Information from both vectors is used to create a trial vector <code>U´</code></li>
</ul></li>
</ol>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Cross-Over Strategies in DE
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>There are several crossover strategies in the literature. Two examples are:</li>
</ul>
<p><strong>Binominal Crossover:</strong></p>
<p>In this strategy, each component of the trial vector is selected from the mutant vector with a probability equal to the crossover rate (<span class="math inline">\(CR\)</span>). This means that each element of the trial vector has an independent probability of being replaced by the corresponding element of the mutant vector.</p>
<p><span class="math display">\[U'_i =
      \begin{cases}
      V_i, &amp; \text{if a random number} \ \sim U(0, 1) \leq CR \ \text{(Crossover Rate)} \\
      U_i, &amp; \text{otherwise}
      \end{cases}
\]</span></p>
<p><strong>Exponential Crossover:</strong></p>
<p>In exponential crossover, the trial vector is constructed by selecting a random starting point and copying elements from the mutant vector with a certain probability. The probability decreases exponentially with the distance from the starting point. This strategy introduces a correlation between neighboring elements in the trial vector.</p>
</div>
</div>
<ol start="4" type="1">
<li><strong>Selection:</strong>
<ul>
<li>Evaluate the fitness of the trial vector obtained from the crossover.</li>
<li>Replace the target vector with the trial vector if its fitness is better.</li>
</ul></li>
<li><strong>Termination:</strong>
<ul>
<li>Repeat the mutation, crossover, and selection steps for a predefined number of generations or until convergence criteria are met.</li>
</ul></li>
<li><strong>Result:</strong>
<ul>
<li>The algorithm returns the best-found solution after the specified number of iterations.</li>
</ul></li>
</ol>
<p>The key parameters in DE include the population size, crossover probability, and the scaling factor. Tweak these parameters based on the characteristics of the optimization problem for optimal performance.</p>
<div id="c09a0a14" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.optimize <span class="im">import</span> minimize</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the Rastrigin function</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rastrigin(x):</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>    A <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> A <span class="op">*</span> <span class="bu">len</span>(x) <span class="op">+</span> <span class="bu">sum</span>([(xi<span class="op">**</span><span class="dv">2</span> <span class="op">-</span> A <span class="op">*</span> np.cos(<span class="dv">2</span> <span class="op">*</span> np.pi <span class="op">*</span> xi)) <span class="cf">for</span> xi <span class="kw">in</span> x])</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a grid for visualization</span></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>x_vals <span class="op">=</span> np.linspace(<span class="op">-</span><span class="fl">5.12</span>, <span class="fl">5.12</span>, <span class="dv">100</span>)</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>y_vals <span class="op">=</span> np.linspace(<span class="op">-</span><span class="fl">5.12</span>, <span class="fl">5.12</span>, <span class="dv">100</span>)</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>X, Y <span class="op">=</span> np.meshgrid(x_vals, y_vals)</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>Z <span class="op">=</span> rastrigin(np.vstack([X.ravel(), Y.ravel()]))</span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Reshape Z to match the shape of X and Y</span></span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>Z <span class="op">=</span> Z.reshape(X.shape)</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the Rastrigin function</span></span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>plt.contour(X, Y, Z, levels<span class="op">=</span><span class="dv">50</span>, cmap<span class="op">=</span><span class="st">'viridis'</span>, label<span class="op">=</span><span class="st">'Rastrigin Function'</span>)</span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Initial guess (starting point for the optimization)</span></span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a>initial_guess <span class="op">=</span> (<span class="dv">4</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">2</span>)</span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the bounds for each variable in the Rastrigin function</span></span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a>bounds <span class="op">=</span> [(<span class="op">-</span><span class="fl">5.12</span>, <span class="fl">5.12</span>)] <span class="op">*</span> <span class="dv">4</span>  <span class="co"># 4D problem, each variable has bounds (-5.12, 5.12)</span></span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the minimize function</span></span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> minimize(rastrigin, initial_guess, bounds<span class="op">=</span>bounds, method<span class="op">=</span><span class="st">'L-BFGS-B'</span>)</span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the optimal solution</span></span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a>optimal_solution <span class="op">=</span> result.x</span>
<span id="cb31-33"><a href="#cb31-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-34"><a href="#cb31-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the optimal solution</span></span>
<span id="cb31-35"><a href="#cb31-35" aria-hidden="true" tabindex="-1"></a>plt.scatter(optimal_solution[<span class="dv">0</span>], optimal_solution[<span class="dv">1</span>], color<span class="op">=</span><span class="st">'red'</span>, marker<span class="op">=</span><span class="st">'x'</span>, label<span class="op">=</span><span class="st">'Optimal Solution'</span>)</span>
<span id="cb31-36"><a href="#cb31-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-37"><a href="#cb31-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Add labels and legend</span></span>
<span id="cb31-38"><a href="#cb31-38" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Optimization of Rastrigin Function with Minimize'</span>)</span>
<span id="cb31-39"><a href="#cb31-39" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Variable 1'</span>)</span>
<span id="cb31-40"><a href="#cb31-40" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Variable 2'</span>)</span>
<span id="cb31-41"><a href="#cb31-41" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb31-42"><a href="#cb31-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-43"><a href="#cb31-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the plot</span></span>
<span id="cb31-44"><a href="#cb31-44" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb31-45"><a href="#cb31-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-46"><a href="#cb31-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the optimization result</span></span>
<span id="cb31-47"><a href="#cb31-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Optimal Solution:"</span>, optimal_solution)</span>
<span id="cb31-48"><a href="#cb31-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Optimal Objective Value:"</span>, result.fun)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="003_scipy_optimize_intro_files/figure-html/cell-19-output-1.png" width="587" height="449" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Optimal Solution: [-2.52869119e-08 -2.07795060e-08 -2.52869119e-08 -1.62721002e-08]
Optimal Objective Value: 3.907985046680551e-13</code></pre>
</div>
</div>
</section>
<section id="other-global-optimization-algorithms" class="level3" data-number="2.3.5">
<h3 data-number="2.3.5" class="anchored" data-anchor-id="other-global-optimization-algorithms"><span class="header-section-number">2.3.5</span> Other global optimization algorithms</h3>
</section>
<section id="direct" class="level3" data-number="2.3.6">
<h3 data-number="2.3.6" class="anchored" data-anchor-id="direct"><span class="header-section-number">2.3.6</span> DIRECT</h3>
<p>DIviding RECTangles (DIRECT) is a deterministic global optimization algorithm capable of minimizing a black box function with its variables subject to lower and upper bound constraints by sampling potential solutions in the search space</p>
</section>
<section id="shgo" class="level3" data-number="2.3.7">
<h3 data-number="2.3.7" class="anchored" data-anchor-id="shgo"><span class="header-section-number">2.3.7</span> SHGO</h3>
<p>SHGO stands for “simplicial homology global optimization”. It is considered appropriate for solving general purpose NLP and blackbox optimization problems to global optimality (low-dimensional problems).</p>
</section>
<section id="basin-hopping" class="level3" data-number="2.3.8">
<h3 data-number="2.3.8" class="anchored" data-anchor-id="basin-hopping"><span class="header-section-number">2.3.8</span> Basin-hopping</h3>
<p>Basin-hopping is a two-phase method that combines a global stepping algorithm with local minimization at each step. Designed to mimic the natural process of energy minimization of clusters of atoms, it works well for similar problems with “funnel-like, but rugged” energy landscapes</p>
</section>
</section>
<section id="project-one-mass-oscillator-optimization" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="project-one-mass-oscillator-optimization"><span class="header-section-number">2.4</span> Project: One-Mass Oscillator Optimization</h2>
<div id="c96dd647" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.optimize <span class="im">import</span> minimize</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="introduction" class="level3" data-number="2.4.1">
<h3 data-number="2.4.1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">2.4.1</span> Introduction</h3>
<p>In this project, you will apply various optimization algorithms to fit a one-mass oscillator model to real-world data. The objective is to minimize the sum of the squared residuals between the model predictions and the observed amplitudes of a one-mass oscillator system across different frequencies.</p>
</section>
<section id="one-mass-oscillator-model" class="level3" data-number="2.4.2">
<h3 data-number="2.4.2" class="anchored" data-anchor-id="one-mass-oscillator-model"><span class="header-section-number">2.4.2</span> One-Mass Oscillator Model</h3>
<p>The one-mass oscillator is characterized by the following equation, representing the amplitudes of the system:</p>
<p><span class="math display">\[
V(\omega) = \frac{F}{\sqrt{(1 - \nu^2)^2 + 4D^2\nu^2}}
\]</span></p>
<p>Here, <span class="math inline">\(\omega\)</span> represents the angular frequency of the system, <span class="math inline">\(\nu\)</span> is the ratio of the excitation frequency to the natural frequency, i.e., <span class="math display">\[
\nu = \frac{\omega_{\text{err}}}{\omega_{\text{eig}}},
\]</span> <span class="math inline">\(D\)</span> is the damping ratio, and <span class="math inline">\(F\)</span> is the force applied to the system.</p>
<p>The goal of the project is to determine the optimal values for the parameters <span class="math inline">\(\omega_{\text{eig}}\)</span>, <span class="math inline">\(D\)</span>, and <span class="math inline">\(F\)</span> that result in the best fit of the one-mass oscillator model to the observed amplitudes.</p>
</section>
<section id="the-real-world-data" class="level3" data-number="2.4.3">
<h3 data-number="2.4.3" class="anchored" data-anchor-id="the-real-world-data"><span class="header-section-number">2.4.3</span> The Real-World Data</h3>
<p>There are two different measurements. <code>J</code> represents the measured frequencies, and <code>N</code> represents the measured amplitudes.</p>
<div id="0c002541" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>df1 <span class="op">=</span> pd.read_pickle(<span class="st">"./data/Hcf.d/df1.pkl"</span>)</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>df2 <span class="op">=</span> pd.read_pickle(<span class="st">"./data/Hcf.d/df2.pkl"</span>)</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>df1.describe()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">J</th>
<th data-quarto-table-cell-role="th">N</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">count</td>
<td>33.000000</td>
<td>33.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">mean</td>
<td>8148.750252</td>
<td>10.430887</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">std</td>
<td>6.870023</td>
<td>2.846469</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">min</td>
<td>8137.649210</td>
<td>4.698761</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">25%</td>
<td>8143.799766</td>
<td>8.319253</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">50%</td>
<td>8146.942295</td>
<td>10.152119</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">75%</td>
<td>8153.934051</td>
<td>13.407260</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">max</td>
<td>8162.504002</td>
<td>14.382749</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="01a97bff" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>df1.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">J</th>
<th data-quarto-table-cell-role="th">N</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">14999</td>
<td>8162.504002</td>
<td>5.527511</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">15011</td>
<td>8156.384831</td>
<td>7.359789</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">15016</td>
<td>8159.199238</td>
<td>6.532958</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">15020</td>
<td>8159.200889</td>
<td>5.895933</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">15025</td>
<td>8153.934051</td>
<td>9.326749</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="7b6a7ca0" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the data, i.e., the measured amplitudes as a function of the measured frequencies</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>plt.scatter(df1[<span class="st">"J"</span>], df1[<span class="st">"N"</span>], color<span class="op">=</span><span class="st">"black"</span>, label<span class="op">=</span><span class="st">"Spektralpunkte"</span>, zorder<span class="op">=</span><span class="dv">5</span>, s<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Frequency [Hz]"</span>)</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Amplitude"</span>)</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="003_scipy_optimize_intro_files/figure-html/cell-23-output-1.png" width="585" height="429" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Note: Low amplitudes distort the fit and are negligible therefore we define a lower threshold for <code>N</code>.</p>
<div id="0fb2c4c3" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>threshold <span class="op">=</span> <span class="fl">0.4</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>df1.sort_values(<span class="st">"N"</span>)</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>max_N <span class="op">=</span> <span class="bu">max</span>(df1[<span class="st">"N"</span>])</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>df1 <span class="op">=</span> df1[df1[<span class="st">"N"</span>]<span class="op">&gt;=</span>threshold<span class="op">*</span>max_N]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We extract the frequency value for maximum value of the amplitude. This serves as the initial value for one decision variable.</p>
<div id="80fa1d25" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>df_max<span class="op">=</span>df1[df1[<span class="st">"N"</span>]<span class="op">==</span><span class="bu">max</span>(df1[<span class="st">"N"</span>])]</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>initial_Oeig <span class="op">=</span> df_max[<span class="st">"J"</span>].values[<span class="dv">0</span>]</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>max_N <span class="op">=</span> df_max[<span class="st">"N"</span>].values[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We also have to define the other two initial guesses for the damping ratio and the force, e.g.,</p>
<div id="795e08d5" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>initial_D <span class="op">=</span> <span class="fl">0.006</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>initial_F <span class="op">=</span> <span class="fl">0.120</span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>initial_values <span class="op">=</span> [initial_Oeig, initial_D, initial_F]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Additionally, we define the bounds for the decision variables:</p>
<div id="9287bdf5" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>min_Oerr <span class="op">=</span> <span class="bu">min</span>(df1[<span class="st">"J"</span>])</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>max_Oerr <span class="op">=</span> <span class="bu">max</span>(df1[<span class="st">"J"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="a7888abd" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>bounds <span class="op">=</span> [(min_Oerr, max_Oerr), (<span class="dv">0</span>, <span class="fl">0.03</span>), (<span class="dv">0</span>, <span class="dv">1</span>)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="objective-function" class="level3" data-number="2.4.4">
<h3 data-number="2.4.4" class="anchored" data-anchor-id="objective-function"><span class="header-section-number">2.4.4</span> Objective Function</h3>
<p>Then we define the objective function:</p>
<div id="ad9c5f38" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> one_mass_oscillator(params, Oerr) <span class="op">-&gt;</span> np.ndarray:</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># returns amplitudes of the system</span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Defines the model of a one mass oscilator </span></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>    Oeig, D, F <span class="op">=</span> params</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>    nue <span class="op">=</span> Oerr <span class="op">/</span> Oeig</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>    V <span class="op">=</span> F <span class="op">/</span> (np.sqrt((<span class="dv">1</span> <span class="op">-</span> nue<span class="op">**</span><span class="dv">2</span>) <span class="op">**</span> <span class="dv">2</span> <span class="op">+</span> (<span class="dv">4</span> <span class="op">*</span> D<span class="op">**</span><span class="dv">2</span> <span class="op">*</span> nue<span class="op">**</span><span class="dv">2</span>)))</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> V</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="78ccb0b7" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> objective_function(params, Oerr, amplitudes) <span class="op">-&gt;</span> np.ndarray:</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># objective function to compare calculated and real amplitudes</span></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.<span class="bu">sum</span>((amplitudes <span class="op">-</span> one_mass_oscillator(params, Oerr)) <span class="op">**</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We define the options for the optimzer and start the optimization process:</p>
<div id="701ac5cf" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>options <span class="op">=</span> {</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"maxfun"</span>: <span class="dv">100000</span>,</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"ftol"</span>: <span class="fl">1e-9</span>,</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"xtol"</span>: <span class="fl">1e-9</span>,</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"stepmx"</span>: <span class="dv">10</span>,</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"eta"</span>: <span class="fl">0.25</span>,</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"gtol"</span>: <span class="fl">1e-5</span>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="a1a7c2e5" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>J <span class="op">=</span> np.array(df1[<span class="st">"J"</span>]) <span class="co"># measured frequency</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> np.array(df1[<span class="st">"N"</span>]) <span class="co"># measured amplitude</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="04d894a2" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> minimize(</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>    objective_function,</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>    initial_values,</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>    args<span class="op">=</span>(J, N),</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>    method<span class="op">=</span><span class="st">'Nelder-Mead'</span>,</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>    bounds<span class="op">=</span>bounds,</span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>    options<span class="op">=</span>options)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="results" class="level3" data-number="2.4.5">
<h3 data-number="2.4.5" class="anchored" data-anchor-id="results"><span class="header-section-number">2.4.5</span> Results</h3>
<p>We can observe the results:</p>
<div id="2775f7f2" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># map optimized values to variables</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>resonant_frequency <span class="op">=</span> result.x[<span class="dv">0</span>]</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>D <span class="op">=</span> result.x[<span class="dv">1</span>]</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>F <span class="op">=</span> result.x[<span class="dv">2</span>]</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a><span class="co"># predict the resonant amplitude with the fitted one mass oscillator.</span></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>X_pred <span class="op">=</span> np.linspace(min_Oerr, max_Oerr, <span class="dv">1000</span>)</span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>ypred_one_mass_oscillator <span class="op">=</span> one_mass_oscillator(result.x, X_pred)</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a>resonant_amplitude <span class="op">=</span> <span class="bu">max</span>(ypred_one_mass_oscillator)</span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"result: </span><span class="sc">{</span>result<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>result:        message: Optimization terminated successfully.
       success: True
        status: 0
           fun: 53.54144061205875
             x: [ 8.148e+03  7.435e-04  2.153e-02]
           nit: 93
          nfev: 169
 final_simplex: (array([[ 8.148e+03,  7.435e-04,  2.153e-02],
                       [ 8.148e+03,  7.435e-04,  2.153e-02],
                       [ 8.148e+03,  7.435e-04,  2.153e-02],
                       [ 8.148e+03,  7.435e-04,  2.153e-02]]), array([ 5.354e+01,  5.354e+01,  5.354e+01,  5.354e+01]))</code></pre>
</div>
</div>
<p>Finally, we can plot the optimized fit and the real values:</p>
<div id="ada2f159" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>plt.scatter(</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>    df1[<span class="st">"J"</span>],</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>    df1[<span class="st">"N"</span>],</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>    color<span class="op">=</span><span class="st">"black"</span>,</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>    label<span class="op">=</span><span class="st">"Spektralpunkte filtered"</span>,</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>    zorder<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a>    s<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a><span class="co"># color the max amplitude point red</span></span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a>plt.scatter(</span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a>    initial_Oeig,</span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a>    max_N,</span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a>    color<span class="op">=</span><span class="st">"red"</span>,</span>
<span id="cb49-14"><a href="#cb49-14" aria-hidden="true" tabindex="-1"></a>    label<span class="op">=</span><span class="st">"Max Amplitude"</span>,</span>
<span id="cb49-15"><a href="#cb49-15" aria-hidden="true" tabindex="-1"></a>    zorder<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb49-16"><a href="#cb49-16" aria-hidden="true" tabindex="-1"></a>    s<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb49-17"><a href="#cb49-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb49-18"><a href="#cb49-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-19"><a href="#cb49-19" aria-hidden="true" tabindex="-1"></a>plt.plot(</span>
<span id="cb49-20"><a href="#cb49-20" aria-hidden="true" tabindex="-1"></a>        X_pred,</span>
<span id="cb49-21"><a href="#cb49-21" aria-hidden="true" tabindex="-1"></a>        ypred_one_mass_oscillator,</span>
<span id="cb49-22"><a href="#cb49-22" aria-hidden="true" tabindex="-1"></a>        label<span class="op">=</span><span class="st">"Alpha"</span>,</span>
<span id="cb49-23"><a href="#cb49-23" aria-hidden="true" tabindex="-1"></a>        color<span class="op">=</span><span class="st">"blue"</span>,</span>
<span id="cb49-24"><a href="#cb49-24" aria-hidden="true" tabindex="-1"></a>        linewidth<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb49-25"><a href="#cb49-25" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb49-26"><a href="#cb49-26" aria-hidden="true" tabindex="-1"></a>plt.scatter(</span>
<span id="cb49-27"><a href="#cb49-27" aria-hidden="true" tabindex="-1"></a>    resonant_frequency,</span>
<span id="cb49-28"><a href="#cb49-28" aria-hidden="true" tabindex="-1"></a>    resonant_amplitude,</span>
<span id="cb49-29"><a href="#cb49-29" aria-hidden="true" tabindex="-1"></a>    color<span class="op">=</span><span class="st">"blue"</span>,</span>
<span id="cb49-30"><a href="#cb49-30" aria-hidden="true" tabindex="-1"></a>    label<span class="op">=</span><span class="st">"Max Curve Fit"</span>,</span>
<span id="cb49-31"><a href="#cb49-31" aria-hidden="true" tabindex="-1"></a>    zorder<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb49-32"><a href="#cb49-32" aria-hidden="true" tabindex="-1"></a>    s<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb49-33"><a href="#cb49-33" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="003_scipy_optimize_intro_files/figure-html/cell-35-output-1.png" width="586" height="411" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="exercises" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="exercises"><span class="header-section-number">2.5</span> Exercises</h2>
<div id="exr-nelder-mead" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 2.1 (Nelder-Mead)</strong></span> &nbsp;</p>
<ol type="1">
<li>What are the steps of the Nelder-Mead algorithm?</li>
<li>What are the advantages and disadvantages of the Nelder-Mead algorithm?</li>
</ol>
</div>
<div id="exr-powell" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 2.2 (Powell’s Method)</strong></span> &nbsp;</p>
<ol type="1">
<li>What are the steps of Powell’s method?</li>
<li>What are the advantages and disadvantages of Powell’s method?</li>
<li>What are similarities between the Nelder-Mead and Powell’s methods?</li>
</ol>
</div>
<div id="exr-cg" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 2.3 (Gradient Descent)</strong></span> &nbsp;</p>
<ol type="1">
<li>What are the steps of the gradient descent algorithm?</li>
<li>What is the learning rate in the gradient descent algorithm?</li>
</ol>
</div>
<div id="exr-newton" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 2.4 (Newton Method)</strong></span> &nbsp;</p>
<ol type="1">
<li>What is the difference between the gradient descent and Newton method?</li>
<li>Which of the two methods converges faster?</li>
</ol>
</div>
<div id="exr-bfgs" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 2.5 (BFGS)</strong></span> &nbsp;</p>
<ul>
<li>In which situations is it possible to use algorithms like BFGS, but not the classical Newton method?</li>
<li>Would you choose Gradient Descent or BFGS for a large-scale optimization problem?</li>
</ul>
</div>
<div id="exr-simulated-annealing" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 2.6 (Dual Annealing)</strong></span> &nbsp;</p>
<ol type="1">
<li>When should you use Simulated Annealing or Dual Annealing over a local optimization algorithm?</li>
<li>Describe the Temperature parameter in Simulated Annealing.</li>
</ol>
</div>
<div id="exr-global-optimization" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 2.7 (Differential Evolution)</strong></span> &nbsp;</p>
<ol type="1">
<li>What are the key steps in the Differential Evolution algorithm?</li>
<li>Explain the crossover operation in Differential Evolution.</li>
</ol>
</div>
</section>
<section id="jupyter-notebook" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="jupyter-notebook"><span class="header-section-number">2.6</span> Jupyter Notebook</h2>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>The Jupyter-Notebook of this lecture is available on GitHub in the <a href="https://github.com/sequential-parameter-optimization/Hyperparameter-Tuning-Cookbook/blob/main/003_scipy_optimize_intro.ipynb">Hyperparameter-Tuning-Cookbook Repository</a></li>
</ul>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./002_awwe.html" class="pagination-link" aria-label="Aircraft Wing Weight Example">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Aircraft Wing Weight Example</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./001_surrogate.html" class="pagination-link" aria-label="Simulation and Surrogate Modeling">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Simulation and Surrogate Modeling</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Copyright 2025, T. Bartz-Beielstein</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://sequential-parameter-optimization.github.io/Hyperparameter-Tuning-Cookbook/">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://x.com/bartzbeielstein">
      <i class="bi bi-twitter" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>