<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Hyperparameter Tuning Cookbook - 3&nbsp; Introduction to scipy.optimize</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./004_spot_sklearn_optimization.html" rel="next">
<link href="./002_awwe.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="twitter:title" content="Hyperparameter Tuning Cookbook - 3&nbsp; Introduction to scipy.optimize">
<meta name="twitter:description" content="">
<meta name="twitter:image" content="003_scipy_optimize_intro_files/figure-html/cell-8-output-1.png">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./001_optimization_surrogate.html">Optimization</a></li><li class="breadcrumb-item"><a href="./003_scipy_optimize_intro.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Introduction to `scipy.optimize`</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Hyperparameter Tuning Cookbook</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/sequential-parameter-optimization/spotPython" rel="" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="./Hyperparameter-Tuning-Cookbook.pdf" rel="" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
              <i class="bi bi-bi-linkedin pe-1"></i>
            LinkedIn
            </a>
          </li>
      </ul>
    </div>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Optimization</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./001_optimization_surrogate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction: Optimization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./002_awwe.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Aircraft Wing Weight Example</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./003_scipy_optimize_intro.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Introduction to <code>scipy.optimize</code></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./004_spot_sklearn_optimization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Sequential Parameter Optimization: Using <code>scipy</code> Optimizers</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Numerical Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./005_num_rsm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Introduction: Numerical Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./006_num_gp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Kriging (Gaussian Process Regression)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./007_num_spot_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Introduction to <code>spotPython</code></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./008_num_spot_multidim.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Multi-dimensional Functions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./009_num_spot_anisotropic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Isotropic and Anisotropic Kriging</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./010_num_spot_sklearn_surrogate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Using <code>sklearn</code> Surrogates in <code>spotPython</code></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./011_num_spot_sklearn_gaussian.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Sequential Parameter Optimization: Gaussian Process Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./012_num_spot_ei.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Expected Improvement</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./013_num_spot_noisy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Handling Noise</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./014_num_spot_ocba.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Optimal Computational Budget Allocation in <code>Spot</code></span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_01_intro_to_notebooks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Introduction to Jupyter Notebook</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_02_git_intro_en.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Git Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_03_python_intro_en.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Python Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_04_spot_doc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Documentation of the Sequential Parameter Optimization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#derivative-free-optimization-algorithms" id="toc-derivative-free-optimization-algorithms" class="nav-link active" data-scroll-target="#derivative-free-optimization-algorithms"><span class="header-section-number">3.1</span> Derivative-free Optimization Algorithms</a>
  <ul class="collapse">
  <li><a href="#sec-nelder-mead-simplex-algorithm" id="toc-sec-nelder-mead-simplex-algorithm" class="nav-link" data-scroll-target="#sec-nelder-mead-simplex-algorithm"><span class="header-section-number">3.1.1</span> Nelder-Mead Simplex Algorithm</a></li>
  <li><a href="#sec-powells-method" id="toc-sec-powells-method" class="nav-link" data-scroll-target="#sec-powells-method"><span class="header-section-number">3.1.2</span> Powell’s Method</a></li>
  </ul></li>
  <li><a href="#gradient-based-optimization-algorithms" id="toc-gradient-based-optimization-algorithms" class="nav-link" data-scroll-target="#gradient-based-optimization-algorithms"><span class="header-section-number">3.2</span> Gradient-based optimization algorithms</a>
  <ul class="collapse">
  <li><a href="#sec-bfgs-intro" id="toc-sec-bfgs-intro" class="nav-link" data-scroll-target="#sec-bfgs-intro"><span class="header-section-number">3.2.1</span> An Introductory Example: Broyden-Fletcher-Goldfarb-Shanno Algorithm (BFGS)</a></li>
  <li><a href="#background-and-basics-for-gradient-based-optimization" id="toc-background-and-basics-for-gradient-based-optimization" class="nav-link" data-scroll-target="#background-and-basics-for-gradient-based-optimization"><span class="header-section-number">3.2.2</span> Background and Basics for Gradient-based Optimization</a></li>
  <li><a href="#gradient" id="toc-gradient" class="nav-link" data-scroll-target="#gradient"><span class="header-section-number">3.2.3</span> Gradient</a></li>
  <li><a href="#jacobian-matrix" id="toc-jacobian-matrix" class="nav-link" data-scroll-target="#jacobian-matrix"><span class="header-section-number">3.2.4</span> Jacobian Matrix</a></li>
  <li><a href="#hessian-matrix" id="toc-hessian-matrix" class="nav-link" data-scroll-target="#hessian-matrix"><span class="header-section-number">3.2.5</span> Hessian Matrix</a></li>
  <li><a href="#gradient-for-optimization" id="toc-gradient-for-optimization" class="nav-link" data-scroll-target="#gradient-for-optimization"><span class="header-section-number">3.2.6</span> Gradient for Optimization</a></li>
  <li><a href="#newton-method" id="toc-newton-method" class="nav-link" data-scroll-target="#newton-method"><span class="header-section-number">3.2.7</span> Newton Method</a></li>
  <li><a href="#bfgs-algorithm" id="toc-bfgs-algorithm" class="nav-link" data-scroll-target="#bfgs-algorithm"><span class="header-section-number">3.2.8</span> BFGS-Algorithm</a></li>
  <li><a href="#procedure" id="toc-procedure" class="nav-link" data-scroll-target="#procedure"><span class="header-section-number">3.2.9</span> Procedure:</a></li>
  <li><a href="#visualization-bfgs-for-rosenbrock" id="toc-visualization-bfgs-for-rosenbrock" class="nav-link" data-scroll-target="#visualization-bfgs-for-rosenbrock"><span class="header-section-number">3.2.10</span> Visualization BFGS for Rosenbrock</a></li>
  </ul></li>
  <li><a href="#gradient--and-hessian-based-optimization-algorithms" id="toc-gradient--and-hessian-based-optimization-algorithms" class="nav-link" data-scroll-target="#gradient--and-hessian-based-optimization-algorithms"><span class="header-section-number">3.3</span> Gradient- and Hessian-based optimization algorithms</a>
  <ul class="collapse">
  <li><a href="#sec-newton-cg" id="toc-sec-newton-cg" class="nav-link" data-scroll-target="#sec-newton-cg"><span class="header-section-number">3.3.1</span> Newton-Conjugate-Gradient Algorithm</a></li>
  <li><a href="#sec-trust-region-newton" id="toc-sec-trust-region-newton" class="nav-link" data-scroll-target="#sec-trust-region-newton"><span class="header-section-number">3.3.2</span> Trust-Region Newton-Conjugate-Gradient Algorithm</a></li>
  <li><a href="#sec-trust-region-truncated" id="toc-sec-trust-region-truncated" class="nav-link" data-scroll-target="#sec-trust-region-truncated"><span class="header-section-number">3.3.3</span> Trust-Region Truncated Generalized Lanczos / Conjugate Gradient Algorithm</a></li>
  </ul></li>
  <li><a href="#global-optimization" id="toc-global-optimization" class="nav-link" data-scroll-target="#global-optimization"><span class="header-section-number">3.4</span> Global Optimization</a>
  <ul class="collapse">
  <li><a href="#dual-annealing-optimization" id="toc-dual-annealing-optimization" class="nav-link" data-scroll-target="#dual-annealing-optimization"><span class="header-section-number">3.4.1</span> Dual Annealing Optimization</a></li>
  <li><a href="#differential-evolution" id="toc-differential-evolution" class="nav-link" data-scroll-target="#differential-evolution"><span class="header-section-number">3.4.2</span> Differential Evolution</a></li>
  <li><a href="#direct" id="toc-direct" class="nav-link" data-scroll-target="#direct"><span class="header-section-number">3.4.3</span> DIRECT</a></li>
  <li><a href="#shgo" id="toc-shgo" class="nav-link" data-scroll-target="#shgo"><span class="header-section-number">3.4.4</span> SHGO</a></li>
  <li><a href="#basin-hopping" id="toc-basin-hopping" class="nav-link" data-scroll-target="#basin-hopping"><span class="header-section-number">3.4.5</span> Basin-hopping</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Introduction to <code>scipy.optimize</code></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p><a href="https://scipy.org">SciPy</a> provides algorithms for optimization, integration, interpolation, eigenvalue problems, algebraic equations, differential equations, statistics and many other classes of problems. SciPy is a collection of mathematical algorithms and convenience functions built on NumPy. It adds significant power to Python by providing the user with high-level commands and classes for manipulating and visualizing data.</p>
<p><a href="https://docs.scipy.org/doc/scipy/reference/optimize.html#module-scipy.optimize">SciPy optimize</a> provides functions for minimizing (or maximizing) objective functions, possibly subject to constraints. It includes solvers for nonlinear problems (with support for both local and global optimization algorithms), linear programing, constrained and nonlinear least-squares, root finding, and curve fitting.</p>
<p>In this notebook, we will learn how to use the <code>scipy.optimize</code> module to solve optimization problems. See: <a href="https://docs.scipy.org/doc/scipy/tutorial/optimize.html">https://docs.scipy.org/doc/scipy/tutorial/optimize.html</a></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>This content is based on information from the scipy.optimize package.</li>
<li>The <code>scipy.optimize</code> package provides several commonly used optimization algorithms. A detailed listing is available in <code>scipy.optimize</code> (can also be found by <code>help(scipy.optimize)</code>).</li>
</ul>
</div>
</div>
<p>Common functions and objects, shared across different SciPy optimize solvers, are shown in <a href="#tbl-shared-functions">Table&nbsp;<span>3.1</span></a>.</p>
<div id="tbl-shared-functions" class="anchored">
<table class="table">
<caption>Table&nbsp;3.1: Common functions and objects, shared across different SciPy optimize solvers</caption>
<thead>
<tr class="header">
<th>Function or Object</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.show_options.html#scipy.optimize.show_options">show_options([solver, method, disp])</a></td>
<td>Show documentation for additional options of optimization solvers.</td>
</tr>
<tr class="even">
<td><a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.OptimizeResult.html#scipy.optimize.OptimizeResult">OptimizeResult</a></td>
<td>Represents the optimization result.</td>
</tr>
<tr class="odd">
<td><a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.OptimizeWarning.html#scipy.optimize.OptimizeWarning">OptimizeWarning</a></td>
<td>Warning issued by solvers.</td>
</tr>
</tbody>
</table>
</div>
<p>We will introduce unconstrained minimization of multivariate scalar functions in this chapter. The <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize">minimize</a> function provides a common interface to unconstrained and constrained minimization algorithms for multivariate scalar functions in <code>scipy.optimize</code>. To demonstrate the minimization function, consider the problem of minimizing the Rosenbrock function of <em>N</em> variables:</p>
<p><span class="math display">\[
f(J) = \sum_{i=1}^{N-1} 100 (x_{i+1} - x_i^2)^2 + (1 - x_i)^2
\]</span></p>
<p>The minimum value of this function is 0, which is achieved when (x_i = 1).</p>
<p>Note that the Rosenbrock function and its derivatives are included in <code>scipy.optimize</code>. The implementations shown in the following sections provide examples of how to define an objective function as well as its Jacobian and Hessian functions. Objective functions in <code>scipy.optimize</code> expect a numpy array as their first parameter, which is to be optimized and must return a float value. The exact calling signature must be <code>f(x, *args)</code>, where <code>x</code> represents a numpy array, and <code>args</code> is a tuple of additional arguments supplied to the objective function.</p>
<section id="derivative-free-optimization-algorithms" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="derivative-free-optimization-algorithms"><span class="header-section-number">3.1</span> Derivative-free Optimization Algorithms</h2>
<p><a href="#sec-nelder-mead-simplex-algorithm"><span>Section&nbsp;3.1.1</span></a> and <a href="#sec-powells-method"><span>Section&nbsp;3.1.2</span></a> present two approaches that do not need gradient information to find the minimum. They use function evaluations to find the minimum.</p>
<section id="sec-nelder-mead-simplex-algorithm" class="level3" data-number="3.1.1">
<h3 data-number="3.1.1" class="anchored" data-anchor-id="sec-nelder-mead-simplex-algorithm"><span class="header-section-number">3.1.1</span> Nelder-Mead Simplex Algorithm</h3>
<p><code>method='Nelder-Mead'</code>: In the example below, the <code>minimize</code> routine is used with the <em>Nelder-Mead</em> simplex algorithm (selected through the <code>method</code> parameter):</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.optimize <span class="im">import</span> minimize</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rosen(x):</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""The Rosenbrock function"""</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">sum</span>(<span class="fl">100.0</span> <span class="op">*</span> (x[<span class="dv">1</span>:] <span class="op">-</span> x[:<span class="op">-</span><span class="dv">1</span>]<span class="op">**</span><span class="fl">2.0</span>)<span class="op">**</span><span class="fl">2.0</span> <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> x[:<span class="op">-</span><span class="dv">1</span>])<span class="op">**</span><span class="fl">2.0</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>x0 <span class="op">=</span> np.array([<span class="fl">1.3</span>, <span class="fl">0.7</span>, <span class="fl">0.8</span>, <span class="fl">1.9</span>, <span class="fl">1.2</span>])</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>res <span class="op">=</span> minimize(rosen, x0, method<span class="op">=</span><span class="st">'nelder-mead'</span>,</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>               options<span class="op">=</span>{<span class="st">'xatol'</span>: <span class="fl">1e-8</span>, <span class="st">'disp'</span>: <span class="va">True</span>})</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(res.x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Optimization terminated successfully.
         Current function value: 0.000000
         Iterations: 339
         Function evaluations: 571
[1. 1. 1. 1. 1.]</code></pre>
</div>
</div>
<p>The simplex algorithm is probably the simplest way to minimize a well-behaved function. It requires only function evaluations and is a good choice for simple minimization problems. However, because it does not use any gradient evaluations, it may take longer to find the minimum.</p>
</section>
<section id="sec-powells-method" class="level3" data-number="3.1.2">
<h3 data-number="3.1.2" class="anchored" data-anchor-id="sec-powells-method"><span class="header-section-number">3.1.2</span> Powell’s Method</h3>
<p>Another optimization algorithm that needs only function calls to find the minimum is <em>Powell</em>’s method, which can be selected by setting the <code>method</code> parameter to <code>'powell'</code> in the <code>minimize</code> function.</p>
<p>To demonstrate how to supply additional arguments to an objective function, let’s consider minimizing the Rosenbrock function with an additional scaling factor <span class="math inline">\(a\)</span> and an offset <span class="math inline">\(b\)</span>:</p>
<p><span class="math display">\[
f(J, a, b) = \sum_{i=1}^{N-1} a (x_{i+1} - x_i^2)^2 + (1 - x_i)^2 + b
\]</span></p>
<p>You can achieve this using the <code>minimize</code> routine with the example parameters <span class="math inline">\(a=0.5\)</span> and <span class="math inline">\(b=1\)</span>:</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rosen_with_args(x, a, b):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""The Rosenbrock function with additional arguments"""</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">sum</span>(a <span class="op">*</span> (x[<span class="dv">1</span>:] <span class="op">-</span> x[:<span class="op">-</span><span class="dv">1</span>]<span class="op">**</span><span class="fl">2.0</span>)<span class="op">**</span><span class="fl">2.0</span> <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> x[:<span class="op">-</span><span class="dv">1</span>])<span class="op">**</span><span class="fl">2.0</span>) <span class="op">+</span> b</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>x0 <span class="op">=</span> np.array([<span class="fl">1.3</span>, <span class="fl">0.7</span>, <span class="fl">0.8</span>, <span class="fl">1.9</span>, <span class="fl">1.2</span>])</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>res <span class="op">=</span> minimize(rosen_with_args, x0, method<span class="op">=</span><span class="st">'nelder-mead'</span>,</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>               args<span class="op">=</span>(<span class="fl">0.5</span>, <span class="fl">1.</span>), options<span class="op">=</span>{<span class="st">'xatol'</span>: <span class="fl">1e-8</span>, <span class="st">'disp'</span>: <span class="va">True</span>})</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(res.x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Optimization terminated successfully.
         Current function value: 1.000000
         Iterations: 319
         Function evaluations: 525
[1.         1.         1.         1.         0.99999999]</code></pre>
</div>
</div>
<p>As an alternative to using the <code>args</code> parameter of <code>minimize</code>, you can wrap the objective function in a new function that accepts only <code>x</code>. This approach is also useful when it is necessary to pass additional parameters to the objective function as keyword arguments.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rosen_with_args(x, a, <span class="op">*</span>, b):  <span class="co"># b is a keyword-only argument</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">sum</span>(a <span class="op">*</span> (x[<span class="dv">1</span>:] <span class="op">-</span> x[:<span class="op">-</span><span class="dv">1</span>]<span class="op">**</span><span class="fl">2.0</span>)<span class="op">**</span><span class="fl">2.0</span> <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> x[:<span class="op">-</span><span class="dv">1</span>])<span class="op">**</span><span class="fl">2.0</span>) <span class="op">+</span> b</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> wrapped_rosen_without_args(x):</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> rosen_with_args(x, <span class="fl">0.5</span>, b<span class="op">=</span><span class="fl">1.</span>)  <span class="co"># pass in `a` and `b`</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>x0 <span class="op">=</span> np.array([<span class="fl">1.3</span>, <span class="fl">0.7</span>, <span class="fl">0.8</span>, <span class="fl">1.9</span>, <span class="fl">1.2</span>])</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>res <span class="op">=</span> minimize(wrapped_rosen_without_args, x0, method<span class="op">=</span><span class="st">'nelder-mead'</span>,</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>               options<span class="op">=</span>{<span class="st">'xatol'</span>: <span class="fl">1e-8</span>,})</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(res.x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1.         1.         1.         1.         0.99999999]</code></pre>
</div>
</div>
<p>Another alternative is to use <code>functools.partial</code>.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> functools <span class="im">import</span> partial</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>partial_rosen <span class="op">=</span> partial(rosen_with_args, a<span class="op">=</span><span class="fl">0.5</span>, b<span class="op">=</span><span class="fl">1.</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>res <span class="op">=</span> minimize(partial_rosen, x0, method<span class="op">=</span><span class="st">'nelder-mead'</span>,</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>               options<span class="op">=</span>{<span class="st">'xatol'</span>: <span class="fl">1e-8</span>,})</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(res.x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1.         1.         1.         1.         0.99999999]</code></pre>
</div>
</div>
</section>
</section>
<section id="gradient-based-optimization-algorithms" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="gradient-based-optimization-algorithms"><span class="header-section-number">3.2</span> Gradient-based optimization algorithms</h2>
<section id="sec-bfgs-intro" class="level3" data-number="3.2.1">
<h3 data-number="3.2.1" class="anchored" data-anchor-id="sec-bfgs-intro"><span class="header-section-number">3.2.1</span> An Introductory Example: Broyden-Fletcher-Goldfarb-Shanno Algorithm (BFGS)</h3>
<p>This section introduces an optimization algorithm that uses gradient information to find the minimum. The Broyden-Fletcher-Goldfarb-Shanno (BFGS) algorithm (selected by setting <code>method='BFGS'</code>) is an optimization algorithm that aims to converge quickly to the solution. This algorithm uses the gradient of the objective function. If the gradient is not provided by the user, it is estimated using first-differences. The BFGS method typically requires fewer function calls compared to the simplex algorithm, even when the gradient needs to be estimated.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example: BFGS
</div>
</div>
<div class="callout-body-container callout-body">
<p>To demonstrate the BFGS algorithm, let’s use the Rosenbrock function again. The gradient of the Rosenbrock function is a vector described by the following mathematical expression:</p>
<p><span class="math display">\[\begin{align}
\frac{\partial f}{\partial x_j} = \sum_{i=1}^{N} 200(x_i - x_{i-1}^2)(\delta_{i,j} - 2x_{i-1}\delta_{i-1,j}) - 2(1 - x_{i-1})\delta_{i-1,j} \\
= 200(x_j - x_{j-1}^2) - 400x_j(x_{j+1} - x_j^2) - 2(1 - x_j)
\end{align}\]</span></p>
<p>This expression is valid for interior derivatives, but special cases are:</p>
<p><span class="math display">\[
\frac{\partial f}{\partial x_0} = -400x_0(x_1 - x_0^2) - 2(1 - x_0)
\]</span></p>
<p><span class="math display">\[
\frac{\partial f}{\partial x_{N-1}} = 200(x_{N-1} - x_{N-2}^2)
\]</span></p>
<p>Here’s a Python function that computes this gradient:</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rosen_der(x):</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    xm <span class="op">=</span> x[<span class="dv">1</span>:<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    xm_m1 <span class="op">=</span> x[:<span class="op">-</span><span class="dv">2</span>]</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    xm_p1 <span class="op">=</span> x[<span class="dv">2</span>:]</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    der <span class="op">=</span> np.zeros_like(x)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    der[<span class="dv">1</span>:<span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> <span class="dv">200</span><span class="op">*</span>(xm<span class="op">-</span>xm_m1<span class="op">**</span><span class="dv">2</span>) <span class="op">-</span> <span class="dv">400</span><span class="op">*</span>(xm_p1 <span class="op">-</span> xm<span class="op">**</span><span class="dv">2</span>)<span class="op">*</span>xm <span class="op">-</span> <span class="dv">2</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>xm)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    der[<span class="dv">0</span>] <span class="op">=</span> <span class="op">-</span><span class="dv">400</span><span class="op">*</span>x[<span class="dv">0</span>]<span class="op">*</span>(x[<span class="dv">1</span>]<span class="op">-</span>x[<span class="dv">0</span>]<span class="op">**</span><span class="dv">2</span>) <span class="op">-</span> <span class="dv">2</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>x[<span class="dv">0</span>])</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    der[<span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> <span class="dv">200</span><span class="op">*</span>(x[<span class="op">-</span><span class="dv">1</span>]<span class="op">-</span>x[<span class="op">-</span><span class="dv">2</span>]<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> der</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>You can specify this gradient information in the minimize function using the jac parameter as illustrated below:</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>res <span class="op">=</span> minimize(rosen, x0, method<span class="op">=</span><span class="st">'BFGS'</span>, jac<span class="op">=</span>rosen_der,</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>               options<span class="op">=</span>{<span class="st">'disp'</span>: <span class="va">True</span>})</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(res.x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Optimization terminated successfully.
         Current function value: 0.000000
         Iterations: 25
         Function evaluations: 30
         Gradient evaluations: 30
[1.00000004 1.0000001  1.00000021 1.00000044 1.00000092]</code></pre>
</div>
</div>
</div>
</div>
</section>
<section id="background-and-basics-for-gradient-based-optimization" class="level3" data-number="3.2.2">
<h3 data-number="3.2.2" class="anchored" data-anchor-id="background-and-basics-for-gradient-based-optimization"><span class="header-section-number">3.2.2</span> Background and Basics for Gradient-based Optimization</h3>
</section>
<section id="gradient" class="level3" data-number="3.2.3">
<h3 data-number="3.2.3" class="anchored" data-anchor-id="gradient"><span class="header-section-number">3.2.3</span> Gradient</h3>
<p>The gradient <span class="math inline">\(\nabla f(J)\)</span> for a scalar function <span class="math inline">\(f(J)\)</span> with <span class="math inline">\(n\)</span> different variables is defined by its partial derivatives:</p>
<p><span class="math display">\[\nabla f(J) = \left[ \frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, \ldots, \frac{\partial f}{\partial x_n} \right]\]</span></p>
</section>
<section id="jacobian-matrix" class="level3" data-number="3.2.4">
<h3 data-number="3.2.4" class="anchored" data-anchor-id="jacobian-matrix"><span class="header-section-number">3.2.4</span> Jacobian Matrix</h3>
<p>The Jacobian matrix <span class="math inline">\(J(J)\)</span> for a vector-valued function <span class="math inline">\(F(J) = [f_1(J), f_2(J), \ldots, f_m(J)]\)</span> is defined as:</p>
<p><span class="math inline">\(J(J) = \begin{bmatrix} \frac{\partial f_1}{\partial x_1} &amp; \frac{\partial f_1}{\partial x_2} &amp; \ldots &amp; \frac{\partial f_1}{\partial x_n} \\ \frac{\partial f_2}{\partial x_1} &amp; \frac{\partial f_2}{\partial x_2} &amp; \ldots &amp; \frac{\partial f_2}{\partial x_n} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ \frac{\partial f_m}{\partial x_1} &amp; \frac{\partial f_m}{\partial x_2} &amp; \ldots &amp; \frac{\partial f_m}{\partial x_n} \end{bmatrix}\)</span></p>
<p>It consists of the first order partial derivatives and gives therefore an overview about the gradients of a vector valued function.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example: Jacobian matrix
</div>
</div>
<div class="callout-body-container callout-body">
<p>Consider a vector-valued function <span class="math inline">\(f : \mathbb{R}^2 \rightarrow \mathbb{R}^3\)</span> defined as follows: <span class="math display">\[f(J) = \begin{bmatrix} x_1^2 + 2x_2 \\ 3x_1 - \sin(x_2) \\ e^{x_1 + x_2} \end{bmatrix}\]</span></p>
<p>Let’s compute the partial derivatives and construct the Jacobian matrix:</p>
<p><span class="math inline">\(\frac{\partial f_1}{\partial x_1} = 2x_1, \quad \frac{\partial f_1}{\partial x_2} = 2\)</span></p>
<p><span class="math inline">\(\frac{\partial f_2}{\partial x_1} = 3, \quad \frac{\partial f_2}{\partial x_2} = -\cos(x_2)\)</span></p>
<p><span class="math inline">\(\frac{\partial f_3}{\partial x_1} = e^{x_1 + x_2}, \quad \frac{\partial f_3}{\partial x_2} = e^{x_1 + x_2}\)</span></p>
<p>So, the Jacobian matrix is:</p>
<p><span class="math display">\[J(J) = \begin{bmatrix} 2x_1 &amp; 2 \\ 3 &amp; -\cos(x_2) \\ e^{x_1 + x_2} &amp; e^{x_1 + x_2} \end{bmatrix}\]</span></p>
<p>This Jacobian matrix provides information about how small changes in the input variables <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> affect the corresponding changes in each component of the output vector.</p>
</div>
</div>
</section>
<section id="hessian-matrix" class="level3" data-number="3.2.5">
<h3 data-number="3.2.5" class="anchored" data-anchor-id="hessian-matrix"><span class="header-section-number">3.2.5</span> Hessian Matrix</h3>
<p>The Hessian matrix <span class="math inline">\(H(J)\)</span> for a scalar function <span class="math inline">\(f(J)\)</span> is defined as:</p>
<p><span class="math inline">\(H(J) = \begin{bmatrix} \frac{\partial^2 f}{\partial x_1^2} &amp; \frac{\partial^2 f}{\partial x_1 \partial x_2} &amp; \ldots &amp; \frac{\partial^2 f}{\partial x_1 \partial x_n} \\ \frac{\partial^2 f}{\partial x_2 \partial x_1} &amp; \frac{\partial^2 f}{\partial x_2^2} &amp; \ldots &amp; \frac{\partial^2 f}{\partial x_2 \partial x_n} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ \frac{\partial^2 f}{\partial x_n \partial x_1} &amp; \frac{\partial^2 f}{\partial x_n \partial x_2} &amp; \ldots &amp; \frac{\partial^2 f}{\partial x_n^2} \end{bmatrix}\)</span></p>
<p>So, the Hessian matrix consists of the second order dervatives of the function. It provides information about the local curvature of the function with respect to changes in the input variables.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example: Hessian matrix
</div>
</div>
<div class="callout-body-container callout-body">
<p>Consider a scalar-valued function: <span class="math display">\[f(J) = x_1^2 + 2x_2^2 + \sin(x_1   x_2)\]</span></p>
<p>The Hessian matrix of this scalar-valued function is the matrix of its second-order partial derivatives with respect to the input variables: <span class="math display">\[H(J) = \begin{bmatrix} \frac{\partial^2 f}{\partial x_1^2} &amp; \frac{\partial^2 f}{\partial x_1 \partial x_2} \\ \frac{\partial^2 f}{\partial x_2 \partial x_1} &amp; \frac{\partial^2 f}{\partial x_2^2} \end{bmatrix}\]</span></p>
<p>Let’s compute the second-order partial derivatives and construct the Hessian matrix:</p>
<p><span class="math display">\[\begin{align}
\frac{\partial^2 f}{\partial x_1^2} &amp;= 2 + \cos(x_1 x_2) x_2^2\\
\frac{\partial^2 f}{\partial x_1 \partial x_2} &amp;= 2x_1  x_2 \cos(x_1 x_2) - \sin(x_1  x_2)\\
\frac{\partial^2 f}{\partial x_2 \partial x_1} &amp;= 2x_1  x_2  \cos(x_1  x_2) - \sin(x_1  x_2)\\
\frac{\partial^2 f}{\partial x_2^2} &amp;= 4x_2^2 + \cos(x_1  x_2) x_1^2
\end{align}\]</span></p>
<p>So, the Hessian matrix is:</p>
<p><span class="math display">\[H(J) = \begin{bmatrix} 2 + \cos(x_1   x_2)   x_2^2 &amp; 2x_1   x_2   \cos(x_1   x_2) - \sin(x_1   x_2) \\ 2x_1   x_2   \cos(x_1   x_2) - \sin(x_1   x_2) &amp; 4x_2^2 + \cos(x_1   x_2)   x_1^2 \end{bmatrix}\]</span></p>
</div>
</div>
</section>
<section id="gradient-for-optimization" class="level3" data-number="3.2.6">
<h3 data-number="3.2.6" class="anchored" data-anchor-id="gradient-for-optimization"><span class="header-section-number">3.2.6</span> Gradient for Optimization</h3>
<p>In optimization, the goal is to find the minimum or maximum of a function. Gradient-based optimization methods utilize information about the gradient (or derivative) of the function to guide the search for the optimal solution. This is particularly useful when dealing with complex, high-dimensional functions where an exhaustive search is impractical.</p>
<p>The gradient descent method can be divided in the following steps:</p>
<ul>
<li><strong>Initialize:</strong> start with an initial guess for the parameters of the function to be optimized.</li>
<li><strong>Compute Gradient:</strong> Calculate the gradient (partial derivatives) of the function with respect to each parameter at the current point. The gradient indicates the direction of the steepest increase in the function.</li>
<li><strong>Update Parameters:</strong> Adjust the parameters in the opposite direction of the gradient, scaled by a learning rate. This step aims to move towards the minimum of the function:
<ul>
<li><span class="math inline">\(x_{k+1} = x_k - \alpha \times \nabla f(x_{k})\)</span></li>
<li><span class="math inline">\(x_{x}\)</span> is current parameter vector or point in the parameter space.</li>
<li><span class="math inline">\(\alpha\)</span> is the learning rate, a positive scalar that determines the step size in each iteration.</li>
<li><span class="math inline">\(\nabla f(x)\)</span> is the gradient of the objective function.</li>
</ul></li>
<li><strong>Iterate:</strong> Repeat the above steps until convergence or a predefined number of iterations. Convergence is typically determined when the change in the function value or parameters becomes negligible.</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example: Gradient Descent
</div>
</div>
<div class="callout-body-container callout-body">
<p>Let’s consider a simple quadratic function as an example: <span class="math display">\[f(x) = x^2 + 4x + y^2 + 2y + 4.\]</span></p>
<p>We’ll use gradient descent to find the minimum of this function.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mpl_toolkits.mplot3d <span class="im">import</span> Axes3D</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the quadratic function</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> quadratic_function(x, y):</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> <span class="dv">4</span><span class="op">*</span>x <span class="op">+</span> y<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> <span class="dv">2</span><span class="op">*</span>y <span class="op">+</span> <span class="dv">4</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the gradient of the quadratic function</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gradient_quadratic_function(x, y):</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    grad_x <span class="op">=</span> <span class="dv">2</span><span class="op">*</span>x <span class="op">+</span> <span class="dv">4</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    grad_y <span class="op">=</span> <span class="dv">2</span><span class="op">*</span>y <span class="op">+</span> <span class="dv">2</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array([grad_x, grad_y])</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Gradient Descent for optimization in 2D</span></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gradient_descent(initial_point, learning_rate, num_iterations):</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>    points <span class="op">=</span> [np.array(initial_point)]</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(num_iterations):</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>        current_point <span class="op">=</span> points[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>        gradient <span class="op">=</span> gradient_quadratic_function(<span class="op">*</span>current_point)</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>        new_point <span class="op">=</span> current_point <span class="op">-</span> learning_rate <span class="op">*</span> gradient</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>        points.append(new_point)</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> points</span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualization of optimization process with 3D surface and consistent arrow sizes</span></span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_optimization_process_3d_consistent_arrows(points):</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> fig.add_subplot(<span class="dv">111</span>, projection<span class="op">=</span><span class="st">'3d'</span>)</span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>    x_vals <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">10</span>, <span class="dv">2</span>, <span class="dv">100</span>)</span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a>    y_vals <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">10</span>, <span class="dv">2</span>, <span class="dv">100</span>)</span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>    X, Y <span class="op">=</span> np.meshgrid(x_vals, y_vals)</span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> quadratic_function(X, Y)</span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>    ax.plot_surface(X, Y, Z, cmap<span class="op">=</span><span class="st">'viridis'</span>, alpha<span class="op">=</span><span class="fl">0.6</span>)</span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a>    ax.scatter(<span class="op">*</span><span class="bu">zip</span>(<span class="op">*</span>points), [quadratic_function(<span class="op">*</span>p) <span class="cf">for</span> p <span class="kw">in</span> points], c<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">'Optimization Trajectory'</span>)</span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(points) <span class="op">-</span> <span class="dv">1</span>):  </span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a>        x, y <span class="op">=</span> points[i]</span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a>        dx, dy <span class="op">=</span> points[i <span class="op">+</span> <span class="dv">1</span>] <span class="op">-</span> points[i]</span>
<span id="cb12-44"><a href="#cb12-44" aria-hidden="true" tabindex="-1"></a>        dz <span class="op">=</span> quadratic_function(<span class="op">*</span>(points[i <span class="op">+</span> <span class="dv">1</span>])) <span class="op">-</span> quadratic_function(<span class="op">*</span>points[i])</span>
<span id="cb12-45"><a href="#cb12-45" aria-hidden="true" tabindex="-1"></a>        gradient_length <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb12-46"><a href="#cb12-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-47"><a href="#cb12-47" aria-hidden="true" tabindex="-1"></a>        ax.quiver(x, y, quadratic_function(<span class="op">*</span>points[i]), dx, dy, dz, color<span class="op">=</span><span class="st">'blue'</span>, length<span class="op">=</span>gradient_length, normalize<span class="op">=</span><span class="va">False</span>, arrow_length_ratio<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb12-48"><a href="#cb12-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-49"><a href="#cb12-49" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="st">'Gradient-Based Optimization with 2D Quadratic Function'</span>)</span>
<span id="cb12-50"><a href="#cb12-50" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="st">'x'</span>)</span>
<span id="cb12-51"><a href="#cb12-51" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">'y'</span>)</span>
<span id="cb12-52"><a href="#cb12-52" aria-hidden="true" tabindex="-1"></a>    ax.set_zlabel(<span class="st">'f(x, y)'</span>)</span>
<span id="cb12-53"><a href="#cb12-53" aria-hidden="true" tabindex="-1"></a>    ax.legend()</span>
<span id="cb12-54"><a href="#cb12-54" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb12-55"><a href="#cb12-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-56"><a href="#cb12-56" aria-hidden="true" tabindex="-1"></a><span class="co"># Initial guess and parameters</span></span>
<span id="cb12-57"><a href="#cb12-57" aria-hidden="true" tabindex="-1"></a>initial_guess <span class="op">=</span> [<span class="op">-</span><span class="fl">9.0</span>, <span class="op">-</span><span class="fl">9.0</span>]</span>
<span id="cb12-58"><a href="#cb12-58" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.2</span></span>
<span id="cb12-59"><a href="#cb12-59" aria-hidden="true" tabindex="-1"></a>num_iterations <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb12-60"><a href="#cb12-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-61"><a href="#cb12-61" aria-hidden="true" tabindex="-1"></a><span class="co"># Run gradient descent in 2D and visualize the optimization process with 3D surface and consistent arrow sizes</span></span>
<span id="cb12-62"><a href="#cb12-62" aria-hidden="true" tabindex="-1"></a>trajectory <span class="op">=</span> gradient_descent(initial_guess, learning_rate, num_iterations)</span>
<span id="cb12-63"><a href="#cb12-63" aria-hidden="true" tabindex="-1"></a>plot_optimization_process_3d_consistent_arrows(trajectory)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="003_scipy_optimize_intro_files/figure-html/cell-8-output-1.png" width="621" height="631"></p>
</div>
</div>
</div>
</div>
</section>
<section id="newton-method" class="level3" data-number="3.2.7">
<h3 data-number="3.2.7" class="anchored" data-anchor-id="newton-method"><span class="header-section-number">3.2.7</span> Newton Method</h3>
<p><strong>Initialization:</strong> Start with an initial guess for the optimal solution: <span class="math inline">\(x_0\)</span>.</p>
<p><strong>Iteration:</strong> Repeat the following three steps until convergence or a predefined stopping criterion is met:</p>
<ol type="1">
<li><p>Calculate the gradient (<span class="math inline">\(\nabla\)</span>) and the Hessian matrix (<span class="math inline">\(\nabla^2\)</span>) of the objective function at the current point: <span class="math display">\[\nabla f(x_k) \quad \text{and} \quad \nabla^2 f(x_k)\]</span></p></li>
<li><p>Update the current solution using the Newton-Raphson update formula <span class="math display">\[x_{k+1} = x_k - [\nabla^2 f(x_k)]^{-1} \nabla f(x_k),\]</span> where</p></li>
</ol>
<ul>
<li><span class="math inline">\(\nabla f(x_k)\)</span> is the gradient (first derivative) of the objective function with respect to the variable <span class="math inline">\(x\)</span>, evaluated at the current solution <span class="math inline">\(x_k\)</span>.</li>
<li><span class="math inline">\(\nabla^2 f(x_k)\)</span>: The Hessian matrix (second derivative) of the objective function with respect to <span class="math inline">\(x\)</span>, evaluated at the current solution <span class="math inline">\(x_k\)</span>.</li>
<li><span class="math inline">\(x_k\)</span>: The current solution or point in the optimization process.</li>
<li><span class="math inline">\(\nabla^2 f(x_k)]^{-1}\)</span>: The inverse of the Hessian matrix at the current point, representing the approximation of the curvature of the objective function.</li>
<li><span class="math inline">\(x_{k+1}\)</span>: The updated solution or point after applying the Newton-Raphson update.</li>
</ul>
<ol start="3" type="1">
<li>Check for convergence.</li>
</ol>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example: Newton Method
</div>
</div>
<div class="callout-body-container callout-body">
<p>We want to optimize the Rosenbrock function and use the Hessian and the Jacobian (which is equal to the gradient vector for scalar objective function) to the <code>minimize</code> function.</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rosenbrock(x):</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">100</span> <span class="op">*</span> (x[<span class="dv">1</span>] <span class="op">-</span> x[<span class="dv">0</span>]<span class="op">**</span><span class="dv">2</span>)<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> x[<span class="dv">0</span>])<span class="op">**</span><span class="dv">2</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rosenbrock_gradient(x):</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    dfdx0 <span class="op">=</span> <span class="op">-</span><span class="dv">400</span> <span class="op">*</span> x[<span class="dv">0</span>] <span class="op">*</span> (x[<span class="dv">1</span>] <span class="op">-</span> x[<span class="dv">0</span>]<span class="op">**</span><span class="dv">2</span>) <span class="op">-</span> <span class="dv">2</span> <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> x[<span class="dv">0</span>])</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    dfdx1 <span class="op">=</span> <span class="dv">200</span> <span class="op">*</span> (x[<span class="dv">1</span>] <span class="op">-</span> x[<span class="dv">0</span>]<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array([dfdx0, dfdx1])</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rosenbrock_hessian(x):</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    d2fdx0 <span class="op">=</span> <span class="dv">1200</span> <span class="op">*</span> x[<span class="dv">0</span>]<span class="op">**</span><span class="dv">2</span> <span class="op">-</span> <span class="dv">400</span> <span class="op">*</span> x[<span class="dv">1</span>] <span class="op">+</span> <span class="dv">2</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>    d2fdx1 <span class="op">=</span> <span class="op">-</span><span class="dv">400</span> <span class="op">*</span> x[<span class="dv">0</span>]</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array([[d2fdx0, d2fdx1], [d2fdx1, <span class="dv">200</span>]])</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> classical_newton_optimization_2d(initial_guess, tol<span class="op">=</span><span class="fl">1e-6</span>, max_iter<span class="op">=</span><span class="dv">100</span>):</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> initial_guess.copy()</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(max_iter):</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>        gradient <span class="op">=</span> rosenbrock_gradient(x)</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>        hessian <span class="op">=</span> rosenbrock_hessian(x)</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Solve the linear system H * d = -g for d</span></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>        d <span class="op">=</span> np.linalg.solve(hessian, <span class="op">-</span>gradient)</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Update x</span></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>        x <span class="op">+=</span> d</span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check for convergence</span></span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> np.linalg.norm(gradient, <span class="bu">ord</span><span class="op">=</span>np.inf) <span class="op">&lt;</span> tol:</span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x</span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Initial guess</span></span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a>initial_guess_2d <span class="op">=</span> np.array([<span class="fl">0.0</span>, <span class="fl">0.0</span>])</span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Run classical Newton optimization for the 2D Rosenbrock function</span></span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a>result_2d <span class="op">=</span> classical_newton_optimization_2d(initial_guess_2d)</span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the result</span></span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Optimal solution:"</span>, result_2d)</span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Objective value:"</span>, rosenbrock(result_2d))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Optimal solution: [1. 1.]
Objective value: 0.0</code></pre>
</div>
</div>
</div>
</div>
</section>
<section id="bfgs-algorithm" class="level3" data-number="3.2.8">
<h3 data-number="3.2.8" class="anchored" data-anchor-id="bfgs-algorithm"><span class="header-section-number">3.2.8</span> BFGS-Algorithm</h3>
<p>BFGS is an optimization algorithm designed for unconstrained optimization problems. It belongs to the class of quasi-Newton methods and is known for its efficiency in finding the minimum of a smooth, unconstrained objective function.</p>
</section>
<section id="procedure" class="level3" data-number="3.2.9">
<h3 data-number="3.2.9" class="anchored" data-anchor-id="procedure"><span class="header-section-number">3.2.9</span> Procedure:</h3>
<ol type="1">
<li><strong>Initialization:</strong>
<ul>
<li>Start with an initial guess for the parameters of the objective function.</li>
<li>Initialize an approximation of the Hessian matrix (inverse) denoted by <span class="math inline">\(H\)</span>.<br>
</li>
</ul></li>
<li><strong>Iterative Update:</strong>
<ul>
<li>At each iteration, compute the gradient vector at the current point.</li>
<li>Update the parameters using the BFGS update formula, which involves the inverse Hessian matrix approximation, the gradient, and the difference in parameter vectors between successive iterations: <span class="math display">\[x_{k+1} = x_k - H_k^{-1} \nabla f(x_k).\]</span></li>
<li>Update the inverse Hessian approximation using the BFGS update formula for the inverse Hessian. <span class="math display">\[H_{k+1} = H_k + \frac{\Delta x_k \Delta x_k^T}{\Delta x_k^T \Delta g_k} - \frac{H_k g_k g_k^T H_k}{g_k^T H_k g_k},\]</span> where:</li>
<li><span class="math inline">\(x_k\)</span> and <span class="math inline">\(x_{k+1}\)</span> are the parameter vectors at the current and updated iterations, respectively.</li>
<li><span class="math inline">\(\nabla f(x_k)\)</span> is the gradient vector at the current iteration.</li>
<li><span class="math inline">\(\Delta x_k = x_{k+1} - x_k\)</span> is the change in parameter vectors.</li>
<li><span class="math inline">\(\Delta g_k = \nabla f(x_{k+1}) - \nabla f(x_k)\)</span> is the change in gradient vectors.</li>
</ul></li>
<li><strong>Convergence:</strong>
<ul>
<li>Repeat the iterative update until the optimization converges. Convergence is typically determined by reaching a sufficiently low gradient or parameter change.</li>
</ul></li>
</ol>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example: BFGS for Rosenbrock
</div>
</div>
<div class="callout-body-container callout-body">
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.optimize <span class="im">import</span> minimize</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the 2D Rosenbrock function</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rosenbrock(x):</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (<span class="dv">1</span> <span class="op">-</span> x[<span class="dv">0</span>])<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> <span class="dv">100</span> <span class="op">*</span> (x[<span class="dv">1</span>] <span class="op">-</span> x[<span class="dv">0</span>]<span class="op">**</span><span class="dv">2</span>)<span class="op">**</span><span class="dv">2</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Initial guess</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>initial_guess <span class="op">=</span> np.array([<span class="fl">0.0</span>, <span class="fl">0.0</span>])</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Minimize the Rosenbrock function using BFGS</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>minimize(rosenbrock, initial_guess, method<span class="op">=</span><span class="st">'BFGS'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>  message: Optimization terminated successfully.
  success: True
   status: 0
      fun: 2.843987518235081e-11
        x: [ 1.000e+00  1.000e+00]
      nit: 19
      jac: [ 3.987e-06 -2.844e-06]
 hess_inv: [[ 4.948e-01  9.896e-01]
            [ 9.896e-01  1.984e+00]]
     nfev: 72
     njev: 24</code></pre>
</div>
</div>
</div>
</div>
</section>
<section id="visualization-bfgs-for-rosenbrock" class="level3" data-number="3.2.10">
<h3 data-number="3.2.10" class="anchored" data-anchor-id="visualization-bfgs-for-rosenbrock"><span class="header-section-number">3.2.10</span> Visualization BFGS for Rosenbrock</h3>
<p>A visualization of the BFGS search process on Rosenbrock’s function can be found here: <a href="https://upload.wikimedia.org/wikipedia/de/f/ff/Rosenbrock-bfgs-animation.gif">https://upload.wikimedia.org/wikipedia/de/f/ff/Rosenbrock-bfgs-animation.gif</a></p>
<!-- 
![BFGS search process on Rosenbrock's function. Figure taken from: [https://upload.wikimedia.org/wikipedia/de/f/ff/Rosenbrock-bfgs-animation.gif](https://upload.wikimedia.org/wikipedia/de/f/ff/Rosenbrock-bfgs-animation.gif)](./figures_static/Rosenbrock-bfgs-animation.gif)
 -->
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tasks
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>In which situations is it possible to use algorithms like BFGS, but not the classical Newton method?</li>
<li>Investigate the Newton-CG method</li>
<li>Use an objective function of your choice and apply Newton-CG</li>
<li>Compare the Newton-CG method with the BFGS. What are the similarities and differences between the two algorithms?</li>
</ul>
</div>
</div>
</section>
</section>
<section id="gradient--and-hessian-based-optimization-algorithms" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="gradient--and-hessian-based-optimization-algorithms"><span class="header-section-number">3.3</span> Gradient- and Hessian-based optimization algorithms</h2>
<p><a href="#sec-newton-cg"><span>Section&nbsp;3.3.1</span></a> presents an optimization algorithm that uses gradient and Hessian information to find the minimum. <a href="#sec-trust-region-newton"><span>Section&nbsp;3.3.2</span></a> presents an optimization algorithm that uses gradient and Hessian information to find the minimum. <a href="#sec-trust-region-truncated"><span>Section&nbsp;3.3.3</span></a> presents an optimization algorithm that uses gradient and Hessian information to find the minimum.</p>
<p>The methods Newton-CG, trust-ncg and trust-krylov are suitable for dealing with large-scale problems (problems with thousands of variables). That is because the conjugate gradient algorithm approximately solve the trust-region subproblem (or invert the Hessian) by iterations without the explicit Hessian factorization. Since only the product of the Hessian with an arbitrary vector is needed, the algorithm is specially suited for dealing with sparse Hessians, allowing low storage requirements and significant time savings for those sparse problems.</p>
<section id="sec-newton-cg" class="level3" data-number="3.3.1">
<h3 data-number="3.3.1" class="anchored" data-anchor-id="sec-newton-cg"><span class="header-section-number">3.3.1</span> Newton-Conjugate-Gradient Algorithm</h3>
<p>Newton-Conjugate Gradient algorithm is a modified Newton’s method and uses a conjugate gradient algorithm to (approximately) invert the local Hessian.</p>
</section>
<section id="sec-trust-region-newton" class="level3" data-number="3.3.2">
<h3 data-number="3.3.2" class="anchored" data-anchor-id="sec-trust-region-newton"><span class="header-section-number">3.3.2</span> Trust-Region Newton-Conjugate-Gradient Algorithm</h3>
</section>
<section id="sec-trust-region-truncated" class="level3" data-number="3.3.3">
<h3 data-number="3.3.3" class="anchored" data-anchor-id="sec-trust-region-truncated"><span class="header-section-number">3.3.3</span> Trust-Region Truncated Generalized Lanczos / Conjugate Gradient Algorithm</h3>
</section>
</section>
<section id="global-optimization" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="global-optimization"><span class="header-section-number">3.4</span> Global Optimization</h2>
<p>Global optimization aims to find the global minimum of a function within given bounds, in the presence of potentially many local minima. Typically, global minimizers efficiently search the parameter space, while using a local minimizer (e.g., minimize) under the hood. SciPy contains a number of good global optimizers. Here, we’ll use those on the same objective function, namely the (aptly named) eggholder function:</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> eggholder(x):</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (<span class="op">-</span>(x[<span class="dv">1</span>] <span class="op">+</span> <span class="dv">47</span>) <span class="op">*</span> np.sin(np.sqrt(<span class="bu">abs</span>(x[<span class="dv">0</span>]<span class="op">/</span><span class="dv">2</span> <span class="op">+</span> (x[<span class="dv">1</span>]  <span class="op">+</span> <span class="dv">47</span>))))</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>            <span class="op">-</span>x[<span class="dv">0</span>] <span class="op">*</span> np.sin(np.sqrt(<span class="bu">abs</span>(x[<span class="dv">0</span>] <span class="op">-</span> (x[<span class="dv">1</span>]  <span class="op">+</span> <span class="dv">47</span>)))))</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>bounds <span class="op">=</span> [(<span class="op">-</span><span class="dv">512</span>, <span class="dv">512</span>), (<span class="op">-</span><span class="dv">512</span>, <span class="dv">512</span>)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mpl_toolkits.mplot3d <span class="im">import</span> Axes3D</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.arange(<span class="op">-</span><span class="dv">512</span>, <span class="dv">513</span>)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.arange(<span class="op">-</span><span class="dv">512</span>, <span class="dv">513</span>)</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>xgrid, ygrid <span class="op">=</span> np.meshgrid(x, y)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>xy <span class="op">=</span> np.stack([xgrid, ygrid])</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure()</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> fig.add_subplot(<span class="dv">111</span>, projection<span class="op">=</span><span class="st">'3d'</span>)</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>ax.view_init(<span class="dv">45</span>, <span class="op">-</span><span class="dv">45</span>)</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>ax.plot_surface(xgrid, ygrid, eggholder(xy), cmap<span class="op">=</span><span class="st">'terrain'</span>)</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'x'</span>)</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'y'</span>)</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>ax.set_zlabel(<span class="st">'eggholder(x, y)'</span>)</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="003_scipy_optimize_intro_files/figure-html/cell-12-output-1.png" width="427" height="398"></p>
</div>
</div>
<p>We now use the global optimizers to obtain the minimum and the function value at the minimum. We’ll store the results in a dictionary so we can compare different optimization results later.</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> optimize</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> <span class="bu">dict</span>()</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>results[<span class="st">'shgo'</span>] <span class="op">=</span> optimize.shgo(eggholder, bounds)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>results[<span class="st">'shgo'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code> message: Optimization terminated successfully.
 success: True
     fun: -935.3379515605789
    funl: [-9.353e+02]
       x: [ 4.395e+02  4.540e+02]
      xl: [[ 4.395e+02  4.540e+02]]
     nit: 1
    nfev: 45
   nlfev: 40
   nljev: 10
   nlhev: 0</code></pre>
</div>
</div>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>results[<span class="st">'DA'</span>] <span class="op">=</span> optimize.dual_annealing(eggholder, bounds)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>results[<span class="st">'DA'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code> message: ['Maximum number of iteration reached']
 success: True
  status: 0
     fun: -959.6406627208298
       x: [ 5.120e+02  4.042e+02]
     nit: 1000
    nfev: 4115
    njev: 38
    nhev: 0</code></pre>
</div>
</div>
<p>All optimizers return an <code>OptimizeResult</code>, which in addition to the solution contains information on the number of function evaluations, whether the optimization was successful, and more. For brevity, we won’t show the full output of the other optimizers:</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>results[<span class="st">'DE'</span>] <span class="op">=</span> optimize.differential_evolution(eggholder, bounds)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>results[<span class="st">'DE'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code> message: Optimization terminated successfully.
 success: True
     fun: -935.3379515603085
       x: [ 4.395e+02  4.540e+02]
     nit: 33
    nfev: 1041
     jac: [ 0.000e+00  0.000e+00]</code></pre>
</div>
</div>
<p><code>shgo</code> has a second method, which returns all local minima rather than only what it thinks is the global minimum:</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>results[<span class="st">'shgo_sobol'</span>] <span class="op">=</span> optimize.shgo(eggholder, bounds, n<span class="op">=</span><span class="dv">200</span>, iters<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>                                      sampling_method<span class="op">=</span><span class="st">'sobol'</span>)</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>results[<span class="st">'shgo_sobol'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code> message: Optimization terminated successfully.
 success: True
     fun: -959.640662720831
    funl: [-9.596e+02 -9.353e+02 ... -6.591e+01 -6.387e+01]
       x: [ 5.120e+02  4.042e+02]
      xl: [[ 5.120e+02  4.042e+02]
           [ 4.395e+02  4.540e+02]
           ...
           [ 3.165e+01 -8.523e+01]
           [ 5.865e+01 -5.441e+01]]
     nit: 5
    nfev: 3529
   nlfev: 2327
   nljev: 634
   nlhev: 0</code></pre>
</div>
</div>
<p>We’ll now plot all found minima on a heatmap of the function:</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure()</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> fig.add_subplot(<span class="dv">111</span>)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>im <span class="op">=</span> ax.imshow(eggholder(xy), interpolation<span class="op">=</span><span class="st">'bilinear'</span>, origin<span class="op">=</span><span class="st">'lower'</span>,</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>               cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'x'</span>)</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'y'</span>)</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_point(res, marker<span class="op">=</span><span class="st">'o'</span>, color<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>    ax.plot(<span class="dv">512</span><span class="op">+</span>res.x[<span class="dv">0</span>], <span class="dv">512</span><span class="op">+</span>res.x[<span class="dv">1</span>], marker<span class="op">=</span>marker, color<span class="op">=</span>color, ms<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>plot_point(results[<span class="st">'DE'</span>], color<span class="op">=</span><span class="st">'c'</span>)  <span class="co"># differential_evolution - cyan</span></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>plot_point(results[<span class="st">'DA'</span>], color<span class="op">=</span><span class="st">'w'</span>)  <span class="co"># dual_annealing.        - white</span></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a><span class="co"># SHGO produces multiple minima, plot them all (with a smaller marker size)</span></span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>plot_point(results[<span class="st">'shgo'</span>], color<span class="op">=</span><span class="st">'r'</span>, marker<span class="op">=</span><span class="st">'+'</span>)</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>plot_point(results[<span class="st">'shgo_sobol'</span>], color<span class="op">=</span><span class="st">'r'</span>, marker<span class="op">=</span><span class="st">'x'</span>)</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(results[<span class="st">'shgo_sobol'</span>].xl.shape[<span class="dv">0</span>]):</span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>    ax.plot(<span class="dv">512</span> <span class="op">+</span> results[<span class="st">'shgo_sobol'</span>].xl[i, <span class="dv">0</span>],</span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>            <span class="dv">512</span> <span class="op">+</span> results[<span class="st">'shgo_sobol'</span>].xl[i, <span class="dv">1</span>],</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>            <span class="st">'ro'</span>, ms<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a>ax.set_xlim([<span class="op">-</span><span class="dv">4</span>, <span class="dv">514</span><span class="op">*</span><span class="dv">2</span>])</span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a>ax.set_ylim([<span class="op">-</span><span class="dv">4</span>, <span class="dv">514</span><span class="op">*</span><span class="dv">2</span>])</span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="003_scipy_optimize_intro_files/figure-html/cell-17-output-1.png" width="457" height="429"></p>
</div>
</div>
<section id="dual-annealing-optimization" class="level3" data-number="3.4.1">
<h3 data-number="3.4.1" class="anchored" data-anchor-id="dual-annealing-optimization"><span class="header-section-number">3.4.1</span> Dual Annealing Optimization</h3>
<p>This function implements the Dual Annealing optimization.</p>
</section>
<section id="differential-evolution" class="level3" data-number="3.4.2">
<h3 data-number="3.4.2" class="anchored" data-anchor-id="differential-evolution"><span class="header-section-number">3.4.2</span> Differential Evolution</h3>
<p>Differential Evolution is an algorithm used for finding the global minimum of multivariate functions. It is stochastic in nature (does not use gradient methods), and can search large areas of candidate space, but often requires larger numbers of function evaluations than conventional gradient based techniques.</p>
</section>
<section id="direct" class="level3" data-number="3.4.3">
<h3 data-number="3.4.3" class="anchored" data-anchor-id="direct"><span class="header-section-number">3.4.3</span> DIRECT</h3>
<p>DIviding RECTangles (DIRECT) is a deterministic global optimization algorithm capable of minimizing a black box function with its variables subject to lower and upper bound constraints by sampling potential solutions in the search space</p>
</section>
<section id="shgo" class="level3" data-number="3.4.4">
<h3 data-number="3.4.4" class="anchored" data-anchor-id="shgo"><span class="header-section-number">3.4.4</span> SHGO</h3>
<p>SHGO stands for “simplicial homology global optimization”. It is considered appropriate for solving general purpose NLP and blackbox optimization problems to global optimality (low-dimensional problems).</p>
</section>
<section id="basin-hopping" class="level3" data-number="3.4.5">
<h3 data-number="3.4.5" class="anchored" data-anchor-id="basin-hopping"><span class="header-section-number">3.4.5</span> Basin-hopping</h3>
<p>Basin-hopping is a two-phase method that combines a global stepping algorithm with local minimization at each step. Designed to mimic the natural process of energy minimization of clusters of atoms, it works well for similar problems with “funnel-like, but rugged” energy landscapes</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./002_awwe.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Aircraft Wing Weight Example</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./004_spot_sklearn_optimization.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Sequential Parameter Optimization: Using <code>scipy</code> Optimizers</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>