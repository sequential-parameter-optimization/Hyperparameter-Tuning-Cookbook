<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>25&nbsp; Addressing Multicollinearity: Principle Component Analysis (PCA) and Factor Analysis (FA) – Hyperparameter Tuning Cookbook</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./100_ddmo_regression.html" rel="next">
<link href="./100_ddmo_eda.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-23a3edf7f3c1ed1fc827cae2f6dd4de5.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta name="twitter:title" content="25&nbsp; Addressing Multicollinearity: Principle Component Analysis (PCA) and Factor Analysis (FA) – Hyperparameter Tuning Cookbook">
<meta name="twitter:description" content="">
<meta name="twitter:image" content="100_ddmo_pca_files/figure-html/fig-scree_plot_pca-1-output-1.png">
<meta name="twitter:card" content="summary_large_image">
<meta name="citation_title" content="[25]{.chapter-number}&nbsp; [Addressing Multicollinearity: Principle Component Analysis (PCA) and Factor Analysis (FA)]{.chapter-title}">
<meta name="citation_fulltext_html_url" content="https://arxiv.org/abs/2307.10262">
<meta name="citation_doi" content="10.48550/arXiv.2307.10262">
<meta name="citation_language" content="en">
<meta name="citation_journal_title" content="arXiv">
<meta name="citation_reference" content="citation_title=Benchmarking in Optimization: Best Practice and Open Issues;,citation_author=Thomas Bartz-Beielstein;,citation_author=Carola Doerr;,citation_author=Jakob Bossek;,citation_author=Sowmya Chandrasekaran;,citation_author=Tome Eftimov;,citation_author=Andreas Fischbach;,citation_author=Pascal Kerschke;,citation_author=Manuel Lopez-Ibanez;,citation_author=Katherine M. Malan;,citation_author=Jason H. Moore;,citation_author=Boris Naujoks;,citation_author=Patryk Orzechowski;,citation_author=Vanessa Volz;,citation_author=Markus Wagner;,citation_author=Thomas Weise;,citation_publication_date=2020-07;,citation_cover_date=2020-07;,citation_year=2020;,citation_fulltext_html_url=https://arxiv.org/abs/2007.03488;,citation_publisher=arXiv;">
<meta name="citation_reference" content="citation_title=Hyperparameter Tuning With Ray Tune;,citation_author=undefined PyTorch;,citation_publication_date=2023-05;,citation_cover_date=2023-05;,citation_year=2023;,citation_fulltext_html_url=https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html;">
<meta name="citation_reference" content="citation_title=Training a Classifier;,citation_author=undefined PyTorch;,citation_publication_date=2023-05;,citation_cover_date=2023-05;,citation_year=2023;,citation_fulltext_html_url=https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html;">
<meta name="citation_reference" content="citation_title=PyTorch Hyperparameter Tuning with SPOT: Comparison with Ray Tuner and Default Hyperparameters on CIFAR10;,citation_author=Thomas Bartz-Beielstein;,citation_publication_date=2023-04;,citation_cover_date=2023-04;,citation_year=2023;,citation_fulltext_html_url=https://github.com/sequential-parameter-optimization/spotpython/blob/main/notebooks/14_spot_ray_hpt_torch_cifar10.ipynb;">
<meta name="citation_reference" content="citation_title=Machine Learning in Official Statistics;,citation_author=Martin Beck;,citation_author=Florian Dumpert;,citation_author=Joerg Feuerhake;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_doi=10.48550/arXiv.1812.10422;">
<meta name="citation_reference" content="citation_title=Qualitätshandbuch der Statistischen Ämter des Bundes und der Länder;,citation_publication_date=2021-03;,citation_cover_date=2021-03;,citation_year=2021;,citation_fulltext_html_url=https://www.destatis.de/DE/Methoden/Qualitaet/qualitaetshandbuch.pdf;,citation_language=de;">
<meta name="citation_reference" content="citation_title=Quality Assurance Framework of the European Statistical System;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_fulltext_html_url=https://ec.europa.eu/eurostat/documents/64157/4392716/ESS-QAF-V2.0-final.pdf;,citation_language=en;">
<meta name="citation_reference" content="citation_title=Standardisierung der Prozesse: 14 Jahre AG SteP;,citation_author=T. Blumöhr;,citation_author=C. Teichmann;,citation_author=A. Noack;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_fulltext_html_url=https://www.destatis.de/DE/Methoden/
               WISTA-Wirtschaft-und-Statistik/2017/05/standardisierung-prozesse-052017.html;,citation_volume=5;,citation_journal_title=WISTA - Wirtschaft und Statistik;,citation_publisher=Wiesbaden: Statistisches Bundesamt (Destatis);">
<meta name="citation_reference" content="citation_title=Generic Statistical Business Process Model - GSBPM;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_fulltext_html_url=https://statswiki.unece.org/display/
               GSBPM/GSBPM+v5.1;,citation_publisher=United Nations Economic Commission for Europe (UNECE);">
<meta name="citation_reference" content="citation_title=Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide;,citation_editor=Eva Bartz;,citation_editor=Thomas Bartz-Beielstein;,citation_editor=Martin Zaefferer;,citation_editor=Olaf Mersmann;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=Engineering Design via Surrogate Modelling;,citation_author=Alexander Forrester;,citation_author=András Sóbester;,citation_author=Andy Keane;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;">
<meta name="citation_reference" content="citation_title=No Free Lunch Theorems for Optimization;,citation_author=David H Wolpert;,citation_author=William G Macready;,citation_publication_date=1997-04;,citation_cover_date=1997-04;,citation_year=1997;,citation_issue=1;,citation_volume=1;,citation_journal_title=IEEE Transactions on Evolutionary Computation;">
<meta name="citation_reference" content="citation_title=An Introduction to Statistical Learning with Applications in R;,citation_author=Gareth James;,citation_author=Daniela Witten;,citation_author=Trevor Hastie;,citation_author=Robert Tibshirani;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;">
<meta name="citation_reference" content="citation_title=Requirements for papers focusing on new or improved global optimization algorithms;,citation_author=Raphael T. Haftka;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_issue=1;,citation_volume=54;,citation_journal_title=Structural and Multidisciplinary Optimization;">
<meta name="citation_reference" content="citation_title=LightGBM: A Highly Efficient Gradient Boosting Decision Tree;,citation_author=Guolin Ke;,citation_author=Qi Meng;,citation_author=Thomas Finley;,citation_author=Taifeng Wang;,citation_author=Wei Chen;,citation_author=Weidong Ma;,citation_author=Qiwei Ye;,citation_author=Tie-Yan Liu;,citation_editor=I. Guyon;,citation_editor=U. Von Luxburg;,citation_editor=S. Bengio;,citation_editor=H. Wallach;,citation_editor=R. Fergus;,citation_editor=S. Vishwanathan;,citation_editor=R. Garnett;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_volume=30;,citation_conference_title=Advances in Neural Information Processing Systems;,citation_conference=Curran Associates, Inc.;">
<meta name="citation_reference" content="citation_title=Greedy Function Approximation: A Gradient Boosting Machine;,citation_author=Jerome H. Friedman;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_issue=5;,citation_volume=29;,citation_journal_title=The Annals of Statistics;">
<meta name="citation_reference" content="citation_title=Machine Learning in Official Statistics;,citation_author=Martin Beck;,citation_author=Florian Dumpert;,citation_author=Joerg Feuerhake;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_doi=10.48550/arXiv.1812.10422;">
<meta name="citation_reference" content="citation_title=Official statistics in the era of big data opportunities and threats;,citation_author=Walter J. Radermacher;,citation_publication_date=2018-11-01;,citation_cover_date=2018-11-01;,citation_year=2018;,citation_fulltext_html_url=https://doi.org/10.1007/s41060-018-0124-z;,citation_issue=3;,citation_doi=10.1007/s41060-018-0124-z;,citation_volume=6;,citation_language=en;,citation_journal_title=International Journal of Data Science and Analytics;">
<meta name="citation_reference" content="citation_title=Machine Learning in Official Statistics;,citation_author=Martin Beck;,citation_author=Florian Dumpert;,citation_author=Joerg Feuerhake;">
<meta name="citation_reference" content="citation_title=A quality framework for statistical algorithms;,citation_author=Wesley Yung;,citation_author=Siu-Ming Tam;,citation_author=Bart Buelens;,citation_author=Hugh Chipman;,citation_author=Florian Dumpert;,citation_author=Gabriele Ascari;,citation_author=Fabiana Rocci;,citation_author=Joep Burger;,citation_author=InKyung Choi;,citation_publication_date=2022-01-01;,citation_cover_date=2022-01-01;,citation_year=2022;,citation_fulltext_html_url=https://content.iospress.com/articles/statistical-journal-of-the-iaos/sji210875;,citation_issue=1;,citation_doi=10.3233/SJI-210875;,citation_volume=38;,citation_language=en;,citation_journal_title=Statistical Journal of the IAOS;">
<meta name="citation_reference" content="citation_title=A quality framework for statistical algorithms;,citation_author=Wesley Yung;,citation_author=Siu-Ming Tam;,citation_author=Bart Buelens;,citation_author=Hugh Chipman;,citation_author=Florian Dumpert;,citation_author=Gabriele Ascari;,citation_author=Fabiana Rocci;,citation_author=Joep Burger;,citation_author=InKyung Choi;,citation_publication_date=2022-01;,citation_cover_date=2022-01;,citation_year=2022;,citation_issue=1;,citation_volume=38;,citation_journal_title=Statistical Journal of the IAOS;">
<meta name="citation_reference" content="citation_title=Qualitätshandbuch der Statistischen Ämter des Bundes und der Länder;,citation_author=Michael Reichelt;">
<meta name="citation_reference" content="citation_title=Data Science and Official Statistics: Toward a New Data Culture;,citation_author=Stefan Schweinfest;,citation_author=Ronald Jansen;,citation_publication_date=2021-10-28;,citation_cover_date=2021-10-28;,citation_year=2021;,citation_fulltext_html_url=https://hdsr.mitpress.mit.edu/pub/1g514ljw/release/4;,citation_issue=4;,citation_doi=10.1162/99608f92.c1237762;,citation_volume=3;,citation_language=en;,citation_journal_title=Harvard Data Science Review;">
<meta name="citation_reference" content="citation_title=Official Statistics 4.0: Verified Facts for People in the 21st Century;,citation_author=Walter J. Radermacher;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;">
<meta name="citation_reference" content="citation_title=Detecting Covariate Drift with Explanations;,citation_author=Steffen Castle;,citation_author=Robert Schwarzenberg;,citation_author=Mohsen Pourvali;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_conference_title=Natural Language Processing and Chinese Computing: 10th CCF International Conference, NLPCC 2021, Qingdao, China, October 13–17, 2021, Proceedings, Part II;,citation_conference=Springer-Verlag;">
<meta name="citation_reference" content="citation_title=Keras;,citation_author=Francois Chollet;,citation_author=others;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_publisher=https:://keras.io;">
<meta name="citation_reference" content="citation_title=TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems;,citation_author=Martin Abadi;,citation_author=Ashish Agarwal;,citation_author=Paul Barham;,citation_author=Eugene Brevdo;,citation_author=Zhifeng Chen;,citation_author=Craig Citro;,citation_author=Greg S. Corrado;,citation_author=Andy Davis;,citation_author=Jeffrey Dean;,citation_author=Matthieu Devin;,citation_author=Sanjay Ghemawat;,citation_author=Ian Goodfellow;,citation_author=Andrew Harp;,citation_author=Geoffrey Irving;,citation_author=Michael Isard;,citation_author=Yangqing Jia;,citation_author=Rafal Jozefowicz;,citation_author=Lukasz Kaiser;,citation_author=Manjunath Kudlur;,citation_author=Josh Levenberg;,citation_author=Dan Mane;,citation_author=Rajat Monga;,citation_author=Sherry Moore;,citation_author=Derek Murray;,citation_author=Chris Olah;,citation_author=Mike Schuster;,citation_author=Jonathon Shlens;,citation_author=Benoit Steiner;,citation_author=Ilya Sutskever;,citation_author=Kunal Talwar;,citation_author=Paul Tucker;,citation_author=Vincent Vanhoucke;,citation_author=Vijay Vasudevan;,citation_author=Fernanda Viegas;,citation_author=Oriol Vinyals;,citation_author=Pete Warden;,citation_author=Martin Wattenberg;,citation_author=Martin Wicke;,citation_author=Yuan Yu;,citation_author=Xiaoqiang Zheng;,citation_publication_date=2016-03;,citation_cover_date=2016-03;,citation_year=2016;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=statsmodels: Econometric and statistical modeling with python;,citation_author=Skipper Seabold;,citation_author=Josef Perktold;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_conference_title=9th Python in Science Conference;">
<meta name="citation_reference" content="citation_title=Scikit-learn: Machine Learning in Python;,citation_author=F. Pedregosa;,citation_author=G. Varoquaux;,citation_author=A. Gramfort;,citation_author=V. Michel;,citation_author=B. Thirion;,citation_author=O. Grisel;,citation_author=M. Blondel;,citation_author=P. Prettenhofer;,citation_author=R. Weiss;,citation_author=V. Dubourg;,citation_author=J. Vanderplas;,citation_author=A. Passos;,citation_author=D. Cournapeau;,citation_author=M. Brucher;,citation_author=M. Perrot;,citation_author=E. Duchesnay;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_volume=12;,citation_journal_title=Journal of Machine Learning Research;">
<meta name="citation_reference" content="citation_title=Array programming with NumPy;,citation_author=Charles R. Harris;,citation_author=K. Jarrod Millman;,citation_author=Stéfan J. Walt;,citation_author=Ralf Gommers;,citation_author=Pauli Virtanen;,citation_author=David Cournapeau;,citation_author=Eric Wieser;,citation_author=Julian Taylor;,citation_author=Sebastian Berg;,citation_author=Nathaniel J. Smith;,citation_author=Robert Kern;,citation_author=Matti Picus;,citation_author=Stephan Hoyer;,citation_author=Marten H. Kerkwijk;,citation_author=Matthew Brett;,citation_author=Allan Haldane;,citation_author=Jaime Fernández Río;,citation_author=Mark Wiebe;,citation_author=Pearu Peterson;,citation_author=Pierre Gérard-Marchant;,citation_author=Kevin Sheppard;,citation_author=Tyler Reddy;,citation_author=Warren Weckesser;,citation_author=Hameer Abbasi;,citation_author=Christoph Gohlke;,citation_author=Travis E. Oliphant;,citation_publication_date=2020-09;,citation_cover_date=2020-09;,citation_year=2020;,citation_issue=7825;,citation_volume=585;,citation_journal_title=Nature;">
<meta name="citation_reference" content="citation_title=Algorithms for Learning Regression Trees and Ensembles on Evolving Data Streams;,citation_author=Elena Ikonomovska;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_dissertation_institution=Jozef Stefan International Postgraduate School;">
<meta name="citation_reference" content="citation_title=Online Bagging and Boosting;,citation_author=N C Oza;,citation_conference_title=2005 IEEE International Conference on Systems, Man and Cybernetics;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Online bagging and boosting;,citation_author=Nikunj C Oza;,citation_author=Stuart Russell;,citation_editor=T Jaakola;,citation_editor=T Richardson;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_conference_title=8th Insternational Workshop on Artificial Intelligence and Statistics;">
<meta name="citation_reference" content="citation_title=Event labeling combining ensemble detectors and background knowledge;,citation_author=Hadi Fanaee-T;,citation_author=Joao Gama;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=2;,citation_volume=2;,citation_journal_title=Progress in Artificial Intelligence;">
<meta name="citation_reference" content="citation_title=Adaptive random forests for evolving data stream classification;,citation_author=Heitor M. Gomes;,citation_author=Albert Bifet;,citation_author=Jesse Read;,citation_author=Jean Paul Barddal;,citation_author=Fabricio Enembreck;,citation_author=Bernhard Pfharinger;,citation_author=Geoff Holmes;,citation_author=Talel Abdessalem;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=9;,citation_volume=106;,citation_journal_title=Machine Learning;">
<meta name="citation_reference" content="citation_title=Literate Programming;,citation_author=Donald E. Knuth;,citation_publication_date=1984-05;,citation_cover_date=1984-05;,citation_year=1984;,citation_fulltext_html_url=https://doi.org/10.1093/comjnl/27.2.97;,citation_issue=2;,citation_doi=10.1093/comjnl/27.2.97;,citation_issn=0010-4620;,citation_volume=27;,citation_journal_title=Comput. J.;,citation_publisher=Oxford University Press, Inc.;">
<meta name="citation_reference" content="citation_title=A Review and Taxonomy of Interactive Optimization Methods in Operations Research;,citation_author=David Meignan;,citation_author=Sigrid Knust;,citation_author=Jean-Marc Frayet;,citation_author=Gilles Pesant;,citation_author=Nicolas Gaud;,citation_publication_date=2015-09;,citation_cover_date=2015-09;,citation_year=2015;,citation_journal_title=ACM Transactions on Interactive Intelligent Systems;">
<meta name="citation_reference" content="citation_title=Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide;,citation_editor=Eva Bartz;,citation_editor=Thomas Bartz-Beielstein;,citation_editor=Martin Zaefferer;,citation_editor=Olaf Mersmann;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=In a Nutshell – The Sequential Parameter Optimization Toolbox;,citation_author=Thomas Bartz-Beielstein;,citation_author=Martin Zaefferer;,citation_author=Frederik Rehbach;,citation_publication_date=2021-12;,citation_cover_date=2021-12;,citation_year=2021;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Direct search methods: Then and now;,citation_author=R M Lewis;,citation_author=V Torczon;,citation_author=M W Trosset;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_issue=1–2;,citation_volume=124;,citation_journal_title=Journal of Computational and Applied Mathematics;">
<meta name="citation_reference" content="citation_title=Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization;,citation_author=Lisha Li;,citation_author=Kevin Jamieson;,citation_author=Giulia DeSalvo;,citation_author=Afshin Rostamizadeh;,citation_author=Ameet Talwalkar;,citation_publication_date=2016-03;,citation_cover_date=2016-03;,citation_year=2016;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Sequential Parameter Optimization;,citation_author=Thomas Bartz-Beielstein;,citation_author=Christian Lasarczyk;,citation_author=Mike Preuss;,citation_editor=B McKay;,citation_editor=others;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_conference_title=Proceedings 2005 Congress on Evolutionary Computation (CEC’05), Edinburgh, Scotland;,citation_conference=IEEE Press;">
<meta name="citation_reference" content="citation_title=Evolutionary Algorithms;,citation_author=Thomas Bartz-Beielstein;,citation_author=Jürgen Branke;,citation_author=Jörn Mehnen;,citation_author=Olaf Mersmann;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=3;,citation_volume=4;,citation_journal_title=Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery;">
<meta name="citation_reference" content="citation_title=Classification and Regression Trees;,citation_author=L Breiman;,citation_author=J H Friedman;,citation_author=R A Olshen;,citation_author=C J Stone;,citation_publication_date=1984;,citation_cover_date=1984;,citation_year=1984;">
<meta name="citation_reference" content="citation_title=Continuous inspection schemes;,citation_author=E. S. Page;,citation_publication_date=1954-06;,citation_cover_date=1954-06;,citation_year=1954;,citation_issue=1-2;,citation_volume=41;,citation_journal_title=Biometrika;">
<meta name="citation_reference" content="citation_title=Counting Large Numbers of Events in Small Registers;,citation_author=Robert Morris;,citation_publication_date=1978-10;,citation_cover_date=1978-10;,citation_year=1978;,citation_issue=10;,citation_volume=21;,citation_journal_title=Commun. ACM;">
<meta name="citation_reference" content="citation_title=Approximate Counting: A Detailed Analysis;,citation_author=Philippe Flajolet;,citation_publication_date=1985-03;,citation_cover_date=1985-03;,citation_year=1985;,citation_issue=1;,citation_volume=25;,citation_journal_title=BIT;">
<meta name="citation_reference" content="citation_title=Random Sampling with a Reservoir;,citation_author=Jeffrey S. Vitter;,citation_publication_date=1985-03;,citation_cover_date=1985-03;,citation_year=1985;,citation_issue=1;,citation_volume=11;,citation_journal_title=ACM Trans. Math. Softw.;">
<meta name="citation_reference" content="citation_title=Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem;,citation_author=Michael McCloskey;,citation_author=Neal J. Cohen;,citation_publication_date=1989-01;,citation_cover_date=1989-01;,citation_year=1989;,citation_issue=C;,citation_volume=24;,citation_journal_title=Psychology of Learning and Motivation - Advances in Research and Theory;">
<meta name="citation_reference" content="citation_title=Detection of Abrupt Changes - Theory and Application;,citation_author=Michèle Basseville;,citation_author=Igor V. Nikiforov;,citation_publication_date=1993;,citation_cover_date=1993;,citation_year=1993;">
<meta name="citation_reference" content="citation_title=An Introduction to Computational Learning Theory;,citation_author=Michael J. Kearns;,citation_author=Umesh V. Vazirani;,citation_publication_date=1994;,citation_cover_date=1994;,citation_year=1994;">
<meta name="citation_reference" content="citation_title=An Introduction to the Kalman Filter;,citation_author=Greg Welch;,citation_author=Gary Bishop;,citation_publication_date=1995;,citation_cover_date=1995;,citation_year=1995;">
<meta name="citation_reference" content="citation_title=The Space Complexity of Approximating the Frequency Moments;,citation_author=Noga Alon;,citation_author=Yossi Matias;,citation_author=Mario Szegedy;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_conference_title=Proceedings of the Twenty-Eighth Annual ACM Symposium on Theory of Computing;,citation_conference=Association for Computing Machinery;,citation_series_title=STOC ’96;">
<meta name="citation_reference" content="citation_title=SPLICE-2 Comparative Evaluation: Electricity Pricing;,citation_author=Michael Harries;,citation_author=U Nsw-cse-tr;,citation_author=New South Wales;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;">
<meta name="citation_reference" content="citation_title=Mining high-speed data streams;,citation_author=Pedro M. Domingos;,citation_author=Geoff Hulten;,citation_editor=Raghu Ramakrishnan;,citation_editor=Salvatore J. Stolfo;,citation_editor=Roberto J. Bayardo;,citation_editor=Ismail Parsa;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_conference_title=Proceedings of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining, Boston, MA, USA, August 20-23, 2000;,citation_conference=ACM;">
<meta name="citation_reference" content="citation_title=Mining Time-Changing Data Streams;,citation_author=Geoff Hulten;,citation_author=Laurie Spencer;,citation_author=Pedro Domingos;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_conference_title=Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;,citation_conference=Association for Computing Machinery;,citation_series_title=KDD ’01;">
<meta name="citation_reference" content="citation_title=A Streaming Ensemble Algorithm (SEA) for Large-Scale Classification;,citation_author=W. Nick Street;,citation_author=YongSeog Kim;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_conference_title=Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;,citation_conference=Association for Computing Machinery;,citation_series_title=KDD ’01;">
<meta name="citation_reference" content="citation_title=3D Data Management: Controlling Data Volume, Velocity, and Variety;,citation_author=Douglas Laney;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_technical_report_institution=META Group;">
<meta name="citation_reference" content="citation_title=Models and Issues in Data Stream Systems;,citation_author=Brian Babcock;,citation_author=Shivnath Babu;,citation_author=Mayur Datar;,citation_author=Rajeev Motwani;,citation_author=Jennifer Widom;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_conference_title=Proceedings of the 21st ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems;,citation_conference=ACM;,citation_series_title=PODS ’02;">
<meta name="citation_reference" content="citation_title=A New Approximate Maximal Margin Classification Algorithm;,citation_author=Claudio Gentile;,citation_publication_date=2002-03;,citation_cover_date=2002-03;,citation_year=2002;,citation_volume=2;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=The Design and Analysis of Computer Experiments;,citation_author=T J Santner;,citation_author=B J Williams;,citation_author=W I Notz;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;">
<meta name="citation_reference" content="citation_title=Learning with drift detection;,citation_author=João Gama;,citation_author=Pedro Medas;,citation_author=Gladys Castillo;,citation_author=Pedro Rodrigues;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_conference_title=In SBIA Brazilian Symposium on Artificial Intelligence;,citation_conference=Springer Verlag;">
<meta name="citation_reference" content="citation_title=Learning with Drift Detection;,citation_author=João Gama;,citation_author=Pedro Medas;,citation_author=Gladys Castillo;,citation_author=Pedro Rodrigues;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_inbook_title=Parallel Problem Solving from Nature - PPSN XIII - 13th International Conference, Ljubljana, Slovenia, September 13-17, 2014. Proceedings;">
<meta name="citation_reference" content="citation_title=Learning with Drift Detection;,citation_author=João Gama;,citation_author=Pedro Medas;,citation_author=Gladys Castillo;,citation_author=Pedro Rodrigues;,citation_editor=Ana L. C. Bazzan;,citation_editor=Sofiane Labidi;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_conference_title=Advances in Artificial Intelligence – SBIA 2004;,citation_conference=Springer Berlin Heidelberg;">
<meta name="citation_reference" content="citation_title=Statistical Analysis of Massive Data Streams: Proceedings of a Workshop;,citation_editor=Sallie Keller-McNulty;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;">
<meta name="citation_reference" content="citation_title=Data Mining: Practical Machine Learning Tools and Techniques;,citation_author=Ian H. Witten;,citation_author=Eibe Frank;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_series_title=The Morgan Kaufmann Series in Data Management Systems;">
<meta name="citation_reference" content="citation_title=Towards Generic Pattern Mining;,citation_author=Mohammed Javeed Zaki;,citation_author=Nagender Parimi;,citation_author=Nilanjana De;,citation_author=Feng Gao;,citation_author=Benjarath Phoophakdee;,citation_author=Joe Urban;,citation_author=Vineet Chaoji;,citation_author=Mohammad Al Hasan;,citation_author=Saeed Salem;,citation_editor=Bernhard Ganter;,citation_editor=Robert Godin;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_volume=3403;,citation_conference_title=Formal Concept Analysis, Third International Conference, ICFCA 2005, Lens, France, February 14-18, 2005, Proceedings;,citation_conference=Springer;,citation_series_title=Lecture Notes in Computer Science;">
<meta name="citation_reference" content="citation_title=Mining Data Streams: A Review;,citation_author=Mohamed Medhat Gaber;,citation_author=Arkady Zaslavsky;,citation_author=Shonali Krishnaswamy;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_volume=34;,citation_journal_title=SIGMOD Rec.;">
<meta name="citation_reference" content="citation_title=Early drift detection method;,citation_author=Manuel Baena-Garcıa;,citation_author=José Campo-Ávila;,citation_author=Raúl Fidalgo;,citation_author=Albert Bifet;,citation_author=R Gavalda;,citation_author=Rafael Morales-Bueno;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_volume=6;,citation_conference_title=Fourth international workshop on knowledge discovery from data streams;">
<meta name="citation_reference" content="citation_title=Online Passive-Aggressive Algorithms;,citation_author=Koby Crammer;,citation_author=Ofer Dekel;,citation_author=Joseph Keshet;,citation_author=Shai Shalev-Shwartz;,citation_author=Yoram Singer;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=19;,citation_volume=7;,citation_journal_title=Journal of Machine Learning Research;">
<meta name="citation_reference" content="citation_title=Data Streams – Models and Algorithms;,citation_editor=Charu Aggarwal;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;">
<meta name="citation_reference" content="citation_title=Learning from Time-Changing Data with Adaptive Windowing;,citation_author=Albert Bifet;,citation_author=Ricard Gavaldà;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_conference_title=Proceedings of the 2007 SIAM International Conference on Data Mining (SDM);">
<meta name="citation_reference" content="citation_title=Learning from time-changing data with adaptive windowing;,citation_author=Albert Bifet;,citation_author=Ricard Gavalda;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_volume=7;,citation_conference_title=Proceedings of the 2007 SIAM international conference on data mining;,citation_conference=SIAM;">
<meta name="citation_reference" content="citation_title=A Survey of Classification Methods in Data Streams;,citation_author=Mohamed Gaber;,citation_author=Arkady Zaslavsky;,citation_author=Shonali Krishnaswamy;,citation_editor=Charu Aggarwal;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_inbook_title=Data Streams – Models and Algorithms;">
<meta name="citation_reference" content="citation_title=Use of Hoeffding trees in concept based data stream mining;,citation_author=Stefan Hoeglinger;,citation_author=Russel Pears;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_journal_title=2007 Third International Conference on Information and Automation for Sustainability;">
<meta name="citation_reference" content="citation_title=Detecting concept drift using statistical testing;,citation_author=Kyosuke Nishida;,citation_author=Koichiro Yamauchi;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_conference_title=International conference on discovery science;,citation_conference=Springer;">
<meta name="citation_reference" content="citation_title=Olindda: A cluster-based approach for detecting novelty and concept drift in data streams;,citation_author=Eduardo J Spinosa;,citation_author=André Ponce Leon F. de Carvalho;,citation_author=Joao Gama;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_conference_title=Proceedings of the 2007 ACM symposium on Applied computing;">
<meta name="citation_reference" content="citation_title=Statistical Quality Control;,citation_author=Douglas C Montgomery;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;">
<meta name="citation_reference" content="citation_title=Adaptive Learning from Evolving Data Streams;,citation_author=Albert Bifet;,citation_author=Ricard Gavaldà;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=Proceedings of the 8th International Symposium on Intelligent Data Analysis: Advances in Intelligent Data Analysis VIII;,citation_conference=Springer-Verlag;,citation_series_title=IDA ’09;">
<meta name="citation_reference" content="citation_title=New Ensemble Methods for Evolving Data Streams;,citation_author=Albert Bifet;,citation_author=Geoff Holmes;,citation_author=Bernhard Pfahringer;,citation_author=Richard Kirkby;,citation_author=Ricard Gavaldà;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;,citation_conference=Association for Computing Machinery;,citation_series_title=KDD ’09;">
<meta name="citation_reference" content="citation_title=Adaptive concept drift detection;,citation_author=Anton Dries;,citation_author=Ulrich Rückert;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=5-6;,citation_volume=2;,citation_journal_title=Stat. Anal. Data Min.;">
<meta name="citation_reference" content="citation_title=Issues in Evaluation of Stream Learning Algorithms;,citation_author=João Gama;,citation_author=Raquel Sebastião;,citation_author=Pedro Pereira Rodrigues;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;,citation_conference=Association for Computing Machinery;,citation_series_title=KDD ’09;">
<meta name="citation_reference" content="citation_title=Stream Data Processing: A Quality of Service Perspective;,citation_author=Qingchun Jiang;,citation_author=Sharma Chakravarthy;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;">
<meta name="citation_reference" content="citation_title=Probabilistic Counting with Randomized Storage;,citation_author=Benjamin Van Durme;,citation_author=Ashwin Lall;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=Proceedings of the 21st International Joint Conference on Artificial Intelligence;,citation_conference=Morgan Kaufmann Publishers Inc.;,citation_series_title=IJCAI’09;">
<meta name="citation_reference" content="citation_title=Adaptive Stream Mining: Pattern Learning and Mining from Evolving Data Streams;,citation_author=Albert Bifet;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_volume=207;,citation_series_title=Frontiers in Artificial Intelligence and Applications;">
<meta name="citation_reference" content="citation_title=We’re not in kansas anymore: detecting domain changes in streams;,citation_author=Mark Dredze;,citation_author=Tim Oates;,citation_author=Christine Piatko;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_conference_title=Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing;">
<meta name="citation_reference" content="citation_title=Large-Scale Inference: Empirical Bayes Methods for Estimation, Testing, and Prediction (Institute of Mathematical Statistics Monographs);,citation_author=Bradley Efron;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;">
<meta name="citation_reference" content="citation_title=Knowledge Discovery from Data Streams;,citation_author=João Gama;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_series_title=Chapman and Hall / CRC Data Mining and Knowledge Discovery Series;">
<meta name="citation_reference" content="citation_title=A DCT based approach for detecting novelty and concept drift in data streams;,citation_author=Morteza Zi Hayat;,citation_author=Mahmoud Reza Hashemi;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_conference_title=2010 International Conference of Soft Computing and Pattern Recognition;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Benchmarking Stream Clustering Algorithms within the MOA Framework;,citation_author=Philipp Kranen;,citation_author=Hardy Kremer;,citation_author=Timm Jansen;,citation_author=Thomas Seidl;,citation_author=Albert Bifet;,citation_author=Geoff Holmes;,citation_author=Bernhard Pfahringer;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_conference_title=16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD 2010), Washington, DC, USA;">
<meta name="citation_reference" content="citation_title=MOA: Massive Online Analysis;,citation_author=Albert Bifet;,citation_author=Geoff Holmes;,citation_author=Richard Kirkby;,citation_author=Bernhard Pfahringer;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_volume=99;,citation_journal_title=Journal of Machine Learning Research;">
<meta name="citation_reference" content="citation_title=Hellinger distance based drift detection for nonstationary environments;,citation_author=Gregory Ditzler;,citation_author=Robi Polikar;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_conference_title=2011 IEEE symposium on computational intelligence in dynamic and uncertain environments (CIDUE);,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Classification and novel class detection in concept-drifting data streams under time constraints;,citation_author=Mohammad Masud;,citation_author=Jing Gao;,citation_author=Latifur Khan;,citation_author=Jiawei Han;,citation_author=Bhavani M Thuraisingham;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=6;,citation_volume=23;,citation_journal_title=IEEE Transactions on Knowledge and Data Engineering;">
<meta name="citation_reference" content="citation_title=New drift detection method for data streams;,citation_author=Parinaz Sobhani;,citation_author=Hamid Beigy;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_conference_title=International conference on adaptive and intelligent systems;,citation_conference=Springer;">
<meta name="citation_reference" content="citation_title=birch: Dealing With Very Large Datasets Using BIRCH;,citation_author=Lysiane Charest;,citation_author=Justin Harrington;,citation_author=Matias Salibian-Barrera;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;">
<meta name="citation_reference" content="citation_title=Synopses for Massive Data: Samples, Histograms, Wavelets, Sketches;,citation_author=Graham Cormode;,citation_author=Minos Garofalakis;,citation_author=Peter J. Haas;,citation_author=Chris Jermaine;,citation_publication_date=2012-01;,citation_cover_date=2012-01;,citation_year=2012;,citation_issue=1–3;,citation_volume=4;,citation_journal_title=Found. Trends Databases;">
<meta name="citation_reference" content="citation_title=Detection of concept drift for learning from stream data;,citation_author=Jeonghoon Lee;,citation_author=Frederic Magoules;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_conference_title=2012 IEEE 14th International Conference on High Performance Computing and Communication &amp;amp;amp; 2012 IEEE 9th International Conference on Embedded Software and Systems;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=mlbench: Machine Learning Benchmark Problems;,citation_author=Friedrich Leisch;,citation_author=Evgenia Dimitriadou;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;">
<meta name="citation_reference" content="citation_title=A unifying view on dataset shift in classification;,citation_author=Jose G. Moreno-Torres;,citation_author=Troy Raeder;,citation_author=Rocı́o Alaı́z-Rodrı́guez;,citation_author=Nitesh V. Chawla;,citation_author=Francisco Herrera;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=1;,citation_volume=45;,citation_journal_title=Pattern Recognit.;">
<meta name="citation_reference" content="citation_title=HadoopStreaming: Utilities for Using R Scripts in Hadoop Streaming;,citation_author=David S. Rosenberg;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;">
<meta name="citation_reference" content="citation_title=Exponentially weighted moving average charts for detecting concept drift;,citation_author=Gordon J Ross;,citation_author=Niall M Adams;,citation_author=Dimitris K Tasoulis;,citation_author=David J Hand;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=2;,citation_volume=33;,citation_journal_title=Pattern recognition letters;">
<meta name="citation_reference" content="citation_title=An efficient method of building an ensemble of classifiers in streaming data;,citation_author=Joung Woo Ryu;,citation_author=Mehmed M Kantardzic;,citation_author=Myung-Won Kim;,citation_author=A Ra Khil;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_conference_title=International Conference on Big Data Analytics;,citation_conference=Springer;">
<meta name="citation_reference" content="citation_title=rlecuyer: R Interface to RNG With Multiple Streams;,citation_author=Hana Sevcikova;,citation_author=Tony Rossini;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;">
<meta name="citation_reference" content="citation_title=Machine Learning that Matters;,citation_author=Kiri Wagstaff;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;">
<meta name="citation_reference" content="citation_title=CD-MOA: Change Detection Framework for Massive Online Analysis;,citation_author=Albert Bifet;,citation_author=Jesse Read;,citation_author=Bernhard Pfahringer;,citation_author=Geoff Holmes;,citation_author=Indrė Žliobaitė;,citation_editor=Allan Tucker;,citation_editor=Frank Höppner;,citation_editor=Arno Siebes;,citation_editor=Stephen Swift;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_conference_title=Advances in Intelligent Data Analysis XII;,citation_conference=Springer Berlin Heidelberg;">
<meta name="citation_reference" content="citation_title=Novelty detection algorithm for data streams multi-class problems;,citation_author=Elaine R Faria;,citation_author=João Gama;,citation_author=André CPLF Carvalho;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_conference_title=Proceedings of the 28th annual ACM symposium on applied computing;">
<meta name="citation_reference" content="citation_title=Turning Big Data into Tiny Data: Constant-Size Coresets for k-Means, PCA and Projective Clustering;,citation_author=Dan Feldman;,citation_author=Melanie Schmidt;,citation_author=Christian Sohler;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_conference_title=Proceedings of the Twenty-Fourth Annual ACM-SIAM Symposium on Discrete Algorithms;,citation_conference=Society for Industrial; Applied Mathematics;,citation_series_title=SODA ’13;">
<meta name="citation_reference" content="citation_title=On evaluating stream learning algorithms;,citation_author=João Gama;,citation_author=Raquel Sebastião;,citation_author=Pedro Pereira Rodrigues;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=3;,citation_volume=90;,citation_journal_title=Machine Learning;">
<meta name="citation_reference" content="citation_title=Scalable Strategies for Computing with Massive Data;,citation_author=Michael J. Kane;,citation_author=John Emerson;,citation_author=Stephen Weston;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=14;,citation_volume=55;,citation_journal_title=Journal of Statistical Software;">
<meta name="citation_reference" content="citation_title=RStorm: Simulate and Develop Streaming Processing in R;,citation_author=Maurits Kaptein;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;">
<meta name="citation_reference" content="citation_title=Drift detection using uncertainty distribution divergence;,citation_author=Patrick Lindstrom;,citation_author=Brian Mac Namee;,citation_author=Sarah Jane Delany;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=1;,citation_volume=4;,citation_journal_title=Evolving Systems;">
<meta name="citation_reference" content="citation_title=Ad Click Prediction: A View from the Trenches;,citation_author=H. Brendan McMahan;,citation_author=Gary Holt;,citation_author=D. Sculley;,citation_author=Michael Young;,citation_author=Dietmar Ebner;,citation_author=Julian Grady;,citation_author=Lan Nie;,citation_author=Todd Phillips;,citation_author=Eugene Davydov;,citation_author=Daniel Golovin;,citation_author=Sharat Chikkerur;,citation_author=Dan Liu;,citation_author=Martin Wattenberg;,citation_author=Arnar Mar Hrafnkelsson;,citation_author=Tom Boulos;,citation_author=Jeremy Kubica;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_conference_title=Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;,citation_conference=Association for Computing Machinery;,citation_series_title=KDD ’13;">
<meta name="citation_reference" content="citation_title=Data Stream Clustering: A Survey.;,citation_author=Jonathan A. Silva;,citation_author=Elaine R. Faria;,citation_author=Rodrigo C. Barros;,citation_author=Eduardo R. Hruschka;,citation_author=Andre Carvalho;,citation_author=Joao Gama;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=1;,citation_volume=46;,citation_journal_title=ACM Computer Surveys;">
<meta name="citation_reference" content="citation_title=ff: Memory-efficient Storage of Large Data on Disk and Fast Access Functions;,citation_author=Daniel Adler;,citation_author=Christian Gläser;,citation_author=Oleg Nenadic;,citation_author=Jens Oehlschlägel;,citation_author=Walter Zucchini;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=factas: Data Mining Methods for Data Streams;,citation_author=Romain Bar;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=streamR: Access to Twitter Streaming API via R;,citation_author=Pablo Barbera;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=DBI: R Database Interface;,citation_author=R Special Interest Group on Databases;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=Concept drift detection through resampling;,citation_author=Maayan Harel;,citation_author=Shie Mannor;,citation_author=Ran El-Yaniv;,citation_author=Koby Crammer;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_conference_title=International conference on machine learning;,citation_conference=PMLR;">
<meta name="citation_reference" content="citation_title=PCA feature extraction for change detection in multidimensional unlabeled data;,citation_author=Ludmila I Kuncheva;,citation_author=William J Faithfull;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=1;,citation_volume=25;,citation_journal_title=IEEE transactions on neural networks and learning systems;">
<meta name="citation_reference" content="citation_title=Mining of Massive Datasets;,citation_author=Jure Leskovec;,citation_author=Anand Rajaraman;,citation_author=Jeffery D. Ullman;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=RMOA: Connect R with MOA to perform streaming classifications;,citation_author=Jan Wijffels;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=A Survey on Concept Drift Adaptation;,citation_author=João Gama;,citation_author=Indrundefined Žliobaitundefined;,citation_author=Albert Bifet;,citation_author=Mykola Pechenizkiy;,citation_author=Abdelhamid Bouchachia;,citation_publication_date=2014-03;,citation_cover_date=2014-03;,citation_year=2014;,citation_issue=4;,citation_volume=46;,citation_journal_title=ACM Comput. Surv.;">
<meta name="citation_reference" content="citation_title=Graph Stream Algorithms: A Survey;,citation_author=Andrew McGregor;,citation_publication_date=2014-05;,citation_cover_date=2014-05;,citation_year=2014;,citation_issue=1;,citation_volume=43;,citation_journal_title=SIGMOD Rec.;">
<meta name="citation_reference" content="citation_title=RStorm: Developing and Testing Streaming Algorithms in R;,citation_author=Maurits Kaptein;,citation_publication_date=2014-06;,citation_cover_date=2014-06;,citation_year=2014;,citation_issue=1;,citation_volume=6;,citation_journal_title=The R Journal;">
<meta name="citation_reference" content="citation_title=SNAP Datasets: Stanford Large Network Dataset Collection;,citation_author=Jure Leskovec;,citation_author=Andrej Krevl;,citation_publication_date=2014-06;,citation_cover_date=2014-06;,citation_year=2014;,citation_publisher=http://snap.stanford.edu/data;">
<meta name="citation_reference" content="citation_title=Questioning the Lambda Architecture;,citation_author=Jay Kreps;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=Sketching as a Tool for Numerical Linear Algebra;,citation_author=David P. Woodruff;,citation_publication_date=2014-10;,citation_cover_date=2014-10;,citation_year=2014;,citation_issue=1–2;,citation_volume=10;,citation_journal_title=Found. Trends Theor. Comput. Sci.;">
<meta name="citation_reference" content="citation_title=Modeling concept drift: A probabilistic graphical model based approach;,citation_author=Hanen Borchani;,citation_author=Ana Maria Martinez;,citation_author=Andrés R. Masegosa;,citation_author=Helge Langseth;,citation_author=Thomas Dyhre Nielsen;,citation_author=Antonio Salmerón;,citation_author=Antonio Fernández;,citation_author=Anders Læsø Madsen;,citation_author=Ramón Sáez;,citation_editor=Elisa Fromont;,citation_editor=Tijl De Bie;,citation_editor=Matthijs Leeuwen;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=Advances in Intelligent Data Analysis XIV;,citation_conference=Springer;,citation_series_title=Lecture Notes in Computer Science;">
<meta name="citation_reference" content="citation_title=twitteR: R Based Twitter Client;,citation_author=Jeff Gentry;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=rEMM: Extensible Markov Model for Data Stream Clustering in R;,citation_author=Michael Hahsler;,citation_author=Margaret H. Dunham;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=streamMOA: Interface for MOA Stream Clustering Algorithms;,citation_author=Michael Hahsler;,citation_author=Matthew Bolanos;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=rstream: Streams of Random Numbers;,citation_author=Josef Leydold;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=Big Data: Principles and Best Practices of Scalable Realtime Data Systems;,citation_author=Nathan Marz;,citation_author=James Warren;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=A pca-based change detection framework for multidimensional data streams: Change detection in multidimensional data streams;,citation_author=Abdulhakim A Qahtan;,citation_author=Basma Alharbi;,citation_author=Suojin Wang;,citation_author=Xiangliang Zhang;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;">
<meta name="citation_reference" content="citation_title=Concept Drift Detection for Streaming Data;,citation_author=Heng Wang;,citation_author=Zubin Abraham;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=International Joint Conference on Neural Networks (IJCNN);">
<meta name="citation_reference" content="citation_title=koaning.io: Linear Models Solving Non-Linear Problems;,citation_author=Vincent Warmerdam;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=Experimental Algorithmics Applied to On-line Machine Learning;,citation_author=Thomas Bartz-Beielstein;,citation_editor=Gregor Papa;,citation_editor=Marjan Mernik;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_conference_title=Bioinspired Optimization Methods and their Applications;">
<meta name="citation_reference" content="citation_title=quantmod: Quantitative Financial Modelling Framework;,citation_author=Jeffrey A. Ryan;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;">
<meta name="citation_reference" content="citation_title=A grid density based framework for classifying streaming data in the presence of concept drift;,citation_author=Tegjyot Singh Sethi;,citation_author=Mehmed Kantardzic;,citation_author=Hanquing Hu;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_issue=1;,citation_volume=46;,citation_journal_title=Journal of Intelligent Information Systems;">
<meta name="citation_reference" content="citation_title=rJava: Low-level R to Java interface;,citation_author=Simon Urbanek;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;">
<meta name="citation_reference" content="citation_title=SparkR: Scaling R Programs with Spark;,citation_author=Shivaram Venkataraman;,citation_author=Zongheng Yang;,citation_author=Davies Liu;,citation_author=Eric Liang;,citation_author=Hossein Falaki;,citation_author=Xiangrui Meng;,citation_author=Reynold Xin;,citation_author=Ali Ghodsi;,citation_author=Michael Franklin;,citation_author=Ion Stoica;,citation_author=Matei Zaharia;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_conference_title=Proceedings of the 2016 International Conference on Management of Data;,citation_conference=Association for Computing Machinery;,citation_series_title=SIGMOD ’16;">
<meta name="citation_reference" content="citation_title=koaning.io: Bayesian/Streaming Algorithms;,citation_author=Vincent Warmerdam;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;">
<meta name="citation_reference" content="citation_title=Outlier Analysis;,citation_author=Charu C Aggarwal;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;">
<meta name="citation_reference" content="citation_title=Video Popularity Prediction in Data Streams Based on Context-Independent Features;,citation_author=Vitor Silva;,citation_author=Ana Trindade Winck;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_conference_title=Proceedings of the Symposium on Applied Computing;,citation_conference=Association for Computing Machinery;,citation_series_title=SAC ’17;">
<meta name="citation_reference" content="citation_title=Einsatz von Machine-Learning-Verfahren in amtlichen Unternehmensstatistiken;,citation_author=Florian Dumpert;,citation_author=Martin Beck;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=2;,citation_volume=11;,citation_journal_title=AStA Wirtschafts- und Sozialstatistisches Archiv;">
<meta name="citation_reference" content="citation_title=Introduction to stream: An Extensible Framework for Data Stream Clustering Research with R;,citation_author=Michael Hahsler;,citation_author=Matthew Bolaños;,citation_author=John Forrest;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=14;,citation_volume=76;,citation_journal_title=Journal of Statistical Software;">
<meta name="citation_reference" content="citation_title=stream: Infrastructure for Data Stream Mining;,citation_author=Michael Hahsler;,citation_author=Matthew Bolaños;,citation_author=John Forrest;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;">
<meta name="citation_reference" content="citation_title=Design and Analysis of Experiments;,citation_author=D C Montgomery;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;">
<meta name="citation_reference" content="citation_title=Time Series Forecasting in the Presence of Concept Drift: A PSO-based Approach;,citation_author=Gustavo H. F. M. Oliveira;,citation_author=Rodolfo C. Cavalcante;,citation_author=George G. Cabral;,citation_author=Leandro L. Minku;,citation_author=Adriano L. I. Oliveira;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_conference_title=2017 IEEE 29th International Conference on Tools with Artificial Intelligence (ICTAI);">
<meta name="citation_reference" content="citation_title=United Nations Global Pulse. Harnessing big data for development and humanitarian action.;,citation_author=United Nations;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;">
<meta name="citation_reference" content="citation_title=koaning.io: Passive Agressive Algorithms;,citation_author=Vincent Warmerdam;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;">
<meta name="citation_reference" content="citation_title=On the Reliable Detection of Concept Drift from Streaming Unlabeled Data;,citation_author=Tegjyot Singh Sethi;,citation_author=Mehmed Kantardzic;,citation_publication_date=2017-03;,citation_cover_date=2017-03;,citation_year=2017;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Proof of Concept Machine Learning - Abschlussbericht;,citation_author=Martin Beck;,citation_author=Florian Dumpert;,citation_author=Jörg Feuerhake;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_technical_report_institution=Statistisches Bundesamt (Destatis);">
<meta name="citation_reference" content="citation_title=Machine Learning for Data Streams with Practical Examples in MOA;,citation_author=Albert Bifet;,citation_author=Ricard Gavalda;,citation_author=Geoff Holmes;,citation_author=Bernhard Pfahringer;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;">
<meta name="citation_reference" content="citation_title=Lifelong Machine Learning;,citation_author=Zhiyuan Chen;,citation_author=Bing Liu;,citation_author=Ronald Brachman;,citation_author=Peter Stone;,citation_author=Francesca Rossi;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;">
<meta name="citation_reference" content="citation_title=Incremental on-line learning: A review and comparison of state of the art algorithms;,citation_author=Viktor Losing;,citation_author=Barbara Hammer;,citation_author=Heiko Wersing;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_volume=275;,citation_journal_title=Neurocomputing;">
<meta name="citation_reference" content="citation_title=Extremely Fast Decision Tree;,citation_author=Chaitanya Manapragada;,citation_author=Geoffrey I. Webb;,citation_author=Mahsa Salehi;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_conference_title=Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;,citation_conference=Association for Computing Machinery;,citation_series_title=KDD ’18;">
<meta name="citation_reference" content="citation_title=An evaluation of data stream clustering algorithms;,citation_author=Stratos Mansalis;,citation_author=Eirini Ntoutsi;,citation_author=Nikos Pelekis;,citation_author=Yannis Theodoridis;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=4;,citation_volume=11;,citation_journal_title=Statistical Analysis and Data Mining: The ASA Data Science Journal;">
<meta name="citation_reference" content="citation_title=koaning.io: How to win with simple, even linear, models;,citation_author=Vincent Warmerdam;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;">
<meta name="citation_reference" content="citation_title=Anomaly Detection in Manufacturing Systems Using Structured Neural Networks;,citation_author=J. Liu;,citation_author=J. Guo;,citation_author=P. V. Orlik;,citation_author=M. Shibata;,citation_author=D. Nakahara;,citation_author=S. Mii;,citation_author=M. Takac;,citation_publication_date=2018-07;,citation_cover_date=2018-07;,citation_year=2018;,citation_technical_report_institution=MITSUBISHI ELECTRIC RESEARCH LABORATORIES;">
<meta name="citation_reference" content="citation_title=Industrial Internet of Things Based Ransomware Detection Using Stacked Variational Neural Network;,citation_author=Muna Al-Hawawreh;,citation_author=Elena Sitnikova;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_conference_title=Proceedings of the 3rd International Conference on Big Data and Internet of Things;,citation_conference=Association for Computing Machinery;,citation_series_title=BDIOT 2019;">
<meta name="citation_reference" content="citation_title=Evaluation of Cognitive Architectures for Cyber-Physical Production Systems;,citation_author=Andreas Bunte;,citation_author=Andreas Fischbach;,citation_author=Jan Strohschein;,citation_author=Thomas Bartz-Beielstein;,citation_author=Heide Faeskorn-Woyke;,citation_author=Oliver Niggemann;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_conference_title=24th IEEE International Conference on Emerging Technologies and Factory Automation, ETFA 2019, Zaragoza, Spain, September 10-13, 2019;">
<meta name="citation_reference" content="citation_title=Nowcasting: Ein Echtzeit-Indikator für die Konjunkturanalyse;,citation_author=Charlotte Senftleben;,citation_author=Till Strohsal;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;">
<meta name="citation_reference" content="citation_title=koaning.io: The Future of Data Science is Past;,citation_author=Vincent Warmerdam;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;">
<meta name="citation_reference" content="citation_title=Forecasting inflation with online prices;,citation_author=Diego Aparicio;,citation_author=Manuel I. Bertolotto;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_issue=2;,citation_volume=36;,citation_journal_title=International Journal of Forecasting;">
<meta name="citation_reference" content="citation_title=CAAI—a cognitive architecture to introduce artificial intelligence in cyber-physical production systems;,citation_author=Andreas Fischbach;,citation_author=Jan Strohschein;,citation_author=Andreas Bunte;,citation_author=Jörg Stork;,citation_author=Heide Faeskorn-Woyke;,citation_author=Natalia Moriz;,citation_author=Thomas Bartz-Beielstein;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_issue=1;,citation_volume=111;,citation_journal_title=The International Journal of Advanced Manufacturing Technology;">
<meta name="citation_reference" content="citation_title=Delayed labelling evaluation for data streams;,citation_author=Maciej Grzenda;,citation_author=Heitor Murilo Gomes;,citation_author=Albert Bifet;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_issue=5;,citation_volume=34;,citation_journal_title=Data Mining and Knowledge Discovery;">
<meta name="citation_reference" content="citation_title=Stream Data Mining: Algorithms and Their Probabilistic Properties;,citation_editor=Leszek Rutkowski;,citation_editor=Maciej Jaworski;,citation_editor=Piotr Duda;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_series_title=Studies in Big Data;">
<meta name="citation_reference" content="citation_title=Loghub: A Large Collection of System Log Datasets towards Automated Log Analytics;,citation_author=Shilin He;,citation_author=Jieming Zhu;,citation_author=Pinjia He;,citation_author=Michael R. Lyu;,citation_publication_date=2020-08;,citation_cover_date=2020-08;,citation_year=2020;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Nowcasting German GDP: Foreign factors, financial markets, and model averaging;,citation_author=Paolo Andreini;,citation_author=Thomas Hasenzagl;,citation_author=Lucrezia Reichlin;,citation_author=Charlotte Senftleben-König;,citation_author=Till Strohsal;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_journal_title=International Journal of Forecasting;">
<meta name="citation_reference" content="citation_title=Modelling the COVID-19 Virus Evolution With Incremental Machine Learning;,citation_author=Andrés L. Suárez-Cetrulo;,citation_author=Ankit Kumar;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;">
<meta name="citation_reference" content="citation_title=Machine Learning for Time-Series with Python: Forecast, predict, and detect;,citation_author=Den Auffarth;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;">
<meta name="citation_reference" content="citation_title=Machine Learning in der amtlichen Statistik - Ergebnisse und Bewertung eines internationalen Projekts;,citation_author=Florian Dumpert;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_technical_report_institution=Statistisches Bundesamt (Destatis);,citation_technical_report_number=4;">
<meta name="citation_reference" content="citation_title=Recurring concept memory management in data streams: exploiting data stream concept evolution to improve performance and transparency;,citation_author=Ben Halstead;,citation_author=Yun Sing Koh;,citation_author=Patricia Riddle;,citation_author=Russel Pears;,citation_author=Mykola Pechenizkiy;,citation_author=Albert Bifet;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_issue=3;,citation_volume=35;,citation_journal_title=Data Mining and Knowledge Discovery;">
<meta name="citation_reference" content="citation_title=Soziale Marktwirtschaft in der digitalen Zukunft: Foresight-Bericht Strategischer Vorausschauprozess des BMWi;,citation_author=Dirk Holtmannspötter;,citation_author=Ulrich Heimeshoff;,citation_author=Justus Haucap;,citation_author=Ina Loebert;,citation_author=Christoph Busch;,citation_author=Andreas Hoffknecht;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_technical_report_institution=VDI Technologiezentrum GmbH im Auftrag des Bundesministerium für Wirtschaft und Energie;">
<meta name="citation_reference" content="citation_title=River: machine learning for streaming data in Python;,citation_author=Jacob Montiel;,citation_author=Max Halford;,citation_author=Saulo Martiello Mastelini;,citation_author=Geoffrey Bolmier;,citation_author=Raphael Sourty;,citation_author=Robin Vaysse;,citation_author=Adil Zouitine;,citation_author=Heitor Murilo Gomes;,citation_author=Jesse Read;,citation_author=Talel Abdessalem;,citation_author=others;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;">
<meta name="citation_reference" content="citation_title=Practical Machine Learning for Streaming Data with Python;,citation_author=Sayan Putatunda;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;">
<meta name="citation_reference" content="citation_title=Infrerring Concept Drift Without Labeled Data;,citation_author=Andrew Reed;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_technical_report_institution=Cloudera Fast Forward Labs;,citation_technical_report_number=FF21;">
<meta name="citation_reference" content="citation_title=Cognitive capabilities for the CAAI in cyber-physical production systems;,citation_author=Jan Strohschein;,citation_author=Andreas Fischbach;,citation_author=Andreas Bunte;,citation_author=Heide Faeskorn-Woyke;,citation_author=Natalia Moriz;,citation_author=Thomas Bartz-Beielstein;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_journal_title=The International Journal of Advanced Manufacturing Technology;">
<meta name="citation_reference" content="citation_title=FARF: A Fair and Adaptive Random Forests Classifier;,citation_author=Wenbin Zhang;,citation_author=Albert Bifet;,citation_author=Xiangliang Zhang;,citation_author=Jeremy C. Weiss;,citation_author=Wolfgang Nejdl;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_conference_title=Advances in Knowledge Discovery and Data Mining: 25th Pacific-Asia Conference, PAKDD 2021, Virtual Event, May 11–14, 2021, Proceedings, Part II;,citation_conference=Springer-Verlag;">
<meta name="citation_reference" content="citation_title=Modelling the COVID-19 virus evolution with Incremental Machine Learning;,citation_author=Andrés L. Suárez-Cetrulo;,citation_author=Ankit Kumar;,citation_author=Luis Miralles-Pechuán;,citation_publication_date=2021-04;,citation_cover_date=2021-04;,citation_year=2021;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Online Learning and Active Learning: A Comparative Study of Passive-Aggressive Algorithm With Support Vector Machine (SVM);,citation_author=K. I Ezukwoke;,citation_author=S. J Zareian;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_issue=3;,citation_volume=21;,citation_journal_title=Journal of Higher Education Theory and Practice;">
<meta name="citation_reference" content="citation_title=Digitale Ordnungspolitik – Wirtschaftspolitik daten- und evidenzbasiert weiterentwickeln;,citation_author=Philipp Steinberg;,citation_author=Nils Börnsen;,citation_author=Dirk Neumann;,citation_publication_date=2021-09;,citation_cover_date=2021-09;,citation_year=2021;,citation_publisher=Wirtschaftsdienst;">
<meta name="citation_reference" content="citation_title=Incremental Unsupervised Domain-Adversarial Training of Neural Networks;,citation_author=Antonio-Javier Gallego;,citation_author=Jorge Calvo-Zaragoza;,citation_author=Robert B. Fisher;,citation_publication_date=2021-11;,citation_cover_date=2021-11;,citation_year=2021;,citation_issue=11;,citation_volume=32;,citation_journal_title=IEEE Transactions on Neural Networks and Learning Systems;">
<meta name="citation_reference" content="citation_title=Incremental learning for property price estimation using location-based services and open data;,citation_author=Francisco Alvarez;,citation_author=Edgar Roman-Rangel;,citation_author=Luis V. Montiel;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_volume=107;,citation_journal_title=Engineering Applications of Artificial Intelligence;">
<meta name="citation_reference" content="citation_title=Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide;,citation_editor=Eva Bartz;,citation_editor=Thomas Bartz-Beielstein;,citation_editor=Martin Zaefferer;,citation_editor=Olaf Mersmann;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=Interpretable Machine Learning: Moving from Mythos to Diagnostics;,citation_author=Valerie Chen;,citation_author=Jeffrey Li;,citation_author=Joon Sik Kim;,citation_author=Gregory Plumb;,citation_author=Ameet Talwalkar;,citation_publication_date=2022-01;,citation_cover_date=2022-01;,citation_year=2022;,citation_issue=6;,citation_volume=19;,citation_journal_title=Queue;">
<meta name="citation_reference" content="citation_title=Online Time-series Anomaly Detection: A Survey of Modern Model-based Approaches;,citation_author=Lucas Correia;,citation_author=Jan-Christoph Goos;,citation_author=Anna V. Kononova;,citation_author=Thomas Bäck;,citation_author=Philipp Klein;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_technical_report_institution=Mercedes-Benz, Germany;">
<meta name="citation_reference" content="citation_title=Green Accelerated Hoeffding Tree;,citation_author=Eva Garcia-Martin;,citation_author=Albert Bifet;,citation_author=Niklas Lavesson;,citation_author=Rikard König;,citation_author=Henrik Linusson;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=Monitoring the Economy in Real Time: Trends and Gaps in Real Activity and Prices;,citation_author=Thomas Hasenzagl;,citation_author=Filippo Pellegrino;,citation_author=Lucrezia Reichlin;,citation_author=Giovanni Ricco;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=Efficiently Correcting Machine Learning: Considering the Role of Example Ordering in Human-in-the-Loop Training of Image Classification Models;,citation_author=Geoff Holmes;,citation_author=Eibe Frank;,citation_author=Dale Fletcher;,citation_author=Corey Sterling;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_conference_title=27th International Conference on Intelligent User Interfaces;,citation_conference=Association for Computing Machinery;,citation_series_title=IUI ’22;">
<meta name="citation_reference" content="citation_title=TemporalWiki: A Lifelong Benchmark for Training and Evaluating Ever-Evolving Language Models;,citation_author=Joel Jang;,citation_author=Seonghyeon Ye;,citation_author=Changho Lee;,citation_author=Sohee Yang;,citation_author=Joongbo Shin;,citation_author=Janghoon Han;,citation_author=Gyeonghun Kim;,citation_author=Minjoon Seo;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=Fast Mining and Forecasting of Co-Evolving Epidemiological Data Streams;,citation_author=Tasuku Kimura;,citation_author=Yasuko Matsubara;,citation_author=Koki Kawabata;,citation_author=Yasushi Sakurai;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_conference_title=Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining;,citation_conference=Association for Computing Machinery;,citation_series_title=KDD ’22;">
<meta name="citation_reference" content="citation_title=Maschine Learning for Streaming Data with Python;,citation_author=Jan Korstanje;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=The Disagreement Problem in Explainable Machine Learning: A Practitioner’s Perspective;,citation_author=Satyapriya Krishna;,citation_author=Tessa Han;,citation_author=Alex Gu;,citation_author=Javin Pombra;,citation_author=Shahin Jabbari;,citation_author=Steven Wu;,citation_author=Himabindu Lakkaraju;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=SparkR: R Front End for ’Apache Spark’;,citation_author=The Apache Software Foundation;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=Short-term local predictions of COVID-19 in the United Kingdom using dynamic supervised machine learning algorithms;,citation_author=Xin Wang;,citation_author=Yijia Dong;,citation_author=William David Thompson;,citation_author=Harish Nair;,citation_author=You Li;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_issue=1;,citation_volume=2;,citation_journal_title=Communications Medicine;">
<meta name="citation_reference" content="citation_title=Log-based Anomaly Detection with Deep Learning: How Far Are We?;,citation_author=Van-Hoang Le;,citation_author=Hongyu Zhang;,citation_publication_date=2022-02;,citation_cover_date=2022-02;,citation_year=2022;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Reliance on metrics is a fundamental challenge for AI.;,citation_author=Rachel L Thomas;,citation_author=David Uminsky;,citation_publication_date=2022-05;,citation_cover_date=2022-05;,citation_year=2022;,citation_issue=5;,citation_volume=3;,citation_journal_title=Patterns (N Y);">
<meta name="citation_reference" content="citation_title=SMRD.de Benutzerhandbuch;,citation_author=Niyaz Valitov;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_technical_report_institution=Bundesnetzagentur für Elektrizität, Gas, Telekommunikation, Post und Eisenbahnen;">
<meta name="citation_reference" content="citation_title=Use of web scraping and text mining techniques in the Istat survey on “Information and Communication Technology in enterprises”;,citation_author=G. Barcaroli;,citation_author=A. Nurra;,citation_author=M. Scarnò;,citation_author=D. Summa;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=Who Makes Mistakes? Using Data Mining Techniques to Analyze Reporting Errors in Total Acres Operated;,citation_author=Jaki S. McCarthy;,citation_author=Morgan S. Earp;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_fulltext_html_url=https://ideas.repec.org/p/ags/unasrr/234367.html;,citation_doi=10.22004/AG.ECON.234367;,citation_journal_title=NASS Research Reports;,citation_publisher=United States Department of Agriculture, National Agricultural Statistics Service;">
<meta name="citation_reference" content="citation_title=Modeling Non-response in National Agricultural Statistics Service (NASS) Surveys Using Classification Trees;,citation_author=Jaki S Mccarthy;,citation_author=Thomas Jacob;,citation_author=Amanda Mccracken;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;">
<meta name="citation_reference" content="citation_title=2007 Census of Agriculture Non-Response Methodology;,citation_author=Will Cecere;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;">
<meta name="citation_reference" content="citation_title=Exploring Quarterly Agricultural Survey Questionnaire Version Reduction Scenarios;,citation_author=Morgan Earp;,citation_author=Scott Cox;,citation_author=Jody Mcdaniel;,citation_author=Chadd Crouse;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;">
<meta name="citation_reference" content="citation_title=USE OF MACHINE LEARNING METHODS TO IMPUTE CATEGORICAL DATA;,citation_author=P. Rey;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;">
<meta name="citation_reference" content="citation_title=Innovative Uses of Data Mining Techniques in the Production of Official Statistics;,citation_author=Jaki Mccarthy;,citation_author=Thomas Jacob;,citation_author=Dale Atkinson;">
<meta name="citation_reference" content="citation_title=Automatic Coding of Occupations. Using Machine Learning Algorithms for Occupation Coding in Several German Panel Surveys;,citation_fulltext_html_url=https://www.researchgate.net/publication/266259591_Automatic_Coding_of_Occupations_Using_Machine_Learning_Algorithms_for_Occupation_Coding_in_Several_German_Panel_Surveys;">
<meta name="citation_reference" content="citation_title=Evaluating hourly air quality forecasting in Canada with nonlinear updatable machine learning methods;,citation_author=Huiping Peng;,citation_author=Aranildo R. Lima;,citation_author=Andrew Teakles;,citation_author=Jian Jin;,citation_author=Alex J. Cannon;,citation_author=William W. Hsieh;,citation_publication_date=2017-03-01;,citation_cover_date=2017-03-01;,citation_year=2017;,citation_fulltext_html_url=https://doi.org/10.1007/s11869-016-0414-3;,citation_issue=2;,citation_doi=10.1007/s11869-016-0414-3;,citation_issn=1873-9326;,citation_volume=10;,citation_journal_title=Air Quality, Atmosphere &amp;amp;amp; Health;">
<meta name="citation_reference" content="citation_title=Online Machine Learning in Big Data Streams;,citation_author=András A. Benczúr;,citation_author=Levente Kocsis;,citation_author=Róbert Pálovics;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_fulltext_html_url=http://arxiv.org/abs/1802.05872;,citation_volume=abs/1802.05872;,citation_journal_title=CoRR;">
<meta name="citation_reference" content="citation_title=Learn: A Novel incremental learning method for text classification;,citation_author=Guangxu Shan;,citation_author=Shiyao Xu;,citation_author=Li Yang;,citation_author=Shengbin Jia;,citation_author=Yang Xiang;,citation_publication_date=2020-06;,citation_cover_date=2020-06;,citation_year=2020;,citation_doi=10.1016/J.ESWA.2020.113198;,citation_issn=0957-4174;,citation_volume=147;,citation_journal_title=Expert Systems with Applications;,citation_publisher=Pergamon;">
<meta name="citation_reference" content="citation_title=Incremental Real-Time Learning Framework for Sentiment Classification: Indian General Election 2019, A Case Study;,citation_author=Sharmistha Chatterjee;,citation_author=Sushmita Gupta;,citation_publication_date=2021-03;,citation_cover_date=2021-03;,citation_year=2021;,citation_doi=10.1109/ICBDA51983.2021.9402992;,citation_isbn=9780738131672;,citation_journal_title=2021 IEEE 6th International Conference on Big Data Analytics, ICBDA 2021;,citation_publisher=Institute of Electrical; Electronics Engineers Inc.;">
<meta name="citation_reference" content="citation_title=MOA: Massive Online Analysis;,citation_abstract=Massive Online Analysis (MOA) is a software environment for implementing algorithms and running experiments for online learning from evolving data streams. MOA includes a collection of offline and online methods as well as tools for evaluation. In particular, it implements boosting, bagging, and Hoeffding Trees, all with and without Na¨ıveNa¨ıve Bayes classifiers at the leaves. MOA supports bi-directional interaction with WEKA, the Waikato Environment for Knowledge Analysis , and is released under the GNU GPL license.;,citation_author=Albert Bifet;,citation_author=Geoff Holmes;,citation_author=Richard Kirkby;,citation_author=Bernhard Pfahringer;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_volume=11;,citation_journal_title=Journal of Machine Learning Research;">
<meta name="citation_reference" content="citation_title=Evaluation and Performance Measurement;,citation_author=Thomas Bartz-Beielstein;,citation_editor=Eva Bartz;,citation_editor=Thomas Bartz-Beielstein;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_inbook_title=undefined;">
<meta name="citation_reference" content="citation_title=Hyperparameter Tuning;,citation_author=Thomas Bartz-Beielstein;,citation_editor=Eva Bartz;,citation_editor=Thomas Bartz-Beielstein;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_inbook_title=undefined;">
<meta name="citation_reference" content="citation_title=Hyperparameter Tuning Approaches;,citation_author=Thomas Bartz-Beielstein;,citation_author=Martin Zaefferer;,citation_editor=Eva Bartz;,citation_editor=Thomas Bartz-Beielstein;,citation_editor=Martin Zaefferer;,citation_editor=Olaf Mersmann;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_inbook_title=Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide;">
<meta name="citation_reference" content="citation_title=Drift Detection and&nbsp;Handling;,citation_abstract=Structural changes (“drift”) in the data cause problems for many algorithms. Based on the drift definitions given in Chap. 1, methods for drift detection and handling are discussed. For the algorithms presented in Chap. 2, it is clarified to what extent concept drift is reacted to. In turn, the extent to which catastrophic forgetting is an issue is described in Sect. 4.3. Section&nbsp;3.1 describes three architectures for implementing drift detection algorithms. Basic properties of window-based approaches are presented in Sect.&nbsp;3.2. Section&nbsp;3.4 presents commonly used drift detection techniques. Section&nbsp;3.4 describes how the drift detection techniques introduced in Sect.&nbsp;3.3 are used in Online Machine Learning (OML) algorithms and summarizes the tree-based OML techniques implemented in the River package. Section&nbsp;3.5 introduces scaling methods for handling drift.;,citation_author=Thomas Bartz-Beielstein;,citation_author=Lukas Hans;,citation_editor=Eva Bartz;,citation_editor=Thomas Bartz-Beielstein;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://doi.org/10.1007/978-981-99-7007-0_3;,citation_doi=10.1007/978-981-99-7007-0_3;,citation_isbn=978-981-99-7007-0;,citation_inbook_title=Online Machine Learning: A Practical Guide with Examples in Python;">
<meta name="citation_reference" content="citation_title=Introduction: From Batch to&nbsp;Online Machine Learning;,citation_abstract=Batch Machine Learning (BML), which is also referred to as “offline machine learning”, reaches its limits when dealing with very large amounts of data. This is especially true for available memory, handling drift in data streams, and processing new, unknown data. Online Machine Learning (OML) is an alternative to BML that overcomes the limitations of BML. In this chapter, the basic terms and concepts of OML are introduced and the differences to BML are shown.;,citation_author=Thomas Bartz-Beielstein;,citation_editor=Eva Bartz;,citation_editor=Thomas Bartz-Beielstein;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://doi.org/10.1007/978-981-99-7007-0_1;,citation_doi=10.1007/978-981-99-7007-0_1;,citation_isbn=978-981-99-7007-0;,citation_inbook_title=Online Machine Learning: A Practical Guide with Examples in Python;">
<meta name="citation_reference" content="citation_title=AMF: Aggregated Mondrian Forests for Online Learning;,citation_author=Jaouad Mourtada;,citation_author=Stephane Gaiffas;,citation_author=Erwan Scornet;,citation_publication_date=2019-06;,citation_cover_date=2019-06;,citation_year=2019;,citation_fulltext_html_url=https://arxiv.org/abs/1906.10529;,citation_doi=10.48550/arXiv.1906.10529;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Extremely fast decision tree;,citation_abstract=We introduce a novel incremental decision tree learning algorithm, Hoeffding Anytime Tree, that is statistically more efficient than the current state-of-the-art, Hoeffding Tree. We demonstrate that an implementation of Hoeffding Anytime Tree’“Extremely Fast Decision Tree”, a minor modification to the MOA implementation of Hoeffding Tree’obtains significantly superior prequential accuracy on most of the largest classification datasets from the UCI repository. Hoeffding Anytime Tree produces the asymptotic batch tree in the limit, is naturally resilient to concept drift, and can be used as a higher accuracy replacement for Hoeffding Tree in most scenarios, at a small additional computational cost.;,citation_author=Chaitanya Manapragada;,citation_author=Geoffrey I. Webb;,citation_author=Mahsa Salehi;,citation_editor=Chih-Jen  Lin;,citation_editor=Hui  Xiong;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_fulltext_html_url=http://www.kdd.org/kdd2018/, https://dl.acm.org/doi/proceedings/10.1145/3219819;,citation_doi=10.1145/3219819.3220005;,citation_conference_title=KDD’ 2018 - Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;,citation_conference=Association for Computing Machinery (ACM);">
<meta name="citation_reference" content="citation_title=Surrogates;,citation_author=Robert B Gramacy;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;">
<meta name="citation_reference" content="citation_title=UvA Deep Learning Tutorials;,citation_author=Phillip Lippe;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://github.com/phlippe/uvadlc_notebooks/tree/master;">
<meta name="citation_reference" content="citation_title=Attention Is All You Need;,citation_author=Ashish Vaswani;,citation_author=Noam Shazeer;,citation_author=Niki Parmar;,citation_author=Jakob Uszkoreit;,citation_author=Llion Jones;,citation_author=Aidan N. Gomez;,citation_author=Lukasz Kaiser;,citation_author=Illia Polosukhin;,citation_publication_date=2017-06;,citation_cover_date=2017-06;,citation_year=2017;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=On the Variance of the Adaptive Learning Rate and Beyond;,citation_author=Liyuan Liu;,citation_author=Haoming Jiang;,citation_author=Pengcheng He;,citation_author=Weizhu Chen;,citation_author=Xiaodong Liu;,citation_author=Jianfeng Gao;,citation_author=Jiawei Han;,citation_publication_date=2019-08;,citation_cover_date=2019-08;,citation_year=2019;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Efficient Transformers: A Survey;,citation_author=Yi Tay;,citation_author=Mostafa Dehghani;,citation_author=Dara Bahri;,citation_author=Donald Metzler;,citation_publication_date=2020-09;,citation_cover_date=2020-09;,citation_year=2020;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding;,citation_author=Jacob Devlin;,citation_author=Ming-Wei Chang;,citation_author=Kenton Lee;,citation_author=Kristina Toutanova;,citation_publication_date=2018-10;,citation_cover_date=2018-10;,citation_year=2018;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale;,citation_author=Alexey Dosovitskiy;,citation_author=Lucas Beyer;,citation_author=Alexander Kolesnikov;,citation_author=Dirk Weissenborn;,citation_author=Xiaohua Zhai;,citation_author=Thomas Unterthiner;,citation_author=Mostafa Dehghani;,citation_author=Matthias Minderer;,citation_author=Georg Heigold;,citation_author=Sylvain Gelly;,citation_author=Jakob Uszkoreit;,citation_author=Neil Houlsby;,citation_publication_date=2020-10;,citation_cover_date=2020-10;,citation_year=2020;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Attention is not Explanation;,citation_author=Sarthak Jain;,citation_author=Byron C. Wallace;,citation_publication_date=2019-02;,citation_cover_date=2019-02;,citation_year=2019;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Attention is not not Explanation;,citation_author=Sarah Wiegreffe;,citation_author=Yuval Pinter;,citation_publication_date=2019-08;,citation_cover_date=2019-08;,citation_year=2019;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Multivariate adaptive regression splines;,citation_author=Jerome H. Friedman;,citation_publication_date=1991;,citation_cover_date=1991;,citation_year=1991;,citation_issue=1;,citation_volume=19;,citation_journal_title=The annals of statistics;">
<meta name="citation_reference" content="citation_title=Learning model trees from evolving data streams;,citation_author=Elena Ikonomovska;,citation_author=João Gama;,citation_author=Sašo Džeroski;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=1;,citation_volume=23;,citation_journal_title=Data Mining and Knowledge Discovery;">
<meta name="citation_reference" content="citation_title=An Introduction to Statistical Learning with Applications in R;,citation_author=Gareth James;,citation_author=Daniela Witten;,citation_author=Trevor Hastie;,citation_author=Robert Tibshirani;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=Deep Learning with Python;,citation_author=Francoise Chollet;,citation_author=J. J. Allaire;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;">
<meta name="citation_reference" content="citation_title=A survey of cross-validation procedures for model selection;,citation_author=Sylvain Arlot;,citation_author=Alain Celisse;,citation_author=others;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_volume=4;,citation_journal_title=Statistics surveys;">
<meta name="citation_reference" content="citation_title=A cross-validatory method for dependent data;,citation_author=PRABIR BURMAN;,citation_author=EDMOND CHOW;,citation_author=DEBORAH NOLAN;,citation_publication_date=1994;,citation_cover_date=1994;,citation_year=1994;,citation_issue=2;,citation_volume=81;,citation_journal_title=Biometrika;">
<meta name="citation_reference" content="citation_title=A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection;,citation_author=Ron Kohavi;,citation_publication_date=1995;,citation_cover_date=1995;,citation_year=1995;,citation_conference_title=Proceedings of the 14th International Joint Conference on Artificial Intelligence - Volume 2;,citation_conference=Morgan Kaufmann Publishers Inc.;,citation_series_title=IJCAI’95;">
<meta name="citation_reference" content="citation_title=Kriging-based sequential design strategies using fast cross-validation techniques with extensions to multi-fidelity computer codes ;,citation_author=Loic Le Gratiet;,citation_author=Claire Cannamela;,citation_publication_date=2012-10;,citation_cover_date=2012-10;,citation_year=2012;">
<meta name="citation_reference" content="citation_title=Cross-Validation of Regression Models;,citation_author=Richard R. Picard;,citation_author=R. Dennis Cook;,citation_publication_date=1984;,citation_cover_date=1984;,citation_year=1984;,citation_issue=387;,citation_volume=79;,citation_journal_title=Journal of the American Statistical Association;">
<meta name="citation_reference" content="citation_title=The Elements of Statistical Learning;,citation_author=Trevor Hastie;,citation_author=Robert Tibshirani;,citation_author=Jerome Friedman;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;">
<meta name="citation_reference" content="citation_title=Deep Residual Learning for Image Recognition;,citation_author=Kaiming He;,citation_author=Xiangyu Zhang;,citation_author=Shaoqing Ren;,citation_author=Jian Sun;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=Identity Mappings in Deep Residual Networks;,citation_author=Kaiming He;,citation_author=Xiangyu Zhang;,citation_author=Shaoqing Ren;,citation_author=Jian Sun;,citation_publication_date=2016-03;,citation_cover_date=2016-03;,citation_year=2016;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Neural Ordinary Differential Equations;,citation_author=Ricky T. Q. Chen;,citation_author=Yulia Rubanova;,citation_author=Jesse Bettencourt;,citation_author=David Duvenaud;,citation_publication_date=2018-06;,citation_cover_date=2018-06;,citation_year=2018;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Mathematical Theory of Optimal Processes;,citation_author=undefined Pontryagin;,citation_publication_date=1987;,citation_cover_date=1987;,citation_year=1987;">
<meta name="citation_reference" content="citation_title=On Neural Differential Equations;,citation_author=Patrick Kidger;,citation_publication_date=2022-02;,citation_cover_date=2022-02;,citation_year=2022;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Stochastic simulation optimization: an optimal computing budget allocation;,citation_author=Chun Hung Chen;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;">
<meta name="citation_reference" content="citation_title=Sequential Parameter Optimization and Optimal Computational Budget Allocation for Noisy Optimization Problems;,citation_author=Thomas Bartz-Beielstein;,citation_author=Martina Friese;,citation_publication_date=2011-01;,citation_cover_date=2011-01;,citation_year=2011;">
<meta name="citation_reference" content="citation_title=Statistik;,citation_author=Joachim Hartung;,citation_author=Bärbel Elpert;,citation_author=Karl-Heinz Klösener;,citation_publication_date=1995;,citation_cover_date=1995;,citation_year=1995;">
<meta name="citation_reference" content="citation_title=Partial correlation — Wikipedia, The Free Encyclopedia;,citation_author=Wikipedia contributors;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://en.wikipedia.org/w/index.php?title=Partial_correlation&amp;amp;amp;oldid=1253637419;">
<meta name="citation_reference" content="citation_title=Understanding Correlation;,citation_author=R. J. Rummel;,citation_publication_date=1976;,citation_cover_date=1976;,citation_year=1976;,citation_fulltext_html_url=https://www.hawaii.edu/powerkills/UC.HTM;">
<meta name="citation_reference" content="citation_title=Two Postestimation Commands for Assessing Confounding Effects in Epidemiological Studies;,citation_author=Zhiqiang Wang;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=2;,citation_volume=7;,citation_journal_title=The Stata Journal;">
<meta name="citation_reference" content="citation_title=Response surface methodology: process and product optimization using designed experiments;,citation_author=Raymond H Myers;,citation_author=Douglas C Montgomery;,citation_author=Christine M Anderson-Cook;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;">
<meta name="citation_reference" content="citation_title=desirability: Function Optimization and Ranking via Desirability Functions;,citation_author=Max Kuhn;,citation_publication_date=2016-09;,citation_cover_date=2016-09;,citation_year=2016;">
<meta name="citation_reference" content="citation_title=Noisy optimization with sequential parameter optimization and optimal computational budget allocation;,citation_author=Thomas Bartz-Beielstein;,citation_author=Martina Friese;,citation_author=Martin Zaefferer;,citation_author=Boris Naujoks;,citation_author=Oliver Flasch;,citation_author=Wolfgang Konen;,citation_author=Patrick Koch;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_conference_title=Proceedings of the 13th annual conference companion on Genetic and evolutionary computation;,citation_conference=ACM;">
<meta name="citation_reference" content="citation_title=Stochastic simulation optimization: an optimal computing budget allocation;,citation_author=Chun Hung Chen;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;">
<meta name="citation_reference" content="citation_title=Generalized Simulated Annealing for Function Optimization;,citation_author=I O Bohachevsky;,citation_publication_date=1986;,citation_cover_date=1986;,citation_year=1986;,citation_issue=3;,citation_volume=28;,citation_journal_title=Technometrics;">
<meta name="citation_reference" content="citation_title=On the Experimental Attainment of Optimum Conditions;,citation_author=G. E. P. Box;,citation_author=K. B. Wilson;,citation_publication_date=1951;,citation_cover_date=1951;,citation_year=1951;,citation_issue=1;,citation_volume=13;,citation_journal_title=Journal of the Royal Statistical Society. Series B (Methodological);">
<meta name="citation_reference" content="citation_title=Design and Analysis of Experiments;,citation_author=D C Montgomery;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;">
<meta name="citation_reference" content="citation_title=Empirical Design of Geometric Algorithms;,citation_author=Karsten Weihe;,citation_author=Ulrik Brandes;,citation_author=Annegret Liebers;,citation_author=Matthias Mı̈ Hannemann;,citation_author=Dorothea Wagner;,citation_author=Thomas Willhalm;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_conference_title=SCG ’99: Proceedings of the Fifteenth Annual Symposium on Computational Geometry;,citation_conference=Association for Computing Machinery;">
<meta name="citation_reference" content="citation_title=Hyperparameter optimization: Foundations, algorithms, best practices, and open challenges;,citation_author=Bernd Bischl;,citation_author=Martin Binder;,citation_author=Michel Lang;,citation_author=Tobias Pielok;,citation_author=Jakob Richter;,citation_author=Stefan Coors;,citation_author=Janek Thomas;,citation_author=Theresa Ullmann;,citation_author=Marc Becker;,citation_author=Anne-Laure Boulesteix;,citation_author=Difan Deng;,citation_author=Marius Lindauer;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_issue=2;,citation_volume=13;,citation_journal_title=WIREs Data Mining and Knowledge Discovery;">
<meta name="citation_reference" content="citation_title=Multi-Factor Experimental Designs for Exploring Response Surfaces;,citation_author=G. E. P. Box;,citation_author=J. S. Hunter;,citation_publication_date=1957;,citation_cover_date=1957;,citation_year=1957;,citation_issue=1;,citation_volume=28;,citation_journal_title=The Annals of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Multi-Objective Evolutionary Algorithms: Past, Present, and Future;,citation_author=Carlos A. Coello Coello;,citation_author=Silvia González Brambila;,citation_author=Josué Figueroa Gamboa;,citation_author=Ma. Guadalupe Castillo Tapia;,citation_editor=Panos M. Pardalos;,citation_editor=Varvara Rasskazova;,citation_editor=Michael N. Vrahatis;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_inbook_title=undefined;">
<meta name="citation_reference" content="citation_title=Modified Desirability Functions for Multiple Response Optimization;,citation_author=E. Del Castillo;,citation_author=D. C. Montgomery;,citation_author=D. R. McCarville;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_volume=28;,citation_journal_title=Journal of Quality Technology;">
<meta name="citation_reference" content="citation_title=Simultaneous Optimization of Several Response Variables;,citation_author=G. Derringer;,citation_author=R. Suich;,citation_publication_date=1980;,citation_cover_date=1980;,citation_year=1980;,citation_volume=12;,citation_journal_title=Journal of Quality Technology;">
<meta name="citation_reference" content="citation_title=A tutorial on multiobjective optimization: fundamentals and evolutionary methods;,citation_author=Michael T. M. Emmerich;,citation_author=AndréH. Deutz;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=3;,citation_volume=17;,citation_journal_title=Natural Computing;">
<meta name="citation_reference" content="citation_title=The Desirability Function;,citation_author=J Harington;,citation_publication_date=1965;,citation_cover_date=1965;,citation_year=1965;,citation_volume=21;,citation_journal_title=Industrial Quality Control;">
<meta name="citation_reference" content="citation_title=Multi-Objective Hyperparameter Optimization in Machine Learning—An Overview;,citation_author=Florian Karl;,citation_author=Tobias Pielok;,citation_author=Julia Moosbauer;,citation_author=Florian Pfisterer;,citation_author=Stefan Coors;,citation_author=Martin Binder;,citation_author=Lennart Schneider;,citation_author=Janek Thomas;,citation_author=Jakob Richter;,citation_author=Michel Lang;,citation_author=Eduardo C. Garrido-Merchán;,citation_author=Juergen Branke;,citation_author=Bernd Bischl;,citation_publication_date=2023-12;,citation_cover_date=2023-12;,citation_year=2023;,citation_issue=4;,citation_volume=3;,citation_journal_title=ACM Trans. Evol. Learn. Optim.;">
<meta name="citation_reference" content="citation_title=A Simplex Method for Function Minimization;,citation_author=J. A. Nelder;,citation_author=R. Mead;,citation_publication_date=1965-01;,citation_cover_date=1965-01;,citation_year=1965;,citation_issue=4;,citation_volume=7;,citation_journal_title=The Computer Journal;">
<meta name="citation_reference" content="citation_title=Multiple Objective Optimization Using Desirability Functions for the Design of a 3D Printer Prototype;,citation_author=Esmeralda Nino;,citation_author=Juan Rosas Rubio;,citation_author=Samuel Bonet;,citation_author=Nazario Ramirez-Beltran;,citation_author=Mauricio Cabrera-Rios;,citation_publication_date=2015-06;,citation_cover_date=2015-06;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=NIST/SEMATECH e-Handbook of Statistical Methods;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;">
<meta name="citation_reference" content="citation_title=The Nelder-Mead simplex procedure for function minimization;,citation_author=Donald M Olsson;,citation_author=Lloyd S Nelson;,citation_publication_date=1975;,citation_cover_date=1975;,citation_year=1975;,citation_issue=1;,citation_volume=17;,citation_journal_title=Technometrics;">
<meta name="citation_reference" content="citation_title=Hyperparameter Tuning Cookbook: A guide for scikit-learn, PyTorch, river, and spotpython;,citation_author=Thomas Bartz-Beielstein;,citation_publication_date=2023-07;,citation_cover_date=2023-07;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2307.10262;,citation_doi=10.48550/arXiv.2307.10262;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Interpolation of scattered data: Distance matrices and conditionally positive definite functions;,citation_abstract=Among other things, we prove that multiquadric surface interpolation is always solvable, thereby settling a conjecture of R. Franke.;,citation_author=Charles A. Micchelli;,citation_publication_date=1986;,citation_cover_date=1986;,citation_year=1986;,citation_fulltext_html_url=https://doi.org/10.1007/BF01893414;,citation_issue=1;,citation_doi=10.1007/BF01893414;,citation_isbn=1432-0940;,citation_volume=2;,citation_journal_title=Constructive Approximation;">
<meta name="citation_reference" content="citation_title=Computational Approaches for Aerospace Design: The Pursuit of Excellence;,citation_author=Andrew J Keane;,citation_author=Prasanth B Nair;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;">
<meta name="citation_reference" content="citation_title=Statistical learning theory;,citation_author=V N Vapnik;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;">
<meta name="citation_reference" content="citation_title=Regularization algorithms for learning that are equivalent to multilayer networks.;,citation_abstract=Learning an input-output mapping from a set of examples, of the type that many neural networks have been constructed to perform, can be regarded as synthesizing an approximation of a multidimensional function (that is, solving the problem of hypersurface reconstruction). From this point of view, this form of learning is closely related to classical approximation techniques, such as generalized splines and regularization theory. A theory is reported that shows the equivalence between regularization and a class of three-layer networks called regularization networks or hyper basis functions. These networks are not only equivalent to generalized splines but are also closely related to the classical radial basis functions used for interpolation tasks and to several pattern recognition and neural network algorithms. They also have an interesting interpretation in terms of prototypes that are synthesized and optimally combined during the learning stage.;,citation_author=T Poggio;,citation_author=F Girosi;,citation_publication_date=1990-02;,citation_cover_date=1990-02;,citation_year=1990;,citation_issue=4945;,citation_doi=10.1126/science.247.4945.978;,citation_issn=0036-8075 (Print); 0036-8075 (Linking);,citation_pmid=17776454;,citation_volume=247;,citation_journal_title=Science;">
<meta name="citation_reference" content="citation_title=Exploratory designs for computational experiments;,citation_abstract=Recent work by Johnson et al. (J. Statist. Plann. Inference 26 (1990) 131–148) establishes equivalence of the maximin distance design criterion and an entropy criterion motivated by function prediction in a Bayesian setting. The latter criterion has been used by Currin et al. (J. Amer. Statist. Assoc. 86 (1991) 953–963) to design experiments for which the motivating application is approximation of a complex deterministic computer model. Because computer experiments often have a large number of controlled variables (inputs), maximin designs of moderate size are often concentrated in the corners of the cuboidal design region, i.e. each input is represented at only two levels. Here we will examine some maximin distance designs constructed within the class of Latin hypercube arrangements. The goal of this is to find designs which offer a compromise between the entropy/maximin criterion, and good projective properties in each dimension (as guaranteed by Latin hypercubes). A simulated annealing search algorithm is presented for constructing these designs, and patterns apparent in the optimal designs are discussed.;,citation_author=Max D. Morris;,citation_author=Toby J. Mitchell;,citation_publication_date=1995;,citation_cover_date=1995;,citation_year=1995;,citation_fulltext_html_url=https://www.sciencedirect.com/science/article/pii/037837589400035T;,citation_issue=3;,citation_doi=https://doi.org/10.1016/0378-3758(94)00035-T;,citation_issn=0378-3758;,citation_volume=43;,citation_journal_title=Journal of Statistical Planning and Inference;">
<meta name="citation_reference" content="citation_title=Evolutionary operation: A method for increasing industrial productivity.;,citation_author=G E P Box;,citation_publication_date=1957;,citation_cover_date=1957;,citation_year=1957;,citation_volume=6;,citation_journal_title=Applied Statistics;">
<meta name="citation_reference" content="citation_title=Minimax and maximin distance designs;,citation_author=M. E. Johnson;,citation_author=L. M. Moore;,citation_author=D. Ylvisaker;,citation_publication_date=1990;,citation_cover_date=1990;,citation_year=1990;,citation_issue=2;,citation_volume=26;,citation_journal_title=Journal of Statistical Planning and Inference;">
<meta name="citation_reference" content="citation_title=Aircraft Design: A Conceptual Approach;,citation_author=Daniel P. Raymer;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;">
<meta name="citation_reference" content="citation_title=Design and analysis of computer experiments;,citation_author=J Sacks;,citation_author=W J Welch;,citation_author=T J Mitchell;,citation_author=H P Wynn;,citation_publication_date=1989;,citation_cover_date=1989;,citation_year=1989;,citation_issue=4;,citation_volume=4;,citation_journal_title=Statistical Science;">
<meta name="citation_reference" content="citation_title=Kriging (Gaussian Process Regression): The Complete Python Code for the Example;,citation_author=Thomas Bartz-Beielstein;,citation_publication_date=2025-06;,citation_cover_date=2025-06;,citation_year=2025;,citation_fulltext_html_url=https://sequential-parameter-optimization.github.io/Hyperparameter-Tuning-Cookbook/006_num_gp.html;">
<meta name="citation_reference" content="citation_title=Efficient global optimization of expensive black-box functions;,citation_author=Donald R. Jones;,citation_author=Matthias Schonlau;,citation_author=William J. Welch;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_issue=4;,citation_volume=13;,citation_journal_title=Journal of Global Optimization;">
<meta name="citation_reference" content="citation_title=On Bayesian Methods for Seeking the Extremum;,citation_author=J. Močkus;,citation_publication_date=1974;,citation_cover_date=1974;,citation_year=1974;,citation_conference_title=Optimization Techniques IFIP Technical Conference;">
</head>

<body class="nav-sidebar docked quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./100_ddmo_eda.html">Data-Driven Modeling and Optimization</a></li><li class="breadcrumb-item"><a href="./100_ddmo_pca.html"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Addressing Multicollinearity: Principle Component Analysis (PCA) and Factor Analysis (FA)</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Hyperparameter Tuning Cookbook</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/sequential-parameter-optimization/spotpython" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="./Hyperparameter-Tuning-Cookbook.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
              <i class="bi bi-linkedin pe-1"></i>
            LinkedIn
            </a>
          </li>
      </ul>
    </div>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Optimization</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./002_awwe.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Aircraft Wing Weight Example</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./003_scipy_optimize_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction to <code>scipy.optimize</code></span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Numerical Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./001_surrogate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Simulation and Surrogate Modeling</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./001_sampling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Sampling Plans</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./006_constructing_surrogate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Constructing a Surrogate</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./005_num_rsm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Response Surface Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./006_num_poly.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Polynomial Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./006_num_rbf.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Radial Basis Function Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./006_num_gp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Kriging (Gaussian Process Regression)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./006_matrices.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Matrices</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./006_infill.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Infill Criteria</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Sequential Parameter Optimization Toolbox (SPOT)</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./007_spot_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Introduction to Sequential Parameter Optimization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./008_num_spot_multidim.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Multi-dimensional Functions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./009_num_spot_anisotropic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Isotropic and Anisotropic Kriging</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./004_spot_sklearn_optimization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Sequential Parameter Optimization: Using <code>scipy</code> Optimizers</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./010_num_spot_sklearn_surrogate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Using <code>sklearn</code> Surrogates in <code>spotpython</code></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./011_num_spot_sklearn_gaussian.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Sequential Parameter Optimization: Gaussian Process Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./012_num_spot_ei.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Infill Criteria</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./013_num_spot_noisy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Handling Noise</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./014_num_spot_ocba.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Optimal Computational Budget Allocation in spotpython</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./015_num_spot_correlation_p.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Kriging with Varying Correlation-p</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./016_num_spot_factorial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Factorial Variables</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./017_num_spot_user_function.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">User-Specified Functions: Extending the Analytical Class</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Data-Driven Modeling and Optimization</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./100_ddmo_eda.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Basic Statistics and Data Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./100_ddmo_pca.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Addressing Multicollinearity: Principle Component Analysis (PCA) and Factor Analysis (FA)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./100_ddmo_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./100_ddmo_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Classification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./100_ddmo_clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Clustering</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Machine Learning and AI</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./200_mlai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Machine Learning and Artificial Intelligence</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Introduction to Hyperparameter Tuning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./300_hpt_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Hyperparameter Tuning with Sklearn</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./400_spot_hpt_sklearn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">HPT: sklearn</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./401_spot_hpt_sklearn_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">HPT: sklearn SVC on Moons Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./401_spot_hpt_sklearn_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">HPT: sklearn SVR on Regression Data</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true">
 <span class="menu-text">Hyperparameter Tuning with River</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./500_spot_hpt_river.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">HPT: River</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./501_spot_river_gui.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Simplifying Hyperparameter Tuning in Online Machine Learning—The spotRiverGUI</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./502_spot_hpt_river_friedman_htr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title"><code>river</code> Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./503_spot_hpt_river_friedman_amfr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">The Friedman Drift Data Set</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true">
 <span class="menu-text">Hyperparameter Tuning with PyTorch Lightning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./700_lightning_basic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Basic Lightning Module</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./701_lightning_details.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">Details of the Lightning Module Integration in spotpython</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./702_lightning_user_datamodule.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">User Specified Basic Lightning Module With spotpython</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./600_spot_lightning_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">HPT PyTorch Lightning: Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./601_spot_hpt_light_diabetes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning with <code>spotpython</code> and <code>PyTorch</code> Lightning for the Diabetes Data Set</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./601_spot_hpt_light_early_stopping.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Early Stopping Explained: HPT with <code>spotpython</code> and <code>PyTorch</code> Lightning for the Diabetes Data Set</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./601_spot_hpt_light_user_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning with PyTorch Lightning and User Data Sets</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./601_spot_hpt_light_user_model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">45</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning with PyTorch Lightning and User Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./601_resnet.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">46</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning with PyTorch Lightning: ResNets</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./601_neural_ode.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">47</span>&nbsp; <span class="chapter-title">Neural ODEs</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./601_neural_ode_example.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">48</span>&nbsp; <span class="chapter-title">Neural ODE Example</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./601_pinn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">49</span>&nbsp; <span class="chapter-title">Physics Informed Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./601_spot_hpt_light_pinn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">50</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning with PyTorch Lightning: Physics Informed Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./602_spot_lightning_xai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">51</span>&nbsp; <span class="chapter-title">Explainable AI with SpotPython and Pytorch</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./603_spot_lightning_transformer_introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">52</span>&nbsp; <span class="chapter-title">HPT PyTorch Lightning Transformer: Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./603_spot_lightning_transformer_hpt.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">53</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning of a Transformer Network with PyTorch Lightning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./604_spot_lightning_save_load_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">54</span>&nbsp; <span class="chapter-title">Saving and Loading</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./605_spot_hpt_light_diabetes_resnet.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">55</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning with <code>spotpython</code> and <code>PyTorch</code> Lightning for the Diabetes Data Set Using a ResNet Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./606_spot_hpt_light_diabetes_user_resnet.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">56</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning with <code>spotpython</code> and <code>PyTorch</code> Lightning for the Diabetes Data Set Using a User Specified ResNet Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./608_spot_hpt_light_condnet.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">57</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning with <code>spotpython</code> and <code>PyTorch</code> Lightning Using a CondNet Model</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true">
 <span class="menu-text">Multi Objective Optimization</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bart25a-desirability-latest.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">58</span>&nbsp; <span class="chapter-title">Introduction to Desirability Functions</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true">
 <span class="menu-text">Lernmodule</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./de_awwe.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">59</span>&nbsp; <span class="chapter-title">Lernmodul: Aircraft Wing Weight Example (AWWE)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./de_sampling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">60</span>&nbsp; <span class="chapter-title">Lernmodul: Versuchspläne (Sampling-Pläne) für Computerexperimente</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./de_kriging.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">61</span>&nbsp; <span class="chapter-title">Lernmodul: Eine Einführung in Kriging</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./de_cholesky.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">62</span>&nbsp; <span class="chapter-title">Lernmodul: Die Cholesky-Zerlegung</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./de_kriging_optimization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">63</span>&nbsp; <span class="chapter-title">Lernmodul: Erweiterung des Kriging-Modells: Numerische Optimierung der Hyperparameter</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./de_kriging_optimization_python_class.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">64</span>&nbsp; <span class="chapter-title">Lernmodul: Erweiterung des Kriging-Modells zu einer Klasse (Python Code)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./de_projekt.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">65</span>&nbsp; <span class="chapter-title">Lernmodul: Kriging Projekt</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./de_projekt_ei.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">66</span>&nbsp; <span class="chapter-title">Lernmodul: Kriging Projekt mit Expected Improvement</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_01_intro_to_notebooks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Introduction to Jupyter Notebook</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_02_git_intro_en.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Git Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_03_python_intro_en.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Python</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_04_gp_background.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Gaussian Processes—Some Background Information</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_05_datasets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Datasets</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_06_slurm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Using Slurm</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_07_package.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">G</span>&nbsp; <span class="chapter-title">Python Package Building</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_08_parallel.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">H</span>&nbsp; <span class="chapter-title">Parallelism in Initial Design</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_99_solutions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">I</span>&nbsp; <span class="chapter-title">Solutions to Selected Exercises</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">25.1</span> Introduction</a></li>
  <li><a href="#sec-data-preprocessing" id="toc-sec-data-preprocessing" class="nav-link" data-scroll-target="#sec-data-preprocessing"><span class="header-section-number">25.2</span> The Car-Sales Data Set</a>
  <ul class="collapse">
  <li><a href="#the-target-variable" id="toc-the-target-variable" class="nav-link" data-scroll-target="#the-target-variable"><span class="header-section-number">25.2.1</span> The Target Variable</a></li>
  <li><a href="#the-features" id="toc-the-features" class="nav-link" data-scroll-target="#the-features"><span class="header-section-number">25.2.2</span> The Features</a></li>
  <li><a href="#combining-non-categorical-and-categorical-encoded-data" id="toc-combining-non-categorical-and-categorical-encoded-data" class="nav-link" data-scroll-target="#combining-non-categorical-and-categorical-encoded-data"><span class="header-section-number">25.2.3</span> Combining Non-categorical and Categorical (encoded) Data</a></li>
  </ul></li>
  <li><a href="#sec-fit-ols" id="toc-sec-fit-ols" class="nav-link" data-scroll-target="#sec-fit-ols"><span class="header-section-number">25.3</span> Fit the Linear Regression Model</a>
  <ul class="collapse">
  <li><a href="#model-summary-and-interpretation" id="toc-model-summary-and-interpretation" class="nav-link" data-scroll-target="#model-summary-and-interpretation"><span class="header-section-number">25.3.1</span> Model Summary and Interpretation</a></li>
  </ul></li>
  <li><a href="#sec-collinearity-diagnostics" id="toc-sec-collinearity-diagnostics" class="nav-link" data-scroll-target="#sec-collinearity-diagnostics"><span class="header-section-number">25.4</span> Collinearity Diagnostics</a>
  <ul class="collapse">
  <li><a href="#the-coefficient-table" id="toc-the-coefficient-table" class="nav-link" data-scroll-target="#the-coefficient-table"><span class="header-section-number">25.4.1</span> The Coefficient Table</a></li>
  <li><a href="#eigenvalues-and-condition-indices" id="toc-eigenvalues-and-condition-indices" class="nav-link" data-scroll-target="#eigenvalues-and-condition-indices"><span class="header-section-number">25.4.2</span> Eigenvalues and Condition Indices</a></li>
  <li><a href="#kayser-meyer-olkin-kmo-measure" id="toc-kayser-meyer-olkin-kmo-measure" class="nav-link" data-scroll-target="#kayser-meyer-olkin-kmo-measure"><span class="header-section-number">25.4.3</span> Kayser-Meyer-Olkin (KMO) Measure</a></li>
  </ul></li>
  <li><a href="#sec-pca" id="toc-sec-pca" class="nav-link" data-scroll-target="#sec-pca"><span class="header-section-number">25.5</span> Addressing Multicollinearity with Principal Component Analysis (PCA)</a>
  <ul class="collapse">
  <li><a href="#introduction-to-pca" id="toc-introduction-to-pca" class="nav-link" data-scroll-target="#introduction-to-pca"><span class="header-section-number">25.5.1</span> Introduction to PCA</a></li>
  <li><a href="#application-of-pca-in-regression-problems" id="toc-application-of-pca-in-regression-problems" class="nav-link" data-scroll-target="#application-of-pca-in-regression-problems"><span class="header-section-number">25.5.2</span> Application of PCA in Regression Problems:</a></li>
  <li><a href="#scree-plot" id="toc-scree-plot" class="nav-link" data-scroll-target="#scree-plot"><span class="header-section-number">25.5.3</span> Scree Plot</a></li>
  <li><a href="#loading-scores-for-pca" id="toc-loading-scores-for-pca" class="nav-link" data-scroll-target="#loading-scores-for-pca"><span class="header-section-number">25.5.4</span> Loading Scores (for PCA)</a></li>
  <li><a href="#pca-for-car-sales-example" id="toc-pca-for-car-sales-example" class="nav-link" data-scroll-target="#pca-for-car-sales-example"><span class="header-section-number">25.5.5</span> PCA for Car Sales Example</a></li>
  <li><a href="#creating-the-regression-model-with-principal-components" id="toc-creating-the-regression-model-with-principal-components" class="nav-link" data-scroll-target="#creating-the-regression-model-with-principal-components"><span class="header-section-number">25.5.6</span> Creating the Regression Model with Principal Components</a></li>
  <li><a href="#collinearity-diagnostics-for-pca-regression-model" id="toc-collinearity-diagnostics-for-pca-regression-model" class="nav-link" data-scroll-target="#collinearity-diagnostics-for-pca-regression-model"><span class="header-section-number">25.5.7</span> Collinearity Diagnostics for PCA Regression Model</a></li>
  <li><a href="#sec-pca-reduced" id="toc-sec-pca-reduced" class="nav-link" data-scroll-target="#sec-pca-reduced"><span class="header-section-number">25.5.8</span> PCA: Creating the Regression Model with three Principle Components only</a></li>
  </ul></li>
  <li><a href="#sec-fa" id="toc-sec-fa" class="nav-link" data-scroll-target="#sec-fa"><span class="header-section-number">25.6</span> Addressing Multicollinearity and Latent Structure with Factor Analysis (FA)</a>
  <ul class="collapse">
  <li><a href="#introduction-to-factor-analysis" id="toc-introduction-to-factor-analysis" class="nav-link" data-scroll-target="#introduction-to-factor-analysis"><span class="header-section-number">25.6.1</span> Introduction to Factor Analysis</a></li>
  <li><a href="#determining-the-number-of-factors-for-factor-analysis" id="toc-determining-the-number-of-factors-for-factor-analysis" class="nav-link" data-scroll-target="#determining-the-number-of-factors-for-factor-analysis"><span class="header-section-number">25.6.2</span> Determining the Number of Factors for Factor Analysis</a></li>
  <li><a href="#scree-plot-for-factor-analysis" id="toc-scree-plot-for-factor-analysis" class="nav-link" data-scroll-target="#scree-plot-for-factor-analysis"><span class="header-section-number">25.6.3</span> Scree Plot for Factor Analysis</a></li>
  <li><a href="#factor-loadings" id="toc-factor-loadings" class="nav-link" data-scroll-target="#factor-loadings"><span class="header-section-number">25.6.4</span> Factor Loadings</a></li>
  <li><a href="#factor-scores" id="toc-factor-scores" class="nav-link" data-scroll-target="#factor-scores"><span class="header-section-number">25.6.5</span> Factor Scores</a></li>
  <li><a href="#creating-the-regression-model-with-extracted-factors-from-fa" id="toc-creating-the-regression-model-with-extracted-factors-from-fa" class="nav-link" data-scroll-target="#creating-the-regression-model-with-extracted-factors-from-fa"><span class="header-section-number">25.6.6</span> Creating the Regression Model with Extracted Factors (from FA)</a></li>
  <li><a href="#factor-analysis-creating-the-regression-model-with-three-extracted-factors-only" id="toc-factor-analysis-creating-the-regression-model-with-three-extracted-factors-only" class="nav-link" data-scroll-target="#factor-analysis-creating-the-regression-model-with-three-extracted-factors-only"><span class="header-section-number">25.6.7</span> Factor Analysis: Creating the Regression Model with three Extracted Factors only</a></li>
  </ul></li>
  <li><a href="#sec-summary-comparison" id="toc-sec-summary-comparison" class="nav-link" data-scroll-target="#sec-summary-comparison"><span class="header-section-number">25.7</span> Summary: Comparing OLS, PCA, and Factor Analysis Models</a>
  <ul class="collapse">
  <li><a href="#interpretation-of-the-regression-models" id="toc-interpretation-of-the-regression-models" class="nav-link" data-scroll-target="#interpretation-of-the-regression-models"><span class="header-section-number">25.7.1</span> Interpretation of the Regression Models</a></li>
  <li><a href="#differences-compared-to-the-standard-ols-model" id="toc-differences-compared-to-the-standard-ols-model" class="nav-link" data-scroll-target="#differences-compared-to-the-standard-ols-model"><span class="header-section-number">25.7.2</span> Differences Compared to the Standard OLS Model</a></li>
  <li><a href="#sec-loading-scores-vs-factor-loadings" id="toc-sec-loading-scores-vs-factor-loadings" class="nav-link" data-scroll-target="#sec-loading-scores-vs-factor-loadings"><span class="header-section-number">25.7.3</span> Key Differences Between Loading Scores (PCA) and Factor Loadings (FA)</a></li>
  <li><a href="#advantages-of-using-pca-and-fa" id="toc-advantages-of-using-pca-and-fa" class="nav-link" data-scroll-target="#advantages-of-using-pca-and-fa"><span class="header-section-number">25.7.4</span> Advantages of Using PCA and FA</a></li>
  <li><a href="#disadvantages-of-using-pca-and-fa" id="toc-disadvantages-of-using-pca-and-fa" class="nav-link" data-scroll-target="#disadvantages-of-using-pca-and-fa"><span class="header-section-number">25.7.5</span> Disadvantages of Using PCA and FA</a></li>
  <li><a href="#when-to-use-which-method" id="toc-when-to-use-which-method" class="nav-link" data-scroll-target="#when-to-use-which-method"><span class="header-section-number">25.7.6</span> When to Use Which Method</a></li>
  </ul></li>
  <li><a href="#sec-other-models" id="toc-sec-other-models" class="nav-link" data-scroll-target="#sec-other-models"><span class="header-section-number">25.8</span> Using Principal Components / Factors in Other Models</a>
  <ul class="collapse">
  <li><a href="#random-forest-regressor-with-the-full-dataset" id="toc-random-forest-regressor-with-the-full-dataset" class="nav-link" data-scroll-target="#random-forest-regressor-with-the-full-dataset"><span class="header-section-number">25.8.1</span> Random Forest Regressor with the Full Dataset</a></li>
  <li><a href="#random-forest-regressor-with-pca-components" id="toc-random-forest-regressor-with-pca-components" class="nav-link" data-scroll-target="#random-forest-regressor-with-pca-components"><span class="header-section-number">25.8.2</span> Random Forest Regressor with PCA Components</a></li>
  <li><a href="#random-forest-regressor-with-extracted-factors-from-fa" id="toc-random-forest-regressor-with-extracted-factors-from-fa" class="nav-link" data-scroll-target="#random-forest-regressor-with-extracted-factors-from-fa"><span class="header-section-number">25.8.3</span> Random Forest Regressor with Extracted Factors (from FA)</a></li>
  <li><a href="#sec-rf-comparison" id="toc-sec-rf-comparison" class="nav-link" data-scroll-target="#sec-rf-comparison"><span class="header-section-number">25.8.4</span> Comparison of the Random Forest Models</a></li>
  </ul></li>
  <li><a href="#videos-principal-component-analysis-pca" id="toc-videos-principal-component-analysis-pca" class="nav-link" data-scroll-target="#videos-principal-component-analysis-pca"><span class="header-section-number">25.9</span> Videos: Principal Component Analysis (PCA)</a></li>
  <li><a href="#jupyter-notebook" id="toc-jupyter-notebook" class="nav-link" data-scroll-target="#jupyter-notebook"><span class="header-section-number">25.10</span> Jupyter Notebook</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./100_ddmo_eda.html">Data-Driven Modeling and Optimization</a></li><li class="breadcrumb-item"><a href="./100_ddmo_pca.html"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Addressing Multicollinearity: Principle Component Analysis (PCA) and Factor Analysis (FA)</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Addressing Multicollinearity: Principle Component Analysis (PCA) and Factor Analysis (FA)</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="introduction" class="level2" data-number="25.1">
<h2 data-number="25.1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">25.1</span> Introduction</h2>
<p>The concepts of Principal Component Analysis (PCA) and Factor Analysis (FA) are both dimensionality reduction techniques. They operate on different assumptions and serve distinct purposes. PCA aims to transform correlated variables into a smaller set of uncorrelated principal components that capture maximum variance, whereas Factor Analysis seeks to explain the correlations between observed variables in terms of a smaller number of unobserved, underlying factors.</p>
<p>After loading and preprocessing the data in <a href="#sec-data-preprocessing" class="quarto-xref"><span>Section 25.2</span></a>, we will explore these methods to reduce dimensions and address multicollinearity. In <a href="#sec-fit-ols" class="quarto-xref"><span>Section 25.3</span></a> we will conduct linear regression on the extracted components or factors. <a href="#sec-collinearity-diagnostics" class="quarto-xref"><span>Section 25.4</span></a> provides diagnostics for multicollinearity, including the coefficient table, eigenvalues, condition indices, and the KMO measure. <a href="#sec-pca" class="quarto-xref"><span>Section 25.5</span></a> explains how PCA is applied to the data, while <a href="#sec-fa" class="quarto-xref"><span>Section 25.6</span></a> discusses Factor Analysis. Both methods are used to mitigate multicollinearity issues in regression models. <a href="#sec-other-models" class="quarto-xref"><span>Section 25.8</span></a> shows how the reduced dimensions can be used in other machine learning models, such as Random Forests.</p>
<p>The following packages are used in this chapter:</p>
<div id="309da83f" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler, OneHotEncoder</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> factor_analyzer <span class="im">import</span> FactorAnalyzer</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> factor_analyzer.factor_analyzer <span class="im">import</span> calculate_kmo</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error, r2_score</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> copy</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> spotpython.utils.stats <span class="im">import</span> condition_index</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> spotpython.utils.pca <span class="im">import</span> (get_pca, plot_pca_scree, plot_pca1vs2, get_pca_topk, get_loading_scores, plot_loading_scores)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="sec-data-preprocessing" class="level2" data-number="25.2">
<h2 data-number="25.2" class="anchored" data-anchor-id="sec-data-preprocessing"><span class="header-section-number">25.2</span> The Car-Sales Data Set</h2>
<p>First, the data is preprocessed to ensure that it does not contain any NaN or infinite values. We load the data set, which contains information about car sales, including various features such as price, engine size, horsepower, and more. The initial shape of the DataFrame is <code>(157, 27)</code>.</p>
<div id="cell-load_car_sales_data" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"data/car_sales.csv"</span>, encoding<span class="op">=</span><span class="st">"utf-8"</span>, index_col<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.shape)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(157, 27)</code></pre>
</div>
<div id="load_car_sales_data" class="cell-output cell-output-display" data-execution_count="2">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Unnamed: 0</th>
<th data-quarto-table-cell-role="th">manufact</th>
<th data-quarto-table-cell-role="th">model</th>
<th data-quarto-table-cell-role="th">sales</th>
<th data-quarto-table-cell-role="th">resale</th>
<th data-quarto-table-cell-role="th">type</th>
<th data-quarto-table-cell-role="th">price</th>
<th data-quarto-table-cell-role="th">engine_s</th>
<th data-quarto-table-cell-role="th">horsepow</th>
<th data-quarto-table-cell-role="th">wheelbas</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">ztype</th>
<th data-quarto-table-cell-role="th">zprice</th>
<th data-quarto-table-cell-role="th">zengine_</th>
<th data-quarto-table-cell-role="th">zhorsepo</th>
<th data-quarto-table-cell-role="th">zwheelba</th>
<th data-quarto-table-cell-role="th">zwidth</th>
<th data-quarto-table-cell-role="th">zlength</th>
<th data-quarto-table-cell-role="th">zcurb_wg</th>
<th data-quarto-table-cell-role="th">zfuel_ca</th>
<th data-quarto-table-cell-role="th">zmpg</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1</td>
<td>Acura</td>
<td>Integra</td>
<td>16.919</td>
<td>16.360</td>
<td>0</td>
<td>21.50</td>
<td>1.8</td>
<td>140.0</td>
<td>101.2</td>
<td>...</td>
<td>-0.592619</td>
<td>-0.410458</td>
<td>-1.207001</td>
<td>-0.810378</td>
<td>-0.822789</td>
<td>-1.115337</td>
<td>-1.112557</td>
<td>-1.172124</td>
<td>-1.222227</td>
<td>0.970527</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2</td>
<td>Acura</td>
<td>TL</td>
<td>39.384</td>
<td>19.875</td>
<td>0</td>
<td>28.40</td>
<td>3.2</td>
<td>225.0</td>
<td>108.1</td>
<td>...</td>
<td>-0.592619</td>
<td>0.070323</td>
<td>0.133157</td>
<td>0.688731</td>
<td>0.080198</td>
<td>-0.246243</td>
<td>0.413677</td>
<td>0.220418</td>
<td>-0.193400</td>
<td>0.270037</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>3</td>
<td>Acura</td>
<td>CL</td>
<td>14.114</td>
<td>18.225</td>
<td>0</td>
<td>NaN</td>
<td>3.2</td>
<td>225.0</td>
<td>106.9</td>
<td>...</td>
<td>-0.592619</td>
<td>NaN</td>
<td>0.133157</td>
<td>0.688731</td>
<td>-0.076843</td>
<td>-0.159334</td>
<td>0.346672</td>
<td>0.145875</td>
<td>-0.193400</td>
<td>0.503534</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>4</td>
<td>Acura</td>
<td>RL</td>
<td>8.588</td>
<td>29.725</td>
<td>0</td>
<td>42.00</td>
<td>3.5</td>
<td>210.0</td>
<td>114.6</td>
<td>...</td>
<td>-0.592619</td>
<td>1.017949</td>
<td>0.420333</td>
<td>0.424182</td>
<td>0.930839</td>
<td>0.072424</td>
<td>0.689144</td>
<td>0.748569</td>
<td>0.012366</td>
<td>-0.430452</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>5</td>
<td>Audi</td>
<td>A4</td>
<td>20.397</td>
<td>22.255</td>
<td>0</td>
<td>23.99</td>
<td>1.8</td>
<td>150.0</td>
<td>102.6</td>
<td>...</td>
<td>-0.592619</td>
<td>-0.236959</td>
<td>-1.207001</td>
<td>-0.634013</td>
<td>-0.639574</td>
<td>-0.854609</td>
<td>-0.695634</td>
<td>-0.602736</td>
<td>-0.399165</td>
<td>0.737030</td>
</tr>
</tbody>
</table>

<p>5 rows × 27 columns</p>
</div>
</div>
</div>
<p>The first column is removed as it’s an index or non-informative column.</p>
<div id="cell-drop_first_column" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.drop(df.columns[<span class="dv">0</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="drop_first_column" class="cell-output cell-output-display" data-execution_count="3">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">manufact</th>
<th data-quarto-table-cell-role="th">model</th>
<th data-quarto-table-cell-role="th">sales</th>
<th data-quarto-table-cell-role="th">resale</th>
<th data-quarto-table-cell-role="th">type</th>
<th data-quarto-table-cell-role="th">price</th>
<th data-quarto-table-cell-role="th">engine_s</th>
<th data-quarto-table-cell-role="th">horsepow</th>
<th data-quarto-table-cell-role="th">wheelbas</th>
<th data-quarto-table-cell-role="th">width</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">ztype</th>
<th data-quarto-table-cell-role="th">zprice</th>
<th data-quarto-table-cell-role="th">zengine_</th>
<th data-quarto-table-cell-role="th">zhorsepo</th>
<th data-quarto-table-cell-role="th">zwheelba</th>
<th data-quarto-table-cell-role="th">zwidth</th>
<th data-quarto-table-cell-role="th">zlength</th>
<th data-quarto-table-cell-role="th">zcurb_wg</th>
<th data-quarto-table-cell-role="th">zfuel_ca</th>
<th data-quarto-table-cell-role="th">zmpg</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>Acura</td>
<td>Integra</td>
<td>16.919</td>
<td>16.360</td>
<td>0</td>
<td>21.50</td>
<td>1.8</td>
<td>140.0</td>
<td>101.2</td>
<td>67.3</td>
<td>...</td>
<td>-0.592619</td>
<td>-0.410458</td>
<td>-1.207001</td>
<td>-0.810378</td>
<td>-0.822789</td>
<td>-1.115337</td>
<td>-1.112557</td>
<td>-1.172124</td>
<td>-1.222227</td>
<td>0.970527</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>Acura</td>
<td>TL</td>
<td>39.384</td>
<td>19.875</td>
<td>0</td>
<td>28.40</td>
<td>3.2</td>
<td>225.0</td>
<td>108.1</td>
<td>70.3</td>
<td>...</td>
<td>-0.592619</td>
<td>0.070323</td>
<td>0.133157</td>
<td>0.688731</td>
<td>0.080198</td>
<td>-0.246243</td>
<td>0.413677</td>
<td>0.220418</td>
<td>-0.193400</td>
<td>0.270037</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>Acura</td>
<td>CL</td>
<td>14.114</td>
<td>18.225</td>
<td>0</td>
<td>NaN</td>
<td>3.2</td>
<td>225.0</td>
<td>106.9</td>
<td>70.6</td>
<td>...</td>
<td>-0.592619</td>
<td>NaN</td>
<td>0.133157</td>
<td>0.688731</td>
<td>-0.076843</td>
<td>-0.159334</td>
<td>0.346672</td>
<td>0.145875</td>
<td>-0.193400</td>
<td>0.503534</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>Acura</td>
<td>RL</td>
<td>8.588</td>
<td>29.725</td>
<td>0</td>
<td>42.00</td>
<td>3.5</td>
<td>210.0</td>
<td>114.6</td>
<td>71.4</td>
<td>...</td>
<td>-0.592619</td>
<td>1.017949</td>
<td>0.420333</td>
<td>0.424182</td>
<td>0.930839</td>
<td>0.072424</td>
<td>0.689144</td>
<td>0.748569</td>
<td>0.012366</td>
<td>-0.430452</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>Audi</td>
<td>A4</td>
<td>20.397</td>
<td>22.255</td>
<td>0</td>
<td>23.99</td>
<td>1.8</td>
<td>150.0</td>
<td>102.6</td>
<td>68.2</td>
<td>...</td>
<td>-0.592619</td>
<td>-0.236959</td>
<td>-1.207001</td>
<td>-0.634013</td>
<td>-0.639574</td>
<td>-0.854609</td>
<td>-0.695634</td>
<td>-0.602736</td>
<td>-0.399165</td>
<td>0.737030</td>
</tr>
</tbody>
</table>

<p>5 rows × 26 columns</p>
</div>
</div>
</div>
<section id="the-target-variable" class="level3" data-number="25.2.1">
<h3 data-number="25.2.1" class="anchored" data-anchor-id="the-target-variable"><span class="header-section-number">25.2.1</span> The Target Variable</h3>
<p>The <code>sales</code> variable, which is our target, is transformed to a log scale. Missing or zero values are handled by replacing them with the median.</p>
<div id="transform_sales_variable" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'ln_sales'</span>] <span class="op">=</span> np.log(df[<span class="st">'sales'</span>].replace(<span class="dv">0</span>, np.nan))</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> df[<span class="st">'ln_sales'</span>].isnull().<span class="bu">any</span>() <span class="kw">or</span> np.isinf(df[<span class="st">'ln_sales'</span>]).<span class="bu">any</span>():</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'ln_sales'</span>] <span class="op">=</span> df[<span class="st">'ln_sales'</span>].fillna(df[<span class="st">'ln_sales'</span>].median()) <span class="co"># Or any other strategy</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">'ln_sales'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="the-features" class="level3" data-number="25.2.2">
<h3 data-number="25.2.2" class="anchored" data-anchor-id="the-features"><span class="header-section-number">25.2.2</span> The Features</h3>
<section id="numerical-features" class="level4" data-number="25.2.2.1">
<h4 data-number="25.2.2.1" class="anchored" data-anchor-id="numerical-features"><span class="header-section-number">25.2.2.1</span> Numerical Features</h4>
<p>The following steps are performed during data preprocessing for numerical features:</p>
<ol type="1">
<li>Check for NaN or infinite values in X.</li>
<li>Replace NaN and infinite values with the median of the respective column.</li>
<li>Remove constant or nearly constant columns (not explicitly shown in code but stated in preprocessing steps).</li>
<li>Standardize the numerical predictors in X using StandardScaler.</li>
<li>Verify that X_scaled does not contain any NaN or infinite values.</li>
</ol>
<div id="3af0e629" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use columns from 'price' to 'mpg' as predictors</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>independent_var_columns <span class="op">=</span> [<span class="st">'price'</span>, <span class="st">'engine_s'</span>, <span class="st">'horsepow'</span>, <span class="st">'wheelbas'</span>,</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>                           <span class="st">'width'</span>, <span class="st">'length'</span>, <span class="st">'curb_wgt'</span>, <span class="st">'fuel_cap'</span>, <span class="st">'mpg'</span>]</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Select those columns, ensuring they are numeric</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df[independent_var_columns].<span class="bu">apply</span>(pd.to_numeric, errors<span class="op">=</span><span class="st">'coerce'</span>)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Handle missing/nans in features by using an appropriate imputation strategy</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> X.fillna(X.median()) <span class="co"># Impute with median or any other appropriate strategy</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the first few rows of the features</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>X.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">price</th>
<th data-quarto-table-cell-role="th">engine_s</th>
<th data-quarto-table-cell-role="th">horsepow</th>
<th data-quarto-table-cell-role="th">wheelbas</th>
<th data-quarto-table-cell-role="th">width</th>
<th data-quarto-table-cell-role="th">length</th>
<th data-quarto-table-cell-role="th">curb_wgt</th>
<th data-quarto-table-cell-role="th">fuel_cap</th>
<th data-quarto-table-cell-role="th">mpg</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>21.500</td>
<td>1.8</td>
<td>140.0</td>
<td>101.2</td>
<td>67.3</td>
<td>172.4</td>
<td>2.639</td>
<td>13.2</td>
<td>28.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>28.400</td>
<td>3.2</td>
<td>225.0</td>
<td>108.1</td>
<td>70.3</td>
<td>192.9</td>
<td>3.517</td>
<td>17.2</td>
<td>25.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>22.799</td>
<td>3.2</td>
<td>225.0</td>
<td>106.9</td>
<td>70.6</td>
<td>192.0</td>
<td>3.470</td>
<td>17.2</td>
<td>26.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>42.000</td>
<td>3.5</td>
<td>210.0</td>
<td>114.6</td>
<td>71.4</td>
<td>196.6</td>
<td>3.850</td>
<td>18.0</td>
<td>22.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>23.990</td>
<td>1.8</td>
<td>150.0</td>
<td>102.6</td>
<td>68.2</td>
<td>178.0</td>
<td>2.998</td>
<td>16.4</td>
<td>27.0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="dba323f0" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> X.isnull().<span class="bu">any</span>().<span class="bu">any</span>():</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"NaNs detected in X. Filling with column medians."</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> X.fillna(X.median())</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>X_scaled <span class="op">=</span> scaler.fit_transform(X)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> np.isnan(X_scaled).<span class="bu">any</span>() <span class="kw">or</span> np.isinf(X_scaled).<span class="bu">any</span>():</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"X_scaled contains NaN or infinite values after preprocessing."</span>)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the scaled data back to a DataFrame</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>X_scaled <span class="op">=</span> pd.DataFrame(X_scaled, columns<span class="op">=</span>X.columns)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the first few rows of the scaled features</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>X_scaled.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">price</th>
<th data-quarto-table-cell-role="th">engine_s</th>
<th data-quarto-table-cell-role="th">horsepow</th>
<th data-quarto-table-cell-role="th">wheelbas</th>
<th data-quarto-table-cell-role="th">width</th>
<th data-quarto-table-cell-role="th">length</th>
<th data-quarto-table-cell-role="th">curb_wgt</th>
<th data-quarto-table-cell-role="th">fuel_cap</th>
<th data-quarto-table-cell-role="th">mpg</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>-0.410053</td>
<td>-1.214376</td>
<td>-0.814577</td>
<td>-0.827661</td>
<td>-1.121287</td>
<td>-1.119971</td>
<td>-1.182726</td>
<td>-1.228700</td>
<td>0.982411</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0.075070</td>
<td>0.134385</td>
<td>0.694066</td>
<td>0.081122</td>
<td>-0.246689</td>
<td>0.416070</td>
<td>0.223285</td>
<td>-0.193381</td>
<td>0.272833</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>-0.318723</td>
<td>0.134385</td>
<td>0.694066</td>
<td>-0.076927</td>
<td>-0.159229</td>
<td>0.348634</td>
<td>0.148020</td>
<td>-0.193381</td>
<td>0.509359</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1.031255</td>
<td>0.423406</td>
<td>0.427835</td>
<td>0.937221</td>
<td>0.073997</td>
<td>0.693306</td>
<td>0.756545</td>
<td>0.013683</td>
<td>-0.436744</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>-0.234987</td>
<td>-1.214376</td>
<td>-0.637089</td>
<td>-0.643270</td>
<td>-0.858907</td>
<td>-0.700370</td>
<td>-0.607830</td>
<td>-0.400444</td>
<td>0.745885</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="categorical-features" class="level4" data-number="25.2.2.2">
<h4 data-number="25.2.2.2" class="anchored" data-anchor-id="categorical-features"><span class="header-section-number">25.2.2.2</span> Categorical Features</h4>
<p>Categorical features (like ‘type’) are one-hot encoded and then combined with the scaled numerical features.</p>
<div id="4b39e419" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>categorical_cols <span class="op">=</span> [<span class="st">'type'</span>] <span class="co"># Replace if more categorical variables exist</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>encoder <span class="op">=</span> OneHotEncoder(drop<span class="op">=</span><span class="st">'first'</span>, sparse_output<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>X_categorical_encoded <span class="op">=</span> encoder.fit_transform(df[categorical_cols])</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert encoded data into a DataFrame</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>X_categorical_encoded_df <span class="op">=</span> pd.DataFrame(X_categorical_encoded,</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>                                        columns<span class="op">=</span>encoder.get_feature_names_out(categorical_cols))</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>X_categorical_encoded_df.describe(include<span class="op">=</span><span class="st">'all'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">type_1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">count</td>
<td>157.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">mean</td>
<td>0.261146</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">std</td>
<td>0.440665</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">min</td>
<td>0.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">25%</td>
<td>0.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">50%</td>
<td>0.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">75%</td>
<td>1.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">max</td>
<td>1.000000</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
</section>
<section id="combining-non-categorical-and-categorical-encoded-data" class="level3" data-number="25.2.3">
<h3 data-number="25.2.3" class="anchored" data-anchor-id="combining-non-categorical-and-categorical-encoded-data"><span class="header-section-number">25.2.3</span> Combining Non-categorical and Categorical (encoded) Data</h3>
<p>The final feature set <code>X_encoded</code> is created by concatenating the scaled numerical features and the one-hot encoded categorical features. This combined DataFrame will be used for regression analysis.</p>
<div id="f21a7167" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>X_encoded <span class="op">=</span> pd.concat([X_scaled, X_categorical_encoded_df], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Dimension: </span><span class="sc">{</span>X_encoded<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">list</span>(X_encoded.columns))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Dimension: (157, 10)
['price', 'engine_s', 'horsepow', 'wheelbas', 'width', 'length', 'curb_wgt', 'fuel_cap', 'mpg', 'type_1']</code></pre>
</div>
</div>
<div id="856ce04e" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>X_encoded.describe(include<span class="op">=</span><span class="st">'all'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">price</th>
<th data-quarto-table-cell-role="th">engine_s</th>
<th data-quarto-table-cell-role="th">horsepow</th>
<th data-quarto-table-cell-role="th">wheelbas</th>
<th data-quarto-table-cell-role="th">width</th>
<th data-quarto-table-cell-role="th">length</th>
<th data-quarto-table-cell-role="th">curb_wgt</th>
<th data-quarto-table-cell-role="th">fuel_cap</th>
<th data-quarto-table-cell-role="th">mpg</th>
<th data-quarto-table-cell-role="th">type_1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">count</td>
<td>1.570000e+02</td>
<td>1.570000e+02</td>
<td>1.570000e+02</td>
<td>1.570000e+02</td>
<td>1.570000e+02</td>
<td>1.570000e+02</td>
<td>1.570000e+02</td>
<td>1.570000e+02</td>
<td>1.570000e+02</td>
<td>157.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">mean</td>
<td>-5.091469e-16</td>
<td>1.018294e-16</td>
<td>1.584012e-16</td>
<td>3.892145e-15</td>
<td>-2.489162e-16</td>
<td>-1.584012e-16</td>
<td>-2.941737e-16</td>
<td>5.657187e-17</td>
<td>1.980016e-17</td>
<td>0.261146</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">std</td>
<td>1.003200e+00</td>
<td>1.003200e+00</td>
<td>1.003200e+00</td>
<td>1.003200e+00</td>
<td>1.003200e+00</td>
<td>1.003200e+00</td>
<td>1.003200e+00</td>
<td>1.003200e+00</td>
<td>1.003200e+00</td>
<td>0.440665</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">min</td>
<td>-1.272376e+00</td>
<td>-1.985097e+00</td>
<td>-2.323220e+00</td>
<td>-1.960346e+00</td>
<td>-2.491490e+00</td>
<td>-2.843334e+00</td>
<td>-2.374152e+00</td>
<td>-1.979307e+00</td>
<td>-2.092426e+00</td>
<td>0.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">25%</td>
<td>-6.459349e-01</td>
<td>-7.326758e-01</td>
<td>-6.370894e-01</td>
<td>-5.905870e-01</td>
<td>-8.006008e-01</td>
<td>-7.303412e-01</td>
<td>-6.446622e-01</td>
<td>-5.557424e-01</td>
<td>-6.732705e-01</td>
<td>0.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">50%</td>
<td>-3.187230e-01</td>
<td>-5.829498e-02</td>
<td>-1.489990e-01</td>
<td>-6.375655e-02</td>
<td>-1.738055e-01</td>
<td>4.142561e-02</td>
<td>-5.695606e-02</td>
<td>-1.933806e-01</td>
<td>3.630749e-02</td>
<td>0.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">75%</td>
<td>3.232563e-01</td>
<td>4.234056e-01</td>
<td>5.165788e-01</td>
<td>6.211231e-01</td>
<td>6.570627e-01</td>
<td>6.558419e-01</td>
<td>6.412452e-01</td>
<td>4.019282e-01</td>
<td>5.093595e-01</td>
<td>1.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">max</td>
<td>4.089638e+00</td>
<td>4.758711e+00</td>
<td>4.687533e+00</td>
<td>4.111375e+00</td>
<td>2.552025e+00</td>
<td>2.783820e+00</td>
<td>3.514119e+00</td>
<td>3.637302e+00</td>
<td>5.003353e+00</td>
<td>1.000000</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
</section>
<section id="sec-fit-ols" class="level2" data-number="25.3">
<h2 data-number="25.3" class="anchored" data-anchor-id="sec-fit-ols"><span class="header-section-number">25.3</span> Fit the Linear Regression Model</h2>
<p>An Ordinary Least Squares (OLS) regression model is fitted using the preprocessed and combined features (<code>X_encoded</code>).</p>
<div id="1b602b62" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>X_encoded_with_const <span class="op">=</span> sm.add_constant(X_encoded) <span class="co"># Adds a constant term (intercept) to the model</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> sm.OLS(df[<span class="st">'ln_sales'</span>], X_encoded_with_const).fit()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="model-summary-and-interpretation" class="level3" data-number="25.3.1">
<h3 data-number="25.3.1" class="anchored" data-anchor-id="model-summary-and-interpretation"><span class="header-section-number">25.3.1</span> Model Summary and Interpretation</h3>
<section id="model-summary-anova-table" class="level4" data-number="25.3.1.1">
<h4 data-number="25.3.1.1" class="anchored" data-anchor-id="model-summary-anova-table"><span class="header-section-number">25.3.1.1</span> Model Summary (ANOVA Table)</h4>
<p>The ANOVA table shows a significant F-value (Prob (F-statistic) close to zero), indicating that the model is statistically significant and better than simply estimating the mean. The Adj. R-squared value, close to 0.40, suggests that nearly 40% of the variation in <code>ln_sales</code> is explained by the model.</p>
<div id="d2831fe0" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:               ln_sales   R-squared:                       0.485
Model:                            OLS   Adj. R-squared:                  0.449
Method:                 Least Squares   F-statistic:                     13.73
Date:                Tue, 05 Aug 2025   Prob (F-statistic):           7.69e-17
Time:                        21:49:10   Log-Likelihood:                -213.62
No. Observations:                 157   AIC:                             449.2
Df Residuals:                     146   BIC:                             482.9
Df Model:                          10                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const          3.0678      0.114     26.962      0.000       2.843       3.293
price         -0.6451      0.177     -3.655      0.000      -0.994      -0.296
engine_s       0.3557      0.192      1.854      0.066      -0.023       0.735
horsepow      -0.1364      0.229     -0.596      0.552      -0.589       0.316
wheelbas       0.3166      0.174      1.816      0.071      -0.028       0.661
width         -0.0763      0.140     -0.547      0.586      -0.352       0.200
length         0.2029      0.185      1.099      0.273      -0.162       0.568
curb_wgt       0.0842      0.211      0.399      0.691      -0.333       0.501
fuel_cap      -0.2284      0.179     -1.276      0.204      -0.582       0.125
mpg            0.3232      0.167      1.941      0.054      -0.006       0.652
type_1         0.8735      0.317      2.756      0.007       0.247       1.500
==============================================================================
Omnibus:                       41.296   Durbin-Watson:                   1.423
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              107.145
Skew:                          -1.064   Prob(JB):                     5.42e-24
Kurtosis:                       6.442   Cond. No.                         11.4
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre>
</div>
</div>
<p>Despite the positive model fit, many predictors show non-significant coefficients (P&gt;|t| much larger than 0.05), suggesting they contribute little to the model.</p>
</section>
</section>
</section>
<section id="sec-collinearity-diagnostics" class="level2" data-number="25.4">
<h2 data-number="25.4" class="anchored" data-anchor-id="sec-collinearity-diagnostics"><span class="header-section-number">25.4</span> Collinearity Diagnostics</h2>
<section id="the-coefficient-table" class="level3" data-number="25.4.1">
<h3 data-number="25.4.1" class="anchored" data-anchor-id="the-coefficient-table"><span class="header-section-number">25.4.1</span> The Coefficient Table</h3>
<p>The coefficient table provides further evidence of multicollinearity. The function <code>compute_coefficients_table()</code> from the <code>spotpython</code> package is used here for comprehensive diagnostics.</p>
<div id="76132861" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> spotpython.utils.stats <span class="im">import</span> compute_coefficients_table</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>coeffs_table <span class="op">=</span> compute_coefficients_table(</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model, X_encoded<span class="op">=</span>X_encoded_with_const, y<span class="op">=</span>y, vif_table<span class="op">=</span><span class="va">None</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Coefficients Table:"</span>)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(coeffs_table)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Coefficients Table:
   Variable  Zero-Order r  Partial r  Semipartial r  Tolerance       VIF
0     price     -0.551325  -0.289521      -0.217155   0.195662  5.110865
1  engine_s     -0.139066   0.151682       0.110172   0.165615  6.038084
2  horsepow     -0.386896  -0.049229      -0.035386   0.116244  8.602562
3  wheelbas      0.292461   0.148618       0.107895   0.200566  4.985881
4     width      0.040572  -0.045185      -0.032473   0.312675  3.198207
5    length      0.216882   0.090597       0.065310   0.178835  5.591740
6  curb_wgt     -0.040042   0.032981       0.023691   0.136742  7.313045
7  fuel_cap     -0.017278  -0.105041      -0.075831   0.190355  5.253349
8       mpg      0.119998   0.158587       0.115313   0.219810  4.549388
9    type_1      0.273500   0.222382       0.163754   0.314477  3.179880</code></pre>
</div>
</div>
<p>For most predictors, the partial correlations (Partial r) decrease significantly compared to the zero-order correlations (Zero-Order r), which suggests multicollinearity. Tolerance values (1 minus the proportion of variance explained by other predictors) are low, indicating that approximately 70%-90% of a given predictor’s variance can be explained by other predictors. Tolerances close to 0 signify high multicollinearity. A Variance Inflation Factor (VIF) greater than 2 is typically considered problematic, and in this table, the smallest VIF is already greater than 2, confirming serious multicollinearity.</p>
</section>
<section id="eigenvalues-and-condition-indices" class="level3" data-number="25.4.2">
<h3 data-number="25.4.2" class="anchored" data-anchor-id="eigenvalues-and-condition-indices"><span class="header-section-number">25.4.2</span> Eigenvalues and Condition Indices</h3>
<p>Eigenvalues indicate how many factors or components can be meaningfully extracted. An eigenvalue greater than 1 suggests that the factor/component explains more variance than a single variable.</p>
<section id="eigenvalues" class="level4" data-number="25.4.2.1">
<h4 data-number="25.4.2.1" class="anchored" data-anchor-id="eigenvalues"><span class="header-section-number">25.4.2.1</span> Eigenvalues</h4>
<p>We use the <code>FactorAnalyzer</code> function from the <code>factor_analyzer</code> package to compute eigenvalues.</p>
<div id="f4fe33dc" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>fa_temp <span class="op">=</span> FactorAnalyzer(n_factors<span class="op">=</span>X_encoded.shape[<span class="dv">1</span>], method<span class="op">=</span><span class="st">"principal"</span>, rotation<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    fa_temp.fit(X_encoded)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    ev, _ <span class="op">=</span> fa_temp.get_eigenvalues()</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    ev <span class="op">=</span> np.sort(ev) <span class="co"># The source prints in ascending order</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Eigenvalues for each component:</span><span class="ch">\n</span><span class="st">"</span>, ev)</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Error during factor analysis fitting: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Consider reducing multicollinearity or removing problematic features."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Eigenvalues for each component:
 [0.06453844 0.09238346 0.13143422 0.15658714 0.20129034 0.25457714
 0.33712112 1.14556836 1.64880929 5.96769049]</code></pre>
</div>
</div>
<p>The eigenvalue-based diagnostics confirm severe multicollinearity. Several eigenvalues are close to 0, indicating strong correlations among predictors.</p>
</section>
<section id="condition-indices" class="level4" data-number="25.4.2.2">
<h4 data-number="25.4.2.2" class="anchored" data-anchor-id="condition-indices"><span class="header-section-number">25.4.2.2</span> Condition Indices</h4>
<p>From <code>spotpython.utils.stats</code>, we can compute the condition index, which is a measure of multicollinearity. A condition index greater than 15 suggests potential multicollinearity issues, and values above 30 indicate severe problems.</p>
<p>Condition indices, calculated as the square roots of the ratios of the largest eigenvalue to each subsequent eigenvalue, also highlight the issue.</p>
<div id="def-condition_index" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 25.1 (Condition Index)</strong></span> The Condition Index (<span class="math inline">\(CI_i\)</span>) for the <span class="math inline">\(i\)</span>-th eigenvalue is defined as: <span class="math display">\[
\text{CI}_i = \sqrt{\frac{\lambda{\max}}{\lambda_i}},
\]</span> where <span class="math inline">\(\lambda_{\max}\)</span> is the largest eigenvalue of the scaled predictor correlation matrix, and <span class="math inline">\(\lambda_i\)</span> is the <span class="math inline">\(i\)</span>-th eigenvalue of the same matrix.</p>
</div>
<p><span class="math inline">\(CI_i\)</span>-values greater than 15 suggest a potential problem, and values over 30 indicate a severe problem.</p>
<div id="b012c167" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>X_cond <span class="op">=</span> copy.deepcopy(X_encoded)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>condition_index_df <span class="op">=</span> condition_index(X_cond)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Condition Index:"</span>)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(condition_index_df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Condition Index:
   Index  Eigenvalue  Condition Index
0      0    0.047116        11.150268
1      1    0.067199         9.336595
2      2    0.121066         6.955955
3      3    0.146634         6.320499
4      4    0.157663         6.095428
5      5    0.248119         4.858905
6      6    0.338187         4.161884
7      7    0.736900         2.819449
8      8    1.531162         1.955951
9      9    5.857833         1.000000</code></pre>
</div>
</div>
</section>
</section>
<section id="kayser-meyer-olkin-kmo-measure" class="level3" data-number="25.4.3">
<h3 data-number="25.4.3" class="anchored" data-anchor-id="kayser-meyer-olkin-kmo-measure"><span class="header-section-number">25.4.3</span> Kayser-Meyer-Olkin (KMO) Measure</h3>
<p>The KMO (Kaiser-Meyer-Olkin) measure is a metric for assessing the suitability of data for Factor Analysis. A KMO value of 0.6 or higher is generally considered acceptable, while a value below 0.5 indicates that the data is not suitable for Factor Analysis.</p>
<p>The KMO measure is based on the correlation and partial correlation between variables. It is calculated as the ratio of the squared sums of correlations to the squared sums of correlations plus the squared sums of partial correlations. KMO values range between 0 and 1, where values close to 1 suggest strong correlations and suitability for Factor Analysis, and values close to 0 indicate weak correlations and unsuitability.</p>
<div id="0b3f1b52" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>kmo_all, kmo_model <span class="op">=</span> calculate_kmo(X_encoded)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">KMO measure: </span><span class="sc">{</span>kmo_model<span class="sc">:.3f}</span><span class="ss"> (0.6+ is often considered acceptable)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
KMO measure: 0.835 (0.6+ is often considered acceptable)</code></pre>
</div>
</div>
<p>A KMO measure of 0.835 indicates that the data is well-suited for Factor Analysis.</p>
</section>
</section>
<section id="sec-pca" class="level2" data-number="25.5">
<h2 data-number="25.5" class="anchored" data-anchor-id="sec-pca"><span class="header-section-number">25.5</span> Addressing Multicollinearity with Principal Component Analysis (PCA)</h2>
<div id="def-multicoll" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 25.2 (Multicollinearity and Multicorrelation)</strong></span> Multicorrelation is a general term that describes correlation between multiple variables. Multicollinearity is a specific problem in regression models caused by strong correlations between independent variables, making model interpretation difficult.</p>
</div>
<section id="introduction-to-pca" class="level3" data-number="25.5.1">
<h3 data-number="25.5.1" class="anchored" data-anchor-id="introduction-to-pca"><span class="header-section-number">25.5.1</span> Introduction to PCA</h3>
<p>Principal Component Analysis (PCA) is a popular unsupervised dimensionality reduction technique. It transforms a set of possibly correlated variables into a set of linearly uncorrelated variables called principal components. The first principal component accounts for as much of the variability in the data as possible, and each succeeding component accounts for as much of the remaining variability as possible. PCA is primarily used for data compression and simplifying complex datasets.</p>
</section>
<section id="application-of-pca-in-regression-problems" class="level3" data-number="25.5.2">
<h3 data-number="25.5.2" class="anchored" data-anchor-id="application-of-pca-in-regression-problems"><span class="header-section-number">25.5.2</span> Application of PCA in Regression Problems:</h3>
<ul>
<li><strong>Dimensionality Reduction:</strong> PCA reduces the number of explanatory variables by transforming original variables into a smaller set of uncorrelated principal components, making regression algorithms less prone to overfitting, especially with many features.</li>
<li><strong>Reducing Multicollinearity:</strong> PCA effectively eliminates multicollinearity in linear regression models because the resulting principal components are orthogonal (uncorrelated) to each other, leading to more stable coefficient estimates.</li>
<li><strong>Handling High-Dimensional Data:</strong> It can reduce the dimensions of datasets with many variables to a manageable level before regression.</li>
<li><strong>Reduced Overfitting Tendencies:</strong> By removing redundant and highly correlated variables, PCA helps reduce the risk of overfitting by focusing the model on the most influential features.</li>
<li><strong>Improved Model Performance:</strong> Performing regression on the most important principal components often leads to better generalization and improved model performance on new data.</li>
<li><strong>Interpretation of Feature Importance:</strong> PCA provides insights into the importance of original features through the variance explained by each principal component, which can identify combinations of variables best representing the data.</li>
</ul>
</section>
<section id="scree-plot" class="level3" data-number="25.5.3">
<h3 data-number="25.5.3" class="anchored" data-anchor-id="scree-plot"><span class="header-section-number">25.5.3</span> Scree Plot</h3>
<div id="def-scree-plot" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 25.3 (Scree Plot)</strong></span> A scree plot is a graphical representation of the eigenvalues of a covariance or correlation matrix in descending order. It is used to determine the number of significant components or factors in dimensionality reduction techniques.</p>
<p>Mathematically, the eigenvalues <span class="math inline">\(\lambda_1, \lambda_2, \dots, \lambda_p\)</span> are plotted against their corresponding component or factor indices <span class="math inline">\(i = 1, 2, \dots, p\)</span>, where <span class="math inline">\(p\)</span> is the total number of components or factors.</p>
<p>The eigenvalues are defined as:</p>
<p><span class="math display">\[
\lambda_i = \text{Var}(\mathbf{z}_i),
\]</span></p>
<p>where <span class="math inline">\(\mathbf{z}_i\)</span> is the <span class="math inline">\(i\)</span>-th principal component or factor, and <span class="math inline">\(\text{Var}(\mathbf{z}_i)\)</span> is its variance.</p>
<p>The scree plot is constructed by plotting the points <span class="math inline">\((i, \lambda_i)\)</span> for <span class="math inline">\(i = 1, 2, \dots, p\)</span>. The “elbow” in the plot, where the eigenvalues start to level off, indicates the optimal number of components or factors to retain.</p>
</div>
</section>
<section id="loading-scores-for-pca" class="level3" data-number="25.5.4">
<h3 data-number="25.5.4" class="anchored" data-anchor-id="loading-scores-for-pca"><span class="header-section-number">25.5.4</span> Loading Scores (for PCA)</h3>
<p>Loading scores in the context of Principal Component Analysis (PCA) represent the correlation or relationship between the original variables and the principal components.</p>
<div id="def-loading_scores" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 25.4 (Loading Scores)</strong></span> The loading score for the <span class="math inline">\(j\)</span>-th variable on the <span class="math inline">\(i\)</span>-th principal component is defined as:</p>
<p><span class="math display">\[
L_{ij} = \mathbf{a}_i^\top \mathbf{x}_j,
\]</span></p>
<p>where:</p>
<p><span class="math inline">\(\mathbf{a}_i\)</span> is the eigenvector corresponding to the <span class="math inline">\(i\)</span>-th principal component, <span class="math inline">\(\mathbf{x}_j\)</span> is the standardized value of the <span class="math inline">\(j\)</span>-th variable.</p>
</div>
<p>In PCA, the loading scores indicate how much each original variable contributes to a given principal component. High absolute values of <span class="math inline">\(L_{ij}\)</span> suggest that the <span class="math inline">\(j\)</span>-th variable strongly influences the <span class="math inline">\(i\)</span>-th principal component. In PCA, loading scores can be viewed as directional vectors in the feature space. The magnitude of the score indicates how dominant the variable is in a component, while the sign represents the direction of the relationship. A high positive loading means a positive influence and correlation with the component, and a high negative loading indicates a negative correlation. Loading score values also show how much each original variable contributes to the explained variance in its respective principal component.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Summary of Loading Scores
</div>
</div>
<div class="callout-body-container callout-body">
<p>Loading scores are used in Principal Component Analysis (PCA).</p>
<ul>
<li>Definition: Loading scores represent the correlation or relationship between the original variables and the principal components.</li>
<li>Purpose: They indicate how much each original variable contributes to a given principal component.</li>
<li>Mathematical Representation: In PCA, the loading scores are the elements of the eigenvectors of the covariance (or correlation) matrix, scaled by the square root of the corresponding eigenvalues.</li>
<li>Interpretation: High absolute values of loading scores suggest that the variable strongly influences the corresponding principal component.</li>
</ul>
</div>
</div>
<p><a href="#sec-loading-scores-vs-factor-loadings" class="quarto-xref"><span>Section 25.7.3</span></a> explains the difference between loading scores in PCA and factor loadings in FA.</p>
</section>
<section id="pca-for-car-sales-example" class="level3" data-number="25.5.5">
<h3 data-number="25.5.5" class="anchored" data-anchor-id="pca-for-car-sales-example"><span class="header-section-number">25.5.5</span> PCA for Car Sales Example</h3>
<section id="computing-the-principal-components" class="level4" data-number="25.5.5.1">
<h4 data-number="25.5.5.1" class="anchored" data-anchor-id="computing-the-principal-components"><span class="header-section-number">25.5.5.1</span> Computing the Principal Components</h4>
<p>The Principal Component Analysis (PCA) is applied only to the features (<code>X_encoded</code>), not to the target variable. We will use functions from <code>spotpython.utils.pca</code>, which are based on <code>sklearn.decomposition.PCA</code> to perform PCA.</p>
<p>Step 1: Perform PCA and scale the data</p>
<div id="pca_car_sales" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>pca, scaled_data, feature_names, sample_names, df_pca_components <span class="op">=</span> get_pca(df<span class="op">=</span>X_encoded, n_components<span class="op">=</span><span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Step 2: Plot the scree plot</p>
<div id="cell-fig-scree_plot_pca-1" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>plot_pca_scree(pca, df_name<span class="op">=</span><span class="st">"Car Sales Data"</span>, max_scree<span class="op">=</span><span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div id="fig-scree_plot_pca-1" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-scree_plot_pca-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="100_ddmo_pca_files/figure-html/fig-scree_plot_pca-1-output-1.png" width="957" height="523" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-scree_plot_pca-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;25.1: Scree plot for PCA showing the explained variance ratio for each principal component.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Step 3: Plot the first two principal components</p>
<div id="cell-fig-pcvals2" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>plot_pca1vs2(pca, df_pca_components, df_name<span class="op">=</span><span class="st">"Car Sales Data"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div id="fig-pcvals2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pcvals2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="100_ddmo_pca_files/figure-html/fig-pcvals2-output-1.png" width="959" height="523" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pcvals2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;25.2: Scatter plot of the first two principal components (PC1 vs PC2) for the Car Sales Data.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Step 4: Get the top k features influencing PC1 and PC2</p>
<div id="pca_top_k_features" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>top_k_features_pc1, top_k_features_pc2 <span class="op">=</span> get_pca_topk(pca, feature_names, k<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Top 10 features influencing PC1:"</span>, top_k_features_pc1)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Top 10 features influencing PC2:"</span>, top_k_features_pc2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Top 10 features influencing PC1: ['curb_wgt', 'engine_s', 'fuel_cap', 'mpg', 'width', 'horsepow', 'length', 'wheelbas', 'price', 'type_1']
Top 10 features influencing PC2: ['price', 'wheelbas', 'horsepow', 'length', 'engine_s', 'width', 'fuel_cap', 'type_1', 'mpg', 'curb_wgt']</code></pre>
</div>
</div>
</section>
<section id="loading-scores-for-pca-10-components" class="level4" data-number="25.5.5.2">
<h4 data-number="25.5.5.2" class="anchored" data-anchor-id="loading-scores-for-pca-10-components"><span class="header-section-number">25.5.5.2</span> Loading Scores for PCA (10 Components)</h4>
<div id="pca_loading_scores-10" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get and print loading scores</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>loading_scores_df <span class="op">=</span> get_loading_scores(pca, X_encoded.columns)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"PCA Loading Scores (10 Components):</span><span class="ch">\n</span><span class="st">"</span>, loading_scores_df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>PCA Loading Scores (10 Components):
                PC1       PC2       PC3       PC4       PC5       PC6  \
price     0.251214  0.568904  0.145341 -0.484049  0.335697 -0.164197   
engine_s  0.364662  0.204801  0.120816  0.392355 -0.419180  0.432765   
horsepow  0.317527  0.438619  0.305988  0.022026 -0.199571 -0.072824   
wheelbas  0.300637 -0.470803  0.154529 -0.380962 -0.080738 -0.283304   
width     0.343110 -0.186317  0.239367  0.582904  0.634863 -0.193732   
length    0.302587 -0.398562  0.440896 -0.197738 -0.274463  0.077374   
curb_wgt  0.382220 -0.036672 -0.252691 -0.118033  0.162548  0.314687   
fuel_cap  0.358821 -0.102589 -0.424633 -0.203499  0.220563  0.384133   
mpg      -0.351143 -0.076695  0.468213 -0.176015  0.326376  0.640074   
type_1    0.072646 -0.095107 -0.362901  0.030564 -0.072634  0.019721   

               PC7       PC8       PC9      PC10  
price    -0.009121 -0.098316 -0.395916  0.227288  
engine_s  0.279081 -0.161115 -0.433737 -0.039611  
horsepow  0.132544  0.184063  0.718133 -0.019567  
wheelbas  0.568127 -0.236665 -0.001192 -0.231065  
width     0.030011  0.022386 -0.009774  0.091688  
length   -0.517766  0.214795 -0.090943  0.335102  
curb_wgt -0.410187 -0.591957  0.262427 -0.248584  
fuel_cap  0.163440  0.640656 -0.004986 -0.074928  
mpg       0.243304 -0.105455  0.148714  0.109367  
type_1    0.241967 -0.236377  0.200080  0.832423  </code></pre>
</div>
</div>
<p><a href="#fig-pca_loading_scores-10" class="quarto-xref">Figure&nbsp;<span>25.3</span></a> shows the loading scores heatmap for the first 10 principal components. The heatmap visualizes how much each original feature contributes to each principal component, with darker colors indicating stronger contributions.</p>
<div id="cell-fig-pca_loading_scores-10" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>plot_loading_scores(loading_scores_df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div id="fig-pca_loading_scores-10" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pca_loading_scores-10-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="100_ddmo_pca_files/figure-html/fig-pca_loading_scores-10-output-1.png" width="1081" height="758" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pca_loading_scores-10-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;25.3: PCA Loading Scores Heatmap showing the influence of original features on the principal components.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="creating-the-regression-model-with-principal-components" class="level3" data-number="25.5.6">
<h3 data-number="25.5.6" class="anchored" data-anchor-id="creating-the-regression-model-with-principal-components"><span class="header-section-number">25.5.6</span> Creating the Regression Model with Principal Components</h3>
<p>Now, a linear regression model is fitted using the principal components derived from PCA. These components are uncorrelated, which should eliminate multicollinearity issues.</p>
<div id="c35800e9" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>X_pca_model_with_const <span class="op">=</span> sm.add_constant(df_pca_components)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>model_pca <span class="op">=</span> sm.OLS(y, X_pca_model_with_const).fit()</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Regression on PCA Components:"</span>)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model_pca.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Regression on PCA Components:
                            OLS Regression Results                            
==============================================================================
Dep. Variable:               ln_sales   R-squared:                       0.485
Model:                            OLS   Adj. R-squared:                  0.449
Method:                 Least Squares   F-statistic:                     13.73
Date:                Tue, 05 Aug 2025   Prob (F-statistic):           7.69e-17
Time:                        21:49:11   Log-Likelihood:                -213.62
No. Observations:                 157   AIC:                             449.2
Df Residuals:                     146   BIC:                             482.9
Df Model:                          10                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const          3.2959      0.078     42.215      0.000       3.142       3.450
PC1           -0.0450      0.032     -1.392      0.166      -0.109       0.019
PC2           -0.6572      0.063    -10.383      0.000      -0.782      -0.532
PC3           -0.0624      0.091     -0.683      0.495      -0.243       0.118
PC4            0.2500      0.135      1.856      0.065      -0.016       0.516
PC5           -0.4628      0.157     -2.943      0.004      -0.774      -0.152
PC6            0.3734      0.197      1.893      0.060      -0.016       0.763
PC7            0.3777      0.205      1.847      0.067      -0.027       0.782
PC8           -0.4887      0.225     -2.171      0.032      -0.934      -0.044
PC9            0.2311      0.302      0.765      0.445      -0.366       0.828
PC10           0.5885      0.361      1.631      0.105      -0.125       1.302
==============================================================================
Omnibus:                       41.296   Durbin-Watson:                   1.423
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              107.145
Skew:                          -1.064   Prob(JB):                     5.42e-24
Kurtosis:                       6.442   Cond. No.                         11.2
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre>
</div>
</div>
<p>When all principal components are retained, the PCA regression model performs identically to the original OLS model in terms of R-squared, Adjusted R-squared, MSE, and RMSE. This is because PCA merely rotates the data, preserving all variance if all components are used. Its benefit lies in handling multicollinearity and enabling dimensionality reduction if fewer components are chosen without significant loss of information.</p>
</section>
<section id="collinearity-diagnostics-for-pca-regression-model" class="level3" data-number="25.5.7">
<h3 data-number="25.5.7" class="anchored" data-anchor-id="collinearity-diagnostics-for-pca-regression-model"><span class="header-section-number">25.5.7</span> Collinearity Diagnostics for PCA Regression Model</h3>
<p>Consider the eigenvalues of the PCA components to verify that they are uncorrelated. The eigenvalues should be close to 1, indicating that the components are orthogonal and do not exhibit multicollinearity.</p>
<div id="a9181a8e" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>fa_temp <span class="op">=</span> FactorAnalyzer(n_factors<span class="op">=</span>df_pca_components.shape[<span class="dv">1</span>], method<span class="op">=</span><span class="st">"principal"</span>, rotation<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>    fa_temp.fit(df_pca_components)</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>    ev, _ <span class="op">=</span> fa_temp.get_eigenvalues()</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>    ev <span class="op">=</span> np.sort(ev) <span class="co"># The source prints in ascending order</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Eigenvalues for each component:</span><span class="ch">\n</span><span class="st">"</span>, ev)</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Error during factor analysis fitting: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Consider reducing multicollinearity or removing problematic features."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Eigenvalues for each component:
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]</code></pre>
</div>
</div>
<p>Next, we compute the condition indices for the PCA components to confirm that they are uncorrelated.</p>
<div id="0ff66499" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>coeffs_table <span class="op">=</span> compute_coefficients_table(</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model_pca, X_encoded<span class="op">=</span>X_pca_model_with_const, y<span class="op">=</span>y, vif_table<span class="op">=</span><span class="va">None</span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Coefficients Table:"</span>)</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(coeffs_table)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Coefficients Table:
  Variable  Zero-Order r  Partial r  Semipartial r  Tolerance  VIF
0      PC1     -0.082694  -0.114428      -0.082694        1.0  1.0
1      PC2     -0.616895  -0.651723      -0.616895        1.0  1.0
2      PC3     -0.040608  -0.056473      -0.040608        1.0  1.0
3      PC4      0.110272   0.151818       0.110272        1.0  1.0
4      PC5     -0.174882  -0.236673      -0.174882        1.0  1.0
5      PC6      0.112489   0.154797       0.112489        1.0  1.0
6      PC7      0.109722   0.151078       0.109722        1.0  1.0
7      PC8     -0.129005  -0.176859      -0.129005        1.0  1.0
8      PC9      0.045456   0.063189       0.045456        1.0  1.0
9     PC10      0.096903   0.133763       0.096903        1.0  1.0</code></pre>
</div>
</div>
<p>As expected, results indicate that there is no multicollinearity among the principal components. This confirms that PCA successfully addresses the multicollinearity problem. The R-squared and Adjusted R-squared values remain the same as the original OLS model since PCA preserves the total variance when all components are retained.</p>
</section>
<section id="sec-pca-reduced" class="level3" data-number="25.5.8">
<h3 data-number="25.5.8" class="anchored" data-anchor-id="sec-pca-reduced"><span class="header-section-number">25.5.8</span> PCA: Creating the Regression Model with three Principle Components only</h3>
<div id="1e37c16a" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a regression model using only the first three principal components</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>df_pc_reduced <span class="op">=</span> df_pca_components.iloc[:, :<span class="dv">3</span>] <span class="co"># select the first three factors</span></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>X_model_pc_reduced <span class="op">=</span> sm.add_constant(df_pc_reduced)</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>model_pc_reduced <span class="op">=</span> sm.OLS(y, X_model_pc_reduced).fit()</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Regression on PCs (three PCs only):"</span>)</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model_pc_reduced.summary())</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Verify collinearity statistics for reduced PCs scores</span></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>coeffs_table_pc_reduced <span class="op">=</span> compute_coefficients_table(</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model_pc_reduced, X_encoded<span class="op">=</span>X_model_pc_reduced, y<span class="op">=</span>y, vif_table<span class="op">=</span><span class="va">None</span></span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Coefficients Table (Reduced PCs Analysis Model):"</span>)</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(coeffs_table_pc_reduced)</span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Verify condition indices for reduced FA scores</span></span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a>X_cond_pc_reduced <span class="op">=</span> copy.deepcopy(df_pc_reduced)</span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a>condition_index_df_pc_reduced <span class="op">=</span> condition_index(X_cond_pc_reduced)</span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Condition Index (Reduced PC Analysis Model):"</span>)</span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(condition_index_df_pc_reduced)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Regression on PCs (three PCs only):
                            OLS Regression Results                            
==============================================================================
Dep. Variable:               ln_sales   R-squared:                       0.389
Model:                            OLS   Adj. R-squared:                  0.377
Method:                 Least Squares   F-statistic:                     32.48
Date:                Tue, 05 Aug 2025   Prob (F-statistic):           2.66e-16
Time:                        21:49:11   Log-Likelihood:                -226.97
No. Observations:                 157   AIC:                             461.9
Df Residuals:                     153   BIC:                             474.2
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const          3.2959      0.083     39.693      0.000       3.132       3.460
PC1           -0.0450      0.034     -1.309      0.193      -0.113       0.023
PC2           -0.6572      0.067     -9.762      0.000      -0.790      -0.524
PC3           -0.0624      0.097     -0.643      0.521      -0.254       0.129
==============================================================================
Omnibus:                       43.520   Durbin-Watson:                   1.413
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              125.210
Skew:                          -1.081   Prob(JB):                     6.47e-28
Kurtosis:                       6.804   Cond. No.                         2.82
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

Coefficients Table (Reduced PCs Analysis Model):
  Variable  Zero-Order r  Partial r  Semipartial r  Tolerance  VIF
0      PC1     -0.082694  -0.105209      -0.082694        1.0  1.0
1      PC2     -0.616895  -0.619530      -0.616895        1.0  1.0
2      PC3     -0.040608  -0.051883      -0.040608        1.0  1.0

Condition Index (Reduced PC Analysis Model):
   Index  Eigenvalue  Condition Index
0      0    0.736900         2.819449
1      1    1.531162         1.955951
2      2    5.857833         1.000000</code></pre>
</div>
</div>
</section>
</section>
<section id="sec-fa" class="level2" data-number="25.6">
<h2 data-number="25.6" class="anchored" data-anchor-id="sec-fa"><span class="header-section-number">25.6</span> Addressing Multicollinearity and Latent Structure with Factor Analysis (FA)</h2>
<section id="introduction-to-factor-analysis" class="level3" data-number="25.6.1">
<h3 data-number="25.6.1" class="anchored" data-anchor-id="introduction-to-factor-analysis"><span class="header-section-number">25.6.1</span> Introduction to Factor Analysis</h3>
<p>Factor Analysis (FA) is a statistical method used to describe variability among observed, correlated variables in terms of a potentially lower number of unobserved variables called factors or latent variables. Unlike PCA, which is primarily a data reduction technique focused on maximizing variance explained, FA assumes that the observed variables are linear combinations of these underlying factors plus an error term. FA’s main goal is to uncover the underlying structure that explains the correlations among observed variables.</p>
</section>
<section id="determining-the-number-of-factors-for-factor-analysis" class="level3" data-number="25.6.2">
<h3 data-number="25.6.2" class="anchored" data-anchor-id="determining-the-number-of-factors-for-factor-analysis"><span class="header-section-number">25.6.2</span> Determining the Number of Factors for Factor Analysis</h3>
<p>For Factor Analysis, the number of factors to extract is a crucial decision. A common approach, consistent with the KMO measure, is to consider factors with eigenvalues greater than 1 (Kaiser’s criterion). Factor analysis is then performed, often with a rotation method like Varimax to improve factor interpretability.</p>
<div id="410f09d8" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>anz_fak <span class="op">=</span> <span class="dv">10</span> <span class="co"># Number of factors to extract, similar to the components in PCA</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>n_factors <span class="op">=</span> <span class="bu">min</span>(anz_fak, X_encoded.shape[<span class="dv">1</span>])</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>fa <span class="op">=</span> FactorAnalyzer(n_factors<span class="op">=</span>n_factors, method<span class="op">=</span><span class="st">"principal"</span>, rotation<span class="op">=</span><span class="st">"varimax"</span>)</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>fa.fit(X_encoded) <span class="co"># Fit the Factor Analyzer</span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>actual_factors <span class="op">=</span> fa.loadings_.shape[<span class="dv">1</span>] <span class="co"># Number of factors actually extracted</span></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"actual_factors: </span><span class="sc">{</span>actual_factors<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> actual_factors <span class="op">&lt;</span> n_factors:</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>        <span class="ss">f"</span><span class="ch">\n</span><span class="ss">Warning: Only </span><span class="sc">{</span>actual_factors<span class="sc">}</span><span class="ss"> factors could be extracted "</span></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>        <span class="ss">f"(requested </span><span class="sc">{</span>n_factors<span class="sc">}</span><span class="ss">)."</span></span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>factor_columns <span class="op">=</span> [<span class="ss">f"Factor</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(actual_factors)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>actual_factors: 10</code></pre>
</div>
</div>
</section>
<section id="scree-plot-for-factor-analysis" class="level3" data-number="25.6.3">
<h3 data-number="25.6.3" class="anchored" data-anchor-id="scree-plot-for-factor-analysis"><span class="header-section-number">25.6.3</span> Scree Plot for Factor Analysis</h3>
<p><a href="#fig-scree_plot_fa" class="quarto-xref">Figure&nbsp;<span>25.4</span></a> shows the eigenvalues for each factor extracted from Factor Analysis. The scree plot helps in determining the number of factors to retain by identifying the “elbow” point where the eigenvalues start to level off, indicating diminishing returns in explained variance.</p>
<div id="cell-fig-scree_plot_fa" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>ev_fa, _ <span class="op">=</span> fa.get_eigenvalues()</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(ev_fa) <span class="op">+</span> <span class="dv">1</span>), ev_fa, marker<span class="op">=</span><span class="st">'o'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Scree Plot for Factor Analysis'</span>)</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Number of Factors'</span>)</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Eigenvalue'</span>)</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>plt.xticks(<span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(ev_fa) <span class="op">+</span> <span class="dv">1</span>))</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div id="fig-scree_plot_fa" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-scree_plot_fa-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="100_ddmo_pca_files/figure-html/fig-scree_plot_fa-output-1.png" width="799" height="523" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-scree_plot_fa-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;25.4: Scree plot for Factor Analysis showing the eigenvalues for each factor.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="factor-loadings" class="level3" data-number="25.6.4">
<h3 data-number="25.6.4" class="anchored" data-anchor-id="factor-loadings"><span class="header-section-number">25.6.4</span> Factor Loadings</h3>
<p>Factor Loadings indicate how strongly each original variable is correlated with the extracted factors. High absolute values suggest that the variable has a significant influence on, or is strongly associated with, that factor. Loadings help in interpreting the meaning of each underlying factor.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Summary of Factor Loadings
</div>
</div>
<div class="callout-body-container callout-body">
<p>Factor loadings are used in Factor Analysis (FA). * Definition: Factor loadings represent the correlation or relationship between the observed variables and the latent factors. * Purpose: They indicate how much each observed variable is explained by a given factor. * Mathematical Representation: In FA, factor loadings are derived from the factor model, where observed variables are expressed as linear combinations of latent factors plus error terms. * Interpretation: High absolute values of factor loadings suggest that the variable is strongly associated with the corresponding factor.</p>
</div>
</div>
<p><a href="#sec-loading-scores-vs-factor-loadings" class="quarto-xref"><span>Section 25.7.3</span></a> explains the difference between loading scores in PCA and factor loadings in FA.</p>
<div id="c1eecbf5" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print factor loadings with 2 decimals</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>factor_loadings <span class="op">=</span> fa.loadings_</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Factor Loadings (rounded to 2 decimals):</span><span class="ch">\n</span><span class="st">"</span>, np.<span class="bu">round</span>(factor_loadings, <span class="dv">2</span>))</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a DataFrame for the factor loadings for better visualization</span></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>factor_loadings_df <span class="op">=</span> pd.DataFrame(</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>    factor_loadings, index<span class="op">=</span>X_encoded.columns, <span class="co"># Original feature names</span></span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>    columns<span class="op">=</span>factor_columns <span class="co"># Factor names</span></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the heatmap for factor loadings</span></span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>sns.heatmap(</span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a>    factor_loadings_df, annot<span class="op">=</span><span class="va">True</span>, <span class="co"># Annotate with values</span></span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a>    fmt<span class="op">=</span><span class="st">".2f"</span>, <span class="co"># Format values to 2 decimals</span></span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a>    cmap<span class="op">=</span><span class="st">"coolwarm"</span>, <span class="co"># Color map</span></span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a>    cbar<span class="op">=</span><span class="va">True</span> <span class="co"># Show color bar</span></span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Factor Loadings Heatmap"</span>)</span>
<span id="cb42-20"><a href="#cb42-20" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Factors"</span>)</span>
<span id="cb42-21"><a href="#cb42-21" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Features"</span>)</span>
<span id="cb42-22"><a href="#cb42-22" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb42-23"><a href="#cb42-23" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Factor Loadings (rounded to 2 decimals):
 [[ 0.12  0.97 -0.01  0.06 -0.01  0.08  0.01  0.09  0.01 -0.15]
 [ 0.12  0.6   0.18  0.28  0.61  0.2   0.31  0.09 -0.01  0.02]
 [ 0.06  0.87 -0.01  0.19  0.26  0.16  0.19  0.01 -0.02  0.26]
 [ 0.13  0.07  0.26  0.18  0.04  0.09  0.9   0.03  0.26 -0.01]
 [ 0.14  0.25  0.12  0.77  0.15  0.14  0.51  0.08  0.    0.01]
 [ 0.09  0.12  0.    0.2   0.14  0.11  0.92  0.09 -0.23  0.03]
 [ 0.28  0.43  0.41  0.26  0.15  0.25  0.44  0.48 -0.01 -0.  ]
 [ 0.63  0.32  0.46  0.22  0.11  0.24  0.4   0.12  0.01  0.  ]
 [-0.2  -0.41 -0.46 -0.2  -0.17 -0.66 -0.25 -0.1  -0.   -0.01]
 [ 0.1  -0.06  0.98  0.06  0.05  0.12  0.1   0.05  0.01 -0.  ]]</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="100_ddmo_pca_files/figure-html/cell-29-output-2.png" width="900" height="758" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="factor-scores" class="level3" data-number="25.6.5">
<h3 data-number="25.6.5" class="anchored" data-anchor-id="factor-scores"><span class="header-section-number">25.6.5</span> Factor Scores</h3>
<p>The factor scores are the transformed values of the original variables based on the extracted factors. These scores represent the values of the latent factors for each observation and can be used as new features in regression models, similar to principal components in PCA.</p>
<div id="def-factor_scores" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 25.5 (Factor Scores)</strong></span> A <strong>factor score</strong> represents the value of a latent factor for a given observation, calculated as a linear combination of the observed variables weighted by the factor score coefficients.</p>
<p>Mathematically, the factor score for the <span class="math inline">\(i\)</span>-th factor and the <span class="math inline">\(j\)</span>-th observation is defined as:</p>
<p><span class="math display">\[
F_{ji} = w_{i1} x_{j1} + w_{i2} x_{j2} + \cdots + w_{ip} x_{jp} = \sum_{k=1}^p w_{ik} x_{jk},
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(F_{ji}\)</span> is the factor score for factor <span class="math inline">\(i\)</span> and observation <span class="math inline">\(j\)</span>,<br>
</li>
<li><span class="math inline">\(w_{ik}\)</span> is the factor score coefficient for variable <span class="math inline">\(k\)</span> on factor <span class="math inline">\(i\)</span>,<br>
</li>
<li><span class="math inline">\(x_{jk}\)</span> is the standardized value of variable <span class="math inline">\(k\)</span> for observation <span class="math inline">\(j\)</span>, and</li>
<li><span class="math inline">\(p\)</span> is the number of observed variables.</li>
</ul>
</div>
<div id="9a748fde" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Factor scores for each row (shape: [n_samples, actual_factors])</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>X_factor_scores <span class="op">=</span> fa.transform(X_encoded)</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"X_factor_scores shape: </span><span class="sc">{</span>X_factor_scores<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Adapt the factor column names to the actual factor count</span></span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>df_factors <span class="op">=</span> pd.DataFrame(X_factor_scores, columns<span class="op">=</span>factor_columns)</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"df_factors shape: </span><span class="sc">{</span>df_factors<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"df_factors head:</span><span class="ch">\n</span><span class="sc">{</span>df_factors<span class="sc">.</span>head()<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>X_factor_scores shape: (157, 10)
df_factors shape: (157, 10)
df_factors head:
    Factor1   Factor2   Factor3   Factor4   Factor5   Factor6   Factor7  \
0 -0.647996 -0.310986 -0.395620 -0.514476 -0.753763 -0.171572 -0.691765   
1 -0.171241  0.352069 -0.579629 -0.677204  0.113380 -0.329903  0.434305   
2  0.077192  0.050156 -0.595317 -0.396626  0.412052 -0.688322  0.246025   
3 -0.683708  0.820534 -0.676114 -0.796906 -0.241928  0.602161  1.058645   
4  0.615152 -0.262258 -0.541357 -0.489288 -1.207964 -0.186946 -0.485740   

    Factor8   Factor9  Factor10  
0 -0.233725  0.567292 -0.139248  
1  0.852994 -0.099874  1.690789  
2  0.941176 -0.209195  2.468886  
3  1.063771  1.022527 -1.245557  
4  0.259073  0.073952  0.308099  </code></pre>
</div>
</div>
</section>
<section id="creating-the-regression-model-with-extracted-factors-from-fa" class="level3" data-number="25.6.6">
<h3 data-number="25.6.6" class="anchored" data-anchor-id="creating-the-regression-model-with-extracted-factors-from-fa"><span class="header-section-number">25.6.6</span> Creating the Regression Model with Extracted Factors (from FA)</h3>
<p>A linear regression model is built using all ten extracted factors from Factor Analysis. The expectation is that these factors are uncorrelated, addressing multicollinearity.</p>
<div id="ec05f8c5" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>X_model_fa <span class="op">=</span> sm.add_constant(df_factors)</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>model_factors <span class="op">=</span> sm.OLS(y, X_model_fa).fit()</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Regression on Factor Scores (all 10 factors):"</span>)</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model_factors.summary())</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Verify collinearity statistics for Factor Analysis scores (VIF and Tolerance)</span></span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>coeffs_table_fa <span class="op">=</span> compute_coefficients_table(</span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model_factors, X_encoded<span class="op">=</span>X_model_fa, y<span class="op">=</span>y, vif_table<span class="op">=</span><span class="va">None</span></span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Coefficients Table (Factor Analysis Model):"</span>)</span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(coeffs_table_fa)</span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Verify condition indices</span></span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a>X_cond_fa <span class="op">=</span> copy.deepcopy(df_factors)</span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a>condition_index_df_fa <span class="op">=</span> condition_index(X_cond_fa)</span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Condition Index (Factor Analysis Model):"</span>)</span>
<span id="cb46-17"><a href="#cb46-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(condition_index_df_fa)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Regression on Factor Scores (all 10 factors):
                            OLS Regression Results                            
==============================================================================
Dep. Variable:               ln_sales   R-squared:                       0.485
Model:                            OLS   Adj. R-squared:                  0.449
Method:                 Least Squares   F-statistic:                     13.73
Date:                Tue, 05 Aug 2025   Prob (F-statistic):           7.69e-17
Time:                        21:49:12   Log-Likelihood:                -213.62
No. Observations:                 157   AIC:                             449.2
Df Residuals:                     146   BIC:                             482.9
Df Model:                          10                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const          3.2959      0.078     42.215      0.000       3.142       3.450
Factor1       -0.1366      0.078     -1.749      0.082      -0.291       0.018
Factor2       -0.7022      0.078     -8.994      0.000      -0.856      -0.548
Factor3        0.3035      0.078      3.888      0.000       0.149       0.458
Factor4     9.177e-06      0.078      0.000      1.000      -0.154       0.154
Factor5        0.1719      0.078      2.201      0.029       0.018       0.326
Factor6       -0.1653      0.078     -2.117      0.036      -0.320      -0.011
Factor7        0.4130      0.078      5.290      0.000       0.259       0.567
Factor8       -0.0072      0.078     -0.092      0.927      -0.161       0.147
Factor9        0.0317      0.078      0.407      0.685      -0.123       0.186
Factor10       0.0665      0.078      0.852      0.396      -0.088       0.221
==============================================================================
Omnibus:                       41.296   Durbin-Watson:                   1.423
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              107.145
Skew:                          -1.064   Prob(JB):                     5.42e-24
Kurtosis:                       6.442   Cond. No.                         1.00
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

Coefficients Table (Factor Analysis Model):
   Variable  Zero-Order r  Partial r  Semipartial r  Tolerance  VIF
0   Factor1     -0.103920  -0.143257      -0.103920        1.0  1.0
1   Factor2     -0.534367  -0.597080      -0.534367        1.0  1.0
2   Factor3      0.231004   0.306300       0.231004        1.0  1.0
3   Factor4      0.000007   0.000010       0.000007        1.0  1.0
4   Factor5      0.130790   0.179228       0.130790        1.0  1.0
5   Factor6     -0.125772  -0.172560      -0.125772        1.0  1.0
6   Factor7      0.314284   0.401023       0.314284        1.0  1.0
7   Factor8     -0.005478  -0.007630      -0.005478        1.0  1.0
8   Factor9      0.024158   0.033630       0.024158        1.0  1.0
9  Factor10      0.050594   0.070298       0.050594        1.0  1.0

Condition Index (Factor Analysis Model):
   Index  Eigenvalue  Condition Index
0      0     1.00641              1.0
1      1     1.00641              1.0
2      2     1.00641              1.0
3      3     1.00641              1.0
4      4     1.00641              1.0
5      5     1.00641              1.0
6      6     1.00641              1.0
7      7     1.00641              1.0
8      8     1.00641              1.0
9      9     1.00641              1.0</code></pre>
</div>
</div>
<p>As expected, the collinearity statistics (VIF and Tolerance) for the factor values show that they are uncorrelated (VIF=1, Tolerance=1). The condition indices are also all close to 1, confirming that Factor Analysis successfully mitigates multicollinearity. The coefficient estimates are larger relative to their standard errors compared to the original model, which can lead to more factors being identified as statistically significant.</p>
<p>If the R-squared and Adjusted R-squared values for <code>model_factors</code> are close to those of the original <code>model</code>, it indicates that the regression model based on Factor Analysis performs similarly well, while successfully reducing multicollinearity. When all factors are used, the predictive performance metrics are identical to the original OLS model.</p>
</section>
<section id="factor-analysis-creating-the-regression-model-with-three-extracted-factors-only" class="level3" data-number="25.6.7">
<h3 data-number="25.6.7" class="anchored" data-anchor-id="factor-analysis-creating-the-regression-model-with-three-extracted-factors-only"><span class="header-section-number">25.6.7</span> Factor Analysis: Creating the Regression Model with three Extracted Factors only</h3>
<section id="setting-up-the-regression-model-with-reduced-factors" class="level4" data-number="25.6.7.1">
<h4 data-number="25.6.7.1" class="anchored" data-anchor-id="setting-up-the-regression-model-with-reduced-factors"><span class="header-section-number">25.6.7.1</span> Setting Up the Regression Model with Reduced Factors</h4>
<p>To demonstrate the effect of dimensionality reduction, a regression model is created using only the first three extracted factors from Factor Analysis.</p>
<div id="298091e6" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a regression model using only the first three factors</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>df_factors_reduced <span class="op">=</span> df_factors.iloc[:, :<span class="dv">3</span>] <span class="co"># select the first three factors</span></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>X_model_fa_reduced <span class="op">=</span> sm.add_constant(df_factors_reduced)</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>model_factors_reduced <span class="op">=</span> sm.OLS(y, X_model_fa_reduced).fit()</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Regression on Factor Scores (three factors only):"</span>)</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model_factors_reduced.summary())</span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Verify collinearity statistics for reduced FA scores</span></span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a>coeffs_table_fa_reduced <span class="op">=</span> compute_coefficients_table(</span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model_factors_reduced, X_encoded<span class="op">=</span>X_model_fa_reduced, y<span class="op">=</span>y, vif_table<span class="op">=</span><span class="va">None</span></span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Coefficients Table (Reduced Factor Analysis Model):"</span>)</span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(coeffs_table_fa_reduced)</span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Verify condition indices for reduced FA scores</span></span>
<span id="cb48-16"><a href="#cb48-16" aria-hidden="true" tabindex="-1"></a>X_cond_fa_reduced <span class="op">=</span> copy.deepcopy(df_factors_reduced)</span>
<span id="cb48-17"><a href="#cb48-17" aria-hidden="true" tabindex="-1"></a>condition_index_df_fa_reduced <span class="op">=</span> condition_index(X_cond_fa_reduced)</span>
<span id="cb48-18"><a href="#cb48-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Condition Index (Reduced Factor Analysis Model):"</span>)</span>
<span id="cb48-19"><a href="#cb48-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(condition_index_df_fa_reduced)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Regression on Factor Scores (three factors only):
                            OLS Regression Results                            
==============================================================================
Dep. Variable:               ln_sales   R-squared:                       0.350
Model:                            OLS   Adj. R-squared:                  0.337
Method:                 Least Squares   F-statistic:                     27.43
Date:                Tue, 05 Aug 2025   Prob (F-statistic):           2.99e-14
Time:                        21:49:12   Log-Likelihood:                -231.87
No. Observations:                 157   AIC:                             471.7
Df Residuals:                     153   BIC:                             484.0
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const          3.2959      0.086     38.474      0.000       3.127       3.465
Factor1       -0.1366      0.086     -1.594      0.113      -0.306       0.033
Factor2       -0.7022      0.086     -8.197      0.000      -0.871      -0.533
Factor3        0.3035      0.086      3.543      0.001       0.134       0.473
==============================================================================
Omnibus:                       43.992   Durbin-Watson:                   1.418
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              134.618
Skew:                          -1.068   Prob(JB):                     5.86e-30
Kurtosis:                       7.002   Cond. No.                         1.00
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

Coefficients Table (Reduced Factor Analysis Model):
  Variable  Zero-Order r  Partial r  Semipartial r  Tolerance  VIF
0  Factor1     -0.103920  -0.127811      -0.103920        1.0  1.0
1  Factor2     -0.534367  -0.552381      -0.534367        1.0  1.0
2  Factor3      0.231004   0.275385       0.231004        1.0  1.0

Condition Index (Reduced Factor Analysis Model):
   Index  Eigenvalue  Condition Index
0      0     1.00641              1.0
1      1     1.00641              1.0
2      2     1.00641              1.0</code></pre>
</div>
</div>
<p>The collinearity statistics for the reduced factor set continue to show that they are uncorrelated, with VIFs of 1.0 and condition indices close to 1.</p>
</section>
<section id="comparison-of-model-performance-of-the-reduced-fa-model-and-the-full-ols-model" class="level4" data-number="25.6.7.2">
<h4 data-number="25.6.7.2" class="anchored" data-anchor-id="comparison-of-model-performance-of-the-reduced-fa-model-and-the-full-ols-model"><span class="header-section-number">25.6.7.2</span> Comparison of Model Performance of the Reduced FA Model and the Full OLS Model</h4>
<p>When reducing the number of factors from 10 to 3, the R-squared and Adjusted R-squared values for the Factor Analysis model decrease significantly (from ~0.48 to ~0.35). This indicates a trade-off: while reducing dimensionality successfully addresses multicollinearity, retaining too few factors can lead to information loss and reduced predictive accuracy. Lower MSE and RMSE values still suggest better predictive performance for the full OLS model in this specific comparison, as it retains more information.</p>
</section>
</section>
</section>
<section id="sec-summary-comparison" class="level2" data-number="25.7">
<h2 data-number="25.7" class="anchored" data-anchor-id="sec-summary-comparison"><span class="header-section-number">25.7</span> Summary: Comparing OLS, PCA, and Factor Analysis Models</h2>
<p>Multicollinearity is a common issue in regression models that can lead to unstable and difficult-to-interpret coefficients. Both Principal Component Analysis (PCA) and Factor Analysis (FA) are powerful techniques for addressing multicollinearity and reducing dimensionality.</p>
<ul>
<li><strong>PCA</strong> is a standard method for addressing multicollinearity by transforming correlated variables into uncorrelated principal components. These components can be effectively used in linear regression and other models like Random Forest. While PCA components are not always easy to interpret directly in terms of original variables, they excel at data compression and reducing model complexity.</li>
<li><strong>Factor Analysis</strong> provides a way to simplify data by identifying underlying latent structures (factors) that explain correlations among variables. It also results in uncorrelated factors, making it suitable for regression problems affected by multicollinearity. Interpretation of factors relies on factor loadings.</li>
</ul>
<p>The choice between PCA and Factor Analysis depends on the specific goals: PCA for dimensionality reduction and variance explanation, FA for discovering latent constructs. Both are valuable tools in the data scientist’s toolkit for handling complex, highly correlated datasets.</p>
<section id="interpretation-of-the-regression-models" class="level3" data-number="25.7.1">
<h3 data-number="25.7.1" class="anchored" data-anchor-id="interpretation-of-the-regression-models"><span class="header-section-number">25.7.1</span> Interpretation of the Regression Models</h3>
<ul>
<li><strong>OLS Model (<code>model</code>):</strong> This model uses the original variables directly. Coefficients indicate the direct relationship between each original variable and the target variable.</li>
<li><strong>PCA Regression Model (<code>model_pca</code>):</strong> This model uses principal components, which are linear combinations of the original variables, as predictors. The coefficients show the relationship between the target variable and these abstract components.</li>
<li><strong>Factor Analysis Model (<code>model_factors</code>):</strong> This model uses extracted factors, which are also linear combinations of original variables, designed to capture underlying latent structures. Coefficients indicate the relationship between the target variable and these latent factors.</li>
</ul>
</section>
<section id="differences-compared-to-the-standard-ols-model" class="level3" data-number="25.7.2">
<h3 data-number="25.7.2" class="anchored" data-anchor-id="differences-compared-to-the-standard-ols-model"><span class="header-section-number">25.7.2</span> Differences Compared to the Standard OLS Model</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 7%">
<col style="width: 26%">
<col style="width: 32%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Feature</th>
<th style="text-align: left;">OLS Model (Standard)</th>
<th style="text-align: left;">PCA Regression Model</th>
<th style="text-align: left;">Factor Analysis Model</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Input Variables</strong></td>
<td style="text-align: left;">Uses original variables (e.g., <code>X_encoded</code>) as predictors.</td>
<td style="text-align: left;">Uses principal components (e.g., <code>df_pca_components</code>) as predictors.</td>
<td style="text-align: left;">Uses extracted factors (e.g., <code>df_factors</code>) as predictors.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Multicollinearity</strong></td>
<td style="text-align: left;">Can suffer from multicollinearity if predictors are highly correlated, leading to unstable coefficients and inflated standard errors.</td>
<td style="text-align: left;">Reduces multicollinearity because principal components are orthogonal (uncorrelated).</td>
<td style="text-align: left;">Reduces multicollinearity by using uncorrelated factors as predictors.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Interpretability</strong></td>
<td style="text-align: left;">Coefficients correspond directly to original variables, making interpretation straightforward.</td>
<td style="text-align: left;">Coefficients relate to abstract principal components, making direct interpretation of original variable influence more challenging.</td>
<td style="text-align: left;">Coefficients relate to abstract factors, making interpretation more challenging. Factor loadings must be analyzed for meaning.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Dimensionality</strong></td>
<td style="text-align: left;">Uses all original variables, potentially including redundant or irrelevant features.</td>
<td style="text-align: left;">Reduces the number of predictors by combining original variables into fewer principal components.</td>
<td style="text-align: left;">Reduces the number of predictors by combining original variables into fewer factors.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Purpose</strong></td>
<td style="text-align: left;">Direct relationship modeling, inference.</td>
<td style="text-align: left;">Dimensionality reduction, variance maximization, multicollinearity mitigation.</td>
<td style="text-align: left;">Discovering latent structures, explaining correlations.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Assumptions</strong></td>
<td style="text-align: left;">None on underlying structure beyond linear relationship.</td>
<td style="text-align: left;">Does not assume an underlying causal model.</td>
<td style="text-align: left;">Assumes observed variables are caused by underlying factors.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Error Variance</strong></td>
<td style="text-align: left;">Does not explicitly separate unique variance.</td>
<td style="text-align: left;">Does not separate unique variance from common variance.</td>
<td style="text-align: left;">Explicitly models unique variance for each variable.</td>
</tr>
</tbody>
</table>
</section>
<section id="sec-loading-scores-vs-factor-loadings" class="level3" data-number="25.7.3">
<h3 data-number="25.7.3" class="anchored" data-anchor-id="sec-loading-scores-vs-factor-loadings"><span class="header-section-number">25.7.3</span> Key Differences Between Loading Scores (PCA) and Factor Loadings (FA)</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 17%">
<col style="width: 41%">
<col style="width: 41%">
</colgroup>
<thead>
<tr class="header">
<th>Aspect</th>
<th>Loading Scores (PCA)</th>
<th>Factor Loadings (FA)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Context</strong></td>
<td>Principal Component Analysis (PCA)</td>
<td>Factor Analysis (FA)</td>
</tr>
<tr class="even">
<td><strong>Purpose</strong></td>
<td>Describe the contribution of variables to principal components.</td>
<td>Describe the relationship between variables and latent factors.</td>
</tr>
<tr class="odd">
<td><strong>Underlying Model</strong></td>
<td>No assumption of latent structure; purely variance-based.</td>
<td>Assumes a latent structure explaining observed variables.</td>
</tr>
<tr class="even">
<td><strong>Error Term</strong></td>
<td>PCA does not explicitly model error variance.</td>
<td>FA explicitly models unique (error) variance for each variable.</td>
</tr>
<tr class="odd">
<td><strong>Interpretability</strong></td>
<td>Components are orthogonal (uncorrelated).</td>
<td>Factors may not be orthogonal, depending on rotation.</td>
</tr>
</tbody>
</table>
<p>While both loading scores and factor loadings describe relationships between variables and derived components or factors, <strong>loading scores</strong> are specific to PCA and focus on maximizing variance, while <strong>factor loadings</strong> are specific to FA and aim to uncover latent structures.</p>
</section>
<section id="advantages-of-using-pca-and-fa" class="level3" data-number="25.7.4">
<h3 data-number="25.7.4" class="anchored" data-anchor-id="advantages-of-using-pca-and-fa"><span class="header-section-number">25.7.4</span> Advantages of Using PCA and FA</h3>
<p><strong>Principal Component Analysis (PCA):</strong></p>
<ul>
<li><strong>Reduced Multicollinearity:</strong> By using uncorrelated principal components, the model avoids instability caused by multicollinearity.</li>
<li><strong>Dimensionality Reduction:</strong> The model uses fewer predictors if desired, improving computational efficiency and potentially generalization by removing noise.</li>
<li><strong>Variance Maximization:</strong> Components are constructed to capture the maximum possible variance from the original data.</li>
</ul>
<p><strong>Factor Analysis (FA):</strong></p>
<ul>
<li><strong>Reduced Multicollinearity:</strong> Similar to PCA, using uncorrelated factors prevents instability from multicollinearity.</li>
<li><strong>Dimensionality Reduction:</strong> Reduces the number of predictors, improving computational efficiency and generalization.</li>
<li><strong>Focus on Underlying Structure:</strong> Factor analysis aims to capture the latent structure of the data, potentially providing better insights into the fundamental relationships between variables.</li>
</ul>
</section>
<section id="disadvantages-of-using-pca-and-fa" class="level3" data-number="25.7.5">
<h3 data-number="25.7.5" class="anchored" data-anchor-id="disadvantages-of-using-pca-and-fa"><span class="header-section-number">25.7.5</span> Disadvantages of Using PCA and FA</h3>
<p><strong>Principal Component Analysis (PCA):</strong></p>
<ul>
<li><strong>Loss of Interpretability:</strong> Principal components are abstract combinations of the original variables, making it harder to directly interpret the coefficients. Understanding individual variable influence requires examining loading scores.</li>
<li><strong>Potential Information Loss:</strong> If too few components are retained, information from the original variables may be lost, potentially reducing predictive accuracy.</li>
</ul>
<p><strong>Factor Analysis (FA):</strong></p>
<ul>
<li><strong>Loss of Interpretability:</strong> Factors are abstract combinations of the original variables, making it harder to directly interpret the coefficients. Factor loadings must be analyzed to understand the influence of individual variables.</li>
<li><strong>Potential Information Loss:</strong> If too few factors are retained, information from the original variables may be lost, reducing predictive accuracy.</li>
<li><strong>Complexity:</strong> The process of extracting factors and interpreting their meaning adds complexity to the modeling process.</li>
<li><strong>Dependence on Factor Selection:</strong> The number of factors to retain is subjective and can affect model performance. Too few factors may oversimplify, while too many may reintroduce multicollinearity.</li>
<li><strong>Assumption of Latent Structure:</strong> Relies on the assumption that an underlying latent structure exists, which may not always be true for all datasets.</li>
</ul>
</section>
<section id="when-to-use-which-method" class="level3" data-number="25.7.6">
<h3 data-number="25.7.6" class="anchored" data-anchor-id="when-to-use-which-method"><span class="header-section-number">25.7.6</span> When to Use Which Method</h3>
<ul>
<li>Use PCA when the primary goal is <strong>dimensionality reduction</strong>, <strong>data compression</strong>, and <strong>multicollinearity resolution</strong>, especially when interpretability of the new components is secondary to predictive performance.</li>
<li>Use Factor Analysis when the goal is to <strong>uncover underlying latent constructs or factors</strong> that explain the relationships among variables, and when you seek to understand the conceptual meaning of these latent variables, even if it adds complexity.</li>
<li>The original OLS model is preferable when <strong>interpretability of original variables is crucial</strong> and multicollinearity is not a significant issue.</li>
</ul>
</section>
</section>
<section id="sec-other-models" class="level2" data-number="25.8">
<h2 data-number="25.8" class="anchored" data-anchor-id="sec-other-models"><span class="header-section-number">25.8</span> Using Principal Components / Factors in Other Models</h2>
<p>The principal components from PCA or factors from Factor Analysis can also be effectively used as predictors in other machine learning models, not just linear regression.</p>
<section id="random-forest-regressor-with-the-full-dataset" class="level3" data-number="25.8.1">
<h3 data-number="25.8.1" class="anchored" data-anchor-id="random-forest-regressor-with-the-full-dataset"><span class="header-section-number">25.8.1</span> Random Forest Regressor with the Full Dataset</h3>
<p>First, a Random Forest Regressor is trained using the original, full dataset (<code>X_encoded</code>).</p>
<div id="ac5122d0" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Prepare Data # </span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the original input features (X_encoded) as predictors</span></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>X_original <span class="op">=</span> X_encoded</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data into training and testing sets</span></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>X_train_orig, X_test_orig, y_train_orig, y_test_orig <span class="op">=</span> train_test_split(X_original, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Fit Random Forest Model </span></span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a>rf_model_orig <span class="op">=</span> RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model on the training data</span></span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a>rf_model_orig.fit(X_train_orig, y_train_orig)</span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Evaluate the Model</span></span>
<span id="cb50-14"><a href="#cb50-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on the test set</span></span>
<span id="cb50-15"><a href="#cb50-15" aria-hidden="true" tabindex="-1"></a>y_pred_orig <span class="op">=</span> rf_model_orig.predict(X_test_orig)</span>
<span id="cb50-16"><a href="#cb50-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate evaluation metrics</span></span>
<span id="cb50-17"><a href="#cb50-17" aria-hidden="true" tabindex="-1"></a>r2_rf_orig <span class="op">=</span> r2_score(y_test_orig, y_pred_orig)</span>
<span id="cb50-18"><a href="#cb50-18" aria-hidden="true" tabindex="-1"></a>mse_rf_orig <span class="op">=</span> mean_squared_error(y_test_orig, y_pred_orig)</span>
<span id="cb50-19"><a href="#cb50-19" aria-hidden="true" tabindex="-1"></a>rmse_rf_orig <span class="op">=</span> np.sqrt(mse_rf_orig)</span>
<span id="cb50-20"><a href="#cb50-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-21"><a href="#cb50-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the results</span></span>
<span id="cb50-22"><a href="#cb50-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Random Forest Model (using original data):"</span>)</span>
<span id="cb50-23"><a href="#cb50-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"R-squared: </span><span class="sc">{</span>r2_rf_orig<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb50-24"><a href="#cb50-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"MSE: </span><span class="sc">{</span>mse_rf_orig<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb50-25"><a href="#cb50-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"RMSE: </span><span class="sc">{</span>rmse_rf_orig<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Random Forest Model (using original data):
R-squared: 0.4032
MSE: 1.3118
RMSE: 1.1453</code></pre>
</div>
</div>
</section>
<section id="random-forest-regressor-with-pca-components" class="level3" data-number="25.8.2">
<h3 data-number="25.8.2" class="anchored" data-anchor-id="random-forest-regressor-with-pca-components"><span class="header-section-number">25.8.2</span> Random Forest Regressor with PCA Components</h3>
<p>Next, a Random Forest Regressor is trained using the principal components derived from PCA. This tests if the dimensionality reduction and multicollinearity resolution of PCA benefit non-linear models.</p>
<div id="1f16fd36" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Prepare Data </span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the extracted PCA components as predictors (using the 10 components)</span></span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>X_pca_rf <span class="op">=</span> df_pca_components</span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data into training and testing sets</span></span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>X_train_pca_rf, X_test_pca_rf, y_train_pca_rf, y_test_pca_rf <span class="op">=</span> train_test_split(X_pca_rf, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Fit Random Forest Model</span></span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the Random Forest Regressor</span></span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a>rf_model_pca <span class="op">=</span> RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb52-11"><a href="#cb52-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model on the training data</span></span>
<span id="cb52-12"><a href="#cb52-12" aria-hidden="true" tabindex="-1"></a>rf_model_pca.fit(X_train_pca_rf, y_train_pca_rf)</span>
<span id="cb52-13"><a href="#cb52-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-14"><a href="#cb52-14" aria-hidden="true" tabindex="-1"></a><span class="co">#  3. Evaluate the Model </span></span>
<span id="cb52-15"><a href="#cb52-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on the test set</span></span>
<span id="cb52-16"><a href="#cb52-16" aria-hidden="true" tabindex="-1"></a>y_pred_pca_rf <span class="op">=</span> rf_model_pca.predict(X_test_pca_rf)</span>
<span id="cb52-17"><a href="#cb52-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate evaluation metrics</span></span>
<span id="cb52-18"><a href="#cb52-18" aria-hidden="true" tabindex="-1"></a>r2_rf_pca <span class="op">=</span> r2_score(y_test_pca_rf, y_pred_pca_rf)</span>
<span id="cb52-19"><a href="#cb52-19" aria-hidden="true" tabindex="-1"></a>mse_rf_pca <span class="op">=</span> mean_squared_error(y_test_pca_rf, y_pred_pca_rf)</span>
<span id="cb52-20"><a href="#cb52-20" aria-hidden="true" tabindex="-1"></a>rmse_rf_pca <span class="op">=</span> np.sqrt(mse_rf_pca)</span>
<span id="cb52-21"><a href="#cb52-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-22"><a href="#cb52-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the results</span></span>
<span id="cb52-23"><a href="#cb52-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Random Forest Model (using PCA components):"</span>)</span>
<span id="cb52-24"><a href="#cb52-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"R-squared: </span><span class="sc">{</span>r2_rf_pca<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb52-25"><a href="#cb52-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"MSE: </span><span class="sc">{</span>mse_rf_pca<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb52-26"><a href="#cb52-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"RMSE: </span><span class="sc">{</span>rmse_rf_pca<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Random Forest Model (using PCA components):
R-squared: 0.2871
MSE: 1.5670
RMSE: 1.2518</code></pre>
</div>
</div>
</section>
<section id="random-forest-regressor-with-extracted-factors-from-fa" class="level3" data-number="25.8.3">
<h3 data-number="25.8.3" class="anchored" data-anchor-id="random-forest-regressor-with-extracted-factors-from-fa"><span class="header-section-number">25.8.3</span> Random Forest Regressor with Extracted Factors (from FA)</h3>
<p>Finally, a Random Forest Regressor is trained using the extracted factors from Factor Analysis (using the 3 factors from the reduced model for this example to illustrate potential impact of reduction).</p>
<div id="4cf4c6bc" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Prepare Data </span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the extracted factors as predictors (using the 3 factors from the reduced FA model)</span></span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>X_factors_rf <span class="op">=</span> df_factors_reduced</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data into training and testing sets</span></span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a>X_train_fa_rf, X_test_fa_rf, y_train_fa_rf, y_test_fa_rf <span class="op">=</span> train_test_split(X_factors_rf, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Fit Random Forest Model </span></span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the Random Forest Regressor</span></span>
<span id="cb54-10"><a href="#cb54-10" aria-hidden="true" tabindex="-1"></a>rf_model_fa <span class="op">=</span> RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb54-11"><a href="#cb54-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model on the training data</span></span>
<span id="cb54-12"><a href="#cb54-12" aria-hidden="true" tabindex="-1"></a>rf_model_fa.fit(X_train_fa_rf, y_train_fa_rf)</span>
<span id="cb54-13"><a href="#cb54-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-14"><a href="#cb54-14" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Evaluate the Model </span></span>
<span id="cb54-15"><a href="#cb54-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on the test set</span></span>
<span id="cb54-16"><a href="#cb54-16" aria-hidden="true" tabindex="-1"></a>y_pred_fa_rf <span class="op">=</span> rf_model_fa.predict(X_test_fa_rf)</span>
<span id="cb54-17"><a href="#cb54-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate evaluation metrics</span></span>
<span id="cb54-18"><a href="#cb54-18" aria-hidden="true" tabindex="-1"></a>r2_rf_fa <span class="op">=</span> r2_score(y_test_fa_rf, y_pred_fa_rf)</span>
<span id="cb54-19"><a href="#cb54-19" aria-hidden="true" tabindex="-1"></a>mse_rf_fa <span class="op">=</span> mean_squared_error(y_test_fa_rf, y_pred_fa_rf)</span>
<span id="cb54-20"><a href="#cb54-20" aria-hidden="true" tabindex="-1"></a>rmse_rf_fa <span class="op">=</span> np.sqrt(mse_rf_fa)</span>
<span id="cb54-21"><a href="#cb54-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-22"><a href="#cb54-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the results</span></span>
<span id="cb54-23"><a href="#cb54-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Random Forest Model (using extracted factors):"</span>)</span>
<span id="cb54-24"><a href="#cb54-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"R-squared: </span><span class="sc">{</span>r2_rf_fa<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb54-25"><a href="#cb54-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"MSE: </span><span class="sc">{</span>mse_rf_fa<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb54-26"><a href="#cb54-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"RMSE: </span><span class="sc">{</span>rmse_rf_fa<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Random Forest Model (using extracted factors):
R-squared: 0.2901
MSE: 1.5605
RMSE: 1.2492</code></pre>
</div>
</div>
</section>
<section id="sec-rf-comparison" class="level3" data-number="25.8.4">
<h3 data-number="25.8.4" class="anchored" data-anchor-id="sec-rf-comparison"><span class="header-section-number">25.8.4</span> Comparison of the Random Forest Models</h3>
<div id="220f50f9" class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print comparison of Random Forest models</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Comparison of Random Forest Models:"</span>)</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Using Original Data:"</span>)</span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"R-squared: </span><span class="sc">{</span>r2_rf_orig<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"MSE: </span><span class="sc">{</span>mse_rf_orig<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"RMSE: </span><span class="sc">{</span>rmse_rf_orig<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Using PCA Components:"</span>)</span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"R-squared: </span><span class="sc">{</span>r2_rf_pca<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"MSE: </span><span class="sc">{</span>mse_rf_pca<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"RMSE: </span><span class="sc">{</span>rmse_rf_pca<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb56-12"><a href="#cb56-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-13"><a href="#cb56-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Using Extracted Factors (from FA):"</span>)</span>
<span id="cb56-14"><a href="#cb56-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"R-squared: </span><span class="sc">{</span>r2_rf_fa<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb56-15"><a href="#cb56-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"MSE: </span><span class="sc">{</span>mse_rf_fa<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb56-16"><a href="#cb56-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"RMSE: </span><span class="sc">{</span>rmse_rf_fa<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Comparison of Random Forest Models:

Using Original Data:
R-squared: 0.4032
MSE: 1.3118
RMSE: 1.1453

Using PCA Components:
R-squared: 0.2871
MSE: 1.5670
RMSE: 1.2518

Using Extracted Factors (from FA):
R-squared: 0.2901
MSE: 1.5605
RMSE: 1.2492</code></pre>
</div>
</div>
<p>In this example, for Random Forest, using the reduced set of 3 factors from PCA and FA led to a decrease in R-squared and an increase in MSE/RMSE compared to using the original variables. This highlights that while dimensionality reduction can be beneficial, choosing too few components or factors can lead to information loss, negatively impacting predictive performance.</p>
</section>
</section>
<section id="videos-principal-component-analysis-pca" class="level2" data-number="25.9">
<h2 data-number="25.9" class="anchored" data-anchor-id="videos-principal-component-analysis-pca"><span class="header-section-number">25.9</span> Videos: Principal Component Analysis (PCA)</h2>
<ul>
<li>Video: <a href="https://youtu.be/FgakZw6K1QQ?si=lmXhc-bpOqb7RmDP">Principal Component Analysis (PCA), Step-by-Step</a></li>
<li>Video: <a href="https://youtu.be/oRvgq966yZg?si=TIUsxNItfyYOjTLt">PCA - Practical Tips</a></li>
<li>Video: <a href="https://youtu.be/Lsue2gEM9D0?si=_fV_RzK8j1jwcb-e">PCA in Python</a></li>
</ul>
</section>
<section id="jupyter-notebook" class="level2" data-number="25.10">
<h2 data-number="25.10" class="anchored" data-anchor-id="jupyter-notebook"><span class="header-section-number">25.10</span> Jupyter Notebook</h2>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>The Jupyter-Notebook of this lecture is available on GitHub in the <a href="https://github.com/sequential-parameter-optimization/Hyperparameter-Tuning-Cookbook/blob/main/100_ddmo_pca.ipynb">Hyperparameter-Tuning-Cookbook Repository</a></li>
</ul>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./100_ddmo_eda.html" class="pagination-link" aria-label="Basic Statistics and Data Analysis">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Basic Statistics and Data Analysis</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./100_ddmo_regression.html" class="pagination-link" aria-label="Regression">
        <span class="nav-page-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Regression</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Copyright 2025, T. Bartz-Beielstein</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://sequential-parameter-optimization.github.io/Hyperparameter-Tuning-Cookbook/">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://x.com/bartzbeielstein">
      <i class="bi bi-twitter" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>