<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="de" xml:lang="de"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>59&nbsp; Lernmodul: Eine Einführung in Kriging – Hyperparameter Tuning Cookbook</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./de_cholesky.html" rel="next">
<link href="./de_sampling.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-23a3edf7f3c1ed1fc827cae2f6dd4de5.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Keine Treffer",
    "search-matching-documents-text": "Treffer",
    "search-copy-link-title": "Link in die Suche kopieren",
    "search-hide-matches-text": "Zusätzliche Treffer verbergen",
    "search-more-match-text": "weitere Treffer in diesem Dokument",
    "search-more-matches-text": "weitere Treffer in diesem Dokument",
    "search-clear-button-title": "Zurücksetzen",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Abbrechen",
    "search-submit-button-title": "Abschicken",
    "search-label": "Suchen"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta name="twitter:title" content="59&nbsp; Lernmodul: Eine Einführung in Kriging – Hyperparameter Tuning Cookbook">
<meta name="twitter:description" content="">
<meta name="twitter:card" content="summary">
<meta name="citation_title" content="[59]{.chapter-number}&nbsp; [Lernmodul: Eine Einführung in Kriging]{.chapter-title}">
<meta name="citation_fulltext_html_url" content="https://arxiv.org/abs/2307.10262">
<meta name="citation_doi" content="10.48550/arXiv.2307.10262">
<meta name="citation_language" content="de">
<meta name="citation_journal_title" content="arXiv">
<meta name="citation_reference" content="citation_title=Benchmarking in Optimization: Best Practice and Open Issues;,citation_author=Thomas Bartz-Beielstein;,citation_author=Carola Doerr;,citation_author=Jakob Bossek;,citation_author=Sowmya Chandrasekaran;,citation_author=Tome Eftimov;,citation_author=Andreas Fischbach;,citation_author=Pascal Kerschke;,citation_author=Manuel Lopez-Ibanez;,citation_author=Katherine M. Malan;,citation_author=Jason H. Moore;,citation_author=Boris Naujoks;,citation_author=Patryk Orzechowski;,citation_author=Vanessa Volz;,citation_author=Markus Wagner;,citation_author=Thomas Weise;,citation_publication_date=2020-07;,citation_cover_date=2020-07;,citation_year=2020;,citation_fulltext_html_url=https://arxiv.org/abs/2007.03488;,citation_publisher=arXiv;">
<meta name="citation_reference" content="citation_title=Hyperparameter Tuning With Ray Tune;,citation_author=undefined PyTorch;,citation_publication_date=2023-05;,citation_cover_date=2023-05;,citation_year=2023;,citation_fulltext_html_url=https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html;">
<meta name="citation_reference" content="citation_title=Training a Classifier;,citation_author=undefined PyTorch;,citation_publication_date=2023-05;,citation_cover_date=2023-05;,citation_year=2023;,citation_fulltext_html_url=https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html;">
<meta name="citation_reference" content="citation_title=PyTorch Hyperparameter Tuning with SPOT: Comparison with Ray Tuner and Default Hyperparameters on CIFAR10;,citation_author=Thomas Bartz-Beielstein;,citation_publication_date=2023-04;,citation_cover_date=2023-04;,citation_year=2023;,citation_fulltext_html_url=https://github.com/sequential-parameter-optimization/spotpython/blob/main/notebooks/14_spot_ray_hpt_torch_cifar10.ipynb;">
<meta name="citation_reference" content="citation_title=Machine Learning in Official Statistics;,citation_author=Martin Beck;,citation_author=Florian Dumpert;,citation_author=Joerg Feuerhake;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_doi=10.48550/arXiv.1812.10422;">
<meta name="citation_reference" content="citation_title=Qualitätshandbuch der Statistischen Ämter des Bundes und der Länder;,citation_publication_date=2021-03;,citation_cover_date=2021-03;,citation_year=2021;,citation_fulltext_html_url=https://www.destatis.de/DE/Methoden/Qualitaet/qualitaetshandbuch.pdf;,citation_language=de;">
<meta name="citation_reference" content="citation_title=Quality Assurance Framework of the European Statistical System;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_fulltext_html_url=https://ec.europa.eu/eurostat/documents/64157/4392716/ESS-QAF-V2.0-final.pdf;,citation_language=en;">
<meta name="citation_reference" content="citation_title=Standardisierung der Prozesse: 14 Jahre AG SteP;,citation_author=T. Blumöhr;,citation_author=C. Teichmann;,citation_author=A. Noack;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_fulltext_html_url=https://www.destatis.de/DE/Methoden/
               WISTA-Wirtschaft-und-Statistik/2017/05/standardisierung-prozesse-052017.html;,citation_volume=5;,citation_journal_title=WISTA - Wirtschaft und Statistik;,citation_publisher=Wiesbaden: Statistisches Bundesamt (Destatis);">
<meta name="citation_reference" content="citation_title=Generic Statistical Business Process Model - GSBPM;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_fulltext_html_url=https://statswiki.unece.org/display/
               GSBPM/GSBPM+v5.1;,citation_publisher=United Nations Economic Commission for Europe (UNECE);">
<meta name="citation_reference" content="citation_title=Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide;,citation_editor=Eva Bartz;,citation_editor=Thomas Bartz-Beielstein;,citation_editor=Martin Zaefferer;,citation_editor=Olaf Mersmann;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=Engineering Design via Surrogate Modelling;,citation_author=Alexander Forrester;,citation_author=András Sóbester;,citation_author=Andy Keane;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;">
<meta name="citation_reference" content="citation_title=No Free Lunch Theorems for Optimization;,citation_author=David H Wolpert;,citation_author=William G Macready;,citation_publication_date=1997-04;,citation_cover_date=1997-04;,citation_year=1997;,citation_issue=1;,citation_volume=1;,citation_journal_title=IEEE Transactions on Evolutionary Computation;">
<meta name="citation_reference" content="citation_title=An Introduction to Statistical Learning with Applications in R;,citation_author=Gareth James;,citation_author=Daniela Witten;,citation_author=Trevor Hastie;,citation_author=Robert Tibshirani;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;">
<meta name="citation_reference" content="citation_title=Requirements for papers focusing on new or improved global optimization algorithms;,citation_author=Raphael T. Haftka;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_issue=1;,citation_volume=54;,citation_journal_title=Structural and Multidisciplinary Optimization;">
<meta name="citation_reference" content="citation_title=LightGBM: A Highly Efficient Gradient Boosting Decision Tree;,citation_author=Guolin Ke;,citation_author=Qi Meng;,citation_author=Thomas Finley;,citation_author=Taifeng Wang;,citation_author=Wei Chen;,citation_author=Weidong Ma;,citation_author=Qiwei Ye;,citation_author=Tie-Yan Liu;,citation_editor=I. Guyon;,citation_editor=U. Von Luxburg;,citation_editor=S. Bengio;,citation_editor=H. Wallach;,citation_editor=R. Fergus;,citation_editor=S. Vishwanathan;,citation_editor=R. Garnett;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_volume=30;,citation_conference_title=Advances in Neural Information Processing Systems;,citation_conference=Curran Associates, Inc.;">
<meta name="citation_reference" content="citation_title=Greedy Function Approximation: A Gradient Boosting Machine;,citation_author=Jerome H. Friedman;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_issue=5;,citation_volume=29;,citation_journal_title=The Annals of Statistics;">
<meta name="citation_reference" content="citation_title=Machine Learning in Official Statistics;,citation_author=Martin Beck;,citation_author=Florian Dumpert;,citation_author=Joerg Feuerhake;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_doi=10.48550/arXiv.1812.10422;">
<meta name="citation_reference" content="citation_title=Official statistics in the era of big data opportunities and threats;,citation_author=Walter J. Radermacher;,citation_publication_date=2018-11-01;,citation_cover_date=2018-11-01;,citation_year=2018;,citation_fulltext_html_url=https://doi.org/10.1007/s41060-018-0124-z;,citation_issue=3;,citation_doi=10.1007/s41060-018-0124-z;,citation_volume=6;,citation_language=en;,citation_journal_title=International Journal of Data Science and Analytics;">
<meta name="citation_reference" content="citation_title=Machine Learning in Official Statistics;,citation_author=Martin Beck;,citation_author=Florian Dumpert;,citation_author=Joerg Feuerhake;">
<meta name="citation_reference" content="citation_title=A quality framework for statistical algorithms;,citation_author=Wesley Yung;,citation_author=Siu-Ming Tam;,citation_author=Bart Buelens;,citation_author=Hugh Chipman;,citation_author=Florian Dumpert;,citation_author=Gabriele Ascari;,citation_author=Fabiana Rocci;,citation_author=Joep Burger;,citation_author=InKyung Choi;,citation_publication_date=2022-01-01;,citation_cover_date=2022-01-01;,citation_year=2022;,citation_fulltext_html_url=https://content.iospress.com/articles/statistical-journal-of-the-iaos/sji210875;,citation_issue=1;,citation_doi=10.3233/SJI-210875;,citation_volume=38;,citation_language=en;,citation_journal_title=Statistical Journal of the IAOS;">
<meta name="citation_reference" content="citation_title=A quality framework for statistical algorithms;,citation_author=Wesley Yung;,citation_author=Siu-Ming Tam;,citation_author=Bart Buelens;,citation_author=Hugh Chipman;,citation_author=Florian Dumpert;,citation_author=Gabriele Ascari;,citation_author=Fabiana Rocci;,citation_author=Joep Burger;,citation_author=InKyung Choi;,citation_publication_date=2022-01;,citation_cover_date=2022-01;,citation_year=2022;,citation_issue=1;,citation_volume=38;,citation_journal_title=Statistical Journal of the IAOS;">
<meta name="citation_reference" content="citation_title=Qualitätshandbuch der Statistischen Ämter des Bundes und der Länder;,citation_author=Michael Reichelt;">
<meta name="citation_reference" content="citation_title=Data Science and Official Statistics: Toward a New Data Culture;,citation_author=Stefan Schweinfest;,citation_author=Ronald Jansen;,citation_publication_date=2021-10-28;,citation_cover_date=2021-10-28;,citation_year=2021;,citation_fulltext_html_url=https://hdsr.mitpress.mit.edu/pub/1g514ljw/release/4;,citation_issue=4;,citation_doi=10.1162/99608f92.c1237762;,citation_volume=3;,citation_language=en;,citation_journal_title=Harvard Data Science Review;">
<meta name="citation_reference" content="citation_title=Official Statistics 4.0: Verified Facts for People in the 21st Century;,citation_author=Walter J. Radermacher;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;">
<meta name="citation_reference" content="citation_title=Detecting Covariate Drift with Explanations;,citation_author=Steffen Castle;,citation_author=Robert Schwarzenberg;,citation_author=Mohsen Pourvali;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_conference_title=Natural Language Processing and Chinese Computing: 10th CCF International Conference, NLPCC 2021, Qingdao, China, October 13–17, 2021, Proceedings, Part II;,citation_conference=Springer-Verlag;">
<meta name="citation_reference" content="citation_title=Keras;,citation_author=Francois Chollet;,citation_author=others;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_publisher=https:://keras.io;">
<meta name="citation_reference" content="citation_title=TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems;,citation_author=Martin Abadi;,citation_author=Ashish Agarwal;,citation_author=Paul Barham;,citation_author=Eugene Brevdo;,citation_author=Zhifeng Chen;,citation_author=Craig Citro;,citation_author=Greg S. Corrado;,citation_author=Andy Davis;,citation_author=Jeffrey Dean;,citation_author=Matthieu Devin;,citation_author=Sanjay Ghemawat;,citation_author=Ian Goodfellow;,citation_author=Andrew Harp;,citation_author=Geoffrey Irving;,citation_author=Michael Isard;,citation_author=Yangqing Jia;,citation_author=Rafal Jozefowicz;,citation_author=Lukasz Kaiser;,citation_author=Manjunath Kudlur;,citation_author=Josh Levenberg;,citation_author=Dan Mane;,citation_author=Rajat Monga;,citation_author=Sherry Moore;,citation_author=Derek Murray;,citation_author=Chris Olah;,citation_author=Mike Schuster;,citation_author=Jonathon Shlens;,citation_author=Benoit Steiner;,citation_author=Ilya Sutskever;,citation_author=Kunal Talwar;,citation_author=Paul Tucker;,citation_author=Vincent Vanhoucke;,citation_author=Vijay Vasudevan;,citation_author=Fernanda Viegas;,citation_author=Oriol Vinyals;,citation_author=Pete Warden;,citation_author=Martin Wattenberg;,citation_author=Martin Wicke;,citation_author=Yuan Yu;,citation_author=Xiaoqiang Zheng;,citation_publication_date=2016-03;,citation_cover_date=2016-03;,citation_year=2016;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=statsmodels: Econometric and statistical modeling with python;,citation_author=Skipper Seabold;,citation_author=Josef Perktold;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_conference_title=9th Python in Science Conference;">
<meta name="citation_reference" content="citation_title=Scikit-learn: Machine Learning in Python;,citation_author=F. Pedregosa;,citation_author=G. Varoquaux;,citation_author=A. Gramfort;,citation_author=V. Michel;,citation_author=B. Thirion;,citation_author=O. Grisel;,citation_author=M. Blondel;,citation_author=P. Prettenhofer;,citation_author=R. Weiss;,citation_author=V. Dubourg;,citation_author=J. Vanderplas;,citation_author=A. Passos;,citation_author=D. Cournapeau;,citation_author=M. Brucher;,citation_author=M. Perrot;,citation_author=E. Duchesnay;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_volume=12;,citation_journal_title=Journal of Machine Learning Research;">
<meta name="citation_reference" content="citation_title=Array programming with NumPy;,citation_author=Charles R. Harris;,citation_author=K. Jarrod Millman;,citation_author=Stéfan J. Walt;,citation_author=Ralf Gommers;,citation_author=Pauli Virtanen;,citation_author=David Cournapeau;,citation_author=Eric Wieser;,citation_author=Julian Taylor;,citation_author=Sebastian Berg;,citation_author=Nathaniel J. Smith;,citation_author=Robert Kern;,citation_author=Matti Picus;,citation_author=Stephan Hoyer;,citation_author=Marten H. Kerkwijk;,citation_author=Matthew Brett;,citation_author=Allan Haldane;,citation_author=Jaime Fernández Río;,citation_author=Mark Wiebe;,citation_author=Pearu Peterson;,citation_author=Pierre Gérard-Marchant;,citation_author=Kevin Sheppard;,citation_author=Tyler Reddy;,citation_author=Warren Weckesser;,citation_author=Hameer Abbasi;,citation_author=Christoph Gohlke;,citation_author=Travis E. Oliphant;,citation_publication_date=2020-09;,citation_cover_date=2020-09;,citation_year=2020;,citation_issue=7825;,citation_volume=585;,citation_journal_title=Nature;">
<meta name="citation_reference" content="citation_title=Algorithms for Learning Regression Trees and Ensembles on Evolving Data Streams;,citation_author=Elena Ikonomovska;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_dissertation_institution=Jozef Stefan International Postgraduate School;">
<meta name="citation_reference" content="citation_title=Online Bagging and Boosting;,citation_author=N C Oza;,citation_conference_title=2005 IEEE International Conference on Systems, Man and Cybernetics;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Online bagging and boosting;,citation_author=Nikunj C Oza;,citation_author=Stuart Russell;,citation_editor=T Jaakola;,citation_editor=T Richardson;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_conference_title=8th Insternational Workshop on Artificial Intelligence and Statistics;">
<meta name="citation_reference" content="citation_title=Event labeling combining ensemble detectors and background knowledge;,citation_author=Hadi Fanaee-T;,citation_author=Joao Gama;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=2;,citation_volume=2;,citation_journal_title=Progress in Artificial Intelligence;">
<meta name="citation_reference" content="citation_title=Adaptive random forests for evolving data stream classification;,citation_author=Heitor M. Gomes;,citation_author=Albert Bifet;,citation_author=Jesse Read;,citation_author=Jean Paul Barddal;,citation_author=Fabricio Enembreck;,citation_author=Bernhard Pfharinger;,citation_author=Geoff Holmes;,citation_author=Talel Abdessalem;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=9;,citation_volume=106;,citation_journal_title=Machine Learning;">
<meta name="citation_reference" content="citation_title=Literate Programming;,citation_author=Donald E. Knuth;,citation_publication_date=1984-05;,citation_cover_date=1984-05;,citation_year=1984;,citation_fulltext_html_url=https://doi.org/10.1093/comjnl/27.2.97;,citation_issue=2;,citation_doi=10.1093/comjnl/27.2.97;,citation_issn=0010-4620;,citation_volume=27;,citation_journal_title=Comput. J.;,citation_publisher=Oxford University Press, Inc.;">
<meta name="citation_reference" content="citation_title=A Review and Taxonomy of Interactive Optimization Methods in Operations Research;,citation_author=David Meignan;,citation_author=Sigrid Knust;,citation_author=Jean-Marc Frayet;,citation_author=Gilles Pesant;,citation_author=Nicolas Gaud;,citation_publication_date=2015-09;,citation_cover_date=2015-09;,citation_year=2015;,citation_journal_title=ACM Transactions on Interactive Intelligent Systems;">
<meta name="citation_reference" content="citation_title=Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide;,citation_editor=Eva Bartz;,citation_editor=Thomas Bartz-Beielstein;,citation_editor=Martin Zaefferer;,citation_editor=Olaf Mersmann;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=In a Nutshell – The Sequential Parameter Optimization Toolbox;,citation_author=Thomas Bartz-Beielstein;,citation_author=Martin Zaefferer;,citation_author=Frederik Rehbach;,citation_publication_date=2021-12;,citation_cover_date=2021-12;,citation_year=2021;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Direct search methods: Then and now;,citation_author=R M Lewis;,citation_author=V Torczon;,citation_author=M W Trosset;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_issue=1–2;,citation_volume=124;,citation_journal_title=Journal of Computational and Applied Mathematics;">
<meta name="citation_reference" content="citation_title=Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization;,citation_author=Lisha Li;,citation_author=Kevin Jamieson;,citation_author=Giulia DeSalvo;,citation_author=Afshin Rostamizadeh;,citation_author=Ameet Talwalkar;,citation_publication_date=2016-03;,citation_cover_date=2016-03;,citation_year=2016;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Sequential Parameter Optimization;,citation_author=Thomas Bartz-Beielstein;,citation_author=Christian Lasarczyk;,citation_author=Mike Preuss;,citation_editor=B McKay;,citation_editor=others;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_conference_title=Proceedings 2005 Congress on Evolutionary Computation (CEC’05), Edinburgh, Scotland;,citation_conference=IEEE Press;">
<meta name="citation_reference" content="citation_title=Evolutionary Algorithms;,citation_author=Thomas Bartz-Beielstein;,citation_author=Jürgen Branke;,citation_author=Jörn Mehnen;,citation_author=Olaf Mersmann;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=3;,citation_volume=4;,citation_journal_title=Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery;">
<meta name="citation_reference" content="citation_title=Classification and Regression Trees;,citation_author=L Breiman;,citation_author=J H Friedman;,citation_author=R A Olshen;,citation_author=C J Stone;,citation_publication_date=1984;,citation_cover_date=1984;,citation_year=1984;">
<meta name="citation_reference" content="citation_title=Continuous inspection schemes;,citation_author=E. S. Page;,citation_publication_date=1954-06;,citation_cover_date=1954-06;,citation_year=1954;,citation_issue=1-2;,citation_volume=41;,citation_journal_title=Biometrika;">
<meta name="citation_reference" content="citation_title=Counting Large Numbers of Events in Small Registers;,citation_author=Robert Morris;,citation_publication_date=1978-10;,citation_cover_date=1978-10;,citation_year=1978;,citation_issue=10;,citation_volume=21;,citation_journal_title=Commun. ACM;">
<meta name="citation_reference" content="citation_title=Approximate Counting: A Detailed Analysis;,citation_author=Philippe Flajolet;,citation_publication_date=1985-03;,citation_cover_date=1985-03;,citation_year=1985;,citation_issue=1;,citation_volume=25;,citation_journal_title=BIT;">
<meta name="citation_reference" content="citation_title=Random Sampling with a Reservoir;,citation_author=Jeffrey S. Vitter;,citation_publication_date=1985-03;,citation_cover_date=1985-03;,citation_year=1985;,citation_issue=1;,citation_volume=11;,citation_journal_title=ACM Trans. Math. Softw.;">
<meta name="citation_reference" content="citation_title=Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem;,citation_author=Michael McCloskey;,citation_author=Neal J. Cohen;,citation_publication_date=1989-01;,citation_cover_date=1989-01;,citation_year=1989;,citation_issue=C;,citation_volume=24;,citation_journal_title=Psychology of Learning and Motivation - Advances in Research and Theory;">
<meta name="citation_reference" content="citation_title=Detection of Abrupt Changes - Theory and Application;,citation_author=Michèle Basseville;,citation_author=Igor V. Nikiforov;,citation_publication_date=1993;,citation_cover_date=1993;,citation_year=1993;">
<meta name="citation_reference" content="citation_title=An Introduction to Computational Learning Theory;,citation_author=Michael J. Kearns;,citation_author=Umesh V. Vazirani;,citation_publication_date=1994;,citation_cover_date=1994;,citation_year=1994;">
<meta name="citation_reference" content="citation_title=An Introduction to the Kalman Filter;,citation_author=Greg Welch;,citation_author=Gary Bishop;,citation_publication_date=1995;,citation_cover_date=1995;,citation_year=1995;">
<meta name="citation_reference" content="citation_title=The Space Complexity of Approximating the Frequency Moments;,citation_author=Noga Alon;,citation_author=Yossi Matias;,citation_author=Mario Szegedy;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_conference_title=Proceedings of the Twenty-Eighth Annual ACM Symposium on Theory of Computing;,citation_conference=Association for Computing Machinery;,citation_series_title=STOC ’96;">
<meta name="citation_reference" content="citation_title=SPLICE-2 Comparative Evaluation: Electricity Pricing;,citation_author=Michael Harries;,citation_author=U Nsw-cse-tr;,citation_author=New South Wales;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;">
<meta name="citation_reference" content="citation_title=Mining high-speed data streams;,citation_author=Pedro M. Domingos;,citation_author=Geoff Hulten;,citation_editor=Raghu Ramakrishnan;,citation_editor=Salvatore J. Stolfo;,citation_editor=Roberto J. Bayardo;,citation_editor=Ismail Parsa;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_conference_title=Proceedings of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining, Boston, MA, USA, August 20-23, 2000;,citation_conference=ACM;">
<meta name="citation_reference" content="citation_title=Mining Time-Changing Data Streams;,citation_author=Geoff Hulten;,citation_author=Laurie Spencer;,citation_author=Pedro Domingos;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_conference_title=Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;,citation_conference=Association for Computing Machinery;,citation_series_title=KDD ’01;">
<meta name="citation_reference" content="citation_title=A Streaming Ensemble Algorithm (SEA) for Large-Scale Classification;,citation_author=W. Nick Street;,citation_author=YongSeog Kim;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_conference_title=Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;,citation_conference=Association for Computing Machinery;,citation_series_title=KDD ’01;">
<meta name="citation_reference" content="citation_title=3D Data Management: Controlling Data Volume, Velocity, and Variety;,citation_author=Douglas Laney;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_technical_report_institution=META Group;">
<meta name="citation_reference" content="citation_title=Models and Issues in Data Stream Systems;,citation_author=Brian Babcock;,citation_author=Shivnath Babu;,citation_author=Mayur Datar;,citation_author=Rajeev Motwani;,citation_author=Jennifer Widom;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_conference_title=Proceedings of the 21st ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems;,citation_conference=ACM;,citation_series_title=PODS ’02;">
<meta name="citation_reference" content="citation_title=A New Approximate Maximal Margin Classification Algorithm;,citation_author=Claudio Gentile;,citation_publication_date=2002-03;,citation_cover_date=2002-03;,citation_year=2002;,citation_volume=2;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=The Design and Analysis of Computer Experiments;,citation_author=T J Santner;,citation_author=B J Williams;,citation_author=W I Notz;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;">
<meta name="citation_reference" content="citation_title=Learning with drift detection;,citation_author=João Gama;,citation_author=Pedro Medas;,citation_author=Gladys Castillo;,citation_author=Pedro Rodrigues;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_conference_title=In SBIA Brazilian Symposium on Artificial Intelligence;,citation_conference=Springer Verlag;">
<meta name="citation_reference" content="citation_title=Learning with Drift Detection;,citation_author=João Gama;,citation_author=Pedro Medas;,citation_author=Gladys Castillo;,citation_author=Pedro Rodrigues;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_inbook_title=Parallel Problem Solving from Nature - PPSN XIII - 13th International Conference, Ljubljana, Slovenia, September 13-17, 2014. Proceedings;">
<meta name="citation_reference" content="citation_title=Learning with Drift Detection;,citation_author=João Gama;,citation_author=Pedro Medas;,citation_author=Gladys Castillo;,citation_author=Pedro Rodrigues;,citation_editor=Ana L. C. Bazzan;,citation_editor=Sofiane Labidi;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_conference_title=Advances in Artificial Intelligence – SBIA 2004;,citation_conference=Springer Berlin Heidelberg;">
<meta name="citation_reference" content="citation_title=Statistical Analysis of Massive Data Streams: Proceedings of a Workshop;,citation_editor=Sallie Keller-McNulty;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;">
<meta name="citation_reference" content="citation_title=Data Mining: Practical Machine Learning Tools and Techniques;,citation_author=Ian H. Witten;,citation_author=Eibe Frank;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_series_title=The Morgan Kaufmann Series in Data Management Systems;">
<meta name="citation_reference" content="citation_title=Towards Generic Pattern Mining;,citation_author=Mohammed Javeed Zaki;,citation_author=Nagender Parimi;,citation_author=Nilanjana De;,citation_author=Feng Gao;,citation_author=Benjarath Phoophakdee;,citation_author=Joe Urban;,citation_author=Vineet Chaoji;,citation_author=Mohammad Al Hasan;,citation_author=Saeed Salem;,citation_editor=Bernhard Ganter;,citation_editor=Robert Godin;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_volume=3403;,citation_conference_title=Formal Concept Analysis, Third International Conference, ICFCA 2005, Lens, France, February 14-18, 2005, Proceedings;,citation_conference=Springer;,citation_series_title=Lecture Notes in Computer Science;">
<meta name="citation_reference" content="citation_title=Mining Data Streams: A Review;,citation_author=Mohamed Medhat Gaber;,citation_author=Arkady Zaslavsky;,citation_author=Shonali Krishnaswamy;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_volume=34;,citation_journal_title=SIGMOD Rec.;">
<meta name="citation_reference" content="citation_title=Early drift detection method;,citation_author=Manuel Baena-Garcıa;,citation_author=José Campo-Ávila;,citation_author=Raúl Fidalgo;,citation_author=Albert Bifet;,citation_author=R Gavalda;,citation_author=Rafael Morales-Bueno;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_volume=6;,citation_conference_title=Fourth international workshop on knowledge discovery from data streams;">
<meta name="citation_reference" content="citation_title=Online Passive-Aggressive Algorithms;,citation_author=Koby Crammer;,citation_author=Ofer Dekel;,citation_author=Joseph Keshet;,citation_author=Shai Shalev-Shwartz;,citation_author=Yoram Singer;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=19;,citation_volume=7;,citation_journal_title=Journal of Machine Learning Research;">
<meta name="citation_reference" content="citation_title=Data Streams – Models and Algorithms;,citation_editor=Charu Aggarwal;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;">
<meta name="citation_reference" content="citation_title=Learning from Time-Changing Data with Adaptive Windowing;,citation_author=Albert Bifet;,citation_author=Ricard Gavaldà;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_conference_title=Proceedings of the 2007 SIAM International Conference on Data Mining (SDM);">
<meta name="citation_reference" content="citation_title=Learning from time-changing data with adaptive windowing;,citation_author=Albert Bifet;,citation_author=Ricard Gavalda;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_volume=7;,citation_conference_title=Proceedings of the 2007 SIAM international conference on data mining;,citation_conference=SIAM;">
<meta name="citation_reference" content="citation_title=A Survey of Classification Methods in Data Streams;,citation_author=Mohamed Gaber;,citation_author=Arkady Zaslavsky;,citation_author=Shonali Krishnaswamy;,citation_editor=Charu Aggarwal;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_inbook_title=Data Streams – Models and Algorithms;">
<meta name="citation_reference" content="citation_title=Use of Hoeffding trees in concept based data stream mining;,citation_author=Stefan Hoeglinger;,citation_author=Russel Pears;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_journal_title=2007 Third International Conference on Information and Automation for Sustainability;">
<meta name="citation_reference" content="citation_title=Detecting concept drift using statistical testing;,citation_author=Kyosuke Nishida;,citation_author=Koichiro Yamauchi;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_conference_title=International conference on discovery science;,citation_conference=Springer;">
<meta name="citation_reference" content="citation_title=Olindda: A cluster-based approach for detecting novelty and concept drift in data streams;,citation_author=Eduardo J Spinosa;,citation_author=André Ponce Leon F. de Carvalho;,citation_author=Joao Gama;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_conference_title=Proceedings of the 2007 ACM symposium on Applied computing;">
<meta name="citation_reference" content="citation_title=Statistical Quality Control;,citation_author=Douglas C Montgomery;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;">
<meta name="citation_reference" content="citation_title=Adaptive Learning from Evolving Data Streams;,citation_author=Albert Bifet;,citation_author=Ricard Gavaldà;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=Proceedings of the 8th International Symposium on Intelligent Data Analysis: Advances in Intelligent Data Analysis VIII;,citation_conference=Springer-Verlag;,citation_series_title=IDA ’09;">
<meta name="citation_reference" content="citation_title=New Ensemble Methods for Evolving Data Streams;,citation_author=Albert Bifet;,citation_author=Geoff Holmes;,citation_author=Bernhard Pfahringer;,citation_author=Richard Kirkby;,citation_author=Ricard Gavaldà;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;,citation_conference=Association for Computing Machinery;,citation_series_title=KDD ’09;">
<meta name="citation_reference" content="citation_title=Adaptive concept drift detection;,citation_author=Anton Dries;,citation_author=Ulrich Rückert;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=5-6;,citation_volume=2;,citation_journal_title=Stat. Anal. Data Min.;">
<meta name="citation_reference" content="citation_title=Issues in Evaluation of Stream Learning Algorithms;,citation_author=João Gama;,citation_author=Raquel Sebastião;,citation_author=Pedro Pereira Rodrigues;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;,citation_conference=Association for Computing Machinery;,citation_series_title=KDD ’09;">
<meta name="citation_reference" content="citation_title=Stream Data Processing: A Quality of Service Perspective;,citation_author=Qingchun Jiang;,citation_author=Sharma Chakravarthy;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;">
<meta name="citation_reference" content="citation_title=Probabilistic Counting with Randomized Storage;,citation_author=Benjamin Van Durme;,citation_author=Ashwin Lall;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=Proceedings of the 21st International Joint Conference on Artificial Intelligence;,citation_conference=Morgan Kaufmann Publishers Inc.;,citation_series_title=IJCAI’09;">
<meta name="citation_reference" content="citation_title=Adaptive Stream Mining: Pattern Learning and Mining from Evolving Data Streams;,citation_author=Albert Bifet;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_volume=207;,citation_series_title=Frontiers in Artificial Intelligence and Applications;">
<meta name="citation_reference" content="citation_title=We’re not in kansas anymore: detecting domain changes in streams;,citation_author=Mark Dredze;,citation_author=Tim Oates;,citation_author=Christine Piatko;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_conference_title=Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing;">
<meta name="citation_reference" content="citation_title=Large-Scale Inference: Empirical Bayes Methods for Estimation, Testing, and Prediction (Institute of Mathematical Statistics Monographs);,citation_author=Bradley Efron;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;">
<meta name="citation_reference" content="citation_title=Knowledge Discovery from Data Streams;,citation_author=João Gama;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_series_title=Chapman and Hall / CRC Data Mining and Knowledge Discovery Series;">
<meta name="citation_reference" content="citation_title=A DCT based approach for detecting novelty and concept drift in data streams;,citation_author=Morteza Zi Hayat;,citation_author=Mahmoud Reza Hashemi;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_conference_title=2010 International Conference of Soft Computing and Pattern Recognition;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Benchmarking Stream Clustering Algorithms within the MOA Framework;,citation_author=Philipp Kranen;,citation_author=Hardy Kremer;,citation_author=Timm Jansen;,citation_author=Thomas Seidl;,citation_author=Albert Bifet;,citation_author=Geoff Holmes;,citation_author=Bernhard Pfahringer;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_conference_title=16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD 2010), Washington, DC, USA;">
<meta name="citation_reference" content="citation_title=MOA: Massive Online Analysis;,citation_author=Albert Bifet;,citation_author=Geoff Holmes;,citation_author=Richard Kirkby;,citation_author=Bernhard Pfahringer;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_volume=99;,citation_journal_title=Journal of Machine Learning Research;">
<meta name="citation_reference" content="citation_title=Hellinger distance based drift detection for nonstationary environments;,citation_author=Gregory Ditzler;,citation_author=Robi Polikar;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_conference_title=2011 IEEE symposium on computational intelligence in dynamic and uncertain environments (CIDUE);,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Classification and novel class detection in concept-drifting data streams under time constraints;,citation_author=Mohammad Masud;,citation_author=Jing Gao;,citation_author=Latifur Khan;,citation_author=Jiawei Han;,citation_author=Bhavani M Thuraisingham;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=6;,citation_volume=23;,citation_journal_title=IEEE Transactions on Knowledge and Data Engineering;">
<meta name="citation_reference" content="citation_title=New drift detection method for data streams;,citation_author=Parinaz Sobhani;,citation_author=Hamid Beigy;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_conference_title=International conference on adaptive and intelligent systems;,citation_conference=Springer;">
<meta name="citation_reference" content="citation_title=birch: Dealing With Very Large Datasets Using BIRCH;,citation_author=Lysiane Charest;,citation_author=Justin Harrington;,citation_author=Matias Salibian-Barrera;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;">
<meta name="citation_reference" content="citation_title=Synopses for Massive Data: Samples, Histograms, Wavelets, Sketches;,citation_author=Graham Cormode;,citation_author=Minos Garofalakis;,citation_author=Peter J. Haas;,citation_author=Chris Jermaine;,citation_publication_date=2012-01;,citation_cover_date=2012-01;,citation_year=2012;,citation_issue=1–3;,citation_volume=4;,citation_journal_title=Found. Trends Databases;">
<meta name="citation_reference" content="citation_title=Detection of concept drift for learning from stream data;,citation_author=Jeonghoon Lee;,citation_author=Frederic Magoules;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_conference_title=2012 IEEE 14th International Conference on High Performance Computing and Communication &amp;amp;amp; 2012 IEEE 9th International Conference on Embedded Software and Systems;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=mlbench: Machine Learning Benchmark Problems;,citation_author=Friedrich Leisch;,citation_author=Evgenia Dimitriadou;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;">
<meta name="citation_reference" content="citation_title=A unifying view on dataset shift in classification;,citation_author=Jose G. Moreno-Torres;,citation_author=Troy Raeder;,citation_author=Rocı́o Alaı́z-Rodrı́guez;,citation_author=Nitesh V. Chawla;,citation_author=Francisco Herrera;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=1;,citation_volume=45;,citation_journal_title=Pattern Recognit.;">
<meta name="citation_reference" content="citation_title=HadoopStreaming: Utilities for Using R Scripts in Hadoop Streaming;,citation_author=David S. Rosenberg;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;">
<meta name="citation_reference" content="citation_title=Exponentially weighted moving average charts for detecting concept drift;,citation_author=Gordon J Ross;,citation_author=Niall M Adams;,citation_author=Dimitris K Tasoulis;,citation_author=David J Hand;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=2;,citation_volume=33;,citation_journal_title=Pattern recognition letters;">
<meta name="citation_reference" content="citation_title=An efficient method of building an ensemble of classifiers in streaming data;,citation_author=Joung Woo Ryu;,citation_author=Mehmed M Kantardzic;,citation_author=Myung-Won Kim;,citation_author=A Ra Khil;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_conference_title=International Conference on Big Data Analytics;,citation_conference=Springer;">
<meta name="citation_reference" content="citation_title=rlecuyer: R Interface to RNG With Multiple Streams;,citation_author=Hana Sevcikova;,citation_author=Tony Rossini;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;">
<meta name="citation_reference" content="citation_title=Machine Learning that Matters;,citation_author=Kiri Wagstaff;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;">
<meta name="citation_reference" content="citation_title=CD-MOA: Change Detection Framework for Massive Online Analysis;,citation_author=Albert Bifet;,citation_author=Jesse Read;,citation_author=Bernhard Pfahringer;,citation_author=Geoff Holmes;,citation_author=Indrė Žliobaitė;,citation_editor=Allan Tucker;,citation_editor=Frank Höppner;,citation_editor=Arno Siebes;,citation_editor=Stephen Swift;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_conference_title=Advances in Intelligent Data Analysis XII;,citation_conference=Springer Berlin Heidelberg;">
<meta name="citation_reference" content="citation_title=Novelty detection algorithm for data streams multi-class problems;,citation_author=Elaine R Faria;,citation_author=João Gama;,citation_author=André CPLF Carvalho;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_conference_title=Proceedings of the 28th annual ACM symposium on applied computing;">
<meta name="citation_reference" content="citation_title=Turning Big Data into Tiny Data: Constant-Size Coresets for k-Means, PCA and Projective Clustering;,citation_author=Dan Feldman;,citation_author=Melanie Schmidt;,citation_author=Christian Sohler;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_conference_title=Proceedings of the Twenty-Fourth Annual ACM-SIAM Symposium on Discrete Algorithms;,citation_conference=Society for Industrial; Applied Mathematics;,citation_series_title=SODA ’13;">
<meta name="citation_reference" content="citation_title=On evaluating stream learning algorithms;,citation_author=João Gama;,citation_author=Raquel Sebastião;,citation_author=Pedro Pereira Rodrigues;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=3;,citation_volume=90;,citation_journal_title=Machine Learning;">
<meta name="citation_reference" content="citation_title=Scalable Strategies for Computing with Massive Data;,citation_author=Michael J. Kane;,citation_author=John Emerson;,citation_author=Stephen Weston;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=14;,citation_volume=55;,citation_journal_title=Journal of Statistical Software;">
<meta name="citation_reference" content="citation_title=RStorm: Simulate and Develop Streaming Processing in R;,citation_author=Maurits Kaptein;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;">
<meta name="citation_reference" content="citation_title=Drift detection using uncertainty distribution divergence;,citation_author=Patrick Lindstrom;,citation_author=Brian Mac Namee;,citation_author=Sarah Jane Delany;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=1;,citation_volume=4;,citation_journal_title=Evolving Systems;">
<meta name="citation_reference" content="citation_title=Ad Click Prediction: A View from the Trenches;,citation_author=H. Brendan McMahan;,citation_author=Gary Holt;,citation_author=D. Sculley;,citation_author=Michael Young;,citation_author=Dietmar Ebner;,citation_author=Julian Grady;,citation_author=Lan Nie;,citation_author=Todd Phillips;,citation_author=Eugene Davydov;,citation_author=Daniel Golovin;,citation_author=Sharat Chikkerur;,citation_author=Dan Liu;,citation_author=Martin Wattenberg;,citation_author=Arnar Mar Hrafnkelsson;,citation_author=Tom Boulos;,citation_author=Jeremy Kubica;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_conference_title=Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;,citation_conference=Association for Computing Machinery;,citation_series_title=KDD ’13;">
<meta name="citation_reference" content="citation_title=Data Stream Clustering: A Survey.;,citation_author=Jonathan A. Silva;,citation_author=Elaine R. Faria;,citation_author=Rodrigo C. Barros;,citation_author=Eduardo R. Hruschka;,citation_author=Andre Carvalho;,citation_author=Joao Gama;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=1;,citation_volume=46;,citation_journal_title=ACM Computer Surveys;">
<meta name="citation_reference" content="citation_title=ff: Memory-efficient Storage of Large Data on Disk and Fast Access Functions;,citation_author=Daniel Adler;,citation_author=Christian Gläser;,citation_author=Oleg Nenadic;,citation_author=Jens Oehlschlägel;,citation_author=Walter Zucchini;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=factas: Data Mining Methods for Data Streams;,citation_author=Romain Bar;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=streamR: Access to Twitter Streaming API via R;,citation_author=Pablo Barbera;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=DBI: R Database Interface;,citation_author=R Special Interest Group on Databases;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=Concept drift detection through resampling;,citation_author=Maayan Harel;,citation_author=Shie Mannor;,citation_author=Ran El-Yaniv;,citation_author=Koby Crammer;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_conference_title=International conference on machine learning;,citation_conference=PMLR;">
<meta name="citation_reference" content="citation_title=PCA feature extraction for change detection in multidimensional unlabeled data;,citation_author=Ludmila I Kuncheva;,citation_author=William J Faithfull;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=1;,citation_volume=25;,citation_journal_title=IEEE transactions on neural networks and learning systems;">
<meta name="citation_reference" content="citation_title=Mining of Massive Datasets;,citation_author=Jure Leskovec;,citation_author=Anand Rajaraman;,citation_author=Jeffery D. Ullman;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=RMOA: Connect R with MOA to perform streaming classifications;,citation_author=Jan Wijffels;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=A Survey on Concept Drift Adaptation;,citation_author=João Gama;,citation_author=Indrundefined Žliobaitundefined;,citation_author=Albert Bifet;,citation_author=Mykola Pechenizkiy;,citation_author=Abdelhamid Bouchachia;,citation_publication_date=2014-03;,citation_cover_date=2014-03;,citation_year=2014;,citation_issue=4;,citation_volume=46;,citation_journal_title=ACM Comput. Surv.;">
<meta name="citation_reference" content="citation_title=Graph Stream Algorithms: A Survey;,citation_author=Andrew McGregor;,citation_publication_date=2014-05;,citation_cover_date=2014-05;,citation_year=2014;,citation_issue=1;,citation_volume=43;,citation_journal_title=SIGMOD Rec.;">
<meta name="citation_reference" content="citation_title=RStorm: Developing and Testing Streaming Algorithms in R;,citation_author=Maurits Kaptein;,citation_publication_date=2014-06;,citation_cover_date=2014-06;,citation_year=2014;,citation_issue=1;,citation_volume=6;,citation_journal_title=The R Journal;">
<meta name="citation_reference" content="citation_title=SNAP Datasets: Stanford Large Network Dataset Collection;,citation_author=Jure Leskovec;,citation_author=Andrej Krevl;,citation_publication_date=2014-06;,citation_cover_date=2014-06;,citation_year=2014;,citation_publisher=http://snap.stanford.edu/data;">
<meta name="citation_reference" content="citation_title=Questioning the Lambda Architecture;,citation_author=Jay Kreps;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=Sketching as a Tool for Numerical Linear Algebra;,citation_author=David P. Woodruff;,citation_publication_date=2014-10;,citation_cover_date=2014-10;,citation_year=2014;,citation_issue=1–2;,citation_volume=10;,citation_journal_title=Found. Trends Theor. Comput. Sci.;">
<meta name="citation_reference" content="citation_title=Modeling concept drift: A probabilistic graphical model based approach;,citation_author=Hanen Borchani;,citation_author=Ana Maria Martinez;,citation_author=Andrés R. Masegosa;,citation_author=Helge Langseth;,citation_author=Thomas Dyhre Nielsen;,citation_author=Antonio Salmerón;,citation_author=Antonio Fernández;,citation_author=Anders Læsø Madsen;,citation_author=Ramón Sáez;,citation_editor=Elisa Fromont;,citation_editor=Tijl De Bie;,citation_editor=Matthijs Leeuwen;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=Advances in Intelligent Data Analysis XIV;,citation_conference=Springer;,citation_series_title=Lecture Notes in Computer Science;">
<meta name="citation_reference" content="citation_title=twitteR: R Based Twitter Client;,citation_author=Jeff Gentry;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=rEMM: Extensible Markov Model for Data Stream Clustering in R;,citation_author=Michael Hahsler;,citation_author=Margaret H. Dunham;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=streamMOA: Interface for MOA Stream Clustering Algorithms;,citation_author=Michael Hahsler;,citation_author=Matthew Bolanos;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=rstream: Streams of Random Numbers;,citation_author=Josef Leydold;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=Big Data: Principles and Best Practices of Scalable Realtime Data Systems;,citation_author=Nathan Marz;,citation_author=James Warren;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=A pca-based change detection framework for multidimensional data streams: Change detection in multidimensional data streams;,citation_author=Abdulhakim A Qahtan;,citation_author=Basma Alharbi;,citation_author=Suojin Wang;,citation_author=Xiangliang Zhang;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;">
<meta name="citation_reference" content="citation_title=Concept Drift Detection for Streaming Data;,citation_author=Heng Wang;,citation_author=Zubin Abraham;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=International Joint Conference on Neural Networks (IJCNN);">
<meta name="citation_reference" content="citation_title=koaning.io: Linear Models Solving Non-Linear Problems;,citation_author=Vincent Warmerdam;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=Experimental Algorithmics Applied to On-line Machine Learning;,citation_author=Thomas Bartz-Beielstein;,citation_editor=Gregor Papa;,citation_editor=Marjan Mernik;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_conference_title=Bioinspired Optimization Methods and their Applications;">
<meta name="citation_reference" content="citation_title=quantmod: Quantitative Financial Modelling Framework;,citation_author=Jeffrey A. Ryan;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;">
<meta name="citation_reference" content="citation_title=A grid density based framework for classifying streaming data in the presence of concept drift;,citation_author=Tegjyot Singh Sethi;,citation_author=Mehmed Kantardzic;,citation_author=Hanquing Hu;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_issue=1;,citation_volume=46;,citation_journal_title=Journal of Intelligent Information Systems;">
<meta name="citation_reference" content="citation_title=rJava: Low-level R to Java interface;,citation_author=Simon Urbanek;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;">
<meta name="citation_reference" content="citation_title=SparkR: Scaling R Programs with Spark;,citation_author=Shivaram Venkataraman;,citation_author=Zongheng Yang;,citation_author=Davies Liu;,citation_author=Eric Liang;,citation_author=Hossein Falaki;,citation_author=Xiangrui Meng;,citation_author=Reynold Xin;,citation_author=Ali Ghodsi;,citation_author=Michael Franklin;,citation_author=Ion Stoica;,citation_author=Matei Zaharia;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_conference_title=Proceedings of the 2016 International Conference on Management of Data;,citation_conference=Association for Computing Machinery;,citation_series_title=SIGMOD ’16;">
<meta name="citation_reference" content="citation_title=koaning.io: Bayesian/Streaming Algorithms;,citation_author=Vincent Warmerdam;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;">
<meta name="citation_reference" content="citation_title=Outlier Analysis;,citation_author=Charu C Aggarwal;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;">
<meta name="citation_reference" content="citation_title=Video Popularity Prediction in Data Streams Based on Context-Independent Features;,citation_author=Vitor Silva;,citation_author=Ana Trindade Winck;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_conference_title=Proceedings of the Symposium on Applied Computing;,citation_conference=Association for Computing Machinery;,citation_series_title=SAC ’17;">
<meta name="citation_reference" content="citation_title=Einsatz von Machine-Learning-Verfahren in amtlichen Unternehmensstatistiken;,citation_author=Florian Dumpert;,citation_author=Martin Beck;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=2;,citation_volume=11;,citation_journal_title=AStA Wirtschafts- und Sozialstatistisches Archiv;">
<meta name="citation_reference" content="citation_title=Introduction to stream: An Extensible Framework for Data Stream Clustering Research with R;,citation_author=Michael Hahsler;,citation_author=Matthew Bolaños;,citation_author=John Forrest;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=14;,citation_volume=76;,citation_journal_title=Journal of Statistical Software;">
<meta name="citation_reference" content="citation_title=stream: Infrastructure for Data Stream Mining;,citation_author=Michael Hahsler;,citation_author=Matthew Bolaños;,citation_author=John Forrest;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;">
<meta name="citation_reference" content="citation_title=Design and Analysis of Experiments;,citation_author=D C Montgomery;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;">
<meta name="citation_reference" content="citation_title=Time Series Forecasting in the Presence of Concept Drift: A PSO-based Approach;,citation_author=Gustavo H. F. M. Oliveira;,citation_author=Rodolfo C. Cavalcante;,citation_author=George G. Cabral;,citation_author=Leandro L. Minku;,citation_author=Adriano L. I. Oliveira;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_conference_title=2017 IEEE 29th International Conference on Tools with Artificial Intelligence (ICTAI);">
<meta name="citation_reference" content="citation_title=United Nations Global Pulse. Harnessing big data for development and humanitarian action.;,citation_author=United Nations;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;">
<meta name="citation_reference" content="citation_title=koaning.io: Passive Agressive Algorithms;,citation_author=Vincent Warmerdam;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;">
<meta name="citation_reference" content="citation_title=On the Reliable Detection of Concept Drift from Streaming Unlabeled Data;,citation_author=Tegjyot Singh Sethi;,citation_author=Mehmed Kantardzic;,citation_publication_date=2017-03;,citation_cover_date=2017-03;,citation_year=2017;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Proof of Concept Machine Learning - Abschlussbericht;,citation_author=Martin Beck;,citation_author=Florian Dumpert;,citation_author=Jörg Feuerhake;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_technical_report_institution=Statistisches Bundesamt (Destatis);">
<meta name="citation_reference" content="citation_title=Machine Learning for Data Streams with Practical Examples in MOA;,citation_author=Albert Bifet;,citation_author=Ricard Gavalda;,citation_author=Geoff Holmes;,citation_author=Bernhard Pfahringer;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;">
<meta name="citation_reference" content="citation_title=Lifelong Machine Learning;,citation_author=Zhiyuan Chen;,citation_author=Bing Liu;,citation_author=Ronald Brachman;,citation_author=Peter Stone;,citation_author=Francesca Rossi;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;">
<meta name="citation_reference" content="citation_title=Incremental on-line learning: A review and comparison of state of the art algorithms;,citation_author=Viktor Losing;,citation_author=Barbara Hammer;,citation_author=Heiko Wersing;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_volume=275;,citation_journal_title=Neurocomputing;">
<meta name="citation_reference" content="citation_title=Extremely Fast Decision Tree;,citation_author=Chaitanya Manapragada;,citation_author=Geoffrey I. Webb;,citation_author=Mahsa Salehi;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_conference_title=Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;,citation_conference=Association for Computing Machinery;,citation_series_title=KDD ’18;">
<meta name="citation_reference" content="citation_title=An evaluation of data stream clustering algorithms;,citation_author=Stratos Mansalis;,citation_author=Eirini Ntoutsi;,citation_author=Nikos Pelekis;,citation_author=Yannis Theodoridis;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=4;,citation_volume=11;,citation_journal_title=Statistical Analysis and Data Mining: The ASA Data Science Journal;">
<meta name="citation_reference" content="citation_title=koaning.io: How to win with simple, even linear, models;,citation_author=Vincent Warmerdam;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;">
<meta name="citation_reference" content="citation_title=Anomaly Detection in Manufacturing Systems Using Structured Neural Networks;,citation_author=J. Liu;,citation_author=J. Guo;,citation_author=P. V. Orlik;,citation_author=M. Shibata;,citation_author=D. Nakahara;,citation_author=S. Mii;,citation_author=M. Takac;,citation_publication_date=2018-07;,citation_cover_date=2018-07;,citation_year=2018;,citation_technical_report_institution=MITSUBISHI ELECTRIC RESEARCH LABORATORIES;">
<meta name="citation_reference" content="citation_title=Industrial Internet of Things Based Ransomware Detection Using Stacked Variational Neural Network;,citation_author=Muna Al-Hawawreh;,citation_author=Elena Sitnikova;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_conference_title=Proceedings of the 3rd International Conference on Big Data and Internet of Things;,citation_conference=Association for Computing Machinery;,citation_series_title=BDIOT 2019;">
<meta name="citation_reference" content="citation_title=Evaluation of Cognitive Architectures for Cyber-Physical Production Systems;,citation_author=Andreas Bunte;,citation_author=Andreas Fischbach;,citation_author=Jan Strohschein;,citation_author=Thomas Bartz-Beielstein;,citation_author=Heide Faeskorn-Woyke;,citation_author=Oliver Niggemann;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_conference_title=24th IEEE International Conference on Emerging Technologies and Factory Automation, ETFA 2019, Zaragoza, Spain, September 10-13, 2019;">
<meta name="citation_reference" content="citation_title=Nowcasting: Ein Echtzeit-Indikator für die Konjunkturanalyse;,citation_author=Charlotte Senftleben;,citation_author=Till Strohsal;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;">
<meta name="citation_reference" content="citation_title=koaning.io: The Future of Data Science is Past;,citation_author=Vincent Warmerdam;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;">
<meta name="citation_reference" content="citation_title=Forecasting inflation with online prices;,citation_author=Diego Aparicio;,citation_author=Manuel I. Bertolotto;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_issue=2;,citation_volume=36;,citation_journal_title=International Journal of Forecasting;">
<meta name="citation_reference" content="citation_title=CAAI—a cognitive architecture to introduce artificial intelligence in cyber-physical production systems;,citation_author=Andreas Fischbach;,citation_author=Jan Strohschein;,citation_author=Andreas Bunte;,citation_author=Jörg Stork;,citation_author=Heide Faeskorn-Woyke;,citation_author=Natalia Moriz;,citation_author=Thomas Bartz-Beielstein;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_issue=1;,citation_volume=111;,citation_journal_title=The International Journal of Advanced Manufacturing Technology;">
<meta name="citation_reference" content="citation_title=Delayed labelling evaluation for data streams;,citation_author=Maciej Grzenda;,citation_author=Heitor Murilo Gomes;,citation_author=Albert Bifet;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_issue=5;,citation_volume=34;,citation_journal_title=Data Mining and Knowledge Discovery;">
<meta name="citation_reference" content="citation_title=Stream Data Mining: Algorithms and Their Probabilistic Properties;,citation_editor=Leszek Rutkowski;,citation_editor=Maciej Jaworski;,citation_editor=Piotr Duda;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_series_title=Studies in Big Data;">
<meta name="citation_reference" content="citation_title=Loghub: A Large Collection of System Log Datasets towards Automated Log Analytics;,citation_author=Shilin He;,citation_author=Jieming Zhu;,citation_author=Pinjia He;,citation_author=Michael R. Lyu;,citation_publication_date=2020-08;,citation_cover_date=2020-08;,citation_year=2020;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Nowcasting German GDP: Foreign factors, financial markets, and model averaging;,citation_author=Paolo Andreini;,citation_author=Thomas Hasenzagl;,citation_author=Lucrezia Reichlin;,citation_author=Charlotte Senftleben-König;,citation_author=Till Strohsal;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_journal_title=International Journal of Forecasting;">
<meta name="citation_reference" content="citation_title=Modelling the COVID-19 Virus Evolution With Incremental Machine Learning;,citation_author=Andrés L. Suárez-Cetrulo;,citation_author=Ankit Kumar;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;">
<meta name="citation_reference" content="citation_title=Machine Learning for Time-Series with Python: Forecast, predict, and detect;,citation_author=Den Auffarth;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;">
<meta name="citation_reference" content="citation_title=Machine Learning in der amtlichen Statistik - Ergebnisse und Bewertung eines internationalen Projekts;,citation_author=Florian Dumpert;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_technical_report_institution=Statistisches Bundesamt (Destatis);,citation_technical_report_number=4;">
<meta name="citation_reference" content="citation_title=Recurring concept memory management in data streams: exploiting data stream concept evolution to improve performance and transparency;,citation_author=Ben Halstead;,citation_author=Yun Sing Koh;,citation_author=Patricia Riddle;,citation_author=Russel Pears;,citation_author=Mykola Pechenizkiy;,citation_author=Albert Bifet;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_issue=3;,citation_volume=35;,citation_journal_title=Data Mining and Knowledge Discovery;">
<meta name="citation_reference" content="citation_title=Soziale Marktwirtschaft in der digitalen Zukunft: Foresight-Bericht Strategischer Vorausschauprozess des BMWi;,citation_author=Dirk Holtmannspötter;,citation_author=Ulrich Heimeshoff;,citation_author=Justus Haucap;,citation_author=Ina Loebert;,citation_author=Christoph Busch;,citation_author=Andreas Hoffknecht;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_technical_report_institution=VDI Technologiezentrum GmbH im Auftrag des Bundesministerium für Wirtschaft und Energie;">
<meta name="citation_reference" content="citation_title=River: machine learning for streaming data in Python;,citation_author=Jacob Montiel;,citation_author=Max Halford;,citation_author=Saulo Martiello Mastelini;,citation_author=Geoffrey Bolmier;,citation_author=Raphael Sourty;,citation_author=Robin Vaysse;,citation_author=Adil Zouitine;,citation_author=Heitor Murilo Gomes;,citation_author=Jesse Read;,citation_author=Talel Abdessalem;,citation_author=others;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;">
<meta name="citation_reference" content="citation_title=Practical Machine Learning for Streaming Data with Python;,citation_author=Sayan Putatunda;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;">
<meta name="citation_reference" content="citation_title=Infrerring Concept Drift Without Labeled Data;,citation_author=Andrew Reed;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_technical_report_institution=Cloudera Fast Forward Labs;,citation_technical_report_number=FF21;">
<meta name="citation_reference" content="citation_title=Cognitive capabilities for the CAAI in cyber-physical production systems;,citation_author=Jan Strohschein;,citation_author=Andreas Fischbach;,citation_author=Andreas Bunte;,citation_author=Heide Faeskorn-Woyke;,citation_author=Natalia Moriz;,citation_author=Thomas Bartz-Beielstein;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_journal_title=The International Journal of Advanced Manufacturing Technology;">
<meta name="citation_reference" content="citation_title=FARF: A Fair and Adaptive Random Forests Classifier;,citation_author=Wenbin Zhang;,citation_author=Albert Bifet;,citation_author=Xiangliang Zhang;,citation_author=Jeremy C. Weiss;,citation_author=Wolfgang Nejdl;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_conference_title=Advances in Knowledge Discovery and Data Mining: 25th Pacific-Asia Conference, PAKDD 2021, Virtual Event, May 11–14, 2021, Proceedings, Part II;,citation_conference=Springer-Verlag;">
<meta name="citation_reference" content="citation_title=Modelling the COVID-19 virus evolution with Incremental Machine Learning;,citation_author=Andrés L. Suárez-Cetrulo;,citation_author=Ankit Kumar;,citation_author=Luis Miralles-Pechuán;,citation_publication_date=2021-04;,citation_cover_date=2021-04;,citation_year=2021;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Online Learning and Active Learning: A Comparative Study of Passive-Aggressive Algorithm With Support Vector Machine (SVM);,citation_author=K. I Ezukwoke;,citation_author=S. J Zareian;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_issue=3;,citation_volume=21;,citation_journal_title=Journal of Higher Education Theory and Practice;">
<meta name="citation_reference" content="citation_title=Digitale Ordnungspolitik – Wirtschaftspolitik daten- und evidenzbasiert weiterentwickeln;,citation_author=Philipp Steinberg;,citation_author=Nils Börnsen;,citation_author=Dirk Neumann;,citation_publication_date=2021-09;,citation_cover_date=2021-09;,citation_year=2021;,citation_publisher=Wirtschaftsdienst;">
<meta name="citation_reference" content="citation_title=Incremental Unsupervised Domain-Adversarial Training of Neural Networks;,citation_author=Antonio-Javier Gallego;,citation_author=Jorge Calvo-Zaragoza;,citation_author=Robert B. Fisher;,citation_publication_date=2021-11;,citation_cover_date=2021-11;,citation_year=2021;,citation_issue=11;,citation_volume=32;,citation_journal_title=IEEE Transactions on Neural Networks and Learning Systems;">
<meta name="citation_reference" content="citation_title=Incremental learning for property price estimation using location-based services and open data;,citation_author=Francisco Alvarez;,citation_author=Edgar Roman-Rangel;,citation_author=Luis V. Montiel;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_volume=107;,citation_journal_title=Engineering Applications of Artificial Intelligence;">
<meta name="citation_reference" content="citation_title=Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide;,citation_editor=Eva Bartz;,citation_editor=Thomas Bartz-Beielstein;,citation_editor=Martin Zaefferer;,citation_editor=Olaf Mersmann;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=Interpretable Machine Learning: Moving from Mythos to Diagnostics;,citation_author=Valerie Chen;,citation_author=Jeffrey Li;,citation_author=Joon Sik Kim;,citation_author=Gregory Plumb;,citation_author=Ameet Talwalkar;,citation_publication_date=2022-01;,citation_cover_date=2022-01;,citation_year=2022;,citation_issue=6;,citation_volume=19;,citation_journal_title=Queue;">
<meta name="citation_reference" content="citation_title=Online Time-series Anomaly Detection: A Survey of Modern Model-based Approaches;,citation_author=Lucas Correia;,citation_author=Jan-Christoph Goos;,citation_author=Anna V. Kononova;,citation_author=Thomas Bäck;,citation_author=Philipp Klein;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_technical_report_institution=Mercedes-Benz, Germany;">
<meta name="citation_reference" content="citation_title=Green Accelerated Hoeffding Tree;,citation_author=Eva Garcia-Martin;,citation_author=Albert Bifet;,citation_author=Niklas Lavesson;,citation_author=Rikard König;,citation_author=Henrik Linusson;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=Monitoring the Economy in Real Time: Trends and Gaps in Real Activity and Prices;,citation_author=Thomas Hasenzagl;,citation_author=Filippo Pellegrino;,citation_author=Lucrezia Reichlin;,citation_author=Giovanni Ricco;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=Efficiently Correcting Machine Learning: Considering the Role of Example Ordering in Human-in-the-Loop Training of Image Classification Models;,citation_author=Geoff Holmes;,citation_author=Eibe Frank;,citation_author=Dale Fletcher;,citation_author=Corey Sterling;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_conference_title=27th International Conference on Intelligent User Interfaces;,citation_conference=Association for Computing Machinery;,citation_series_title=IUI ’22;">
<meta name="citation_reference" content="citation_title=TemporalWiki: A Lifelong Benchmark for Training and Evaluating Ever-Evolving Language Models;,citation_author=Joel Jang;,citation_author=Seonghyeon Ye;,citation_author=Changho Lee;,citation_author=Sohee Yang;,citation_author=Joongbo Shin;,citation_author=Janghoon Han;,citation_author=Gyeonghun Kim;,citation_author=Minjoon Seo;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=Fast Mining and Forecasting of Co-Evolving Epidemiological Data Streams;,citation_author=Tasuku Kimura;,citation_author=Yasuko Matsubara;,citation_author=Koki Kawabata;,citation_author=Yasushi Sakurai;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_conference_title=Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining;,citation_conference=Association for Computing Machinery;,citation_series_title=KDD ’22;">
<meta name="citation_reference" content="citation_title=Maschine Learning for Streaming Data with Python;,citation_author=Jan Korstanje;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=The Disagreement Problem in Explainable Machine Learning: A Practitioner’s Perspective;,citation_author=Satyapriya Krishna;,citation_author=Tessa Han;,citation_author=Alex Gu;,citation_author=Javin Pombra;,citation_author=Shahin Jabbari;,citation_author=Steven Wu;,citation_author=Himabindu Lakkaraju;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=SparkR: R Front End for ’Apache Spark’;,citation_author=The Apache Software Foundation;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=Short-term local predictions of COVID-19 in the United Kingdom using dynamic supervised machine learning algorithms;,citation_author=Xin Wang;,citation_author=Yijia Dong;,citation_author=William David Thompson;,citation_author=Harish Nair;,citation_author=You Li;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_issue=1;,citation_volume=2;,citation_journal_title=Communications Medicine;">
<meta name="citation_reference" content="citation_title=Log-based Anomaly Detection with Deep Learning: How Far Are We?;,citation_author=Van-Hoang Le;,citation_author=Hongyu Zhang;,citation_publication_date=2022-02;,citation_cover_date=2022-02;,citation_year=2022;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Reliance on metrics is a fundamental challenge for AI.;,citation_author=Rachel L Thomas;,citation_author=David Uminsky;,citation_publication_date=2022-05;,citation_cover_date=2022-05;,citation_year=2022;,citation_issue=5;,citation_volume=3;,citation_journal_title=Patterns (N Y);">
<meta name="citation_reference" content="citation_title=SMRD.de Benutzerhandbuch;,citation_author=Niyaz Valitov;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_technical_report_institution=Bundesnetzagentur für Elektrizität, Gas, Telekommunikation, Post und Eisenbahnen;">
<meta name="citation_reference" content="citation_title=Use of web scraping and text mining techniques in the Istat survey on “Information and Communication Technology in enterprises”;,citation_author=G. Barcaroli;,citation_author=A. Nurra;,citation_author=M. Scarnò;,citation_author=D. Summa;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=Who Makes Mistakes? Using Data Mining Techniques to Analyze Reporting Errors in Total Acres Operated;,citation_author=Jaki S. McCarthy;,citation_author=Morgan S. Earp;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_fulltext_html_url=https://ideas.repec.org/p/ags/unasrr/234367.html;,citation_doi=10.22004/AG.ECON.234367;,citation_journal_title=NASS Research Reports;,citation_publisher=United States Department of Agriculture, National Agricultural Statistics Service;">
<meta name="citation_reference" content="citation_title=Modeling Non-response in National Agricultural Statistics Service (NASS) Surveys Using Classification Trees;,citation_author=Jaki S Mccarthy;,citation_author=Thomas Jacob;,citation_author=Amanda Mccracken;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;">
<meta name="citation_reference" content="citation_title=2007 Census of Agriculture Non-Response Methodology;,citation_author=Will Cecere;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;">
<meta name="citation_reference" content="citation_title=Exploring Quarterly Agricultural Survey Questionnaire Version Reduction Scenarios;,citation_author=Morgan Earp;,citation_author=Scott Cox;,citation_author=Jody Mcdaniel;,citation_author=Chadd Crouse;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;">
<meta name="citation_reference" content="citation_title=USE OF MACHINE LEARNING METHODS TO IMPUTE CATEGORICAL DATA;,citation_author=P. Rey;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;">
<meta name="citation_reference" content="citation_title=Innovative Uses of Data Mining Techniques in the Production of Official Statistics;,citation_author=Jaki Mccarthy;,citation_author=Thomas Jacob;,citation_author=Dale Atkinson;">
<meta name="citation_reference" content="citation_title=Automatic Coding of Occupations. Using Machine Learning Algorithms for Occupation Coding in Several German Panel Surveys;,citation_fulltext_html_url=https://www.researchgate.net/publication/266259591_Automatic_Coding_of_Occupations_Using_Machine_Learning_Algorithms_for_Occupation_Coding_in_Several_German_Panel_Surveys;">
<meta name="citation_reference" content="citation_title=Evaluating hourly air quality forecasting in Canada with nonlinear updatable machine learning methods;,citation_author=Huiping Peng;,citation_author=Aranildo R. Lima;,citation_author=Andrew Teakles;,citation_author=Jian Jin;,citation_author=Alex J. Cannon;,citation_author=William W. Hsieh;,citation_publication_date=2017-03-01;,citation_cover_date=2017-03-01;,citation_year=2017;,citation_fulltext_html_url=https://doi.org/10.1007/s11869-016-0414-3;,citation_issue=2;,citation_doi=10.1007/s11869-016-0414-3;,citation_issn=1873-9326;,citation_volume=10;,citation_journal_title=Air Quality, Atmosphere &amp;amp;amp; Health;">
<meta name="citation_reference" content="citation_title=Online Machine Learning in Big Data Streams;,citation_author=András A. Benczúr;,citation_author=Levente Kocsis;,citation_author=Róbert Pálovics;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_fulltext_html_url=http://arxiv.org/abs/1802.05872;,citation_volume=abs/1802.05872;,citation_journal_title=CoRR;">
<meta name="citation_reference" content="citation_title=Learn: A Novel incremental learning method for text classification;,citation_author=Guangxu Shan;,citation_author=Shiyao Xu;,citation_author=Li Yang;,citation_author=Shengbin Jia;,citation_author=Yang Xiang;,citation_publication_date=2020-06;,citation_cover_date=2020-06;,citation_year=2020;,citation_doi=10.1016/J.ESWA.2020.113198;,citation_issn=0957-4174;,citation_volume=147;,citation_journal_title=Expert Systems with Applications;,citation_publisher=Pergamon;">
<meta name="citation_reference" content="citation_title=Incremental Real-Time Learning Framework for Sentiment Classification: Indian General Election 2019, A Case Study;,citation_author=Sharmistha Chatterjee;,citation_author=Sushmita Gupta;,citation_publication_date=2021-03;,citation_cover_date=2021-03;,citation_year=2021;,citation_doi=10.1109/ICBDA51983.2021.9402992;,citation_isbn=9780738131672;,citation_journal_title=2021 IEEE 6th International Conference on Big Data Analytics, ICBDA 2021;,citation_publisher=Institute of Electrical; Electronics Engineers Inc.;">
<meta name="citation_reference" content="citation_title=MOA: Massive Online Analysis;,citation_abstract=Massive Online Analysis (MOA) is a software environment for implementing algorithms and running experiments for online learning from evolving data streams. MOA includes a collection of offline and online methods as well as tools for evaluation. In particular, it implements boosting, bagging, and Hoeffding Trees, all with and without Na¨ıveNa¨ıve Bayes classifiers at the leaves. MOA supports bi-directional interaction with WEKA, the Waikato Environment for Knowledge Analysis , and is released under the GNU GPL license.;,citation_author=Albert Bifet;,citation_author=Geoff Holmes;,citation_author=Richard Kirkby;,citation_author=Bernhard Pfahringer;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_volume=11;,citation_journal_title=Journal of Machine Learning Research;">
<meta name="citation_reference" content="citation_title=Evaluation and Performance Measurement;,citation_author=Thomas Bartz-Beielstein;,citation_editor=Eva Bartz;,citation_editor=Thomas Bartz-Beielstein;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_inbook_title=undefined;">
<meta name="citation_reference" content="citation_title=Hyperparameter Tuning;,citation_author=Thomas Bartz-Beielstein;,citation_editor=Eva Bartz;,citation_editor=Thomas Bartz-Beielstein;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_inbook_title=undefined;">
<meta name="citation_reference" content="citation_title=Hyperparameter Tuning Approaches;,citation_author=Thomas Bartz-Beielstein;,citation_author=Martin Zaefferer;,citation_editor=Eva Bartz;,citation_editor=Thomas Bartz-Beielstein;,citation_editor=Martin Zaefferer;,citation_editor=Olaf Mersmann;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_inbook_title=Hyperparameter Tuning for Machine and Deep Learning with R - A Practical Guide;">
<meta name="citation_reference" content="citation_title=Drift Detection and&nbsp;Handling;,citation_abstract=Structural changes (“drift”) in the data cause problems for many algorithms. Based on the drift definitions given in Chap. 1, methods for drift detection and handling are discussed. For the algorithms presented in Chap. 2, it is clarified to what extent concept drift is reacted to. In turn, the extent to which catastrophic forgetting is an issue is described in Sect. 4.3. Section&nbsp;3.1 describes three architectures for implementing drift detection algorithms. Basic properties of window-based approaches are presented in Sect.&nbsp;3.2. Section&nbsp;3.4 presents commonly used drift detection techniques. Section&nbsp;3.4 describes how the drift detection techniques introduced in Sect.&nbsp;3.3 are used in Online Machine Learning (OML) algorithms and summarizes the tree-based OML techniques implemented in the River package. Section&nbsp;3.5 introduces scaling methods for handling drift.;,citation_author=Thomas Bartz-Beielstein;,citation_author=Lukas Hans;,citation_editor=Eva Bartz;,citation_editor=Thomas Bartz-Beielstein;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://doi.org/10.1007/978-981-99-7007-0_3;,citation_doi=10.1007/978-981-99-7007-0_3;,citation_isbn=978-981-99-7007-0;,citation_inbook_title=Online Machine Learning: A Practical Guide with Examples in Python;">
<meta name="citation_reference" content="citation_title=Introduction: From Batch to&nbsp;Online Machine Learning;,citation_abstract=Batch Machine Learning (BML), which is also referred to as “offline machine learning”, reaches its limits when dealing with very large amounts of data. This is especially true for available memory, handling drift in data streams, and processing new, unknown data. Online Machine Learning (OML) is an alternative to BML that overcomes the limitations of BML. In this chapter, the basic terms and concepts of OML are introduced and the differences to BML are shown.;,citation_author=Thomas Bartz-Beielstein;,citation_editor=Eva Bartz;,citation_editor=Thomas Bartz-Beielstein;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://doi.org/10.1007/978-981-99-7007-0_1;,citation_doi=10.1007/978-981-99-7007-0_1;,citation_isbn=978-981-99-7007-0;,citation_inbook_title=Online Machine Learning: A Practical Guide with Examples in Python;">
<meta name="citation_reference" content="citation_title=AMF: Aggregated Mondrian Forests for Online Learning;,citation_author=Jaouad Mourtada;,citation_author=Stephane Gaiffas;,citation_author=Erwan Scornet;,citation_publication_date=2019-06;,citation_cover_date=2019-06;,citation_year=2019;,citation_fulltext_html_url=https://arxiv.org/abs/1906.10529;,citation_doi=10.48550/arXiv.1906.10529;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Extremely fast decision tree;,citation_abstract=We introduce a novel incremental decision tree learning algorithm, Hoeffding Anytime Tree, that is statistically more efficient than the current state-of-the-art, Hoeffding Tree. We demonstrate that an implementation of Hoeffding Anytime Tree’“Extremely Fast Decision Tree”, a minor modification to the MOA implementation of Hoeffding Tree’obtains significantly superior prequential accuracy on most of the largest classification datasets from the UCI repository. Hoeffding Anytime Tree produces the asymptotic batch tree in the limit, is naturally resilient to concept drift, and can be used as a higher accuracy replacement for Hoeffding Tree in most scenarios, at a small additional computational cost.;,citation_author=Chaitanya Manapragada;,citation_author=Geoffrey I. Webb;,citation_author=Mahsa Salehi;,citation_editor=Chih-Jen  Lin;,citation_editor=Hui  Xiong;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_fulltext_html_url=http://www.kdd.org/kdd2018/, https://dl.acm.org/doi/proceedings/10.1145/3219819;,citation_doi=10.1145/3219819.3220005;,citation_conference_title=KDD’ 2018 - Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;,citation_conference=Association for Computing Machinery (ACM);">
<meta name="citation_reference" content="citation_title=Surrogates;,citation_author=Robert B Gramacy;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;">
<meta name="citation_reference" content="citation_title=UvA Deep Learning Tutorials;,citation_author=Phillip Lippe;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://github.com/phlippe/uvadlc_notebooks/tree/master;">
<meta name="citation_reference" content="citation_title=Attention Is All You Need;,citation_author=Ashish Vaswani;,citation_author=Noam Shazeer;,citation_author=Niki Parmar;,citation_author=Jakob Uszkoreit;,citation_author=Llion Jones;,citation_author=Aidan N. Gomez;,citation_author=Lukasz Kaiser;,citation_author=Illia Polosukhin;,citation_publication_date=2017-06;,citation_cover_date=2017-06;,citation_year=2017;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=On the Variance of the Adaptive Learning Rate and Beyond;,citation_author=Liyuan Liu;,citation_author=Haoming Jiang;,citation_author=Pengcheng He;,citation_author=Weizhu Chen;,citation_author=Xiaodong Liu;,citation_author=Jianfeng Gao;,citation_author=Jiawei Han;,citation_publication_date=2019-08;,citation_cover_date=2019-08;,citation_year=2019;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Efficient Transformers: A Survey;,citation_author=Yi Tay;,citation_author=Mostafa Dehghani;,citation_author=Dara Bahri;,citation_author=Donald Metzler;,citation_publication_date=2020-09;,citation_cover_date=2020-09;,citation_year=2020;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding;,citation_author=Jacob Devlin;,citation_author=Ming-Wei Chang;,citation_author=Kenton Lee;,citation_author=Kristina Toutanova;,citation_publication_date=2018-10;,citation_cover_date=2018-10;,citation_year=2018;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale;,citation_author=Alexey Dosovitskiy;,citation_author=Lucas Beyer;,citation_author=Alexander Kolesnikov;,citation_author=Dirk Weissenborn;,citation_author=Xiaohua Zhai;,citation_author=Thomas Unterthiner;,citation_author=Mostafa Dehghani;,citation_author=Matthias Minderer;,citation_author=Georg Heigold;,citation_author=Sylvain Gelly;,citation_author=Jakob Uszkoreit;,citation_author=Neil Houlsby;,citation_publication_date=2020-10;,citation_cover_date=2020-10;,citation_year=2020;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Attention is not Explanation;,citation_author=Sarthak Jain;,citation_author=Byron C. Wallace;,citation_publication_date=2019-02;,citation_cover_date=2019-02;,citation_year=2019;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Attention is not not Explanation;,citation_author=Sarah Wiegreffe;,citation_author=Yuval Pinter;,citation_publication_date=2019-08;,citation_cover_date=2019-08;,citation_year=2019;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Multivariate adaptive regression splines;,citation_author=Jerome H. Friedman;,citation_publication_date=1991;,citation_cover_date=1991;,citation_year=1991;,citation_issue=1;,citation_volume=19;,citation_journal_title=The annals of statistics;">
<meta name="citation_reference" content="citation_title=Learning model trees from evolving data streams;,citation_author=Elena Ikonomovska;,citation_author=João Gama;,citation_author=Sašo Džeroski;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=1;,citation_volume=23;,citation_journal_title=Data Mining and Knowledge Discovery;">
<meta name="citation_reference" content="citation_title=An Introduction to Statistical Learning with Applications in R;,citation_author=Gareth James;,citation_author=Daniela Witten;,citation_author=Trevor Hastie;,citation_author=Robert Tibshirani;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=Deep Learning with Python;,citation_author=Francoise Chollet;,citation_author=J. J. Allaire;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;">
<meta name="citation_reference" content="citation_title=A survey of cross-validation procedures for model selection;,citation_author=Sylvain Arlot;,citation_author=Alain Celisse;,citation_author=others;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_volume=4;,citation_journal_title=Statistics surveys;">
<meta name="citation_reference" content="citation_title=A cross-validatory method for dependent data;,citation_author=PRABIR BURMAN;,citation_author=EDMOND CHOW;,citation_author=DEBORAH NOLAN;,citation_publication_date=1994;,citation_cover_date=1994;,citation_year=1994;,citation_issue=2;,citation_volume=81;,citation_journal_title=Biometrika;">
<meta name="citation_reference" content="citation_title=A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection;,citation_author=Ron Kohavi;,citation_publication_date=1995;,citation_cover_date=1995;,citation_year=1995;,citation_conference_title=Proceedings of the 14th International Joint Conference on Artificial Intelligence - Volume 2;,citation_conference=Morgan Kaufmann Publishers Inc.;,citation_series_title=IJCAI’95;">
<meta name="citation_reference" content="citation_title=Kriging-based sequential design strategies using fast cross-validation techniques with extensions to multi-fidelity computer codes ;,citation_author=Loic Le Gratiet;,citation_author=Claire Cannamela;,citation_publication_date=2012-10;,citation_cover_date=2012-10;,citation_year=2012;">
<meta name="citation_reference" content="citation_title=Cross-Validation of Regression Models;,citation_author=Richard R. Picard;,citation_author=R. Dennis Cook;,citation_publication_date=1984;,citation_cover_date=1984;,citation_year=1984;,citation_issue=387;,citation_volume=79;,citation_journal_title=Journal of the American Statistical Association;">
<meta name="citation_reference" content="citation_title=The Elements of Statistical Learning;,citation_author=Trevor Hastie;,citation_author=Robert Tibshirani;,citation_author=Jerome Friedman;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;">
<meta name="citation_reference" content="citation_title=Deep Residual Learning for Image Recognition;,citation_author=Kaiming He;,citation_author=Xiangyu Zhang;,citation_author=Shaoqing Ren;,citation_author=Jian Sun;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=Identity Mappings in Deep Residual Networks;,citation_author=Kaiming He;,citation_author=Xiangyu Zhang;,citation_author=Shaoqing Ren;,citation_author=Jian Sun;,citation_publication_date=2016-03;,citation_cover_date=2016-03;,citation_year=2016;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Neural Ordinary Differential Equations;,citation_author=Ricky T. Q. Chen;,citation_author=Yulia Rubanova;,citation_author=Jesse Bettencourt;,citation_author=David Duvenaud;,citation_publication_date=2018-06;,citation_cover_date=2018-06;,citation_year=2018;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Mathematical Theory of Optimal Processes;,citation_author=undefined Pontryagin;,citation_publication_date=1987;,citation_cover_date=1987;,citation_year=1987;">
<meta name="citation_reference" content="citation_title=On Neural Differential Equations;,citation_author=Patrick Kidger;,citation_publication_date=2022-02;,citation_cover_date=2022-02;,citation_year=2022;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Stochastic simulation optimization: an optimal computing budget allocation;,citation_author=Chun Hung Chen;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;">
<meta name="citation_reference" content="citation_title=Sequential Parameter Optimization and Optimal Computational Budget Allocation for Noisy Optimization Problems;,citation_author=Thomas Bartz-Beielstein;,citation_author=Martina Friese;,citation_publication_date=2011-01;,citation_cover_date=2011-01;,citation_year=2011;">
<meta name="citation_reference" content="citation_title=Statistik;,citation_author=Joachim Hartung;,citation_author=Bärbel Elpert;,citation_author=Karl-Heinz Klösener;,citation_publication_date=1995;,citation_cover_date=1995;,citation_year=1995;">
<meta name="citation_reference" content="citation_title=Partial correlation — Wikipedia, The Free Encyclopedia;,citation_author=Wikipedia contributors;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://en.wikipedia.org/w/index.php?title=Partial_correlation&amp;amp;amp;oldid=1253637419;">
<meta name="citation_reference" content="citation_title=Understanding Correlation;,citation_author=R. J. Rummel;,citation_publication_date=1976;,citation_cover_date=1976;,citation_year=1976;,citation_fulltext_html_url=https://www.hawaii.edu/powerkills/UC.HTM;">
<meta name="citation_reference" content="citation_title=Two Postestimation Commands for Assessing Confounding Effects in Epidemiological Studies;,citation_author=Zhiqiang Wang;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=2;,citation_volume=7;,citation_journal_title=The Stata Journal;">
<meta name="citation_reference" content="citation_title=Response surface methodology: process and product optimization using designed experiments;,citation_author=Raymond H Myers;,citation_author=Douglas C Montgomery;,citation_author=Christine M Anderson-Cook;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;">
<meta name="citation_reference" content="citation_title=desirability: Function Optimization and Ranking via Desirability Functions;,citation_author=Max Kuhn;,citation_publication_date=2016-09;,citation_cover_date=2016-09;,citation_year=2016;">
<meta name="citation_reference" content="citation_title=Noisy optimization with sequential parameter optimization and optimal computational budget allocation;,citation_author=Thomas Bartz-Beielstein;,citation_author=Martina Friese;,citation_author=Martin Zaefferer;,citation_author=Boris Naujoks;,citation_author=Oliver Flasch;,citation_author=Wolfgang Konen;,citation_author=Patrick Koch;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_conference_title=Proceedings of the 13th annual conference companion on Genetic and evolutionary computation;,citation_conference=ACM;">
<meta name="citation_reference" content="citation_title=Stochastic simulation optimization: an optimal computing budget allocation;,citation_author=Chun Hung Chen;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;">
<meta name="citation_reference" content="citation_title=Generalized Simulated Annealing for Function Optimization;,citation_author=I O Bohachevsky;,citation_publication_date=1986;,citation_cover_date=1986;,citation_year=1986;,citation_issue=3;,citation_volume=28;,citation_journal_title=Technometrics;">
<meta name="citation_reference" content="citation_title=On the Experimental Attainment of Optimum Conditions;,citation_author=G. E. P. Box;,citation_author=K. B. Wilson;,citation_publication_date=1951;,citation_cover_date=1951;,citation_year=1951;,citation_issue=1;,citation_volume=13;,citation_journal_title=Journal of the Royal Statistical Society. Series B (Methodological);">
<meta name="citation_reference" content="citation_title=Design and Analysis of Experiments;,citation_author=D C Montgomery;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;">
<meta name="citation_reference" content="citation_title=Empirical Design of Geometric Algorithms;,citation_author=Karsten Weihe;,citation_author=Ulrik Brandes;,citation_author=Annegret Liebers;,citation_author=Matthias Mı̈ Hannemann;,citation_author=Dorothea Wagner;,citation_author=Thomas Willhalm;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_conference_title=SCG ’99: Proceedings of the Fifteenth Annual Symposium on Computational Geometry;,citation_conference=Association for Computing Machinery;">
<meta name="citation_reference" content="citation_title=Hyperparameter optimization: Foundations, algorithms, best practices, and open challenges;,citation_author=Bernd Bischl;,citation_author=Martin Binder;,citation_author=Michel Lang;,citation_author=Tobias Pielok;,citation_author=Jakob Richter;,citation_author=Stefan Coors;,citation_author=Janek Thomas;,citation_author=Theresa Ullmann;,citation_author=Marc Becker;,citation_author=Anne-Laure Boulesteix;,citation_author=Difan Deng;,citation_author=Marius Lindauer;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_issue=2;,citation_volume=13;,citation_journal_title=WIREs Data Mining and Knowledge Discovery;">
<meta name="citation_reference" content="citation_title=Multi-Factor Experimental Designs for Exploring Response Surfaces;,citation_author=G. E. P. Box;,citation_author=J. S. Hunter;,citation_publication_date=1957;,citation_cover_date=1957;,citation_year=1957;,citation_issue=1;,citation_volume=28;,citation_journal_title=The Annals of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Multi-Objective Evolutionary Algorithms: Past, Present, and Future;,citation_author=Carlos A. Coello Coello;,citation_author=Silvia González Brambila;,citation_author=Josué Figueroa Gamboa;,citation_author=Ma. Guadalupe Castillo Tapia;,citation_editor=Panos M. Pardalos;,citation_editor=Varvara Rasskazova;,citation_editor=Michael N. Vrahatis;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_inbook_title=undefined;">
<meta name="citation_reference" content="citation_title=Modified Desirability Functions for Multiple Response Optimization;,citation_author=E. Del Castillo;,citation_author=D. C. Montgomery;,citation_author=D. R. McCarville;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_volume=28;,citation_journal_title=Journal of Quality Technology;">
<meta name="citation_reference" content="citation_title=Simultaneous Optimization of Several Response Variables;,citation_author=G. Derringer;,citation_author=R. Suich;,citation_publication_date=1980;,citation_cover_date=1980;,citation_year=1980;,citation_volume=12;,citation_journal_title=Journal of Quality Technology;">
<meta name="citation_reference" content="citation_title=A tutorial on multiobjective optimization: fundamentals and evolutionary methods;,citation_author=Michael T. M. Emmerich;,citation_author=AndréH. Deutz;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=3;,citation_volume=17;,citation_journal_title=Natural Computing;">
<meta name="citation_reference" content="citation_title=The Desirability Function;,citation_author=J Harington;,citation_publication_date=1965;,citation_cover_date=1965;,citation_year=1965;,citation_volume=21;,citation_journal_title=Industrial Quality Control;">
<meta name="citation_reference" content="citation_title=Multi-Objective Hyperparameter Optimization in Machine Learning—An Overview;,citation_author=Florian Karl;,citation_author=Tobias Pielok;,citation_author=Julia Moosbauer;,citation_author=Florian Pfisterer;,citation_author=Stefan Coors;,citation_author=Martin Binder;,citation_author=Lennart Schneider;,citation_author=Janek Thomas;,citation_author=Jakob Richter;,citation_author=Michel Lang;,citation_author=Eduardo C. Garrido-Merchán;,citation_author=Juergen Branke;,citation_author=Bernd Bischl;,citation_publication_date=2023-12;,citation_cover_date=2023-12;,citation_year=2023;,citation_issue=4;,citation_volume=3;,citation_journal_title=ACM Trans. Evol. Learn. Optim.;">
<meta name="citation_reference" content="citation_title=A Simplex Method for Function Minimization;,citation_author=J. A. Nelder;,citation_author=R. Mead;,citation_publication_date=1965-01;,citation_cover_date=1965-01;,citation_year=1965;,citation_issue=4;,citation_volume=7;,citation_journal_title=The Computer Journal;">
<meta name="citation_reference" content="citation_title=Multiple Objective Optimization Using Desirability Functions for the Design of a 3D Printer Prototype;,citation_author=Esmeralda Nino;,citation_author=Juan Rosas Rubio;,citation_author=Samuel Bonet;,citation_author=Nazario Ramirez-Beltran;,citation_author=Mauricio Cabrera-Rios;,citation_publication_date=2015-06;,citation_cover_date=2015-06;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=NIST/SEMATECH e-Handbook of Statistical Methods;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;">
<meta name="citation_reference" content="citation_title=The Nelder-Mead simplex procedure for function minimization;,citation_author=Donald M Olsson;,citation_author=Lloyd S Nelson;,citation_publication_date=1975;,citation_cover_date=1975;,citation_year=1975;,citation_issue=1;,citation_volume=17;,citation_journal_title=Technometrics;">
<meta name="citation_reference" content="citation_title=Hyperparameter Tuning Cookbook: A guide for scikit-learn, PyTorch, river, and spotpython;,citation_author=Thomas Bartz-Beielstein;,citation_publication_date=2023-07;,citation_cover_date=2023-07;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2307.10262;,citation_doi=10.48550/arXiv.2307.10262;,citation_journal_title=arXiv e-prints;">
<meta name="citation_reference" content="citation_title=Interpolation of scattered data: Distance matrices and conditionally positive definite functions;,citation_abstract=Among other things, we prove that multiquadric surface interpolation is always solvable, thereby settling a conjecture of R. Franke.;,citation_author=Charles A. Micchelli;,citation_publication_date=1986;,citation_cover_date=1986;,citation_year=1986;,citation_fulltext_html_url=https://doi.org/10.1007/BF01893414;,citation_issue=1;,citation_doi=10.1007/BF01893414;,citation_isbn=1432-0940;,citation_volume=2;,citation_journal_title=Constructive Approximation;">
<meta name="citation_reference" content="citation_title=Computational Approaches for Aerospace Design: The Pursuit of Excellence;,citation_author=Andrew J Keane;,citation_author=Prasanth B Nair;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;">
<meta name="citation_reference" content="citation_title=Statistical learning theory;,citation_author=V N Vapnik;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;">
<meta name="citation_reference" content="citation_title=Regularization algorithms for learning that are equivalent to multilayer networks.;,citation_abstract=Learning an input-output mapping from a set of examples, of the type that many neural networks have been constructed to perform, can be regarded as synthesizing an approximation of a multidimensional function (that is, solving the problem of hypersurface reconstruction). From this point of view, this form of learning is closely related to classical approximation techniques, such as generalized splines and regularization theory. A theory is reported that shows the equivalence between regularization and a class of three-layer networks called regularization networks or hyper basis functions. These networks are not only equivalent to generalized splines but are also closely related to the classical radial basis functions used for interpolation tasks and to several pattern recognition and neural network algorithms. They also have an interesting interpretation in terms of prototypes that are synthesized and optimally combined during the learning stage.;,citation_author=T Poggio;,citation_author=F Girosi;,citation_publication_date=1990-02;,citation_cover_date=1990-02;,citation_year=1990;,citation_issue=4945;,citation_doi=10.1126/science.247.4945.978;,citation_issn=0036-8075 (Print); 0036-8075 (Linking);,citation_pmid=17776454;,citation_volume=247;,citation_journal_title=Science;">
<meta name="citation_reference" content="citation_title=Exploratory designs for computational experiments;,citation_abstract=Recent work by Johnson et al. (J. Statist. Plann. Inference 26 (1990) 131–148) establishes equivalence of the maximin distance design criterion and an entropy criterion motivated by function prediction in a Bayesian setting. The latter criterion has been used by Currin et al. (J. Amer. Statist. Assoc. 86 (1991) 953–963) to design experiments for which the motivating application is approximation of a complex deterministic computer model. Because computer experiments often have a large number of controlled variables (inputs), maximin designs of moderate size are often concentrated in the corners of the cuboidal design region, i.e. each input is represented at only two levels. Here we will examine some maximin distance designs constructed within the class of Latin hypercube arrangements. The goal of this is to find designs which offer a compromise between the entropy/maximin criterion, and good projective properties in each dimension (as guaranteed by Latin hypercubes). A simulated annealing search algorithm is presented for constructing these designs, and patterns apparent in the optimal designs are discussed.;,citation_author=Max D. Morris;,citation_author=Toby J. Mitchell;,citation_publication_date=1995;,citation_cover_date=1995;,citation_year=1995;,citation_fulltext_html_url=https://www.sciencedirect.com/science/article/pii/037837589400035T;,citation_issue=3;,citation_doi=https://doi.org/10.1016/0378-3758(94)00035-T;,citation_issn=0378-3758;,citation_volume=43;,citation_journal_title=Journal of Statistical Planning and Inference;">
<meta name="citation_reference" content="citation_title=Evolutionary operation: A method for increasing industrial productivity.;,citation_author=G E P Box;,citation_publication_date=1957;,citation_cover_date=1957;,citation_year=1957;,citation_volume=6;,citation_journal_title=Applied Statistics;">
<meta name="citation_reference" content="citation_title=Minimax and maximin distance designs;,citation_author=M. E. Johnson;,citation_author=L. M. Moore;,citation_author=D. Ylvisaker;,citation_publication_date=1990;,citation_cover_date=1990;,citation_year=1990;,citation_issue=2;,citation_volume=26;,citation_journal_title=Journal of Statistical Planning and Inference;">
<meta name="citation_reference" content="citation_title=Aircraft Design: A Conceptual Approach;,citation_author=Daniel P. Raymer;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;">
<meta name="citation_reference" content="citation_title=Design and analysis of computer experiments;,citation_author=J Sacks;,citation_author=W J Welch;,citation_author=T J Mitchell;,citation_author=H P Wynn;,citation_publication_date=1989;,citation_cover_date=1989;,citation_year=1989;,citation_issue=4;,citation_volume=4;,citation_journal_title=Statistical Science;">
<meta name="citation_reference" content="citation_title=Kriging (Gaussian Process Regression): The Complete Python Code for the Example;,citation_author=Thomas Bartz-Beielstein;,citation_publication_date=2025-06;,citation_cover_date=2025-06;,citation_year=2025;,citation_fulltext_html_url=https://sequential-parameter-optimization.github.io/Hyperparameter-Tuning-Cookbook/006_num_gp.html;">
</head>

<body class="nav-sidebar docked quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Seitenleiste umschalten" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./de_awwe.html">Lernmodule</a></li><li class="breadcrumb-item"><a href="./de_kriging.html"><span class="chapter-number">59</span>&nbsp; <span class="chapter-title">Lernmodul: Eine Einführung in Kriging</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Seitenleiste umschalten" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Suchen" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Hyperparameter Tuning Cookbook</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/sequential-parameter-optimization/spotpython" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="./Hyperparameter-Tuning-Cookbook.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
              <i class="bi bi-linkedin pe-1"></i>
            LinkedIn
            </a>
          </li>
      </ul>
    </div>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Suchen"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Optimization</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./002_awwe.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Aircraft Wing Weight Example</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./003_scipy_optimize_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction to <code>scipy.optimize</code></span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Numerical Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./001_surrogate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Simulation and Surrogate Modeling</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./001_sampling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Sampling Plans</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./006_constructing_surrogate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Constructing a Surrogate</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./005_num_rsm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Response Surface Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./006_num_poly.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Polynomial Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./006_num_rbf.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Radial Basis Function Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./006_num_gp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Kriging (Gaussian Process Regression)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./006_matrices.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Matrices</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Sequential Parameter Optimization Toolbox (SPOT)</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./007_spot_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Introduction to Sequential Parameter Optimization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./008_num_spot_multidim.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Multi-dimensional Functions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./009_num_spot_anisotropic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Isotropic and Anisotropic Kriging</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./004_spot_sklearn_optimization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Sequential Parameter Optimization: Using <code>scipy</code> Optimizers</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./010_num_spot_sklearn_surrogate.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Using <code>sklearn</code> Surrogates in <code>spotpython</code></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./011_num_spot_sklearn_gaussian.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Sequential Parameter Optimization: Gaussian Process Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./012_num_spot_ei.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Expected Improvement</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./013_num_spot_noisy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Handling Noise</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./014_num_spot_ocba.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Optimal Computational Budget Allocation in spotpython</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./015_num_spot_correlation_p.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Kriging with Varying Correlation-p</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./016_num_spot_factorial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Factorial Variables</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./017_num_spot_user_function.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">User-Specified Functions: Extending the Analytical Class</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Data-Driven Modeling and Optimization</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./100_ddmo_eda.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Basic Statistics and Data Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./100_ddmo_pca.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Multicollinearity and Principle Component Analysis (PCA)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./100_ddmo_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./100_ddmo_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Classification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./100_ddmo_clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Clustering</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Machine Learning and AI</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./200_mlai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Machine Learning and Artificial Intelligence</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Introduction to Hyperparameter Tuning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./300_hpt_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Hyperparameter Tuning with Sklearn</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./400_spot_hpt_sklearn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">HPT: sklearn</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./401_spot_hpt_sklearn_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">HPT: sklearn SVC on Moons Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./401_spot_hpt_sklearn_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">HPT: sklearn SVR on Regression Data</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true">
 <span class="menu-text">Hyperparameter Tuning with River</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./500_spot_hpt_river.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">HPT: River</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./501_spot_river_gui.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Simplifying Hyperparameter Tuning in Online Machine Learning—The spotRiverGUI</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./502_spot_hpt_river_friedman_htr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title"><code>river</code> Hyperparameter Tuning: Hoeffding Tree Regressor with Friedman Drift Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./503_spot_hpt_river_friedman_amfr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">The Friedman Drift Data Set</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true">
 <span class="menu-text">Hyperparameter Tuning with PyTorch Lightning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./700_lightning_basic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Basic Lightning Module</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./701_lightning_details.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Details of the Lightning Module Integration in spotpython</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./702_lightning_user_datamodule.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">User Specified Basic Lightning Module With spotpython</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./600_spot_lightning_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">HPT PyTorch Lightning: Data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./601_spot_hpt_light_diabetes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning with <code>spotpython</code> and <code>PyTorch</code> Lightning for the Diabetes Data Set</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./601_spot_hpt_light_user_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">42</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning with PyTorch Lightning and User Data Sets</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./601_spot_hpt_light_user_model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">43</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning with PyTorch Lightning and User Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./601_resnet.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">44</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning with PyTorch Lightning: ResNets</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./601_neural_ode.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">45</span>&nbsp; <span class="chapter-title">Neural ODEs</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./601_neural_ode_example.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">46</span>&nbsp; <span class="chapter-title">Neural ODE Example</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./601_pinn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">47</span>&nbsp; <span class="chapter-title">Physics Informed Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./601_spot_hpt_light_pinn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">48</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning with PyTorch Lightning: Physics Informed Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./602_spot_lightning_xai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">49</span>&nbsp; <span class="chapter-title">Explainable AI with SpotPython and Pytorch</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./603_spot_lightning_transformer_introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">50</span>&nbsp; <span class="chapter-title">HPT PyTorch Lightning Transformer: Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./603_spot_lightning_transformer_hpt.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">51</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning of a Transformer Network with PyTorch Lightning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./604_spot_lightning_save_load_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">52</span>&nbsp; <span class="chapter-title">Saving and Loading</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./605_spot_hpt_light_diabetes_resnet.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">53</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning with <code>spotpython</code> and <code>PyTorch</code> Lightning for the Diabetes Data Set Using a ResNet Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./606_spot_hpt_light_diabetes_user_resnet.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">54</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning with <code>spotpython</code> and <code>PyTorch</code> Lightning for the Diabetes Data Set Using a User Specified ResNet Model</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./608_spot_hpt_light_condnet.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">55</span>&nbsp; <span class="chapter-title">Hyperparameter Tuning with <code>spotpython</code> and <code>PyTorch</code> Lightning Using a CondNet Model</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true">
 <span class="menu-text">Multi Objective Optimization</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bart25a-desirability-latest.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">56</span>&nbsp; <span class="chapter-title">Introduction to Desirability Functions</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true">
 <span class="menu-text">Lernmodule</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./de_awwe.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">57</span>&nbsp; <span class="chapter-title">Lernmodul: Aircraft Wing Weight Example (AWWE)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./de_sampling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">58</span>&nbsp; <span class="chapter-title">Lernmodul: Versuchspläne (Sampling-Pläne) für Computerexperimente</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./de_kriging.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">59</span>&nbsp; <span class="chapter-title">Lernmodul: Eine Einführung in Kriging</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./de_cholesky.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">60</span>&nbsp; <span class="chapter-title">Lernmodul: Die Cholesky-Zerlegung</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./de_kriging_optimization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">61</span>&nbsp; <span class="chapter-title">Lernmodul: Erweiterung des Kriging-Modells: Numerische Optimierung der Hyperparameter</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_01_intro_to_notebooks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Introduction to Jupyter Notebook</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_02_git_intro_en.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Git Introduction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_03_python_intro_en.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Python</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_04_gp_background.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Gaussian Processes—Some Background Information</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_05_datasets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Datasets</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_06_slurm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Using Slurm</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_07_package.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">G</span>&nbsp; <span class="chapter-title">Python Package Building</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_08_parallel.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">H</span>&nbsp; <span class="chapter-title">Parallelism in Initial Design</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_99_solutions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">I</span>&nbsp; <span class="chapter-title">Solutions to Selected Exercises</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Inhaltsverzeichnis</h2>
   
  <ul>
  <li><a href="#konzeptionelle-grundlagen-des-kriging" id="toc-konzeptionelle-grundlagen-des-kriging" class="nav-link active" data-scroll-target="#konzeptionelle-grundlagen-des-kriging"><span class="header-section-number">59.1</span> Konzeptionelle Grundlagen des Kriging</a>
  <ul class="collapse">
  <li><a href="#von-einfachen-modellen-zur-intelligenten-interpolation" id="toc-von-einfachen-modellen-zur-intelligenten-interpolation" class="nav-link" data-scroll-target="#von-einfachen-modellen-zur-intelligenten-interpolation"><span class="header-section-number">59.1.1</span> Von einfachen Modellen zur intelligenten Interpolation</a></li>
  <li><a href="#die-kernphilosophie-des-kriging-eine-stochastische-prozessperspektive" id="toc-die-kernphilosophie-des-kriging-eine-stochastische-prozessperspektive" class="nav-link" data-scroll-target="#die-kernphilosophie-des-kriging-eine-stochastische-prozessperspektive"><span class="header-section-number">59.1.2</span> Die Kernphilosophie des Kriging: Eine stochastische Prozessperspektive</a></li>
  </ul></li>
  <li><a href="#die-mathematische-architektur-eines-kriging-modells" id="toc-die-mathematische-architektur-eines-kriging-modells" class="nav-link" data-scroll-target="#die-mathematische-architektur-eines-kriging-modells"><span class="header-section-number">59.2</span> Die mathematische Architektur eines Kriging-Modells</a>
  <ul class="collapse">
  <li><a href="#glossar-der-kriging-notation" id="toc-glossar-der-kriging-notation" class="nav-link" data-scroll-target="#glossar-der-kriging-notation"><span class="header-section-number">59.2.1</span> Glossar der Kriging-Notation</a></li>
  <li><a href="#der-korrelationskernel-quantifizierung-von-beziehungen" id="toc-der-korrelationskernel-quantifizierung-von-beziehungen" class="nav-link" data-scroll-target="#der-korrelationskernel-quantifizierung-von-beziehungen"><span class="header-section-number">59.2.2</span> Der Korrelationskernel: Quantifizierung von Beziehungen</a></li>
  <li><a href="#aufbau-des-systems-die-korrelationsmatrizen-psi-und-vecpsi" id="toc-aufbau-des-systems-die-korrelationsmatrizen-psi-und-vecpsi" class="nav-link" data-scroll-target="#aufbau-des-systems-die-korrelationsmatrizen-psi-und-vecpsi"><span class="header-section-number">59.2.3</span> Aufbau des Systems: Die Korrelationsmatrizen <span class="math inline">\(\Psi\)</span> und <span class="math inline">\(\vec{\psi}\)</span></a></li>
  <li><a href="#sec-mle" id="toc-sec-mle" class="nav-link" data-scroll-target="#sec-mle"><span class="header-section-number">59.2.4</span> Modellkalibrierung durch Maximum-Likelihood-Schätzung (MLE)</a></li>
  </ul></li>
  <li><a href="#implementierung-und-vorhersage" id="toc-implementierung-und-vorhersage" class="nav-link" data-scroll-target="#implementierung-und-vorhersage"><span class="header-section-number">59.3</span> Implementierung und Vorhersage</a>
  <ul class="collapse">
  <li><a href="#der-kriging-prädiktor-generierung-neuer-werte" id="toc-der-kriging-prädiktor-generierung-neuer-werte" class="nav-link" data-scroll-target="#der-kriging-prädiktor-generierung-neuer-werte"><span class="header-section-number">59.3.1</span> Der Kriging-Prädiktor: Generierung neuer Werte</a></li>
  <li><a href="#sec-numerical-best-practices" id="toc-sec-numerical-best-practices" class="nav-link" data-scroll-target="#sec-numerical-best-practices"><span class="header-section-number">59.3.2</span> Numerische Best Practices und der Nugget-Effekt</a></li>
  </ul></li>
  <li><a href="#sec-example-de" id="toc-sec-example-de" class="nav-link" data-scroll-target="#sec-example-de"><span class="header-section-number">59.4</span> Eine vollständige exemplarische Vorgehensweise: Kriging der Sinusfunktion</a>
  <ul class="collapse">
  <li><a href="#schritt-für-schritt-codeausführung-und-interpretation" id="toc-schritt-für-schritt-codeausführung-und-interpretation" class="nav-link" data-scroll-target="#schritt-für-schritt-codeausführung-und-interpretation"><span class="header-section-number">59.4.1</span> Schritt-für-Schritt-Codeausführung und Interpretation</a></li>
  <li><a href="#fazit-und-ausblick" id="toc-fazit-und-ausblick" class="nav-link" data-scroll-target="#fazit-und-ausblick"><span class="header-section-number">59.4.2</span> Fazit und Ausblick</a></li>
  </ul></li>
  <li><a href="#zusatzmaterialien" id="toc-zusatzmaterialien" class="nav-link" data-scroll-target="#zusatzmaterialien"><span class="header-section-number">59.5</span> Zusatzmaterialien</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./de_awwe.html">Lernmodule</a></li><li class="breadcrumb-item"><a href="./de_kriging.html"><span class="chapter-number">59</span>&nbsp; <span class="chapter-title">Lernmodul: Eine Einführung in Kriging</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">59</span>&nbsp; <span class="chapter-title">Lernmodul: Eine Einführung in Kriging</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="konzeptionelle-grundlagen-des-kriging" class="level2" data-number="59.1">
<h2 data-number="59.1" class="anchored" data-anchor-id="konzeptionelle-grundlagen-des-kriging"><span class="header-section-number">59.1</span> Konzeptionelle Grundlagen des Kriging</h2>
<section id="von-einfachen-modellen-zur-intelligenten-interpolation" class="level3" data-number="59.1.1">
<h3 data-number="59.1.1" class="anchored" data-anchor-id="von-einfachen-modellen-zur-intelligenten-interpolation"><span class="header-section-number">59.1.1</span> Von einfachen Modellen zur intelligenten Interpolation</h3>
<p>In der modernen ingenieur- und naturwissenschaftlichen Forschung werden Praktiker häufig mit „Black-Box“-Funktionen konfrontiert. Dies sind Systeme oder Simulationen, deren interne Funktionsweise entweder unbekannt oder so komplex ist, dass sie praktisch undurchschaubar ist. Ein gängiges Beispiel ist eine hochpräzise Simulation der numerischen Strömungsmechanik (CFD), bei der Eingaben wie die Flügelgeometrie oder die Strömungsgeschwindigkeit Ausgaben wie Auftrieb und Luftwiderstand erzeugen. Jede Auswertung dieser Black Box kann außerordentlich teuer sein und Stunden oder sogar Tage an Supercomputerzeit in Anspruch nehmen. Wenn das Ziel darin besteht, den Designraum zu erkunden oder ein optimales Design zu finden, ist die Durchführung von Tausenden dieser Auswertungen oft nicht durchführbar.</p>
<p>Diese Herausforderung führt zur Notwendigkeit von <strong>Surrogatmodellen</strong>, auch bekannt als Metamodelle oder Antwortflächenmodelle “Response-Surface”. Ein Surrogatmodell ist eine rechengünstige Annäherung an eine teure Black-Box-Funktion. Es wird konstruiert, indem eine kleine Anzahl sorgfältig ausgewählter Auswertungen der wahren Funktion durchgeführt und dann ein mathematisches Modell an diese beobachteten Datenpunkte angepasst wird. Dieses „Modell eines Modells“ kann dann Tausende Male zu vernachlässigbaren Kosten ausgewertet werden, was eine effiziente Optimierung, Sensitivitätsanalyse und Erkundung des Designraums ermöglicht.</p>
<section id="eine-brücke-zum-kriging-verständnis-von-radialen-basisfunktionen-rbfs" class="level4" data-number="59.1.1.1">
<h4 data-number="59.1.1.1" class="anchored" data-anchor-id="eine-brücke-zum-kriging-verständnis-von-radialen-basisfunktionen-rbfs"><span class="header-section-number">59.1.1.1</span> Eine Brücke zum Kriging: Verständnis von Radialen Basisfunktionen (RBFs)</h4>
<p>Eine leistungsstarke und intuitive Klasse von Surrogatmodellen ist das <strong>Modell der Radialen Basisfunktionen (RBF)</strong>. Die grundlegende Idee hinter einem RBF ist es, eine komplexe Funktion als gewichtete Summe einfacherer, gut verstandener Basisfunktionen darzustellen. Jede Basisfunktion ist an einem der bekannten Datenpunkte zentriert, und ihr Wert hängt nur vom Abstand zu diesem Zentrum ab.</p>
<p>Mathematisch hat ein RBF-Modell die Form: <span class="math display">\[
\hat{f}(\vec{x}) = \sum_{i=1}^{n} w_i \psi(||\vec{x} - \vec{c}^{(i)}||)
\]</span> wobei <span class="math inline">\(\hat{f}(\vec{x})\)</span> der vorhergesagte Wert an einem neuen Punkt <span class="math inline">\(\vec{x}\)</span> ist, <span class="math inline">\(w_i\)</span> die Gewichte sind, <span class="math inline">\(\vec{c}^{(i)}\)</span> die Zentren der Basisfunktionen (typischerweise die Standorte der bekannten Datenpunkte, <span class="math inline">\(\vec{x}^{(i)}\)</span>) und <span class="math inline">\(\psi\)</span> die radiale Basisfunktion selbst ist, die auf dem euklidischen Abstand <span class="math inline">\(||\vec{x} - \vec{c}^{(i)}||\)</span> operiert.</p>
<p>Gängige Wahlen für <span class="math inline">\(\psi\)</span> umfassen die linearen, kubischen, Gauß’schen oder multiquadratischen Funktionen <span class="citation" data-cites="Forr08a">(<a href="references.html#ref-Forr08a" role="doc-biblioref">Forrester, Sóbester, und Keane 2008</a>)</span>. Indem wir fordern, dass das Modell exakt durch alle bekannten Datenpunkte verläuft (ein Prozess, der als Interpolation bezeichnet wird), können wir ein System linearer Gleichungen aufstellen, um die unbekannten Gewichte <span class="math inline">\(w_i\)</span> zu lösen. Dies wird typischerweise in Matrixform geschrieben als: <span class="math display">\[
\Psi \vec{w} = \vec{y}
\]</span> wobei <span class="math inline">\(\Psi\)</span> eine Matrix der Auswertungen der Basisfunktionen ist, <span class="math inline">\(\vec{w}\)</span> der Vektor der Gewichte und <span class="math inline">\(\vec{y}\)</span> der Vektor der beobachteten Antworten ist. Das Lösen nach den Gewichten ist dann eine Frage der Matrixinversion: <span class="math inline">\(\vec{w} = \Psi^{-1} \vec{y}\)</span>. Die Schönheit dieses Ansatzes liegt darin, dass er ein potenziell hochgradig nichtlineares Modellierungsproblem in ein unkompliziertes lineares Algebraproblem umwandelt <span class="citation" data-cites="Forr08a">(<a href="references.html#ref-Forr08a" role="doc-biblioref">Forrester, Sóbester, und Keane 2008</a>)</span>.</p>
<p>Diese Struktur weist eine bemerkenswerte Ähnlichkeit mit anderen Modellierungsparadigmen auf. Die RBF-Formulierung ist funktional identisch mit einem einschichtigen künstlichen neuronalen Netz, bei dem die Neuronen eine radiale Aktivierungsfunktion verwenden. In dieser Analogie ist die Eingabe für jedes Neuron der Abstand von einem Zentrum, die Aktivierungsfunktion des Neurons ist die Basisfunktion <span class="math inline">\(\psi\)</span>, und die Ausgabe des Netzwerks ist die gewichtete Summe dieser Aktivierungen. Diese Verbindung bietet ein nützliches mentales Modell für diejenigen, die mit maschinellem Lernen vertraut sind, und rahmt RBFs nicht als esoterische statistische Technik, sondern als nahen Verwandten von neuronalen Netzen ein, die beide leistungsstarke universelle Funktionsapproximatoren sind.</p>
</section>
<section id="einordnung-des-kriging" class="level4" data-number="59.1.1.2">
<h4 data-number="59.1.1.2" class="anchored" data-anchor-id="einordnung-des-kriging"><span class="header-section-number">59.1.1.2</span> Einordnung des Kriging</h4>
<p>In dieser Landschaft tritt das <strong>Kriging</strong> als eine besonders anspruchsvolle und flexible Art eines RBF-Modells hervor. Ursprünglich aus dem Bereich der Geostatistik durch die Arbeit von Danie G. Krige und Georges Matheron stammend, wurde es entwickelt, um Erzkonzentrationen im Bergbau vorherzusagen <span class="citation" data-cites="Forr08a">(<a href="references.html#ref-Forr08a" role="doc-biblioref">Forrester, Sóbester, und Keane 2008</a>)</span>. Seine Anwendung auf deterministische Computerexperimente wurde von <span class="citation" data-cites="Sack89a">Sacks u.&nbsp;a. (<a href="references.html#ref-Sack89a" role="doc-biblioref">1989</a>)</span> vorangetrieben und ist seitdem zu einem Eckpfeiler des Ingenieurdesigns und der Optimierung geworden.</p>
<p>Im Bereich des maschinellen Lernens ist Kriging besser bekannt als <strong>Gauß-Prozess-Regression (GPR)</strong>. Obwohl sich die Terminologie unterscheidet, ist das zugrunde liegende mathematische Gerüst dasselbe. Kriging unterscheidet sich von einfacheren RBF-Modellen durch seine einzigartige Basisfunktion und seine statistische Grundlage, die nicht nur eine Vorhersage, sondern auch ein Maß für die Unsicherheit dieser Vorhersage liefert.</p>
</section>
</section>
<section id="die-kernphilosophie-des-kriging-eine-stochastische-prozessperspektive" class="level3" data-number="59.1.2">
<h3 data-number="59.1.2" class="anchored" data-anchor-id="die-kernphilosophie-des-kriging-eine-stochastische-prozessperspektive"><span class="header-section-number">59.1.2</span> Die Kernphilosophie des Kriging: Eine stochastische Prozessperspektive</h3>
<p>Um das Kriging wirklich zu verstehen, muss man einen konzeptionellen Sprung wagen, der zunächst kontraintuitiv sein kann. Selbst bei der Modellierung eines perfekt deterministischen Computercodes – bei dem dieselbe Eingabe immer genau dieselbe Ausgabe erzeugt – behandelt das Kriging die Ausgabe der Funktion als eine einzelne Realisierung eines <strong>stochastischen (oder zufälligen) Prozesses</strong>.</p>
<p>Das bedeutet nicht, dass wir annehmen, die Funktion sei zufällig. Stattdessen drücken wir unsere Unsicherheit über den Wert der Funktion an nicht beobachteten Stellen aus. Bevor wir Daten haben, könnte der Wert der Funktion an jedem Punkt alles sein. Nachdem wir einige Punkte beobachtet haben, ist unsere Unsicherheit reduziert, aber sie existiert immer noch überall sonst. Das stochastische Prozessgerüst bietet eine formale mathematische Sprache, um diese Unsicherheit zu beschreiben.</p>
<section id="das-prinzip-der-lokalität-und-korrelation" class="level4" data-number="59.1.2.1">
<h4 data-number="59.1.2.1" class="anchored" data-anchor-id="das-prinzip-der-lokalität-und-korrelation"><span class="header-section-number">59.1.2.1</span> Das Prinzip der Lokalität und Korrelation</h4>
<p>Dieser angenommene stochastische Prozess ist nicht völlig unstrukturiert. Er wird von einer <strong>Korrelationsstruktur</strong> bestimmt, die eine grundlegende Annahme über die Welt verkörpert: das Prinzip der Lokalität. Dieses Prinzip besagt, dass Punkte, die im Eingaberaum nahe beieinander liegen, erwartungsgemäß ähnliche Ausgabewerte haben (d.&nbsp;h. sie sind hoch korreliert), während Punkte, die weit voneinander entfernt sind, erwartungsgemäß unähnliche oder unzusammenhängende Ausgabewerte haben (d.&nbsp;h. sie sind unkorreliert). Diese Annahme gilt für die große Mehrheit der physikalischen Phänomene und glatten mathematischen Funktionen, die keine chaotischen, diskontinuierlichen Sprünge aufweisen. Die Korrelation zwischen zwei beliebigen Punkten wird durch eine <strong>Kovarianzfunktion</strong> oder einen <strong>Kernel</strong> quantifiziert, der das Herzstück des Kriging-Modells ist.</p>
</section>
<section id="gauß-prozess-prior" class="level4" data-number="59.1.2.2">
<h4 data-number="59.1.2.2" class="anchored" data-anchor-id="gauß-prozess-prior"><span class="header-section-number">59.1.2.2</span> Gauß-Prozess-Prior</h4>
<p>Speziell nimmt das Kriging an, dass dieser stochastische Prozess ein <strong>Gauß-Prozess</strong> ist. Ein Gauß-Prozess ist eine Sammlung von Zufallsvariablen, von denen jede endliche Anzahl eine gemeinsame multivariate Normalverteilung (MVN) hat. Dies ist eine starke Annahme, da eine multivariate Normalverteilung vollständig durch nur zwei Komponenten definiert ist: einen <strong>Mittelwertvektor (<span class="math inline">\(\vec{\mu}\)</span>)</strong> und eine <strong>Kovarianzmatrix (<span class="math inline">\(\Sigma\)</span>)</strong> <span class="citation" data-cites="Forr08a">(<a href="references.html#ref-Forr08a" role="doc-biblioref">Forrester, Sóbester, und Keane 2008</a>)</span>.</p>
<p>Dies ist als der <strong>Gauß-Prozess-Prior</strong> bekannt. Es ist unsere „vorherige Überzeugung“ über die Natur der Funktion, bevor wir Daten gesehen haben. Wir glauben, dass die Funktionswerte an jedem Satz von Punkten gemeinsam gaußverteilt sein werden, zentriert um einen gewissen Mittelwert, mit einer Kovarianzstruktur, die durch den Abstand zwischen den Punkten diktiert wird. Wenn wir Daten beobachten, verwenden wir Bayes’sche Inferenz, um diese vorherige Überzeugung zu aktualisieren, was zu einem <strong>Gauß-Prozess-Posterior</strong> führt. Dieser Posterior ist ebenfalls ein Gauß-Prozess, aber sein Mittelwert und seine Kovarianz wurden aktualisiert, um mit den beobachteten Daten konsistent zu sein. Der Mittelwert dieses posterioren Prozesses gibt uns die Kriging-Vorhersage, und seine Varianz gibt uns ein Maß für die Unsicherheit über diese Vorhersage. Diese statistische Grundlage ist es, die das Kriging auszeichnet und es ihm ermöglicht, nicht nur zu interpolieren, sondern auch seine eigene Zuverlässigkeit zu quantifizieren.</p>
</section>
</section>
</section>
<section id="die-mathematische-architektur-eines-kriging-modells" class="level2" data-number="59.2">
<h2 data-number="59.2" class="anchored" data-anchor-id="die-mathematische-architektur-eines-kriging-modells"><span class="header-section-number">59.2</span> Die mathematische Architektur eines Kriging-Modells</h2>
<p>Um vom konzeptionellen Ansatz des Kriging zur praktischen Umsetzung zu gelangen, ist es unerlässlich, seine mathematischen Komponenten zu verstehen. Dieser Abschnitt analysiert die Architektur des Modells und verbindet konsequent die abstrakte mathematische Notation aus Referenztexten mit den konkreten Variablen, die im bereitgestellten Python-Code verwendet werden.</p>
<section id="glossar-der-kriging-notation" class="level3" data-number="59.2.1">
<h3 data-number="59.2.1" class="anchored" data-anchor-id="glossar-der-kriging-notation"><span class="header-section-number">59.2.1</span> Glossar der Kriging-Notation</h3>
<p><a href="#tbl-glossar-de" class="quarto-xref">Tabelle&nbsp;<span>59.1</span></a> dient als Glossar, um die Notation aus <span class="citation" data-cites="Forr08a">(<a href="references.html#ref-Forr08a" role="doc-biblioref">Forrester, Sóbester, und Keane 2008</a>)</span>, dem Kochbuch <span class="citation" data-cites="bart23iArXiv">(<a href="references.html#ref-bart23iArXiv" role="doc-biblioref">Bartz-Beielstein 2023</a>)</span> und dem in diesem Dokument in <a href="#sec-example-de" class="quarto-xref"><span>Kapitel 59.4</span></a> bereitgestellten Python-Code abzugleichen.</p>
<div id="tbl-glossar-de" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-glossar-de-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tabelle&nbsp;59.1: Glossar
</figcaption>
<div aria-describedby="tbl-glossar-de-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Mathematisches Symbol</th>
<th style="text-align: left;">Konzeptionelle Bedeutung</th>
<th style="text-align: left;">Python-Variable</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(n\)</span></td>
<td style="text-align: left;">Anzahl der Trainings-/Stichprobenpunkte</td>
<td style="text-align: left;"><code>n</code> oder <code>X_train.shape</code></td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(k\)</span></td>
<td style="text-align: left;">Anzahl der Eingabedimensionen/Variablen</td>
<td style="text-align: left;"><code>X_train.shape</code></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(m\)</span></td>
<td style="text-align: left;">Anzahl der Punkte für die Vorhersage</td>
<td style="text-align: left;"><code>m</code> oder <code>x_predict.shape</code></td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(X\)</span></td>
<td style="text-align: left;"><span class="math inline">\(n \times k\)</span> Matrix der Trainingspunkt-Standorte</td>
<td style="text-align: left;"><code>X_train</code></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(y\)</span></td>
<td style="text-align: left;"><span class="math inline">\(n \times 1\)</span> Vektor der beobachteten Antworten</td>
<td style="text-align: left;"><code>y_train</code></td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(\vec{x}\)</span></td>
<td style="text-align: left;">Ein neuer Standort für die Vorhersage</td>
<td style="text-align: left;">Eine Zeile in <code>x_predict</code></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(\Psi\)</span> (Psi)</td>
<td style="text-align: left;"><span class="math inline">\(n \times n\)</span> Korrelationsmatrix der Trainingsdaten</td>
<td style="text-align: left;"><code>Psi</code></td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(\vec{\psi}\)</span> (psi)</td>
<td style="text-align: left;"><span class="math inline">\(n \times m\)</span> Vorhersage-Trainings-Korrelationsmatrix</td>
<td style="text-align: left;"><code>psi</code></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(\vec{\theta}\)</span> (theta)</td>
<td style="text-align: left;"><span class="math inline">\(k \times 1\)</span> Vektor der Aktivitäts-/Breiten-Hyperparameter</td>
<td style="text-align: left;"><code>theta</code></td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(\vec{p}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(k \times 1\)</span> Vektor der Glattheits-Hyperparameter</td>
<td style="text-align: left;">Implizit <span class="math inline">\(p=2\)</span> im Code</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(\mu\)</span> (mu)</td>
<td style="text-align: left;">Der globale Mittelwert des stochastischen Prozesses</td>
<td style="text-align: left;"><code>mu_hat</code></td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(\sigma^2\)</span> (sigma-quadrat)</td>
<td style="text-align: left;">Die Varianz des stochastischen Prozesses</td>
<td style="text-align: left;">Im Code nicht explizit berechnet</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(\lambda\)</span> (lambda)</td>
<td style="text-align: left;">Der Regressions-/Nugget-Parameter</td>
<td style="text-align: left;"><code>eps</code></td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(\hat{y}(\vec{x})\)</span></td>
<td style="text-align: left;">Die Kriging-Vorhersage am Punkt <span class="math inline">\(\vec{x}\)</span></td>
<td style="text-align: left;"><code>f_predict</code></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="der-korrelationskernel-quantifizierung-von-beziehungen" class="level3" data-number="59.2.2">
<h3 data-number="59.2.2" class="anchored" data-anchor-id="der-korrelationskernel-quantifizierung-von-beziehungen"><span class="header-section-number">59.2.2</span> Der Korrelationskernel: Quantifizierung von Beziehungen</h3>
<p>Der Kern des Kriging-Modells ist seine spezialisierte Basisfunktion, auch als Kernel oder Kovarianzfunktion bekannt. Diese Funktion definiert die Korrelation zwischen zwei beliebigen Punkten im Designraum. Die gebräuchlichste Form, und die in unseren Referenztexten verwendete, ist der Gauß’sche Kernel.</p>
<p>Die Kriging-Basisfunktion ist definiert als: <span class="math display">\[\psi(\vec{x}^{(i)}, \vec{x}) = \exp\left(-\sum_{j=1}^{k} \theta_j |x_j^{(i)} - x_j|^{p_j}\right)\]</span> Diese Gleichung berechnet die Korrelation zwischen einem bekannten Punkt <span class="math inline">\(\vec{x}^{(i)}\)</span> und jedem anderen Punkt <span class="math inline">\(\vec{x}\)</span>. Sie wird von zwei Schlüsselsätzen von Hyperparametern gesteuert: <span class="math inline">\(\vec{\theta}\)</span> und <span class="math inline">\(\vec{p}\)</span>.</p>
<section id="hyperparameter-vectheta-theta-der-aktivitätsparameter" class="level4" data-number="59.2.2.1">
<h4 data-number="59.2.2.1" class="anchored" data-anchor-id="hyperparameter-vectheta-theta-der-aktivitätsparameter"><span class="header-section-number">59.2.2.1</span> Hyperparameter <span class="math inline">\(\vec{\theta}\)</span> (Theta): Der Aktivitätsparameter</h4>
<p>Der Parametervektor <span class="math inline">\(\vec{\theta} = \{\theta_1, \theta_2,..., \theta_k\}^T\)</span> ist wohl der wichtigste Hyperparameter im Kriging-Modell. Jede Komponente <span class="math inline">\(\theta_j\)</span> steuert, wie schnell die Korrelation mit dem Abstand entlang der <span class="math inline">\(j\)</span>-ten Dimension abfällt. Er wird oft als „Aktivitäts“- oder „Breiten“-Parameter bezeichnet.</p>
<ul>
<li>Ein <strong>großes <span class="math inline">\(\theta_j\)</span></strong> zeigt an, dass die Funktion sehr empfindlich auf Änderungen in der <span class="math inline">\(j\)</span>-ten Variablen reagiert. Die Korrelation wird sehr schnell abfallen, wenn sich die Punkte in dieser Dimension voneinander entfernen, was zu einer „schmalen“ Basisfunktion führt. Dies impliziert, dass die zugrunde liegende Funktion entlang dieser Achse sehr „aktiv“ ist oder sich schnell ändert.</li>
<li>Ein <strong>kleines <span class="math inline">\(\theta_j\)</span></strong> zeigt an, dass die Funktion relativ unempfindlich auf Änderungen in der <span class="math inline">\(j\)</span>-ten Variablen reagiert. Die Korrelation wird langsam abfallen, was zu einer „breiten“ Basisfunktion führt, die ihren Einfluss über einen größeren Bereich ausdehnt.</li>
</ul>
<p>Die Tatsache, dass <span class="math inline">\(\vec{\theta}\)</span> ein Vektor ist – mit einem separaten Wert für jede Eingabedimension – ist ein entscheidendes Merkmal, das dem Kriging immense Leistungsfähigkeit verleiht, insbesondere bei mehrdimensionalen Problemen. Dies ist als <strong>anisotrope Modellierung</strong> bekannt. Indem die Korrelationslänge für jede Variable unterschiedlich sein kann, kann sich das Modell an Funktionen anpassen, die sich entlang verschiedener Achsen unterschiedlich verhalten. Zum Beispiel könnte eine Funktion sehr schnell auf Temperaturänderungen, aber sehr langsam auf Druckänderungen reagieren. Ein anisotropes Kriging-Modell kann dieses Verhalten erfassen, indem es ein großes <span class="math inline">\(\theta\)</span> für die Temperatur und ein kleines <span class="math inline">\(\theta\)</span> für den Druck lernt.</p>
<p>Diese Fähigkeit hat eine tiefgreifende Konsequenz: <strong>automatische Relevanzbestimmung</strong>. Während des Modellanpassungsprozesses (den wir in <a href="#sec-mle" class="quarto-xref"><span>Kapitel 59.2.4</span></a> diskutieren werden) findet der Optimierungsalgorithmus die <span class="math inline">\(\vec{\theta}\)</span>-Werte, die die Daten am besten erklären. Wenn eine bestimmte Eingangsvariable <span class="math inline">\(x_j\)</span> wenig oder keinen Einfluss auf die Ausgabe <span class="math inline">\(y\)</span> hat, wird das Modell einen sehr kleinen Wert für <span class="math inline">\(\theta_j\)</span> lernen. Ein kleines <span class="math inline">\(\theta_j\)</span> macht den Term <span class="math inline">\(\theta_j|x_j^{(i)} - x_j|^{p_j}\)</span> nahe null, was die Korrelation effektiv unempfindlich gegenüber Änderungen in dieser Dimension macht. Daher kann ein Ingenieur nach der Anpassung des Modells den optimierten <span class="math inline">\(\vec{\theta}\)</span>-Vektor inspizieren, um eine Sensitivitätsanalyse durchzuführen. Die Dimensionen mit den größten <span class="math inline">\(\theta_j\)</span>-Werten sind die einflussreichsten Treiber der Systemantwort. Dies verwandelt das Surrogatmodell von einem einfachen Black-Box-Approximator in ein Werkzeug zur Generierung wissenschaftlicher und technischer Erkenntnisse. Der im <a href="https://sequential-parameter-optimization.github.io/Hyperparameter-Tuning-Cookbook/006_num_gp.html#sec-kriging-example-006">Hyperparameter Tuning Cookbook</a> bereitgestellte und in <a href="#sec-example-de" class="quarto-xref"><span>Kapitel 59.4</span></a> besprochene Python-Code, als eindimensionales Beispiel, vereinfacht dies durch die Verwendung eines einzelnen skalaren <code>theta</code>, aber das Verständnis seiner Rolle als Vektor ist entscheidend, um den Nutzen des Kriging in realen Anwendungen zu schätzen <span class="citation" data-cites="bart23icode">(<a href="references.html#ref-bart23icode" role="doc-biblioref">Bartz-Beielstein 2025</a>)</span>.</p>
</section>
<section id="hyperparameter-vecp-der-glattheitsparameter" class="level4" data-number="59.2.2.2">
<h4 data-number="59.2.2.2" class="anchored" data-anchor-id="hyperparameter-vecp-der-glattheitsparameter"><span class="header-section-number">59.2.2.2</span> Hyperparameter <span class="math inline">\(\vec{p}\)</span>: Der Glattheitsparameter</h4>
<p>Der Parametervektor <span class="math inline">\(\vec{p} = \{p_1, p_2,..., p_k\}^T\)</span> steuert die Glattheit der Funktion an den Datenpunkten. Sein Wert ist typischerweise auf das Intervall <span class="math inline">\([1,2]\)</span> beschränkt <span class="citation" data-cites="Forr08a">(<a href="references.html#ref-Forr08a" role="doc-biblioref">Forrester, Sóbester, und Keane 2008</a>)</span>. Die Wahl von <span class="math inline">\(p_j\)</span> hat tiefgreifende Auswirkungen auf die Form der resultierenden Basisfunktion:</p>
<ul>
<li>Wenn <strong><span class="math inline">\(p_j = 2\)</span></strong>, ist die resultierende Funktion unendlich differenzierbar, was bedeutet, dass sie sehr glatt ist. Dies ist im bereitgestellten Python-Code der Fall, was durch die Verwendung der <code>sqeuclidean</code>-Distanzmetrik (quadrierter Abstand entspricht <span class="math inline">\(p=2\)</span>) implizit ist. Die <code>sqeuclidean</code>-Metrik ist auf <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.sqeuclidean.html">https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.sqeuclidean.html</a> beschrieben.</li>
<li>Wenn <strong><span class="math inline">\(p_j = 1\)</span></strong>, ist die resultierende Funktion stetig, aber an den Datenpunkten nicht differenzierbar, was ihr ein „spitzeres“ oder „stacheligeres“ Aussehen verleiht.</li>
</ul>
<p>Die Wahl von <span class="math inline">\(p\)</span> spiegelt eine Annahme über die Natur der zugrunde liegenden Funktion wider. Die meisten physikalischen Prozesse sind glatt, was <span class="math inline">\(p=2\)</span> zu einer gängigen und robusten Wahl macht. Für Funktionen mit bekannten scharfen Merkmalen kann jedoch die Optimierung von <span class="math inline">\(p\)</span> in Richtung 1 eine bessere Anpassung ermöglichen.</p>
</section>
</section>
<section id="aufbau-des-systems-die-korrelationsmatrizen-psi-und-vecpsi" class="level3" data-number="59.2.3">
<h3 data-number="59.2.3" class="anchored" data-anchor-id="aufbau-des-systems-die-korrelationsmatrizen-psi-und-vecpsi"><span class="header-section-number">59.2.3</span> Aufbau des Systems: Die Korrelationsmatrizen <span class="math inline">\(\Psi\)</span> und <span class="math inline">\(\vec{\psi}\)</span></h3>
<p>Mit dem definierten Korrelationskernel können wir nun die Matrizen konstruieren, die den Kern des Kriging-Systems bilden. Diese Matrizen quantifizieren die Beziehungen zwischen allen Punkten in unserem Problem: den bekannten Trainingspunkten und den neuen Vorhersagepunkten.</p>
<section id="die-psi-matrix-psi-korrelation-der-trainingsdaten" class="level4" data-number="59.2.3.1">
<h4 data-number="59.2.3.1" class="anchored" data-anchor-id="die-psi-matrix-psi-korrelation-der-trainingsdaten"><span class="header-section-number">59.2.3.1</span> Die <code>Psi</code>-Matrix (<span class="math inline">\(\Psi\)</span>): Korrelation der Trainingsdaten</h4>
<p>Die Matrix <span class="math inline">\(\Psi\)</span> ist die <span class="math inline">\(n \times n\)</span> Korrelationsmatrix der <span class="math inline">\(n\)</span> Trainingsdaten mit sich selbst. Jedes Element <span class="math inline">\(\Psi_{ij}\)</span> ist die Korrelation zwischen dem Trainingspunkt <span class="math inline">\(\vec{x}^{(i)}\)</span> und dem Trainingspunkt <span class="math inline">\(\vec{x}^{(j)}\)</span>, berechnet mit der Basisfunktion. <span class="math display">\[
\Psi_{ij} = \text{corr}(\vec{x}^{(i)}, \vec{x}^{(j)}) = \exp\left(-\sum_{l=1}^{k} \theta_l |x_l^{(i)} - x_l^{(j)}|^{p_l}\right).
\]</span> Da die Korrelation eines Punktes mit sich selbst perfekt ist, sind die diagonalen Elemente <span class="math inline">\(\Psi_{ii}\)</span> immer gleich 1. Die Matrix ist auch symmetrisch, da der Abstand von Punkt <span class="math inline">\(A\)</span> zu <span class="math inline">\(B\)</span> derselbe ist wie von <span class="math inline">\(B\)</span> zu <span class="math inline">\(A\)</span>.</p>
<p><strong>Code-Analyse (<code>build_Psi</code>):</strong> Die bereitgestellte Python-Funktion <code>build_Psi</code> implementiert diese Berechnung effizient.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.spatial.distance <span class="im">import</span> pdist, squareform, cdist</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy.linalg <span class="im">import</span> cholesky</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> sqrt, spacing, exp, multiply, eye</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy.linalg <span class="im">import</span> solve</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.spatial.distance <span class="im">import</span> pdist, squareform, cdist</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_Psi(X, theta, eps<span class="op">=</span>sqrt(spacing(<span class="dv">1</span>))):</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    D <span class="op">=</span> squareform(pdist(X, metric<span class="op">=</span><span class="st">'sqeuclidean'</span>, out<span class="op">=</span><span class="va">None</span>, w<span class="op">=</span>theta))</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    Psi <span class="op">=</span> exp(<span class="op">-</span>D)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    Psi <span class="op">+=</span> multiply(eye(X.shape[<span class="dv">0</span>]), eps)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Psi</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ol type="1">
<li><code>D = squareform(pdist(X, metric='sqeuclidean', out=None, w=theta))</code>: Diese Zeile ist der rechnerische Kern. Die Funktion <code>scipy.spatial.distance.pdist</code> berechnet die paarweisen Abstände zwischen allen Zeilen in der Eingabematrix <code>X_train</code>.
<ul>
<li><code>metric='sqeuclidean'</code> gibt an, dass der quadrierte euklidische Abstand, <span class="math inline">\((x_i - x_j)^2\)</span>, verwendet werden soll. Dies setzt implizit den Hyperparameter <span class="math inline">\(p=2\)</span>.</li>
<li><code>w=theta</code> wendet den Aktivitätsparameter als Gewicht auf den quadrierten Abstand jeder Dimension an und berechnet <span class="math inline">\(\theta_j(x_{ij} - x_{kj})^2\)</span> für jedes Paar von Punkten <span class="math inline">\(i, k\)</span> und jede Dimension <span class="math inline">\(j\)</span>. Für den 1D-Fall im Code ist dies einfach <code>theta * (x_i - x_j)^2</code>.</li>
<li><code>squareform</code> wandelt dann den von <code>pdist</code> zurückgegebenen komprimierten Abstandsvektor in die vollständige, symmetrische <span class="math inline">\(n \times n\)</span> Abstandsmatrix um, die wir <span class="math inline">\(D\)</span> nennen können.</li>
</ul></li>
<li><code>Psi = exp(-D)</code>: Dies führt eine elementweise Potenzierung des Negativen der Abstandsmatrix durch und vervollständigt die Berechnung des Gauß’schen Kernels.</li>
<li><code>Psi += multiply(eye(X.shape), eps)</code>: Diese Zeile addiert eine kleine Konstante <code>eps</code> zur Diagonale der <span class="math inline">\(\Psi\)</span>-Matrix. Dies ist der „Nugget“-Term, eine entscheidende Komponente sowohl für die numerische Stabilität als auch für die Rauschmodellierung, die in <a href="#sec-numerical-best-practices" class="quarto-xref"><span>Kapitel 59.3.2</span></a> behandelt wird.</li>
</ol>
</section>
<section id="der-psi-vektormatrix-vecpsi-vorhersage-trainings-korrelation" class="level4" data-number="59.2.3.2">
<h4 data-number="59.2.3.2" class="anchored" data-anchor-id="der-psi-vektormatrix-vecpsi-vorhersage-trainings-korrelation"><span class="header-section-number">59.2.3.2</span> Der <code>psi</code>-Vektor/Matrix (<span class="math inline">\(\vec{\psi}\)</span>): Vorhersage-Trainings-Korrelation</h4>
<p>Die Matrix <span class="math inline">\(\vec{\psi}\)</span> ist die <span class="math inline">\(n \times m\)</span> Matrix der Korrelationen zwischen den <span class="math inline">\(n\)</span> bekannten Trainingspunkten und den <span class="math inline">\(m\)</span> neuen Punkten, an denen wir eine Vorhersage machen möchten. Jedes Element <span class="math inline">\(\psi_{ij}\)</span> ist die Korrelation zwischen dem <span class="math inline">\(i\)</span>-ten Trainingspunkt <span class="math inline">\(\vec{x}^{(i)}\)</span> und dem <span class="math inline">\(j\)</span>-ten Vorhersagepunkt <span class="math inline">\(\vec{x}_{pred}^{(j)}\)</span>. <span class="math display">\[\psi_{ij} = \text{corr}(\vec{x}^{(i)}, \vec{x}_{pred}^{(j)})\]</span></p>
<p><strong>Code-Analyse (<code>build_psi</code>):</strong> Die Funktion <code>build_psi</code> berechnet diese Matrix.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_psi(X_train, x_predict, theta):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    D <span class="op">=</span> cdist(x_predict, X_train, metric<span class="op">=</span><span class="st">'sqeuclidean'</span>, out<span class="op">=</span><span class="va">None</span>, w<span class="op">=</span>theta)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    psi <span class="op">=</span> exp(<span class="op">-</span>D)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> psi.T</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ol type="1">
<li><code>D = cdist(x_predict, X_train, metric='sqeuclidean', out=None, w=theta)</code>: Hier wird <code>scipy.spatial.distance.cdist</code> verwendet, siehe <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cdist.html">https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cdist.html</a>, da wir Abstände zwischen Punkten aus zwei <em>verschiedenen</em> Mengen berechnen: den <span class="math inline">\(m\)</span> Vorhersagepunkten in <code>x_predict</code> und den <span class="math inline">\(n\)</span> Trainingspunkten in <code>X_train</code>. Dies führt zu einer <span class="math inline">\(m \times n\)</span> Matrix gewichteter quadrierter Abstände.</li>
<li><code>psi = exp(-D)</code>: Wie zuvor vervollständigt dies die Kernel-Berechnung.</li>
<li><code>return psi.T</code>: Die resultierende Matrix wird transponiert, um die Größe <span class="math inline">\(n \times m\)</span> zu haben. Dies ist eine Konvention, um mit der in den Vorhersageformeln in Referenztexten wie <span class="citation" data-cites="Forr08a">Forrester, Sóbester, und Keane (<a href="references.html#ref-Forr08a" role="doc-biblioref">2008</a>)</span> dargestellten Matrixalgebra übereinzustimmen.</li>
</ol>
</section>
</section>
<section id="sec-mle" class="level3" data-number="59.2.4">
<h3 data-number="59.2.4" class="anchored" data-anchor-id="sec-mle"><span class="header-section-number">59.2.4</span> Modellkalibrierung durch Maximum-Likelihood-Schätzung (MLE)</h3>
<p>Sobald die Struktur des Modells durch den Kernel definiert ist, müssen wir die optimalen Werte für seine Hyperparameter, nämlich <span class="math inline">\(\vec{\theta}\)</span> und <span class="math inline">\(\vec{p}\)</span>, bestimmen. Der Code in <a href="#sec-example-de" class="quarto-xref"><span>Kapitel 59.4</span></a> umgeht diesen Schritt, indem er <code>theta = 1.0</code> fest codiert, aber in jeder praktischen Anwendung müssen diese Parameter aus den Daten gelernt werden. Eine gebräuchliche Methode hierfür ist die <strong>Maximum-Likelihood-Schätzung (MLE)</strong>.</p>
<p>Die Kernidee der MLE besteht darin, die Frage zu beantworten: „Welche Werte der Hyperparameter machen bei unseren beobachteten Daten diese Daten am wahrscheinlichsten?“ Wir finden die Parameter, die die Wahrscheinlichkeit maximieren, die Daten beobachtet zu haben, die wir tatsächlich gesammelt haben.</p>
<section id="die-likelihood-funktion" class="level4" data-number="59.2.4.1">
<h4 data-number="59.2.4.1" class="anchored" data-anchor-id="die-likelihood-funktion"><span class="header-section-number">59.2.4.1</span> Die Likelihood-Funktion</h4>
<p>Unter der Annahme des Gauß-Prozesses wird die gemeinsame Wahrscheinlichkeit, den Antwortvektor <span class="math inline">\(\vec{y}\)</span> bei gegebenen Parametern zu beobachten, durch die multivariate normale Wahrscheinlichkeitsdichtefunktion beschrieben. Diese Funktion ist unsere Likelihood, <span class="math inline">\(L\)</span>: <span id="eq-likelihood-de"><span class="math display">\[
L(\mu, \sigma^2, \vec{\theta}, \vec{p} | \vec{y}) = \frac{1}{(2\pi\sigma^2)^{n/2}|\Psi|^{1/2}} \exp\left[ - \frac{(\vec{y} - \vec{1}\mu)^T \vec{\Psi}^{-1}(\vec{y} - \vec{1}\mu) }{2 \sigma^2}\right].
\tag{59.1}\]</span></span> Hier sind <span class="math inline">\(\mu\)</span> und <span class="math inline">\(\sigma^2\)</span> der globale Mittelwert und die Varianz des Prozesses, und <span class="math inline">\(\Psi\)</span> ist die Korrelationsmatrix, die implizit von <span class="math inline">\(\vec{\theta}\)</span> und <span class="math inline">\(\vec{p}\)</span> abhängt. Beachten Sie, dass <span class="math inline">\(|\Psi|\)</span> die Determinante (also ein reellwertiger Skalar) der Korrelationsmatrix ist.</p>
</section>
<section id="die-konzentrierte-log-likelihood" class="level4" data-number="59.2.4.2">
<h4 data-number="59.2.4.2" class="anchored" data-anchor-id="die-konzentrierte-log-likelihood"><span class="header-section-number">59.2.4.2</span> Die konzentrierte Log-Likelihood</h4>
<p>Die direkte Maximierung der Likelihood-Funktion (<a href="#eq-likelihood-de" class="quarto-xref">Gleichung&nbsp;<span>59.1</span></a>) ist schwierig. Aus Gründen der rechnerischen Stabilität und mathematischen Bequemlichkeit arbeiten wir stattdessen mit ihrem natürlichen Logarithmus, der Log-Likelihood (siehe Gleichung (2.29) in <span class="citation" data-cites="Forr08a">Forrester, Sóbester, und Keane (<a href="references.html#ref-Forr08a" role="doc-biblioref">2008</a>)</span>): <span id="eq-log-likelihood-de"><span class="math display">\[
\ln(L) = -\frac{n}{2}\ln(2\pi) - \frac{n}{2}\ln(\sigma^2) - \frac{1}{2}\ln|\Psi| - \frac{(\vec{y} - \vec{1}\mu)^T \Psi^{-1}(\vec{y} - \vec{1}\mu)}{2\sigma^2}.
\tag{59.2}\]</span></span></p>
<p>Eine wesentliche Vereinfachung ergibt sich, da wir für jedes gegebene <span class="math inline">\(\vec{\theta}\)</span> und <span class="math inline">\(\vec{p}\)</span> (und damit ein festes <span class="math inline">\(\Psi\)</span>) die optimalen Werte für <span class="math inline">\(\mu\)</span> und <span class="math inline">\(\sigma^2\)</span> analytisch finden können, indem wir Ableitungen bilden und sie auf null setzen. Die MLE für den Mittelwert ist (siehe Gleichung (2.30) in <span class="citation" data-cites="Forr08a">Forrester, Sóbester, und Keane (<a href="references.html#ref-Forr08a" role="doc-biblioref">2008</a>)</span>): <span id="eq-mu-hat-de"><span class="math display">\[
\hat{\mu} = \frac{\mathbf{1}^T \Psi^{-1} \vec{y}}{\mathbf{1}^T \Psi^{-1} \mathbf{1}}.
\tag{59.3}\]</span></span> Die Berechnung in <a href="#eq-mu-hat-de" class="quarto-xref">Gleichung&nbsp;<span>59.3</span></a> kann als Berechung eines verallgemeinerten gewichteten Durchschnitts der beobachteten Antworten interpretiert werden, wobei die Gewichtung die Korrelationsstruktur berücksichtigt.</p>
<p>Ein ähnlicher Ausdruck existiert für die optimale Varianz, <span class="math inline">\(\hat{\sigma}^2\)</span> (siehe Gleichung (2.31) in <span class="citation" data-cites="Forr08a">Forrester, Sóbester, und Keane (<a href="references.html#ref-Forr08a" role="doc-biblioref">2008</a>)</span>): <span class="math display">\[
\hat{\sigma}^2 = \frac{(\vec{y} - \mathbf{1}\hat{\mu})^T \Psi^{-1} (\vec{y} - \mathbf{1}\hat{\mu})}{n}.
\]</span></p>
<p>Indem wir diese analytischen Ausdrücke für <span class="math inline">\(\hat{\mu}\)</span> und <span class="math inline">\(\hat{\sigma}^2\)</span> wieder in die Log-Likelihood-Funktion (<a href="#eq-log-likelihood-de" class="quarto-xref">Gleichung&nbsp;<span>59.2</span></a>) einsetzen, erhalten wir die <strong>konzentrierte Log-Likelihood-Funktion</strong> (siehe Gleichung (2.32) in <span class="citation" data-cites="Forr08a">Forrester, Sóbester, und Keane (<a href="references.html#ref-Forr08a" role="doc-biblioref">2008</a>)</span>): <span class="math display">\[
\ln(L) \approx -\frac{n}{2}\ln(\hat{\sigma}^2) - \frac{1}{2}\ln|\Psi|.
\]</span> Diese vereinfachte Funktion hängt nun nur noch von den Hyperparametern <span class="math inline">\(\vec{\theta}\)</span> und <span class="math inline">\(\vec{p}\)</span> ab, die in <span class="math inline">\(\Psi\)</span> und <span class="math inline">\(\hat{\sigma}^2\)</span> eingebettet sind.</p>
</section>
<section id="numerische-optimierung" class="level4" data-number="59.2.4.3">
<h4 data-number="59.2.4.3" class="anchored" data-anchor-id="numerische-optimierung"><span class="header-section-number">59.2.4.3</span> Numerische Optimierung</h4>
<p>Wir können die optimalen <span class="math inline">\(\vec{\theta}\)</span> und <span class="math inline">\(\vec{p}\)</span> nicht analytisch bestimmen. Die konzentrierte Log-Likelihood ist jedoch eine skalare Funktion, die relativ schnell zu berechnen ist. Wir können daher einen numerischen Optimierungsalgorithmus – wie einen genetischen Algorithmus, Nelder-Mead oder Differential Evolution – verwenden, um den Hyperparameterraum zu durchsuchen und die Werte von <span class="math inline">\(\vec{\theta}\)</span> und <span class="math inline">\(\vec{p}\)</span> zu finden, die diese Funktion maximieren. Dieser Suchprozess ist die „Trainings“- oder „Anpassungs“-Phase beim Aufbau eines Kriging-Modells. Sobald die optimalen Hyperparameter gefunden sind, ist das Modell vollständig kalibriert und bereit, Vorhersagen zu treffen.</p>
</section>
</section>
</section>
<section id="implementierung-und-vorhersage" class="level2" data-number="59.3">
<h2 data-number="59.3" class="anchored" data-anchor-id="implementierung-und-vorhersage"><span class="header-section-number">59.3</span> Implementierung und Vorhersage</h2>
<p>Nachdem der theoretische und mathematische Rahmen geschaffen wurde, konzentriert sich dieser Teil auf die praktische Anwendung des Kriging-Modells: wie man es zur Erstellung von Vorhersagen verwendet und welche wesentlichen numerischen Techniken sicherstellen, dass der Prozess sowohl effizient als auch robust ist.</p>
<section id="der-kriging-prädiktor-generierung-neuer-werte" class="level3" data-number="59.3.1">
<h3 data-number="59.3.1" class="anchored" data-anchor-id="der-kriging-prädiktor-generierung-neuer-werte"><span class="header-section-number">59.3.1</span> Der Kriging-Prädiktor: Generierung neuer Werte</h3>
<p>Das ultimative Ziel beim Aufbau eines Kriging-Modells ist die Vorhersage des Funktionswerts an neuen, unbeobachteten Punkten. Die hierfür verwendete Formel ist als <strong>Bester Linearer Unverzerrter Prädiktor (BLUP)</strong> bekannt. Sie liefert den Mittelwert des posterioren Gauß-Prozesses am Vorhersageort, was unsere beste Schätzung des Funktionswerts ist.</p>
<p>Die Vorhersageformel lautet (siehe Gleichung (2.40) in <span class="citation" data-cites="Forr08a">Forrester, Sóbester, und Keane (<a href="references.html#ref-Forr08a" role="doc-biblioref">2008</a>)</span>): <span id="eq-blup-de"><span class="math display">\[
\hat{y}(\vec{x}) = \hat{\mu} + \vec{\psi}^T \Psi^{-1} (\vec{y} - \mathbf{1}\hat{\mu}),
\tag{59.4}\]</span></span> wobei <span class="math inline">\(\hat{y}(\vec{x})\)</span> die Vorhersage an einem neuen Punkt <span class="math inline">\(\vec{x}\)</span> ist und alle anderen Terme wie im Glossar definiert sind.Im Folgenden beschreiben wir die einzelnen Komponenten dieser Gleichung und ihre Bedeutung:</p>
<ol type="1">
<li><strong><span class="math inline">\(\hat{\mu}\)</span></strong>: Die Vorhersage beginnt mit dem geschätzten globalen Mittelwert des Prozesses. Dies ist unsere Basisvermutung, bevor wir den Einfluss der lokalen Datenpunkte berücksichtigen.</li>
<li><strong><span class="math inline">\((\vec{y} - \mathbf{1}\hat{\mu})\)</span></strong>: Dies ist der Vektor der Residuen. Er stellt die Differenz zwischen jedem beobachteten Datenpunkt und dem globalen Mittelwert dar. Dieser Vektor erfasst die spezifischen, lokalen Informationen, die unsere Trainingsdaten liefern.</li>
<li><strong><span class="math inline">\(\Psi^{-1} (\vec{y} - \mathbf{1}\hat{\mu})\)</span></strong>: Dieser Term kann als ein Vektor von Gewichten betrachtet werden, nennen wir ihn <span class="math inline">\(\vec{w}\)</span>. Indem wir die Residuen mit der Inversen der Korrelationsmatrix multiplizieren, berechnen wir einen Satz von Gewichten, der die Interkorrelationen zwischen den Trainingspunkten berücksichtigt. Dieser Schritt sagt im Wesentlichen: „Wie viel sollte jedes Residuum beitragen, wenn man bedenkt, dass die Datenpunkte selbst nicht unabhängig sind?“</li>
<li><strong><span class="math inline">\(\vec{\psi}^T \vec{w}\)</span></strong>: Die endgültige Vorhersage wird durch eine gewichtete Summe dieser berechneten Gewichte angepasst. Die Gewichte für diese Summe sind die Korrelationen (<span class="math inline">\(\vec{\psi}\)</span>) zwischen dem neuen Vorhersagepunkt <span class="math inline">\(\vec{x}\)</span> und jedem der Trainingspunkte. Im Wesentlichen besagt die Formel: „Beginne mit dem globalen Mittelwert und füge dann eine Korrektur basierend auf den beobachteten Residuen hinzu. Der Einfluss jedes Residuums wird durch die Korrelation des neuen Punktes mit dem entsprechenden Trainingspunkt bestimmt.“</li>
</ol>
<p><strong>Code-Analyse (<code>mu_hat</code> und <code>f_predict</code>):</strong> Der bereitgestellte Python-Code implementiert diesen Vorhersageprozess direkt.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>Psi <span class="op">=</span> build_Psi(X, theta)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>U <span class="op">=</span> cholesky(Psi).T</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>one <span class="op">=</span> np.ones(n).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>mu_hat <span class="op">=</span> (one.T <span class="op">@</span> solve(U, solve(U.T, y_train))) <span class="op">/</span> (one.T <span class="op">@</span> solve(U, solve(U.T, one)))</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>f_predict <span class="op">=</span> mu_hat <span class="op">*</span> np.ones(m).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>) <span class="op">+</span> psi.T <span class="op">@</span> solve(U, solve(U.T, y_train <span class="op">-</span> one <span class="op">*</span> mu_hat))</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li><code>mu_hat = (one.T @ solve(U, solve(U.T, y_train))) / (one.T @ solve(U, solve(U.T, one)))</code>: Dies ist eine direkte und numerisch stabile Implementierung der Formel für <span class="math inline">\(\hat{\mu}\)</span>, siehe <a href="#eq-mu-hat-de" class="quarto-xref">Gleichung&nbsp;<span>59.3</span></a>. Anstatt <code>Psi_inv</code> explizit zu berechnen, wird der auf Cholesky basierende Löser verwendet, der im nächsten Abschnitt detailliert wird. Der Ausdruck <code>solve(U, solve(U.T, y_train))</code> ist äquivalent zu <code>Psi_inv @ y_train</code>.</li>
<li><code>f_predict = mu_hat *... + psi.T @ solve(U, solve(U.T, y_train - one * mu_hat))</code>: Diese Zeile ist eine direkte Übersetzung der BLUP-Formel aus <a href="#eq-blup-de" class="quarto-xref">Gleichung&nbsp;<span>59.4</span></a>. Sie berechnet die Residuen <code>y_train - one * mu_hat</code>, multipliziert sie mit <code>Psi_inv</code> unter Verwendung des Cholesky-Lösers und berechnet dann das Skalarprodukt mit <code>psi.T</code>, bevor das Ergebnis zum Basiswert <code>mu_hat</code> addiert wird.</li>
</ul>
</section>
<section id="sec-numerical-best-practices" class="level3" data-number="59.3.2">
<h3 data-number="59.3.2" class="anchored" data-anchor-id="sec-numerical-best-practices"><span class="header-section-number">59.3.2</span> Numerische Best Practices und der Nugget-Effekt</h3>
<p>Eine direkte Implementierung der Kriging-Gleichungen unter Verwendung der Standard-Matrixinversion kann sowohl langsam als auch numerisch anfällig sein. Professionelle Implementierungen stützen sich auf spezifische numerische Techniken, um Effizienz und Robustheit zu gewährleisten.</p>
<section id="effiziente-inversion-mit-cholesky-zerlegung" class="level4" data-number="59.3.2.1">
<h4 data-number="59.3.2.1" class="anchored" data-anchor-id="effiziente-inversion-mit-cholesky-zerlegung"><span class="header-section-number">59.3.2.1</span> Effiziente Inversion mit Cholesky-Zerlegung</h4>
<p>Die Berechnung der Matrixinversen <span class="math inline">\(\Psi^{-1}\)</span> ist der rechenintensivste Schritt sowohl im MLE-Prozess als auch bei der endgültigen Vorhersage. Eine direkte Inversion hat eine Rechenkomplexität von etwa <span class="math inline">\(O(n^3)\)</span>. Wenn die Matrix schlecht konditioniert ist (fast singulär), kann die direkte Inversion außerdem zu großen numerischen Fehlern führen.</p>
<p>Ein überlegener Ansatz ist die Verwendung der <strong>Cholesky-Zerlegung</strong>. Diese Methode gilt für symmetrische, positiv definite Matrizen wie <span class="math inline">\(\Psi\)</span>. Sie zerlegt <span class="math inline">\(\Psi\)</span> in das Produkt einer unteren Dreiecksmatrix <span class="math inline">\(L\)</span> und ihrer Transponierten <span class="math inline">\(L^T\)</span> (oder einer oberen Dreiecksmatrix <span class="math inline">\(U\)</span> und ihrer Transponierten <span class="math inline">\(U^T\)</span>), sodass <span class="math inline">\(\Psi = LL^T\)</span>. Diese Zerlegung ist schneller als die Inversion, mit einer Komplexität von ungefähr <span class="math inline">\(O(n^3/3)\)</span> <span class="citation" data-cites="Forr08a">(<a href="references.html#ref-Forr08a" role="doc-biblioref">Forrester, Sóbester, und Keane 2008</a>)</span>.</p>
<p>Sobald <span class="math inline">\(\Psi\)</span> zerlegt ist, wird das Lösen eines linearen Systems wie <span class="math inline">\(\Psi \vec{w} = \vec{b}\)</span> zu einem zweistufigen Prozess der Lösung zweier viel einfacherer Dreieckssysteme, ein Verfahren, das als Vorwärts- und Rückwärtssubstitution bekannt ist:</p>
<ol type="1">
<li>Löse <span class="math inline">\(L\vec{v} = \vec{b}\)</span> nach <span class="math inline">\(\vec{v}\)</span>.</li>
<li>Löse <span class="math inline">\(L^T\vec{w} = \vec{v}\)</span> nach <span class="math inline">\(\vec{w}\)</span>.</li>
</ol>
<p>Genau das macht der Python-Code. Die Zeile <code>U = cholesky(Psi).T</code> führt die Zerlegung durch (NumPys <code>cholesky</code> gibt den unteren Dreiecksfaktor <span class="math inline">\(L\)</span> zurück, also wird er transponiert, um den oberen Dreiecksfaktor <span class="math inline">\(U\)</span> zu erhalten). Anschließend implementieren Ausdrücke wie <code>solve(U, solve(U.T,...))</code> die effiziente zweistufige Lösung, ohne jemals die vollständige Inverse von <span class="math inline">\(\Psi\)</span> zu bilden.</p>
</section>
<section id="der-nugget-von-numerischer-stabilität-zur-rauschmodellierung" class="level4" data-number="59.3.2.2">
<h4 data-number="59.3.2.2" class="anchored" data-anchor-id="der-nugget-von-numerischer-stabilität-zur-rauschmodellierung"><span class="header-section-number">59.3.2.2</span> Der Nugget: Von numerischer Stabilität zur Rauschmodellierung</h4>
<p>Die Cholesky-Zerlegung funktioniert nur, wenn die Matrix <span class="math inline">\(\Psi\)</span> streng positiv definit ist. Ein Problem tritt auf, wenn zwei Trainingspunkte <span class="math inline">\(\vec{x}^{(i)}\)</span> und <span class="math inline">\(\vec{x}^{(j)}\)</span> sehr nahe beieinander liegen. In diesem Fall wird ihre Korrelation nahe 1 sein, was die entsprechenden Zeilen und Spalten in <span class="math inline">\(\Psi\)</span> nahezu identisch macht. Dies führt dazu, dass die Matrix schlecht konditioniert oder fast singulär wird, was zum Scheitern der Cholesky-Zerlegung führen kann.</p>
<p>Dieses Problem wird gelöst, indem ein kleiner positiver Wert zur Diagonale der Korrelationsmatrix addiert wird: <span class="math inline">\(\Psi_{new} = \Psi + \lambda I\)</span>, wobei <span class="math inline">\(I\)</span> die Identitätsmatrix ist. Diese kleine Addition, oft als <strong>Nugget</strong> bezeichnet, stellt sicher, dass die Matrix gut konditioniert und invertierbar bleibt. Im bereitgestellten Code dient die Variable <code>eps</code> diesem Zweck.</p>
<p>Obwohl es als numerischer „Hack“ beginnen mag, hat dieser Nugget-Term eine tiefgreifende und starke statistische Interpretation: Er modelliert Rauschen in den Daten. Dies führt zu zwei unterschiedlichen Arten von Kriging-Modellen:</p>
<ol type="1">
<li><strong>Interpolierendes Kriging (<span class="math inline">\(\lambda \approx 0\)</span>):</strong> Wenn der Nugget null oder sehr klein ist (wie <code>eps</code> im Code), wird das Modell gezwungen, exakt durch jeden Trainingsdatenpunkt zu verlaufen. Dies ist für deterministische Computerexperimente geeignet, bei denen die Ausgabe rauschfrei ist.</li>
<li><strong>Regressives Kriging (<span class="math inline">\(\lambda &gt; 0\)</span>):</strong> Wenn bekannt ist, dass die Daten verrauscht sind (z. B. aus physikalischen Experimenten oder stochastischen Simulationen), würde das Erzwingen der Interpolation jedes Punktes dazu führen, dass das Modell das Rauschen anpasst, was zu einer übermäßig komplexen und „zappeligen“ Oberfläche führt, die schlecht generalisiert. Durch Hinzufügen eines größeren Nugget-Terms <span class="math inline">\(\lambda\)</span> zur Diagonale teilen wir dem Modell explizit mit, dass es Varianz (Rauschen) in den Beobachtungen gibt. Das Modell ist nicht mehr verpflichtet, exakt durch die Datenpunkte zu verlaufen. Stattdessen wird es eine glattere Regressionskurve erstellen, die den zugrunde liegenden Trend erfasst und gleichzeitig das Rauschen herausfiltert. Die Größe von <span class="math inline">\(\lambda\)</span> kann als weiterer zu optimierender Hyperparameter behandelt werden, der die Varianz des Rauschens darstellt.</li>
</ol>
<p>Dieselbe mathematische Operation – das Hinzufügen eines Wertes zur Diagonale von <span class="math inline">\(\Psi\)</span> – dient somit einem doppelten Zweck. Ein winziges, festes <code>eps</code> ist eine pragmatische Lösung für die numerische Stabilität. Ein größeres, potenziell optimiertes <span class="math inline">\(\lambda\)</span> ist ein formaler statistischer Parameter, der das Verhalten des Modells grundlegend von einem exakten Interpolator zu einem rauschfilternden Regressor ändert.</p>
</section>
</section>
</section>
<section id="sec-example-de" class="level2" data-number="59.4">
<h2 data-number="59.4" class="anchored" data-anchor-id="sec-example-de"><span class="header-section-number">59.4</span> Eine vollständige exemplarische Vorgehensweise: Kriging der Sinusfunktion</h2>
<p>Dieser letzte Teil fasst die gesamte vorangegangene Theorie zusammen, indem er sie auf das bereitgestellte Python-Codebeispiel aus dem <a href="https://sequential-parameter-optimization.github.io/Hyperparameter-Tuning-Cookbook/006_num_gp.html#sec-kriging-example-006">Hyperparameter Tuning Cookbook</a> anwendet. Wir werden das Skript Schritt für Schritt durchgehen und die Eingaben, Prozesse und Ausgaben in jeder Phase interpretieren, um eine konkrete Veranschaulichung des Kriging in Aktion zu geben.</p>
<section id="schritt-für-schritt-codeausführung-und-interpretation" class="level3" data-number="59.4.1">
<h3 data-number="59.4.1" class="anchored" data-anchor-id="schritt-für-schritt-codeausführung-und-interpretation"><span class="header-section-number">59.4.1</span> Schritt-für-Schritt-Codeausführung und Interpretation</h3>
<p>Das Beispiel zielt darauf ab, die Funktion <span class="math inline">\(y = \sin(x)\)</span> unter Verwendung einer kleinen Anzahl von Stichprobenpunkten zu modellieren. Dies ist ein klassisches „Spielzeugproblem“, das nützlich ist, um zu visualisieren, wie sich das Modell verhält.</p>
<section id="schritt-1-datengenerierung" class="level4" data-number="59.4.1.1">
<h4 data-number="59.4.1.1" class="anchored" data-anchor-id="schritt-1-datengenerierung"><span class="header-section-number">59.4.1.1</span> Schritt 1: Datengenerierung</h4>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">2</span> <span class="op">*</span> np.pi, n, endpoint<span class="op">=</span><span class="va">False</span>).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> np.sin(X_train)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Hier generiert das Skript die Trainingsdaten.</p>
<ul>
<li><code>n = 8</code>: Wir entscheiden uns, die Funktion an acht verschiedenen Stellen abzutasten.</li>
<li><code>X_train</code>: Dies erstellt ein Array von acht gleichmäßig verteilten Punkten im Intervall [0, <span class="math inline">\(2\pi\)</span>], die als Trainingspunkte dienen.</li>
<li><code>y_train = np.sin(X_train)</code>: Dies berechnet die Sinuswerte an den Trainingspunkten. Das Ergebnis ist ein <span class="math inline">\(8 \times 1\)</span> Vektor, der die beobachteten Antworten darstellt.</li>
</ul>
</section>
<section id="schritt-2-definition-der-korrelationsmatrix-psi" class="level4" data-number="59.4.1.2">
<h4 data-number="59.4.1.2" class="anchored" data-anchor-id="schritt-2-definition-der-korrelationsmatrix-psi"><span class="header-section-number">59.4.1.2</span> Schritt 2: Definition der Korrelationsmatrix (<span class="math inline">\(\Psi\)</span>)</h4>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>theta <span class="op">=</span> np.array([<span class="fl">1.0</span>])</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>Psi <span class="op">=</span> build_Psi(X_train, theta)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Dieser Schritt berechnet die <span class="math inline">\(8 \times 8\)</span> Korrelationsmatrix <span class="math inline">\(\Psi\)</span> für die Trainingsdaten.</p>
<ul>
<li><code>theta = np.array([1.0])</code>: Der Aktivitätshyperparameter <span class="math inline">\(\theta\)</span> wird auf 1.0 gesetzt. In einer realen Anwendung würde dieser Wert durch MLE gefunden, aber hier wird er zur Vereinfachung festgesetzt.</li>
<li><code>Psi = build_Psi(X_train, theta)</code>: Die Funktion <code>build_Psi</code> wird aufgerufen. Sie berechnet den gewichteten quadrierten Abstand zwischen jedem Paar von Punkten in <code>X_train</code> und wendet dann den exponentiellen Kernel an. Die resultierende <code>Psi</code>-Matrix quantifiziert die angenommene Korrelation zwischen all unseren bekannten Datenpunkten. Die diagonalen Elemente sind 1 (plus ein winziges <code>eps</code>), und die außerdiagonalen Werte nehmen ab, wenn der Abstand zwischen den entsprechenden Punkten zunimmt.</li>
</ul>
</section>
<section id="schritt-3-definition-der-vorhersagepunkte" class="level4" data-number="59.4.1.3">
<h4 data-number="59.4.1.3" class="anchored" data-anchor-id="schritt-3-definition-der-vorhersagepunkte"><span class="header-section-number">59.4.1.3</span> Schritt 3: Definition der Vorhersagepunkte</h4>
<div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>x_predict <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">2</span> <span class="op">*</span> np.pi, m, endpoint<span class="op">=</span><span class="va">True</span>).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Wir definieren nun die Orte, an denen wir neue Vorhersagen machen wollen. Wir erstellen ein dichtes Gitter von <code>m = 100</code> Punkten, das das gesamte Intervall [0, <span class="math inline">\(2\pi\)</span>] abdeckt. Dies sind die Punkte, an denen wir unser Surrogatmodell auswerten werden, um eine glatte Kurve zu erzeugen.</p>
</section>
<section id="schritt-4-berechnung-der-vorhersagekorrelation-vecpsi" class="level4" data-number="59.4.1.4">
<h4 data-number="59.4.1.4" class="anchored" data-anchor-id="schritt-4-berechnung-der-vorhersagekorrelation-vecpsi"><span class="header-section-number">59.4.1.4</span> Schritt 4: Berechnung der Vorhersagekorrelation (<span class="math inline">\(\vec{\psi}\)</span>)</h4>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>psi <span class="op">=</span> build_psi(X_train, x_predict, theta)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Dieser Schritt berechnet die <span class="math inline">\(8 \times 100\)</span> Korrelationsmatrix <span class="math inline">\(\vec{\psi}\)</span>. Die Funktion <code>build_psi</code> berechnet die Korrelation zwischen jedem der acht Trainingspunkte und jedem der 100 Vorhersagepunkte. Jede Spalte der resultierenden <code>psi</code>-Matrix entspricht einem Vorhersagepunkt und enthält seine acht Korrelationswerte mit dem Trainingssatz. Diese Matrix verbindet die neuen, unbekannten Orte mit unserer bestehenden Wissensbasis.</p>
</section>
<section id="schritt-5-berechnung-der-vorhersage" class="level4" data-number="59.4.1.5">
<h4 data-number="59.4.1.5" class="anchored" data-anchor-id="schritt-5-berechnung-der-vorhersage"><span class="header-section-number">59.4.1.5</span> Schritt 5: Berechnung der Vorhersage</h4>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>U <span class="op">=</span> cholesky(Psi).T</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>one <span class="op">=</span> np.ones(n).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>mu_hat <span class="op">=</span> (one.T <span class="op">@</span> solve(U, solve(U.T, y_train))) <span class="op">/</span> (one.T <span class="op">@</span> solve(U, solve(U.T, one)))</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>f_predict <span class="op">=</span> mu_hat <span class="op">*</span> np.ones(m).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>) <span class="op">+</span> psi.T <span class="op">@</span> solve(U, solve(U.T, y_train <span class="op">-</span> one <span class="op">*</span> mu_hat))</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Dies ist der entscheidende Schritt, in dem die tatsächlichen Vorhersagen gemacht werden.</p>
<ol type="1">
<li><code>U = cholesky(Psi).T</code>: Die numerisch entscheidende Cholesky-Zerlegung von <span class="math inline">\(\Psi\)</span> wird durchgeführt.</li>
<li><code>mu_hat =...</code>: Die Maximum-Likelihood-Schätzung für den globalen Mittelwert <span class="math inline">\(\mu\)</span> wird unter Verwendung des numerisch stabilen Cholesky-Lösers berechnet. Für diese spezifischen symmetrischen Daten wird <code>mu_hat</code> nahe null sein.</li>
<li><code>f_predict =...</code>: Die BLUP-Formel wird implementiert. Sie berechnet die Residuen <code>(y_train - one * mu_hat)</code>, findet die gewichteten Residuen unter Verwendung des Cholesky-Lösers (<code>solve(U, solve(U.T,...))</code>) und berechnet dann die endgültige Vorhersage durch eine gewichtete Summe basierend auf den Vorhersagekorrelationen <code>psi.T</code>. Das Ergebnis, <code>f_predict</code>, ist ein <span class="math inline">\(100 \times 1\)</span> Vektor, der die vorhergesagten Sinuswerte an jedem der <code>x_predict</code>-Orte enthält.</li>
</ol>
</section>
<section id="schritt-6-visualisierung" class="level4" data-number="59.4.1.6">
<h4 data-number="59.4.1.6" class="anchored" data-anchor-id="schritt-6-visualisierung"><span class="header-section-number">59.4.1.6</span> Schritt 6: Visualisierung</h4>
<p>Der letzte Codeblock stellt die Ergebnisse grafisch dar.</p>
<ul>
<li><strong>Messungen (Blaue Punkte):</strong> Die ursprünglichen 8 Datenpunkte werden dargestellt.</li>
<li><strong>Wahre Sinusfunktion (Graue gestrichelte Linie):</strong> Die tatsächliche <span class="math inline">\(\sin(x)\)</span>-Funktion wird als Referenz dargestellt.</li>
<li><strong>Kriging-Vorhersage (Orange Linie):</strong> Die vorhergesagten Werte <code>f_predict</code> werden gegen <code>x_predict</code> aufgetragen.</li>
</ul>
<p>Die Grafik zeigt die Schlüsseleigenschaften des Kriging-Modells. Die orangefarbene Linie verläuft <em>exakt</em> durch jeden der blauen Punkte und demonstriert damit ihre <strong>interpolierende</strong> Natur (da <code>eps</code> sehr klein war). Wichtiger noch, zwischen den Stichprobenpunkten liefert die Vorhersage eine glatte und bemerkenswert genaue Annäherung an die wahre zugrunde liegende Sinuskurve, obwohl das Modell in diesen Bereichen keine anderen Informationen über die Funktion hatte als die acht Stichprobenpunkte und die angenommene Korrelationsstruktur.</p>
</section>
</section>
<section id="fazit-und-ausblick" class="level3" data-number="59.4.2">
<h3 data-number="59.4.2" class="anchored" data-anchor-id="fazit-und-ausblick"><span class="header-section-number">59.4.2</span> Fazit und Ausblick</h3>
<p>Wir begannen damit, das Kriging als eine anspruchsvolle Form der Modellierung mit radialen Basisfunktionen einzuordnen und seine Kernphilosophie zu übernehmen, deterministische Funktionen als Realisierungen eines stochastischen Prozesses zu behandeln. Anschließend haben wir seine Architektur zerlegt: den leistungsstarken Korrelationskernel mit seinen Aktivitäts- (<span class="math inline">\(\theta\)</span>) und Glattheits- (<span class="math inline">\(p\)</span>) Hyperparametern, die Konstruktion der Korrelationsmatrizen (<span class="math inline">\(\Psi\)</span> und <span class="math inline">\(\vec{\psi}\)</span>) und den Ansatz der Maximum-Likelihood-Schätzung zur Modellkalibrierung. Schließlich haben wir die numerischen Best Practices wie die Cholesky-Zerlegung untersucht und die doppelte Rolle des Nugget-Terms für die numerische Stabilität und die statistische Rauschmodellierung besprochen. Die schrittweise exemplarische Vorgehensweise des Sinusbeispiels lieferte eine konkrete Demonstration dieser Konzepte und zeigte, wie eine kleine Menge von Datenpunkten verwendet werden kann, um ein genaues, interpolierendes Modell einer unbekannten Funktion zu erzeugen.</p>
<p>Für den angehenden Praktiker ist dies nur der Anfang. Die Welt des Kriging und der Gauß-Prozess-Regression ist reich an fortgeschrittenen Techniken, die auf diesen Grundlagen aufbauen.</p>
<ul>
<li><p><strong>Fehlerschätzungen und sequentielles Design:</strong> Ein wesentliches Merkmal, das im Beispielcode nicht untersucht wurde, ist, dass das Kriging nicht nur eine mittlere Vorhersage, sondern auch eine <strong>Varianz</strong> an jedem Punkt liefert, die die Unsicherheit des Modells quantifiziert. Diese Varianz ist in Regionen weit entfernt von Datenpunkten hoch und in deren Nähe niedrig. Diese Fehlerschätzung ist die Grundlage für <strong>aktives Lernen</strong> oder <strong>sequentielles Design</strong>, bei dem Infill-Kriterien wie die <strong>erwartete Verbesserung (EI)</strong> verwendet werden, um den nächsten zu beprobenden Punkt intelligent auszuwählen, wobei ein Gleichgewicht zwischen der Notwendigkeit, vielversprechende Regionen auszunutzen (niedriger vorhergesagter Wert) und der Notwendigkeit, unsichere Regionen zu erkunden (hohe Varianz), hergestellt wird.</p></li>
<li><p><strong>Gradienten-erweitertes Kriging:</strong> In vielen modernen Simulationsumgebungen ist es möglich, nicht nur den Funktionswert, sondern auch seine Gradienten (Ableitungen) zu geringen zusätzlichen Kosten zu erhalten. Das <strong>Gradienten-erweiterte Kriging</strong> integriert diese Gradienteninformationen in das Modell, was seine Genauigkeit drastisch verbessert und den Aufbau hochpräziser Modelle mit sehr wenigen Stichprobenpunkten ermöglicht.</p></li>
<li><p><strong>Multi-Fidelity-Modellierung (Co-Kriging):</strong> Oft haben Ingenieure Zugang zu mehreren Informationsquellen mit unterschiedlicher Genauigkeit und Kosten – zum Beispiel ein schnelles, aber ungenaues analytisches Modell und eine langsame, aber hochpräzise CFD-Simulation. <strong>Co-Kriging</strong> ist ein Rahmenwerk, das diese unterschiedlichen Datenquellen verschmilzt, indem es die reichlich vorhandenen billigen Daten verwendet, um einen Basistrend zu etablieren, und die spärlichen teuren Daten, um ihn zu korrigieren, was zu einem Modell führt, das genauer ist als eines, das nur aus einer der Datenquellen allein erstellt wurde.</p></li>
</ul>
</section>
</section>
<section id="zusatzmaterialien" class="level2" data-number="59.5">
<h2 data-number="59.5" class="anchored" data-anchor-id="zusatzmaterialien"><span class="header-section-number">59.5</span> Zusatzmaterialien</h2>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Interaktive Webseite
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p>Eine interaktive Webseite zum Thema <strong>Kriging</strong> ist hier zu finden: <a href="https://advm1.gm.fh-koeln.de/~bartz/bart21i/de_kriging_interactive.html">Kriging Interaktiv</a>.</p></li>
<li><p>Eine interaktive Webseite zum Thema <strong>MLE</strong> ist hier zu finden: <a href="https://advm1.gm.fh-koeln.de/~bartz/bart21i/de_mle_interactive.html">MLE Interaktiv</a>.</p></li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Audiomaterial
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Ein Audio zum Thema *Kriging** ist hier zu finden: <a href="https://advm1.gm.fh-koeln.de/~bartz/bart21i/audio/numerischeMatheKriging.m4a">Cholesky Audio</a>.</li>
<li>Ein Audio zum Thema *Stochastische Prozesses** ist hier zu finden: <a href="https://advm1.gm.fh-koeln.de/~bartz/bart21i/audio/stochastischeProzesse.m4a">Cholesky Audio</a>.</li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Jupyter-Notebook
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Das Jupyter-Notebook für dieses Lernmodul ist auf GitHub im <a href="https://github.com/sequential-parameter-optimization/Hyperparameter-Tuning-Cookbook/blob/main/de_kriging.ipynb">Hyperparameter-Tuning-Cookbook Repository</a> verfügbar.</li>
</ul>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-bart23iArXiv" class="csl-entry" role="listitem">
Bartz-Beielstein, Thomas. 2023. <span>„<span>Hyperparameter Tuning Cookbook: A guide for scikit-learn, PyTorch, river, and spotpython</span>“</span>. <em>arXiv e-prints</em>, Juli. <a href="https://doi.org/10.48550/arXiv.2307.10262">https://doi.org/10.48550/arXiv.2307.10262</a>.
</div>
<div id="ref-bart23icode" class="csl-entry" role="listitem">
———. 2025. <span>„Kriging (Gaussian Process Regression): The Complete Python Code for the Example“</span>. <a href="https://sequential-parameter-optimization.github.io/Hyperparameter-Tuning-Cookbook/006_num_gp.html">https://sequential-parameter-optimization.github.io/Hyperparameter-Tuning-Cookbook/006_num_gp.html</a>.
</div>
<div id="ref-Forr08a" class="csl-entry" role="listitem">
Forrester, Alexander, András Sóbester, und Andy Keane. 2008. <em><span>Engineering Design via Surrogate Modelling</span></em>. Wiley.
</div>
<div id="ref-Sack89a" class="csl-entry" role="listitem">
Sacks, J, W J Welch, T J Mitchell, und H P Wynn. 1989. <span>„<span>Design and analysis of computer experiments</span>“</span>. <em>Statistical Science</em> 4 (4): 409–35.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Kopiert");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Kopiert");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./de_sampling.html" class="pagination-link" aria-label="Lernmodul: Versuchspläne (Sampling-Pläne) für Computerexperimente">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">58</span>&nbsp; <span class="chapter-title">Lernmodul: Versuchspläne (Sampling-Pläne) für Computerexperimente</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./de_cholesky.html" class="pagination-link" aria-label="Lernmodul: Die Cholesky-Zerlegung">
        <span class="nav-page-text"><span class="chapter-number">60</span>&nbsp; <span class="chapter-title">Lernmodul: Die Cholesky-Zerlegung</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Copyright 2025, T. Bartz-Beielstein</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://sequential-parameter-optimization.github.io/Hyperparameter-Tuning-Cookbook/">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://x.com/bartzbeielstein">
      <i class="bi bi-twitter" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>