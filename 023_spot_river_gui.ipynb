{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "execute:\n",
        "  cache: false\n",
        "  eval: true\n",
        "  echo: true\n",
        "  warning: false\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# The spotriver GUI\n",
        "\n",
        "## Hyperparameter Tuning\n",
        "\n",
        "Calls `run_spot_river_experiment` from \n",
        "`spotRiver.tuner.run.py` with the following parameters:\n",
        "\n",
        "* MAX_TIME,\n",
        "* INIT_SIZE\n",
        "* PREFIX\n",
        "* horizon\n",
        "* n_total\n",
        "* perc_train\n",
        "* oml_grace_period\n",
        "* data_set\n",
        "* prepmodel\n",
        "* coremodel\n",
        "\n",
        "### The run_spot_river_experiment Method\n",
        "\n",
        "`run_spot_river_experiment` calls the tuner spot after processing the following steps:\n",
        "\n",
        "1. Generate an experiment name.\n",
        "2. Initialize the `fun_control` dictionary.\n",
        "3. Select the data set based on the `data_set` parameter and generate a data frame.\n",
        "4. Splits the data into training and test sets.\n",
        "5. Sets the oml_grace_period parameter.\n",
        "6. Select the preprocessing model based on the `prepmodel` parameter.\n",
        "7. Sets the weights for the evaluation function and the weight coeffient.\n",
        "8. Loads the coremodel based on the `coremodel` parameter with hyperparameters set to the values specified in the `RiverHyperDict` dictionary.\n",
        "9. Determines the default hyperparameters.\n",
        "10. Selects the evaluation function: `HyperRiver.fun_oml_horizon`.\n",
        "11. Determines hyperparameter types, names, lower and upper bounds for the `spot` tuner.\n",
        "12. Starts tensorboard as a background process.\n",
        "13. Starts the `spot` tuner.\n",
        "\n",
        "When the tuner is finished, the following steps are performed:\n",
        "\n",
        "1. The tensorboard process is terminated.\n",
        "2. The spot_tuner object and the `fun_control` dictionary are returned.\n",
        "\n",
        "After the tuner is finished, the following information is available:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Binary Classification\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load User Specific Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "{'Time': datetime.datetime(2016, 12, 31, 23, 0, tzinfo=datetime.timezone.utc)} 10951.217\n"
          ]
        }
      ],
      "source": [
        "from spotRiver.data.generic import GenericData\n",
        "import importlib.resources as pkg_resources\n",
        "import spotRiver.data as data\n",
        "inp_file = pkg_resources.files(data)\n",
        "csv_path = str(inp_file.resolve())\n",
        "dataset = GenericData(filename=\"UnivariateData.csv\",\n",
        "                    directory=csv_path,\n",
        "                    target=\"Consumption\",\n",
        "                    n_features=1,\n",
        "                    n_samples=None,\n",
        "                    converters={\"Consumption\": float},\n",
        "                    parse_dates={\"Time\": \"%Y-%m-%d %H:%M:%S%z\"})\n",
        "print(dataset.n_samples)\n",
        "for x, y in dataset:\n",
        "    print(x, y)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Time': datetime.datetime(2016, 12, 31, 23, 0, tzinfo=datetime.timezone.utc)} 10951.217\n"
          ]
        }
      ],
      "source": [
        "from spotRiver.data.generic import GenericData\n",
        "csv_path = \"./userData\"\n",
        "dataset = GenericData(filename=\"univariate_data.csv\",\n",
        "                    directory=csv_path,\n",
        "                    target=\"Consumption\",\n",
        "                    n_features=1,\n",
        "                    n_samples=51_706,\n",
        "                    converters={\"Consumption\": float},\n",
        "                    parse_dates={\"Time\": \"%Y-%m-%d %H:%M:%S%z\"})\n",
        "for x, y in dataset:\n",
        "    print(x, y)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "51706"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.n_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
