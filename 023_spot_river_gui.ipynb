{
 "cells": [
  {
   "cell_type": "raw",
   "id": "35c06dd0",
   "metadata": {},
   "source": [
    "---\n",
    "execute:\n",
    "  cache: false\n",
    "  eval: true\n",
    "  echo: true\n",
    "  warning: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2634092",
   "metadata": {},
   "source": [
    "# The spotRiver Hyperparameter Tuning GUI\n",
    "\n",
    "::: {.callout-note}\n",
    "Note: This document refers to `spotRiverGUI` version 0.0.25 which was released on Feb, 17th 2024 on GitHub, see: [https://github.com/sequential-parameter-optimization/spotGUI/tree/main](https://github.com/sequential-parameter-optimization/spotGUI/tree/main). The GUI is under active development and new features will be added soon.\n",
    "::: \n",
    "\n",
    "## Starting the GUI\n",
    "\n",
    "The GUI can be started by executing the `spotRiverGUI.py` file in the `spotGUI/spotRiverGUI` directory.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```{bash}\n",
    ">> python spotRiverGUI.py\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The GUI window will open, as shown in @fig-spotRiverGUI-00.\n",
    "\n",
    "![spotriver GUI](./figures_static/spotRiverGUI-00.png){#fig-spotRiverGUI-00}\n",
    "\n",
    "\n",
    "After the GUI window has opened, the user can select the task. Currently, `Binary Classification` is  available. Further tasks like `Regression` will be available soon.\n",
    "\n",
    "Depending on the task, the user can select the data set, the preprocessing model, the metric, and the online machine learning model.\n",
    "\n",
    "## Binary Classification Options\n",
    "\n",
    "If the `Binary Classification` task is selected, the user can select pre-specified data sets from the `Data` drop-down menu.\n",
    "\n",
    "### River Data Sets {#sec-river-datasets}\n",
    "\n",
    "The following data sets from the `river` package are available (the descriptions are taken from the `river` package):\n",
    "\n",
    "* `Bananas`: An artificial dataset where instances belongs to several clusters with a banana shape.There are two attributes that correspond to the x and y axis, respectively. More: [https://riverml.xyz/dev/api/datasets/Bananas/](https://riverml.xyz/dev/api/datasets/Bananas/).\n",
    "* `CreditCard`: Credit card frauds. The datasets contains transactions made by credit cards in September 2013 by European cardholders. Feature '`Class`' is the response variable and it takes value 1 in case of fraud and 0 otherwise. More: [https://riverml.xyz/dev/api/datasets/CreditCard/](https://riverml.xyz/dev/api/datasets/CreditCard/).\n",
    "* `Elec2`: Electricity prices in New South Wales. This is a binary classification task, where the goal is to predict if the price of electricity will go up or down. This data was collected from the Australian New South Wales Electricity Market. In this market, prices are not fixed and are affected by demand and supply of the market. They are set every five minutes. Electricity transfers to/from the neighboring state of Victoria were done to alleviate fluctuations. More: [https://riverml.xyz/dev/api/datasets/Elec2/](https://riverml.xyz/dev/api/datasets/Elec2/).\n",
    "* `Higgs`: The data has been produced using Monte Carlo simulations. The first 21 features (columns 2-22) are kinematic properties measured by the particle detectors in the accelerator. The last seven features are functions of the first 21 features; these are high-level features derived by physicists to help discriminate between the two classes. More: [https://riverml.xyz/dev/api/datasets/Higgs/](https://riverml.xyz/dev/api/datasets/Higgs/).\n",
    "* `HTTP`: HTTP dataset of the KDD 1999 cup. The goal is to predict whether or not an HTTP connection is anomalous or not. The dataset only contains 2,211 (0.4%) positive labels. More: [https://riverml.xyz/dev/api/datasets/HTTP/](https://riverml.xyz/dev/api/datasets/HTTP/).\n",
    "* `Phishing`: Phishing websites. This dataset contains features from web pages that are classified as phishing or not.[https://riverml.xyz/dev/api/datasets/Phishing/](https://riverml.xyz/dev/api/datasets/Phishing/)\n",
    "\n",
    "### User Data Sets\n",
    "\n",
    "Besides the `river` data sets described in @sec-river-datasets, the user can also select a user-defined data set. Currently, comma-separated values (CSV) files are supported. Further formats will be supported soon. The user-defined CSV data set must be a binary classification task with the target variable in the last column. The first row must contain the column names. If the file is copied to the subdirectory `userData`, the user can select the data set from the `Data` drop-down menu.\n",
    "\n",
    "As an example, we have provided a CSV-version of the `Phishing` data set. The file is located in the `userData` subdirectory and is called `PhishingData.csv`. It contains the following columns:\n",
    "\n",
    "\n",
    "\n",
    "```{csv}\n",
    "empty_server_form_handler,popup_window,https,request_from_other_domain,anchor_from_other_domain,is_popular,long_url,age_of_domain,ip_in_url,is_phishing\n",
    "0.0,0.0,0.0,0.0,0.0,0.5,1.0,1,1,1\n",
    "1.0,0.0,0.5,0.5,0.0,0.5,0.0,1,0,1\n",
    "0.0,0.0,1.0,0.0,0.5,0.5,0.0,1,0,1\n",
    "0.0,0.0,1.0,0.0,0.0,1.0,0.5,0,0,1\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "Based on the required format, we can see that `target_column` is the last column, here: `is_phishing`.\n",
    "\n",
    "### Stream Data Sets\n",
    "\n",
    "Forthcoming versions of the GUI will support stream data sets, e.g, the Friedman data set as described in @bart23c5. The Friedman-Drift data was also used in the hyperparameter tuning study in @bart23c10.\n",
    "\n",
    "### Data Set Options\n",
    "\n",
    "Currently, the user can select the following parameters for the data sets:\n",
    "\n",
    "* `target_column`: The target column.\n",
    "* `n_total`: The total number of instances. Since some data sets are quite large, the user can select a subset of the data set by specifying the `n_total` value.\n",
    "* `test_size`: The size of the test set in percent (0.0-1.0). The training set will be `1 - test_size`.\n",
    "\n",
    "\n",
    "To compare different data scaling methods, the user can select the preprocessing model from the `Preprocessing` drop-down menu.\n",
    "Currently, the following preprocessing models are available:\n",
    "\n",
    "* `StandardScaler`: Standardize features by removing the mean and scaling to unit variance.\n",
    "* `MinMaxScaler`: Scale features to a range.\n",
    "* `None`: No scaling is performed.\n",
    "\n",
    "The `spotRiverGUI` will not provide sophisticated data preprocessing methods. We assume that the data was preprocessed before it is copied into the `userData` subdirectory.\n",
    "\n",
    "\n",
    "## Regression\n",
    "\n",
    "Regression tasks will be supported soon.\n",
    "The same workflow as for the binary classification task will be used, i.e., the user can select the data set, the preprocessing model, the metric, and the online machine learning model.\n",
    "\n",
    "## Experiment Options\n",
    "\n",
    "Currently, the user can select the following options for specifying the experiment duration:\n",
    "\n",
    "* `MAX_TIME`: The maximum time in minutes for the experiment.\n",
    "* `FUN_EVALS`: The number of function evaluations for the experiment. \n",
    "\n",
    "If the `MAX_TIME` is reached or `FUN_EVALS` OML-models are evaluated, the experiment will be stopped.\n",
    "\n",
    "::: {.callout-note}\n",
    "#### Initial design is always evaluated\n",
    "\n",
    "* The initial design will always be evaluated before one of the stopping criteria is reached.\n",
    "* If the initial design is very large or the model evaluations are very time-consuming, the runtime will be larger than the `MAX_TIME` value.\n",
    "\n",
    ":::\n",
    "\n",
    "Based on the `INIT_SIZE`, the number of hyperparameter configurations for the initial design can be specified. The initial design is evaluated before the first surrogate model is build. A detailed description of the initial design and the surrogate model based hyperparameter tuning can be found in @bart23c5 and in @bart21ic3.\n",
    "\n",
    "The `PREFIX` parameter can be used to specify  the experiment name.\n",
    "\n",
    "The `spotPython` hyperparameter tuning program allows the user to specify several options for the hyperparameter tuning process. The `spotRiverGUI` will support more options in future versions. Currently, the user can specify whether the outcome from the experiment is noisy or deterministic. The corresponding parameter is called `NOISE`. The reader is referred to @bart23c10 and to the chapter \"Handling Noise\" ([https://sequential-parameter-optimization.github.io/Hyperparameter-Tuning-Cookbook/013_num_spot_noisy.html](https://sequential-parameter-optimization.github.io/Hyperparameter-Tuning-Cookbook/013_num_spot_noisy.html)) for further information about the `NOISE` parameter.\n",
    "\n",
    "\n",
    "## Evaluation Options\n",
    "\n",
    "The user can select one of the following evaluation metrics for binary classification tasks from the `metric` drop-down menu:\n",
    "\n",
    "* `accuracy_score`\n",
    "* `cohen_kappa_score`\n",
    "* `f1_score`\n",
    "* `hamming_loss`\n",
    "* `hinge_loss`\n",
    "* `jaccard_score`\n",
    "* `matthews_corrcoef`\n",
    "* `precision_score`\n",
    "* `recall_score`\n",
    "* `roc_auc_score`\n",
    "* `zero_one_loss`\n",
    "\n",
    "These metrics are based on the `scikit-learn` module, which  implements several loss, score, and utility functions to measure classification performance, see [https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics). `spotRiverGUI` supports metrics that are computed from the `y_pred` and the `y_true` values. The `y_pred` values are the predicted target values, and the `y_true` values are the true target values. The `y_pred` values are generated by the online machine learning model, and the `y_true` values are the true target values from the data set.\n",
    "\n",
    "::: {.callout-note}\n",
    "#### Evaluation Metrics: Minimization and Maximization\n",
    "\n",
    "* Some metrics are minimized, and some are maximized. The `spotRiverGUI` will support the user in selecting the correct metric based on the task. For example, the `accuracy_score` is maximized, and the `hamming_loss` is minimized. The user can select the metric and `spotRiverGUI` will automatically determine whether the metric is minimized or maximized.\n",
    "\n",
    ":::\n",
    "\n",
    "In addition to the evaluation metric results, `spotRiver` considers the time and memory consumption of the online machine learning model. \n",
    "The `spotRiverGUI` will support the user in selecting the time and memory consumption as additional evaluation metrics. By modifying the weight vector, which is shown in the `weights: y, time, mem` field, the user can specify the importance of the evaluation metrics. For example, the weight vector `1,0,0` specifies that only the `y` metric (e.g., accuracy) is considered. The weight vector `0,1,0` specifies that only the time metric is considered. The weight vector `0,0,1` specifies that only the memory metric is considered. The weight vector `1,1,1` specifies that all metrics are considered. \n",
    "\n",
    "::: {.callout-note}\n",
    "#### The weight vector\n",
    "\n",
    "* The specification of adequate weights is highly problem dependent.\n",
    "* There is no generic setting that fits to all problems.\n",
    "\n",
    ":::\n",
    "\n",
    "As described in @bart23c5, a prediction horizon is used for the comparison of the online-machine learning algorithms.\n",
    "The `horizon` can be specified in the `spotRiverGUI` by the user and is highly problem dependent.\n",
    "\n",
    "The `spotRiverGUI` uses the `eval_oml_horizon` method from the `spotRiver` package, which evaluates the online-machine learning model on a rolling horizon basis. \n",
    "\n",
    "In addition to the `horizon` value, the user can specify the `oml_grace_period` value. During the `oml_grace_period`, the OML-model is trained on the (small) training data set. No predictions are made during this initial training phase, but the memory and computation time are measured. Then, the OML-model is evaluated on the test data set using a given (sklearn) evaluation metric. \n",
    "The default value of the `oml_grace_period` is `horizon`. For convenience, the value `horizon` is also selected when the user specifies the `oml_grace_period` value as `None`.\n",
    "\n",
    "::: {.callout-note}\n",
    "#### The oml_grace_period\n",
    "\n",
    "* If the `oml_grace_period` is set to the size of the training data set, the OML-model is trained on the entire training data set and then evaluated on the test data set using a given (sklearn) evaluation metric.\n",
    "* This setting might be \"unfair\" in some cases, because the OML-model should learn online and not on the entire training data set.\n",
    "* Therefore, a small data set is recommended for the `oml_grace_period` setting and the prediction `horizon` is a recommended value for the `oml_grace_period` setting. The reader is referred to @bart23c5 for further information about the `oml_grace_period` setting.\n",
    "\n",
    ":::\n",
    "\n",
    "## Online Machine Learning Model Options\n",
    "\n",
    "The user can select one of the following online machine learning models from the `coremodel` drop-down menu:\n",
    "\n",
    "* `forest.AMFClassifier`: Aggregated Mondrian Forest classifier for online learning. This implementation is truly online, in the sense that a single pass is performed, and that predictions can be produced anytime. More: [https://riverml.xyz/dev/api/forest/AMFClassifier/](https://riverml.xyz/dev/api/forest/AMFClassifier/).\n",
    "* `tree.ExtremelyFastDecisionTreeClassifier`: Extremely Fast Decision Tree (EFDT) classifier. Also referred to as the Hoeffding AnyTime Tree (HATT) classifier. In practice, despite the name, EFDTs are typically slower than a vanilla Hoeffding Tree to process data. More: [https://riverml.xyz/dev/api/tree/ExtremelyFastDecisionTreeClassifier/](https://riverml.xyz/dev/api/tree/ExtremelyFastDecisionTreeClassifier/).\n",
    "* `tree.HoeffdingTreeClassifier`: Hoeffding Tree or Very Fast Decision Tree classifier. More: [https://riverml.xyz/dev/api/tree/HoeffdingTreeClassifier/](https://riverml.xyz/dev/api/tree/HoeffdingTreeClassifier/).\n",
    "* `tree.HoeffdingAdaptiveTreeClassifier`: Hoeffding Adaptive Tree classifier. More: [https://riverml.xyz/dev/api/tree/HoeffdingAdaptiveTreeClassifier/](https://riverml.xyz/dev/api/tree/HoeffdingAdaptiveTreeClassifier/).\n",
    "* `linear_model.LogisticRegression`: Logistic regression classifier. More: [hhttps://riverml.xyz/dev/api/linear-model/LogisticRegression/](https://riverml.xyz/dev/api/linear-model/LogisticRegression/).\n",
    "\n",
    "The `spotRiverGUI` automatically determines the hyperparameters for the selected online machine learning model and adapts the input fields to the model hyperparameters. The user can modify the hyperparameters in the GUI. @fig-spotRiverGUI-01 shows the `spotRiverGUI` when the `forest.AMFClassifier` is selected and @fig-spotRiverGUI-02 shows the `spotRiverGUI` when the `tree.HoeffdingTreeClassifier` is selected.\n",
    "\n",
    "![`spotRiverGUI` when `forest.AMFClassifier` is selected](./figures_static/spotRiverGUI-01.png){#fig-spotRiverGUI-01}\n",
    "\n",
    "![`spotRiverGUI` when `tree.HoeffdingAdaptiveTreeClassifier` is selected](./figures_static/spotRiverGUI-02.png){#fig-spotRiverGUI-02}\n",
    "\n",
    "\n",
    "Numerical and categorical hyperparameters are treated differently in the `spotRiverGUI`:\n",
    "\n",
    "* The user can modify the lower and upper bounds for the numerical hyperparameters.\n",
    "* There are no upper or lower bounds for categorical hyperparameters. Instead, hyperparameter values for the categorical hyperparameters are considered as sets of values, e.g., the set of `ExhaustiveSplitter`,  `HistogramSplitter`,  `GaussianSplitter` is provided for the `splitter` hyperparameter of the `tree.HoeffdingAdaptiveTreeClassifier` model  as can be seen in @fig-spotRiverGUI-02. The user can select the full set or any subset of the set of values for the categorical hyperparameters.\n",
    "\n",
    "In addition to the lower and upper bounds (or the set of values for the categorical hyperparameters), the `spotRiverGUI` provides information about the `Default values` and the `Transformation` function.\n",
    "If the `Transformation` function is set to `None`, the values of the hyperparameters are passed to the `spot` tuner as they are. If the `Transformation` function is set to `transform_power_2_int`, the value $x$ is transformed to $2^x$ before it is passed to the `spot` tuner.\n",
    "\n",
    "Modifications of the `Default values` and `Transformation` functions values in the `spotRiverGUI` have no effect on the hyperparameter tuning process. This is intensional. In future versions, the user will be able to add their own hyperparameter dictionaries to the `spotRiverGUI`, which allows the modification of `Default values` and `Transformation` functions values. Furthermore, the `spotRiverGUI` will support more online machine learning models in future versions. \n",
    "\n",
    "## Showing the Data\n",
    "\n",
    "The `spotRiverGUI` provides the `Show Data` button, which opens a new window and shows information about the data set. \n",
    "The first figure (@fig-bananas-01) shows histograms of the target variables in the train and test data sets. The second figure (@fig-bananas-02) shows scatter plots of the features in the train data set. The third figure (@fig-bananas-03) shows the corresponding scatter plots of the features in the test data set.\n",
    "\n",
    "![`spotRiverGUI` when `Bananas` data is selected for the `Show Data` option](./figures_static/bananas-01.png){#fig-bananas-01}\n",
    "\n",
    "![`spotRiverGUI` when `Bananas` data is selected for the `Show Data` option](./figures_static/bananas-02.png){#fig-bananas-02}\n",
    "\n",
    "![`spotRiverGUI` when `Bananas` data is selected for the `Show Data` option](./figures_static/bananas-03.png){#fig-bananas-03}\n",
    "\n",
    "\n",
    "::: {.callout-note}\n",
    "#### Size of the Displayed Data Sets\n",
    "\n",
    "* Some data sets are quite large and the display of the data sets might take some time.\n",
    "* Therefore, a random subset of 1000 instances of the data set is displayed if the data set is larger than 1000 instances.\n",
    "\n",
    ":::\n",
    "\n",
    "Showing the data is important, especially for the new / unknown data sets as can be seen in @fig-http-01, @fig-http-02, and @fig-http-03: The target variable is highly biased. The user can check whether the data set is correctly formatted and whether the target variable is correctly specified.\n",
    "\n",
    "![Output from the `spotRiverGUI` when `HTTP` data is selected for the `Show Data` option. The target variabel is biased.](./figures_static/http-01.png){#fig-http-01}\n",
    "\n",
    "![Output from the `spotRiverGUI` when `HTTP` data is selected for the `Show Data` option. A subset of 1000 randomly chosen data points is shown. Only a few positive events are in the data.](./figures_static/http-02.png){#fig-http-02}\n",
    "\n",
    "![Output from the `spotRiverGUI` when `HTTP` data is selected for the `Show Data` option. The test data set shows the same structure as the train data set.](./figures_static/http-03.png){#fig-http-03}\n",
    "\n",
    "In addition to the histograms and scatter plots, the `spotRiverGUI` provides textual information about the data set in the console window. e.g., for the `Bananas` data set, the following information is shown:\n",
    "\n",
    "\n",
    "\n",
    "```{bash}\n",
    "Train data summary:\n",
    "                   x1             x2             x3              y\n",
    "count  397248.000000  397248.000000  397248.000000  397248.000000\n",
    "mean       -2.269013       5.558081       7.488495       0.003904\n",
    "std         0.461650       0.434611       1.317235       0.062363\n",
    "min        -2.302585      -2.302585      -2.302585       0.000000\n",
    "25%        -2.302585       5.380358       6.490875       0.000000\n",
    "50%        -2.302585       5.517854       7.414633       0.000000\n",
    "75%        -2.302585       5.723912       8.371959       0.000000\n",
    "max         8.098369      10.906691      16.277711       1.000000\n",
    "\n",
    "Test data summary:\n",
    "                   x1             x2             x3              y\n",
    "count  170250.000000  170250.000000  170250.000000  170250.000000\n",
    "mean       -2.267430       5.556740       7.490932       0.003877\n",
    "std         0.473859       0.435927       1.316398       0.062142\n",
    "min        -2.302585      -2.302585      -2.302585       0.000000\n",
    "25%        -2.302585       5.380358       6.492391       0.000000\n",
    "50%        -2.302585       5.517854       7.419441       0.000000\n",
    "75%        -2.302585       5.723912       8.376747       0.000000\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## Saving the Experiment\n",
    "\n",
    "If the experiment should not be started immediately, the user can save the experiment by clicking on the `Save Experiment` button. The `spotRiverGUI` will save the experiment as a pickle file. The file name is generated based on the `PREFIX` parameter. \n",
    "The pickle file contains a set of dictionaries, which are used to start the experiment.\n",
    "\n",
    "`spotRiverGUI` shows a summary of the selected hyperparameters in the console window as can be seen in @tbl-hyperdict.\n",
    "\n",
    "| name                   | type   | default          |      lower |    upper | transform             |\n",
    "|------------------------|--------|------------------|------------|----------|-----------------------|\n",
    "| grace_period           | int    | 200              |     10     | 1000     | None                  |\n",
    "| max_depth              | int    | 20               |      2     |   20     | transform_power_2_int |\n",
    "| delta                  | float  | 1e-07            |      1e-08 |    1e-06 | None                  |\n",
    "| tau                    | float  | 0.05             |      0.01  |    0.1   | None                  |\n",
    "| leaf_prediction        | factor | nba              |      0     |    2     | None                  |\n",
    "| nb_threshold           | int    | 0                |      0     |   10     | None                  |\n",
    "| splitter               | factor | GaussianSplitter |      0     |    2     | None                  |\n",
    "| bootstrap_sampling     | factor | 0                |      0     |    1     | None                  |\n",
    "| drift_window_threshold | int    | 300              |    100     |  500     | None                  |\n",
    "| drift_detector         | factor | ADWIN            |      0     |    0     | None                  |\n",
    "| switch_significance    | float  | 0.05             |      0.01  |    0.1   | None                  |\n",
    "| binary_split           | factor | 0                |      0     |    1     | None                  |\n",
    "| max_size               | float  | 100.0            |    100     | 1000     | None                  |\n",
    "| memory_estimate_period | int    | 1000000          | 100000     |    1e+06 | None                  |\n",
    "| stop_mem_management    | factor | 0                |      0     |    1     | None                  |\n",
    "| remove_poor_attrs      | factor | 0                |      0     |    1     | None                  |\n",
    "| merit_preprune         | factor | 0                |      0     |    1     | None                  |\n",
    "\n",
    ": The hyperparameter dictionary for the `tree.HoeffdingAdaptiveTreeClassifier` model. {#tbl-hyperdict}\n",
    "\n",
    "\n",
    "## Loading an Experiment\n",
    "\n",
    "Future versions of the `spotRiverGUI` will support the loading of experiments from the GUI.\n",
    "Currently, the user can load the experiment by executing the command `load_experiment`, see [https://sequential-parameter-optimization.github.io/spotPython/reference/spotPython/utils/file/#spotPython.utils.file.load_experiment](https://sequential-parameter-optimization.github.io/spotPython/reference/spotPython/utils/file/#spotPython.utils.file.load_experiment).\n",
    "\n",
    "\n",
    "## Running a New Experiment\n",
    "\n",
    "An experiment can be started by clicking on the `Run Experiment` button. \n",
    "The GUI calls `run_spot_python_experiment` from `spotGUI.tuner.spotRun`.\n",
    "Output will be shown in the console window from which the GUI was started.\n",
    "\n",
    "\n",
    "### Starting and Stopping Tensorboard\n",
    "\n",
    "Tensorboard is automatically started when an experiment is started. The tensorboard process can be observed in a browser by opening the [http://localhost:6006](http://localhost:6006) page. Tensorboard provides a visual representation of the hyperparameter tuning process. @fig-tensorboard-05 and @fig-tensorboard-04 show the tensorboard page when the `spotRiverGUI` is performing the tuning process.\n",
    "\n",
    "![Tensorboard visualiation of the hyperparameter tuning process](./figures_static/tb-05.png){#fig-tensorboard-05 width=100%}\n",
    "\n",
    "![Tensorboard. Parallel coordinates plot](./figures_static/tb-04.png){#fig-tensorboard-04 width=50%}\n",
    "\n",
    "\n",
    "`spotPython.utils.tensorboard` provides the methods `start_tensorboard` and `stop_tensorboard` to start and stop tensorboard as a background process.\n",
    "After the experiment is finished, the tensorboard process is stopped automatically.\n",
    "\n",
    "\n",
    "## Analysis\n",
    "\n",
    "If the hyperparameter tuning process is finished, the user can analyze the results by clicking on the `Analysis` button. The following options are available:\n",
    "\n",
    "* Progress plot\n",
    "* Compare tuned versus default hyperparameters\n",
    "* Importance of hyperparameters\n",
    "* Contour plot\n",
    "* Parallel coordinates plot\n",
    "\n",
    "\n",
    "@fig-prg-00 shows the progress plot of the hyperparameter tuning process. Black dots denote results from the initial design. Red dots illustrate the improvement found by the surrogate model based optimization. For binary classifiaction tasks, the `roc_auc_score` is used as the evaluation metric as shown in @fig-auc-00. The confusion matrix is shown in @fig-cm-00. The default versus tuned hyperparameters are shown in @fig-default-tuned-00. The surrogate plot is shown in @fig-surrogate-00, @fig-surrogate-01, and @fig-surrogate-02.\n",
    "\n",
    "\n",
    "![Progress plot of the hyperparameter tuning process](./figures_static/prg-00.png){#fig-prg-00}\n",
    "\n",
    "![Confusion matrix](./figures_static/cm-00.png){#fig-cm-00}\n",
    "\n",
    "![Area under the ROC curve](./figures_static/auc-00.png){#fig-auc-00}\n",
    "\n",
    "![Default versus tuned hyperparameters](./figures_static/default-tuned-00.png){#fig-default-tuned-00}\n",
    "\n",
    "![Surrogate plot](./figures_static/surrogate-00.png){#fig-surrogate-00}\n",
    "\n",
    "![Surrogate plot](./figures_static/surrogate-01.png){#fig-surrogate-01}\n",
    "\n",
    "![Surrogate plot](./figures_static/surrogate-02.png){#fig-surrogate-02}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
