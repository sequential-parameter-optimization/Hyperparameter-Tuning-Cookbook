{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "lang: de\n",
        "---\n",
        "\n",
        "# Lernmodul: Erweiterung des Kriging-Modells: Numerische Optimierung der Hyperparameter\n",
        "\n",
        "## Einleitung\n",
        "\n",
        "Das vorhergehende Lernmodul hat die konzeptionellen Grundlagen und die mathematische Architektur von Kriging-Modellen vorgestellt, illustriert am Beispiel der Sinusfunktion. In dieser Einführung wurde der Aktivitätsparameter $\\theta$ aus Gründen der Einfachheit auf einen festen Wert (1.0) gesetzt. In realen Anwendungen ist es jedoch entscheidend, diese Parameter optimal aus den vorliegenden Daten zu bestimmen, um die bestmögliche Modellgüte zu erzielen.\n",
        "\n",
        "Dieses Dokument baut auf dem bestehenden Wissen auf und erläutert, wie die Kriging-Hyperparameter, insbesondere der Aktivitätsparameter $\\theta$, numerisch optimiert werden können. Wir werden uns auf die Maximierung der sogenannten \"konzentrierten Log-Likelihood-Funktion\" konzentrieren, einem gängigen Ansatz zur Parameterschätzung in Kriging-Modellen. Die gezeigte Python-Code-Erweiterung des Sinusfunktions-Beispiels verdeutlicht die praktische Umsetzung.\n",
        "\n",
        "##  Kriging-Hyperparameter: Theta ($\\vec{\\theta}$) und p ($\\vec{p}$)\n",
        "\n",
        "Im Kriging-Modell steuern zwei wichtige Vektoren von Hyperparametern die Form und die Eigenschaften der Korrelationsfunktion:\n",
        "\n",
        "*   **Aktivitätsparameter $\\vec{\\theta} = (\\theta_1, \\theta_2, \\ldots, \\theta_k)^T$**: Dieser Vektor regelt, wie schnell die Korrelation zwischen zwei Punkten mit zunehmendem Abstand in jeder Dimension abfällt. Ein großer Wert für $\\theta_j$ in einer Dimension $j$ bedeutet, dass die Funktion in dieser Dimension sehr \"aktiv\" ist oder sich schnell ändert, und somit nur Punkte in unmittelbarer Nähe stark korrelieren. Dies ermöglicht eine automatische Relevanzbestimmung, bei der wichtige Variablen durch höhere $\\theta$-Werte identifiziert werden können.\n",
        "*   **Glattheitsparameter $\\vec{p} = (p_1, p_2, \\ldots, p_k)^T$**: Dieser Vektor beeinflusst die Glattheit der Vorhersagefunktion in jeder Dimension. Üblicherweise liegen die Werte für $p_j$ zwischen 1 und 2. Im vorherigen Lernmodul wurde implizit $p_j=2$ verwendet (durch die \"sqeuclidean\"-Distanzmetrik), was zu unendlich differenzierbaren, sehr glatten Funktionen führt. Eine Optimierung von $\\vec{p}$ ist möglich, wird aber in diesem Beispiel aus Gründen der Komplexität ausgeklammert, da $p_j=2$ oft als Standard für glatte Funktionen angenommen wird.\n",
        "\n",
        "## Die Notwendigkeit der Optimierung: Die konzentrierte Log-Likelihood\n",
        "\n",
        "Um die optimalen Werte für $\\vec{\\theta}$ (und $\\vec{p}$) zu finden, wird häufig die Maximum-Likelihood-Schätzung (MLE) verwendet. Die Grundidee der MLE besteht darin, diejenigen Parameterwerte zu finden, die die Wahrscheinlichkeit maximieren, die tatsächlich beobachteten Daten zu erhalten.\n",
        "\n",
        "Die zu maximierende Funktion ist die **Log-Likelihood-Funktion**. Für gegebene $\\vec{\\theta}$ und $\\vec{p}$ (und somit eine feste Korrelationsmatrix $\\Psi$) können die Schätzer für den globalen Mittelwert $\\hat{\\mu}$ und die Prozessvarianz $\\hat{\\sigma}^2$ analytisch abgeleitet werden. Durch Einsetzen dieser Schätzer in die Log-Likelihood-Funktion erhalten wir die sogenannte **konzentrierte Log-Likelihood-Funktion**:\n",
        "\n",
        "$$\n",
        "\\ln(L) \\approx - \\frac{n}{2} \\ln(\\hat{\\sigma}^2) - \\frac{1}{2} \\ln |\\vec{\\Psi}|\n",
        "$$\n",
        "\n",
        "Hierbei ist:\n",
        "\n",
        "*   $n$: Die Anzahl der Beobachtungspunkte.\n",
        "*   $\\hat{\\sigma}^2$: Der Maximum-Likelihood-Schätzer der Prozessvarianz.\n",
        "*   $|\\vec{\\Psi}|$: Die Determinante der Korrelationsmatrix $\\vec{\\Psi}$.\n",
        "\n",
        "Die direkte Maximierung dieser Funktion ist mathematisch schwierig, da sie bezüglich $\\vec{\\theta}$ und $\\vec{p}$ nicht analytisch differenzierbar ist. Daher wird eine **numerische Optimierung** eingesetzt, um die Parameter zu finden, die die konzentrierte Log-Likelihood maximieren.\n",
        "\n",
        "## Numerische Optimierungsalgorithmen\n",
        "\n",
        "Für die numerische Optimierung der Parameter $\\vec{\\theta}$ und $\\vec{p}$ können verschiedene Algorithmen verwendet werden, darunter:\n",
        "\n",
        "*   Nelder-Mead-Simplex-Verfahren\n",
        "*   Konjugierte Gradienten-Verfahren\n",
        "*   Simulated Annealing\n",
        "*   Differential Evolution\n",
        "\n",
        "Die `scipy.optimize`-Bibliothek in Python bietet eine umfassende Sammlung solcher Optimierungsfunktionen. Da die meisten Optimierungsalgorithmen in `scipy.optimize` auf Minimierung ausgelegt sind, wird die **negative** konzentrierte Log-Likelihood-Funktion als Optimierungsziel verwendet.\n",
        "\n",
        "Ein wichtiger numerischer Aspekt bei der Berechnung der Log-Likelihood ist die Determinante von $\\Psi$. Für schlecht konditionierte Matrizen kann $|\\Psi|$ gegen Null gehen, was zu numerischer Instabilität führen kann. Um dies zu vermeiden, wird der Logarithmus der Determinante $\\ln(|\\Psi|)$ stabiler berechnet, indem man die Cholesky-Zerlegung $\\Psi = L L^T$ nutzt und dann $\\ln(|\\Psi|) = 2 \\sum_{i=1}^{n} \\ln(L_{ii})$ berechnet.\n",
        "\n",
        "Für die Suche nach $\\theta$ ist es sinnvoll, Suchbereiche auf einer logarithmischen Skala zu definieren, typischerweise von $10^{-3}$ bis $10^2$. Es ist auch ratsam, die Eingabedaten auf den Bereich zwischen Null und Eins zu skalieren, um die Konsistenz der $\\theta$-Werte über verschiedene Probleme hinweg zu gewährleisten.\n",
        "\n",
        "## Erweiterung des Sinusfunktions-Beispiels mit Hyperparameter-Optimierung\n",
        "\n",
        "Wir erweitern nun den Beispielcode aus dem \"Lernmodul: Eine Einführung in Kriging\" (Kriging-Anpassung an eine Sinusfunktion mit 8 Punkten), um den Aktivitätsparameter $\\theta$ numerisch zu optimieren.\n",
        "\n",
        "Die Hauptänderung besteht in der Definition einer neuen Zielfunktion, `neg_log_likelihood`, die von `scipy.optimize.minimize` minimiert wird. Diese Funktion nimmt die zu optimierenden Parameter (hier `theta`) entgegen und berechnet die negative konzentrierte Log-Likelihood basierend auf den Trainingsdaten."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import (exp, multiply, eye, linspace, spacing, sqrt)\n",
        "from numpy.linalg import cholesky, solve\n",
        "from scipy.spatial.distance import squareform, pdist, cdist\n",
        "from scipy.optimize import minimize # Für die Optimierung"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  Kriging-Basisfunktionen (Definition der Korrelation)\n",
        "\n",
        "Der Kernel von Kriging verwendet eine spezialisierte Basisfunktion für die Korrelation:\n",
        "$$\n",
        "\\psi(x^{(i)}, x) = \\exp(- \\sum_{j=1}^k \\theta_j |x_j^{(i)} - x_j|^{p_j}).\n",
        "$$\n",
        "\n",
        "Für dieses 1D-Beispiel ($k=1$) und mit $p_j=2$ (quadratische euklidische Distanz implizit durch `pdist`-Nutzung) und $\\theta_j = \\theta$ (ein einzelner Wert) vereinfacht es sich."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def build_Psi(X, theta, eps=sqrt(spacing(1))):\n",
        "    \"\"\"\n",
        "    Berechnet die Korrelationsmatrix Psi basierend auf paarweisen quadratischen\n",
        "    euklidischen Distanzen zwischen Eingabelokationen, skaliert mit theta.\n",
        "    Fügt ein kleines Epsilon zur Diagonalen für numerische Stabilität hinzu (Nugget-Effekt).\n",
        "    Hinweis: p_j ist implizit 2 aufgrund der 'sqeuclidean'-Metrik.\n",
        "    \"\"\"\n",
        "    # Sicherstellen, dass theta ein 1D-Array für das 'w'-Argument von cdist/pdist ist\n",
        "    if not isinstance(theta, np.ndarray) or theta.ndim == 0:\n",
        "        theta = np.array([theta])\n",
        "\n",
        "    D = squareform(pdist(X, metric='sqeuclidean', w=theta))\n",
        "    Psi = exp(-D)\n",
        "    # Ein kleiner Wert wird zur Diagonalen hinzugefügt für numerische Stabilität (Nugget)\n",
        "    # Korrektur: X.shape für die Anzahl der Zeilen der Identitätsmatrix\n",
        "    Psi += multiply(eye(X.shape[0]), eps)\n",
        "    return Psi\n",
        "\n",
        "def build_psi(X_train, x_predict, theta):\n",
        "    \"\"\"\n",
        "    Berechnet den Korrelationsvektor (oder Matrix) psi zwischen neuen Vorhersageorten\n",
        "    und Trainingsdatenlokationen.\n",
        "    \"\"\"\n",
        "    # Sicherstellen, dass theta ein 1D-Array für das 'w'-Argument von cdist/pdist ist\n",
        "    if not isinstance(theta, np.ndarray) or theta.ndim == 0:\n",
        "        theta = np.array([theta])\n",
        "\n",
        "    D = cdist(x_predict, X_train, metric='sqeuclidean', w=theta)\n",
        "    psi = exp(-D)\n",
        "    return psi.T # Transponieren, um konsistent mit der Literatur zu sein (n x m oder n x 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Zielfunktion für die Hyperparameter-Optimierung (Negative Log-Likelihood)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def neg_log_likelihood(params, X_train, y_train):\n",
        "    \"\"\"\n",
        "    Berechnet die negative konzentrierte Log-Likelihood für das Kriging-Modell.\n",
        "    params: ein 1D-Numpy-Array, wobei params theta ist.\n",
        "            (Falls auch p optimiert würde, wäre es params usw.)\n",
        "    X_train: (n, k)-Matrix der Trainings-Eingabelokationen\n",
        "    y_train: (n, 1)-Vektor der Trainings-Ausgabewerte\n",
        "    \"\"\"\n",
        "    theta = params\n",
        "    # Für dieses Beispiel ist p implizit auf 2 festgelegt (durch 'sqeuclidean' in build_Psi)\n",
        "    # Falls p optimiert würde, müsste es hier aus 'params' extrahiert und an build_Psi übergeben werden\n",
        "    n = X_train.shape[0]\n",
        "\n",
        "    # 1. Korrelationsmatrix Psi aufbauen\n",
        "    Psi = build_Psi(X_train, theta)\n",
        "\n",
        "    # 2. mu_hat berechnen (MLE des Mittelwerts)\n",
        "    # Verwendung der Cholesky-Zerlegung für stabile Inversion\n",
        "    try:\n",
        "        # numpy.cholesky gibt L (untere Dreiecksmatrix) zurück, daher transponieren für U (obere)\n",
        "        U = cholesky(Psi).T\n",
        "    except np.linalg.LinAlgError:\n",
        "        # Bei Fehlern (z.B. wenn Psi nicht positiv definit ist, durch schlechte theta-Werte)\n",
        "        # einen sehr großen Wert zurückgeben, um diese Parameter zu bestrafen\n",
        "        return 1e15\n",
        "\n",
        "    one = np.ones(n).reshape(-1, 1)\n",
        "    # Stabile Berechnung von Psi_inv @ y und Psi_inv @ one\n",
        "    Psi_inv_y = solve(U, solve(U.T, y_train))\n",
        "    Psi_inv_one = solve(U, solve(U.T, one))\n",
        "\n",
        "    # Berechnung von mu_hat\n",
        "    mu_hat = (one.T @ Psi_inv_y) / (one.T @ Psi_inv_one)\n",
        "    mu_hat = mu_hat.item() # Skalaren Wert extrahieren\n",
        "\n",
        "    # 3. sigma_hat_sq berechnen (MLE der Prozessvarianz)\n",
        "    y_minus_mu_one = y_train - one * mu_hat\n",
        "    # Korrekte Berechnung: (y-1*mu_hat).T @ Psi_inv @ (y-1*mu_hat) / n\n",
        "    sigma_hat_sq = (y_minus_mu_one.T @ solve(U, solve(U.T, y_minus_mu_one))) / n\n",
        "    sigma_hat_sq = sigma_hat_sq.item()\n",
        "\n",
        "    if sigma_hat_sq < 1e-10: # Sicherstellen, dass sigma_hat_sq nicht-negativ und nicht zu klein ist\n",
        "        return 1e15 # Sehr großen Wert zurückgeben zur Bestrafung\n",
        "\n",
        "    # 4. Log-Determinante von Psi mittels Cholesky-Zerlegung für Stabilität berechnen\n",
        "    # ln(|Psi|) = 2 * Summe(ln(L_ii)) wobei L die untere Dreiecksmatrix der Cholesky-Zerlegung ist\n",
        "    log_det_Psi = 2 * np.sum(np.log(np.diag(U.T))) # U.T ist L\n",
        "\n",
        "    # 5. Negative konzentrierte Log-Likelihood berechnen\n",
        "    # ln(L) = - (n/2) * ln(sigma_hat_sq) - (1/2) * ln(|Psi|)\n",
        "    # Zu minimieren ist -ln(L)\n",
        "    nll = 0.5 * n * np.log(sigma_hat_sq) + 0.5 * log_det_Psi\n",
        "    return nll"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Datenpunkte für das Sinusfunktions-Beispiel\n",
        "\n",
        "Das Beispiel verwendet eine 1D-Sinusfunktion, gemessen an acht gleichmäßig verteilten x-Lokationen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "n_train = 8 # Anzahl der Stichprobenlokationen\n",
        "X_train = np.linspace(0, 2 * np.pi, n_train, endpoint=False).reshape(-1, 1) # x-Lokationen generieren\n",
        "y_train = np.sin(X_train) # Zugehörige y-Werte (Sinus von x)\n",
        "\n",
        "# --- Originale Vorhersage-Einrichtung (festes theta=1.0) ---\n",
        "theta_fixed = np.array([1.0])\n",
        "Psi_fixed = build_Psi(X_train, theta_fixed)\n",
        "U_fixed = cholesky(Psi_fixed).T\n",
        "one_fixed = np.ones(n_train).reshape(-1, 1)\n",
        "mu_hat_fixed = (one_fixed.T @ solve(U_fixed, solve(U_fixed.T, y_train))) / \\\n",
        "               (one_fixed.T @ solve(U_fixed, solve(U_fixed.T, one_fixed)))\n",
        "mu_hat_fixed = mu_hat_fixed.item()\n",
        "\n",
        "m_predict = 100 # Anzahl der neuen Lokationen für die Vorhersage\n",
        "x_predict = np.linspace(0, 2 * np.pi, m_predict, endpoint=True).reshape(-1, 1)\n",
        "psi_fixed = build_psi(X_train, x_predict, theta_fixed)\n",
        "f_predict_fixed = mu_hat_fixed * np.ones(m_predict).reshape(-1, 1) + \\\n",
        "                  psi_fixed.T @ solve(U_fixed, solve(U_fixed.T, y_train - one_fixed * mu_hat_fixed))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optimierung von Theta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "initial_theta_guess = np.array([1.0]) # Startwert für Theta\n",
        "# Suchbereiche für Theta (z.B. von 1e-3 bis 1e2 auf linearer Skala, wie in den Quellen empfohlen)\n",
        "# SciPy minimize erwartet Suchbereiche als Tupel von (min, max) für jeden Parameter\n",
        "bounds = [(0.001, 100.0)] # Für Theta\n",
        "print(\"\\n--- Starte Hyperparameter-Optimierung für Theta ---\")\n",
        "# 'L-BFGS-B' wird verwendet, da es Beschränkungen (bounds) unterstützt und gut für kontinuierliche Optimierung ist.\n",
        "result = minimize(neg_log_likelihood, initial_theta_guess, args=(X_train, y_train),\n",
        "                  method='L-BFGS-B', bounds=bounds)\n",
        "\n",
        "optimized_theta = result.x\n",
        "optimized_nll = result.fun\n",
        "\n",
        "print(f\"Optimierung erfolgreich: {result.success}\")\n",
        "print(f\"Optimales Theta: {optimized_theta[0]:.4f}\")  # Extract the first element if it's a single value\n",
        "print(f\"Minimaler Negativer Log-Likelihood: {optimized_nll:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Vorhersage mit optimiertem Theta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Psi_optimized = build_Psi(X_train, optimized_theta)\n",
        "U_optimized = cholesky(Psi_optimized).T\n",
        "one_optimized = np.ones(n_train).reshape(-1, 1)\n",
        "mu_hat_optimized = (one_optimized.T @ solve(U_optimized, solve(U_optimized.T, y_train))) / \\\n",
        "                   (one_optimized.T @ solve(U_optimized, solve(U_optimized.T, one_optimized)))\n",
        "mu_hat_optimized = mu_hat_optimized.item()\n",
        "\n",
        "psi_optimized = build_psi(X_train, x_predict, optimized_theta)\n",
        "f_predict_optimized = mu_hat_optimized * np.ones(m_predict).reshape(-1, 1) + \\\n",
        "                      psi_optimized.T @ solve(U_optimized, solve(U_optimized.T, y_train - one_optimized * mu_hat_optimized))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualisierung der Ergebnisse"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x_predict, np.sin(x_predict), color=\"grey\", linestyle='--', label=\"Wahre Sinusfunktion\")\n",
        "plt.plot(X_train, y_train, \"bo\", markersize=8, label=f\"Messpunkte ({n_train} Punkte)\")\n",
        "plt.plot(x_predict, f_predict_fixed, color=\"red\", linestyle=':', label=f\"Kriging-Vorhersage (Fixes Theta={theta_fixed[0]:.1f})\")\n",
        "plt.plot(x_predict, f_predict_optimized, color=\"orange\", label=f\"Kriging-Vorhersage (Optimiertes Theta={optimized_theta[0]:.2f})\")\n",
        "plt.title(f\"Kriging-Vorhersage der Sinusfunktion mit {n_train} Punkten\\nOptimierung des Aktivitätsparameters Theta\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6. Ergebnisse und Diskussion\n",
        "\n",
        "Die grafische Darstellung der Ergebnisse zeigt die Verbesserung der Kriging-Vorhersage nach der Optimierung des Aktivitätsparameters $\\theta$. Die Kurve, die mit dem optimierten $\\theta$-Wert generiert wurde, passt sich in der Regel besser an die Trainingsdaten an und bildet den wahren Funktionsverlauf präziser ab, als dies mit einem willkürlich gewählten $\\theta$-Wert der Fall wäre. Der Optimierungsalgorithmus findet den $\\theta$-Wert, der die Korrelationsstruktur der Daten am besten erklärt und somit ein \"realistischeres\" Modell der zugrunde liegenden Funktion liefert.\n",
        "\n",
        "In diesem 1D-Beispiel ist der Unterschied möglicherweise subtil, aber in höherdimensionalen Problemen, wo Variablen unterschiedliche \"Aktivitäten\" aufweisen, ist die automatische Bestimmung von $\\vec{\\theta}$ entscheidend für die Modellgenauigkeit und die Identifizierung wichtiger Input-Variablen.\n",
        "\n",
        "### 7. Fazit und Ausblick\n",
        "\n",
        "Dieses Lernmodul hat gezeigt, wie die Maximum-Likelihood-Schätzung in Verbindung mit numerischen Optimierungsverfahren genutzt werden kann, um die Hyperparameter eines Kriging-Modells optimal an die Daten anzupassen. Die Optimierung der konzentrierten Log-Likelihood-Funktion ist ein Standardansatz, der die Robustheit und Genauigkeit von Kriging-Modellen erheblich verbessert.\n",
        "\n",
        "Für fortgeschrittenere Anwendungen könnten weitere Schritte unternommen werden:\n",
        "\n",
        "*   **Optimierung von $\\vec{p}$**: Der Glattheitsparameter $\\vec{p}$ könnte ebenfalls in den Optimierungsprozess einbezogen werden, um noch flexiblere Anpassungen zu ermöglichen.\n",
        "*   **Kriging-Regression für verrauschte Daten**: Falls die Trainingsdaten Rauschen enthalten (z.B. aus physikalischen Experimenten), kann ein zusätzlicher \"Nugget\"-Parameter $\\lambda$ in der Korrelationsmatrix optimiert werden. Dies transformiert das interpolierende Kriging in ein regressives Kriging, das Rauschen explizit modelliert und eine glattere Vorhersagekurve liefert.\n",
        "*   **Aktives Lernen und Expected Improvement (EI)**: Kriging-Modelle liefern nicht nur Vorhersagen, sondern auch Unsicherheitsschätzungen (Varianz) an jedem Punkt. Dies ermöglicht den Einsatz von \"Infill-Kriterien\" wie Expected Improvement (EI), um den nächsten vielversprechendsten Punkt für eine Funktionsauswertung intelligent auszuwählen, was besonders bei teuren Simulationen effizient ist.\n",
        "*   **Co-Kriging (Multi-Fidelity-Modellierung)**: Wenn Daten aus verschiedenen Quellen mit unterschiedlicher Genauigkeit und Kosten verfügbar sind, kann Co-Kriging (auch Multi-Fidelity-Modellierung genannt) diese Daten integrieren, um genauere Modelle zu erstellen.\n",
        "\n",
        "Diese erweiterten Konzepte bilden die Grundlage für robuste und effiziente Optimierungsprozesse in vielen technischen und wissenschaftlichen Disziplinen.\n",
        "\n",
        "## Zusatzmaterialien\n",
        "\n",
        ":::{.callout-note}\n",
        "#### Interaktive Webseite\n",
        "\n",
        "* Eine interaktive Webseite zum Thema **Kriging: Optimierung der Hyperparameter** ist hier zu finden: [Kriging Interaktiv](https://advm1.gm.fh-koeln.de/~bartz/bart21i/de_kriging_optimization_interactive.html).\n",
        "\n",
        ":::\n",
        "\n",
        ":::{.callout-note}\n",
        "#### Jupyter-Notebook\n",
        "\n",
        "* Das Jupyter-Notebook für dieses Lernmodul ist auf GitHub im [Hyperparameter-Tuning-Cookbook Repository](https://github.com/sequential-parameter-optimization/Hyperparameter-Tuning-Cookbook/blob/main/de_kriging_optimization.ipynb) verfügbar.\n",
        "\n",
        ":::\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/bartz/miniforge3/envs/spot312/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}