{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "execute:\n",
        "  cache: false\n",
        "  eval: true\n",
        "  echo: true\n",
        "  warning: false\n",
        "---\n",
        "\n",
        "# HPT: sklearn SVR on Regression Data {#sec-hpt-sklearn-svR}\n",
        "\n",
        "This chapter is a tutorial for the Hyperparameter Tuning (HPT) of a `sklearn` SVR model on a regression dataset.\n",
        "\n",
        "## Step 1: Setup {#sec-setup-svr}\n",
        "\n",
        "Before we consider the detailed experimental setup, we select the parameters that affect run time, initial design size and the device that is used.\n",
        "\n",
        "::: {.callout-caution}\n",
        "### Caution: Run time and initial design size should be increased for real experiments\n",
        "\n",
        "* MAX_TIME is set to one minute for demonstration purposes. For real experiments, this should be increased to at least 1 hour.\n",
        "* INIT_SIZE is set to 5 for demonstration purposes. For real experiments, this should be increased to at least 10.\n",
        "\n",
        ":::\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "MAX_TIME = 1\n",
        "INIT_SIZE = 20\n",
        "PREFIX = \"18\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "import os\n",
        "from math import inf\n",
        "import numpy as np\n",
        "import warnings\n",
        "if not os.path.exists('./figures'):\n",
        "    os.makedirs('./figures')\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Initialization of the Empty `fun_control` Dictionary\n",
        "\n",
        "`spotpython` supports the visualization of the hyperparameter tuning process with TensorBoard. The following example shows how to use TensorBoard with `spotpython`.\n",
        "The `fun_control` dictionary is the central data structure that is used to control the optimization process. It is initialized as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from spotpython.utils.init import fun_control_init\n",
        "from spotpython.hyperparameters.values import set_control_key_value\n",
        "from spotpython.utils.eda import print_res_table\n",
        "fun_control = fun_control_init(\n",
        "    PREFIX=PREFIX,\n",
        "    TENSORBOARD_CLEAN=True,\n",
        "    max_time=MAX_TIME,\n",
        "    fun_evals=inf,\n",
        "    tolerance_x = np.sqrt(np.spacing(1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.callout-tip}\n",
        "#### Tip: TensorBoard\n",
        "* Since the `spot_tensorboard_path` argument is not `None`, which is the default, `spotpython` will log the optimization process in the TensorBoard folder.\n",
        "* The `TENSORBOARD_CLEAN` argument is set to `True` to archive the TensorBoard folder if it already exists. This is useful if you want to start a hyperparameter tuning process from scratch.\n",
        "If you want to continue a hyperparameter tuning process, set `TENSORBOARD_CLEAN` to `False`. Then the TensorBoard folder will not be archived and the old and new TensorBoard files will shown in the TensorBoard dashboard.\n",
        ":::\n",
        "\n",
        "\n",
        "## Step 3: SKlearn Load Data (Classification) {#sec-data-loading-17}\n",
        "\n",
        "Randomly generate classification data. Here, we use similar data as in [Comparison of kernel ridge regression and SVR](https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_kernel_ridge_regression.html#sphx-glr-auto-examples-miscellaneous-plot-kernel-ridge-regression-py)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "\n",
        "rng = np.random.RandomState(42)\n",
        "\n",
        "X = 5 * rng.rand(10, 1)\n",
        "y = np.sin(1/X).ravel()*np.cos(X).ravel()\n",
        "\n",
        "# Add noise to targets\n",
        "y[::5] += 3 * (0.5 - rng.rand(X.shape[0] // 5))\n",
        "\n",
        "X_plot = np.linspace(0, 5, 100000)[:, None]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "n_features = 1\n",
        "target_column = \"y\"\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "train = pd.DataFrame(np.hstack((X_train, y_train.reshape(-1, 1))))\n",
        "test = pd.DataFrame(np.hstack((X_test, y_test.reshape(-1, 1))))\n",
        "train.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
        "test.columns = [f\"x{i}\" for i in range(1, n_features+1)] + [target_column]\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "n_samples = len(train)\n",
        "# add the dataset to the fun_control\n",
        "fun_control.update({\"data\": None, # dataset,\n",
        "               \"train\": train,\n",
        "               \"test\": test,\n",
        "               \"n_samples\": n_samples,\n",
        "               \"target_column\": target_column})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Specification of the Preprocessing Model {#sec-specification-of-preprocessing-model-17}\n",
        "\n",
        "Data preprocesssing can be very simple, e.g., you can ignore it. Then you would choose the `prep_model` \"None\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "prep_model = None\n",
        "fun_control.update({\"prep_model\": prep_model})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A default approach for numerical data is the `StandardScaler` (mean 0, variance 1).  This can be selected as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "prep_model = StandardScaler\n",
        "fun_control.update({\"prep_model\": prep_model})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Even more complicated pre-processing steps are possible, e.g., the follwing pipeline:\n",
        "\n",
        "```{raw}\n",
        "categorical_columns = []\n",
        "one_hot_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "prep_model = ColumnTransformer(\n",
        "         transformers=[\n",
        "             (\"categorical\", one_hot_encoder, categorical_columns),\n",
        "         ],\n",
        "         remainder=StandardScaler,\n",
        "     )\n",
        "```\n",
        "\n",
        "## Step 5: Select Model (`algorithm`) and `core_model_hyper_dict`\n",
        "\n",
        "The selection of the algorithm (ML model) that should be tuned is done by specifying the its name from the `sklearn` implementation.  For example, the `SVC` support vector machine classifier is selected as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from spotpython.hyperparameters.values import add_core_model_to_fun_control\n",
        "from spotpython.hyperdict.sklearn_hyper_dict import SklearnHyperDict\n",
        "from sklearn.svm import SVR\n",
        "add_core_model_to_fun_control(core_model=SVR,\n",
        "                              fun_control=fun_control,\n",
        "                              hyper_dict=SklearnHyperDict,\n",
        "                              filename=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now `fun_control` has the information from the JSON file.\n",
        "The corresponding entries for the `core_model` class are shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fun_control['core_model_hyper_dict']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::{.callout-note}\n",
        "#### `sklearn Model` Selection\n",
        "\n",
        "The following `sklearn` models are supported by default:\n",
        "\n",
        "* RidgeCV\n",
        "* RandomForestClassifier\n",
        "* SVC\n",
        "* SVR\n",
        "* LogisticRegression\n",
        "* KNeighborsClassifier\n",
        "* GradientBoostingClassifier\n",
        "* GradientBoostingRegressor\n",
        "* ElasticNet\n",
        "\n",
        "They can be imported as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| label: 017_import_sklearn_models\n",
        "from sklearn.linear_model import RidgeCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.linear_model import ElasticNet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "## Step 6: Modify `hyper_dict` Hyperparameters for the Selected Algorithm aka `core_model`\n",
        "\n",
        " `spotpython` provides functions for modifying the hyperparameters, their bounds and factors as well as for activating and de-activating hyperparameters without re-compilation of the Python source code. These functions were described in @sec-modifying-hyperparameter-levels.\n",
        "\n",
        "### Modify hyperparameter of type numeric and integer (boolean)\n",
        "\n",
        "Numeric and boolean values can be modified using the `modify_hyper_parameter_bounds` method.  \n",
        "\n",
        ":::{.callout-note}\n",
        "#### `sklearn Model` Hyperparameters\n",
        "\n",
        "The hyperparameters of the `sklearn`  `SVC` model are described in the [sklearn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html).\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "* For example, to change the `tol` hyperparameter of the `SVC` model to the interval [1e-5, 1e-3], the following code can be used:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from spotpython.hyperparameters.values import modify_hyper_parameter_bounds\n",
        "modify_hyper_parameter_bounds(fun_control, \"tol\", bounds=[1e-5, 1e-3])\n",
        "modify_hyper_parameter_bounds(fun_control, \"epsilon\", bounds=[0.1, 1.0])\n",
        "# modify_hyper_parameter_bounds(fun_control, \"degree\", bounds=[2, 5])\n",
        "fun_control[\"core_model_hyper_dict\"][\"tol\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Modify hyperparameter of type factor\n",
        "\n",
        "Factors can be modified with the `modify_hyper_parameter_levels` function.  For example, to exclude the `sigmoid` kernel from the tuning, the `kernel` hyperparameter of the `SVR` model can be modified as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from spotpython.hyperparameters.values import modify_hyper_parameter_levels\n",
        "# modify_hyper_parameter_levels(fun_control, \"kernel\", [\"poly\", \"rbf\"])\n",
        "modify_hyper_parameter_levels(fun_control, \"kernel\", [\"rbf\"])\n",
        "fun_control[\"core_model_hyper_dict\"][\"kernel\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optimizers {#sec-optimizers-17}\n",
        "\n",
        "Optimizers are described in @sec-optimizer.\n",
        "\n",
        "## Step 7: Selection of the Objective (Loss) Function\n",
        "\n",
        "There are two metrics:\n",
        "\n",
        "1. `metric_river` is used for the river based evaluation via `eval_oml_iter_progressive`.\n",
        "2. `metric_sklearn` is used for the sklearn based evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.metrics import mean_absolute_error, accuracy_score, roc_curve, roc_auc_score, log_loss, mean_squared_error\n",
        "fun_control.update({\n",
        "               \"metric_sklearn\": mean_squared_error,\n",
        "               \"weights\": 1.0,\n",
        "               })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::{.callout-warning}\n",
        "#### `metric_sklearn`: Minimization and Maximization\n",
        "\n",
        "* Because the `metric_sklearn` is used for the sklearn based evaluation, it is important to know whether the metric should be minimized or maximized.\n",
        "* The `weights` parameter is used to indicate whether the metric should be minimized or maximized.\n",
        "* If `weights` is set to `-1.0`, the metric is maximized.\n",
        "* If `weights` is set to `1.0`, the metric is minimized, e.g., `weights = 1.0` for `mean_absolute_error`, or `weights = -1.0` for `roc_auc_score`.\n",
        "\n",
        ":::\n",
        "\n",
        "### Predict Classes or Class Probabilities\n",
        "\n",
        "If the key `\"predict_proba\"` is set to `True`, the class probabilities are predicted. `False` is the default, i.e., the classes are predicted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fun_control.update({\n",
        "               \"predict_proba\": False,\n",
        "               })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Calling the SPOT Function\n",
        "\n",
        "\n",
        "### The Objective Function {#sec-the-objective-function-17}\n",
        "\n",
        "The objective function is selected next. It implements an interface from `sklearn`'s training, validation, and  testing methods to `spotpython`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from spotpython.fun.hypersklearn import HyperSklearn\n",
        "fun = HyperSklearn().fun_sklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following code snippet shows how to get the default hyperparameters as an array, so that they can be passed to the `Spot` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from spotpython.hyperparameters.values import get_default_hyperparameters_as_array\n",
        "X_start = get_default_hyperparameters_as_array(fun_control)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run the `Spot` Optimizer\n",
        "\n",
        "The class `Spot` [[SOURCE]](https://github.com/sequential-parameter-optimization/spotpython/blob/main/src/spotpython/spot/spot.py) is the hyperparameter tuning workhorse. It is initialized with the following parameters:\n",
        "\n",
        "* `fun`: the objective function\n",
        "* `fun_control`: the dictionary with the control parameters for the objective function\n",
        "* `design`: the experimental design\n",
        "* `design_control`: the dictionary with the control parameters for the experimental design\n",
        "* `surrogate`: the surrogate model\n",
        "* `surrogate_control`: the dictionary with the control parameters for the surrogate model\n",
        "* `optimizer`: the optimizer\n",
        "* `optimizer_control`: the dictionary with the control parameters for the optimizer\n",
        "\n",
        ":::{.callout-note}\n",
        "#### Note: Total run time\n",
        " The total run time may exceed the specified `max_time`, because the initial design (here: `init_size` = INIT_SIZE as specified above) is always evaluated, even if this takes longer than `max_time`.\n",
        ":::"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from spotpython.utils.init import design_control_init, surrogate_control_init\n",
        "design_control = design_control_init()\n",
        "set_control_key_value(control_dict=design_control,\n",
        "                        key=\"init_size\",\n",
        "                        value=INIT_SIZE,\n",
        "                        replace=True)\n",
        "\n",
        "surrogate_control = surrogate_control_init(method=\"regression\",\n",
        "                                           n_theta=2)\n",
        "from spotpython.spot import Spot\n",
        "spot_tuner = Spot(fun=fun,\n",
        "                   fun_control=fun_control,\n",
        "                   design_control=design_control,\n",
        "                   surrogate_control=surrogate_control)\n",
        "spot_tuner.run(X_start=X_start)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TensorBoard {#sec-tensorboard-17}\n",
        "\n",
        "Now we can start TensorBoard in the background with the following command, where `./runs` is the default directory for the TensorBoard log files:\n",
        "\n",
        "```{raw}\n",
        "tensorboard --logdir=\"./runs\"\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from spotpython.utils.init import get_tensorboard_path\n",
        "get_tensorboard_path(fun_control)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After the hyperparameter tuning run is finished, the progress of the hyperparameter tuning can be visualized. The black points represent the performace values (score or metric) of  hyperparameter configurations from the initial design, whereas the red points represents the  hyperparameter configurations found by the surrogate model based optimization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "spot_tuner.plot_progress(log_y=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results can also be printed in tabular form."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print_res_table(spot_tuner)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A histogram can be used to visualize the most important hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "spot_tuner.plot_importance(threshold=0.0025)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get Default Hyperparameters\n",
        "\n",
        "The default hyperparameters, which will be used for a comparion with the tuned hyperparameters, can be obtained with the following commands:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from spotpython.hyperparameters.values import get_one_core_model_from_X\n",
        "from spotpython.hyperparameters.values import get_default_hyperparameters_as_array\n",
        "X_start = get_default_hyperparameters_as_array(fun_control)\n",
        "model_default = get_one_core_model_from_X(X_start, fun_control, default=True)\n",
        "model_default"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get SPOT Results\n",
        "\n",
        "In a similar way, we can obtain the hyperparameters found by `spotpython`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from spotpython.hyperparameters.values import get_one_core_model_from_X\n",
        "X_tuned = spot_tuner.to_all_dim(spot_tuner.min_X.reshape(1,-1))\n",
        "model_spot = get_one_core_model_from_X(X_tuned, fun_control)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot: Compare Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_default.fit(X_train, y_train)\n",
        "y_default = model_default.predict(X_plot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_spot.fit(X_train, y_train)\n",
        "y_spot = model_spot.predict(X_plot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(X[:100], y[:100], c=\"orange\", label=\"data\", zorder=1, edgecolors=(0, 0, 0))\n",
        "plt.plot(\n",
        "    X_plot,\n",
        "    y_default,\n",
        "    c=\"red\",\n",
        "    label=\"Default SVR\")\n",
        "\n",
        "plt.plot(\n",
        "    X_plot, y_spot, c=\"blue\", label=\"SPOT SVR\")\n",
        "\n",
        "plt.xlabel(\"data\")\n",
        "plt.ylabel(\"target\")\n",
        "plt.title(\"SVR\")\n",
        "_ = plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Detailed Hyperparameter Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "spot_tuner.plot_important_hyperparameter_contour(filename=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parallel Coordinates Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "spot_tuner.parallel_plot()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/bartz/miniforge3/envs/spot312/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}