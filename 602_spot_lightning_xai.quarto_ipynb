{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12c3e02a",
   "metadata": {},
   "source": [
    "---\n",
    "jupyter: python3\n",
    "title: Explainable AI with SpotPython and Pytorch\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "#| label: imports\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b18b1df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.data.diabetes import Diabetes\n",
    "from spotpython.hyperdict.light_hyper_dict import LightHyperDict\n",
    "from spotpython.fun.hyperlight import HyperLight\n",
    "from spotpython.utils.init import (fun_control_init, surrogate_control_init, design_control_init)\n",
    "from spotpython.utils.eda import gen_design_table\n",
    "from spotpython.spot import spot\n",
    "from spotpython.utils.file import get_experiment_filename\n",
    "from spotpython.hyperparameters.values import set_hyperparameter\n",
    "from math import inf\n",
    "\n",
    "PREFIX=\"602_1\"\n",
    "\n",
    "data_set = Diabetes()\n",
    "\n",
    "fun_control = fun_control_init(\n",
    "    save_experiment=True,\n",
    "    PREFIX=PREFIX,\n",
    "    fun_evals=inf,\n",
    "    max_time=60,\n",
    "    data_set = data_set,\n",
    "    core_model_name=\"light.regression.NNLinearRegressor\",\n",
    "    hyperdict=LightHyperDict,\n",
    "    _L_in=10,\n",
    "    _L_out=1)\n",
    "\n",
    "fun = HyperLight().fun\n",
    "\n",
    "\n",
    "set_hyperparameter(fun_control, \"optimizer\", [ \"Adadelta\", \"Adam\", \"Adamax\"])\n",
    "set_hyperparameter(fun_control, \"l1\", [5,7])\n",
    "set_hyperparameter(fun_control, \"epochs\", [10,12])\n",
    "set_hyperparameter(fun_control, \"batch_size\", [4,11])\n",
    "set_hyperparameter(fun_control, \"dropout_prob\", [0.0, 0.025])\n",
    "set_hyperparameter(fun_control, \"patience\", [2,9])\n",
    "\n",
    "design_control = design_control_init(init_size=20)\n",
    "\n",
    "spot_tuner = spot.Spot(fun=fun,fun_control=fun_control, design_control=design_control)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7620be90",
   "metadata": {},
   "source": [
    "### Running the Hyperparameter Tuning or Loading the Existing Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9e05971",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.utils.file import get_experiment_filename, load_experiment\n",
    "import os\n",
    "overwrite = False\n",
    "filename = get_experiment_filename(PREFIX)\n",
    "if os.path.exists(filename) and not overwrite:\n",
    "    (spot_tuner, fun_control, design_control,\n",
    "    surrogate_control, optimizer_control) = load_experiment(filename)\n",
    "else:\n",
    "    print(\"File does not exist or overwrite is True. Starting new experiment.\")\n",
    "    res = spot_tuner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76491c0e",
   "metadata": {},
   "source": [
    "### Results from the Hyperparameter Tuning Experiment\n",
    "\n",
    "* After the hyperparameter tuning is finished, the following information is available:\n",
    "    * the `spot_tuner` object and the associated\n",
    "    * `fun_control` dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0a158a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = spot_tuner.print_results(print_screen=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd85cd6",
   "metadata": {},
   "source": [
    "#### Getting the Best Model, i.e, the Tuned Architecture\n",
    "\n",
    "* The method `get_tuned_architecture` [[DOC]](https://sequential-parameter-optimization.github.io/spotPython/reference/spotpython/hyperparameters/values/#spotpython.hyperparameters.values.get_tuned_architecture) returns the best model architecture found during the hyperparameter tuning.\n",
    "* It returns the transformed values, i.e., `batch_size = 2^x` if the hyperparameter `batch_size` was transformed with the `transform_power_2_int` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90122819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.hyperparameters.values import get_tuned_architecture\n",
    "import pprint\n",
    "config = get_tuned_architecture(spot_tuner, fun_control)\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebb98f9",
   "metadata": {},
   "source": [
    "* Note: `get_tuned_architecture` has the option `force_minX` which does not have any effect in this case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2678dc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.hyperparameters.values import get_tuned_architecture\n",
    "config = get_tuned_architecture(spot_tuner, fun_control, force_minX=True)\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ce0a74",
   "metadata": {},
   "source": [
    "### Training the Tuned Architecture on the Test Data\n",
    "\n",
    "* Since we are interested in the explainability of the model, we will train the tuned architecture on the test data.\n",
    "* `spotpythons`'s `test_model` function [[DOC]](https://sequential-parameter-optimization.github.io/spotPython/reference/spotpython/light/testmodel/) is used to train the model on the test data.\n",
    "* Note: Until now, we do not use any information about the NN's weights and biases. Only the architecture, which is available as the `config`, is used.\n",
    "* `spotpython` used the TensorBoard logger to save the training process in the `./runs` directory. Therefore, we have to enable the TensorBoard logger in the `fun_control` dictionary. To get a clean start, we remove an existing `runs` folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3262475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.light.testmodel import test_model\n",
    "from spotpython.light.loadmodel import load_light_from_checkpoint\n",
    "import os\n",
    "# if the directory \"./runs\" exists, delete it\n",
    "if os.path.exists(\"./runs\"):\n",
    "    os.system(\"rm -r ./runs\")\n",
    "fun_control.update({\"tensorboard_log\": True})\n",
    "test_model(config, fun_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "load_model_from_chkpt",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: load_model_from_chkpt\n",
    "model = load_light_from_checkpoint(config, fun_control)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a0ec99",
   "metadata": {},
   "source": [
    "##### Details of the Training Process on the Test Data\n",
    "\n",
    "* The `test_model` method initializes the model with the tuned architecture as follows:\n",
    "\n",
    "```python\n",
    "model = fun_control[\"core_model\"](**config, _L_in=_L_in, _L_out=_L_out, _torchmetric=_torchmetric)\n",
    "```\n",
    "\n",
    "* Then, the Lightning Trainer is initialized with the `fun_control` dictionary and the model as follows:\n",
    "    \n",
    "    ```python\n",
    "        trainer = L.Trainer(\n",
    "        default_root_dir=os.path.join(fun_control[\"CHECKPOINT_PATH\"], config_id),\n",
    "        max_epochs=model.hparams.epochs,\n",
    "        accelerator=fun_control[\"accelerator\"],\n",
    "        devices=fun_control[\"devices\"],\n",
    "        logger=TensorBoardLogger(\n",
    "            save_dir=fun_control[\"TENSORBOARD_PATH\"],\n",
    "            version=config_id,\n",
    "            default_hp_metric=True,\n",
    "            log_graph=fun_control[\"log_graph\"],\n",
    "        ),\n",
    "        callbacks=[\n",
    "            EarlyStopping(monitor=\"val_loss\", patience=config[\"patience\"], mode=\"min\", strict=False, verbose=False),\n",
    "            ModelCheckpoint(\n",
    "                dirpath=os.path.join(fun_control[\"CHECKPOINT_PATH\"], config_id), save_last=True\n",
    "            ), \n",
    "        ],\n",
    "        enable_progress_bar=enable_progress_bar,\n",
    "    )\n",
    "    trainer.fit(model=model, datamodule=dm)    \n",
    "    test_result = trainer.test(datamodule=dm, ckpt_path=\"last\")\n",
    "    ```\n",
    "\n",
    "* As shown in the code above, the last checkpoint ist saved.\n",
    "* `spotpython`'s method `load_light_from_checkpoint` is used to load the last checkpoint and to get the model's weights and biases. It requires the `fun_control` dictionary and the `config_id` as input to find the correct checkpoint.\n",
    "* Now, the model is trained and the weights and biases are available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "248c1b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "import torch\n",
    "\n",
    "x = torch.randn(1, 10).requires_grad_(True)\n",
    "x = x.to(\"mps\")\n",
    "output = model(x)\n",
    "dot = make_dot(output, params=dict(model.named_parameters()), show_attrs=True, show_saved=True)\n",
    "dot.render(\"model_architecture\", format=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c66288",
   "metadata": {},
   "source": [
    "![architecture](./model_architecture.png)\n",
    "\n",
    "## XAI Methods\n",
    "\n",
    "* `spotpython` provides methods to explain the model's predictions. The following neural network elements can be analyzed: \n",
    "\n",
    "### Weights\n",
    "\n",
    "* Weights are the parameters of the neural network that are learned from the data during training. They connect neurons between layers and determine the strength and direction of the signal sent from one neuron to another. The network adjusts the weights during training to minimize the error between the predicted output and the actual output.\n",
    "* Interpretation of the weights: A high weight value indicates a strong influence of the input neuron on the output. Positive weights suggest a positive correlation, whereas negative weights suggest an inverse relationship between neurons.\n",
    "\n",
    "### Activations\n",
    "\n",
    "* Activations are the outputs produced by neurons after applying an activation function to the weighted sum of inputs. The activation function (e.g., ReLU, sigmoid, tanh) adds non-linearity to the model, allowing it to learn more complex relationships.\n",
    "* Interpretation of the activations: The value of activations indicates the intensity of the signal passed to the next layer. Certain activation patterns can highlight which features or parts of the data the network is focusing on.\n",
    "\n",
    "### Gradients\n",
    "\n",
    "* Gradients are the partial derivatives of the loss function with respect to different parameters (weights) of the network. During backpropagation, gradients are used to update the weights in the direction that reduces the loss by methods like gradient descent.\n",
    "* Interpretation of the gradients: The magnitude of the gradient indicates how much a parameter should change to reduce the error. A large gradient implies a steeper slope and a bigger update, while a small gradient suggests that the parameter is near an optimal point. If gradients are too small (vanishing gradient problem), the network may learn slowly or stop learning. If they are too large (exploding gradient problem), the updates may be unstable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18322fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.plot.xai import (get_activations, get_gradients, get_weights, visualize_weights, visualize_gradients, visualize_mean_activations, visualize_gradient_distributions, visualize_weights_distributions, visualize_activations_distributions)\n",
    "batch_size = config[\"batch_size\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8740ce",
   "metadata": {},
   "source": [
    "### Getting the Weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00f9159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.plot.xai import sort_layers\n",
    "weights = get_weights(model)\n",
    "sort_layers(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e835737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_weights(model, absolute=True, cmap=\"GreenYellowRed\", figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02b5c7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_weights_distributions(model, color=f\"C{0}\", columns=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b81644",
   "metadata": {},
   "source": [
    "### Getting the Activations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a5dc920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.plot.xai import get_activations\n",
    "activations, mean_activations = get_activations(net=model, fun_control=fun_control, batch_size=batch_size, device=\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "visualize_mean_activations",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: visualize_mean_activations\n",
    "visualize_mean_activations(mean_activations, absolute=True, cmap=\"GreenYellowRed\", figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "visualize_activations_distributions",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: visualize_activations_distributions\n",
    "visualize_activations_distributions(activations=activations,\n",
    "                                    net=model, color=\"C0\", columns=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e54e823",
   "metadata": {},
   "source": [
    "### Getting the Gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "get_gradients",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: get_gradients\n",
    "gradients = get_gradients(net=model, fun_control=fun_control, batch_size=batch_size, device = \"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d61f2edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_gradients(model, fun_control, batch_size, absolute=True, cmap=\"GreenYellowRed\", figsize=(6, 6), device=\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d0e8d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_gradient_distributions(model, fun_control, batch_size=batch_size, color=f\"C{0}\", device=\"mps\", columns=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42a9144",
   "metadata": {},
   "source": [
    "## Feature Attributions\n",
    "\n",
    "### Integrated Gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cb83857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.plot.xai import get_attributions, plot_attributions\n",
    "df_att = get_attributions(spot_tuner, fun_control, attr_method=\"IntegratedGradients\", n_rel=10)\n",
    "plot_attributions(df_att, attr_method=\"IntegratedGradients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28c4b20",
   "metadata": {},
   "source": [
    "### Deep Lift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa01f8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lift = get_attributions(spot_tuner, fun_control, attr_method=\"DeepLift\",n_rel=10)\n",
    "print(df_lift)\n",
    "plot_attributions(df_lift,  attr_method=\"DeepLift\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c64c1d",
   "metadata": {},
   "source": [
    "### Feature Ablation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c34a95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fl = get_attributions(spot_tuner, fun_control, attr_method=\"FeatureAblation\",n_rel=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63bce813",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_fl)\n",
    "plot_attributions(df_fl, attr_method=\"FeatureAblation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c060f9d",
   "metadata": {},
   "source": [
    "## Conductance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea7f0be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.plot.xai import plot_conductance_last_layer, get_weights_conductance_last_layer\n",
    "weights_last, layer_conductance_last = get_weights_conductance_last_layer(spot_tuner, fun_control)\n",
    "plot_conductance_last_layer(weights_last, layer_conductance_last, figsize=(6, 6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3",
   "path": "/Users/bartz/miniforge3/envs/spot312/share/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
