{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "lang: de\n",
        "eval: true\n",
        "---\n",
        "\n",
        "# Lernmodul: Erweiterung des Kriging-Modells zu einer Klasse (Python Code)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import (exp, multiply, eye, linspace, spacing, sqrt)\n",
        "from numpy.linalg import cholesky, solve\n",
        "from scipy.spatial.distance import squareform, pdist, cdist\n",
        "from scipy.optimize import minimize # Für die Optimierung\n",
        "\n",
        "\n",
        "class KrigingRegressor:\n",
        "    \"\"\"Ein Kriging-Regressionsmodell mit Hyperparameter-Optimierung.\n",
        "    \n",
        "    Attributes:\n",
        "        initial_theta (float): Startwert für den Aktivitätsparameter Theta.\n",
        "        bounds (list): Liste von Tupeln für die Grenzen der Hyperparameter-Optimierung.\n",
        "        opt_theta_ (float): Optimierter Theta-Wert nach dem Fitting.\n",
        "        X_train_ (array): Trainings-Eingabedaten.\n",
        "        y_train_ (array): Trainings-Zielwerte.\n",
        "        U_ (array): Cholesky-Zerlegung der Korrelationsmatrix.\n",
        "        mu_hat_ (float): Geschätzter Mittelwert.\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    def __init__(self, initial_theta=1.0, bounds=[(0.001, 100.0)]):\n",
        "        self.initial_theta = initial_theta\n",
        "        self.bounds = bounds\n",
        "    \n",
        "    def _build_Psi(self, X, theta, eps=sqrt(spacing(1))):\n",
        "        \"\"\"Berechnet die Korrelationsmatrix Psi.\"\"\"\n",
        "        if not isinstance(theta, np.ndarray) or theta.ndim == 0:\n",
        "            theta = np.array([theta])\n",
        "        \n",
        "        D = squareform(pdist(X, metric='sqeuclidean', w=theta))\n",
        "        Psi = exp(-D)\n",
        "        Psi += multiply(eye(X.shape[0]), eps)\n",
        "        return Psi\n",
        "    \n",
        "    def _build_psi(self, X_train, x_predict, theta):\n",
        "        \"\"\"Berechnet den Korrelationsvektor psi.\"\"\"\n",
        "        if not isinstance(theta, np.ndarray) or theta.ndim == 0:\n",
        "            theta = np.array([theta])\n",
        "        \n",
        "        D = cdist(x_predict, X_train, metric='sqeuclidean', w=theta)\n",
        "        psi = exp(-D)\n",
        "        return psi.T\n",
        "    \n",
        "    def _neg_log_likelihood(self, params, X_train, y_train):\n",
        "        \"\"\"Berechnet die negative konzentrierte Log-Likelihood.\"\"\"\n",
        "        theta = params\n",
        "        n = X_train.shape[0]\n",
        "        \n",
        "        try:\n",
        "            Psi = self._build_Psi(X_train, theta)\n",
        "            U = cholesky(Psi).T\n",
        "        except np.linalg.LinAlgError:\n",
        "            return 1e15\n",
        "        \n",
        "        one = np.ones(n).reshape(-1, 1)\n",
        "        \n",
        "        # Berechne mu_hat (MLE des Mittelwerts)\n",
        "        Psi_inv_y = solve(U, solve(U.T, y_train))\n",
        "        Psi_inv_one = solve(U, solve(U.T, one))\n",
        "        mu_hat = (one.T @ Psi_inv_y) / (one.T @ Psi_inv_one)\n",
        "        mu_hat = mu_hat.item()\n",
        "        \n",
        "        # Berechne sigma_hat_sq (MLE der Prozessvarianz)\n",
        "        y_minus_mu_one = y_train - one * mu_hat\n",
        "        sigma_hat_sq = (y_minus_mu_one.T @ Psi_inv_y) / n\n",
        "        sigma_hat_sq = sigma_hat_sq.item()\n",
        "        \n",
        "        if sigma_hat_sq < 1e-10:\n",
        "            return 1e15\n",
        "        \n",
        "        # Berechne negative konzentrierte Log-Likelihood\n",
        "        log_det_Psi = 2 * np.sum(np.log(np.diag(U.T)))\n",
        "        nll = 0.5 * (n * np.log(sigma_hat_sq) + log_det_Psi)\n",
        "        \n",
        "        return nll\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Fit das Kriging-Modell an die Trainingsdaten.\n",
        "        \n",
        "        // ...existing docstring...\n",
        "        \"\"\"\n",
        "        self.X_train_ = X\n",
        "        self.y_train_ = y.reshape(-1, 1)\n",
        "        \n",
        "        # Optimierung der Hyperparameter\n",
        "        initial_theta = np.array([self.initial_theta])\n",
        "        result = minimize(self._neg_log_likelihood, \n",
        "                        initial_theta,\n",
        "                        args=(self.X_train_, self.y_train_),\n",
        "                        method='L-BFGS-B', \n",
        "                        bounds=self.bounds)\n",
        "        \n",
        "        self.opt_theta_ = result.x\n",
        "        \n",
        "        # Berechne optimale Parameter für Vorhersagen\n",
        "        Psi_opt = self._build_Psi(self.X_train_, self.opt_theta_)\n",
        "        self.U_ = cholesky(Psi_opt).T\n",
        "        n_train = self.X_train_.shape[0]\n",
        "        one = np.ones(n_train).reshape(-1, 1)\n",
        "        \n",
        "        self.mu_hat_ = (one.T @ solve(self.U_, solve(self.U_.T, self.y_train_))) / \\\n",
        "                      (one.T @ solve(self.U_, solve(self.U_.T, one)))\n",
        "        self.mu_hat_ = self.mu_hat_.item()\n",
        "        \n",
        "        return self\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\"Vorhersage für neue Datenpunkte.\n",
        "        \n",
        "        Args:\n",
        "            X (array-like): Eingabedaten für Vorhersage der Form (n_samples, n_features)\n",
        "            \n",
        "        Returns:\n",
        "            array: Vorhergesagte Werte\n",
        "        \"\"\"\n",
        "        n_train = self.X_train_.shape[0]\n",
        "        one = np.ones(n_train).reshape(-1, 1)\n",
        "        # Fix: Use self._build_psi instead of build_psi\n",
        "        psi = self._build_psi(self.X_train_, X, self.opt_theta_)\n",
        "        \n",
        "        return self.mu_hat_ * np.ones(X.shape[0]).reshape(-1, 1) + \\\n",
        "            psi.T @ solve(self.U_, solve(self.U_.T, \n",
        "            self.y_train_ - one * self.mu_hat_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def plot_kriging_results(X_train, y_train, X_test, y_test, y_pred, theta, figsize=(10, 6)):\n",
        "    \"\"\"Visualisiert die Kriging-Vorhersage im Vergleich zur wahren Funktion.\n",
        "    \n",
        "    Args:\n",
        "        X_train (array-like): Trainings-Eingabedaten\n",
        "        y_train (array-like): Trainings-Zielwerte\n",
        "        X_test (array-like): Test-Eingabedaten\n",
        "        y_test (array-like): Wahre Werte zum Vergleich\n",
        "        y_pred (array-like): Vorhersagewerte des Modells\n",
        "        theta (float): Optimierter Theta-Parameter\n",
        "        figsize (tuple, optional): Größe der Abbildung. Default ist (10, 6).\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=figsize)\n",
        "    \n",
        "    # Sortiere Test-Daten nach X-Werten für eine glatte Linie\n",
        "    sort_idx_test = np.argsort(X_test.ravel())\n",
        "    X_test_sorted = X_test[sort_idx_test]\n",
        "    y_test_sorted = y_test[sort_idx_test]\n",
        "    y_pred_sorted = y_pred[sort_idx_test]\n",
        "    \n",
        "    # Wahre Funktion\n",
        "    plt.plot(X_test_sorted, y_test_sorted, color=\"grey\", linestyle='--', \n",
        "            label=\"Wahre Sinusfunktion\")\n",
        "    \n",
        "    # Trainingspunkte\n",
        "    n_train = len(X_train)\n",
        "    plt.plot(X_train, y_train, \"bo\", markersize=8, \n",
        "            label=f\"Messpunkte ({n_train} Punkte)\")\n",
        "    \n",
        "    # Vorhersage\n",
        "    plt.plot(X_test_sorted, y_pred_sorted, color=\"orange\", \n",
        "            label=f\"Kriging-Vorhersage (Theta={theta:.2f})\")\n",
        "    \n",
        "    # Plot-Eigenschaften\n",
        "    plt.title(f\"Kriging-Vorhersage mit {n_train} Trainings-Punkten\\n\" + \n",
        "             f\"Optimierter Aktivitätsparameter Theta={theta:.2f}\")\n",
        "    plt.xlabel(\"x\")\n",
        "    plt.ylabel(\"y\")\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ein erste Beispielverwendung:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Generiere Trainingsdaten\n",
        "n_train = 4\n",
        "X_train = np.linspace(0, 2 * np.pi, n_train, endpoint=False).reshape(-1, 1)\n",
        "y_train = np.sin(X_train)\n",
        "\n",
        "# Erstelle und trainiere das Modell\n",
        "model = KrigingRegressor(initial_theta=1.0)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Generiere Testdaten\n",
        "X_test = np.linspace(0, 2 * np.pi, 100, endpoint=True).reshape(-1, 1)\n",
        "y_test = np.sin(X_test)\n",
        "\n",
        "# Mache Vorhersagen\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Visualisiere die Ergebnisse\n",
        "\n",
        "plot_kriging_results(\n",
        "    X_train=X_train,\n",
        "    y_train=y_train,\n",
        "    X_test=X_test,\n",
        "    y_test=y_test,\n",
        "    y_pred=y_pred,\n",
        "    theta=model.opt_theta_[0]\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ein zweites Beispiel mit train_test_split:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Generate sample data\n",
        "n_samples = 100\n",
        "X = np.linspace(0, 2 * np.pi, n_samples).reshape(-1, 1)\n",
        "y = np.sin(X)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=96, random_state=42)\n",
        "\n",
        "# Fit model\n",
        "model = KrigingRegressor(initial_theta=1)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Visualize results\n",
        "plot_kriging_results(\n",
        "    X_train=X_train,\n",
        "    y_train=y_train,\n",
        "    X_test=X_test,\n",
        "    y_test=y_test,\n",
        "    y_pred=y_pred,\n",
        "    theta=model.opt_theta_[0]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/bartz/miniforge3/envs/spot312/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}