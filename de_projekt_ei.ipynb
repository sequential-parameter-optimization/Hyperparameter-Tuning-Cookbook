{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "lang: de\n",
        "eval: true\n",
        "---\n",
        "\n",
        "\n",
        "# Lernmodul: Kriging Projekt mit Expected Improvement\n",
        "\n",
        "Dies ist ein erweitertes Lernmodul, das auf dem \"Lernmodul: Kriging Projekt\" aufbaut und \"Expected Improvement\" (EI) als Infill-Kriterium verwendet.\n",
        "\n",
        "\n",
        "## Einleitung\n",
        "Das vorhergehende \"Lernmodul: Kriging Projekt\" hat die Grundlagen der sequenziellen Optimierung mittels Kriging-Surrogatmodellen etabliert. Dabei wurde die nächste Evaluierungsstelle im Designraum einfach durch die Minimierung der Surrogatmodellvorhersage gewählt – ein Ansatz, der hauptsächlich auf **Exploitation** abzielt, also der Ausnutzung vielversprechender Regionen. In der Praxis ist es jedoch entscheidend, ein Gleichgewicht zwischen Exploitation und **Exploration** (Erkundung unsicherer Regionen) zu finden, insbesondere bei teuren Black-Box-Funktionen.\n",
        "\n",
        "Dieses Lernmodul erweitert den sequenziellen Optimierungsablauf, indem es **Expected Improvement (EI)** als Infill-Kriterium integriert. EI ist eine der einflussreichsten und am weitesten verbreiteten Methoden in der bayesianischen Optimierung, da sie Exploitation und Exploration auf elegante Weise in einem einzigen Kriterium vereint.\n",
        "\n",
        "## 1. Die KrigingRegressor-Klasse (Erweiterung)\n",
        "\n",
        "Die `KrigingRegressor`-Klasse, die bereits für die Berechnung der Korrelationsmatrizen, die Maximum-Likelihood-Schätzung der Hyperparameter ($\\hat{\\mu}$, $\\hat{\\sigma}^2$, $\\vec{\\theta}$) und die Vorhersagefunktion (`predict`) verwendet wurde, wird um eine Methode zur Berechnung des Expected Improvement erweitert.\n",
        "\n",
        "EI nutzt sowohl die **Vorhersage des Modells** ($\\hat{y}(\\vec{x})$) als auch die **Unsicherheit der Vorhersage** (Varianz $\\hat{s}^2(\\vec{x})$), die Kriging-Modelle bereitstellen können. Die Fähigkeit von Kriging, ein Maß für die Unsicherheit zu liefern, ist ein entscheidender Vorteil gegenüber einfacheren Surrogatmodellen wie Polynomen.\n",
        "\n",
        "## 2. Die Black-Box-Funktion `f(x)` (Wiederholung)\n",
        "Wie im vorherigen Modul simuliert die Black-Box-Funktion `f(x)` ein teures oder undurchsichtiges System. Für dieses Beispiel verwenden wir weiterhin eine analytische Funktion, um die Prinzipien zu demonstrieren.\n",
        "\n",
        "## 3. Initialer Stichprobenplan `X` (Wiederholung)\n",
        "Der Prozess beginnt mit einem initialen Stichprobenplan, der typischerweise mittels **Latin Hypercube Sampling (LHS)** erstellt wird. LHS ist eine **raumfüllende** Technik, die sicherstellt, dass der Eingaberaum effizient und gleichmäßig erkundet wird, was eine gute Ausgangsbasis für das Kriging-Modell bietet.\n",
        "\n",
        "## 4. Sequenzieller Optimierungsablauf mit Expected Improvement\n",
        "Der iterative Prozess der sequenziellen Optimierung wird wie folgt angepasst:\n",
        "\n",
        "1.  **Initialisierung**: Ein initialer Stichprobenplan `X` wird erstellt und die Black-Box-Funktion `f` an diesen Punkten evaluiert, um die Beobachtungen `y` zu erhalten.\n",
        "2.  **Kriging-Modell anpassen**: Das Kriging-Modell wird mit den gesammelten Daten (`X`, `y`) angepasst. Hierbei werden die Hyperparameter (insbesondere $\\vec{\\theta}$) mittels Maximum-Likelihood-Schätzung optimiert.\n",
        "3.  **Expected Improvement (EI) berechnen**: Für eine Vielzahl von Kandidatenpunkten im Designraum wird das Expected Improvement berechnet. EI quantifiziert den erwarteten Gewinn, wenn man die Black-Box an einem bestimmten Punkt evaluiert, im Vergleich zum besten bisher beobachteten Wert (`y_min`). Die Formel für EI lautet:\n",
        "    $$ E[I(\\vec{x})] = (\\hat{y}_{min} - \\hat{y}(\\vec{x})) \\cdot \\Phi\\left(\\frac{\\hat{y}_{min} - \\hat{y}(\\vec{x})}{\\hat{s}(\\vec{x})}\\right) + \\hat{s}(\\vec{x}) \\cdot \\phi\\left(\\frac{\\hat{y}_{min} - \\hat{y}(\\vec{x})}{\\hat{s}(\\vec{x})}\\right) $$\n",
        "    wobei:\n",
        "    *   $\\hat{y}_{min}$ der beste bisher beobachtete Funktionswert ist.\n",
        "    *   $\\hat{y}(\\vec{x})$ die Kriging-Vorhersage am Punkt $\\vec{x}$ ist.\n",
        "    *   $\\hat{s}(\\vec{x})$ die geschätzte Standardabweichung (Wurzel aus der Varianz) der Vorhersage am Punkt $\\vec{x}$ ist.\n",
        "    *   $\\Phi$ die kumulative Verteilungsfunktion (CDF) und $\\phi$ die Wahrscheinlichkeitsdichtefunktion (PDF) der Standardnormalverteilung sind.\n",
        "    *   Ein Wert von 0 wird zurückgegeben, wenn $\\hat{s}(\\vec{x}) = 0$ (d.h. an einem bereits beprobten Punkt ist die Unsicherheit null).\n",
        "\n",
        "4.  **Nächsten Infill-Punkt auswählen**: Anstatt den Punkt mit der besten Vorhersage zu wählen, wird der Punkt ausgewählt, der das **Expected Improvement maximiert**. Da die meisten Optimierungsalgorithmen auf Minimierung ausgelegt sind, wird üblicherweise die **negative Expected Improvement**-Funktion minimiert.\n",
        "5.  **Evaluierung und Aktualisierung**: Der ausgewählte Punkt wird der teuren Black-Box-Funktion übergeben, die Beobachtung wird zum Trainingsdatensatz hinzugefügt, und der Prozess wird iteriert.\n",
        "\n",
        "**Vorteile von EI:**\n",
        "*   **Automatisches Gleichgewicht**: EI balanciert Exploration und Exploitation automatisch, ohne manuelle Gewichtungsparameter.\n",
        "*   **Theoretische Fundierung**: Es hat eine starke theoretische Rechtfertigung aus der Entscheidungstheorie.\n",
        "*   **Effiziente Optimierung**: Die differenzierbare Natur von EI macht es für gradientenbasierte Optimierungsalgorithmen geeignet.\n",
        "*   **Globale Konvergenz**: Eine Maximierung von EI führt letztendlich zum globalen Optimum, da EI an beprobten Punkten auf null fällt, was die Suche in ungesampelte, unsichere oder vielversprechende Bereiche lenkt.\n",
        "\n",
        "## Der entsprechende Python-Code:\n",
        "\n",
        "Für dieses Modul simulieren wir eine `KrigingRegressor`-Klasse, die die notwendigen `fit`, `predict` und `expected_improvement` Methoden enthält. Der Fokus des Codes liegt auf dem angepassten sequenziellen Optimierungsablauf."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import minimize\n",
        "from scipy.stats import norm\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy.linalg import cholesky, solve\n",
        "from scipy.spatial.distance import pdist, squareform, cdist\n",
        "\n",
        "#1. Die KrigingRegressor-Klasse (erweitert um Expected Improvement)\n",
        "# Für dieses Beispiel vereinfachen wir die Implementierung,\n",
        "# um den Fokus auf Expected Improvement zu legen.\n",
        "# Eine vollständige Implementierung wäre umfangreicher.\n",
        "class KrigingRegressor:\n",
        "    def __init__(self, theta=None, p=2.0, eps=np.sqrt(np.spacing(1))):\n",
        "        self.theta = theta if theta is not None else np.array([1.0]) # Aktivitätshyperparameter\n",
        "        self.p = p # Glattheitsparameter, hier fest auf 2.0 (sqeuclidean)\n",
        "        self.eps = eps # Nugget-Effekt für numerische Stabilität\n",
        "        self.X_train = None\n",
        "        self.y_train = None\n",
        "        self.mu_hat = None\n",
        "        self.sigma_hat_sq = None\n",
        "        self.Psi = None\n",
        "        self.U = None # Cholesky-Faktor\n",
        "\n",
        "    def _build_psi_matrix(self, X_data, w=None):\n",
        "        \"\"\"Berechnet die Korrelationsmatrix Psi mit gewichteter quadrierter euklidischer Distanz.\n",
        "        \n",
        "        Args:\n",
        "            X_data (np.ndarray): Eingabedaten-Matrix\n",
        "            w (np.ndarray, optional): Gewichtungsparameter (theta)\n",
        "            \n",
        "        Returns:\n",
        "            np.ndarray: Korrelationsmatrix Psi\n",
        "        \"\"\"\n",
        "        if w is None:\n",
        "            w = self.theta\n",
        "        \n",
        "        D = squareform(pdist(X_data, metric='sqeuclidean', w=w))\n",
        "        Psi = np.exp(-D)\n",
        "        \n",
        "        # Nugget-Effekt für numerische Stabilität - verwende die Anzahl der Datenpunkte\n",
        "        n_points = X_data.shape[0]  # Anzahl der Zeilen (Datenpunkte)\n",
        "        Psi += np.multiply(np.eye(n_points), self.eps)\n",
        "        \n",
        "        return Psi\n",
        "\n",
        "    def _build_psi_vector(self, X_predict, X_train, w=None):\n",
        "        # Berechnet den Korrelationsvektor psi zwischen Vorhersage- und Trainingspunkten\n",
        "        if w is None:\n",
        "            w = self.theta\n",
        "        D = cdist(X_predict, X_train, metric='sqeuclidean', w=w)\n",
        "        psi = np.exp(-D)\n",
        "        return psi.T # Transponieren, um n x m oder n x 1 zu erhalten\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        \"\"\"Trainiert das Kriging-Modell auf den gegebenen Daten.\n",
        "        \n",
        "        Args:\n",
        "            X_train (np.ndarray): Trainings-Eingabedaten\n",
        "            y_train (np.ndarray): Trainings-Zielwerte\n",
        "        \"\"\"\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        n = self.X_train.shape[0]  # Anzahl der Datenpunkte, nicht die gesamte Shape\n",
        "\n",
        "        # Numerisch stabile Berechnung der Psi-Matrix\n",
        "        self.Psi = self._build_psi_matrix(self.X_train)\n",
        "\n",
        "        # Cholesky-Zerlegung für effiziente Inversion\n",
        "        # U ist der obere Dreiecksfaktor (Transponierte des unteren)\n",
        "        try:\n",
        "            self.U = cholesky(self.Psi).T\n",
        "        except np.linalg.LinAlgError:\n",
        "            print(\"Cholesky-Zerlegung fehlgeschlagen, Matrix ist nicht positiv definit.\")\n",
        "            # Fallback oder Fehlerbehandlung, z.B. größeren Nugget-Term verwenden\n",
        "            self.Psi = self._build_psi_matrix(self.X_train, self.theta + 1e-6)\n",
        "            self.U = cholesky(self.Psi).T\n",
        "\n",
        "        # Berechnung von mu_hat (geschätzter globaler Mittelwert)\n",
        "        one_vec = np.ones((n, 1))\n",
        "        # solve(U, solve(U.T, vec)) ist äquivalent zu inv(Psi) @ vec unter Verwendung von Cholesky\n",
        "        self.mu_hat = (one_vec.T @ solve(self.U, solve(self.U.T, self.y_train))) / \\\n",
        "                    (one_vec.T @ solve(self.U, solve(self.U.T, one_vec)))\n",
        "        self.mu_hat = self.mu_hat.item() # Extrahiere Skalarwert\n",
        "\n",
        "        # Berechnung von sigma_hat_sq (geschätzte Prozessvarianz)\n",
        "        self.sigma_hat_sq = ((self.y_train - one_vec * self.mu_hat).T @ \\\n",
        "                            solve(self.U, solve(self.U.T, self.y_train - one_vec * self.mu_hat))) / n\n",
        "        self.sigma_hat_sq = self.sigma_hat_sq.item()\n",
        "\n",
        "    def predict(self, X_predict):\n",
        "        \"\"\"Vorhersage für neue Datenpunkte.\n",
        "        \n",
        "        Args:\n",
        "            X_predict (np.ndarray): Eingabedaten für Vorhersage\n",
        "            \n",
        "        Returns:\n",
        "            np.ndarray: Vorhergesagte Werte\n",
        "        \"\"\"\n",
        "        if self.X_train is None or self.y_train is None:\n",
        "            raise ValueError(\"Modell muss zuerst mit fit() trainiert werden.\")\n",
        "\n",
        "        m = X_predict.shape[0]  # Anzahl der Vorhersagepunkte\n",
        "        n = self.X_train.shape[0]  # Anzahl der Trainingspunkte\n",
        "        \n",
        "        one_vec_m = np.ones((m, 1))\n",
        "        one_vec_n = np.ones((n, 1))\n",
        "\n",
        "        psi_vec = self._build_psi_vector(X_predict, self.X_train)\n",
        "\n",
        "        # BLUP-Formel: y_hat(x) = mu_hat + psi.T @ inv(Psi) @ (y_train - 1 * mu_hat)\n",
        "        f_predict = self.mu_hat * one_vec_m + \\\n",
        "                    psi_vec.T @ solve(self.U, solve(self.U.T, self.y_train - one_vec_n * self.mu_hat))\n",
        "        return f_predict.flatten()\n",
        "\n",
        "    def predict_variance(self, X_predict):\n",
        "        if self.X_train is None or self.y_train is None:\n",
        "            raise ValueError(\"Modell muss zuerst mit fit() trainiert werden.\")\n",
        "\n",
        "        psi_vec = self._build_psi_vector(X_predict, self.X_train)\n",
        "        \n",
        "        # Geschätzter Fehler (Varianz) s^2(x)\n",
        "        # s^2(x) = sigma_hat_sq * (1 - psi.T @ inv(Psi) @ psi)\n",
        "        s_sq = self.sigma_hat_sq * (1 - np.diag(psi_vec.T @ solve(self.U, solve(self.U.T, psi_vec))))\n",
        "        # Sicherstellen, dass die Varianz nicht negativ ist (numerische Stabilität)\n",
        "        s_sq[s_sq < 1e-10] = 1e-10 \n",
        "        return s_sq.flatten()\n",
        "\n",
        "    def expected_improvement(self, x_cand, y_min_current):\n",
        "        # x_cand sollte ein 2D-Array sein, auch für 1D-Probleme: np.array([[x]])\n",
        "        mu_cand = self.predict(x_cand) # y_hat(x)\n",
        "        s_cand = np.sqrt(self.predict_variance(x_cand)) # s(x)\n",
        "\n",
        "        # Handhabung für s_cand == 0 (bereits beprobte Punkte)\n",
        "        # Vermeidet Division durch Null und gibt EI = 0 zurück\n",
        "        ei_values = np.zeros_like(mu_cand)\n",
        "        \n",
        "        # Indizes, wo s_cand > 0 ist\n",
        "        positive_s_indices = s_cand > 1e-10 \n",
        "\n",
        "        if np.any(positive_s_indices):\n",
        "            s_pos = s_cand[positive_s_indices]\n",
        "            mu_pos = mu_cand[positive_s_indices]\n",
        "            \n",
        "            Z = (y_min_current - mu_pos) / s_pos\n",
        "            \n",
        "            # Formel für Expected Improvement\n",
        "            # EI = (ymin - y_hat) * Phi(Z) + s * phi(Z)\n",
        "            ei_values[positive_s_indices] = (y_min_current - mu_pos) * norm.cdf(Z) + s_pos * norm.pdf(Z)\n",
        "        \n",
        "        # Sicherstellen, dass EI nicht negativ wird (numerische Stabilität)\n",
        "        ei_values[ei_values < 0] = 0\n",
        "        return ei_values\n",
        "\n",
        "    def _neg_expected_improvement(self, x_cand_flat, y_min_current):\n",
        "        # Wrapper für die Optimierung, erwartet flaches x_cand\n",
        "        x_cand = np.array(x_cand_flat).reshape(1, -1) # Formatiere zu 2D\n",
        "        ei = self.expected_improvement(x_cand, y_min_current)\n",
        "        # Minimierungsziel ist negatives EI\n",
        "        return -ei # EI ist hier ein Skalar, daher "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Die Black-Box-Funktion f(x)\n",
        "\n",
        "Beispiel: Sinusfunktion mit hinzugefügtem (optionalem) Rauschen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def f(x_val):\n",
        "    # Standardisierung von x_val von zu [0, 2*pi] für die Sinusfunktion\n",
        "    # Annahme, dass die Optimierung in^k durchgeführt wird und die Blackbox \n",
        "    # intern die Skalierung handhabt.\n",
        "    # Für dieses Beispiel behalten wir die direkte Nutzung der Sinusfunktion.\n",
        "    return np.sin(x_val) # + np.random.normal(0, 0.05) # Optional: Rauschen hinzufügen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#3. Initialer Stichprobenplan X (Latin Hypercube Sampling)\n",
        "\n",
        "Implementierung eines einfachen LHS für 1D für das Beispiel\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def latin_hypercube_sampling(n_points, n_dims, lower_bound=0, upper_bound=1):\n",
        "    \"\"\"Erstellt Latin Hypercube Samples im gegebenen Bereich.\n",
        "    \n",
        "    Args:\n",
        "        n_points (int): Anzahl der zu generierenden Punkte\n",
        "        n_dims (int): Anzahl der Dimensionen\n",
        "        lower_bound (float): Untere Grenze des Suchraums\n",
        "        upper_bound (float): Obere Grenze des Suchraums\n",
        "        \n",
        "    Returns:\n",
        "        np.ndarray: Array der Form (n_points, n_dims) mit LHS-Samples\n",
        "    \"\"\"\n",
        "    points = np.zeros((n_points, n_dims))\n",
        "    \n",
        "    for i in range(n_dims):\n",
        "        # Erstelle n_points gleichmäßige Intervalle\n",
        "        bins = np.linspace(lower_bound, upper_bound, n_points + 1)\n",
        "        \n",
        "        # Berechne die Intervallbreite\n",
        "        interval_width = (upper_bound - lower_bound) / n_points\n",
        "        \n",
        "        # Generiere zufällige Offsets innerhalb jedes Intervalls\n",
        "        random_offsets = np.random.rand(n_points) * interval_width\n",
        "        \n",
        "        # Setze Punkte in jedes Intervall\n",
        "        points[:, i] = bins[:-1] + random_offsets\n",
        "        \n",
        "        # Permutiere die Punkte für jede Dimension (wichtig für LHS)\n",
        "        np.random.shuffle(points[:, i])\n",
        "    \n",
        "    return points"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hauptskript für die sequentielle Optimierung"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "n_initial_points = 5 # Anzahl der initialen Stichprobenpunkte\n",
        "n_infill_points = 10 # Anzahl der hinzuzufügenden Infill-Punkte\n",
        "n_dimensions = 1     # Problem-Dimension (für sin(x) ist k=1)\n",
        "\n",
        "# 1. Initialisierung: Initialer Stichprobenplan und Evaluierung\n",
        "# x-Werte im Bereich für die Optimierung\n",
        "X_initial = latin_hypercube_sampling(n_initial_points, n_dimensions)\n",
        "# y-Werte im Bereich [0, 2*pi] für die Sinusfunktion\n",
        "# Wir skalieren X_initial für die f-Funktion, wenn f in einem anderen Bereich definiert ist.\n",
        "# Für Sin(x) verwenden wir direkt X_initial skaliert auf [0, 2*pi]\n",
        "X_train_scaled = X_initial * (2 * np.pi) # Skalierung für sin(x)\n",
        "y_train = np.array([f(x_val) for x_val in X_train_scaled]).reshape(-1, 1)\n",
        "X_train = X_initial # Behalte X_train in für KrigingRegressor\n",
        "\n",
        "# Initialisiere KrigingRegressor\n",
        "kriging_model = KrigingRegressor()\n",
        "kriging_model.fit(X_train, y_train)\n",
        "\n",
        "# Speicher für die Visualisierung\n",
        "all_X = X_train.copy()\n",
        "all_y = y_train.copy()\n",
        "\n",
        "# Range für die Vorhersage/Visualisierung\n",
        "x_plot = np.linspace(0, 1, 100).reshape(-1, 1) # Im standardisierten Bereich\n",
        "x_plot_scaled = x_plot * (2 * np.pi) # Skalieren für die wahre Funktion\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(x_plot_scaled, f(x_plot_scaled), 'grey', linestyle='--', label='Wahre Sinusfunktion')\n",
        "plt.plot(all_X * (2 * np.pi), all_y, 'bo', markersize=8, label='Messungen (Initial)')\n",
        "plt.title('Sequenzielle Optimierung mit Expected Improvement')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Sequenzieller Optimierungsablauf\n",
        "for i in range(n_infill_points):\n",
        "    print(f\"\\n--- Iteration {i+1}: Suche Infill-Punkt mittels Expected Improvement ---\")\n",
        "    \n",
        "    # Besten bisher beobachteten Wert finden (für Minimierungsproblem)\n",
        "    y_min_current = np.min(all_y)\n",
        "    print(f\"Bester bisheriger Wert (y_min): {np.round(y_min_current, 4)}\")\n",
        "\n",
        "    # Suchgrenzen für die Optimierung auf dem Surrogatmodell (im Einheitshyperwürfel)\n",
        "    # Für 1D ist es einfach\n",
        "    bounds = [(0, 1)] * n_dimensions\n",
        "\n",
        "    # Optimierung des Surrogatmodells zur Suche des nächsten Infill-Punktes\n",
        "    # Wir minimieren die negative Expected Improvement\n",
        "    # Starte die Suche von mehreren zufälligen Punkten, um lokale Minima zu vermeiden\n",
        "    num_restarts = 5\n",
        "    best_ei_val = -np.inf\n",
        "    next_x_infill = None\n",
        "\n",
        "    for _ in range(num_restarts):\n",
        "        # Zufälliger Startpunkt innerhalb der Grenzen\n",
        "        x0 = np.random.rand(n_dimensions) \n",
        "        \n",
        "        res = minimize(kriging_model._neg_expected_improvement, x0, \n",
        "                        args=(y_min_current,), \n",
        "                        bounds=bounds, \n",
        "                        method='L-BFGS-B') # Oder andere geeignete Methode\n",
        "        \n",
        "        # EI ist der negative Wert des Ergebnisses der Minimierung\n",
        "        current_ei_val = -res.fun \n",
        "        \n",
        "        if current_ei_val > best_ei_val:\n",
        "            best_ei_val = current_ei_val\n",
        "            next_x_infill = res.x\n",
        "    \n",
        "    if next_x_infill is None:\n",
        "        # Fallback, falls Optimierung fehlschlägt, z.B. zufälligen Punkt wählen\n",
        "        next_x_infill = np.random.rand(n_dimensions)\n",
        "        print(\"Warnung: EI-Optimierung fehlgeschlagen, wähle zufälligen Punkt.\")\n",
        "\n",
        "    # Stelle sicher, dass next_x_infill 2D ist für die predict-Methoden\n",
        "    next_x_infill_2d = next_x_infill.reshape(1, -1)\n",
        "\n",
        "    print(f\"Gewählter Infill-Punkt (standardisiert): {np.round(next_x_infill, 4)}\")\n",
        "    print(f\"Geschätztes EI am Infill-Punkt: {np.round(best_ei_val, 4)}\")\n",
        "\n",
        "    # Evaluierung des Infill-Punktes auf der realen Black-Box-Funktion\n",
        "    # Skaliere den Infill-Punkt für die f-Funktion\n",
        "    next_x_infill_scaled = next_x_infill * (2 * np.pi)\n",
        "    y_new = np.array([f(next_x_infill_scaled)]).reshape(-1, 1)\n",
        "    print(f\"Tatsächlicher Wert am Infill-Punkt: {np.round(y_new.item(), 4)}\")\n",
        "\n",
        "    # Daten zum Trainingssatz hinzufügen\n",
        "    all_X = np.vstack((all_X, next_x_infill_2d))\n",
        "    all_y = np.vstack((all_y, y_new))\n",
        "\n",
        "    # Kriging-Modell neu anpassen mit den aktualisierten Daten\n",
        "    kriging_model.fit(all_X, all_y)\n",
        "\n",
        "    # Visualisierung des aktuellen Zustands\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    # Plot auf der ersten Y-Achse (linke Seite)\n",
        "    ax1 = plt.gca()\n",
        "    ax1.plot(x_plot_scaled, f(x_plot_scaled), 'grey', linestyle='--', label='Wahre Sinusfunktion')\n",
        "    ax1.plot(x_plot_scaled, kriging_model.predict(x_plot), 'orange', label='Kriging Vorhersage')\n",
        "    ax1.plot(all_X[:-1] * (2 * np.pi), all_y[:-1], 'bo', markersize=8, label='Messungen (bisher)')\n",
        "    ax1.plot(all_X[-1] * (2 * np.pi), all_y[-1], 'ro', markersize=10, label='Neuer Infill-Punkt')\n",
        "    ax1.set_xlabel('x')\n",
        "    ax1.set_ylabel('y')\n",
        "    ax1.grid(True)\n",
        "\n",
        "    # Plot Expected Improvement auf der zweiten Y-Achse (rechte Seite)\n",
        "    ax2 = ax1.twinx()\n",
        "    ei_values_plot = kriging_model.expected_improvement(x_plot, y_min_current)\n",
        "    ax2.plot(x_plot_scaled, ei_values_plot, 'g:', label='Expected Improvement (EI)')\n",
        "    ax2.set_ylabel('Expected Improvement', color='g')\n",
        "    ax2.tick_params(axis='y', labelcolor='g')\n",
        "\n",
        "    plt.title(f'Iteration {i+1}: Kriging Vorhersage und EI (y_min={np.round(y_min_current, 4)})')\n",
        "\n",
        "    # Korrekte Behandlung der Legenden von beiden Achsen\n",
        "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
        "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
        "    ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper right')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "print(\"\\n--- Optimierung abgeschlossen ---\")\n",
        "print(f\"Finaler bester Wert gefunden: {np.round(np.min(all_y).item(), 4)}\")\n",
        "print(f\"Gesamtzahl der Evaluierungen: {len(all_y)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ergebnisse und Diskussion\n",
        "Der angepasste Code demonstriert die Funktionsweise von Expected Improvement. In jeder Iteration wird nicht nur die Kriging-Vorhersage aktualisiert, sondern auch das Expected Improvement über den gesamten Designraum berechnet und visualisiert.\n",
        "\n",
        "*   **Visuelle Darstellung**: Sie werden sehen, dass die \"Expected Improvement\"-Kurve (grün gestrichelt) in Bereichen mit niedriger Vorhersage (gut für Exploitation) und/oder hoher Unsicherheit (gut für Exploration) hohe Werte aufweist. Der neue Infill-Punkt (roter Kreis) wird typischerweise an der Spitze eines solchen EI-Peaks platziert.\n",
        "*   **Gleichgewicht**: Im Gegensatz zur reinen Minimierung der Vorhersage, die dazu neigen könnte, in lokalen Minima stecken zu bleiben, fördert EI die Erkundung von Regionen, in denen das Modell unsicher ist, auch wenn die aktuelle Vorhersage dort nicht optimal ist. Dies ist besonders vorteilhaft bei multimodalen Funktionen oder wenn die initialen Stichproben den Designraum nicht vollständig abdecken.\n",
        "*   **Konvergenz**: Durch die kontinuierliche Hinzufügung von Punkten mit hohem Expected Improvement wird das Modell schrittweise genauer, und die Suche wird effizienter auf das globale Optimum hingeführt. Die EI-Werte nehmen typischerweise ab, wenn das Modell sicherer wird und das Optimum gefunden wird.\n",
        "\n",
        "Dieses Modul zeigt, wie die Integration von Expected Improvement die Effizienz und Robustheit der sequenziellen Optimierung mit Kriging-Modellen erheblich verbessert, indem es eine intelligente Strategie zur Auswahl des nächsten Funktionsauswertungspunkts bereitstellt."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/bartz/miniforge3/envs/spot312/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}