{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "execute:\n",
        "  cache: false\n",
        "  eval: true\n",
        "  echo: true\n",
        "  warning: false\n",
        "jupyter: python3\n",
        "---\n",
        "\n",
        "# Hyperparameter Tuning with PyTorch Lightning and User Data Sets  {#sec-light-user-data-1001}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: false\n",
        "#| label: 1001_user_data_imports\n",
        "import numpy as np\n",
        "import os\n",
        "from math import inf\n",
        "import numpy as np\n",
        "import warnings\n",
        "if not os.path.exists('./figures'):\n",
        "    os.makedirs('./figures')\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this section, we will show how user specfied data can be used for the `PyTorch` Lightning hyperparameter tuning workflow with `spotpython`.\n",
        "\n",
        "## Loading a User Specified Data Set\n",
        "\n",
        "Using a user-specified data set is straightforward.\n",
        "\n",
        "The user simply needs to provide a data set and loads is as a  `spotpython`  `CVSDataset()` class by specifying the path, filename, and target column.\n",
        "\n",
        "Consider the following example, where the user has a data set stored in the `userData` directory. The data set is stored in a file named `data.csv`. The target column is named `target`. To show the data, it is loaded as a `pandas` data frame and the first 5 rows are displayed. This step is not necessary for the hyperparameter tuning process, but it is useful for understanding the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import pandas as pd\n",
        "\n",
        "# from utils import *\n",
        "# from train import *\n",
        "\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = 'cpu'\n",
        "epochs = 2000\n",
        "seeds = [42, 43, 44, 45, 46, 47, 48, 49, 50, 51]\n",
        "input_features = ['PI tot V [-]', 'Bereich u2red']\n",
        "data = pd.read_csv(\"/Users/bartz/workspace/schu25a_netgen_gecco/data/data_man_tca88.csv\")\n",
        "data[\"source_file\"] = [\"tca88\"] * len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ManyToManyDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        df_list,\n",
        "        target,\n",
        "        drop=None,\n",
        "        dtype=torch.float32,\n",
        "    ):\n",
        "        try: \n",
        "            self.data = [df.drop(drop, axis=1) for df in df_list]\n",
        "        except:\n",
        "            self.data = df_list\n",
        "        self.target = [torch.tensor(df[target].to_numpy(), dtype=dtype) for df in self.data]\n",
        "        self.features = [torch.tensor(df.drop([target], axis=1).to_numpy(), dtype=dtype)for df in self.data]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.features[index]\n",
        "        y = self.target[index]\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    \n",
        "class ManyToOneDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        df_list,\n",
        "        target,\n",
        "        drop=None,\n",
        "        dtype=torch.float32,\n",
        "    ):\n",
        "        try: \n",
        "            self.data = [df.drop(drop, axis=1) for df in df_list]\n",
        "        except:\n",
        "            self.data = df_list\n",
        "        self.target = [torch.tensor(df[target].to_numpy()[0], dtype=dtype) for df in self.data]\n",
        "        self.features = [torch.tensor(df.drop([target], axis=1).to_numpy(), dtype=dtype)for df in self.data]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.features[index]\n",
        "        y = self.target[index]\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data(data,\n",
        "              input_features=['V tot V red [m³/s]'], \n",
        "              target= 'PI tot V [-]' ,\n",
        "              drop = ['Bereich u2red','source_file'],\n",
        "              group_by='Bereich u2red',\n",
        "              feature_scaling=None, \n",
        "              target_scaling=None, \n",
        "              create_dataset=True, \n",
        "              dataset_type='many_to_many'):\n",
        "\n",
        "    if feature_scaling is not None:\n",
        "        data[input_features] = feature_scaling.fit_transform(data[input_features])\n",
        "    \n",
        "    if target_scaling is not None:\n",
        "        data[target] = target_scaling.fit_transform(data[target])    \n",
        "    \n",
        "    if create_dataset == False:\n",
        "        return data\n",
        "    else:\n",
        "        groups = []\n",
        "        groups_name = []\n",
        "        data_groups = data.groupby(group_by)\n",
        "\n",
        "    for name, group in data_groups:\n",
        "        groups.append(group)\n",
        "        groups_name.append(name)\n",
        "    \n",
        "    if dataset_type == 'many_to_many':\n",
        "        return ManyToManyDataset(groups, target=target, drop=drop), data\n",
        "    elif dataset_type == \"many_to_one\":\n",
        "        return ManyToOneDataset(groups, target=target, drop=drop), data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "kennlinienfeld: tca88\n",
            "tca88\n",
            "seed: 42\n",
            "indices: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
            "indices: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
            "indices: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
            "indices: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
            "indices: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
            "indices: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
            "indices: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
            "indices: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
            "indices: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n"
          ]
        }
      ],
      "source": [
        "kennlinienfelder = data.groupby(\"source_file\")\n",
        "pred_dict = {}\n",
        "\n",
        "seeds = [42]\n",
        "for kennlinienfeld in kennlinienfelder:\n",
        "    print(f\"kennlinienfeld: {kennlinienfeld[0]}\")\n",
        "    data_name = kennlinienfeld[0]\n",
        "    print(data_name)\n",
        "    ds, data = ds, _ = load_data(kennlinienfeld[1], \n",
        "                                input_features=['PI tot V [-]' ], \n",
        "                                target='V tot V red [m³/s]',\n",
        "                                drop = ['source_file', \"Bereich u2red\"],\n",
        "                                group_by=\"Bereich u2red\",\n",
        "                                # feature_scaling=MinMaxScaler()\n",
        "                                )\n",
        "    \n",
        "    pred_dict[data_name] = {}\n",
        "\n",
        "    for seed in seeds:\n",
        "        print(f\"seed: {seed}\")\n",
        "        # seed_everything(seed)\n",
        "        g = torch.Generator()\n",
        "        g.manual_seed(seed)\n",
        "        \n",
        "        pred_dict[data_name][seed] = {}\n",
        "        pred_dict[data_name][seed]['x'] = []\n",
        "        pred_dict[data_name][seed]['y_hat'] = []\n",
        "        pred_dict[data_name][seed]['y'] = []\n",
        "        pred_dict[data_name][seed]['mape'] = []\n",
        "        pred_dict[data_name][seed]['rmse'] = []\n",
        "        \n",
        "        # Create indices for the split\n",
        "        indices = list(range(len(ds)))        \n",
        "        for i in indices:\n",
        "            print(f\"indices: {indices}\")\n",
        "            test_indices = [indices[i]]\n",
        "            train_indices = [index for index in indices if index != test_indices[0]]\n",
        "            \n",
        "            train_dataset = torch.utils.data.Subset(ds, train_indices)\n",
        "            test_dataset = torch.utils.data.Subset(ds, test_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following step is not necessary for the hyperparameter tuning process, but it is useful for understanding the data. The data set is loaded as a `DataLoader` from `torch.utils.data` to check the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch Size: 1\n",
            "Inputs Shape: torch.Size([1, 6, 1])\n",
            "Targets Shape: torch.Size([1, 6])\n",
            "---------------\n",
            "Inputs: tensor([[[1.2800],\n",
            "         [1.4400],\n",
            "         [1.4700],\n",
            "         [1.4900],\n",
            "         [1.5100],\n",
            "         [1.5400]]])\n",
            "Targets: tensor([[2.0100, 1.7700, 1.6800, 1.5900, 1.4500, 1.0400]])\n"
          ]
        }
      ],
      "source": [
        "#| label: 1001_user_data_dataloader\n",
        "# Set batch size for DataLoader\n",
        "batch_size = 1\n",
        "# Create DataLoader\n",
        "from torch.utils.data import DataLoader\n",
        "dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Iterate over the data in the DataLoader\n",
        "for batch in dataloader:\n",
        "    inputs, targets = batch\n",
        "    print(f\"Batch Size: {inputs.size(0)}\")\n",
        "    print(f\"Inputs Shape: {inputs.shape}\")\n",
        "    print(f\"Targets Shape: {targets.shape}\")\n",
        "    print(\"---------------\")\n",
        "    print(f\"Inputs: {inputs}\")\n",
        "    print(f\"Targets: {targets}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set size: 2\n"
          ]
        }
      ],
      "source": [
        "from spotpython.data.lightdatamodule import LightDataModule\n",
        "data_module = LightDataModule(dataset=train_dataset, batch_size=5, test_size=0.5)\n",
        "data_module.setup()\n",
        "print(f\"Training set size: {len(data_module.data_train)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8, 1)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_dataset), len(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Seed set to 123\n",
            "Seed set to 123\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moving TENSORBOARD_PATH: runs/ to TENSORBOARD_PATH_OLD: runs_OLD/runs_2025_01_27_19_26_44_0\n",
            "Created spot_tensorboard_path: runs/spot_logs/1001_bartz11_2025-01-27_19-26-44 for SummaryWriter()\n",
            "module_name: light\n",
            "submodule_name: regression\n",
            "model_name: ManyToManyRNNRegressor\n",
            "_init_spot_writer(): Created spot_tensorboard_path: runs/spot_logs/1001_bartz11_2025-01-27_19-26-44 for SummaryWriter()\n"
          ]
        }
      ],
      "source": [
        "from spotpython.hyperdict.light_hyper_dict import LightHyperDict\n",
        "from spotpython.fun.hyperlight import HyperLight\n",
        "from spotpython.utils.init import (fun_control_init, surrogate_control_init, design_control_init)\n",
        "from spotpython.utils.eda import print_res_table\n",
        "from spotpython.hyperparameters.values import set_hyperparameter\n",
        "from spotpython.spot import Spot\n",
        "from math import inf\n",
        "\n",
        "\n",
        "fun_control=fun_control_init(\n",
        "    penalty_NA=1000,\n",
        "    ocba_delta=1,\n",
        "    TENSORBOARD_CLEAN=True,\n",
        "    tensorboard_log=True,\n",
        "    accelerator=\"cpu\",\n",
        "    collate_fn_name=\"PadSequenceManyToMany\",\n",
        "    show_config=True,\n",
        "    verbosity=1,\n",
        "    save_experiment=False,\n",
        "    save_result=True,\n",
        "    PREFIX=\"1001\",\n",
        "    fun_evals=inf,\n",
        "    fun_repeats=2,\n",
        "    max_time=1,\n",
        "    data_full_train = train_dataset,\n",
        "    data_val=test_dataset,\n",
        "    data_test=test_dataset,\n",
        "    shuffle_train=False,\n",
        "    shuffle_val=False,    \n",
        "    core_model_name=\"light.regression.ManyToManyRNNRegressor\",\n",
        "    hyperdict=LightHyperDict,\n",
        "    log_level=50,\n",
        "    _L_in=1,\n",
        "    _L_out=1)\n",
        "\n",
        "# set_hyperparameter(fun_control, \"optimizer\", [ \"Adadelta\", \"Adam\", \"Adamax\"])\n",
        "set_hyperparameter(fun_control, \"rnn_units\", [6, 12])\n",
        "set_hyperparameter(fun_control, \"fc_units\", [6, 12])\n",
        "set_hyperparameter(fun_control, \"epochs\", [12 , 16])\n",
        "set_hyperparameter(fun_control, \"batch_size\", [6,12])\n",
        "set_hyperparameter(fun_control, \"dropout_prob\", [0.0, 0.025])\n",
        "set_hyperparameter(fun_control, \"patience\", [5,10])\n",
        "set_hyperparameter(fun_control, \"lr_mult\", [0.1, 20.0])\n",
        "\n",
        "design_control = design_control_init(init_size=20, repeats=2)\n",
        "\n",
        "surrogate_control = surrogate_control_init(log_level=50, noise=True)\n",
        "\n",
        "\n",
        "\n",
        "fun = HyperLight().fun\n",
        "\n",
        "spot_tuner = Spot(fun=fun,fun_control=fun_control, design_control=design_control, surrogate_control=surrogate_control)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (mps), used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name   | Type          | Params | Mode  | In sizes              | Out sizes   \n",
            "----------------------------------------------------------------------------------------\n",
            "0 | layers | ManyToManyRNN | 66.6 K | train | [[512, 10, 1], [512]] | [512, 10, 1]\n",
            "----------------------------------------------------------------------------------------\n",
            "66.6 K    Trainable params\n",
            "0         Non-trainable params\n",
            "66.6 K    Total params\n",
            "0.266     Total estimated model params size (MB)\n",
            "6         Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "In fun(): config:\n",
            "{'act_fn': ELU(),\n",
            " 'batch_size': 512,\n",
            " 'dropout_prob': 0.01884581875246618,\n",
            " 'epochs': 32768,\n",
            " 'fc_units': 128,\n",
            " 'lr_mult': 2.809808474191879,\n",
            " 'optimizer': 'RMSprop',\n",
            " 'patience': 64,\n",
            " 'rnn_units': 128}\n",
            "train_size: 8, val_size: 1 used for train & val data.\n",
            "LightDataModule.val_dataloader(). Val. set size: 1\n",
            "LightDataModule.train_dataloader(). data_train size: 8\n",
            "LightDataModule.val_dataloader(). Val. set size: 1\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            nan            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            nan            </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (mps), used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name   | Type          | Params | Mode  | In sizes              | Out sizes   \n",
            "----------------------------------------------------------------------------------------\n",
            "0 | layers | ManyToManyRNN | 66.6 K | train | [[512, 10, 1], [512]] | [512, 10, 1]\n",
            "----------------------------------------------------------------------------------------\n",
            "66.6 K    Trainable params\n",
            "0         Non-trainable params\n",
            "66.6 K    Total params\n",
            "0.266     Total estimated model params size (MB)\n",
            "6         Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_model result: {'val_loss': nan, 'hp_metric': nan}\n",
            "\n",
            "In fun(): config:\n",
            "{'act_fn': ELU(),\n",
            " 'batch_size': 512,\n",
            " 'dropout_prob': 0.01884581875246618,\n",
            " 'epochs': 32768,\n",
            " 'fc_units': 128,\n",
            " 'lr_mult': 2.809808474191879,\n",
            " 'optimizer': 'RMSprop',\n",
            " 'patience': 64,\n",
            " 'rnn_units': 128}\n",
            "train_size: 8, val_size: 1 used for train & val data.\n",
            "LightDataModule.val_dataloader(). Val. set size: 1\n",
            "LightDataModule.train_dataloader(). data_train size: 8\n",
            "LightDataModule.val_dataloader(). Val. set size: 1\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            nan            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            nan            </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (mps), used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name   | Type          | Params | Mode  | In sizes              | Out sizes   \n",
            "----------------------------------------------------------------------------------------\n",
            "0 | layers | ManyToManyRNN | 165 K  | train | [[128, 10, 1], [128]] | [128, 10, 1]\n",
            "----------------------------------------------------------------------------------------\n",
            "165 K     Trainable params\n",
            "0         Non-trainable params\n",
            "165 K     Total params\n",
            "0.663     Total estimated model params size (MB)\n",
            "6         Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_model result: {'val_loss': nan, 'hp_metric': nan}\n",
            "\n",
            "In fun(): config:\n",
            "{'act_fn': ReLU(),\n",
            " 'batch_size': 128,\n",
            " 'dropout_prob': 0.0142125747442629,\n",
            " 'epochs': 32768,\n",
            " 'fc_units': 512,\n",
            " 'lr_mult': 9.12722977776746,\n",
            " 'optimizer': 'AdamW',\n",
            " 'patience': 1024,\n",
            " 'rnn_units': 128}\n",
            "train_size: 8, val_size: 1 used for train & val data.\n",
            "LightDataModule.val_dataloader(). Val. set size: 1\n",
            "LightDataModule.train_dataloader(). data_train size: 8\n",
            "LightDataModule.val_dataloader(). Val. set size: 1\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.019548479467630386    </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.019548479467630386    </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.019548479467630386   \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.019548479467630386   \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (mps), used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name   | Type          | Params | Mode  | In sizes              | Out sizes   \n",
            "----------------------------------------------------------------------------------------\n",
            "0 | layers | ManyToManyRNN | 165 K  | train | [[128, 10, 1], [128]] | [128, 10, 1]\n",
            "----------------------------------------------------------------------------------------\n",
            "165 K     Trainable params\n",
            "0         Non-trainable params\n",
            "165 K     Total params\n",
            "0.663     Total estimated model params size (MB)\n",
            "6         Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_model result: {'val_loss': 0.019548479467630386, 'hp_metric': 0.019548479467630386}\n",
            "\n",
            "In fun(): config:\n",
            "{'act_fn': ReLU(),\n",
            " 'batch_size': 128,\n",
            " 'dropout_prob': 0.0142125747442629,\n",
            " 'epochs': 32768,\n",
            " 'fc_units': 512,\n",
            " 'lr_mult': 9.12722977776746,\n",
            " 'optimizer': 'AdamW',\n",
            " 'patience': 1024,\n",
            " 'rnn_units': 128}\n",
            "train_size: 8, val_size: 1 used for train & val data.\n",
            "LightDataModule.val_dataloader(). Val. set size: 1\n",
            "LightDataModule.train_dataloader(). data_train size: 8\n",
            "LightDataModule.val_dataloader(). Val. set size: 1\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01575664058327675    </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01575664058327675    </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01575664058327675   \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01575664058327675   \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (mps), used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name   | Type          | Params | Mode  | In sizes                | Out sizes    \n",
            "-------------------------------------------------------------------------------------------\n",
            "0 | layers | ManyToManyRNN | 264 K  | train | [[2048, 10, 1], [2048]] | [2048, 10, 1]\n",
            "-------------------------------------------------------------------------------------------\n",
            "264 K     Trainable params\n",
            "0         Non-trainable params\n",
            "264 K     Total params\n",
            "1.057     Total estimated model params size (MB)\n",
            "6         Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_model result: {'val_loss': 0.01575664058327675, 'hp_metric': 0.01575664058327675}\n",
            "\n",
            "In fun(): config:\n",
            "{'act_fn': Sigmoid(),\n",
            " 'batch_size': 2048,\n",
            " 'dropout_prob': 0.0022695775157144005,\n",
            " 'epochs': 8192,\n",
            " 'fc_units': 256,\n",
            " 'lr_mult': 5.060179557823568,\n",
            " 'optimizer': 'ASGD',\n",
            " 'patience': 512,\n",
            " 'rnn_units': 256}\n",
            "train_size: 8, val_size: 1 used for train & val data.\n",
            "LightDataModule.val_dataloader(). Val. set size: 1\n",
            "LightDataModule.train_dataloader(). data_train size: 8\n",
            "LightDataModule.val_dataloader(). Val. set size: 1\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     3.266231060028076     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     3.266231060028076     </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    3.266231060028076    \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    3.266231060028076    \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (mps), used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name   | Type          | Params | Mode  | In sizes                | Out sizes    \n",
            "-------------------------------------------------------------------------------------------\n",
            "0 | layers | ManyToManyRNN | 264 K  | train | [[2048, 10, 1], [2048]] | [2048, 10, 1]\n",
            "-------------------------------------------------------------------------------------------\n",
            "264 K     Trainable params\n",
            "0         Non-trainable params\n",
            "264 K     Total params\n",
            "1.057     Total estimated model params size (MB)\n",
            "6         Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_model result: {'val_loss': 3.266231060028076, 'hp_metric': 3.266231060028076}\n",
            "\n",
            "In fun(): config:\n",
            "{'act_fn': Sigmoid(),\n",
            " 'batch_size': 2048,\n",
            " 'dropout_prob': 0.0022695775157144005,\n",
            " 'epochs': 8192,\n",
            " 'fc_units': 256,\n",
            " 'lr_mult': 5.060179557823568,\n",
            " 'optimizer': 'ASGD',\n",
            " 'patience': 512,\n",
            " 'rnn_units': 256}\n",
            "train_size: 8, val_size: 1 used for train & val data.\n",
            "LightDataModule.val_dataloader(). Val. set size: 1\n",
            "LightDataModule.train_dataloader(). data_train size: 8\n",
            "LightDataModule.val_dataloader(). Val. set size: 1\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    3.2405953407287598     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    3.2405953407287598     </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   3.2405953407287598    \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   3.2405953407287598    \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (mps), used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_model result: {'val_loss': 3.2405953407287598, 'hp_metric': 3.2405953407287598}\n",
            "\n",
            "In fun(): config:\n",
            "{'act_fn': Sigmoid(),\n",
            " 'batch_size': 4096,\n",
            " 'dropout_prob': 0.0201673407115772,\n",
            " 'epochs': 65536,\n",
            " 'fc_units': 512,\n",
            " 'lr_mult': 17.282901823310606,\n",
            " 'optimizer': 'Adam',\n",
            " 'patience': 256,\n",
            " 'rnn_units': 1024}\n",
            "train_size: 8, val_size: 1 used for train & val data.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  | Name   | Type          | Params | Mode  | In sizes                | Out sizes    \n",
            "-------------------------------------------------------------------------------------------\n",
            "0 | layers | ManyToManyRNN | 3.2 M  | train | [[4096, 10, 1], [4096]] | [4096, 10, 1]\n",
            "-------------------------------------------------------------------------------------------\n",
            "3.2 M     Trainable params\n",
            "0         Non-trainable params\n",
            "3.2 M     Total params\n",
            "12.612    Total estimated model params size (MB)\n",
            "6         Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LightDataModule.val_dataloader(). Val. set size: 1\n",
            "LightDataModule.train_dataloader(). data_train size: 8\n",
            "LightDataModule.val_dataloader(). Val. set size: 1\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            nan            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            nan            </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_model result: {'val_loss': nan, 'hp_metric': nan}\n",
            "\n",
            "In fun(): config:\n",
            "{'act_fn': Sigmoid(),\n",
            " 'batch_size': 4096,\n",
            " 'dropout_prob': 0.0201673407115772,\n",
            " 'epochs': 65536,\n",
            " 'fc_units': 512,\n",
            " 'lr_mult': 17.282901823310606,\n",
            " 'optimizer': 'Adam',\n",
            " 'patience': 256,\n",
            " 'rnn_units': 1024}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (mps), used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_size: 8, val_size: 1 used for train & val data.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  | Name   | Type          | Params | Mode  | In sizes                | Out sizes    \n",
            "-------------------------------------------------------------------------------------------\n",
            "0 | layers | ManyToManyRNN | 3.2 M  | train | [[4096, 10, 1], [4096]] | [4096, 10, 1]\n",
            "-------------------------------------------------------------------------------------------\n",
            "3.2 M     Trainable params\n",
            "0         Non-trainable params\n",
            "3.2 M     Total params\n",
            "12.612    Total estimated model params size (MB)\n",
            "6         Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LightDataModule.val_dataloader(). Val. set size: 1\n",
            "LightDataModule.train_dataloader(). data_train size: 8\n",
            "LightDataModule.val_dataloader(). Val. set size: 1\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            nan            </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            nan            </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_model result: {'val_loss': nan, 'hp_metric': nan}\n",
            "\n",
            "In fun(): config:\n",
            "{'act_fn': ReLU(),\n",
            " 'batch_size': 512,\n",
            " 'dropout_prob': 0.01095261700046298,\n",
            " 'epochs': 32768,\n",
            " 'fc_units': 2048,\n",
            " 'lr_mult': 18.24386117212687,\n",
            " 'optimizer': 'RAdam',\n",
            " 'patience': 128,\n",
            " 'rnn_units': 2048}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (mps), used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name   | Type          | Params | Mode  | In sizes              | Out sizes   \n",
            "----------------------------------------------------------------------------------------\n",
            "0 | layers | ManyToManyRNN | 16.8 M | train | [[512, 10, 1], [512]] | [512, 10, 1]\n",
            "----------------------------------------------------------------------------------------\n",
            "16.8 M    Trainable params\n",
            "0         Non-trainable params\n",
            "16.8 M    Total params\n",
            "67.174    Total estimated model params size (MB)\n",
            "6         Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_size: 8, val_size: 1 used for train & val data.\n",
            "LightDataModule.val_dataloader(). Val. set size: 1\n",
            "LightDataModule.train_dataloader(). data_train size: 8\n",
            "LightDataModule.val_dataloader(). Val. set size: 1\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.20582202076911926    </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.20582202076911926    </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.20582202076911926   \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.20582202076911926   \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (mps), used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "\n",
            "  | Name   | Type          | Params | Mode  | In sizes              | Out sizes   \n",
            "----------------------------------------------------------------------------------------\n",
            "0 | layers | ManyToManyRNN | 16.8 M | train | [[512, 10, 1], [512]] | [512, 10, 1]\n",
            "----------------------------------------------------------------------------------------\n",
            "16.8 M    Trainable params\n",
            "0         Non-trainable params\n",
            "16.8 M    Total params\n",
            "67.174    Total estimated model params size (MB)\n",
            "6         Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_model result: {'val_loss': 0.20582202076911926, 'hp_metric': 0.20582202076911926}\n",
            "\n",
            "In fun(): config:\n",
            "{'act_fn': ReLU(),\n",
            " 'batch_size': 512,\n",
            " 'dropout_prob': 0.01095261700046298,\n",
            " 'epochs': 32768,\n",
            " 'fc_units': 2048,\n",
            " 'lr_mult': 18.24386117212687,\n",
            " 'optimizer': 'RAdam',\n",
            " 'patience': 128,\n",
            " 'rnn_units': 2048}\n",
            "train_size: 8, val_size: 1 used for train & val data.\n",
            "LightDataModule.val_dataloader(). Val. set size: 1\n",
            "LightDataModule.train_dataloader(). data_train size: 8\n",
            "LightDataModule.val_dataloader(). Val. set size: 1\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2419612854719162     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2419612854719162     </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2419612854719162    \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2419612854719162    \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (mps), used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_model result: {'val_loss': 0.2419612854719162, 'hp_metric': 0.2419612854719162}\n",
            "\n",
            "In fun(): config:\n",
            "{'act_fn': Tanh(),\n",
            " 'batch_size': 4096,\n",
            " 'dropout_prob': 0.009678046868863095,\n",
            " 'epochs': 16384,\n",
            " 'fc_units': 2048,\n",
            " 'lr_mult': 13.031834796253152,\n",
            " 'optimizer': 'SGD',\n",
            " 'patience': 32,\n",
            " 'rnn_units': 4096}\n",
            "train_size: 8, val_size: 1 used for train & val data.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  | Name   | Type          | Params | Mode  | In sizes                | Out sizes    \n",
            "-------------------------------------------------------------------------------------------\n",
            "0 | layers | ManyToManyRNN | 50.4 M | train | [[4096, 10, 1], [4096]] | [4096, 10, 1]\n",
            "-------------------------------------------------------------------------------------------\n",
            "50.4 M    Trainable params\n",
            "0         Non-trainable params\n",
            "50.4 M    Total params\n",
            "201.441   Total estimated model params size (MB)\n",
            "6         Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LightDataModule.val_dataloader(). Val. set size: 1\n",
            "LightDataModule.train_dataloader(). data_train size: 8\n"
          ]
        }
      ],
      "source": [
        "#| label: 1001_user_data_run\n",
        "res = spot_tuner.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print_res_table(spot_tuner)\n",
        "spot_tuner.plot_important_hyperparameter_contour(max_imp=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(spot_tuner.y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This section showed how to use user-specified data sets for the hyperparameter tuning process with `spotpython`. The user needs to provide the data set and load it as a `spotpython` `CSVDataset()` class."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "spot312",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
