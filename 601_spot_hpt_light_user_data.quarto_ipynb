{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "execute:\n",
        "  cache: false\n",
        "  eval: true\n",
        "  echo: true\n",
        "  warning: false\n",
        "jupyter: python3\n",
        "---\n",
        "\n",
        "\n",
        "# Hyperparameter Tuning with PyTorch Lightning and User Data Sets  {#sec-light-user-data-601}\n"
      ],
      "id": "386e1166"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| label: 601_user_data_imports\n",
        "import numpy as np\n",
        "import os\n",
        "from math import inf\n",
        "import numpy as np\n",
        "import warnings\n",
        "if not os.path.exists('./figures'):\n",
        "    os.makedirs('./figures')\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "id": "user_data_imports",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this section, we will show how user specfied data can be used for the `PyTorch` Lightning hyperparameter tuning workflow with `spotpython`.\n",
        "\n",
        "## Loading a User Specified Data Set\n",
        "\n",
        "Using a user-specified data set is straightforward.\n",
        "\n",
        "The user simply needs to provide a data set and loads is as a  `spotpython`  `CVSDataset()` class by specifying the path, filename, and target column.\n",
        "\n",
        "Consider the following example, where the user has a data set stored in the `userData` directory. The data set is stored in a file named `data.csv`. The target column is named `target`. To show the data, it is loaded as a `pandas` data frame and the first 5 rows are displayed. This step is not necessary for the hyperparameter tuning process, but it is useful for understanding the data.\n"
      ],
      "id": "25c08d9d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: 601_user_data_load\n",
        "# load the csv data set as a pandas dataframe and dislay the first 5 rows\n",
        "import pandas as pd\n",
        "data = pd.read_csv(\"./userData/data.csv\")\n",
        "print(data.head())"
      ],
      "id": "user_data_load",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, the data set is loaded as a `spotpython` `CSVDataset()` class. This step is necessary for the hyperparameter tuning process. \n"
      ],
      "id": "aeb8244c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: 601_user_data_load_csvdataset\n",
        "from spotpython.data.csvdataset import CSVDataset\n",
        "import torch\n",
        "data_set = CSVDataset(directory=\"./userData/\",\n",
        "                     filename=\"data.csv\",\n",
        "                     target_column=\"target\",\n",
        "                     feature_type=torch.float32,\n",
        "                     target_type=torch.float32,\n",
        "                     rmNA=True)\n",
        "print(len(data_set))"
      ],
      "id": "user_data_load_csvdataset",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following step is not necessary for the hyperparameter tuning process, but it is useful for understanding the data. The data set is loaded as a `DataLoader` from `torch.utils.data` to check the data.\n"
      ],
      "id": "39568a6c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: 601_user_data_dataloader\n",
        "# Set batch size for DataLoader\n",
        "batch_size = 5\n",
        "# Create DataLoader\n",
        "from torch.utils.data import DataLoader\n",
        "dataloader = DataLoader(data_set, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Iterate over the data in the DataLoader\n",
        "for batch in dataloader:\n",
        "    inputs, targets = batch\n",
        "    print(f\"Batch Size: {inputs.size(0)}\")\n",
        "    print(f\"Inputs Shape: {inputs.shape}\")\n",
        "    print(f\"Targets Shape: {targets.shape}\")\n",
        "    print(\"---------------\")\n",
        "    print(f\"Inputs: {inputs}\")\n",
        "    print(f\"Targets: {targets}\")\n",
        "    break"
      ],
      "id": "user_data_dataloader",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Similar to the setting from @sec-basic-setup-601, the hyperparameter tuning setup is defined. Instead of using the `Diabetes` data set, the user data set is used. The `data_set` parameter is set to the user data set. The `fun_control` dictionary is set up via the `fun_control_init` function.\n",
        "\n",
        "Note, that we have modified the `fun_evals` parameter to 12 and the `init_size` to 7 to reduce the computational time for this example.\n"
      ],
      "id": "be449a20"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: 601_user_data_setup\n",
        "from spotpython.hyperdict.light_hyper_dict import LightHyperDict\n",
        "from spotpython.fun.hyperlight import HyperLight\n",
        "from spotpython.utils.init import (fun_control_init, surrogate_control_init, design_control_init)\n",
        "from spotpython.utils.eda import gen_design_table\n",
        "from spotpython.hyperparameters.values import set_hyperparameter\n",
        "from spotpython.spot import spot\n",
        "\n",
        "fun_control = fun_control_init(\n",
        "    PREFIX=\"601\",\n",
        "    fun_evals=12,\n",
        "    max_time=1,\n",
        "    data_set = data_set,\n",
        "    core_model_name=\"light.regression.NNLinearRegressor\",\n",
        "    hyperdict=LightHyperDict,\n",
        "    _L_in=10,\n",
        "    _L_out=1)\n",
        "\n",
        "design_control = design_control_init(init_size=7)\n",
        "\n",
        "set_hyperparameter(fun_control, \"initialization\", [\"Default\"])\n",
        "\n",
        "fun = HyperLight().fun\n",
        "\n",
        "spot_tuner = spot.Spot(fun=fun,fun_control=fun_control, design_control=design_control)"
      ],
      "id": "user_data_setup",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: 601_user_data_run\n",
        "res = spot_tuner.run()\n",
        "print(gen_design_table(fun_control=fun_control, spot=spot_tuner))\n",
        "spot_tuner.plot_important_hyperparameter_contour(max_imp=3)"
      ],
      "id": "user_data_run",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This section showed how to use user-specified data sets for the hyperparameter tuning process with `spotpython`. The user needs to provide the data set and load it as a `spotpython` `CSVDataset()` class."
      ],
      "id": "0eba9554"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/bartz/miniforge3/envs/spot312/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}