{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de97ae81",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning with `spotpython` and `PyTorch` Lightning for the Diabetes Data Set\n",
    "\n",
    "In this section, we will show how `spotpython` can be integrated into the `PyTorch` Lightning\n",
    "training workflow for a regression task.\n",
    "It demonstrates how easy it is to use `spotpython` to tune hyperparameters for a `PyTorch` Lightning model.\n",
    "\n",
    "After importing the necessary libraries, the `fun_control` dictionary is set up via the `fun_control_init` function.\n",
    "The `fun_control` dictionary contains\n",
    "\n",
    "* `PREFIX`: a unique identifier for the experiment\n",
    "* `fun_evals`: the number of function evaluations\n",
    "* `max_time`: the maximum run time in minutes\n",
    "* `data_set`: the data set. Here we use the `Diabetes` data set that is provided by `spotpython`.\n",
    "* `core_model_name`: the class name of the neural network model. This neural network model is provided by `spotpython`.\n",
    "* `hyperdict`: the hyperparameter dictionary. This dictionary is used to define the hyperparameters of the neural network model. It is also provided by `spotpython`.\n",
    "* `_L_in`: the number of input features. Since the `Diabetes` data set has 10 features, `_L_in` is set to 10.\n",
    "* `_L_out`: the number of output features. Since we want to predict a single value, `_L_out` is set to 1.\n",
    "\n",
    "The method `set_hyperparameter` allows the user to modify default hyperparameter settings. Here we set the `initialization` method to `[\"Default\"]`. No other initializations are used in this experiment.\n",
    "The `HyperLight` class is used to define the objective function `fun`. It connects the `PyTorch` and the `spotpython` methods and is provided by `spotpython`.\n",
    "Finally, a `Spot` object is created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: 601_setup\n",
    "import os\n",
    "import numpy as np\n",
    "from math import inf\n",
    "import warnings\n",
    "from spotpython.data.diabetes import Diabetes\n",
    "from spotpython.hyperdict.light_hyper_dict import LightHyperDict\n",
    "from spotpython.fun.hyperlight import HyperLight\n",
    "from spotpython.utils.init import (fun_control_init, surrogate_control_init, design_control_init)\n",
    "from spotpython.utils.eda import gen_design_table\n",
    "from spotpython.hyperparameters.values import set_hyperparameter\n",
    "from spotpython.spot import spot\n",
    "from spotpython.utils.file import get_experiment_filename\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "PREFIX=\"601\"\n",
    "\n",
    "data_set = Diabetes()\n",
    "\n",
    "fun_control = fun_control_init(\n",
    "    save_experiment=True,\n",
    "    PREFIX=PREFIX,\n",
    "    TENSORBOARD_CLEAN=False,\n",
    "    tensorboard_log=False,\n",
    "    fun_evals=inf,\n",
    "    max_time=1,\n",
    "    data_set = data_set,\n",
    "    core_model_name=\"light.regression.NNLinearRegressor\",\n",
    "    hyperdict=LightHyperDict,\n",
    "    _L_in=10,\n",
    "    _L_out=1)\n",
    "\n",
    "set_hyperparameter(fun_control, \"optimizer\", [\n",
    "                \"Adadelta\",\n",
    "                \"Adagrad\",\n",
    "                \"Adam\",\n",
    "                \"AdamW\",\n",
    "                \"Adamax\",\n",
    "            ])\n",
    "\n",
    "set_hyperparameter(fun_control, \"l1\", [3,9])\n",
    "set_hyperparameter(fun_control, \"epochs\", [3,5])\n",
    "set_hyperparameter(fun_control, \"batch_size\", [4,11])\n",
    "set_hyperparameter(fun_control, \"dropout_prob\", [0.0, 0.025])\n",
    "# set_hyperparameter(fun_control, \"lr_mult\", [0.01, 20.0])\n",
    "set_hyperparameter(fun_control, \"patience\", [2,3])\n",
    "\n",
    "design_control = design_control_init(init_size=10)\n",
    "fun = HyperLight().fun\n",
    "spot_tuner = spot.Spot(fun=fun,fun_control=fun_control, design_control=design_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "save_experiment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: 601_save_experiment\n",
    "print(gen_design_table(fun_control))\n",
    "\n",
    "filename = get_experiment_filename(fun_control[\"PREFIX\"])\n",
    "# if userExperimnents directory does not exist, create it\n",
    "if not os.path.exists(\"userExperiment\"):\n",
    "    os.makedirs(\"userExperiment\")\n",
    "filename = os.path.join(\"userExperiment\", filename)\n",
    "if spot_tuner.spot_writer is not None:\n",
    "    spot_tuner.spot_writer.close()\n",
    "# remove attribute spot_writer from spot_tuner object\n",
    "if hasattr(spot_tuner, \"spot_writer\"):\n",
    "    delattr(spot_tuner, \"spot_writer\")\n",
    "# So the experiment, so that it ccan be executed on a remote machine\n",
    "spot_tuner.save_experiment(filename=filename, overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095cd49c",
   "metadata": {},
   "source": [
    "Calling the method `run()` starts the hyperparameter tuning process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "run",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: 601_run\n",
    "res = spot_tuner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed54e3d",
   "metadata": {},
   "source": [
    "## Looking at the Results\n",
    "\n",
    "### Tuning Progress\n",
    "\n",
    "After the hyperparameter tuning run is finished, the progress of the hyperparameter tuning can be visualized with `spotpython`'s method `plot_progress`. The black points represent the performace values (score or metric) of  hyperparameter configurations from the initial design, whereas the red points represents the  hyperparameter configurations found by the surrogate model based optimization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64739377",
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_tuner.plot_progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b380ee45",
   "metadata": {},
   "source": [
    "### Tuned Hyperparameters and Their Importance\n",
    "\n",
    "Results can be printed in tabular form.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0956abd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.utils.eda import gen_design_table\n",
    "print(gen_design_table(fun_control=fun_control, spot=spot_tuner))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d32a1e4",
   "metadata": {},
   "source": [
    "A histogram can be used to visualize the most important hyperparameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e38a2469",
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_tuner.plot_importance(threshold=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3808fdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_tuner.plot_important_hyperparameter_contour(max_imp=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522f3726",
   "metadata": {},
   "source": [
    "### Get the Tuned Architecture {#sec-get-spot-results-31}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19cbf233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "from spotpython.hyperparameters.values import get_tuned_architecture\n",
    "config = get_tuned_architecture(spot_tuner, fun_control)\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d3a825",
   "metadata": {},
   "source": [
    "* Test on the full data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d2704a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the value of the key \"TENSORBOARD_CLEAN\" to True in the fun_control dictionary and use the update() method to update the fun_control dictionary\n",
    "fun_control.update({\"TENSORBOARD_CLEAN\": True})\n",
    "fun_control.update({\"tensorboard_log\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70b63742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "def chk_pickle(s):\n",
    "    # Construct the filename\n",
    "    filename = s + '.pickle'\n",
    "\n",
    "    # Check if the file exists\n",
    "    return os.path.isfile(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e13dfb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.light.testmodel import test_model\n",
    "from spotpython.light.loadmodel import load_light_from_checkpoint\n",
    "from spotpython.utils.init import get_feature_names\n",
    "\n",
    "\n",
    "if chk_pickle(\"model_loaded_\" + PREFIX):\n",
    "    with open(\"model_loaded_\" + PREFIX + \".pickle\", \"rb\") as f:\n",
    "        model_loaded = pickle.load(f)\n",
    "else:\n",
    "    test_model(config, fun_control)\n",
    "    model_loaded = load_light_from_checkpoint(config, fun_control)\n",
    "    # save model_loaded to pickle file\n",
    "    with open(\"model_loaded_\" + PREFIX + \".pickle\", \"wb\") as f:\n",
    "        pickle.dump(model_loaded, f)\n",
    "\n",
    "get_feature_names(fun_control)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d24d16",
   "metadata": {},
   "source": [
    "## Cross Validation With Lightning\n",
    "\n",
    "* The `KFold` class from `sklearn.model_selection` is used to generate the folds for cross-validation.\n",
    "* These mechanism is used to generate the folds for the final evaluation of the model.\n",
    "* The `CrossValidationDataModule` class [[SOURCE]](https://github.com/sequential-parameter-optimization/spotpython/blob/main/src/spotpython/data/lightcrossvalidationdatamodule.py) is used to generate the folds for the hyperparameter tuning process.\n",
    "* It is called from the `cv_model` function [[SOURCE]](https://github.com/sequential-parameter-optimization/spotpython/blob/main/src/spotpython/light/cvmodel.py).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d21e3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "914b5398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.light.cvmodel import cv_model\n",
    "from spotpython.hyperparameters.values import set_control_key_value\n",
    "set_control_key_value(control_dict=fun_control,\n",
    "                        key=\"k_folds\",\n",
    "                        value=2,\n",
    "                        replace=True)\n",
    "set_control_key_value(control_dict=fun_control,\n",
    "                        key=\"test_size\",\n",
    "                        value=0.6,\n",
    "                        replace=True)\n",
    "cv_model(config, fun_control)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a656dbc",
   "metadata": {},
   "source": [
    "## Extending the Basic Setup\n",
    "\n",
    "This basic setup can be adapted to user-specific needs in many ways. For example, the user can specify a custom data set, a custom model, or a custom loss function.\n",
    "The following sections provide more details on how to customize the hyperparameter tuning process.\n",
    "Before we proceed, we will provide an overview of the basic settings of the hyperparameter tuning process and explain the parameters used so far.\n",
    "\n",
    "### General Experiment Setup {#sec-general-experiment-setup-601}\n",
    "\n",
    "To keep track of the different experiments, we use a `PREFIX` for the experiment name. The `PREFIX` is used to create a unique experiment name. The `PREFIX` is also used to create a unique TensorBoard folder, which is used to store the TensorBoard log files.\n",
    "\n",
    "`spotpython` allows the specification of two different types of stopping criteria: first, the number of function evaluations (`fun_evals`), and second, the maximum run time in seconds (`max_time`). Here, we will set the number of function evaluations to infinity and the maximum run time to one minute.\n",
    "\n",
    "`max_time` is set to one minute for demonstration purposes. For real experiments, this value should be increased.\n",
    "Note,  the total run time may exceed the specified `max_time`, because the initial design is always evaluated, even if this takes longer than `max_time`.\n",
    "\n",
    "\n",
    "### Data Setup {#sec-data-601}\n",
    "\n",
    "Here, we have provided the `Diabetes` data set class, which is a subclass of `torch.utils.data.Dataset`. \n",
    "Data preprocessing is handled by `Lightning` and `PyTorch`. It is described in the [LIGHTNINGDATAMODULE](https://lightning.ai/docs/pytorch/stable/data/datamodule.html) documentation. \n",
    "\n",
    "The data splitting, i.e., the generation of training, validation, and testing data, is handled by `Lightning`.\n",
    "\n",
    "\n",
    "### Objective Function `fun` {#sec-the-objective-function-31}\n",
    "\n",
    "The objective function `fun` from the class `HyperLight` [[SOURCE]](https://github.com/sequential-parameter-optimization/spotpython/blob/main/src/spotpython/fun/hyperlight.py) is selected next. It implements an interface from `PyTorch`'s training, validation, and testing methods to `spotpython`.\n",
    "\n",
    "### Core-Model Setup\n",
    "\n",
    "By using `core_model_name = \"light.regression.NNLinearRegressor\"`, the `spotpython` model class `NetLightRegression` [[SOURCE]](https://sequential-parameter-optimization.github.io/spotpython/reference/spotpython/light/regression/netlightregression/) from the `light.regression` module is selected.\n",
    "\n",
    "### Hyperdict Setup\n",
    "\n",
    "For a given `core_model_name`, the corresponding hyperparameters are automatically loaded from the associated dictionary, which is stored as a JSON file. The JSON file contains hyperparameter type information, names, and bounds. For `spotpython` models, the hyperparameters are stored in the `LightHyperDict`, see [[SOURCE]](https://github.com/sequential-parameter-optimization/spotpython/blob/main/src/spotpython/hyperdict/light_hyper_dict.json)\n",
    "Alternatively, you can load a local hyper_dict.\n",
    "The `hyperdict`  uses the default hyperparameter settings. These can be modified as described in @sec-modifying-hyperparameter-levels.\n",
    "\n",
    "### Other Settings {#sec-other-settings-601}\n",
    "\n",
    "There are several additional parameters that can be specified, e.g., since we did not specify a loss function, `mean_squared_error` is used, which is the default loss function. These will be explained in more detail in the following sections.\n",
    "\n",
    "\n",
    "## Tensorboard {#sec-tensorboard-601}\n",
    "\n",
    "The textual output shown in the console (or code cell) can be visualized with Tensorboard, if the argument `tensorboard_log` to `fun_control_init()` is set to `True`. The Tensorboard log files are stored in the `runs` folder. To start Tensorboard, run the following command in the terminal:\n",
    "\n",
    "\n",
    "\n",
    "```{raw}\n",
    "tensorboard --logdir=\"runs/\"\n",
    "```\n",
    "\n",
    "\n",
    "Further information can be found in the [PyTorch Lightning documentation](https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.loggers.tensorboard.html) for Tensorboard.\n",
    "\n",
    "## Loading the Saved Experiment and Getting the Hyperparameters of the Tuned Model\n",
    "\n",
    "To get the tuned hyperparameters as a dictionary, the `get_experiment_from_PREFIX` function can be used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62b1e8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.utils.file import get_experiment_from_PREFIX\n",
    "config = get_experiment_from_PREFIX(\"601\")[\"config\"]\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe99874",
   "metadata": {},
   "source": [
    "## Using the `spotgui`\n",
    "\n",
    "The `spotgui` [[github]](https://github.com/sequential-parameter-optimization/spotGUI) provides a convenient way to interact with the hyperparameter tuning process.\n",
    "To obtain the settings from @sec-summary-setting-up-the-experiment-601, the `spotgui` can be started as shown in @fig-spotgui.\n",
    "\n",
    "![spotgui](./figures_static/024_gui.png){width=100% #fig-spotgui}\n",
    "\n",
    "## Summary\n",
    "\n",
    "This section presented an introduction to the basic setup of hyperparameter tuning with `spotpython` and `PyTorch` Lightning.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3",
   "path": "/Users/bartz/miniforge3/envs/spot312/share/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
