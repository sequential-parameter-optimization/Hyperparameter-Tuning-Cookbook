{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2694fd3",
   "metadata": {},
   "source": [
    "---\n",
    "title: Saving and Loading\n",
    "execute:\n",
    "  cache: false\n",
    "  eval: true\n",
    "  echo: true\n",
    "  warning: false\n",
    "jupyter: python3\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial shows how to save and load objects in `spotpython`.\n",
    "It is split into the following parts:\n",
    "- @sec-spotpython-saving-and-loading shows how to save and load objects in `spotpython`, if `spotpython` is used as an optimizer.\n",
    "- @sec-spotpython-as-a-hyperparameter-tuner-37 shows how to save and load hyperparameter tuning experiments.\n",
    "- @sec-saving-and-loading-pytorch-lightning-models-37 shows how to save and load `PyTorch Lightning` models.\n",
    "- @sec-converting-a-lightning-model-to-a-plain-torch-model-37 shows how to convert a `PyTorch Lightning` model to a plain `PyTorch` model.\n",
    "\n",
    "## spotpython: Saving and Loading Optimization Experiments {#sec-spotpython-saving-and-loading}\n",
    "\n",
    "In this section, we will show how results from `spotpython` can be saved and reloaded.\n",
    "Here, `spotpython` can be used as an optimizer. \n",
    "\n",
    "## spotpython as an Optimizer\n",
    "\n",
    "If `spotpython` is used as an optimizer, no dictionary of hyperparameters has be specified. The `fun_control` dictionary is sufficient. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "code-optimization-experiment-604",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotpython tuning: 4.7932399644479124 [########--] 75.00% \r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotpython tuning: 2.0379524815147736 [#########-] 87.50% \r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotpython tuning: 1.9863250753932071 [##########] 100.00% Done...\r\n",
      "\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment saved to spot_branin_experiment.pickle\n",
      "filename: spot_branin_experiment.pickle\n"
     ]
    }
   ],
   "source": [
    "#| label: code-optimization-experiment-604\n",
    "import os\n",
    "import pprint\n",
    "from spotpython.utils.file import load_experiment\n",
    "from spotpython.utils.file import get_experiment_filename\n",
    "import numpy as np\n",
    "from math import inf\n",
    "from spotpython.spot import spot\n",
    "from spotpython.utils.init import (\n",
    "    fun_control_init,\n",
    "    design_control_init,\n",
    "    surrogate_control_init,\n",
    "    optimizer_control_init)\n",
    "from spotpython.fun.objectivefunctions import analytical\n",
    "fun = analytical().fun_branin\n",
    "fun_control = fun_control_init(\n",
    "            PREFIX=\"branin\",            \n",
    "            lower = np.array([0, 0]),\n",
    "            upper = np.array([10, 10]),\n",
    "            fun_evals=8,\n",
    "            fun_repeats=1,\n",
    "            max_time=inf,\n",
    "            noise=False,\n",
    "            tolerance_x=0,\n",
    "            ocba_delta=0,\n",
    "            var_type=[\"num\", \"num\"],\n",
    "            infill_criterion=\"ei\",\n",
    "            n_points=1,\n",
    "            seed=123,\n",
    "            log_level=20,\n",
    "            show_models=False,\n",
    "            show_progress=True)\n",
    "design_control = design_control_init(\n",
    "            init_size=5,\n",
    "            repeats=1)\n",
    "surrogate_control = surrogate_control_init(\n",
    "            model_fun_evals=10000,\n",
    "            min_theta=-3,\n",
    "            max_theta=3,\n",
    "            n_theta=2,\n",
    "            theta_init_zero=True,\n",
    "            n_p=1,\n",
    "            optim_p=False,\n",
    "            var_type=[\"num\", \"num\"],\n",
    "            seed=124)\n",
    "optimizer_control = optimizer_control_init(\n",
    "            max_iter=1000,\n",
    "            seed=125)\n",
    "spot_tuner = spot.Spot(fun=fun,\n",
    "            fun_control=fun_control,\n",
    "            design_control=design_control,\n",
    "            surrogate_control=surrogate_control,\n",
    "            optimizer_control=optimizer_control)\n",
    "spot_tuner.run()\n",
    "PREFIX = fun_control[\"PREFIX\"]\n",
    "filename = get_experiment_filename(PREFIX)\n",
    "spot_tuner.save_experiment(filename=filename)\n",
    "print(f\"filename: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "code-reload-optimization-experiment-604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded experiment from spot_branin_experiment.pickle\n"
     ]
    }
   ],
   "source": [
    "#| label: code-reload-optimization-experiment-604\n",
    "(spot_tuner_1, fun_control_1, design_control_1,\n",
    "    surrogate_control_1, optimizer_control_1) = load_experiment(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1002ba16",
   "metadata": {},
   "source": [
    "The progress of the original experiment is shown in @fig-plot-progress-37a and the reloaded experiment in @fig-plot-progress-37b.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fig-plot-progress-604a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/pdf": "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",
      "text/plain": [
       "<Figure size 2700x1800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| label: fig-plot-progress-604a\n",
    "#| fig-cap: Progress of the original experiment\n",
    "spot_tuner.plot_progress(log_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fig-plot-progress-604b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/pdf": "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",
      "text/plain": [
       "<Figure size 2700x1800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| label: fig-plot-progress-604b\n",
    "#| fig-cap: Progress of the reloaded experiment\n",
    "spot_tuner_1.plot_progress(log_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3db7f9",
   "metadata": {},
   "source": [
    "The results from the original experiment are shown in @tbl-results-37a and the reloaded experiment in @tbl-results-37b.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "tbl-results-604a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min y: 1.9863250753932071\n",
      "x0: 10.0\n",
      "x1: 3.2107652010539627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['x0', 10.0], ['x1', 3.2107652010539627]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| label: tbl-results-604a\n",
    "spot_tuner.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "tbl-results-604b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min y: 1.9863250753932071\n",
      "x0: 10.0\n",
      "x1: 3.2107652010539627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['x0', 10.0], ['x1', 3.2107652010539627]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| label: tbl-results-604b\n",
    "spot_tuner_1.print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341d9e60",
   "metadata": {},
   "source": [
    "#### Getting the Tuned Hyperparameters\n",
    "\n",
    "The tuned hyperparameters can be obtained as a dictionary with the following code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "code-get-tuned-optimization-604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x0': 10.0, 'x1': 3.2107652010539627}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| label: code-get-tuned-optimization-604\n",
    "from spotpython.hyperparameters.values import get_tuned_hyperparameters\n",
    "get_tuned_hyperparameters(spot_tuner=spot_tuner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7636ccbd",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "### Summary: Saving and Loading Optimization Experiments\n",
    "* If `spotpython` is used as an optimizer (without an hyperparameter dictionary), experiments can be saved and reloaded with the `save_experiment` and `load_experiment` functions.\n",
    "* The tuned hyperparameters can be obtained with the `get_tuned_hyperparameters` function.\n",
    ":::\n",
    "\n",
    "## spotpython as a Hyperparameter Tuner {#sec-spotpython-as-a-hyperparameter-tuner-37}\n",
    "\n",
    "If `spotpython` is used as a hyperparameter tuner,\n",
    "in addition to the `fun_control` dictionary a `core_model` dictionary has to be specified.\n",
    "Furthermore, a data set has to be selected and added to the `fun_control` dictionary.\n",
    "Here, we will use the `Diabetes` data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "warnings-off-604",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: warnings-off-604\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4cb67c",
   "metadata": {},
   "source": [
    "### The Diabetes Data Set\n",
    "\n",
    "The hyperparameter tuning of a `PyTorch Lightning` network on the `Diabetes` data set is used as an example. The `Diabetes` data set is a PyTorch Dataset for regression, which originates from the `scikit-learn` package, see [https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes).\n",
    "\n",
    "Ten baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements were obtained for each of n = 442 diabetes patients,  as well as the response of interest, a quantitative measure of disease progression one year after baseline.\n",
    "The `Diabetes` data set is has the following properties:\n",
    "\n",
    "* Samples total: 442\n",
    "* Dimensionality: 10\n",
    "* Features: real, $-.2 < x < .2$\n",
    "* Targets: integer $25 - 346$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "code-hyperparameter-tuning-604",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module_name: light\n",
      "submodule_name: regression\n",
      "model_name: NNLinearRegressor\n",
      "| name           | type   | default   |   lower |   upper | transform             |\n",
      "|----------------|--------|-----------|---------|---------|-----------------------|\n",
      "| l1             | int    | 3         |     3   |   4     | transform_power_2_int |\n",
      "| epochs         | int    | 4         |     3   |   5     | transform_power_2_int |\n",
      "| batch_size     | int    | 4         |     4   |  11     | transform_power_2_int |\n",
      "| act_fn         | factor | ReLU      |     0   |   5     | None                  |\n",
      "| optimizer      | factor | SGD       |     0   |   2     | None                  |\n",
      "| dropout_prob   | float  | 0.01      |     0   |   0.025 | None                  |\n",
      "| lr_mult        | float  | 1.0       |     0.1 |  10     | None                  |\n",
      "| patience       | int    | 2         |     2   |   3     | transform_power_2_int |\n",
      "| batch_norm     | factor | 0         |     0   |   1     | None                  |\n",
      "| initialization | factor | Default   |     0   |   4     | None                  |\n"
     ]
    }
   ],
   "source": [
    "#| label: code-hyperparameter-tuning-604\n",
    "from spotpython.data.diabetes import Diabetes\n",
    "from spotpython.hyperdict.light_hyper_dict import LightHyperDict\n",
    "from spotpython.fun.hyperlight import HyperLight\n",
    "from spotpython.utils.init import (fun_control_init, surrogate_control_init, design_control_init)\n",
    "from spotpython.utils.eda import gen_design_table\n",
    "from spotpython.spot import spot\n",
    "from spotpython.utils.file import get_experiment_filename\n",
    "\n",
    "PREFIX=\"604\"\n",
    "\n",
    "data_set = Diabetes()\n",
    "\n",
    "fun_control = fun_control_init(\n",
    "    PREFIX=PREFIX,\n",
    "    fun_evals=inf,\n",
    "    max_time=1,\n",
    "    data_set = data_set,\n",
    "    core_model_name=\"light.regression.NNLinearRegressor\",\n",
    "    hyperdict=LightHyperDict,\n",
    "    _L_in=10,\n",
    "    _L_out=1)\n",
    "\n",
    "fun = HyperLight().fun\n",
    "\n",
    "from spotpython.hyperparameters.values import set_hyperparameter\n",
    "set_hyperparameter(fun_control, \"optimizer\", [ \"Adadelta\", \"Adam\", \"Adamax\"])\n",
    "set_hyperparameter(fun_control, \"l1\", [3,4])\n",
    "set_hyperparameter(fun_control, \"epochs\", [3,5])\n",
    "set_hyperparameter(fun_control, \"batch_size\", [4,11])\n",
    "set_hyperparameter(fun_control, \"dropout_prob\", [0.0, 0.025])\n",
    "set_hyperparameter(fun_control, \"patience\", [2,3])\n",
    "\n",
    "design_control = design_control_init(init_size=10)\n",
    "\n",
    "print(gen_design_table(fun_control))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "save_experiment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: 604_save_experiment\n",
    "fun_control.update({\"save_experiment\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77fe175a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: File userExperiment/spot_604_experiment.pickle already exists. Use overwrite=True to overwrite the file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | Mode  | In sizes   | Out sizes\n",
      "-----------------------------------------------------------------------\n",
      "0 | layers | Sequential | 491    | train | [2048, 10] | [2048, 1]\n",
      "-----------------------------------------------------------------------\n",
      "491       Trainable params\n",
      "0         Non-trainable params\n",
      "491       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=16` reached.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | Mode  | In sizes | Out sizes\n",
      "---------------------------------------------------------------------\n",
      "0 | layers | Sequential | 169    | train | [64, 10] | [64, 1]  \n",
      "---------------------------------------------------------------------\n",
      "169       Trainable params\n",
      "0         Non-trainable params\n",
      "169       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "15        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 23995.974609375, 'hp_metric': 23995.974609375}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=16` reached.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | Mode  | In sizes  | Out sizes\n",
      "----------------------------------------------------------------------\n",
      "0 | layers | Sequential | 595    | train | [256, 10] | [256, 1] \n",
      "----------------------------------------------------------------------\n",
      "595       Trainable params\n",
      "0         Non-trainable params\n",
      "595       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "33        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 24026.373046875, 'hp_metric': 24026.373046875}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | Mode  | In sizes  | Out sizes\n",
      "----------------------------------------------------------------------\n",
      "0 | layers | Sequential | 213    | train | [512, 10] | [512, 1] \n",
      "----------------------------------------------------------------------\n",
      "213       Trainable params\n",
      "0         Non-trainable params\n",
      "213       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "21        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 23620.583984375, 'hp_metric': 23620.583984375}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | Mode  | In sizes  | Out sizes\n",
      "----------------------------------------------------------------------\n",
      "0 | layers | Sequential | 595    | train | [128, 10] | [128, 1] \n",
      "----------------------------------------------------------------------\n",
      "595       Trainable params\n",
      "0         Non-trainable params\n",
      "595       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "33        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 24180.556640625, 'hp_metric': 24180.556640625}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | Mode  | In sizes | Out sizes\n",
      "---------------------------------------------------------------------\n",
      "0 | layers | Sequential | 491    | train | [32, 10] | [32, 1]  \n",
      "---------------------------------------------------------------------\n",
      "491       Trainable params\n",
      "0         Non-trainable params\n",
      "491       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 23986.830078125, 'hp_metric': 23986.830078125}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=16` reached.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | Mode  | In sizes  | Out sizes\n",
      "----------------------------------------------------------------------\n",
      "0 | layers | Sequential | 169    | train | [512, 10] | [512, 1] \n",
      "----------------------------------------------------------------------\n",
      "169       Trainable params\n",
      "0         Non-trainable params\n",
      "169       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "15        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=8` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 24038.296875, 'hp_metric': 24038.296875}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | Mode  | In sizes | Out sizes\n",
      "---------------------------------------------------------------------\n",
      "0 | layers | Sequential | 213    | train | [32, 10] | [32, 1]  \n",
      "---------------------------------------------------------------------\n",
      "213       Trainable params\n",
      "0         Non-trainable params\n",
      "213       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "21        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 23852.763671875, 'hp_metric': 23852.763671875}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=32` reached.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | Mode  | In sizes  | Out sizes\n",
      "----------------------------------------------------------------------\n",
      "0 | layers | Sequential | 169    | train | [128, 10] | [128, 1] \n",
      "----------------------------------------------------------------------\n",
      "169       Trainable params\n",
      "0         Non-trainable params\n",
      "169       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "15        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 22770.611328125, 'hp_metric': 22770.611328125}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=16` reached.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | Mode  | In sizes   | Out sizes\n",
      "-----------------------------------------------------------------------\n",
      "0 | layers | Sequential | 595    | train | [1024, 10] | [1024, 1]\n",
      "-----------------------------------------------------------------------\n",
      "595       Trainable params\n",
      "0         Non-trainable params\n",
      "595       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "33        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 23918.626953125, 'hp_metric': 23918.626953125}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=32` reached.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | Mode  | In sizes | Out sizes\n",
      "---------------------------------------------------------------------\n",
      "0 | layers | Sequential | 213    | train | [32, 10] | [32, 1]  \n",
      "---------------------------------------------------------------------\n",
      "213       Trainable params\n",
      "0         Non-trainable params\n",
      "213       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "21        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 23849.4296875, 'hp_metric': 23849.4296875}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 23438.02734375, 'hp_metric': 23438.02734375}\n",
      "spotpython tuning: 22770.611328125 [----------] 2.15% \r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | Mode  | In sizes | Out sizes\n",
      "---------------------------------------------------------------------\n",
      "0 | layers | Sequential | 213    | train | [16, 10] | [16, 1]  \n",
      "---------------------------------------------------------------------\n",
      "213       Trainable params\n",
      "0         Non-trainable params\n",
      "213       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "21        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 23946.251953125, 'hp_metric': 23946.251953125}\n",
      "spotpython tuning: 22770.611328125 [----------] 4.48% \r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | Mode  | In sizes | Out sizes\n",
      "---------------------------------------------------------------------\n",
      "0 | layers | Sequential | 213    | train | [64, 10] | [64, 1]  \n",
      "---------------------------------------------------------------------\n",
      "213       Trainable params\n",
      "0         Non-trainable params\n",
      "213       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "21        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=32` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 23783.455078125, 'hp_metric': 23783.455078125}\n",
      "spotpython tuning: 22770.611328125 [#---------] 7.81% \r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | Mode  | In sizes | Out sizes\n",
      "---------------------------------------------------------------------\n",
      "0 | layers | Sequential | 491    | train | [32, 10] | [32, 1]  \n",
      "---------------------------------------------------------------------\n",
      "491       Trainable params\n",
      "0         Non-trainable params\n",
      "491       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 4903.05126953125, 'hp_metric': 4903.05126953125}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotpython tuning: 4903.05126953125 [#---------] 9.75% \r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | Mode  | In sizes | Out sizes\n",
      "---------------------------------------------------------------------\n",
      "0 | layers | Sequential | 491    | train | [32, 10] | [32, 1]  \n",
      "---------------------------------------------------------------------\n",
      "491       Trainable params\n",
      "0         Non-trainable params\n",
      "491       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 5344.9443359375, 'hp_metric': 5344.9443359375}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotpython tuning: 4903.05126953125 [#---------] 13.54% \r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | Mode  | In sizes   | Out sizes\n",
      "-----------------------------------------------------------------------\n",
      "0 | layers | Sequential | 491    | train | [1024, 10] | [1024, 1]\n",
      "-----------------------------------------------------------------------\n",
      "491       Trainable params\n",
      "0         Non-trainable params\n",
      "491       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 24064.033203125, 'hp_metric': 24064.033203125}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotpython tuning: 4903.05126953125 [##--------] 18.01% \r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | Mode  | In sizes | Out sizes\n",
      "---------------------------------------------------------------------\n",
      "0 | layers | Sequential | 491    | train | [32, 10] | [32, 1]  \n",
      "---------------------------------------------------------------------\n",
      "491       Trainable params\n",
      "0         Non-trainable params\n",
      "491       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=8` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 23473.666015625, 'hp_metric': 23473.666015625}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotpython tuning: 4903.05126953125 [##--------] 22.09% \r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | Mode  | In sizes  | Out sizes\n",
      "----------------------------------------------------------------------\n",
      "0 | layers | Sequential | 491    | train | [128, 10] | [128, 1] \n",
      "----------------------------------------------------------------------\n",
      "491       Trainable params\n",
      "0         Non-trainable params\n",
      "491       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=32` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 23331.263671875, 'hp_metric': 23331.263671875}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotpython tuning: 4903.05126953125 [###-------] 29.44% \r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | Mode  | In sizes | Out sizes\n",
      "---------------------------------------------------------------------\n",
      "0 | layers | Sequential | 491    | train | [16, 10] | [16, 1]  \n",
      "---------------------------------------------------------------------\n",
      "491       Trainable params\n",
      "0         Non-trainable params\n",
      "491       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=32` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 23682.443359375, 'hp_metric': 23682.443359375}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotpython tuning: 4903.05126953125 [####------] 43.07% \r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | Mode  | In sizes | Out sizes\n",
      "---------------------------------------------------------------------\n",
      "0 | layers | Sequential | 491    | train | [64, 10] | [64, 1]  \n",
      "---------------------------------------------------------------------\n",
      "491       Trainable params\n",
      "0         Non-trainable params\n",
      "491       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=32` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 3258.4697265625, 'hp_metric': 3258.4697265625}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotpython tuning: 3258.4697265625 [######----] 55.55% \r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | Mode  | In sizes  | Out sizes\n",
      "----------------------------------------------------------------------\n",
      "0 | layers | Sequential | 169    | train | [256, 10] | [256, 1] \n",
      "----------------------------------------------------------------------\n",
      "169       Trainable params\n",
      "0         Non-trainable params\n",
      "169       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "15        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=32` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 23730.748046875, 'hp_metric': 23730.748046875}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotpython tuning: 3258.4697265625 [######----] 64.05% \r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | Mode  | In sizes | Out sizes\n",
      "---------------------------------------------------------------------\n",
      "0 | layers | Sequential | 491    | train | [64, 10] | [64, 1]  \n",
      "---------------------------------------------------------------------\n",
      "491       Trainable params\n",
      "0         Non-trainable params\n",
      "491       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=32` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 22964.625, 'hp_metric': 22964.625}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotpython tuning: 3258.4697265625 [#######---] 73.29% \r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | Mode  | In sizes | Out sizes\n",
      "---------------------------------------------------------------------\n",
      "0 | layers | Sequential | 491    | train | [16, 10] | [16, 1]  \n",
      "---------------------------------------------------------------------\n",
      "491       Trainable params\n",
      "0         Non-trainable params\n",
      "491       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=32` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 21555.431640625, 'hp_metric': 21555.431640625}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotpython tuning: 3258.4697265625 [#########-] 86.62% \r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | Mode  | In sizes   | Out sizes\n",
      "-----------------------------------------------------------------------\n",
      "0 | layers | Sequential | 491    | train | [2048, 10] | [2048, 1]\n",
      "-----------------------------------------------------------------------\n",
      "491       Trainable params\n",
      "0         Non-trainable params\n",
      "491       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=32` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 23992.6328125, 'hp_metric': 23992.6328125}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotpython tuning: 3258.4697265625 [#########-] 92.97% \r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | Mode  | In sizes  | Out sizes\n",
      "----------------------------------------------------------------------\n",
      "0 | layers | Sequential | 491    | train | [128, 10] | [128, 1] \n",
      "----------------------------------------------------------------------\n",
      "491       Trainable params\n",
      "0         Non-trainable params\n",
      "491       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=32` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 24022.75390625, 'hp_metric': 24022.75390625}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotpython tuning: 3258.4697265625 [##########] 97.82% \r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | Mode  | In sizes   | Out sizes\n",
      "-----------------------------------------------------------------------\n",
      "0 | layers | Sequential | 595    | train | [2048, 10] | [2048, 1]\n",
      "-----------------------------------------------------------------------\n",
      "595       Trainable params\n",
      "0         Non-trainable params\n",
      "595       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "33        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=8` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 24006.078125, 'hp_metric': 24006.078125}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotpython tuning: 3258.4697265625 [##########] 100.00% Done...\r\n",
      "\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment saved to spot_604_experiment.pickle\n"
     ]
    }
   ],
   "source": [
    "spot_tuner = spot.Spot(fun=fun,fun_control=fun_control, design_control=design_control)\n",
    "spot_tuner.save_experiment(path=\"userExperiment\", overwrite=False)\n",
    "res = spot_tuner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49f33e8",
   "metadata": {},
   "source": [
    "The tuned hyperparameters can be obtained as a dictionary with the following code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "code-get-tuned-hyperparameters-37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': 4.0,\n",
       " 'epochs': 5.0,\n",
       " 'batch_size': 6.0,\n",
       " 'act_fn': 3.0,\n",
       " 'optimizer': 0.0,\n",
       " 'dropout_prob': 0.024999427371776895,\n",
       " 'lr_mult': 3.1577462928629245,\n",
       " 'patience': 2.0,\n",
       " 'batch_norm': 0.0,\n",
       " 'initialization': 3.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| label: code-get-tuned-hyperparameters-37\n",
    "from spotpython.hyperparameters.values import get_tuned_hyperparameters\n",
    "get_tuned_hyperparameters(spot_tuner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a99192",
   "metadata": {},
   "source": [
    "Here , the numerical levels of the hyperparameters are used as keys in the dictionary.\n",
    "If the `fun_control` dictionary is used, the names of the hyperparameters are used as keys in the dictionary. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "code-get-tuned-hyperparameters-fun-ctrl37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': 4.0,\n",
       " 'epochs': 5.0,\n",
       " 'batch_size': 6.0,\n",
       " 'act_fn': 'LeakyReLU',\n",
       " 'optimizer': 'Adadelta',\n",
       " 'dropout_prob': 0.024999427371776895,\n",
       " 'lr_mult': 3.1577462928629245,\n",
       " 'patience': 2.0,\n",
       " 'batch_norm': 0,\n",
       " 'initialization': 'xavier_uniform'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| label: code-get-tuned-hyperparameters-fun-ctrl37\n",
    "get_tuned_hyperparameters(spot_tuner, fun_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "code-save-experiment-37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: File userExperiment/spot_604_experiment.pickle already exists. Use overwrite=True to overwrite the file.\n"
     ]
    }
   ],
   "source": [
    "#| label: code-save-experiment-37\n",
    "spot_tuner.save_experiment(path=\"userExperiment\", overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22263f1",
   "metadata": {
    "user_expressions": [
     {
      "expression": "filename",
      "result": {
       "data": {
        "text/plain": "'spot_branin_experiment.pickle'"
       },
       "metadata": {},
       "status": "ok"
      }
     }
    ]
   },
   "source": [
    "The results from the experiment are stored in the pickle file `{python} filename`.\n",
    "The experiment can be reloaded with the following code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0658a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename: spot_branin_experiment.pickle\n"
     ]
    }
   ],
   "source": [
    "print(f\"filename: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "code-reload-hyper-experiment-37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded experiment from spot_604_experiment.pickle\n"
     ]
    }
   ],
   "source": [
    "#| label: code-reload-hyper-experiment-37\n",
    "from spotpython.utils.file import load_experiment\n",
    "(spot_tuner_1, fun_control_1, design_control_1,\n",
    "    surrogate_control_1, optimizer_control_1) = load_experiment(PREFIX=PREFIX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6399f15a",
   "metadata": {},
   "source": [
    "Plot the progress of the original experiment are identical to the reloaded experiment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac8549a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/pdf": "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",
      "text/plain": [
       "<Figure size 2700x1800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/pdf": "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",
      "text/plain": [
       "<Figure size 2700x1800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spot_tuner.plot_progress(log_y=True)\n",
    "spot_tuner_1.plot_progress(log_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f915e5",
   "metadata": {},
   "source": [
    "Finally, the tuned hyperparameters can be obtained as a dictionary from the reloaded experiment with the following code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e5720f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': 4.0,\n",
       " 'epochs': 5.0,\n",
       " 'batch_size': 6.0,\n",
       " 'act_fn': 'LeakyReLU',\n",
       " 'optimizer': 'Adadelta',\n",
       " 'dropout_prob': 0.024999427371776895,\n",
       " 'lr_mult': 3.1577462928629245,\n",
       " 'patience': 2.0,\n",
       " 'batch_norm': 0,\n",
       " 'initialization': 'xavier_uniform'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tuned_hyperparameters(spot_tuner_1, fun_control_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0c1129",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "### Summary: Saving and Loading Hyperparameter-Tuning Experiments\n",
    "* If `spotpython` is used as an hyperparameter tuner (with an hyperparameter dictionary), experiments can be saved and reloaded with the `save_experiment` and `load_experiment` functions.\n",
    "* The tuned hyperparameters can be obtained with the `get_tuned_hyperparameters` function.\n",
    ":::\n",
    "\n",
    "\n",
    "## Saving and Loading PyTorch Lightning Models {#sec-saving-and-loading-pytorch-lightning-models-37}\n",
    "\n",
    "@sec-spotpython-saving-and-loading  and @sec-spotpython-as-a-hyperparameter-tuner-37 explained how to save and load optimization and hyperparameter tuning experiments and how to get the tuned hyperparameters as a dictionary.\n",
    "This section shows how to save and load `PyTorch Lightning` models.\n",
    "\n",
    "\n",
    "### Get the Tuned Architecture {#sec-get-spot-results-31}\n",
    "\n",
    "In contrast to the function `get_tuned_hyperparameters`, the function `get_tuned_architecture` returns the tuned architecture of the model as a dictionary. Here, the transformations are already applied to the numerical levels of the hyperparameters and the encoding (and types) are the original types of the hyperparameters used by the model. The `config` dictionary can be passed to the model without any modifications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7c203f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'act_fn': LeakyReLU(),\n",
      " 'batch_norm': False,\n",
      " 'batch_size': 64,\n",
      " 'dropout_prob': 0.024999427371776895,\n",
      " 'epochs': 32,\n",
      " 'initialization': 'xavier_uniform',\n",
      " 'l1': 16,\n",
      " 'lr_mult': 3.1577462928629245,\n",
      " 'optimizer': 'Adadelta',\n",
      " 'patience': 4}\n"
     ]
    }
   ],
   "source": [
    "from spotpython.hyperparameters.values import get_tuned_architecture\n",
    "config = get_tuned_architecture(spot_tuner, fun_control)\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14b2e14",
   "metadata": {},
   "source": [
    "After getting the tuned architecture, the model can be created and tested with the following code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7cb23b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | Mode  | In sizes | Out sizes\n",
      "---------------------------------------------------------------------\n",
      "0 | layers | Sequential | 491    | train | [64, 10] | [64, 1]  \n",
      "---------------------------------------------------------------------\n",
      "491       Trainable params\n",
      "0         Non-trainable params\n",
      "491       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=32` reached.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /Users/bartz/workspace/Hyperparameter-Tuning-Cookbook/runs/saved_models/16_32_64_LeakyReLU_Adadelta_0.025_3.1577_4_False_xavier_uniform_TEST/last-v1.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded model weights from the checkpoint at /Users/bartz/workspace/Hyperparameter-Tuning-Cookbook/runs/saved_models/16_32_64_LeakyReLU_Adadelta_0.025_3.1577_4_False_xavier_uniform_TEST/last-v1.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">        Test metric        </span><span style=\"font-weight: bold\">       DataLoader 0        </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span><span style=\"color: #800080; text-decoration-color: #800080\">     4248.83251953125      </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span><span style=\"color: #800080; text-decoration-color: #800080\">     4248.83251953125      </span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    4248.83251953125     \u001b[0m\u001b[35m \u001b[0m\n",
       "\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    4248.83251953125     \u001b[0m\u001b[35m \u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_model result: {'val_loss': 4248.83251953125, 'hp_metric': 4248.83251953125}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4248.83251953125, 4248.83251953125)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spotpython.light.testmodel import test_model\n",
    "test_model(config, fun_control)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9881c3ca",
   "metadata": {},
   "source": [
    "### Load a Model from Checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "770b29d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config: {'l1': 16, 'epochs': 32, 'batch_size': 64, 'act_fn': LeakyReLU(), 'optimizer': 'Adadelta', 'dropout_prob': 0.024999427371776895, 'lr_mult': 3.1577462928629245, 'patience': 4, 'batch_norm': False, 'initialization': 'xavier_uniform'}\n",
      "Loading model with 16_32_64_LeakyReLU_Adadelta_0.025_3.1577_4_False_xavier_uniform_TEST from runs/saved_models/16_32_64_LeakyReLU_Adadelta_0.025_3.1577_4_False_xavier_uniform_TEST/last.ckpt\n",
      "Model: NNLinearRegressor(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=16, bias=True)\n",
      "    (1): LeakyReLU()\n",
      "    (2): Dropout(p=0.024999427371776895, inplace=False)\n",
      "    (3): Linear(in_features=16, out_features=8, bias=True)\n",
      "    (4): LeakyReLU()\n",
      "    (5): Dropout(p=0.024999427371776895, inplace=False)\n",
      "    (6): Linear(in_features=8, out_features=8, bias=True)\n",
      "    (7): LeakyReLU()\n",
      "    (8): Dropout(p=0.024999427371776895, inplace=False)\n",
      "    (9): Linear(in_features=8, out_features=4, bias=True)\n",
      "    (10): LeakyReLU()\n",
      "    (11): Dropout(p=0.024999427371776895, inplace=False)\n",
      "    (12): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (13): LeakyReLU()\n",
      "    (14): Dropout(p=0.024999427371776895, inplace=False)\n",
      "    (15): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (16): LeakyReLU()\n",
      "    (17): Dropout(p=0.024999427371776895, inplace=False)\n",
      "    (18): Linear(in_features=4, out_features=2, bias=True)\n",
      "    (19): LeakyReLU()\n",
      "    (20): Dropout(p=0.024999427371776895, inplace=False)\n",
      "    (21): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (22): LeakyReLU()\n",
      "    (23): Dropout(p=0.024999427371776895, inplace=False)\n",
      "    (24): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (25): LeakyReLU()\n",
      "    (26): Dropout(p=0.024999427371776895, inplace=False)\n",
      "    (27): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (28): LeakyReLU()\n",
      "    (29): Dropout(p=0.024999427371776895, inplace=False)\n",
      "    (30): Linear(in_features=2, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from spotpython.light.loadmodel import load_light_from_checkpoint\n",
    "model_loaded = load_light_from_checkpoint(config, fun_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "657812be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': False,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict(),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_pre_hooks': OrderedDict(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_hooks_with_kwargs': OrderedDict(),\n",
       " '_forward_hooks_always_called': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks_with_kwargs': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_post_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict([('layers',\n",
       "               Sequential(\n",
       "                 (0): Linear(in_features=10, out_features=16, bias=True)\n",
       "                 (1): LeakyReLU()\n",
       "                 (2): Dropout(p=0.024999427371776895, inplace=False)\n",
       "                 (3): Linear(in_features=16, out_features=8, bias=True)\n",
       "                 (4): LeakyReLU()\n",
       "                 (5): Dropout(p=0.024999427371776895, inplace=False)\n",
       "                 (6): Linear(in_features=8, out_features=8, bias=True)\n",
       "                 (7): LeakyReLU()\n",
       "                 (8): Dropout(p=0.024999427371776895, inplace=False)\n",
       "                 (9): Linear(in_features=8, out_features=4, bias=True)\n",
       "                 (10): LeakyReLU()\n",
       "                 (11): Dropout(p=0.024999427371776895, inplace=False)\n",
       "                 (12): Linear(in_features=4, out_features=4, bias=True)\n",
       "                 (13): LeakyReLU()\n",
       "                 (14): Dropout(p=0.024999427371776895, inplace=False)\n",
       "                 (15): Linear(in_features=4, out_features=4, bias=True)\n",
       "                 (16): LeakyReLU()\n",
       "                 (17): Dropout(p=0.024999427371776895, inplace=False)\n",
       "                 (18): Linear(in_features=4, out_features=2, bias=True)\n",
       "                 (19): LeakyReLU()\n",
       "                 (20): Dropout(p=0.024999427371776895, inplace=False)\n",
       "                 (21): Linear(in_features=2, out_features=2, bias=True)\n",
       "                 (22): LeakyReLU()\n",
       "                 (23): Dropout(p=0.024999427371776895, inplace=False)\n",
       "                 (24): Linear(in_features=2, out_features=2, bias=True)\n",
       "                 (25): LeakyReLU()\n",
       "                 (26): Dropout(p=0.024999427371776895, inplace=False)\n",
       "                 (27): Linear(in_features=2, out_features=2, bias=True)\n",
       "                 (28): LeakyReLU()\n",
       "                 (29): Dropout(p=0.024999427371776895, inplace=False)\n",
       "                 (30): Linear(in_features=2, out_features=1, bias=True)\n",
       "               ))]),\n",
       " 'prepare_data_per_node': True,\n",
       " 'allow_zero_length_dataloader_with_multiple_devices': False,\n",
       " '_log_hyperparams': True,\n",
       " '_dtype': torch.float32,\n",
       " '_device': device(type='mps', index=0),\n",
       " '_trainer': None,\n",
       " '_example_input_array': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " '_automatic_optimization': True,\n",
       " '_strict_loading': None,\n",
       " '_current_fx_name': None,\n",
       " '_param_requires_grad_state': {},\n",
       " '_metric_attributes': None,\n",
       " '_compiler_ctx': None,\n",
       " '_fabric': None,\n",
       " '_fabric_optimizers': [],\n",
       " '_device_mesh': None,\n",
       " '_L_in': 10,\n",
       " '_L_out': 1,\n",
       " '_torchmetric': 'mean_squared_error',\n",
       " 'metric': <function torchmetrics.functional.regression.mse.mean_squared_error(preds: torch.Tensor, target: torch.Tensor, squared: bool = True, num_outputs: int = 1) -> torch.Tensor>,\n",
       " '_hparams_name': 'kwargs',\n",
       " '_hparams': \"act_fn\":         LeakyReLU()\n",
       " \"batch_norm\":     False\n",
       " \"batch_size\":     64\n",
       " \"dropout_prob\":   0.024999427371776895\n",
       " \"epochs\":         32\n",
       " \"initialization\": xavier_uniform\n",
       " \"l1\":             16\n",
       " \"lr_mult\":        3.1577462928629245\n",
       " \"optimizer\":      Adadelta\n",
       " \"patience\":       4,\n",
       " '_hparams_initial': \"act_fn\":         LeakyReLU()\n",
       " \"batch_norm\":     False\n",
       " \"batch_size\":     64\n",
       " \"dropout_prob\":   0.024999427371776895\n",
       " \"epochs\":         32\n",
       " \"initialization\": xavier_uniform\n",
       " \"l1\":             16\n",
       " \"lr_mult\":        3.1577462928629245\n",
       " \"optimizer\":      Adadelta\n",
       " \"patience\":       4}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(model_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a272198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.save(model_loaded, \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "027add9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = torch.load(\"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1d5123d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': False,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict(),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_pre_hooks': OrderedDict(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_hooks_with_kwargs': OrderedDict(),\n",
       " '_forward_hooks_always_called': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks_with_kwargs': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_post_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict([('layers',\n",
       "               Sequential(\n",
       "                 (0): Linear(in_features=10, out_features=16, bias=True)\n",
       "                 (1): LeakyReLU()\n",
       "                 (2): Dropout(p=0.024999427371776895, inplace=False)\n",
       "                 (3): Linear(in_features=16, out_features=8, bias=True)\n",
       "                 (4): LeakyReLU()\n",
       "                 (5): Dropout(p=0.024999427371776895, inplace=False)\n",
       "                 (6): Linear(in_features=8, out_features=8, bias=True)\n",
       "                 (7): LeakyReLU()\n",
       "                 (8): Dropout(p=0.024999427371776895, inplace=False)\n",
       "                 (9): Linear(in_features=8, out_features=4, bias=True)\n",
       "                 (10): LeakyReLU()\n",
       "                 (11): Dropout(p=0.024999427371776895, inplace=False)\n",
       "                 (12): Linear(in_features=4, out_features=4, bias=True)\n",
       "                 (13): LeakyReLU()\n",
       "                 (14): Dropout(p=0.024999427371776895, inplace=False)\n",
       "                 (15): Linear(in_features=4, out_features=4, bias=True)\n",
       "                 (16): LeakyReLU()\n",
       "                 (17): Dropout(p=0.024999427371776895, inplace=False)\n",
       "                 (18): Linear(in_features=4, out_features=2, bias=True)\n",
       "                 (19): LeakyReLU()\n",
       "                 (20): Dropout(p=0.024999427371776895, inplace=False)\n",
       "                 (21): Linear(in_features=2, out_features=2, bias=True)\n",
       "                 (22): LeakyReLU()\n",
       "                 (23): Dropout(p=0.024999427371776895, inplace=False)\n",
       "                 (24): Linear(in_features=2, out_features=2, bias=True)\n",
       "                 (25): LeakyReLU()\n",
       "                 (26): Dropout(p=0.024999427371776895, inplace=False)\n",
       "                 (27): Linear(in_features=2, out_features=2, bias=True)\n",
       "                 (28): LeakyReLU()\n",
       "                 (29): Dropout(p=0.024999427371776895, inplace=False)\n",
       "                 (30): Linear(in_features=2, out_features=1, bias=True)\n",
       "               ))]),\n",
       " 'prepare_data_per_node': True,\n",
       " 'allow_zero_length_dataloader_with_multiple_devices': False,\n",
       " '_log_hyperparams': True,\n",
       " '_dtype': torch.float32,\n",
       " '_device': device(type='mps', index=0),\n",
       " '_trainer': None,\n",
       " '_example_input_array': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " '_automatic_optimization': True,\n",
       " '_strict_loading': None,\n",
       " '_current_fx_name': None,\n",
       " '_param_requires_grad_state': {},\n",
       " '_metric_attributes': None,\n",
       " '_compiler_ctx': None,\n",
       " '_fabric': None,\n",
       " '_fabric_optimizers': [],\n",
       " '_device_mesh': None,\n",
       " '_L_in': 10,\n",
       " '_L_out': 1,\n",
       " '_torchmetric': 'mean_squared_error',\n",
       " 'metric': <function torchmetrics.functional.regression.mse.mean_squared_error(preds: torch.Tensor, target: torch.Tensor, squared: bool = True, num_outputs: int = 1) -> torch.Tensor>,\n",
       " '_hparams_name': 'kwargs',\n",
       " '_hparams': \"act_fn\":         LeakyReLU()\n",
       " \"batch_norm\":     False\n",
       " \"batch_size\":     64\n",
       " \"dropout_prob\":   0.024999427371776895\n",
       " \"epochs\":         32\n",
       " \"initialization\": xavier_uniform\n",
       " \"l1\":             16\n",
       " \"lr_mult\":        3.1577462928629245\n",
       " \"optimizer\":      Adadelta\n",
       " \"patience\":       4,\n",
       " '_hparams_initial': \"act_fn\":         LeakyReLU()\n",
       " \"batch_norm\":     False\n",
       " \"batch_size\":     64\n",
       " \"dropout_prob\":   0.024999427371776895\n",
       " \"epochs\":         32\n",
       " \"initialization\": xavier_uniform\n",
       " \"l1\":             16\n",
       " \"lr_mult\":        3.1577462928629245\n",
       " \"optimizer\":      Adadelta\n",
       " \"patience\":       4}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show all attributes of the model\n",
    "vars(mymodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f3f522",
   "metadata": {},
   "source": [
    "## Converting a Lightning Model to a Plain Torch Model {#sec-converting-a-lightning-model-to-a-plain-torch-model-37}\n",
    "\n",
    "### The Function `get_removed_attributes_and_base_net`\n",
    "\n",
    "`spotpython` provides a function to covert a `PyTorch Lightning` model to a plain `PyTorch` model. The function `get_removed_attributes_and_base_net` returns a tuple with the removed attributes and the base net. The base net is a plain `PyTorch` model. The removed attributes are the attributes of the `PyTorch Lightning` model that are not part of the base net.\n",
    "\n",
    "This conversion can be reverted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8eabb9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from spotpython.utils.device import getDevice\n",
    "from torch.utils.data import random_split\n",
    "from spotpython.utils.classes import get_removed_attributes_and_base_net\n",
    "from spotpython.hyperparameters.optimizer import optimizer_handler\n",
    "removed_attributes, torch_net = get_removed_attributes_and_base_net(net=mymodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e1d9554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_automatic_optimization': True, '_current_fx_name': None, '_device': device(type='mps', index=0), '_hparams_name': 'kwargs', '_device_mesh': None, '_hparams': \"act_fn\":         LeakyReLU()\n",
      "\"batch_norm\":     False\n",
      "\"batch_size\":     64\n",
      "\"dropout_prob\":   0.024999427371776895\n",
      "\"epochs\":         32\n",
      "\"initialization\": xavier_uniform\n",
      "\"l1\":             16\n",
      "\"lr_mult\":        3.1577462928629245\n",
      "\"optimizer\":      Adadelta\n",
      "\"patience\":       4, '_fabric': None, '_example_input_array': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), '_strict_loading': None, '_fabric_optimizers': [], 'allow_zero_length_dataloader_with_multiple_devices': False, '_metric_attributes': None, '_compiler_ctx': None, 'prepare_data_per_node': True, '_hparams_initial': \"act_fn\":         LeakyReLU()\n",
      "\"batch_norm\":     False\n",
      "\"batch_size\":     64\n",
      "\"dropout_prob\":   0.024999427371776895\n",
      "\"epochs\":         32\n",
      "\"initialization\": xavier_uniform\n",
      "\"l1\":             16\n",
      "\"lr_mult\":        3.1577462928629245\n",
      "\"optimizer\":      Adadelta\n",
      "\"patience\":       4, 'metric': <function mean_squared_error at 0x31c8387c0>, '_L_in': 10, '_log_hyperparams': True, '_param_requires_grad_state': {}, '_L_out': 1, '_dtype': torch.float32, '_torchmetric': 'mean_squared_error', '_trainer': None}\n"
     ]
    }
   ],
   "source": [
    "print(removed_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee83d475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNLinearRegressor(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=16, bias=True)\n",
      "    (1): LeakyReLU()\n",
      "    (2): Dropout(p=0.024999427371776895, inplace=False)\n",
      "    (3): Linear(in_features=16, out_features=8, bias=True)\n",
      "    (4): LeakyReLU()\n",
      "    (5): Dropout(p=0.024999427371776895, inplace=False)\n",
      "    (6): Linear(in_features=8, out_features=8, bias=True)\n",
      "    (7): LeakyReLU()\n",
      "    (8): Dropout(p=0.024999427371776895, inplace=False)\n",
      "    (9): Linear(in_features=8, out_features=4, bias=True)\n",
      "    (10): LeakyReLU()\n",
      "    (11): Dropout(p=0.024999427371776895, inplace=False)\n",
      "    (12): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (13): LeakyReLU()\n",
      "    (14): Dropout(p=0.024999427371776895, inplace=False)\n",
      "    (15): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (16): LeakyReLU()\n",
      "    (17): Dropout(p=0.024999427371776895, inplace=False)\n",
      "    (18): Linear(in_features=4, out_features=2, bias=True)\n",
      "    (19): LeakyReLU()\n",
      "    (20): Dropout(p=0.024999427371776895, inplace=False)\n",
      "    (21): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (22): LeakyReLU()\n",
      "    (23): Dropout(p=0.024999427371776895, inplace=False)\n",
      "    (24): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (25): LeakyReLU()\n",
      "    (26): Dropout(p=0.024999427371776895, inplace=False)\n",
      "    (27): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (28): LeakyReLU()\n",
      "    (29): Dropout(p=0.024999427371776895, inplace=False)\n",
      "    (30): Linear(in_features=2, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(torch_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78738bd",
   "metadata": {},
   "source": [
    "###  An Example how to use the Plain Torch Net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39ec22c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/pdf": "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",
      "text/plain": [
       "<Figure size 1650x1050 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the Diabetes dataset from sklearn\n",
    "diabetes = load_diabetes()\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create a PyTorch dataset\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create a PyTorch dataloader\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "torch_net.to(getDevice(\"cpu\"))\n",
    "\n",
    "# train the net\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(torch_net.parameters(), lr=0.01)\n",
    "n_epochs = 100\n",
    "losses = []\n",
    "for epoch in range(n_epochs):\n",
    "    for inputs, targets in train_dataloader:\n",
    "        targets = targets.view(-1, 1)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = torch_net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "# visualize the network training\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3",
   "path": "/Users/bartz/miniforge3/envs/spot312/share/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
