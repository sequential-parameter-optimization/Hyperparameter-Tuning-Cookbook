{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eae83071",
   "metadata": {},
   "source": [
    "---\n",
    "execute:\n",
    "  cache: false\n",
    "  eval: true\n",
    "  echo: true\n",
    "  warning: false\n",
    "jupyter: python3\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "# Saving and Loading {#sec-spotpython-saving-and-loading}\n",
    "\n",
    "This tutorial shows how to save and load objects in `spotPython`.\n",
    "It is split into the following parts:\n",
    "- @sec-spotpython-saving-and-loading shows how to save and load objects in `spotPython`, if `spotPython` is used as an optimizer.\n",
    "- @sec-spotpython-as-a-hyperparameter-tuner-37 shows how to save and load hyperparameter tuning experiments.\n",
    "- @sec-saving-and-loading-pytorch-lightning-models-37 shows how to save and load `PyTorch Lightning` models.\n",
    "- @sec-converting-a-lightning-model-to-a-plain-torch-model-37 shows how to convert a `PyTorch Lightning` model to a plain `PyTorch` model.\n",
    "\n",
    "## spotPython: Saving and Loading Optimization Experiments {#sec-spotpython-saving-and-loading}\n",
    "\n",
    "In this section, we will show how results from `spotPython` can be saved and reloaded.\n",
    "Here, `spotPython` can be used as an optimizer. \n",
    "\n",
    "### spotPython as an Optimizer\n",
    "\n",
    "If `spotPython` is used as an optimizer, no dictionary of hyperparameters has be specified. The `fun_control` dictionary is sufficient. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "code-optimization-experiment-37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotPython tuning: 4.7932399644479124 [########--] 75.00% \r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotPython tuning: 2.0379795645847087 [#########-] 87.50% \r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotPython tuning: 1.986328241945829 [##########] 100.00% Done...\r\n",
      "\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename: spot_branin_experiment.pickle\n"
     ]
    }
   ],
   "source": [
    "#| label: code-optimization-experiment-37\n",
    "import os\n",
    "import pprint\n",
    "from spotPython.utils.file import load_experiment\n",
    "from spotPython.utils.file import get_experiment_filename\n",
    "import numpy as np\n",
    "from math import inf\n",
    "from spotPython.spot import spot\n",
    "from spotPython.utils.init import (\n",
    "    fun_control_init,\n",
    "    design_control_init,\n",
    "    surrogate_control_init,\n",
    "    optimizer_control_init)\n",
    "from spotPython.fun.objectivefunctions import analytical\n",
    "fun = analytical().fun_branin\n",
    "fun_control = fun_control_init(\n",
    "            PREFIX=\"branin\",\n",
    "            SUMMARY_WRITER=False,\n",
    "            lower = np.array([0, 0]),\n",
    "            upper = np.array([10, 10]),\n",
    "            fun_evals=8,\n",
    "            fun_repeats=1,\n",
    "            max_time=inf,\n",
    "            noise=False,\n",
    "            tolerance_x=0,\n",
    "            ocba_delta=0,\n",
    "            var_type=[\"num\", \"num\"],\n",
    "            infill_criterion=\"ei\",\n",
    "            n_points=1,\n",
    "            seed=123,\n",
    "            log_level=20,\n",
    "            show_models=False,\n",
    "            show_progress=True)\n",
    "design_control = design_control_init(\n",
    "            init_size=5,\n",
    "            repeats=1)\n",
    "surrogate_control = surrogate_control_init(\n",
    "            model_fun_evals=10000,\n",
    "            min_theta=-3,\n",
    "            max_theta=3,\n",
    "            n_theta=2,\n",
    "            theta_init_zero=True,\n",
    "            n_p=1,\n",
    "            optim_p=False,\n",
    "            var_type=[\"num\", \"num\"],\n",
    "            seed=124)\n",
    "optimizer_control = optimizer_control_init(\n",
    "            max_iter=1000,\n",
    "            seed=125)\n",
    "spot_tuner = spot.Spot(fun=fun,\n",
    "            fun_control=fun_control,\n",
    "            design_control=design_control,\n",
    "            surrogate_control=surrogate_control,\n",
    "            optimizer_control=optimizer_control)\n",
    "spot_tuner.run()\n",
    "PREFIX = fun_control[\"PREFIX\"]\n",
    "filename = get_experiment_filename(PREFIX)\n",
    "spot_tuner.save_experiment(filename=filename)\n",
    "print(f\"filename: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "code-reload-optimization-experiment-37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: code-reload-optimization-experiment-37\n",
    "(spot_tuner_1, fun_control_1, design_control_1,\n",
    "    surrogate_control_1, optimizer_control_1) = load_experiment(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d51d3b2",
   "metadata": {},
   "source": [
    "The progress of the original experiment is shown in @fig-plot-progress-37a and the reloaded experiment in @fig-plot-progress-37b.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fig-plot-progress-37a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/pdf": "JVBERi0xLjQKJazcIKu6CjEgMCBvYmoKPDwgL1R5cGUgL0NhdGFsb2cgL1BhZ2VzIDIgMCBSID4+CmVuZG9iago4IDAgb2JqCjw8IC9Gb250IDMgMCBSIC9YT2JqZWN0IDcgMCBSIC9FeHRHU3RhdGUgNCAwIFIgL1BhdHRlcm4gNSAwIFIKL1NoYWRpbmcgNiAwIFIgL1Byb2NTZXQgWyAvUERGIC9UZXh0IC9JbWFnZUIgL0ltYWdlQyAvSW1hZ2VJIF0gPj4KZW5kb2JqCjExIDAgb2JqCjw8IC9UeXBlIC9QYWdlIC9QYXJlbnQgMiAwIFIgL1Jlc291cmNlcyA4IDAgUgovTWVkaWFCb3ggWyAwIDAgNTQxLjYgMTk3LjY1NDE2MjgzMTMgXSAvQ29udGVudHMgOSAwIFIgL0Fubm90cyAxMCAwIFIgPj4KZW5kb2JqCjkgMCBvYmoKPDwgL0xlbmd0aCAxMiAwIFIgL0ZpbHRlciAvRmxhdGVEZWNvZGUgPj4Kc3RyZWFtCnictVZNbxQ5EL37V/gIBzyuctllH8myRCDtITASh9UeViEEogREQJu/v697etrVmck0e9hDj7rfPNcrl10fm1dX/3y5vHp3fuZ/e+82/evyhyN/g+faR3+D58GTP8dz7SK+7lwWCgVvt9MbNQ0FryUBisvPz859cpuXWPwDK85d4sA+aciSNA+2kgTpwO0EUK1BJ2RcYoHJJu9sXsMzeBkq/ITCgLicQ2RlTQupDkqIky13ho0+uO/4jf4FnPeZQhXNNfNAZQ4t+8s7d7Z1m9fkKfrtpzEO24/uT/+Mnvu//Pat+33rLtzohCOOgaXGvNioRU/JE2mIpaYiIpVW9fmIfs1BSq2JFvoGPalfEe7aSFIBe1U/HepzjqHUVhbyBjylzoIlsTXmCvKquhyqJ8qhUUzNqhvwlHoiDpqiRiaKsqqej6hXCpSIylLeoCf1VaFIOPcEV1b1y6G+SAkpU5Nq9S16Sl8kBVLmEjPYq/p6qJ+JQtYhyxaZZ9CTqRdrSC3hnHTgrulXq28vUeEQK3H2LbCOL08befPz6v7vn1++fT1ymGPhiRwqrGUZbjGKkEWObUKxqNWhhjAVUq2TOCSR2BIL3IF092WoIdsbhyMqnCJyFNEZvXsWpz8k1xh3G0mh8vgymVBj4cB1pHxriTnPrnfkKdcJdzWDURWlIhnfm5b8f/jO1vey910klCJch6inuABGz0dSbgF5gjq5J3Wgk0oLGrPUsid1oJOQeFpKQ3GeSB3opCrIolTynjN/G0oLqF2IxcyZgU5qglaG6qp7UgcMqYUYcRhzADrQScSKi9ZSnn0yiKEJB2k65PSe1hFDy7jYDbk/O2YQQyu4DJkjz64ZxNJQAFJFFnTajBiaouZERahnWkcsDaUxkea+hY4YGroXVTSubq0jI+27X44gOe62Tvi9v/If/Fffs2IsStPYsBsdkPVB0B2w3dIE6eE3f0T/6ttMLzkwR1WcekT7VCQA2plK1rbKfpGxcwxOMF0z/QIdh1iRUehZqazScUii1LBh68mFu/C/EBP2bz0KA2as5aRopiotGHCIS11OOx2+tUOIhftwYNHetBdo76UWdu//6z52QXp3/mhDR+0vWqjkkCTVNpQG09lkuBhFVHfexEFolLgfJtSH+cNcrVlriIiJFKxPx0knTh/XuzZNWiojzKt0pCiuIeY6tCDD3p3/EJY4j9GPIvJoZD+Yx7HbR2P83ZExHqzV4X/P6euesHTh/gVcvIp9CmVuZHN0cmVhbQplbmRvYmoKMTIgMCBvYmoKOTM4CmVuZG9iagoxMCAwIG9iagpbIF0KZW5kb2JqCjE5IDAgb2JqCjw8IC9MZW5ndGggNTEgL0ZpbHRlciAvRmxhdGVEZWNvZGUgPj4Kc3RyZWFtCnicM7I0VTBQsLQAEoaW5grmRpYKKYZcQD6IlcsFE8sBswyANFhpDkxFDlcGVxoAv4wNVgplbmRzdHJlYW0KZW5kb2JqCjIwIDAgb2JqCjw8IC9MZW5ndGggMzA3IC9GaWx0ZXIgL0ZsYXRlRGVjb2RlID4+CnN0cmVhbQp4nD2SS24DMQxD9z6FLhDA+tme86Qoupjef9snJemKHNkWRWqWukxZUx6QNJOEf+nwcLGd8jtsz2Zm4Fqil4nllOfQFWLuonzZzEZdWSfF6oRmOrfoUTkXBzZNqp+rLKXdLngO1yaeW/YRP7zQoB7UNS4JN3RXo2UpNGOq+3/Se/yMMuBqTF1sUqt7HzxeRFXo6AdHiSJjlxfn40EJ6UrCaFqIlXdFA0Hu8rTKewnu295qyLIHqZjOOylmsOt0Ui5uF4chHsjyqPDlo9hrQs/4sCsl9EjYhjNyJ+5oxubUyOKQ/t6NBEuPrmgh8+CvbtYuYLxTOkViZE5yrGmLVU73UBTTucO9DBD1bEVDKXOR1epfw84La5ZsFnhK+gUeo90mSw5W2duoTu+tPNnQ9x9a13QfCmVuZHN0cmVhbQplbmRvYmoKMjEgMCBvYmoKPDwgL0xlbmd0aCAyNDkgL0ZpbHRlciAvRmxhdGVEZWNvZGUgPj4Kc3RyZWFtCnicPVA7jkQhDOs5hS/wJPIjcB5Gqy1m79+uA5opUEx+tjMk0BGBRwwxlK/jJa2groG/i0LxbuLrg8Igq0NSIM56D4h07KY2kRM6HZwzP2E3Y47ARTEGnOl0pj0HJjn7wgqEcxtl7FZIJ4mqIo7qM44pnip7n3gWLO3INlsnkj3kIOFSUonJpZ+Uyj9typQKOmbRBCwSueBkE004y7tJUowZlDLqHqZ2In2sPMijOuhkTc6sI5nZ00/bmfgccLdf2mROlcd0Hsz4nLTOgzkVuvfjiTYHTY3a6Oz3E2kqL1K7HVqdfnUSld0Y5xgSl2d/Gd9k//kH/odaIgplbmRzdHJlYW0KZW5kb2JqCjIyIDAgb2JqCjw8IC9MZW5ndGggMzk1IC9GaWx0ZXIgL0ZsYXRlRGVjb2RlID4+CnN0cmVhbQp4nD1SS27FQAjb5xRcoNLwm895UlXdvPtva0NSqSq8iTHGMH3KkLnlS10ScYXJt16uWzymfC5bWpl5iLuLjSU+ttyX7iG2XXQusTgdR/ILMp0qRKjNqtGh+EKWhQeQTvChC8J9Of7jL4DB17ANuOE9MkGwJOYpQsZuURmaEkERYeeRFaikUJ9Zwt9R7uv3MgVqb4ylC2Mc9Am0BUJtSMQC6kAAROyUVK2QjmckE78V3WdiHGDn0bIBrhlURJZ77MeIqc6ojLxExD5PTfoolkwtVsZuUxlf/JSM1Hx0BSqpNPKU8tBVs9ALWIl5EvY5/Ej459ZsIYY6btbyieUfM8UyEs5gSzlgoZfjR+DbWXURrh25uM50gR+V1nBMtOt+yPVP/nTbWs11vHIIokDlTUHwuw6uRrHExDI+nY0peqIssBqavEYzwWEQEdb3w8gDGv1yvBA0p2sitFgim7ViRI2KbHM9vQTWTO/FOdbDE8Js753WobIzMyohgtq6hmrrQHazvvNwtp8/M+iibQplbmRzdHJlYW0KZW5kb2JqCjIzIDAgb2JqCjw8IC9MZW5ndGggMjQ5IC9GaWx0ZXIgL0ZsYXRlRGVjb2RlID4+CnN0cmVhbQp4nE1RSYoDMAy75xX6QCFek7ynQ5lD5//Xyg6FOQQJr5KTlphYCw8xhB8sPfiRIXM3/Rt+otm7WXqSydn/mOciU1H4UqguYkJdiBvPoRHwPaFrElmxvfE5LKOZc74HH4W4BDOhAWN9STK5qOaVIRNODHUcDlqkwrhrYsPiWtE8jdxu+0ZmZSaEDY9kQtwYgIgg6wKyGCyUNjYTMlnOA+0NyQ1aYNepG1GLgiuU1gl0olbEqszgs+bWdjdDLfLgqH3x+mhWl2CF0Uv1WHhfhT6YqZl27pJCeuFNOyLMHgqkMjstK7V7xOpugfo/y1Lw/cn3+B2vD838XJwKZW5kc3RyZWFtCmVuZG9iagoyNCAwIG9iago8PCAvTGVuZ3RoIDk0IC9GaWx0ZXIgL0ZsYXRlRGVjb2RlID4+CnN0cmVhbQp4nEWNwRHAIAgE/1RBCQoK2k8mk4f2/40QMnxg5w7uhAULtnlGHwWVJl4VWAdKY9xQj0C94XItydwFD3Anf9rQVJyW03dpkUlVKdykEnn/DmcmkKh50WOd9wtj+yM8CmVuZHN0cmVhbQplbmRvYmoKMjUgMCBvYmoKPDwgL0xlbmd0aCA3MiAvRmlsdGVyIC9GbGF0ZURlY29kZSA+PgpzdHJlYW0KeJwzMrdQMFCwNAEShhYmCuZmBgophlxAvqmJuUIuF0gMxMoBswyAtCWcgohngJggbRDFIBZEsZmJGUQdnAGRy+BKAwAl2xbJCmVuZHN0cmVhbQplbmRvYmoKMjYgMCBvYmoKPDwgL0xlbmd0aCAxNjMgL0ZpbHRlciAvRmxhdGVEZWNvZGUgPj4Kc3RyZWFtCnicRZA7EgMhDEN7TqEj+CMDPs9mMik2929j2GxSwNNYIIO7E4LU2oKJ6IKHtiXdBe+tBGdj/Ok2bjUS5AR1gFak42iUUn25xWmVdPFoNnMrC60THWYOepSjGaAQOhXe7aLkcqbuzvlDcPVf9b9i3TmbiYHJyh0IzepT3Pk2O6K6usn+pMfcrNd+K+xVYWlZS8sJt527ZkAJ3FM52qs9Px8KOvYKZW5kc3RyZWFtCmVuZG9iagoyNyAwIG9iago8PCAvTGVuZ3RoIDIxOCAvRmlsdGVyIC9GbGF0ZURlY29kZSA+PgpzdHJlYW0KeJw9ULmNBDEMy12FGljAeu2pZxaLS6b/9Ej59iLRFkVSKjWZkikvdZQlWVPeOnyWxA55huVuZDYlKkUvk7Al99AK8X2J5hT33dWWs0M0l2g5fgszKqobHdNLNppwKhO6oNzDM/oNbXQDVocesVsg0KRg17YgcscPGAzBmROLIgxKTQb/rnKPn16LGz7D8UMUkZIO5jX/WP3ycw2vU48nkW5vvuJenKkOAxEckpq8I11YsS4SEWk1QU3PwFotgLu3Xv4btCO6DED2icRxmlKOob9rcKXPL+UnU9gKZW5kc3RyZWFtCmVuZG9iagoyOCAwIG9iago8PCAvTGVuZ3RoIDgzIC9GaWx0ZXIgL0ZsYXRlRGVjb2RlID4+CnN0cmVhbQp4nEWMuw3AMAhEe6ZgBH4m9j5RlMLevw0QJW64J909XB0JmSluM8NDBp4MLIZdcYH0ljALXEdQjp3so2HVvuoEjfWmUvPvD5Se7KzihusBAkIaZgplbmRzdHJlYW0KZW5kb2JqCjI5IDAgb2JqCjw8IC9MZW5ndGggMTYwIC9GaWx0ZXIgL0ZsYXRlRGVjb2RlID4+CnN0cmVhbQp4nEWQORIDMQgEc72CJ0hcgvesy7XB+v+pB9ZHoukCNBy6Fk3KehRoPumxRqG60GvoLEqSRMEWkh1Qp2OIOyhITEhjkki2HoMjmlizXZiZVCqzUuG0acXCv9la1chEjXCN/InpBlT8T+pclPBNg6+SMfoYVLw7g4xJ+F5F3Fox7f5EMLEZ9glvRSYFhImxqdm+z2CGzPcK1zjH8w1MgjfrCmVuZHN0cmVhbQplbmRvYmoKMzAgMCBvYmoKPDwgL0xlbmd0aCA3MCAvRmlsdGVyIC9GbGF0ZURlY29kZSA+PgpzdHJlYW0KeJwzMzZTMFCwMAISpqaGCuZGlgophlxAPoiVywUTywGzzCzMgSwjC5CWHC5DC2MwbWJspGBmYgZkWSAxILoyuNIAmJoTAwplbmRzdHJlYW0KZW5kb2JqCjMxIDAgb2JqCjw8IC9MZW5ndGggMzIwIC9GaWx0ZXIgL0ZsYXRlRGVjb2RlID4+CnN0cmVhbQp4nDVSS24FMQjbzym4QKXwT87zqqqLvvtvaxO9FUwwYOMpL1nSS77UJdulw+RbH/clsULej+2azFLF9xazFM8tr0fPEbctCgRREz1YmS8VItTP9Og6qHBKn4FXCLcUG7yDSQCDavgHHqUzIFDnQMa7YjJSA4Ik2HNpcQiJciaJf6S8nt8nraSh9D1Zmcvfk0ul0B1NTugBxcrFSaBdSfmgmZhKRJKX632xQvSGwJI8PkcxyYDsNoltogUm5x6lJczEFDqwxwK8ZprVVehgwh6HKYxXC7OoHmzyWxOVpB2t4xnZMN7LMFNioeGwBdTmYmWC7uXjNa/CiO1Rk13DcO6WzXcI0Wj+GxbK4GMVkoBHp7ESDWk4wIjAnl44xV7zEzkOwIhjnZosDGNoJqd6jonA0J6zpWHGxx5a9fMPVOl8hwplbmRzdHJlYW0KZW5kb2JqCjMyIDAgb2JqCjw8IC9MZW5ndGggMTMzIC9GaWx0ZXIgL0ZsYXRlRGVjb2RlID4+CnN0cmVhbQp4nEWPSw4EIQhE95yijsDHH+dxMumFc//tgJ1uE2M9hVSBuYKhPS5rA50VHyEZtvG3qZaORVk+VHpSVg/J4Iesxssh3KAs8IJJKoYhUIuYGpEtZW63gNs2DbKylVOljrCLozCP9rRsFR5folsidZI/g8QqL9zjuh3Ipda73qKLvn+kATEJCmVuZHN0cmVhbQplbmRvYmoKMzMgMCBvYmoKPDwgL0xlbmd0aCAzNDAgL0ZpbHRlciAvRmxhdGVEZWNvZGUgPj4Kc3RyZWFtCnicNVI5bgQxDOv9Cn0ggG7b79kgSJH8vw2p2RQDcXRSlDtaVHbLh4VUtex0+bSV2hI35HdlhcQJyasS7VKGSKi8ViHV75kyr7c1ZwTIUqXC5KTkccmCP8OlpwvH+baxr+XIHY8eWBUjoUTAMsXE6BqWzu6wZlt+lmnAj3iEnCvWLcdYBVIb3TjtiveheS2yBoi9mZaKCh1WiRZ+QfGgR4199hhUWCDR7RxJcIyJUJGAdoHaSAw5eyx2UR/0MygxE+jaG0XcQYElkpg5xbp09N/40LGg/tiMN786KulbWllj0j4b7ZTGLDLpelj0dPPWx4MLNO+i/OfVDBI0ZY2Sxget2jmGoplRVni3Q5MNzTHHIfMOnsMZCUr6PBS/jyUTHZTI3w4NoX9fHqOMnDbeAuaiP20VBw7is8NeuYEVShdrkvcBqUzogen/r/G1vtfXHx3tgMYKZW5kc3RyZWFtCmVuZG9iagozNCAwIG9iago8PCAvTGVuZ3RoIDI1MSAvRmlsdGVyIC9GbGF0ZURlY29kZSA+PgpzdHJlYW0KeJwtUUlyA0EIu88r9IRmp99jlyuH5P/XCMoHBg2LQHRa4qCMnyAsV7zlkatow98zMYLfBYd+K9dtWORAVCBJY1A1oXbxevQe2HGYCcyT1rAMZqwP/Iwp3OjF4TEZZ7fXZdQQ7F2vPZlByaxcxCUTF0zVYSNnDj+ZMi60cz03IOdGWJdhkG5WGjMSjjSFSCGFqpukzgRBEoyuRo02chT7pS+PdIZVjagx7HMtbV/PTThr0OxYrPLklB5dcS4nFy+sHPT1NgMXUWms8kBIwP1uD/VzspPfeEvnzhbT43vNyfLCVGDFm9duQDbV4t+8iOP7jK/n5/n8A19gW4gKZW5kc3RyZWFtCmVuZG9iagozNSAwIG9iago8PCAvTGVuZ3RoIDIxNSAvRmlsdGVyIC9GbGF0ZURlY29kZSA+PgpzdHJlYW0KeJw1UTkOAyEM7PcV/kAkjC94T6Iozf6/zYzRVh7BXIa0lCGZ8lKTqCHlUz56mS6cutzXzGo055a0LXOAuLa8L62SwIlmiIPBaZi4AZo8AUPX0ahRQxce0NSlUyiw3AQ+irduD91jtYGXtiHniSBiKBksQc2pRRMWbc8npDW/Xosb3pft3chTpcaWGIEGAVY4HNfo1/CVPU8m0XQVMtSrNcsYCRNFIjz5jqbVE+taNNIyEtTGEaxqA7w7/TBOAAATccsCZJ9KlLPkxG+x9LMGV/r+AZ9HVJYKZW5kc3RyZWFtCmVuZG9iagoxNyAwIG9iago8PCAvVHlwZSAvRm9udCAvQmFzZUZvbnQgL0JNUVFEVitEZWphVnVTYW5zIC9GaXJzdENoYXIgMCAvTGFzdENoYXIgMjU1Ci9Gb250RGVzY3JpcHRvciAxNiAwIFIgL1N1YnR5cGUgL1R5cGUzIC9OYW1lIC9CTVFRRFYrRGVqYVZ1U2FucwovRm9udEJCb3ggWyAtMTAyMSAtNDYzIDE3OTQgMTIzMyBdIC9Gb250TWF0cml4IFsgMC4wMDEgMCAwIDAuMDAxIDAgMCBdCi9DaGFyUHJvY3MgMTggMCBSCi9FbmNvZGluZyA8PCAvVHlwZSAvRW5jb2RpbmcKL0RpZmZlcmVuY2VzIFsgNDggL3plcm8gL29uZSAvdHdvIC90aHJlZSAvZm91ciAvZml2ZSAvc2l4IC9zZXZlbiAvZWlnaHQgNzMgL0kgOTcgL2EgMTAxCi9lIDEwNSAvaSAxMTAgL24gL28gMTE0IC9yIDExNiAvdCBdCj4+Ci9XaWR0aHMgMTUgMCBSID4+CmVuZG9iagoxNiAwIG9iago8PCAvVHlwZSAvRm9udERlc2NyaXB0b3IgL0ZvbnROYW1lIC9CTVFRRFYrRGVqYVZ1U2FucyAvRmxhZ3MgMzIKL0ZvbnRCQm94IFsgLTEwMjEgLTQ2MyAxNzk0IDEyMzMgXSAvQXNjZW50IDkyOSAvRGVzY2VudCAtMjM2IC9DYXBIZWlnaHQgMAovWEhlaWdodCAwIC9JdGFsaWNBbmdsZSAwIC9TdGVtViAwIC9NYXhXaWR0aCAxMzQyID4+CmVuZG9iagoxNSAwIG9iagpbIDYwMCA2MDAgNjAwIDYwMCA2MDAgNjAwIDYwMCA2MDAgNjAwIDYwMCA2MDAgNjAwIDYwMCA2MDAgNjAwIDYwMCA2MDAgNjAwCjYwMCA2MDAgNjAwIDYwMCA2MDAgNjAwIDYwMCA2MDAgNjAwIDYwMCA2MDAgNjAwIDYwMCA2MDAgMzE4IDQwMSA0NjAgODM4IDYzNgo5NTAgNzgwIDI3NSAzOTAgMzkwIDUwMCA4MzggMzE4IDM2MSAzMTggMzM3IDYzNiA2MzYgNjM2IDYzNiA2MzYgNjM2IDYzNiA2MzYKNjM2IDYzNiAzMzcgMzM3IDgzOCA4MzggODM4IDUzMSAxMDAwIDY4NCA2ODYgNjk4IDc3MCA2MzIgNTc1IDc3NSA3NTIgMjk1CjI5NSA2NTYgNTU3IDg2MyA3NDggNzg3IDYwMyA3ODcgNjk1IDYzNSA2MTEgNzMyIDY4NCA5ODkgNjg1IDYxMSA2ODUgMzkwIDMzNwozOTAgODM4IDUwMCA1MDAgNjEzIDYzNSA1NTAgNjM1IDYxNSAzNTIgNjM1IDYzNCAyNzggMjc4IDU3OSAyNzggOTc0IDYzNCA2MTIKNjM1IDYzNSA0MTEgNTIxIDM5MiA2MzQgNTkyIDgxOCA1OTIgNTkyIDUyNSA2MzYgMzM3IDYzNiA4MzggNjAwIDYzNiA2MDAgMzE4CjM1MiA1MTggMTAwMCA1MDAgNTAwIDUwMCAxMzQyIDYzNSA0MDAgMTA3MCA2MDAgNjg1IDYwMCA2MDAgMzE4IDMxOCA1MTggNTE4CjU5MCA1MDAgMTAwMCA1MDAgMTAwMCA1MjEgNDAwIDEwMjMgNjAwIDUyNSA2MTEgMzE4IDQwMSA2MzYgNjM2IDYzNiA2MzYgMzM3CjUwMCA1MDAgMTAwMCA0NzEgNjEyIDgzOCAzNjEgMTAwMCA1MDAgNTAwIDgzOCA0MDEgNDAxIDUwMCA2MzYgNjM2IDMxOCA1MDAKNDAxIDQ3MSA2MTIgOTY5IDk2OSA5NjkgNTMxIDY4NCA2ODQgNjg0IDY4NCA2ODQgNjg0IDk3NCA2OTggNjMyIDYzMiA2MzIgNjMyCjI5NSAyOTUgMjk1IDI5NSA3NzUgNzQ4IDc4NyA3ODcgNzg3IDc4NyA3ODcgODM4IDc4NyA3MzIgNzMyIDczMiA3MzIgNjExIDYwNQo2MzAgNjEzIDYxMyA2MTMgNjEzIDYxMyA2MTMgOTgyIDU1MCA2MTUgNjE1IDYxNSA2MTUgMjc4IDI3OCAyNzggMjc4IDYxMiA2MzQKNjEyIDYxMiA2MTIgNjEyIDYxMiA4MzggNjEyIDYzNCA2MzQgNjM0IDYzNCA1OTIgNjM1IDU5MiBdCmVuZG9iagoxOCAwIG9iago8PCAvSSAxOSAwIFIgL2EgMjAgMCBSIC9lIDIxIDAgUiAvZWlnaHQgMjIgMCBSIC9maXZlIDIzIDAgUiAvZm91ciAyNCAwIFIKL2kgMjUgMCBSIC9uIDI2IDAgUiAvbyAyNyAwIFIgL29uZSAyOCAwIFIgL3IgMjkgMCBSIC9zZXZlbiAzMCAwIFIKL3NpeCAzMSAwIFIgL3QgMzIgMCBSIC90aHJlZSAzMyAwIFIgL3R3byAzNCAwIFIgL3plcm8gMzUgMCBSID4+CmVuZG9iagozIDAgb2JqCjw8IC9GMSAxNyAwIFIgPj4KZW5kb2JqCjQgMCBvYmoKPDwgL0ExIDw8IC9UeXBlIC9FeHRHU3RhdGUgL0NBIDAgL2NhIDEgPj4KL0EyIDw8IC9UeXBlIC9FeHRHU3RhdGUgL0NBIDEgL2NhIDEgPj4gPj4KZW5kb2JqCjUgMCBvYmoKPDwgPj4KZW5kb2JqCjYgMCBvYmoKPDwgPj4KZW5kb2JqCjcgMCBvYmoKPDwgL00wIDEzIDAgUiAvTTEgMTQgMCBSID4+CmVuZG9iagoxMyAwIG9iago8PCAvVHlwZSAvWE9iamVjdCAvU3VidHlwZSAvRm9ybSAvQkJveCBbIC04IC04IDggOCBdIC9MZW5ndGggMTMxCi9GaWx0ZXIgL0ZsYXRlRGVjb2RlID4+CnN0cmVhbQp4nG2QQQ6EIAxF9z1FL/BJS0Vl69JruJlM4v23A3FATN000L48flH+kvBOpcD4JAlLTrPketOQ0rpMjBjm1bIox6BRLdbOdTioz9BwY3SLsRSm1NboeKOb6Tbekz/6sFkhRj8cDq+EexZDJlwpMQaH3wsv28P/EZ5e1MAfoo1+Y1pD/QplbmRzdHJlYW0KZW5kb2JqCjE0IDAgb2JqCjw8IC9UeXBlIC9YT2JqZWN0IC9TdWJ0eXBlIC9Gb3JtIC9CQm94IFsgLTggLTggOCA4IF0gL0xlbmd0aCAxMzEKL0ZpbHRlciAvRmxhdGVEZWNvZGUgPj4Kc3RyZWFtCnicbZBBDoQgDEX3PUUv8ElLRWXr0mu4mUzi/bcDcUBM3TTQvjx+Uf6S8E6lwPgkCUtOs+R605DSukyMGObVsijHoFEt1s51OKjP0HBjdIuxFKbU1uh4o5vpNt6TP/qwWSFGPxwOr4R7FkMmXCkxBoffCy/bw/8Rnl7UwB+ijX5jWkP9CmVuZHN0cmVhbQplbmRvYmoKMiAwIG9iago8PCAvVHlwZSAvUGFnZXMgL0tpZHMgWyAxMSAwIFIgXSAvQ291bnQgMSA+PgplbmRvYmoKMzYgMCBvYmoKPDwgL0NyZWF0b3IgKE1hdHBsb3RsaWIgdjMuOC4yLCBodHRwczovL21hdHBsb3RsaWIub3JnKQovUHJvZHVjZXIgKE1hdHBsb3RsaWIgcGRmIGJhY2tlbmQgdjMuOC4yKQovQ3JlYXRpb25EYXRlIChEOjIwMjQwNzE3MTQxNDE2KzAyJzAwJykgPj4KZW5kb2JqCnhyZWYKMCAzNwowMDAwMDAwMDAwIDY1NTM1IGYgCjAwMDAwMDAwMTYgMDAwMDAgbiAKMDAwMDAwODYxOSAwMDAwMCBuIAowMDAwMDA3ODk1IDAwMDAwIG4gCjAwMDAwMDc5MjcgMDAwMDAgbiAKMDAwMDAwODAyNiAwMDAwMCBuIAowMDAwMDA4MDQ3IDAwMDAwIG4gCjAwMDAwMDgwNjggMDAwMDAgbiAKMDAwMDAwMDA2NSAwMDAwMCBuIAowMDAwMDAwMzQzIDAwMDAwIG4gCjAwMDAwMDEzNzYgMDAwMDAgbiAKMDAwMDAwMDIwOCAwMDAwMCBuIAowMDAwMDAxMzU2IDAwMDAwIG4gCjAwMDAwMDgxMTEgMDAwMDAgbiAKMDAwMDAwODM2NSAwMDAwMCBuIAowMDAwMDA2NjIzIDAwMDAwIG4gCjAwMDAwMDY0MTYgMDAwMDAgbiAKMDAwMDAwNjAwMiAwMDAwMCBuIAowMDAwMDA3Njc2IDAwMDAwIG4gCjAwMDAwMDEzOTYgMDAwMDAgbiAKMDAwMDAwMTUxOSAwMDAwMCBuIAowMDAwMDAxODk5IDAwMDAwIG4gCjAwMDAwMDIyMjEgMDAwMDAgbiAKMDAwMDAwMjY4OSAwMDAwMCBuIAowMDAwMDAzMDExIDAwMDAwIG4gCjAwMDAwMDMxNzcgMDAwMDAgbiAKMDAwMDAwMzMyMSAwMDAwMCBuIAowMDAwMDAzNTU3IDAwMDAwIG4gCjAwMDAwMDM4NDggMDAwMDAgbiAKMDAwMDAwNDAwMyAwMDAwMCBuIAowMDAwMDA0MjM2IDAwMDAwIG4gCjAwMDAwMDQzNzggMDAwMDAgbiAKMDAwMDAwNDc3MSAwMDAwMCBuIAowMDAwMDA0OTc3IDAwMDAwIG4gCjAwMDAwMDUzOTAgMDAwMDAgbiAKMDAwMDAwNTcxNCAwMDAwMCBuIAowMDAwMDA4Njc5IDAwMDAwIG4gCnRyYWlsZXIKPDwgL1NpemUgMzcgL1Jvb3QgMSAwIFIgL0luZm8gMzYgMCBSID4+CnN0YXJ0eHJlZgo4ODM2CiUlRU9GCg==",
      "text/plain": [
       "<Figure size 2700x1800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| label: fig-plot-progress-37a\n",
    "#| fig-cap: Progress of the original experiment\n",
    "spot_tuner.plot_progress(log_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fig-plot-progress-37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/pdf": "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",
      "text/plain": [
       "<Figure size 2700x1800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| label: fig-plot-progress-37b\n",
    "#| fig-cap: Progress of the reloaded experiment\n",
    "spot_tuner_1.plot_progress(log_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6dc032",
   "metadata": {},
   "source": [
    "The results from the original experiment are shown in @tbl-results-37a and the reloaded experiment in @tbl-results-37b.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "tbl-results-37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min y: 1.986328241945829\n",
      "x0: 10.0\n",
      "x1: 3.2107728198306598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['x0', 10.0], ['x1', 3.2107728198306598]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| label: tbl-results-37a\n",
    "spot_tuner.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "tbl-results-37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min y: 1.986328241945829\n",
      "x0: 10.0\n",
      "x1: 3.2107728198306598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['x0', 10.0], ['x1', 3.2107728198306598]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| label: tbl-results-37b\n",
    "spot_tuner_1.print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8f0873",
   "metadata": {},
   "source": [
    "#### Getting the Tuned Hyperparameters\n",
    "\n",
    "The tuned hyperparameters can be obtained as a dictionary with the following code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "code-get-tuned-optimization-37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x0': 10.0, 'x1': 3.2107728198306598}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| label: code-get-tuned-optimization-37\n",
    "from spotPython.hyperparameters.values import get_tuned_hyperparameters\n",
    "get_tuned_hyperparameters(spot_tuner=spot_tuner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b30ddd6",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "### Summary: Saving and Loading Optimization Experiments\n",
    "* If `spotPython` is used as an optimizer (without an hyperparameter dictionary), experiments can be saved and reloaded with the `save_experiment` and `load_experiment` functions.\n",
    "* The tuned hyperparameters can be obtained with the `get_tuned_hyperparameters` function.\n",
    ":::\n",
    "\n",
    "\n",
    "\n",
    "## spotPython as a Hyperparameter Tuner {#sec-spotpython-as-a-hyperparameter-tuner-37}\n",
    "\n",
    "If `spotPython` is used as a hyperparameter tuner, in addition to the `fun_control` dictionary a `core_model` dictionary have to be specified.\n",
    "This will be explained in @sec-adding-a-core-model-37.\n",
    "\n",
    "Furthermore, a data set has to be selected and added to the `fun_control` dictionary.\n",
    "Here, we will use the `Diabetes` data set.\n",
    "\n",
    "\n",
    "### The Diabetes Data Set\n",
    "\n",
    "The hyperparameter tuning of a `PyTorch Lightning` network on the `Diabetes` data set is used as an example. The `Diabetes` data set is a PyTorch Dataset for regression, which originates from the `scikit-learn` package, see [https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes).\n",
    "\n",
    " Ten baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements were obtained for each of n = 442 diabetes patients,  as well as the response of interest, a quantitative measure of disease progression one year after baseline.\n",
    "The `Diabetes` data set is described in @tbl-diabetes-31.\n",
    "\n",
    "| Description | Value |\n",
    "| --- | --- |\n",
    "| Samples total | 442 |\n",
    "| Dimensionality | 10 |\n",
    "| Features | real, -.2 < x < .2 |\n",
    "| Targets | integer 25 - 346 |\n",
    ": The Diabetes data set {#tbl-diabetes-31}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "code-hyperparameter-tuning-37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving TENSORBOARD_PATH: runs/ to TENSORBOARD_PATH_OLD: runs_OLD/runs_2024_07_17_14_14_17\n",
      "Created spot_tensorboard_path: runs/spot_logs/037_maans14_2024-07-17_14-14-17 for SummaryWriter()\n"
     ]
    }
   ],
   "source": [
    "#| label: code-hyperparameter-tuning-37\n",
    "from spotPython.utils.device import getDevice\n",
    "from math import inf\n",
    "from spotPython.utils.init import fun_control_init\n",
    "import numpy as np\n",
    "from spotPython.hyperparameters.values import set_control_key_value\n",
    "from spotPython.data.diabetes import Diabetes\n",
    "\n",
    "MAX_TIME = inf\n",
    "FUN_EVALS = 8\n",
    "INIT_SIZE = 5\n",
    "WORKERS = 0\n",
    "PREFIX=\"037\"\n",
    "DEVICE = getDevice()\n",
    "DEVICES = 1\n",
    "TEST_SIZE = 0.4\n",
    "TORCH_METRIC = \"mean_squared_error\"\n",
    "dataset = Diabetes()\n",
    "\n",
    "fun_control = fun_control_init(\n",
    "    _L_in=10,\n",
    "    _L_out=1,\n",
    "    _torchmetric=TORCH_METRIC,\n",
    "    PREFIX=PREFIX,\n",
    "    TENSORBOARD_CLEAN=True,\n",
    "    data_set=dataset,\n",
    "    device=DEVICE,\n",
    "    enable_progress_bar=False,\n",
    "    fun_evals=FUN_EVALS,\n",
    "    log_level=10,\n",
    "    max_time=MAX_TIME,\n",
    "    num_workers=WORKERS,\n",
    "    show_progress=True,\n",
    "    test_size=TEST_SIZE,\n",
    "    tolerance_x=np.sqrt(np.spacing(1)),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846e444e",
   "metadata": {},
   "source": [
    "### Adding a `core_model` to the `fun_control` Dictionary {#sec-adding-a-core-model-37}\n",
    "\n",
    "`spotPython` includes the `NetLightRegression` class [[SOURCE]](https://github.com/sequential-parameter-optimization/spotPython/blob/main/src/spotPython/light/NetLightRegression.py) for configurable neural networks. \n",
    "The class is imported here. It inherits from the class `Lightning.LightningModule`, which is the base class for all models in `Lightning`. `Lightning.LightningModule` is a subclass of `torch.nn.Module` and provides additional functionality for the training and testing of neural networks. The class `Lightning.LightningModule` is described in the [Lightning documentation](https://lightning.ai/docs/pytorch/stable/common/lightning_module.html).\n",
    "\n",
    "\n",
    "The hyperparameters of the model are specified in the `core_model_hyper_dict` dictionary [[SOURCE]](https://github.com/sequential-parameter-optimization/spotPython/blob/main/src/spotPython/hyperdict/light_hyper_dict.json).\n",
    "\n",
    "The `core_model` dictionary contains the hyperparameters of the model to be tuned. These hyperparameters can be specified and modified with as shown in the following code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "code-add-core-model-to-fun-control-37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting hyperparameter epochs to value [4, 5].\n",
      "Variable type is int.\n",
      "Core type is None.\n",
      "Calling modify_hyper_parameter_bounds().\n",
      "Setting hyperparameter batch_size to value [4, 5].\n",
      "Variable type is int.\n",
      "Core type is None.\n",
      "Calling modify_hyper_parameter_bounds().\n",
      "Setting hyperparameter optimizer to value ['Adam', 'RAdam'].\n",
      "Variable type is factor.\n",
      "Core type is str.\n",
      "Calling modify_hyper_parameter_levels().\n",
      "Setting hyperparameter dropout_prob to value [0.01, 0.1].\n",
      "Variable type is float.\n",
      "Core type is None.\n",
      "Calling modify_hyper_parameter_bounds().\n",
      "Setting hyperparameter lr_mult to value [0.05, 1.0].\n",
      "Variable type is float.\n",
      "Core type is None.\n",
      "Calling modify_hyper_parameter_bounds().\n",
      "Setting hyperparameter patience to value [2, 3].\n",
      "Variable type is int.\n",
      "Core type is None.\n",
      "Calling modify_hyper_parameter_bounds().\n",
      "Setting hyperparameter act_fn to value ['ReLU', 'LeakyReLU'].\n",
      "Variable type is factor.\n",
      "Core type is instance().\n",
      "Calling modify_hyper_parameter_levels().\n"
     ]
    }
   ],
   "source": [
    "#| label: code-add-core-model-to-fun-control-37\n",
    "from spotPython.light.regression.netlightregression import NetLightRegression\n",
    "from spotPython.hyperdict.light_hyper_dict import LightHyperDict\n",
    "from spotPython.hyperparameters.values import add_core_model_to_fun_control\n",
    "add_core_model_to_fun_control(fun_control=fun_control,\n",
    "                              core_model=NetLightRegression,\n",
    "                              hyper_dict=LightHyperDict)\n",
    "from spotPython.hyperparameters.values import set_control_hyperparameter_value\n",
    "\n",
    "set_control_hyperparameter_value(fun_control, \"epochs\", [4, 5])\n",
    "set_control_hyperparameter_value(fun_control, \"batch_size\", [4, 5])\n",
    "set_control_hyperparameter_value(fun_control, \"optimizer\", [\n",
    "                \"Adam\",\n",
    "                \"RAdam\",\n",
    "            ])\n",
    "set_control_hyperparameter_value(fun_control, \"dropout_prob\", [0.01, 0.1])\n",
    "set_control_hyperparameter_value(fun_control, \"lr_mult\", [0.05, 1.0])\n",
    "set_control_hyperparameter_value(fun_control, \"patience\", [2, 3])\n",
    "set_control_hyperparameter_value(fun_control, \"act_fn\",[\n",
    "                \"ReLU\",\n",
    "                \"LeakyReLU\"\n",
    "            ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b25d5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CHECKPOINT_PATH': 'runs/saved_models/',\n",
      " 'DATASET_PATH': 'data/',\n",
      " 'PREFIX': '037',\n",
      " 'RESULTS_PATH': 'results/',\n",
      " 'TENSORBOARD_PATH': 'runs/',\n",
      " '_L_in': 10,\n",
      " '_L_out': 1,\n",
      " '_torchmetric': 'mean_squared_error',\n",
      " 'accelerator': 'auto',\n",
      " 'converters': None,\n",
      " 'core_model': <class 'spotPython.light.regression.netlightregression.NetLightRegression'>,\n",
      " 'core_model_hyper_dict': {'act_fn': {'class_name': 'spotPython.torch.activation',\n",
      "                                      'core_model_parameter_type': 'instance()',\n",
      "                                      'default': 'ReLU',\n",
      "                                      'levels': ['ReLU', 'LeakyReLU'],\n",
      "                                      'lower': 0,\n",
      "                                      'transform': 'None',\n",
      "                                      'type': 'factor',\n",
      "                                      'upper': 1},\n",
      "                           'batch_size': {'default': 4,\n",
      "                                          'lower': 4,\n",
      "                                          'transform': 'transform_power_2_int',\n",
      "                                          'type': 'int',\n",
      "                                          'upper': 5},\n",
      "                           'dropout_prob': {'default': 0.01,\n",
      "                                            'lower': 0.01,\n",
      "                                            'transform': 'None',\n",
      "                                            'type': 'float',\n",
      "                                            'upper': 0.1},\n",
      "                           'epochs': {'default': 4,\n",
      "                                      'lower': 4,\n",
      "                                      'transform': 'transform_power_2_int',\n",
      "                                      'type': 'int',\n",
      "                                      'upper': 5},\n",
      "                           'initialization': {'core_model_parameter_type': 'str',\n",
      "                                              'default': 'Default',\n",
      "                                              'levels': ['Default'],\n",
      "                                              'lower': 0,\n",
      "                                              'transform': 'None',\n",
      "                                              'type': 'factor',\n",
      "                                              'upper': 0},\n",
      "                           'l1': {'default': 3,\n",
      "                                  'lower': 3,\n",
      "                                  'transform': 'transform_power_2_int',\n",
      "                                  'type': 'int',\n",
      "                                  'upper': 8},\n",
      "                           'lr_mult': {'default': 1.0,\n",
      "                                       'lower': 0.05,\n",
      "                                       'transform': 'None',\n",
      "                                       'type': 'float',\n",
      "                                       'upper': 1.0},\n",
      "                           'optimizer': {'class_name': 'torch.optim',\n",
      "                                         'core_model_parameter_type': 'str',\n",
      "                                         'default': 'SGD',\n",
      "                                         'levels': ['Adam', 'RAdam'],\n",
      "                                         'lower': 0,\n",
      "                                         'transform': 'None',\n",
      "                                         'type': 'factor',\n",
      "                                         'upper': 1},\n",
      "                           'patience': {'default': 2,\n",
      "                                        'lower': 2,\n",
      "                                        'transform': 'transform_power_2_int',\n",
      "                                        'type': 'int',\n",
      "                                        'upper': 3}},\n",
      " 'core_model_hyper_dict_default': {'act_fn': {'class_name': 'spotPython.torch.activation',\n",
      "                                              'core_model_parameter_type': 'instance()',\n",
      "                                              'default': 'ReLU',\n",
      "                                              'levels': ['Sigmoid',\n",
      "                                                         'Tanh',\n",
      "                                                         'ReLU',\n",
      "                                                         'LeakyReLU',\n",
      "                                                         'ELU',\n",
      "                                                         'Swish'],\n",
      "                                              'lower': 0,\n",
      "                                              'transform': 'None',\n",
      "                                              'type': 'factor',\n",
      "                                              'upper': 5},\n",
      "                                   'batch_size': {'default': 4,\n",
      "                                                  'lower': 1,\n",
      "                                                  'transform': 'transform_power_2_int',\n",
      "                                                  'type': 'int',\n",
      "                                                  'upper': 4},\n",
      "                                   'dropout_prob': {'default': 0.01,\n",
      "                                                    'lower': 0.0,\n",
      "                                                    'transform': 'None',\n",
      "                                                    'type': 'float',\n",
      "                                                    'upper': 0.25},\n",
      "                                   'epochs': {'default': 4,\n",
      "                                              'lower': 4,\n",
      "                                              'transform': 'transform_power_2_int',\n",
      "                                              'type': 'int',\n",
      "                                              'upper': 9},\n",
      "                                   'initialization': {'core_model_parameter_type': 'str',\n",
      "                                                      'default': 'Default',\n",
      "                                                      'levels': ['Default',\n",
      "                                                                 'Kaiming',\n",
      "                                                                 'Xavier'],\n",
      "                                                      'lower': 0,\n",
      "                                                      'transform': 'None',\n",
      "                                                      'type': 'factor',\n",
      "                                                      'upper': 2},\n",
      "                                   'l1': {'default': 3,\n",
      "                                          'lower': 3,\n",
      "                                          'transform': 'transform_power_2_int',\n",
      "                                          'type': 'int',\n",
      "                                          'upper': 8},\n",
      "                                   'lr_mult': {'default': 1.0,\n",
      "                                               'lower': 0.1,\n",
      "                                               'transform': 'None',\n",
      "                                               'type': 'float',\n",
      "                                               'upper': 10.0},\n",
      "                                   'optimizer': {'class_name': 'torch.optim',\n",
      "                                                 'core_model_parameter_type': 'str',\n",
      "                                                 'default': 'SGD',\n",
      "                                                 'levels': ['Adadelta',\n",
      "                                                            'Adagrad',\n",
      "                                                            'Adam',\n",
      "                                                            'AdamW',\n",
      "                                                            'SparseAdam',\n",
      "                                                            'Adamax',\n",
      "                                                            'ASGD',\n",
      "                                                            'NAdam',\n",
      "                                                            'RAdam',\n",
      "                                                            'RMSprop',\n",
      "                                                            'Rprop',\n",
      "                                                            'SGD'],\n",
      "                                                 'lower': 0,\n",
      "                                                 'transform': 'None',\n",
      "                                                 'type': 'factor',\n",
      "                                                 'upper': 11},\n",
      "                                   'patience': {'default': 2,\n",
      "                                                'lower': 2,\n",
      "                                                'transform': 'transform_power_2_int',\n",
      "                                                'type': 'int',\n",
      "                                                'upper': 6}},\n",
      " 'core_model_name': None,\n",
      " 'counter': 0,\n",
      " 'data': None,\n",
      " 'data_dir': './data',\n",
      " 'data_module': None,\n",
      " 'data_set': <spotPython.data.diabetes.Diabetes object at 0x3cabbe810>,\n",
      " 'data_set_name': None,\n",
      " 'db_dict_name': None,\n",
      " 'design': None,\n",
      " 'device': 'mps',\n",
      " 'devices': 1,\n",
      " 'enable_progress_bar': False,\n",
      " 'eval': None,\n",
      " 'fun_evals': 8,\n",
      " 'fun_repeats': 1,\n",
      " 'horizon': None,\n",
      " 'hyperdict': None,\n",
      " 'infill_criterion': 'y',\n",
      " 'k_folds': 3,\n",
      " 'log_graph': False,\n",
      " 'log_level': 10,\n",
      " 'loss_function': None,\n",
      " 'lower': array([3. , 4. , 1. , 0. , 0. , 0. , 0.1, 2. , 0. ]),\n",
      " 'max_surrogate_points': 30,\n",
      " 'max_time': inf,\n",
      " 'metric_params': {},\n",
      " 'metric_river': None,\n",
      " 'metric_sklearn': None,\n",
      " 'metric_sklearn_name': None,\n",
      " 'metric_torch': None,\n",
      " 'model_dict': {},\n",
      " 'n_points': 1,\n",
      " 'n_samples': None,\n",
      " 'n_total': None,\n",
      " 'noise': False,\n",
      " 'num_workers': 0,\n",
      " 'ocba_delta': 0,\n",
      " 'oml_grace_period': None,\n",
      " 'optimizer': None,\n",
      " 'path': None,\n",
      " 'prep_model': None,\n",
      " 'prep_model_name': None,\n",
      " 'progress_file': None,\n",
      " 'save_model': False,\n",
      " 'scaler': None,\n",
      " 'scenario': None,\n",
      " 'seed': 123,\n",
      " 'show_batch_interval': 1000000,\n",
      " 'show_models': False,\n",
      " 'show_progress': True,\n",
      " 'shuffle': None,\n",
      " 'sigma': 0.0,\n",
      " 'spot_tensorboard_path': 'runs/spot_logs/037_maans14_2024-07-17_14-14-17',\n",
      " 'spot_writer': <torch.utils.tensorboard.writer.SummaryWriter object at 0x3caab65d0>,\n",
      " 'target_column': None,\n",
      " 'target_type': None,\n",
      " 'task': None,\n",
      " 'test': None,\n",
      " 'test_seed': 1234,\n",
      " 'test_size': 0.4,\n",
      " 'tolerance_x': 1.4901161193847656e-08,\n",
      " 'train': None,\n",
      " 'upper': array([ 8.  ,  9.  ,  4.  ,  5.  , 11.  ,  0.25, 10.  ,  6.  ,  2.  ]),\n",
      " 'var_name': ['l1',\n",
      "              'epochs',\n",
      "              'batch_size',\n",
      "              'act_fn',\n",
      "              'optimizer',\n",
      "              'dropout_prob',\n",
      "              'lr_mult',\n",
      "              'patience',\n",
      "              'initialization'],\n",
      " 'var_type': ['int',\n",
      "              'int',\n",
      "              'int',\n",
      "              'factor',\n",
      "              'factor',\n",
      "              'float',\n",
      "              'float',\n",
      "              'int',\n",
      "              'factor'],\n",
      " 'verbosity': 0,\n",
      " 'weight_coeff': 0.0,\n",
      " 'weights': 1.0,\n",
      " 'weights_entry': None}\n"
     ]
    }
   ],
   "source": [
    "import pprint as pp\n",
    "from spotPython.hyperparameters.values import set_factor_hyperparameter_values\n",
    "set_factor_hyperparameter_values(fun_control, \"initialization\", [\"Default\"])\n",
    "pp.pprint(fun_control)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4fbbc8",
   "metadata": {},
   "source": [
    "### `design_control`,  `surrogate_control` Dictionaries and the Objective Function {#sec-specifying-design-surrogate-control-dictionaries-37}\n",
    "\n",
    "After specifying the `design_control` and `surrogate_control` dictionaries, the objective function `fun` from the class `HyperLight` [[SOURCE]](https://github.com/sequential-parameter-optimization/spotPython/blob/main/src/spotPython/fun/hyperlight.py) is selected. It implements an interface from `PyTorch`'s training, validation, and testing methods to `spotPython`.\n",
    "\n",
    "Then, the hyperparameter tuning can be started.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "code-start-hyperparameter-tuning-37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule.setup(): stage: TrainerFn.FITTING\n",
      "train_size: 0.36, val_size: 0.24 used for train & val data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------\n",
      "0 | layers | Sequential | 4.4 K  | [16, 10] | [16, 1]  \n",
      "-------------------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.018     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule.val_dataloader(). Val. set size: 106\n",
      "LightDataModule.train_dataloader(). data_train size: 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=32` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule.setup(): stage: TrainerFn.VALIDATING\n",
      "LightDataModule.val_dataloader(). Val. set size: 106\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">      Validate metric      </span><span style=\"font-weight: bold\">       DataLoader 0        </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span><span style=\"color: #800080; text-decoration-color: #800080\">     3785.64111328125      </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span><span style=\"color: #800080; text-decoration-color: #800080\">     3785.64111328125      </span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    3785.64111328125     \u001b[0m\u001b[35m \u001b[0m\n",
       "\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    3785.64111328125     \u001b[0m\u001b[35m \u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------\n",
      "0 | layers | Sequential | 1.3 K  | [32, 10] | [32, 1]  \n",
      "-------------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 3785.64111328125, 'hp_metric': 3785.64111328125}\n",
      "LightDataModule.setup(): stage: TrainerFn.FITTING\n",
      "train_size: 0.36, val_size: 0.24 used for train & val data.\n",
      "LightDataModule.val_dataloader(). Val. set size: 106\n",
      "LightDataModule.train_dataloader(). data_train size: 160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule.setup(): stage: TrainerFn.VALIDATING\n",
      "LightDataModule.val_dataloader(). Val. set size: 106\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">      Validate metric      </span><span style=\"font-weight: bold\">       DataLoader 0        </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span><span style=\"color: #800080; text-decoration-color: #800080\">            nan            </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span><span style=\"color: #800080; text-decoration-color: #800080\">            nan            </span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m\n",
       "\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------\n",
      "0 | layers | Sequential | 15.9 K | [16, 10] | [16, 1]  \n",
      "-------------------------------------------------------------\n",
      "15.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.9 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': nan, 'hp_metric': nan}\n",
      "LightDataModule.setup(): stage: TrainerFn.FITTING\n",
      "train_size: 0.36, val_size: 0.24 used for train & val data.\n",
      "LightDataModule.val_dataloader(). Val. set size: 106\n",
      "LightDataModule.train_dataloader(). data_train size: 160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule.setup(): stage: TrainerFn.VALIDATING\n",
      "LightDataModule.val_dataloader(). Val. set size: 106\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">      Validate metric      </span><span style=\"font-weight: bold\">       DataLoader 0        </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span><span style=\"color: #800080; text-decoration-color: #800080\">            nan            </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span><span style=\"color: #800080; text-decoration-color: #800080\">            nan            </span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m\n",
       "\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m           nan           \u001b[0m\u001b[35m \u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------\n",
      "0 | layers | Sequential | 425    | [32, 10] | [32, 1]  \n",
      "-------------------------------------------------------------\n",
      "425       Trainable params\n",
      "0         Non-trainable params\n",
      "425       Total params\n",
      "0.002     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': nan, 'hp_metric': nan}\n",
      "LightDataModule.setup(): stage: TrainerFn.FITTING\n",
      "train_size: 0.36, val_size: 0.24 used for train & val data.\n",
      "LightDataModule.val_dataloader(). Val. set size: 106\n",
      "LightDataModule.train_dataloader(). data_train size: 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=16` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule.setup(): stage: TrainerFn.VALIDATING\n",
      "LightDataModule.val_dataloader(). Val. set size: 106\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">      Validate metric      </span><span style=\"font-weight: bold\">       DataLoader 0        </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span><span style=\"color: #800080; text-decoration-color: #800080\">      23998.68359375       </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span><span style=\"color: #800080; text-decoration-color: #800080\">      23998.68359375       </span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m     23998.68359375      \u001b[0m\u001b[35m \u001b[0m\n",
       "\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m     23998.68359375      \u001b[0m\u001b[35m \u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------\n",
      "0 | layers | Sequential | 1.3 K  | [16, 10] | [16, 1]  \n",
      "-------------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 23998.68359375, 'hp_metric': 23998.68359375}\n",
      "LightDataModule.setup(): stage: TrainerFn.FITTING\n",
      "train_size: 0.36, val_size: 0.24 used for train & val data.\n",
      "LightDataModule.val_dataloader(). Val. set size: 106\n",
      "LightDataModule.train_dataloader(). data_train size: 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=16` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule.setup(): stage: TrainerFn.VALIDATING\n",
      "LightDataModule.val_dataloader(). Val. set size: 106\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">      Validate metric      </span><span style=\"font-weight: bold\">       DataLoader 0        </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span><span style=\"color: #800080; text-decoration-color: #800080\">      23886.58984375       </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span><span style=\"color: #800080; text-decoration-color: #800080\">      23886.58984375       </span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m     23886.58984375      \u001b[0m\u001b[35m \u001b[0m\n",
       "\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m     23886.58984375      \u001b[0m\u001b[35m \u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/spotPython/utils/repair.py:71: UserWarning:\n",
      "\n",
      "\n",
      "!!! The dimension of the returned y array is 3, which is smaller than the original dimension 5.\n",
      "\n",
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/spotPython/utils/repair.py:75: UserWarning:\n",
      "\n",
      "\n",
      "!!! Check whether to continue with the reduced dimension is useful.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 23886.58984375, 'hp_metric': 23886.58984375}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------\n",
      "0 | layers | Sequential | 4.4 K  | [16, 10] | [16, 1]  \n",
      "-------------------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.018     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule.setup(): stage: TrainerFn.FITTING\n",
      "train_size: 0.36, val_size: 0.24 used for train & val data.\n",
      "LightDataModule.val_dataloader(). Val. set size: 106\n",
      "LightDataModule.train_dataloader(). data_train size: 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=32` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule.setup(): stage: TrainerFn.VALIDATING\n",
      "LightDataModule.val_dataloader(). Val. set size: 106\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">      Validate metric      </span><span style=\"font-weight: bold\">       DataLoader 0        </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span><span style=\"color: #800080; text-decoration-color: #800080\">     4100.16943359375      </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span><span style=\"color: #800080; text-decoration-color: #800080\">     4100.16943359375      </span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    4100.16943359375     \u001b[0m\u001b[35m \u001b[0m\n",
       "\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    4100.16943359375     \u001b[0m\u001b[35m \u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 4100.16943359375, 'hp_metric': 4100.16943359375}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotPython tuning: 3785.64111328125 [#####-----] 50.00% \r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------\n",
      "0 | layers | Sequential | 4.4 K  | [16, 10] | [16, 1]  \n",
      "-------------------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.018     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule.setup(): stage: TrainerFn.FITTING\n",
      "train_size: 0.36, val_size: 0.24 used for train & val data.\n",
      "LightDataModule.val_dataloader(). Val. set size: 106\n",
      "LightDataModule.train_dataloader(). data_train size: 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=32` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule.setup(): stage: TrainerFn.VALIDATING\n",
      "LightDataModule.val_dataloader(). Val. set size: 106\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">      Validate metric      </span><span style=\"font-weight: bold\">       DataLoader 0        </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span><span style=\"color: #800080; text-decoration-color: #800080\">     4670.54931640625      </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span><span style=\"color: #800080; text-decoration-color: #800080\">     4670.54931640625      </span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    4670.54931640625     \u001b[0m\u001b[35m \u001b[0m\n",
       "\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    4670.54931640625     \u001b[0m\u001b[35m \u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 4670.54931640625, 'hp_metric': 4670.54931640625}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotPython tuning: 3785.64111328125 [######----] 62.50% \r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------\n",
      "0 | layers | Sequential | 4.4 K  | [16, 10] | [16, 1]  \n",
      "-------------------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.018     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule.setup(): stage: TrainerFn.FITTING\n",
      "train_size: 0.36, val_size: 0.24 used for train & val data.\n",
      "LightDataModule.val_dataloader(). Val. set size: 106\n",
      "LightDataModule.train_dataloader(). data_train size: 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=32` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule.setup(): stage: TrainerFn.VALIDATING\n",
      "LightDataModule.val_dataloader(). Val. set size: 106\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">      Validate metric      </span><span style=\"font-weight: bold\">       DataLoader 0        </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span><span style=\"color: #800080; text-decoration-color: #800080\">      3872.4970703125      </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span><span style=\"color: #800080; text-decoration-color: #800080\">      3872.4970703125      </span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m     3872.4970703125     \u001b[0m\u001b[35m \u001b[0m\n",
       "\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m     3872.4970703125     \u001b[0m\u001b[35m \u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 3872.4970703125, 'hp_metric': 3872.4970703125}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotPython tuning: 3785.64111328125 [########--] 75.00% \r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------\n",
      "0 | layers | Sequential | 4.4 K  | [16, 10] | [16, 1]  \n",
      "-------------------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.018     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule.setup(): stage: TrainerFn.FITTING\n",
      "train_size: 0.36, val_size: 0.24 used for train & val data.\n",
      "LightDataModule.val_dataloader(). Val. set size: 106\n",
      "LightDataModule.train_dataloader(). data_train size: 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=32` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule.setup(): stage: TrainerFn.VALIDATING\n",
      "LightDataModule.val_dataloader(). Val. set size: 106\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">      Validate metric      </span><span style=\"font-weight: bold\">       DataLoader 0        </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span><span style=\"color: #800080; text-decoration-color: #800080\">     3954.82568359375      </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span><span style=\"color: #800080; text-decoration-color: #800080\">     3954.82568359375      </span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    3954.82568359375     \u001b[0m\u001b[35m \u001b[0m\n",
       "\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    3954.82568359375     \u001b[0m\u001b[35m \u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 3954.82568359375, 'hp_metric': 3954.82568359375}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotPython tuning: 3785.64111328125 [#########-] 87.50% \r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------\n",
      "0 | layers | Sequential | 4.4 K  | [16, 10] | [16, 1]  \n",
      "-------------------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.018     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule.setup(): stage: TrainerFn.FITTING\n",
      "train_size: 0.36, val_size: 0.24 used for train & val data.\n",
      "LightDataModule.val_dataloader(). Val. set size: 106\n",
      "LightDataModule.train_dataloader(). data_train size: 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=32` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule.setup(): stage: TrainerFn.VALIDATING\n",
      "LightDataModule.val_dataloader(). Val. set size: 106\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">      Validate metric      </span><span style=\"font-weight: bold\">       DataLoader 0        </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span><span style=\"color: #800080; text-decoration-color: #800080\">     4039.84130859375      </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span><span style=\"color: #800080; text-decoration-color: #800080\">     4039.84130859375      </span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    4039.84130859375     \u001b[0m\u001b[35m \u001b[0m\n",
       "\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    4039.84130859375     \u001b[0m\u001b[35m \u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 4039.84130859375, 'hp_metric': 4039.84130859375}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotPython tuning: 3785.64111328125 [##########] 100.00% Done...\r\n",
      "\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spotPython.spot.spot.Spot at 0x3cab0f450>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| label: code-start-hyperparameter-tuning-37\n",
    "from spotPython.utils.init import design_control_init, surrogate_control_init\n",
    "design_control = design_control_init(init_size=INIT_SIZE)\n",
    "\n",
    "surrogate_control = surrogate_control_init(noise=True,\n",
    "                                            n_theta=2)\n",
    "from spotPython.fun.hyperlight import HyperLight\n",
    "fun = HyperLight(log_level=10).fun\n",
    "from spotPython.spot import spot\n",
    "spot_tuner = spot.Spot(fun=fun,\n",
    "                       fun_control=fun_control,\n",
    "                       design_control=design_control,\n",
    "                       surrogate_control=surrogate_control)\n",
    "spot_tuner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17e6f1d",
   "metadata": {},
   "source": [
    "The tuned hyperparameters can be obtained as a dictionary with the following code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "code-get-tuned-hyperparameters-37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': 6.0,\n",
       " 'epochs': 5.0,\n",
       " 'batch_size': 4.0,\n",
       " 'act_fn': 1.0,\n",
       " 'optimizer': 0.0,\n",
       " 'dropout_prob': 0.03138229888019608,\n",
       " 'lr_mult': 0.4445644503748593,\n",
       " 'patience': 3.0,\n",
       " 'initialization': 0.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| label: code-get-tuned-hyperparameters-37\n",
    "from spotPython.hyperparameters.values import get_tuned_hyperparameters\n",
    "get_tuned_hyperparameters(spot_tuner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac55ddb",
   "metadata": {},
   "source": [
    "Here , the numerical levels of the hyperparameters are used as keys in the dictionary.\n",
    "If the `fun_control` dictionary is used, the names of the hyperparameters are used as keys in the dictionary. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "code-get-tuned-hyperparameters-fun-ctrl37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': 6.0,\n",
       " 'epochs': 5.0,\n",
       " 'batch_size': 4.0,\n",
       " 'act_fn': 'LeakyReLU',\n",
       " 'optimizer': 'Adam',\n",
       " 'dropout_prob': 0.03138229888019608,\n",
       " 'lr_mult': 0.4445644503748593,\n",
       " 'patience': 3.0,\n",
       " 'initialization': 'Default'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| label: code-get-tuned-hyperparameters-fun-ctrl37\n",
    "get_tuned_hyperparameters(spot_tuner, fun_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "code-save-experiment-37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename: spot_037_experiment.pickle\n"
     ]
    }
   ],
   "source": [
    "#| label: code-save-experiment-37\n",
    "PREFIX = fun_control[\"PREFIX\"]\n",
    "filename = get_experiment_filename(PREFIX)\n",
    "spot_tuner.save_experiment(filename=filename)\n",
    "print(f\"filename: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af5d9cd",
   "metadata": {
    "user_expressions": [
     {
      "expression": "filename",
      "result": {
       "data": {
        "text/plain": "'spot_037_experiment.pickle'"
       },
       "metadata": {},
       "status": "ok"
      }
     }
    ]
   },
   "source": [
    "The results from the experiment are stored in the pickle file `{python} filename`.\n",
    "The experiment can be reloaded with the following code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "code-reload-hyper-experiment-37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: code-reload-hyper-experiment-37\n",
    "(spot_tuner_1, fun_control_1, design_control_1,\n",
    "    surrogate_control_1, optimizer_control_1) = load_experiment(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12c98e9",
   "metadata": {},
   "source": [
    "Plot the progress of the original experiment are identical to the reloaded experiment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27953327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/pdf": "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",
      "text/plain": [
       "<Figure size 2700x1800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/pdf": "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",
      "text/plain": [
       "<Figure size 2700x1800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spot_tuner.plot_progress(log_y=True)\n",
    "spot_tuner_1.plot_progress(log_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec483059",
   "metadata": {},
   "source": [
    "Finally, the tuned hyperparameters can be obtained as a dictionary from the reloaded experiment with the following code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f4cf862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': 6.0,\n",
       " 'epochs': 5.0,\n",
       " 'batch_size': 4.0,\n",
       " 'act_fn': 'LeakyReLU',\n",
       " 'optimizer': 'Adam',\n",
       " 'dropout_prob': 0.03138229888019608,\n",
       " 'lr_mult': 0.4445644503748593,\n",
       " 'patience': 3.0,\n",
       " 'initialization': 'Default'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tuned_hyperparameters(spot_tuner_1, fun_control_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05254fa",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "### Summary: Saving and Loading Hyperparameter-Tuning Experiments\n",
    "* If `spotPython` is used as an hyperparameter tuner (with an hyperparameter dictionary), experiments can be saved and reloaded with the `save_experiment` and `load_experiment` functions.\n",
    "* The tuned hyperparameters can be obtained with the `get_tuned_hyperparameters` function.\n",
    ":::\n",
    "\n",
    "\n",
    "## Saving and Loading PyTorch Lightning Models {#sec-saving-and-loading-pytorch-lightning-models-37}\n",
    "\n",
    "@sec-spotpython-saving-and-loading  and @sec-spotpython-as-a-hyperparameter-tuner-37 explained how to save and load optimization and hyperparameter tuning experiments and how to get the tuned hyperparameters as a dictionary.\n",
    "This section shows how to save and load `PyTorch Lightning` models.\n",
    "\n",
    "\n",
    "### Get the Tuned Architecture {#sec-get-spot-results-31}\n",
    "\n",
    "In contrast to the function `get_tuned_hyperparameters`, the function `get_tuned_architecture` returns the tuned architecture of the model as a dictionary. Here, the transformations are already applied to the numerical levels of the hyperparameters and the encoding (and types) are the original types of the hyperparameters used by the model. The `config` dictionary can be passed to the model without any modifications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "036bbd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'act_fn': LeakyReLU(),\n",
      " 'batch_size': 16,\n",
      " 'dropout_prob': 0.03138229888019608,\n",
      " 'epochs': 32,\n",
      " 'initialization': 'Default',\n",
      " 'l1': 64,\n",
      " 'lr_mult': 0.4445644503748593,\n",
      " 'optimizer': 'Adam',\n",
      " 'patience': 8}\n"
     ]
    }
   ],
   "source": [
    "from spotPython.hyperparameters.values import get_tuned_architecture\n",
    "config = get_tuned_architecture(spot_tuner, fun_control)\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c202004",
   "metadata": {},
   "source": [
    "After getting the tuned architecture, the model can be created and tested with the following code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ea98d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------\n",
      "0 | layers | Sequential | 4.4 K  | [16, 10] | [16, 1]  \n",
      "-------------------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.018     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule.setup(): stage: TrainerFn.FITTING\n",
      "train_size: 0.36, val_size: 0.24 used for train & val data.\n",
      "LightDataModule.val_dataloader(). Val. set size: 106\n",
      "LightDataModule.train_dataloader(). data_train size: 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=32` reached.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /Users/bartz/workspace/Hyperparameter-Tuning-Cookbook/runs/saved_models/64_32_16_LeakyReLU_Adam_0.0314_0.4446_8_Default_TEST/last.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded model weights from the checkpoint at /Users/bartz/workspace/Hyperparameter-Tuning-Cookbook/runs/saved_models/64_32_16_LeakyReLU_Adam_0.0314_0.4446_8_Default_TEST/last.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule.setup(): stage: TrainerFn.TESTING\n",
      "test_size: 0.4 used for test dataset.\n",
      "LightDataModule.test_dataloader(). Test set size: 177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">        Test metric        </span><span style=\"font-weight: bold\">       DataLoader 0        </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span><span style=\"color: #800080; text-decoration-color: #800080\">     5560.75830078125      </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span><span style=\"color: #800080; text-decoration-color: #800080\">     5560.75830078125      </span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    5560.75830078125     \u001b[0m\u001b[35m \u001b[0m\n",
       "\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m    5560.75830078125     \u001b[0m\u001b[35m \u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_model result: {'val_loss': 5560.75830078125, 'hp_metric': 5560.75830078125}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5560.75830078125, 5560.75830078125)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spotPython.light.testmodel import test_model\n",
    "test_model(config, fun_control)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f960e7",
   "metadata": {},
   "source": [
    "### Load a Model from Checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44a7d42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config: {'l1': 64, 'epochs': 32, 'batch_size': 16, 'act_fn': LeakyReLU(), 'optimizer': 'Adam', 'dropout_prob': 0.03138229888019608, 'lr_mult': 0.4445644503748593, 'patience': 8, 'initialization': 'Default'}\n",
      "Loading model with 64_32_16_LeakyReLU_Adam_0.0314_0.4446_8_Default_TEST from runs/saved_models/64_32_16_LeakyReLU_Adam_0.0314_0.4446_8_Default_TEST/last.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: NetLightRegression(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=64, bias=True)\n",
      "    (1): LeakyReLU()\n",
      "    (2): Dropout(p=0.03138229888019608, inplace=False)\n",
      "    (3): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (4): LeakyReLU()\n",
      "    (5): Dropout(p=0.03138229888019608, inplace=False)\n",
      "    (6): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (7): LeakyReLU()\n",
      "    (8): Dropout(p=0.03138229888019608, inplace=False)\n",
      "    (9): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (10): LeakyReLU()\n",
      "    (11): Dropout(p=0.03138229888019608, inplace=False)\n",
      "    (12): Linear(in_features=16, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from spotPython.light.loadmodel import load_light_from_checkpoint\n",
    "model_loaded = load_light_from_checkpoint(config, fun_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ccdabd24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': False,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict(),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_pre_hooks': OrderedDict(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_hooks_with_kwargs': OrderedDict(),\n",
       " '_forward_hooks_always_called': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks_with_kwargs': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_post_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict([('layers',\n",
       "               Sequential(\n",
       "                 (0): Linear(in_features=10, out_features=64, bias=True)\n",
       "                 (1): LeakyReLU()\n",
       "                 (2): Dropout(p=0.03138229888019608, inplace=False)\n",
       "                 (3): Linear(in_features=64, out_features=32, bias=True)\n",
       "                 (4): LeakyReLU()\n",
       "                 (5): Dropout(p=0.03138229888019608, inplace=False)\n",
       "                 (6): Linear(in_features=32, out_features=32, bias=True)\n",
       "                 (7): LeakyReLU()\n",
       "                 (8): Dropout(p=0.03138229888019608, inplace=False)\n",
       "                 (9): Linear(in_features=32, out_features=16, bias=True)\n",
       "                 (10): LeakyReLU()\n",
       "                 (11): Dropout(p=0.03138229888019608, inplace=False)\n",
       "                 (12): Linear(in_features=16, out_features=1, bias=True)\n",
       "               ))]),\n",
       " 'prepare_data_per_node': True,\n",
       " 'allow_zero_length_dataloader_with_multiple_devices': False,\n",
       " '_log_hyperparams': True,\n",
       " '_dtype': torch.float32,\n",
       " '_device': device(type='mps', index=0),\n",
       " '_trainer': None,\n",
       " '_example_input_array': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " '_automatic_optimization': True,\n",
       " '_strict_loading': None,\n",
       " '_current_fx_name': None,\n",
       " '_param_requires_grad_state': {},\n",
       " '_metric_attributes': None,\n",
       " '_compiler_ctx': None,\n",
       " '_fabric': None,\n",
       " '_fabric_optimizers': [],\n",
       " '_L_in': 10,\n",
       " '_L_out': 1,\n",
       " '_torchmetric': 'mean_squared_error',\n",
       " 'metric': <function torchmetrics.functional.regression.mse.mean_squared_error(preds: torch.Tensor, target: torch.Tensor, squared: bool = True, num_outputs: int = 1) -> torch.Tensor>,\n",
       " '_hparams_name': 'kwargs',\n",
       " '_hparams': \"act_fn\":         LeakyReLU()\n",
       " \"batch_size\":     16\n",
       " \"dropout_prob\":   0.03138229888019608\n",
       " \"epochs\":         32\n",
       " \"initialization\": Default\n",
       " \"l1\":             64\n",
       " \"lr_mult\":        0.4445644503748593\n",
       " \"optimizer\":      Adam\n",
       " \"patience\":       8,\n",
       " '_hparams_initial': \"act_fn\":         LeakyReLU()\n",
       " \"batch_size\":     16\n",
       " \"dropout_prob\":   0.03138229888019608\n",
       " \"epochs\":         32\n",
       " \"initialization\": Default\n",
       " \"l1\":             64\n",
       " \"lr_mult\":        0.4445644503748593\n",
       " \"optimizer\":      Adam\n",
       " \"patience\":       8}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(model_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20468763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.save(model_loaded, \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16fdee75",
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = torch.load(\"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "213b537c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': False,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict(),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_pre_hooks': OrderedDict(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_hooks_with_kwargs': OrderedDict(),\n",
       " '_forward_hooks_always_called': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks_with_kwargs': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_post_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict([('layers',\n",
       "               Sequential(\n",
       "                 (0): Linear(in_features=10, out_features=64, bias=True)\n",
       "                 (1): LeakyReLU()\n",
       "                 (2): Dropout(p=0.03138229888019608, inplace=False)\n",
       "                 (3): Linear(in_features=64, out_features=32, bias=True)\n",
       "                 (4): LeakyReLU()\n",
       "                 (5): Dropout(p=0.03138229888019608, inplace=False)\n",
       "                 (6): Linear(in_features=32, out_features=32, bias=True)\n",
       "                 (7): LeakyReLU()\n",
       "                 (8): Dropout(p=0.03138229888019608, inplace=False)\n",
       "                 (9): Linear(in_features=32, out_features=16, bias=True)\n",
       "                 (10): LeakyReLU()\n",
       "                 (11): Dropout(p=0.03138229888019608, inplace=False)\n",
       "                 (12): Linear(in_features=16, out_features=1, bias=True)\n",
       "               ))]),\n",
       " 'prepare_data_per_node': True,\n",
       " 'allow_zero_length_dataloader_with_multiple_devices': False,\n",
       " '_log_hyperparams': True,\n",
       " '_dtype': torch.float32,\n",
       " '_device': device(type='mps', index=0),\n",
       " '_trainer': None,\n",
       " '_example_input_array': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " '_automatic_optimization': True,\n",
       " '_strict_loading': None,\n",
       " '_current_fx_name': None,\n",
       " '_param_requires_grad_state': {},\n",
       " '_metric_attributes': None,\n",
       " '_compiler_ctx': None,\n",
       " '_fabric': None,\n",
       " '_fabric_optimizers': [],\n",
       " '_L_in': 10,\n",
       " '_L_out': 1,\n",
       " '_torchmetric': 'mean_squared_error',\n",
       " 'metric': <function torchmetrics.functional.regression.mse.mean_squared_error(preds: torch.Tensor, target: torch.Tensor, squared: bool = True, num_outputs: int = 1) -> torch.Tensor>,\n",
       " '_hparams_name': 'kwargs',\n",
       " '_hparams': \"act_fn\":         LeakyReLU()\n",
       " \"batch_size\":     16\n",
       " \"dropout_prob\":   0.03138229888019608\n",
       " \"epochs\":         32\n",
       " \"initialization\": Default\n",
       " \"l1\":             64\n",
       " \"lr_mult\":        0.4445644503748593\n",
       " \"optimizer\":      Adam\n",
       " \"patience\":       8,\n",
       " '_hparams_initial': \"act_fn\":         LeakyReLU()\n",
       " \"batch_size\":     16\n",
       " \"dropout_prob\":   0.03138229888019608\n",
       " \"epochs\":         32\n",
       " \"initialization\": Default\n",
       " \"l1\":             64\n",
       " \"lr_mult\":        0.4445644503748593\n",
       " \"optimizer\":      Adam\n",
       " \"patience\":       8}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show all attributes of the model\n",
    "vars(mymodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b6c983",
   "metadata": {},
   "source": [
    "## Converting a Lightning Model to a Plain Torch Model {#sec-converting-a-lightning-model-to-a-plain-torch-model-37}\n",
    "\n",
    "### The Function `get_removed_attributes_and_base_net`\n",
    "\n",
    "`spotPython` provides a function to covert a `PyTorch Lightning` model to a plain `PyTorch` model. The function `get_removed_attributes_and_base_net` returns a tuple with the removed attributes and the base net. The base net is a plain `PyTorch` model. The removed attributes are the attributes of the `PyTorch Lightning` model that are not part of the base net.\n",
    "\n",
    "This conversion can be reverted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2296c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from spotPython.utils.device import getDevice\n",
    "from torch.utils.data import random_split\n",
    "from spotPython.utils.classes import get_removed_attributes_and_base_net\n",
    "from spotPython.hyperparameters.optimizer import optimizer_handler\n",
    "removed_attributes, torch_net = get_removed_attributes_and_base_net(net=mymodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12496c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_automatic_optimization': True, 'allow_zero_length_dataloader_with_multiple_devices': False, '_dtype': torch.float32, 'metric': <function mean_squared_error at 0x3ab5d59e0>, '_metric_attributes': None, '_strict_loading': None, '_hparams_initial': \"act_fn\":         LeakyReLU()\n",
      "\"batch_size\":     16\n",
      "\"dropout_prob\":   0.03138229888019608\n",
      "\"epochs\":         32\n",
      "\"initialization\": Default\n",
      "\"l1\":             64\n",
      "\"lr_mult\":        0.4445644503748593\n",
      "\"optimizer\":      Adam\n",
      "\"patience\":       8, '_trainer': None, '_hparams': \"act_fn\":         LeakyReLU()\n",
      "\"batch_size\":     16\n",
      "\"dropout_prob\":   0.03138229888019608\n",
      "\"epochs\":         32\n",
      "\"initialization\": Default\n",
      "\"l1\":             64\n",
      "\"lr_mult\":        0.4445644503748593\n",
      "\"optimizer\":      Adam\n",
      "\"patience\":       8, '_example_input_array': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), '_torchmetric': 'mean_squared_error', 'prepare_data_per_node': True, '_hparams_name': 'kwargs', '_param_requires_grad_state': {}, '_fabric_optimizers': [], '_compiler_ctx': None, '_L_out': 1, '_device': device(type='mps', index=0), '_fabric': None, '_L_in': 10, '_log_hyperparams': True, '_current_fx_name': None}\n"
     ]
    }
   ],
   "source": [
    "print(removed_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7beec5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetLightRegression(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=64, bias=True)\n",
      "    (1): LeakyReLU()\n",
      "    (2): Dropout(p=0.03138229888019608, inplace=False)\n",
      "    (3): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (4): LeakyReLU()\n",
      "    (5): Dropout(p=0.03138229888019608, inplace=False)\n",
      "    (6): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (7): LeakyReLU()\n",
      "    (8): Dropout(p=0.03138229888019608, inplace=False)\n",
      "    (9): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (10): LeakyReLU()\n",
      "    (11): Dropout(p=0.03138229888019608, inplace=False)\n",
      "    (12): Linear(in_features=16, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(torch_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7983365f",
   "metadata": {},
   "source": [
    "###  An Example how to use the Plain Torch Net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a742987d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/pdf": "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",
      "text/plain": [
       "<Figure size 1650x1050 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the Diabetes dataset from sklearn\n",
    "diabetes = load_diabetes()\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create a PyTorch dataset\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create a PyTorch dataloader\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "torch_net.to(getDevice(\"cpu\"))\n",
    "\n",
    "# train the net\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(torch_net.parameters(), lr=0.01)\n",
    "n_epochs = 100\n",
    "losses = []\n",
    "for epoch in range(n_epochs):\n",
    "    for inputs, targets in train_dataloader:\n",
    "        targets = targets.view(-1, 1)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = torch_net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "# visualize the network training\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3",
   "path": "/Users/bartz/miniforge3/envs/spotCondaEnv/share/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
