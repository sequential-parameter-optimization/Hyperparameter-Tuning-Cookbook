{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Parallelism in Initial Design**\n",
    "In `spotpython`, we provide a wrapper function, that encapsulates the objective function to enable its parallel execution via `multiprocessing` or `joblib`, allowing multiple configurations to be evaluated at the same time.\n",
    "\n",
    "## Example\n",
    "***\n",
    "### Setup\n",
    "To demonstrate the performance gain enabled by parallelization, we use a similar example to that in Section 47, where we perform hyperparameter tuning with `spotpython`and `PyTorch` Lightning on the Diabetes dataset using a ResNet model. We compare the time required with and without parallelization.\n",
    "\n",
    "First, we import the necessary libraries, including the wrapper function `make_parallel`. We then define the `fun_control` and `design_control` settings. For `design_control`, we deliberately choose a larger initial design size of 80 in order to clearly demonstrate the performance gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotpython.data.diabetes import Diabetes\n",
    "from spotpython.hyperdict.light_hyper_dict import LightHyperDict\n",
    "from spotpython.fun.hyperlight import HyperLight\n",
    "from spotpython.utils.init import (fun_control_init, design_control_init)\n",
    "from spotpython.hyperparameters.values import set_hyperparameter\n",
    "from spotpython.spot import Spot\n",
    "from math import inf\n",
    "from spotpython.utils.parallel import make_parallel\n",
    "import time\n",
    "\n",
    "dataset = Diabetes()\n",
    "\n",
    "fun_control = fun_control_init(\n",
    "    fun_evals=80,\n",
    "    max_time=inf,\n",
    "    data_set=dataset,\n",
    "    core_model_name=\"light.regression.NNResNetRegressor\",\n",
    "    hyperdict=LightHyperDict,\n",
    "    _L_in=10,\n",
    "    _L_out=1,\n",
    "    seed=125,\n",
    "    tensorboard_log=True,\n",
    "    TENSORBOARD_CLEAN=True,\n",
    "    \n",
    ")\n",
    "\n",
    "set_hyperparameter(fun_control, \"optimizer\", [\"Adadelta\", \"Adam\", \"Adamax\"])\n",
    "set_hyperparameter(fun_control, \"l1\", [2, 5])\n",
    "set_hyperparameter(fun_control, \"epochs\", [5, 8])\n",
    "set_hyperparameter(fun_control, \"batch_size\", [5, 8])\n",
    "set_hyperparameter(fun_control, \"dropout_prob\", [0.0, 0.5])\n",
    "set_hyperparameter(fun_control, \"patience\", [2, 3])\n",
    "set_hyperparameter(fun_control, \"lr_mult\", [0.1, 10.0])\n",
    "\n",
    "design_control = design_control_init(\n",
    "    init_size=80\n",
    ")\n",
    "\n",
    "fun = HyperLight().fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now measure the time required for sequential and parallel evaluation, beginning with the sequential approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start1 = time.time()\n",
    "spot_tuner = Spot(fun=fun, fun_control=fun_control, design_control=design_control)\n",
    "res = spot_tuner.run()\n",
    "end1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322.39894580841064\n"
     ]
    }
   ],
   "source": [
    "print(end1 - start1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use `make_parallel`, the number of cores must be specified via the `num_cores` parameter. By default, the function utilizes `multiprocessing`, but other parallelization methods can be selected using the `method` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start2 = time.time()\n",
    "parallel_fun = make_parallel(fun, num_cores=8)\n",
    "spot_parallel_tuner = Spot(fun=parallel_fun, fun_control=fun_control, design_control=design_control)\n",
    "res = spot_parallel_tuner.run()\n",
    "end2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.39355731010437\n"
     ]
    }
   ],
   "source": [
    "print(end2 - start2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "As we can see, the sequential execution took 322 seconds, while the parallel execution with 8 cores and `multiprocessing` required only 96 seconds. This corresponds to an improvement of approximately **70%** on an initial design of 80.\n",
    "## Notes\n",
    "***\n",
    "### OS\n",
    "Linux uses the `fork` method by default to start new processes, whereas macOS and Windows use the `spawn` method. This leads to differences in how processes are handled across operating systems. We use the functionality of `set_all_seeds` to ensure that the evaluation remains reproducible across all operating systems.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
