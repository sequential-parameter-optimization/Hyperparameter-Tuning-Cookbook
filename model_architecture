digraph {
	graph [size="20.55,20.55"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	14356292112 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	14303410112 [label=LinearBackward0]
	14303180640 -> 14303410112
	14303180640 [label=MulBackward0]
	14335490080 -> 14303180640
	14335490080 [label=LinearBackward0]
	14335479424 -> 14335490080
	14335479424 [label=MulBackward0]
	14339662000 -> 14335479424
	14339662000 [label=LinearBackward0]
	14339666704 -> 14339662000
	14339666704 [label=MulBackward0]
	14341677472 -> 14339666704
	14341677472 [label=LinearBackward0]
	14341677568 -> 14341677472
	14341677568 [label=MulBackward0]
	14341677760 -> 14341677568
	14341677760 [label=LinearBackward0]
	14341677856 -> 14341677760
	14341677856 [label=MulBackward0]
	14341678048 -> 14341677856
	14341678048 [label=LinearBackward0]
	14341678144 -> 14341678048
	14341678144 [label=MulBackward0]
	14341678336 -> 14341678144
	14341678336 [label=LinearBackward0]
	14341678432 -> 14341678336
	14341678432 [label=MulBackward0]
	14341678624 -> 14341678432
	14341678624 [label=LinearBackward0]
	14341678720 -> 14341678624
	14341678720 [label=MulBackward0]
	14341678912 -> 14341678720
	14341678912 [label=LinearBackward0]
	14341679008 -> 14341678912
	14341679008 [label=MulBackward0]
	14341679200 -> 14341679008
	14341679200 [label=LinearBackward0]
	14341679296 -> 14341679200
	14341679296 [label=MulBackward0]
	14341679488 -> 14341679296
	14341679488 [label=LinearBackward0]
	14341679584 -> 14341679488
	14341679584 [label=ToCopyBackward0]
	14341679776 -> 14341679584
	14160214320 [label="
 (1, 10)" fillcolor=lightblue]
	14160214320 -> 14341679776
	14341679776 [label=AccumulateGrad]
	14341679536 -> 14341679488
	14356290912 [label="layers.0.weight
 (128, 10)" fillcolor=lightblue]
	14356290912 -> 14341679536
	14341679536 [label=AccumulateGrad]
	14341679392 -> 14341679488
	14356313376 [label="layers.0.bias
 (128)" fillcolor=lightblue]
	14356313376 -> 14341679392
	14341679392 [label=AccumulateGrad]
	14341679248 -> 14341679200
	14356312896 [label="layers.3.weight
 (64, 128)" fillcolor=lightblue]
	14356312896 -> 14341679248
	14341679248 [label=AccumulateGrad]
	14341679104 -> 14341679200
	14356312576 [label="layers.3.bias
 (64)" fillcolor=lightblue]
	14356312576 -> 14341679104
	14341679104 [label=AccumulateGrad]
	14341678960 -> 14341678912
	14356313456 [label="layers.6.weight
 (64, 64)" fillcolor=lightblue]
	14356313456 -> 14341678960
	14341678960 [label=AccumulateGrad]
	14341678816 -> 14341678912
	14356313536 [label="layers.6.bias
 (64)" fillcolor=lightblue]
	14356313536 -> 14341678816
	14341678816 [label=AccumulateGrad]
	14341678672 -> 14341678624
	14356313616 [label="layers.9.weight
 (32, 64)" fillcolor=lightblue]
	14356313616 -> 14341678672
	14341678672 [label=AccumulateGrad]
	14341678528 -> 14341678624
	14356313696 [label="layers.9.bias
 (32)" fillcolor=lightblue]
	14356313696 -> 14341678528
	14341678528 [label=AccumulateGrad]
	14341678384 -> 14341678336
	14356287792 [label="layers.12.weight
 (32, 32)" fillcolor=lightblue]
	14356287792 -> 14341678384
	14341678384 [label=AccumulateGrad]
	14341678240 -> 14341678336
	14356293472 [label="layers.12.bias
 (32)" fillcolor=lightblue]
	14356293472 -> 14341678240
	14341678240 [label=AccumulateGrad]
	14341678096 -> 14341678048
	14356313776 [label="layers.15.weight
 (32, 32)" fillcolor=lightblue]
	14356313776 -> 14341678096
	14341678096 [label=AccumulateGrad]
	14341677952 -> 14341678048
	14356313856 [label="layers.15.bias
 (32)" fillcolor=lightblue]
	14356313856 -> 14341677952
	14341677952 [label=AccumulateGrad]
	14341677808 -> 14341677760
	14356313936 [label="layers.18.weight
 (16, 32)" fillcolor=lightblue]
	14356313936 -> 14341677808
	14341677808 [label=AccumulateGrad]
	14341677664 -> 14341677760
	14356314016 [label="layers.18.bias
 (16)" fillcolor=lightblue]
	14356314016 -> 14341677664
	14341677664 [label=AccumulateGrad]
	14341677520 -> 14341677472
	14356314096 [label="layers.21.weight
 (16, 16)" fillcolor=lightblue]
	14356314096 -> 14341677520
	14341677520 [label=AccumulateGrad]
	14341677376 -> 14341677472
	14356314176 [label="layers.21.bias
 (16)" fillcolor=lightblue]
	14356314176 -> 14341677376
	14341677376 [label=AccumulateGrad]
	14341676128 -> 14339662000
	14356314256 [label="layers.24.weight
 (16, 16)" fillcolor=lightblue]
	14356314256 -> 14341676128
	14341676128 [label=AccumulateGrad]
	14341676896 -> 14339662000
	14356314336 [label="layers.24.bias
 (16)" fillcolor=lightblue]
	14356314336 -> 14341676896
	14341676896 [label=AccumulateGrad]
	14335237120 -> 14335490080
	14356314416 [label="layers.27.weight
 (16, 16)" fillcolor=lightblue]
	14356314416 -> 14335237120
	14335237120 [label=AccumulateGrad]
	14335243360 -> 14335490080
	14356314496 [label="layers.27.bias
 (16)" fillcolor=lightblue]
	14356314496 -> 14335243360
	14335243360 [label=AccumulateGrad]
	14222349536 -> 14303410112
	14356314576 [label="layers.30.weight
 (1, 16)" fillcolor=lightblue]
	14356314576 -> 14222349536
	14222349536 [label=AccumulateGrad]
	14338980640 -> 14303410112
	14356314656 [label="layers.30.bias
 (1)" fillcolor=lightblue]
	14356314656 -> 14338980640
	14338980640 [label=AccumulateGrad]
	14303410112 -> 14356292112
}
