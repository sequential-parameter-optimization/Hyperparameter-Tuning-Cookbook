digraph {
	graph [size="20.55,20.55"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	14084555152 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	6203895920 [label=LinearBackward0]
	6203895392 -> 6203895920
	6203895392 [label=MulBackward0]
	14084953744 -> 6203895392
	14084953744 [label=LinearBackward0]
	6204104160 -> 14084953744
	6204104160 [label=MulBackward0]
	6204104352 -> 6204104160
	6204104352 [label=LinearBackward0]
	6204104448 -> 6204104352
	6204104448 [label=MulBackward0]
	6204104640 -> 6204104448
	6204104640 [label=LinearBackward0]
	6204104736 -> 6204104640
	6204104736 [label=MulBackward0]
	6204104928 -> 6204104736
	6204104928 [label=LinearBackward0]
	6204105024 -> 6204104928
	6204105024 [label=MulBackward0]
	6204105216 -> 6204105024
	6204105216 [label=LinearBackward0]
	6204105312 -> 6204105216
	6204105312 [label=MulBackward0]
	6204105504 -> 6204105312
	6204105504 [label=LinearBackward0]
	6204105600 -> 6204105504
	6204105600 [label=MulBackward0]
	6204105792 -> 6204105600
	6204105792 [label=LinearBackward0]
	6204105888 -> 6204105792
	6204105888 [label=MulBackward0]
	6204106080 -> 6204105888
	6204106080 [label=LinearBackward0]
	6204106176 -> 6204106080
	6204106176 [label=MulBackward0]
	6204106368 -> 6204106176
	6204106368 [label=LinearBackward0]
	6204106464 -> 6204106368
	6204106464 [label=MulBackward0]
	6204106656 -> 6204106464
	6204106656 [label=LinearBackward0]
	6204106752 -> 6204106656
	6204106752 [label=ToCopyBackward0]
	6204106944 -> 6204106752
	14067695232 [label="
 (1, 10)" fillcolor=lightblue]
	14067695232 -> 6204106944
	6204106944 [label=AccumulateGrad]
	6204106704 -> 6204106656
	14067511568 [label="layers.0.weight
 (128, 10)" fillcolor=lightblue]
	14067511568 -> 6204106704
	6204106704 [label=AccumulateGrad]
	6204106560 -> 6204106656
	14067510528 [label="layers.0.bias
 (128)" fillcolor=lightblue]
	14067510528 -> 6204106560
	6204106560 [label=AccumulateGrad]
	6204106416 -> 6204106368
	14067511488 [label="layers.3.weight
 (64, 128)" fillcolor=lightblue]
	14067511488 -> 6204106416
	6204106416 [label=AccumulateGrad]
	6204106272 -> 6204106368
	14067511648 [label="layers.3.bias
 (64)" fillcolor=lightblue]
	14067511648 -> 6204106272
	6204106272 [label=AccumulateGrad]
	6204106128 -> 6204106080
	14067510848 [label="layers.6.weight
 (64, 64)" fillcolor=lightblue]
	14067510848 -> 6204106128
	6204106128 [label=AccumulateGrad]
	6204105984 -> 6204106080
	14067512048 [label="layers.6.bias
 (64)" fillcolor=lightblue]
	14067512048 -> 6204105984
	6204105984 [label=AccumulateGrad]
	6204105840 -> 6204105792
	14067512128 [label="layers.9.weight
 (32, 64)" fillcolor=lightblue]
	14067512128 -> 6204105840
	6204105840 [label=AccumulateGrad]
	6204105696 -> 6204105792
	14067512368 [label="layers.9.bias
 (32)" fillcolor=lightblue]
	14067512368 -> 6204105696
	6204105696 [label=AccumulateGrad]
	6204105552 -> 6204105504
	14067378736 [label="layers.12.weight
 (32, 32)" fillcolor=lightblue]
	14067378736 -> 6204105552
	6204105552 [label=AccumulateGrad]
	6204105408 -> 6204105504
	14067400640 [label="layers.12.bias
 (32)" fillcolor=lightblue]
	14067400640 -> 6204105408
	6204105408 [label=AccumulateGrad]
	6204105264 -> 6204105216
	14067512448 [label="layers.15.weight
 (32, 32)" fillcolor=lightblue]
	14067512448 -> 6204105264
	6204105264 [label=AccumulateGrad]
	6204105120 -> 6204105216
	14067512688 [label="layers.15.bias
 (32)" fillcolor=lightblue]
	14067512688 -> 6204105120
	6204105120 [label=AccumulateGrad]
	6204104976 -> 6204104928
	14067512768 [label="layers.18.weight
 (16, 32)" fillcolor=lightblue]
	14067512768 -> 6204104976
	6204104976 [label=AccumulateGrad]
	6204104832 -> 6204104928
	14067513008 [label="layers.18.bias
 (16)" fillcolor=lightblue]
	14067513008 -> 6204104832
	6204104832 [label=AccumulateGrad]
	6204104688 -> 6204104640
	14067513088 [label="layers.21.weight
 (16, 16)" fillcolor=lightblue]
	14067513088 -> 6204104688
	6204104688 [label=AccumulateGrad]
	6204104544 -> 6204104640
	14067513328 [label="layers.21.bias
 (16)" fillcolor=lightblue]
	14067513328 -> 6204104544
	6204104544 [label=AccumulateGrad]
	6204104400 -> 6204104352
	14067513408 [label="layers.24.weight
 (16, 16)" fillcolor=lightblue]
	14067513408 -> 6204104400
	6204104400 [label=AccumulateGrad]
	6204104256 -> 6204104352
	14067513488 [label="layers.24.bias
 (16)" fillcolor=lightblue]
	14067513488 -> 6204104256
	6204104256 [label=AccumulateGrad]
	6204104016 -> 14084953744
	14067513728 [label="layers.27.weight
 (16, 16)" fillcolor=lightblue]
	14067513728 -> 6204104016
	6204104016 [label=AccumulateGrad]
	6204103680 -> 14084953744
	14067513808 [label="layers.27.bias
 (16)" fillcolor=lightblue]
	14067513808 -> 6204103680
	6204103680 [label=AccumulateGrad]
	6203895344 -> 6203895920
	14067514048 [label="layers.30.weight
 (1, 16)" fillcolor=lightblue]
	14067514048 -> 6203895344
	6203895344 [label=AccumulateGrad]
	6203899184 -> 6203895920
	14067514128 [label="layers.30.bias
 (1)" fillcolor=lightblue]
	14067514128 -> 6203899184
	6203899184 [label=AccumulateGrad]
	6203895920 -> 14084555152
}
