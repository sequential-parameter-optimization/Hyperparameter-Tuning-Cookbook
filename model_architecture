digraph {
	graph [size="18.3,18.3"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	13256313584 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	13695777520 [label=LinearBackward0]
	13692296048 -> 13695777520
	13692296048 [label=WhereBackward0]
	13760551600 -> 13692296048
	13760551600 [label=LinearBackward0]
	13691348224 -> 13760551600
	13691348224 [label=WhereBackward0]
	13760159200 -> 13691348224
	13760159200 [label=LinearBackward0]
	13760160496 -> 13760159200
	13760160496 [label=WhereBackward0]
	13760160688 -> 13760160496
	13760160688 [label=LinearBackward0]
	13760160832 -> 13760160688
	13760160832 [label=WhereBackward0]
	13760161024 -> 13760160832
	13760161024 [label=LinearBackward0]
	13760161168 -> 13760161024
	13760161168 [label=WhereBackward0]
	13760161360 -> 13760161168
	13760161360 [label=LinearBackward0]
	13760161504 -> 13760161360
	13760161504 [label=WhereBackward0]
	13760161696 -> 13760161504
	13760161696 [label=LinearBackward0]
	13760161840 -> 13760161696
	13760161840 [label=WhereBackward0]
	13760162032 -> 13760161840
	13760162032 [label=LinearBackward0]
	13760162176 -> 13760162032
	13760162176 [label=ToCopyBackward0]
	13760162368 -> 13760162176
	13256312224 [label="
 (1, 10)" fillcolor=lightblue]
	13256312224 -> 13760162368
	13760162368 [label=AccumulateGrad]
	13760162128 -> 13760162032
	13256332128 [label="layers.0.weight
 (320, 10)" fillcolor=lightblue]
	13256332128 -> 13760162128
	13760162128 [label=AccumulateGrad]
	13760162080 -> 13760162032
	13256332048 [label="layers.0.bias
 (320)" fillcolor=lightblue]
	13256332048 -> 13760162080
	13760162080 [label=AccumulateGrad]
	13760161984 -> 13760161840
	13760161984 [label=MulBackward0]
	13760162032 -> 13760161984
	13760161792 -> 13760161696
	13256332288 [label="layers.3.weight
 (160, 320)" fillcolor=lightblue]
	13256332288 -> 13760161792
	13760161792 [label=AccumulateGrad]
	13760161744 -> 13760161696
	13256329088 [label="layers.3.bias
 (160)" fillcolor=lightblue]
	13256329088 -> 13760161744
	13760161744 [label=AccumulateGrad]
	13760161648 -> 13760161504
	13760161648 [label=MulBackward0]
	13760161696 -> 13760161648
	13760161456 -> 13760161360
	13256332208 [label="layers.6.weight
 (320, 160)" fillcolor=lightblue]
	13256332208 -> 13760161456
	13760161456 [label=AccumulateGrad]
	13760161408 -> 13760161360
	13256331648 [label="layers.6.bias
 (320)" fillcolor=lightblue]
	13256331648 -> 13760161408
	13760161408 [label=AccumulateGrad]
	13760161312 -> 13760161168
	13760161312 [label=MulBackward0]
	13760161360 -> 13760161312
	13760161120 -> 13760161024
	13256332448 [label="layers.9.weight
 (160, 320)" fillcolor=lightblue]
	13256332448 -> 13760161120
	13760161120 [label=AccumulateGrad]
	13760161072 -> 13760161024
	13256332528 [label="layers.9.bias
 (160)" fillcolor=lightblue]
	13256332528 -> 13760161072
	13760161072 [label=AccumulateGrad]
	13760160976 -> 13760160832
	13760160976 [label=MulBackward0]
	13760161024 -> 13760160976
	13760160784 -> 13760160688
	13256332688 [label="layers.12.weight
 (160, 160)" fillcolor=lightblue]
	13256332688 -> 13760160784
	13760160784 [label=AccumulateGrad]
	13760160736 -> 13760160688
	13256332608 [label="layers.12.bias
 (160)" fillcolor=lightblue]
	13256332608 -> 13760160736
	13760160736 [label=AccumulateGrad]
	13760160640 -> 13760160496
	13760160640 [label=MulBackward0]
	13760160688 -> 13760160640
	13760160448 -> 13760159200
	13256333168 [label="layers.15.weight
 (80, 160)" fillcolor=lightblue]
	13256333168 -> 13760160448
	13760160448 [label=AccumulateGrad]
	13760160304 -> 13760159200
	13256333328 [label="layers.15.bias
 (80)" fillcolor=lightblue]
	13256333328 -> 13760160304
	13760160304 [label=AccumulateGrad]
	13760159968 -> 13691348224
	13760159968 [label=MulBackward0]
	13760159200 -> 13760159968
	13691352304 -> 13760551600
	13256333248 [label="layers.18.weight
 (80, 80)" fillcolor=lightblue]
	13256333248 -> 13691352304
	13691352304 [label=AccumulateGrad]
	13691343568 -> 13760551600
	13256333408 [label="layers.18.bias
 (80)" fillcolor=lightblue]
	13256333408 -> 13691343568
	13691343568 [label=AccumulateGrad]
	13760557888 -> 13692296048
	13760557888 [label=MulBackward0]
	13760551600 -> 13760557888
	13760180288 -> 13695777520
	13256313984 [label="layers.21.weight
 (1, 80)" fillcolor=lightblue]
	13256313984 -> 13760180288
	13760180288 [label=AccumulateGrad]
	13696059568 -> 13695777520
	13256333568 [label="layers.21.bias
 (1)" fillcolor=lightblue]
	13256333568 -> 13696059568
	13696059568 [label=AccumulateGrad]
	13695777520 -> 13256313584
}
