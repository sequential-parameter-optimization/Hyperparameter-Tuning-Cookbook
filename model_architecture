digraph {
	graph [size="18.3,18.3"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	12963422016 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	12963264736 [label=LinearBackward0]
	12963263296 -> 12963264736
	12963263296 [label=WhereBackward0]
	13229318560 -> 12963263296
	13229318560 [label=LinearBackward0]
	12963436896 -> 13229318560
	12963436896 [label=WhereBackward0]
	12963702496 -> 12963436896
	12963702496 [label=LinearBackward0]
	12963702784 -> 12963702496
	12963702784 [label=WhereBackward0]
	12963703120 -> 12963702784
	12963703120 [label=LinearBackward0]
	12963703264 -> 12963703120
	12963703264 [label=WhereBackward0]
	12963703456 -> 12963703264
	12963703456 [label=LinearBackward0]
	12963703600 -> 12963703456
	12963703600 [label=WhereBackward0]
	12963703792 -> 12963703600
	12963703792 [label=LinearBackward0]
	12963703936 -> 12963703792
	12963703936 [label=WhereBackward0]
	12963704128 -> 12963703936
	12963704128 [label=LinearBackward0]
	12963704272 -> 12963704128
	12963704272 [label=WhereBackward0]
	12963704464 -> 12963704272
	12963704464 [label=LinearBackward0]
	12963704608 -> 12963704464
	12963704608 [label=ToCopyBackward0]
	12963704800 -> 12963704608
	12963419376 [label="
 (1, 10)" fillcolor=lightblue]
	12963419376 -> 12963704800
	12963704800 [label=AccumulateGrad]
	12963704560 -> 12963704464
	12963426736 [label="layers.0.weight
 (320, 10)" fillcolor=lightblue]
	12963426736 -> 12963704560
	12963704560 [label=AccumulateGrad]
	12963704512 -> 12963704464
	12963426256 [label="layers.0.bias
 (320)" fillcolor=lightblue]
	12963426256 -> 12963704512
	12963704512 [label=AccumulateGrad]
	12963704416 -> 12963704272
	12963704416 [label=MulBackward0]
	12963704464 -> 12963704416
	12963704224 -> 12963704128
	12963426896 [label="layers.3.weight
 (160, 320)" fillcolor=lightblue]
	12963426896 -> 12963704224
	12963704224 [label=AccumulateGrad]
	12963704176 -> 12963704128
	12963426976 [label="layers.3.bias
 (160)" fillcolor=lightblue]
	12963426976 -> 12963704176
	12963704176 [label=AccumulateGrad]
	12963704080 -> 12963703936
	12963704080 [label=MulBackward0]
	12963704128 -> 12963704080
	12963703888 -> 12963703792
	12963426816 [label="layers.6.weight
 (320, 160)" fillcolor=lightblue]
	12963426816 -> 12963703888
	12963703888 [label=AccumulateGrad]
	12963703840 -> 12963703792
	12963427056 [label="layers.6.bias
 (320)" fillcolor=lightblue]
	12963427056 -> 12963703840
	12963703840 [label=AccumulateGrad]
	12963703744 -> 12963703600
	12963703744 [label=MulBackward0]
	12963703792 -> 12963703744
	12963703552 -> 12963703456
	12963427136 [label="layers.9.weight
 (160, 320)" fillcolor=lightblue]
	12963427136 -> 12963703552
	12963703552 [label=AccumulateGrad]
	12963703504 -> 12963703456
	12963427216 [label="layers.9.bias
 (160)" fillcolor=lightblue]
	12963427216 -> 12963703504
	12963703504 [label=AccumulateGrad]
	12963703408 -> 12963703264
	12963703408 [label=MulBackward0]
	12963703456 -> 12963703408
	12963703216 -> 12963703120
	12963427296 [label="layers.12.weight
 (160, 160)" fillcolor=lightblue]
	12963427296 -> 12963703216
	12963703216 [label=AccumulateGrad]
	12963703168 -> 12963703120
	12963427376 [label="layers.12.bias
 (160)" fillcolor=lightblue]
	12963427376 -> 12963703168
	12963703168 [label=AccumulateGrad]
	12963703072 -> 12963702784
	12963703072 [label=MulBackward0]
	12963703120 -> 12963703072
	12963702928 -> 12963702496
	12963427456 [label="layers.15.weight
 (80, 160)" fillcolor=lightblue]
	12963427456 -> 12963702928
	12963702928 [label=AccumulateGrad]
	12963702736 -> 12963702496
	12963427536 [label="layers.15.bias
 (80)" fillcolor=lightblue]
	12963427536 -> 12963702736
	12963702736 [label=AccumulateGrad]
	12963702832 -> 12963436896
	12963702832 [label=MulBackward0]
	12963702496 -> 12963702832
	12963702544 -> 13229318560
	12963427616 [label="layers.18.weight
 (80, 80)" fillcolor=lightblue]
	12963427616 -> 12963702544
	12963702544 [label=AccumulateGrad]
	12963702592 -> 13229318560
	12963427696 [label="layers.18.bias
 (80)" fillcolor=lightblue]
	12963427696 -> 12963702592
	12963702592 [label=AccumulateGrad]
	12963133472 -> 12963263296
	12963133472 [label=MulBackward0]
	13229318560 -> 12963133472
	12963261040 -> 12963264736
	12963295344 [label="layers.21.weight
 (1, 80)" fillcolor=lightblue]
	12963295344 -> 12963261040
	12963261040 [label=AccumulateGrad]
	12963263536 -> 12963264736
	16260197392 [label="layers.21.bias
 (1)" fillcolor=lightblue]
	16260197392 -> 12963263536
	12963263536 [label=AccumulateGrad]
	12963264736 -> 12963422016
}
