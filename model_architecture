digraph {
	graph [size="40.949999999999996,40.949999999999996"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	13735309184 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	13930682384 -> 14172787872 [dir=none]
	14172787872 [label="input
 (1, 2)" fillcolor=orange]
	13930682384 -> 14172785552 [dir=none]
	14172785552 [label="weight
 (1, 2)" fillcolor=orange]
	13930682384 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13849887408 -> 13930682384
	13849887408 -> 14172787952 [dir=none]
	14172787952 [label="other
 (1, 2)" fillcolor=orange]
	13849887408 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	13930866352 -> 13849887408
	13930866352 -> 14172787712 [dir=none]
	14172787712 [label="input
 (1, 2)" fillcolor=orange]
	13930866352 -> 14172785392 [dir=none]
	14172785392 [label="weight
 (2, 2)" fillcolor=orange]
	13930866352 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14172953936 -> 13930866352
	14172953936 -> 14172787792 [dir=none]
	14172787792 [label="other
 (1, 2)" fillcolor=orange]
	14172953936 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14172954032 -> 14172953936
	14172954032 -> 14172787552 [dir=none]
	14172787552 [label="input
 (1, 2)" fillcolor=orange]
	14172954032 -> 14172785232 [dir=none]
	14172785232 [label="weight
 (2, 2)" fillcolor=orange]
	14172954032 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14172954272 -> 14172954032
	14172954272 -> 14172787632 [dir=none]
	14172787632 [label="other
 (1, 2)" fillcolor=orange]
	14172954272 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14172954224 -> 14172954272
	14172954224 -> 14172787392 [dir=none]
	14172787392 [label="input
 (1, 2)" fillcolor=orange]
	14172954224 -> 14172785072 [dir=none]
	14172785072 [label="weight
 (2, 2)" fillcolor=orange]
	14172954224 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14172954560 -> 14172954224
	14172954560 -> 14172787472 [dir=none]
	14172787472 [label="other
 (1, 2)" fillcolor=orange]
	14172954560 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14172954512 -> 14172954560
	14172954512 -> 14172787232 [dir=none]
	14172787232 [label="input
 (1, 4)" fillcolor=orange]
	14172954512 -> 14172784912 [dir=none]
	14172784912 [label="weight
 (2, 4)" fillcolor=orange]
	14172954512 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14172954848 -> 14172954512
	14172954848 -> 14172787312 [dir=none]
	14172787312 [label="other
 (1, 4)" fillcolor=orange]
	14172954848 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14172954800 -> 14172954848
	14172954800 -> 14172785872 [dir=none]
	14172785872 [label="input
 (1, 4)" fillcolor=orange]
	14172954800 -> 14172784752 [dir=none]
	14172784752 [label="weight
 (4, 4)" fillcolor=orange]
	14172954800 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14172955136 -> 14172954800
	14172955136 -> 14172786032 [dir=none]
	14172786032 [label="other
 (1, 4)" fillcolor=orange]
	14172955136 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14172955088 -> 14172955136
	14172955088 -> 14172787152 [dir=none]
	14172787152 [label="input
 (1, 4)" fillcolor=orange]
	14172955088 -> 14172784592 [dir=none]
	14172784592 [label="weight
 (4, 4)" fillcolor=orange]
	14172955088 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14172955424 -> 14172955088
	14172955424 -> 14172786992 [dir=none]
	14172786992 [label="other
 (1, 4)" fillcolor=orange]
	14172955424 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14172955376 -> 14172955424
	14172955376 -> 14172782912 [dir=none]
	14172782912 [label="input
 (1, 4)" fillcolor=orange]
	14172955376 -> 14172784432 [dir=none]
	14172784432 [label="weight
 (4, 4)" fillcolor=orange]
	14172955376 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14172955712 -> 14172955376
	14172955712 -> 14172782752 [dir=none]
	14172782752 [label="other
 (1, 4)" fillcolor=orange]
	14172955712 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14172955664 -> 14172955712
	14172955664 -> 14172786672 [dir=none]
	14172786672 [label="input
 (1, 8)" fillcolor=orange]
	14172955664 -> 14172784272 [dir=none]
	14172784272 [label="weight
 (4, 8)" fillcolor=orange]
	14172955664 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14172956000 -> 14172955664
	14172956000 -> 14172786912 [dir=none]
	14172786912 [label="other
 (1, 8)" fillcolor=orange]
	14172956000 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14172955952 -> 14172956000
	14172955952 -> 14172786832 [dir=none]
	14172786832 [label="input
 (1, 8)" fillcolor=orange]
	14172955952 -> 14172784112 [dir=none]
	14172784112 [label="weight
 (8, 8)" fillcolor=orange]
	14172955952 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14172956288 -> 14172955952
	14172956288 -> 14172787072 [dir=none]
	14172787072 [label="other
 (1, 8)" fillcolor=orange]
	14172956288 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14172956240 -> 14172956288
	14172956240 -> 13930631952 [dir=none]
	13930631952 [label="input
 (1, 8)" fillcolor=orange]
	14172956240 -> 14172783952 [dir=none]
	14172783952 [label="weight
 (8, 8)" fillcolor=orange]
	14172956240 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14172956576 -> 14172956240
	14172956576 -> 13930642352 [dir=none]
	13930642352 [label="other
 (1, 8)" fillcolor=orange]
	14172956576 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	13930862800 -> 14172956576
	13930862800 -> 13930627232 [dir=none]
	13930627232 [label="input
 (1, 16)" fillcolor=orange]
	13930862800 -> 14172783792 [dir=none]
	14172783792 [label="weight
 (8, 16)" fillcolor=orange]
	13930862800 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14172956672 -> 13930862800
	14172956672 -> 13930629072 [dir=none]
	13930629072 [label="other
 (1, 16)" fillcolor=orange]
	14172956672 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14172956912 -> 14172956672
	14172956912 -> 13930640592 [dir=none]
	13930640592 [label="input
 (1, 16)" fillcolor=orange]
	14172956912 -> 14172782992 [dir=none]
	14172782992 [label="weight
 (16, 16)" fillcolor=orange]
	14172956912 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14172957008 -> 14172956912
	14172957008 -> 13930642032 [dir=none]
	13930642032 [label="other
 (1, 16)" fillcolor=orange]
	14172957008 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14172957056 -> 14172957008
	14172957056 -> 13930641392 [dir=none]
	13930641392 [label="input
 (1, 32)" fillcolor=orange]
	14172957056 -> 14172782672 [dir=none]
	14172782672 [label="weight
 (16, 32)" fillcolor=orange]
	14172957056 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14172957296 -> 14172957056
	14172957296 -> 13930627392 [dir=none]
	13930627392 [label="other
 (1, 32)" fillcolor=orange]
	14172957296 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14172957344 -> 14172957296
	14172957344 -> 13735309504 [dir=none]
	13735309504 [label="input
 (1, 10)" fillcolor=orange]
	14172957344 -> 14172783472 [dir=none]
	14172783472 [label="weight
 (32, 10)" fillcolor=orange]
	14172957344 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14172957584 -> 14172957344
	14172957584 [label=ToCopyBackward0]
	13930690736 -> 14172957584
	13735309424 [label="
 (1, 10)" fillcolor=lightblue]
	13735309424 -> 13930690736
	13930690736 [label=AccumulateGrad]
	14172957680 -> 14172957344
	14172783472 [label="layers.0.weight
 (32, 10)" fillcolor=lightblue]
	14172783472 -> 14172957680
	14172957680 [label=AccumulateGrad]
	14172957440 -> 14172957344
	14172783552 [label="layers.0.bias
 (32)" fillcolor=lightblue]
	14172783552 -> 14172957440
	14172957440 [label=AccumulateGrad]
	14172957392 -> 14172957056
	14172782672 [label="layers.3.weight
 (16, 32)" fillcolor=lightblue]
	14172782672 -> 14172957392
	14172957392 [label=AccumulateGrad]
	14172957152 -> 14172957056
	14172783632 [label="layers.3.bias
 (16)" fillcolor=lightblue]
	14172783632 -> 14172957152
	14172957152 [label=AccumulateGrad]
	14172957104 -> 14172956912
	14172782992 [label="layers.6.weight
 (16, 16)" fillcolor=lightblue]
	14172782992 -> 14172957104
	14172957104 [label=AccumulateGrad]
	14172956864 -> 14172956912
	14172783712 [label="layers.6.bias
 (16)" fillcolor=lightblue]
	14172783712 -> 14172956864
	14172956864 [label=AccumulateGrad]
	14172956720 -> 13930862800
	14172783792 [label="layers.9.weight
 (8, 16)" fillcolor=lightblue]
	14172783792 -> 14172956720
	14172956720 [label=AccumulateGrad]
	14172956528 -> 13930862800
	14172783872 [label="layers.9.bias
 (8)" fillcolor=lightblue]
	14172783872 -> 14172956528
	14172956528 [label=AccumulateGrad]
	14172956624 -> 14172956240
	14172783952 [label="layers.12.weight
 (8, 8)" fillcolor=lightblue]
	14172783952 -> 14172956624
	14172956624 [label=AccumulateGrad]
	14172956384 -> 14172956240
	14172784032 [label="layers.12.bias
 (8)" fillcolor=lightblue]
	14172784032 -> 14172956384
	14172956384 [label=AccumulateGrad]
	14172956336 -> 14172955952
	14172784112 [label="layers.15.weight
 (8, 8)" fillcolor=lightblue]
	14172784112 -> 14172956336
	14172956336 [label=AccumulateGrad]
	14172956096 -> 14172955952
	14172784192 [label="layers.15.bias
 (8)" fillcolor=lightblue]
	14172784192 -> 14172956096
	14172956096 [label=AccumulateGrad]
	14172956048 -> 14172955664
	14172784272 [label="layers.18.weight
 (4, 8)" fillcolor=lightblue]
	14172784272 -> 14172956048
	14172956048 [label=AccumulateGrad]
	14172955808 -> 14172955664
	14172784352 [label="layers.18.bias
 (4)" fillcolor=lightblue]
	14172784352 -> 14172955808
	14172955808 [label=AccumulateGrad]
	14172955760 -> 14172955376
	14172784432 [label="layers.21.weight
 (4, 4)" fillcolor=lightblue]
	14172784432 -> 14172955760
	14172955760 [label=AccumulateGrad]
	14172955520 -> 14172955376
	14172784512 [label="layers.21.bias
 (4)" fillcolor=lightblue]
	14172784512 -> 14172955520
	14172955520 [label=AccumulateGrad]
	14172955472 -> 14172955088
	14172784592 [label="layers.24.weight
 (4, 4)" fillcolor=lightblue]
	14172784592 -> 14172955472
	14172955472 [label=AccumulateGrad]
	14172955232 -> 14172955088
	14172784672 [label="layers.24.bias
 (4)" fillcolor=lightblue]
	14172784672 -> 14172955232
	14172955232 [label=AccumulateGrad]
	14172955184 -> 14172954800
	14172784752 [label="layers.27.weight
 (4, 4)" fillcolor=lightblue]
	14172784752 -> 14172955184
	14172955184 [label=AccumulateGrad]
	14172954944 -> 14172954800
	14172784832 [label="layers.27.bias
 (4)" fillcolor=lightblue]
	14172784832 -> 14172954944
	14172954944 [label=AccumulateGrad]
	14172954896 -> 14172954512
	14172784912 [label="layers.30.weight
 (2, 4)" fillcolor=lightblue]
	14172784912 -> 14172954896
	14172954896 [label=AccumulateGrad]
	14172954656 -> 14172954512
	14172784992 [label="layers.30.bias
 (2)" fillcolor=lightblue]
	14172784992 -> 14172954656
	14172954656 [label=AccumulateGrad]
	14172954608 -> 14172954224
	14172785072 [label="layers.33.weight
 (2, 2)" fillcolor=lightblue]
	14172785072 -> 14172954608
	14172954608 [label=AccumulateGrad]
	14172954368 -> 14172954224
	14172785152 [label="layers.33.bias
 (2)" fillcolor=lightblue]
	14172785152 -> 14172954368
	14172954368 [label=AccumulateGrad]
	14172954320 -> 14172954032
	14172785232 [label="layers.36.weight
 (2, 2)" fillcolor=lightblue]
	14172785232 -> 14172954320
	14172954320 [label=AccumulateGrad]
	14172954128 -> 14172954032
	14172785312 [label="layers.36.bias
 (2)" fillcolor=lightblue]
	14172785312 -> 14172954128
	14172954128 [label=AccumulateGrad]
	14172953840 -> 13930866352
	14172785392 [label="layers.39.weight
 (2, 2)" fillcolor=lightblue]
	14172785392 -> 14172953840
	14172953840 [label=AccumulateGrad]
	14172953792 -> 13930866352
	14172785472 [label="layers.39.bias
 (2)" fillcolor=lightblue]
	14172785472 -> 14172953792
	14172953792 [label=AccumulateGrad]
	13930859680 -> 13930682384
	14172785552 [label="layers.42.weight
 (1, 2)" fillcolor=lightblue]
	14172785552 -> 13930859680
	13930859680 [label=AccumulateGrad]
	13850409904 -> 13930682384
	14172785632 [label="layers.42.bias
 (1)" fillcolor=lightblue]
	14172785632 -> 13850409904
	13850409904 [label=AccumulateGrad]
	13930682384 -> 13735309184
}
