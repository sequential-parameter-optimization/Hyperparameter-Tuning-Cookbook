digraph {
	graph [size="15.149999999999999,15.149999999999999"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	14763864096 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	13872507648 [label=LinearBackward0]
	13766519456 -> 13872507648
	13766519456 [label=MulBackward0]
	14763579120 -> 13766519456
	14763579120 [label=LinearBackward0]
	14860661808 -> 14763579120
	14860661808 [label=MulBackward0]
	14860662048 -> 14860661808
	14860662048 [label=LinearBackward0]
	14860662000 -> 14860662048
	14860662000 [label=MulBackward0]
	14860662336 -> 14860662000
	14860662336 [label=LinearBackward0]
	14860662432 -> 14860662336
	14860662432 [label=MulBackward0]
	14860662624 -> 14860662432
	14860662624 [label=LinearBackward0]
	14860662720 -> 14860662624
	14860662720 [label=MulBackward0]
	14860662912 -> 14860662720
	14860662912 [label=LinearBackward0]
	14860663008 -> 14860662912
	14860663008 [label=MulBackward0]
	14860663200 -> 14860663008
	14860663200 [label=LinearBackward0]
	14860663296 -> 14860663200
	14860663296 [label=MulBackward0]
	14860663488 -> 14860663296
	14860663488 [label=LinearBackward0]
	14860663584 -> 14860663488
	14860663584 [label=ToCopyBackward0]
	14860663776 -> 14860663584
	14763864656 [label="
 (1, 10)" fillcolor=lightblue]
	14763864656 -> 14860663776
	14860663776 [label=AccumulateGrad]
	14860663536 -> 14860663488
	14763865856 [label="layers.0.weight
 (320, 10)" fillcolor=lightblue]
	14763865856 -> 14860663536
	14860663536 [label=AccumulateGrad]
	14860663392 -> 14860663488
	14763865936 [label="layers.0.bias
 (320)" fillcolor=lightblue]
	14763865936 -> 14860663392
	14860663392 [label=AccumulateGrad]
	14860663248 -> 14860663200
	14763866096 [label="layers.3.weight
 (160, 320)" fillcolor=lightblue]
	14763866096 -> 14860663248
	14860663248 [label=AccumulateGrad]
	14860663104 -> 14860663200
	14763866176 [label="layers.3.bias
 (160)" fillcolor=lightblue]
	14763866176 -> 14860663104
	14860663104 [label=AccumulateGrad]
	14860662960 -> 14860662912
	14763866016 [label="layers.6.weight
 (320, 160)" fillcolor=lightblue]
	14763866016 -> 14860662960
	14860662960 [label=AccumulateGrad]
	14860662816 -> 14860662912
	14763866256 [label="layers.6.bias
 (320)" fillcolor=lightblue]
	14763866256 -> 14860662816
	14860662816 [label=AccumulateGrad]
	14860662672 -> 14860662624
	14763866336 [label="layers.9.weight
 (160, 320)" fillcolor=lightblue]
	14763866336 -> 14860662672
	14860662672 [label=AccumulateGrad]
	14860662528 -> 14860662624
	14763866416 [label="layers.9.bias
 (160)" fillcolor=lightblue]
	14763866416 -> 14860662528
	14860662528 [label=AccumulateGrad]
	14860662384 -> 14860662336
	14763866496 [label="layers.12.weight
 (160, 160)" fillcolor=lightblue]
	14763866496 -> 14860662384
	14860662384 [label=AccumulateGrad]
	14860662240 -> 14860662336
	14763866576 [label="layers.12.bias
 (160)" fillcolor=lightblue]
	14763866576 -> 14860662240
	14860662240 [label=AccumulateGrad]
	14860662144 -> 14860662048
	14763866656 [label="layers.15.weight
 (80, 160)" fillcolor=lightblue]
	14763866656 -> 14860662144
	14860662144 [label=AccumulateGrad]
	14860661904 -> 14860662048
	14763866736 [label="layers.15.bias
 (80)" fillcolor=lightblue]
	14763866736 -> 14860661904
	14860661904 [label=AccumulateGrad]
	14860661712 -> 14763579120
	14763866816 [label="layers.18.weight
 (80, 80)" fillcolor=lightblue]
	14763866816 -> 14860661712
	14860661712 [label=AccumulateGrad]
	14860650384 -> 14763579120
	14763866896 [label="layers.18.bias
 (80)" fillcolor=lightblue]
	14763866896 -> 14860650384
	14860650384 [label=AccumulateGrad]
	14764287568 -> 13872507648
	14763852176 [label="layers.21.weight
 (1, 80)" fillcolor=lightblue]
	14763852176 -> 14764287568
	14764287568 [label=AccumulateGrad]
	14763580368 -> 13872507648
	14763866976 [label="layers.21.bias
 (1)" fillcolor=lightblue]
	14763866976 -> 14763580368
	14763580368 [label=AccumulateGrad]
	13872507648 -> 14763864096
}
