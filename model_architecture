digraph {
	graph [size="51.449999999999996,51.449999999999996"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	14575005488 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	14575044976 -> 14747966336 [dir=none]
	14747966336 [label="input
 (1, 2)" fillcolor=orange]
	14575044976 -> 14747963616 [dir=none]
	14747963616 [label="weight
 (1, 2)" fillcolor=orange]
	14575044976 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14543626128 -> 14575044976
	14543626128 -> 14747966096 [dir=none]
	14747966096 [label="condition
 (1, 2)" fillcolor=orange]
	14543626128 [label="WhereBackward0
-------------------------
condition: [saved tensor]"]
	14747299712 -> 14543626128
	14747299712 -> 14747966176 [dir=none]
	14747966176 [label="input
 (1, 2)" fillcolor=orange]
	14747299712 -> 14747963456 [dir=none]
	14747963456 [label="weight
 (2, 2)" fillcolor=orange]
	14747299712 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14747580544 -> 14747299712
	14747580544 -> 14747965936 [dir=none]
	14747965936 [label="condition
 (1, 2)" fillcolor=orange]
	14747580544 [label="WhereBackward0
-------------------------
condition: [saved tensor]"]
	14747580448 -> 14747580544
	14747580448 -> 14747966016 [dir=none]
	14747966016 [label="input
 (1, 2)" fillcolor=orange]
	14747580448 -> 14747963296 [dir=none]
	14747963296 [label="weight
 (2, 2)" fillcolor=orange]
	14747580448 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14747580880 -> 14747580448
	14747580880 -> 14747965776 [dir=none]
	14747965776 [label="condition
 (1, 2)" fillcolor=orange]
	14747580880 [label="WhereBackward0
-------------------------
condition: [saved tensor]"]
	14747580736 -> 14747580880
	14747580736 -> 14747965856 [dir=none]
	14747965856 [label="input
 (1, 2)" fillcolor=orange]
	14747580736 -> 14747963136 [dir=none]
	14747963136 [label="weight
 (2, 2)" fillcolor=orange]
	14747580736 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14747581168 -> 14747580736
	14747581168 -> 14747965616 [dir=none]
	14747965616 [label="condition
 (1, 2)" fillcolor=orange]
	14747581168 [label="WhereBackward0
-------------------------
condition: [saved tensor]"]
	14747581216 -> 14747581168
	14747581216 -> 14747965696 [dir=none]
	14747965696 [label="input
 (1, 4)" fillcolor=orange]
	14747581216 -> 14747962976 [dir=none]
	14747962976 [label="weight
 (2, 4)" fillcolor=orange]
	14747581216 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14747581504 -> 14747581216
	14747581504 -> 14747965456 [dir=none]
	14747965456 [label="condition
 (1, 4)" fillcolor=orange]
	14747581504 [label="WhereBackward0
-------------------------
condition: [saved tensor]"]
	14747581552 -> 14747581504
	14747581552 -> 14747965536 [dir=none]
	14747965536 [label="input
 (1, 4)" fillcolor=orange]
	14747581552 -> 14747962816 [dir=none]
	14747962816 [label="weight
 (4, 4)" fillcolor=orange]
	14747581552 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14747581840 -> 14747581552
	14747581840 -> 14747965296 [dir=none]
	14747965296 [label="condition
 (1, 4)" fillcolor=orange]
	14747581840 [label="WhereBackward0
-------------------------
condition: [saved tensor]"]
	14747581888 -> 14747581840
	14747581888 -> 14747965376 [dir=none]
	14747965376 [label="input
 (1, 4)" fillcolor=orange]
	14747581888 -> 14747962656 [dir=none]
	14747962656 [label="weight
 (4, 4)" fillcolor=orange]
	14747581888 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14747582176 -> 14747581888
	14747582176 -> 14747965216 [dir=none]
	14747965216 [label="condition
 (1, 4)" fillcolor=orange]
	14747582176 [label="WhereBackward0
-------------------------
condition: [saved tensor]"]
	14747582224 -> 14747582176
	14747582224 -> 14747964096 [dir=none]
	14747964096 [label="input
 (1, 4)" fillcolor=orange]
	14747582224 -> 14747962496 [dir=none]
	14747962496 [label="weight
 (4, 4)" fillcolor=orange]
	14747582224 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14747582416 -> 14747582224
	14747582416 -> 14747964016 [dir=none]
	14747964016 [label="condition
 (1, 4)" fillcolor=orange]
	14747582416 [label="WhereBackward0
-------------------------
condition: [saved tensor]"]
	14556922016 -> 14747582416
	14556922016 -> 14747963936 [dir=none]
	14747963936 [label="input
 (1, 8)" fillcolor=orange]
	14556922016 -> 14747962336 [dir=none]
	14747962336 [label="weight
 (4, 8)" fillcolor=orange]
	14556922016 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14556922304 -> 14556922016
	14556922304 -> 14747960976 [dir=none]
	14747960976 [label="condition
 (1, 8)" fillcolor=orange]
	14556922304 [label="WhereBackward0
-------------------------
condition: [saved tensor]"]
	14556922352 -> 14556922304
	14556922352 -> 14747960816 [dir=none]
	14747960816 [label="input
 (1, 8)" fillcolor=orange]
	14556922352 -> 14747962176 [dir=none]
	14747962176 [label="weight
 (8, 8)" fillcolor=orange]
	14556922352 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14556922640 -> 14556922352
	14556922640 -> 14747964336 [dir=none]
	14747964336 [label="condition
 (1, 8)" fillcolor=orange]
	14556922640 [label="WhereBackward0
-------------------------
condition: [saved tensor]"]
	14747294528 -> 14556922640
	14747294528 -> 14747964896 [dir=none]
	14747964896 [label="input
 (1, 8)" fillcolor=orange]
	14747294528 -> 14747962016 [dir=none]
	14747962016 [label="weight
 (8, 8)" fillcolor=orange]
	14747294528 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14556922736 -> 14747294528
	14556922736 -> 14747959376 [dir=none]
	14747959376 [label="condition
 (1, 8)" fillcolor=orange]
	14556922736 [label="WhereBackward0
-------------------------
condition: [saved tensor]"]
	14556922880 -> 14556922736
	14556922880 -> 14747959456 [dir=none]
	14747959456 [label="input
 (1, 16)" fillcolor=orange]
	14556922880 -> 14747961856 [dir=none]
	14747961856 [label="weight
 (8, 16)" fillcolor=orange]
	14556922880 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14556923168 -> 14556922880
	14556923168 -> 14747959616 [dir=none]
	14747959616 [label="condition
 (1, 16)" fillcolor=orange]
	14556923168 [label="WhereBackward0
-------------------------
condition: [saved tensor]"]
	14556923216 -> 14556923168
	14556923216 -> 14747959536 [dir=none]
	14747959536 [label="input
 (1, 16)" fillcolor=orange]
	14556923216 -> 14747961056 [dir=none]
	14747961056 [label="weight
 (16, 16)" fillcolor=orange]
	14556923216 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14556923552 -> 14556923216
	14556923552 -> 14747959856 [dir=none]
	14747959856 [label="condition
 (1, 16)" fillcolor=orange]
	14556923552 [label="WhereBackward0
-------------------------
condition: [saved tensor]"]
	14556923504 -> 14556923552
	14556923504 -> 14747959696 [dir=none]
	14747959696 [label="input
 (1, 32)" fillcolor=orange]
	14556923504 -> 14747960736 [dir=none]
	14747960736 [label="weight
 (16, 32)" fillcolor=orange]
	14556923504 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14556923888 -> 14556923504
	14556923888 -> 14747959936 [dir=none]
	14747959936 [label="condition
 (1, 32)" fillcolor=orange]
	14556923888 [label="WhereBackward0
-------------------------
condition: [saved tensor]"]
	14556923840 -> 14556923888
	14556923840 -> 4355711344 [dir=none]
	4355711344 [label="input
 (1, 10)" fillcolor=orange]
	14556923840 -> 14747961536 [dir=none]
	14747961536 [label="weight
 (32, 10)" fillcolor=orange]
	14556923840 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14556924224 -> 14556923840
	14556924224 [label=ToCopyBackward0]
	14556924176 -> 14556924224
	14747683728 [label="
 (1, 10)" fillcolor=lightblue]
	14747683728 -> 14556924176
	14556924176 [label=AccumulateGrad]
	14556924080 -> 14556923840
	14747961536 [label="layers.0.weight
 (32, 10)" fillcolor=lightblue]
	14747961536 -> 14556924080
	14556924080 [label=AccumulateGrad]
	14556924128 -> 14556923840
	14747961616 [label="layers.0.bias
 (32)" fillcolor=lightblue]
	14747961616 -> 14556924128
	14556924128 [label=AccumulateGrad]
	14556924032 -> 14556923888
	14556924032 -> 14747972896 [dir=none]
	14747972896 [label="other
 ()" fillcolor=orange]
	14556924032 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14556923840 -> 14556924032
	14556923744 -> 14556923504
	14747960736 [label="layers.3.weight
 (16, 32)" fillcolor=lightblue]
	14747960736 -> 14556923744
	14556923744 [label=AccumulateGrad]
	14556923792 -> 14556923504
	14747961696 [label="layers.3.bias
 (16)" fillcolor=lightblue]
	14747961696 -> 14556923792
	14556923792 [label=AccumulateGrad]
	14556923696 -> 14556923552
	14556923696 -> 14747973696 [dir=none]
	14747973696 [label="other
 ()" fillcolor=orange]
	14556923696 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14556923504 -> 14556923696
	14556923408 -> 14556923216
	14747961056 [label="layers.6.weight
 (16, 16)" fillcolor=lightblue]
	14747961056 -> 14556923408
	14556923408 [label=AccumulateGrad]
	14556923456 -> 14556923216
	14747961776 [label="layers.6.bias
 (16)" fillcolor=lightblue]
	14747961776 -> 14556923456
	14556923456 [label=AccumulateGrad]
	14556923360 -> 14556923168
	14556923360 -> 14747974496 [dir=none]
	14747974496 [label="other
 ()" fillcolor=orange]
	14556923360 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14556923216 -> 14556923360
	14556923072 -> 14556922880
	14747961856 [label="layers.9.weight
 (8, 16)" fillcolor=lightblue]
	14747961856 -> 14556923072
	14556923072 [label=AccumulateGrad]
	14556923120 -> 14556922880
	14747961936 [label="layers.9.bias
 (8)" fillcolor=lightblue]
	14747961936 -> 14556923120
	14556923120 [label=AccumulateGrad]
	14556923024 -> 14556922736
	14556923024 -> 14747975296 [dir=none]
	14747975296 [label="other
 ()" fillcolor=orange]
	14556923024 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14556922880 -> 14556923024
	14556922832 -> 14747294528
	14747962016 [label="layers.12.weight
 (8, 8)" fillcolor=lightblue]
	14747962016 -> 14556922832
	14556922832 [label=AccumulateGrad]
	14556922688 -> 14747294528
	14747962096 [label="layers.12.bias
 (8)" fillcolor=lightblue]
	14747962096 -> 14556922688
	14556922688 [label=AccumulateGrad]
	14747298224 -> 14556922640
	14747298224 -> 14556889568 [dir=none]
	14556889568 [label="other
 ()" fillcolor=orange]
	14747298224 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14747294528 -> 14747298224
	14556922544 -> 14556922352
	14747962176 [label="layers.15.weight
 (8, 8)" fillcolor=lightblue]
	14747962176 -> 14556922544
	14556922544 [label=AccumulateGrad]
	14556922592 -> 14556922352
	14747962256 [label="layers.15.bias
 (8)" fillcolor=lightblue]
	14747962256 -> 14556922592
	14556922592 [label=AccumulateGrad]
	14556922496 -> 14556922304
	14556922496 -> 14556890368 [dir=none]
	14556890368 [label="other
 ()" fillcolor=orange]
	14556922496 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14556922352 -> 14556922496
	14556922208 -> 14556922016
	14747962336 [label="layers.18.weight
 (4, 8)" fillcolor=lightblue]
	14747962336 -> 14556922208
	14556922208 [label=AccumulateGrad]
	14556922256 -> 14556922016
	14747962416 [label="layers.18.bias
 (4)" fillcolor=lightblue]
	14747962416 -> 14556922256
	14556922256 [label=AccumulateGrad]
	14556922160 -> 14747582416
	14556922160 -> 14556891168 [dir=none]
	14556891168 [label="other
 ()" fillcolor=orange]
	14556922160 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14556922016 -> 14556922160
	14556921968 -> 14747582224
	14747962496 [label="layers.21.weight
 (4, 4)" fillcolor=lightblue]
	14747962496 -> 14556921968
	14556921968 [label=AccumulateGrad]
	14556921920 -> 14747582224
	14747962576 [label="layers.21.bias
 (4)" fillcolor=lightblue]
	14747962576 -> 14556921920
	14556921920 [label=AccumulateGrad]
	14747582368 -> 14747582176
	14747582368 -> 14556891968 [dir=none]
	14556891968 [label="other
 ()" fillcolor=orange]
	14747582368 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14747582224 -> 14747582368
	14747582080 -> 14747581888
	14747962656 [label="layers.24.weight
 (4, 4)" fillcolor=lightblue]
	14747962656 -> 14747582080
	14747582080 [label=AccumulateGrad]
	14747582128 -> 14747581888
	14747962736 [label="layers.24.bias
 (4)" fillcolor=lightblue]
	14747962736 -> 14747582128
	14747582128 [label=AccumulateGrad]
	14747582032 -> 14747581840
	14747582032 -> 14556892768 [dir=none]
	14556892768 [label="other
 ()" fillcolor=orange]
	14747582032 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14747581888 -> 14747582032
	14747581744 -> 14747581552
	14747962816 [label="layers.27.weight
 (4, 4)" fillcolor=lightblue]
	14747962816 -> 14747581744
	14747581744 [label=AccumulateGrad]
	14747581792 -> 14747581552
	14747962896 [label="layers.27.bias
 (4)" fillcolor=lightblue]
	14747962896 -> 14747581792
	14747581792 [label=AccumulateGrad]
	14747581696 -> 14747581504
	14747581696 -> 14556893568 [dir=none]
	14556893568 [label="other
 ()" fillcolor=orange]
	14747581696 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14747581552 -> 14747581696
	14747581408 -> 14747581216
	14747962976 [label="layers.30.weight
 (2, 4)" fillcolor=lightblue]
	14747962976 -> 14747581408
	14747581408 [label=AccumulateGrad]
	14747581456 -> 14747581216
	14747963056 [label="layers.30.bias
 (2)" fillcolor=lightblue]
	14747963056 -> 14747581456
	14747581456 [label=AccumulateGrad]
	14747581360 -> 14747581168
	14747581360 -> 14556894368 [dir=none]
	14556894368 [label="other
 ()" fillcolor=orange]
	14747581360 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14747581216 -> 14747581360
	14747581072 -> 14747580736
	14747963136 [label="layers.33.weight
 (2, 2)" fillcolor=lightblue]
	14747963136 -> 14747581072
	14747581072 [label=AccumulateGrad]
	14747581120 -> 14747580736
	14747963216 [label="layers.33.bias
 (2)" fillcolor=lightblue]
	14747963216 -> 14747581120
	14747581120 [label=AccumulateGrad]
	14747581024 -> 14747580880
	14747581024 -> 14556895168 [dir=none]
	14556895168 [label="other
 ()" fillcolor=orange]
	14747581024 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14747580736 -> 14747581024
	14747580688 -> 14747580448
	14747963296 [label="layers.36.weight
 (2, 2)" fillcolor=lightblue]
	14747963296 -> 14747580688
	14747580688 [label=AccumulateGrad]
	14747580784 -> 14747580448
	14747963376 [label="layers.36.bias
 (2)" fillcolor=lightblue]
	14747963376 -> 14747580784
	14747580784 [label=AccumulateGrad]
	14747580592 -> 14747580544
	14747580592 -> 14556895968 [dir=none]
	14556895968 [label="other
 ()" fillcolor=orange]
	14747580592 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14747580448 -> 14747580592
	14747567152 -> 14747299712
	14747963456 [label="layers.39.weight
 (2, 2)" fillcolor=lightblue]
	14747963456 -> 14747567152
	14747567152 [label=AccumulateGrad]
	14747580496 -> 14747299712
	14747963536 [label="layers.39.bias
 (2)" fillcolor=lightblue]
	14747963536 -> 14747580496
	14747580496 [label=AccumulateGrad]
	14574987072 -> 14543626128
	14574987072 -> 14556896768 [dir=none]
	14556896768 [label="other
 ()" fillcolor=orange]
	14574987072 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14747299712 -> 14574987072
	14574978960 -> 14575044976
	14747963616 [label="layers.42.weight
 (1, 2)" fillcolor=lightblue]
	14747963616 -> 14574978960
	14574978960 [label=AccumulateGrad]
	14747534240 -> 14575044976
	14747963696 [label="layers.42.bias
 (1)" fillcolor=lightblue]
	14747963696 -> 14747534240
	14747534240 [label=AccumulateGrad]
	14575044976 -> 14575005488
}
