digraph {
	graph [size="15.149999999999999,15.149999999999999"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	13953992576 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	13324804944 [label=LinearBackward0]
	13953888464 -> 13324804944
	13953888464 [label=MulBackward0]
	13957567184 -> 13953888464
	13957567184 [label=LinearBackward0]
	13957567712 -> 13957567184
	13957567712 [label=MulBackward0]
	13957567904 -> 13957567712
	13957567904 [label=LinearBackward0]
	13957568000 -> 13957567904
	13957568000 [label=MulBackward0]
	13957568192 -> 13957568000
	13957568192 [label=LinearBackward0]
	13957568288 -> 13957568192
	13957568288 [label=MulBackward0]
	13957568480 -> 13957568288
	13957568480 [label=LinearBackward0]
	13957568576 -> 13957568480
	13957568576 [label=MulBackward0]
	13957568768 -> 13957568576
	13957568768 [label=LinearBackward0]
	13957568864 -> 13957568768
	13957568864 [label=MulBackward0]
	13957569056 -> 13957568864
	13957569056 [label=LinearBackward0]
	13957569152 -> 13957569056
	13957569152 [label=MulBackward0]
	13957569344 -> 13957569152
	13957569344 [label=LinearBackward0]
	13957569440 -> 13957569344
	13957569440 [label=ToCopyBackward0]
	13957569632 -> 13957569440
	13953991856 [label="
 (1, 10)" fillcolor=lightblue]
	13953991856 -> 13957569632
	13957569632 [label=AccumulateGrad]
	13957569392 -> 13957569344
	13954001136 [label="layers.0.weight
 (160, 10)" fillcolor=lightblue]
	13954001136 -> 13957569392
	13957569392 [label=AccumulateGrad]
	13957569248 -> 13957569344
	13954001696 [label="layers.0.bias
 (160)" fillcolor=lightblue]
	13954001696 -> 13957569248
	13957569248 [label=AccumulateGrad]
	13957569104 -> 13957569056
	13953682400 [label="layers.3.weight
 (80, 160)" fillcolor=lightblue]
	13953682400 -> 13957569104
	13957569104 [label=AccumulateGrad]
	13957568960 -> 13957569056
	13953482048 [label="layers.3.bias
 (80)" fillcolor=lightblue]
	13953482048 -> 13957568960
	13957568960 [label=AccumulateGrad]
	13957568816 -> 13957568768
	13953938240 [label="layers.6.weight
 (160, 80)" fillcolor=lightblue]
	13953938240 -> 13957568816
	13957568816 [label=AccumulateGrad]
	13957568672 -> 13957568768
	13953931360 [label="layers.6.bias
 (160)" fillcolor=lightblue]
	13953931360 -> 13957568672
	13957568672 [label=AccumulateGrad]
	13957568528 -> 13957568480
	13954001856 [label="layers.9.weight
 (80, 160)" fillcolor=lightblue]
	13954001856 -> 13957568528
	13957568528 [label=AccumulateGrad]
	13957568384 -> 13957568480
	13954001936 [label="layers.9.bias
 (80)" fillcolor=lightblue]
	13954001936 -> 13957568384
	13957568384 [label=AccumulateGrad]
	13957568240 -> 13957568192
	13954001776 [label="layers.12.weight
 (80, 80)" fillcolor=lightblue]
	13954001776 -> 13957568240
	13957568240 [label=AccumulateGrad]
	13957568096 -> 13957568192
	13954002016 [label="layers.12.bias
 (80)" fillcolor=lightblue]
	13954002016 -> 13957568096
	13957568096 [label=AccumulateGrad]
	13957567952 -> 13957567904
	13954002096 [label="layers.15.weight
 (40, 80)" fillcolor=lightblue]
	13954002096 -> 13957567952
	13957567952 [label=AccumulateGrad]
	13957567808 -> 13957567904
	13954002176 [label="layers.15.bias
 (40)" fillcolor=lightblue]
	13954002176 -> 13957567808
	13957567808 [label=AccumulateGrad]
	13957567664 -> 13957567184
	13954002256 [label="layers.18.weight
 (40, 40)" fillcolor=lightblue]
	13954002256 -> 13957567664
	13957567664 [label=AccumulateGrad]
	13957566416 -> 13957567184
	13954002336 [label="layers.18.bias
 (40)" fillcolor=lightblue]
	13954002336 -> 13957566416
	13957566416 [label=AccumulateGrad]
	13956453552 -> 13324804944
	13954002416 [label="layers.21.weight
 (1, 40)" fillcolor=lightblue]
	13954002416 -> 13956453552
	13956453552 [label=AccumulateGrad]
	13955844320 -> 13324804944
	13954002496 [label="layers.21.bias
 (1)" fillcolor=lightblue]
	13954002496 -> 13955844320
	13955844320 [label=AccumulateGrad]
	13324804944 -> 13953992576
}
