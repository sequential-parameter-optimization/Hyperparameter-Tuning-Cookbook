digraph {
	graph [size="40.949999999999996,40.949999999999996"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	14173005184 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	14315002016 -> 14180325952 [dir=none]
	14180325952 [label="input
 (1, 2)" fillcolor=orange]
	14315002016 -> 14178490144 [dir=none]
	14178490144 [label="weight
 (1, 2)" fillcolor=orange]
	14315002016 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14314785040 -> 14315002016
	14314785040 -> 14180326032 [dir=none]
	14180326032 [label="other
 (1, 2)" fillcolor=orange]
	14314785040 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14315056928 -> 14314785040
	14315056928 -> 14180325712 [dir=none]
	14180325712 [label="input
 (1, 2)" fillcolor=orange]
	14315056928 -> 14178489984 [dir=none]
	14178489984 [label="weight
 (2, 2)" fillcolor=orange]
	14315056928 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14148245616 -> 14315056928
	14148245616 -> 14180325872 [dir=none]
	14180325872 [label="other
 (1, 2)" fillcolor=orange]
	14148245616 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14172979504 -> 14148245616
	14172979504 -> 14314846672 [dir=none]
	14314846672 [label="input
 (1, 2)" fillcolor=orange]
	14172979504 -> 14178489824 [dir=none]
	14178489824 [label="weight
 (2, 2)" fillcolor=orange]
	14172979504 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14172983296 -> 14172979504
	14172983296 -> 14180325792 [dir=none]
	14180325792 [label="other
 (1, 2)" fillcolor=orange]
	14172983296 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14180376032 -> 14172983296
	14180376032 -> 14178491424 [dir=none]
	14178491424 [label="input
 (1, 2)" fillcolor=orange]
	14180376032 -> 14178489664 [dir=none]
	14178489664 [label="weight
 (2, 2)" fillcolor=orange]
	14180376032 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14180376272 -> 14180376032
	14180376272 -> 14315130624 [dir=none]
	14315130624 [label="other
 (1, 2)" fillcolor=orange]
	14180376272 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14180376416 -> 14180376272
	14180376416 -> 14180325472 [dir=none]
	14180325472 [label="input
 (1, 4)" fillcolor=orange]
	14180376416 -> 14178489504 [dir=none]
	14178489504 [label="weight
 (2, 4)" fillcolor=orange]
	14180376416 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14180376704 -> 14180376416
	14180376704 -> 14180325552 [dir=none]
	14180325552 [label="other
 (1, 4)" fillcolor=orange]
	14180376704 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14180376656 -> 14180376704
	14180376656 -> 14180325312 [dir=none]
	14180325312 [label="input
 (1, 4)" fillcolor=orange]
	14180376656 -> 14178489344 [dir=none]
	14178489344 [label="weight
 (4, 4)" fillcolor=orange]
	14180376656 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14180376992 -> 14180376656
	14180376992 -> 14180325392 [dir=none]
	14180325392 [label="other
 (1, 4)" fillcolor=orange]
	14180376992 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14180376944 -> 14180376992
	14180376944 -> 14180324672 [dir=none]
	14180324672 [label="input
 (1, 4)" fillcolor=orange]
	14180376944 -> 14178489184 [dir=none]
	14178489184 [label="weight
 (4, 4)" fillcolor=orange]
	14180376944 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14180377280 -> 14180376944
	14180377280 -> 14180325232 [dir=none]
	14180325232 [label="other
 (1, 4)" fillcolor=orange]
	14180377280 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14180377232 -> 14180377280
	14180377232 -> 14315140704 [dir=none]
	14315140704 [label="input
 (1, 4)" fillcolor=orange]
	14180377232 -> 14178489024 [dir=none]
	14178489024 [label="weight
 (4, 4)" fillcolor=orange]
	14180377232 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14180377568 -> 14180377232
	14180377568 -> 14180325072 [dir=none]
	14180325072 [label="other
 (1, 4)" fillcolor=orange]
	14180377568 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14180377520 -> 14180377568
	14180377520 -> 14180324912 [dir=none]
	14180324912 [label="input
 (1, 8)" fillcolor=orange]
	14180377520 -> 14178488864 [dir=none]
	14178488864 [label="weight
 (4, 8)" fillcolor=orange]
	14180377520 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14180377856 -> 14180377520
	14180377856 -> 14180324992 [dir=none]
	14180324992 [label="other
 (1, 8)" fillcolor=orange]
	14180377856 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14180377808 -> 14180377856
	14180377808 -> 14180324752 [dir=none]
	14180324752 [label="input
 (1, 8)" fillcolor=orange]
	14180377808 -> 14178488704 [dir=none]
	14178488704 [label="weight
 (8, 8)" fillcolor=orange]
	14180377808 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14180378144 -> 14180377808
	14180378144 -> 14180324832 [dir=none]
	14180324832 [label="other
 (1, 8)" fillcolor=orange]
	14180378144 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14180378096 -> 14180378144
	14180378096 -> 14173003824 [dir=none]
	14173003824 [label="input
 (1, 8)" fillcolor=orange]
	14180378096 -> 14178488544 [dir=none]
	14178488544 [label="weight
 (8, 8)" fillcolor=orange]
	14180378096 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14180378432 -> 14180378096
	14180378432 -> 14178491504 [dir=none]
	14178491504 [label="other
 (1, 8)" fillcolor=orange]
	14180378432 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14180378384 -> 14180378432
	14180378384 -> 14180323072 [dir=none]
	14180323072 [label="input
 (1, 16)" fillcolor=orange]
	14180378384 -> 14178488384 [dir=none]
	14178488384 [label="weight
 (8, 16)" fillcolor=orange]
	14180378384 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14180378720 -> 14180378384
	14180378720 -> 14180324592 [dir=none]
	14180324592 [label="other
 (1, 16)" fillcolor=orange]
	14180378720 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14180378672 -> 14180378720
	14180378672 -> 14178454576 [dir=none]
	14178454576 [label="input
 (1, 16)" fillcolor=orange]
	14180378672 -> 14178488064 [dir=none]
	14178488064 [label="weight
 (16, 16)" fillcolor=orange]
	14180378672 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14180378960 -> 14180378672
	14180378960 -> 14180324192 [dir=none]
	14180324192 [label="other
 (1, 16)" fillcolor=orange]
	14180378960 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14180379008 -> 14180378960
	14180379008 -> 14173003904 [dir=none]
	14173003904 [label="input
 (1, 32)" fillcolor=orange]
	14180379008 -> 14178488144 [dir=none]
	14178488144 [label="weight
 (16, 32)" fillcolor=orange]
	14180379008 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14180379248 -> 14180379008
	14180379248 -> 14178455776 [dir=none]
	14178455776 [label="other
 (1, 32)" fillcolor=orange]
	14180379248 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	14180379296 -> 14180379248
	14180379296 -> 14180143648 [dir=none]
	14180143648 [label="input
 (1, 10)" fillcolor=orange]
	14180379296 -> 14178487424 [dir=none]
	14178487424 [label="weight
 (32, 10)" fillcolor=orange]
	14180379296 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	14180379536 -> 14180379296
	14180379536 [label=ToCopyBackward0]
	14180379584 -> 14180379536
	14314544560 [label="
 (1, 10)" fillcolor=lightblue]
	14314544560 -> 14180379584
	14180379584 [label=AccumulateGrad]
	14180379632 -> 14180379296
	14178487424 [label="layers.0.weight
 (32, 10)" fillcolor=lightblue]
	14178487424 -> 14180379632
	14180379632 [label=AccumulateGrad]
	14180379392 -> 14180379296
	14178487104 [label="layers.0.bias
 (32)" fillcolor=lightblue]
	14178487104 -> 14180379392
	14180379392 [label=AccumulateGrad]
	14180379344 -> 14180379008
	14178488144 [label="layers.3.weight
 (16, 32)" fillcolor=lightblue]
	14178488144 -> 14180379344
	14180379344 [label=AccumulateGrad]
	14180379104 -> 14180379008
	14178488224 [label="layers.3.bias
 (16)" fillcolor=lightblue]
	14178488224 -> 14180379104
	14180379104 [label=AccumulateGrad]
	14180379056 -> 14180378672
	14178488064 [label="layers.6.weight
 (16, 16)" fillcolor=lightblue]
	14178488064 -> 14180379056
	14180379056 [label=AccumulateGrad]
	14180378816 -> 14180378672
	14178488304 [label="layers.6.bias
 (16)" fillcolor=lightblue]
	14178488304 -> 14180378816
	14180378816 [label=AccumulateGrad]
	14180378768 -> 14180378384
	14178488384 [label="layers.9.weight
 (8, 16)" fillcolor=lightblue]
	14178488384 -> 14180378768
	14180378768 [label=AccumulateGrad]
	14180378528 -> 14180378384
	14178488464 [label="layers.9.bias
 (8)" fillcolor=lightblue]
	14178488464 -> 14180378528
	14180378528 [label=AccumulateGrad]
	14180378480 -> 14180378096
	14178488544 [label="layers.12.weight
 (8, 8)" fillcolor=lightblue]
	14178488544 -> 14180378480
	14180378480 [label=AccumulateGrad]
	14180378240 -> 14180378096
	14178488624 [label="layers.12.bias
 (8)" fillcolor=lightblue]
	14178488624 -> 14180378240
	14180378240 [label=AccumulateGrad]
	14180378192 -> 14180377808
	14178488704 [label="layers.15.weight
 (8, 8)" fillcolor=lightblue]
	14178488704 -> 14180378192
	14180378192 [label=AccumulateGrad]
	14180377952 -> 14180377808
	14178488784 [label="layers.15.bias
 (8)" fillcolor=lightblue]
	14178488784 -> 14180377952
	14180377952 [label=AccumulateGrad]
	14180377904 -> 14180377520
	14178488864 [label="layers.18.weight
 (4, 8)" fillcolor=lightblue]
	14178488864 -> 14180377904
	14180377904 [label=AccumulateGrad]
	14180377664 -> 14180377520
	14178488944 [label="layers.18.bias
 (4)" fillcolor=lightblue]
	14178488944 -> 14180377664
	14180377664 [label=AccumulateGrad]
	14180377616 -> 14180377232
	14178489024 [label="layers.21.weight
 (4, 4)" fillcolor=lightblue]
	14178489024 -> 14180377616
	14180377616 [label=AccumulateGrad]
	14180377376 -> 14180377232
	14178489104 [label="layers.21.bias
 (4)" fillcolor=lightblue]
	14178489104 -> 14180377376
	14180377376 [label=AccumulateGrad]
	14180377328 -> 14180376944
	14178489184 [label="layers.24.weight
 (4, 4)" fillcolor=lightblue]
	14178489184 -> 14180377328
	14180377328 [label=AccumulateGrad]
	14180377088 -> 14180376944
	14178489264 [label="layers.24.bias
 (4)" fillcolor=lightblue]
	14178489264 -> 14180377088
	14180377088 [label=AccumulateGrad]
	14180377040 -> 14180376656
	14178489344 [label="layers.27.weight
 (4, 4)" fillcolor=lightblue]
	14178489344 -> 14180377040
	14180377040 [label=AccumulateGrad]
	14180376800 -> 14180376656
	14178489424 [label="layers.27.bias
 (4)" fillcolor=lightblue]
	14178489424 -> 14180376800
	14180376800 [label=AccumulateGrad]
	14180376752 -> 14180376416
	14178489504 [label="layers.30.weight
 (2, 4)" fillcolor=lightblue]
	14178489504 -> 14180376752
	14180376752 [label=AccumulateGrad]
	14180376512 -> 14180376416
	14178489584 [label="layers.30.bias
 (2)" fillcolor=lightblue]
	14178489584 -> 14180376512
	14180376512 [label=AccumulateGrad]
	14180376464 -> 14180376032
	14178489664 [label="layers.33.weight
 (2, 2)" fillcolor=lightblue]
	14178489664 -> 14180376464
	14180376464 [label=AccumulateGrad]
	14180376176 -> 14180376032
	14178489744 [label="layers.33.bias
 (2)" fillcolor=lightblue]
	14178489744 -> 14180376176
	14180376176 [label=AccumulateGrad]
	14180376080 -> 14172979504
	14178489824 [label="layers.36.weight
 (2, 2)" fillcolor=lightblue]
	14178489824 -> 14180376080
	14180376080 [label=AccumulateGrad]
	14180376128 -> 14172979504
	14178489904 [label="layers.36.bias
 (2)" fillcolor=lightblue]
	14178489904 -> 14180376128
	14180376128 [label=AccumulateGrad]
	14172982096 -> 14315056928
	14178489984 [label="layers.39.weight
 (2, 2)" fillcolor=lightblue]
	14178489984 -> 14172982096
	14172982096 [label=AccumulateGrad]
	14172987328 -> 14315056928
	14178490064 [label="layers.39.bias
 (2)" fillcolor=lightblue]
	14178490064 -> 14172987328
	14172987328 [label=AccumulateGrad]
	14315001584 -> 14315002016
	14178490144 [label="layers.42.weight
 (1, 2)" fillcolor=lightblue]
	14178490144 -> 14315001584
	14315001584 [label=AccumulateGrad]
	14314817616 -> 14315002016
	14178490224 [label="layers.42.bias
 (1)" fillcolor=lightblue]
	14178490224 -> 14314817616
	14314817616 [label=AccumulateGrad]
	14315002016 -> 14173005184
}
