digraph {
	graph [size="40.949999999999996,40.949999999999996"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	13819832320 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	13845782608 -> 13845868096 [dir=none]
	13845868096 [label="input
 (1, 2)" fillcolor=orange]
	13845782608 -> 13845865376 [dir=none]
	13845865376 [label="weight
 (1, 2)" fillcolor=orange]
	13845782608 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13845788848 -> 13845782608
	13845788848 -> 13845868176 [dir=none]
	13845868176 [label="other
 (1, 2)" fillcolor=orange]
	13845788848 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	13845449360 -> 13845788848
	13845449360 -> 13845867936 [dir=none]
	13845867936 [label="input
 (1, 2)" fillcolor=orange]
	13845449360 -> 13845865216 [dir=none]
	13845865216 [label="weight
 (2, 2)" fillcolor=orange]
	13845449360 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13819760592 -> 13845449360
	13819760592 -> 13845868016 [dir=none]
	13845868016 [label="other
 (1, 2)" fillcolor=orange]
	13819760592 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	13845804896 -> 13819760592
	13845804896 -> 13845867776 [dir=none]
	13845867776 [label="input
 (1, 2)" fillcolor=orange]
	13845804896 -> 13845865056 [dir=none]
	13845865056 [label="weight
 (2, 2)" fillcolor=orange]
	13845804896 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13845805088 -> 13845804896
	13845805088 -> 13845867856 [dir=none]
	13845867856 [label="other
 (1, 2)" fillcolor=orange]
	13845805088 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	13845804992 -> 13845805088
	13845804992 -> 13845867616 [dir=none]
	13845867616 [label="input
 (1, 2)" fillcolor=orange]
	13845804992 -> 13845864896 [dir=none]
	13845864896 [label="weight
 (2, 2)" fillcolor=orange]
	13845804992 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13845805376 -> 13845804992
	13845805376 -> 13845867696 [dir=none]
	13845867696 [label="other
 (1, 2)" fillcolor=orange]
	13845805376 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	13845805328 -> 13845805376
	13845805328 -> 13845867456 [dir=none]
	13845867456 [label="input
 (1, 4)" fillcolor=orange]
	13845805328 -> 13845864736 [dir=none]
	13845864736 [label="weight
 (2, 4)" fillcolor=orange]
	13845805328 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13845805664 -> 13845805328
	13845805664 -> 13845867536 [dir=none]
	13845867536 [label="other
 (1, 4)" fillcolor=orange]
	13845805664 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	13845805616 -> 13845805664
	13845805616 -> 13845867296 [dir=none]
	13845867296 [label="input
 (1, 4)" fillcolor=orange]
	13845805616 -> 13845864576 [dir=none]
	13845864576 [label="weight
 (4, 4)" fillcolor=orange]
	13845805616 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13845805952 -> 13845805616
	13845805952 -> 13845867376 [dir=none]
	13845867376 [label="other
 (1, 4)" fillcolor=orange]
	13845805952 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	13845805904 -> 13845805952
	13845805904 -> 13845865856 [dir=none]
	13845865856 [label="input
 (1, 4)" fillcolor=orange]
	13845805904 -> 13845864416 [dir=none]
	13845864416 [label="weight
 (4, 4)" fillcolor=orange]
	13845805904 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13845806240 -> 13845805904
	13845806240 -> 13845867216 [dir=none]
	13845867216 [label="other
 (1, 4)" fillcolor=orange]
	13845806240 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	13845806192 -> 13845806240
	13845806192 -> 13845865696 [dir=none]
	13845865696 [label="input
 (1, 4)" fillcolor=orange]
	13845806192 -> 13845864256 [dir=none]
	13845864256 [label="weight
 (4, 4)" fillcolor=orange]
	13845806192 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13845806528 -> 13845806192
	13845806528 -> 13845867136 [dir=none]
	13845867136 [label="other
 (1, 4)" fillcolor=orange]
	13845806528 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	13845806480 -> 13845806528
	13845806480 -> 13845862896 [dir=none]
	13845862896 [label="input
 (1, 8)" fillcolor=orange]
	13845806480 -> 13845864096 [dir=none]
	13845864096 [label="weight
 (4, 8)" fillcolor=orange]
	13845806480 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13845806816 -> 13845806480
	13845806816 -> 13845862736 [dir=none]
	13845862736 [label="other
 (1, 8)" fillcolor=orange]
	13845806816 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	13845806768 -> 13845806816
	13845806768 -> 13845866736 [dir=none]
	13845866736 [label="input
 (1, 8)" fillcolor=orange]
	13845806768 -> 13845863936 [dir=none]
	13845863936 [label="weight
 (8, 8)" fillcolor=orange]
	13845806768 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13845807008 -> 13845806768
	13845807008 -> 13845866976 [dir=none]
	13845866976 [label="other
 (1, 8)" fillcolor=orange]
	13845807008 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	13846298736 -> 13845807008
	13846298736 -> 13845858176 [dir=none]
	13845858176 [label="input
 (1, 8)" fillcolor=orange]
	13846298736 -> 13845863776 [dir=none]
	13845863776 [label="weight
 (8, 8)" fillcolor=orange]
	13846298736 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13846298976 -> 13846298736
	13846298976 -> 13845858096 [dir=none]
	13845858096 [label="other
 (1, 8)" fillcolor=orange]
	13846298976 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	13846298928 -> 13846298976
	13846298928 -> 13845858336 [dir=none]
	13845858336 [label="input
 (1, 16)" fillcolor=orange]
	13846298928 -> 13845863616 [dir=none]
	13845863616 [label="weight
 (8, 16)" fillcolor=orange]
	13846298928 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13846299264 -> 13846298928
	13846299264 -> 13845857616 [dir=none]
	13845857616 [label="other
 (1, 16)" fillcolor=orange]
	13846299264 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	13846299216 -> 13846299264
	13846299216 -> 13845858016 [dir=none]
	13845858016 [label="input
 (1, 16)" fillcolor=orange]
	13846299216 -> 13845862656 [dir=none]
	13845862656 [label="weight
 (16, 16)" fillcolor=orange]
	13846299216 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13846299504 -> 13846299216
	13846299504 -> 13845866016 [dir=none]
	13845866016 [label="other
 (1, 16)" fillcolor=orange]
	13846299504 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	13846299552 -> 13846299504
	13846299552 -> 13845859296 [dir=none]
	13845859296 [label="input
 (1, 32)" fillcolor=orange]
	13846299552 -> 13845863456 [dir=none]
	13845863456 [label="weight
 (16, 32)" fillcolor=orange]
	13846299552 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13846299792 -> 13846299552
	13846299792 -> 13845866096 [dir=none]
	13845866096 [label="other
 (1, 32)" fillcolor=orange]
	13846299792 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	13846299840 -> 13846299792
	13846299840 -> 13845642800 [dir=none]
	13845642800 [label="input
 (1, 10)" fillcolor=orange]
	13846299840 -> 13845751168 [dir=none]
	13845751168 [label="weight
 (32, 10)" fillcolor=orange]
	13846299840 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13846300080 -> 13846299840
	13846300080 [label=ToCopyBackward0]
	13846300128 -> 13846300080
	13845577584 [label="
 (1, 10)" fillcolor=lightblue]
	13845577584 -> 13846300128
	13846300128 [label=AccumulateGrad]
	13846300176 -> 13846299840
	13845751168 [label="layers.0.weight
 (32, 10)" fillcolor=lightblue]
	13845751168 -> 13846300176
	13846300176 [label=AccumulateGrad]
	13846299936 -> 13846299840
	13845750928 [label="layers.0.bias
 (32)" fillcolor=lightblue]
	13845750928 -> 13846299936
	13846299936 [label=AccumulateGrad]
	13846299888 -> 13846299552
	13845863456 [label="layers.3.weight
 (16, 32)" fillcolor=lightblue]
	13845863456 -> 13846299888
	13846299888 [label=AccumulateGrad]
	13846299648 -> 13846299552
	13845862976 [label="layers.3.bias
 (16)" fillcolor=lightblue]
	13845862976 -> 13846299648
	13846299648 [label=AccumulateGrad]
	13846299600 -> 13846299216
	13845862656 [label="layers.6.weight
 (16, 16)" fillcolor=lightblue]
	13845862656 -> 13846299600
	13846299600 [label=AccumulateGrad]
	13846299360 -> 13846299216
	13845863536 [label="layers.6.bias
 (16)" fillcolor=lightblue]
	13845863536 -> 13846299360
	13846299360 [label=AccumulateGrad]
	13846299312 -> 13846298928
	13845863616 [label="layers.9.weight
 (8, 16)" fillcolor=lightblue]
	13845863616 -> 13846299312
	13846299312 [label=AccumulateGrad]
	13846299072 -> 13846298928
	13845863696 [label="layers.9.bias
 (8)" fillcolor=lightblue]
	13845863696 -> 13846299072
	13846299072 [label=AccumulateGrad]
	13846299024 -> 13846298736
	13845863776 [label="layers.12.weight
 (8, 8)" fillcolor=lightblue]
	13845863776 -> 13846299024
	13846299024 [label=AccumulateGrad]
	13846298688 -> 13846298736
	13845863856 [label="layers.12.bias
 (8)" fillcolor=lightblue]
	13845863856 -> 13846298688
	13846298688 [label=AccumulateGrad]
	13845807056 -> 13845806768
	13845863936 [label="layers.15.weight
 (8, 8)" fillcolor=lightblue]
	13845863936 -> 13845807056
	13845807056 [label=AccumulateGrad]
	13845806912 -> 13845806768
	13845864016 [label="layers.15.bias
 (8)" fillcolor=lightblue]
	13845864016 -> 13845806912
	13845806912 [label=AccumulateGrad]
	13845806864 -> 13845806480
	13845864096 [label="layers.18.weight
 (4, 8)" fillcolor=lightblue]
	13845864096 -> 13845806864
	13845806864 [label=AccumulateGrad]
	13845806624 -> 13845806480
	13845864176 [label="layers.18.bias
 (4)" fillcolor=lightblue]
	13845864176 -> 13845806624
	13845806624 [label=AccumulateGrad]
	13845806576 -> 13845806192
	13845864256 [label="layers.21.weight
 (4, 4)" fillcolor=lightblue]
	13845864256 -> 13845806576
	13845806576 [label=AccumulateGrad]
	13845806336 -> 13845806192
	13845864336 [label="layers.21.bias
 (4)" fillcolor=lightblue]
	13845864336 -> 13845806336
	13845806336 [label=AccumulateGrad]
	13845806288 -> 13845805904
	13845864416 [label="layers.24.weight
 (4, 4)" fillcolor=lightblue]
	13845864416 -> 13845806288
	13845806288 [label=AccumulateGrad]
	13845806048 -> 13845805904
	13845864496 [label="layers.24.bias
 (4)" fillcolor=lightblue]
	13845864496 -> 13845806048
	13845806048 [label=AccumulateGrad]
	13845806000 -> 13845805616
	13845864576 [label="layers.27.weight
 (4, 4)" fillcolor=lightblue]
	13845864576 -> 13845806000
	13845806000 [label=AccumulateGrad]
	13845805760 -> 13845805616
	13845864656 [label="layers.27.bias
 (4)" fillcolor=lightblue]
	13845864656 -> 13845805760
	13845805760 [label=AccumulateGrad]
	13845805712 -> 13845805328
	13845864736 [label="layers.30.weight
 (2, 4)" fillcolor=lightblue]
	13845864736 -> 13845805712
	13845805712 [label=AccumulateGrad]
	13845805472 -> 13845805328
	13845864816 [label="layers.30.bias
 (2)" fillcolor=lightblue]
	13845864816 -> 13845805472
	13845805472 [label=AccumulateGrad]
	13845805424 -> 13845804992
	13845864896 [label="layers.33.weight
 (2, 2)" fillcolor=lightblue]
	13845864896 -> 13845805424
	13845805424 [label=AccumulateGrad]
	13845805040 -> 13845804992
	13845864976 [label="layers.33.bias
 (2)" fillcolor=lightblue]
	13845864976 -> 13845805040
	13845805040 [label=AccumulateGrad]
	13845805184 -> 13845804896
	13845865056 [label="layers.36.weight
 (2, 2)" fillcolor=lightblue]
	13845865056 -> 13845805184
	13845805184 [label=AccumulateGrad]
	13845804752 -> 13845804896
	13845865136 [label="layers.36.bias
 (2)" fillcolor=lightblue]
	13845865136 -> 13845804752
	13845804752 [label=AccumulateGrad]
	13819761120 -> 13845449360
	13845865216 [label="layers.39.weight
 (2, 2)" fillcolor=lightblue]
	13845865216 -> 13819761120
	13819761120 [label=AccumulateGrad]
	13845793376 -> 13845449360
	13845865296 [label="layers.39.bias
 (2)" fillcolor=lightblue]
	13845865296 -> 13845793376
	13845793376 [label=AccumulateGrad]
	13819730656 -> 13845782608
	13845865376 [label="layers.42.weight
 (1, 2)" fillcolor=lightblue]
	13845865376 -> 13819730656
	13819730656 [label=AccumulateGrad]
	13845519936 -> 13845782608
	13845865456 [label="layers.42.bias
 (1)" fillcolor=lightblue]
	13845865456 -> 13845519936
	13845519936 [label=AccumulateGrad]
	13845782608 -> 13819832320
}
