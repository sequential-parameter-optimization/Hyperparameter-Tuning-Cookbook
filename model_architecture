digraph {
	graph [size="15.149999999999999,15.149999999999999"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	13246226080 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	13234266048 [label=LinearBackward0]
	13234059248 -> 13234266048
	13234059248 [label=MulBackward0]
	13234333360 -> 13234059248
	13234333360 [label=LinearBackward0]
	13234233712 -> 13234333360
	13234233712 [label=MulBackward0]
	13234376032 -> 13234233712
	13234376032 [label=LinearBackward0]
	13246275808 -> 13234376032
	13246275808 [label=MulBackward0]
	13246276000 -> 13246275808
	13246276000 [label=LinearBackward0]
	13246276096 -> 13246276000
	13246276096 [label=MulBackward0]
	13246276288 -> 13246276096
	13246276288 [label=LinearBackward0]
	13246276384 -> 13246276288
	13246276384 [label=MulBackward0]
	13246276576 -> 13246276384
	13246276576 [label=LinearBackward0]
	13246276672 -> 13246276576
	13246276672 [label=MulBackward0]
	13246276864 -> 13246276672
	13246276864 [label=LinearBackward0]
	13246276960 -> 13246276864
	13246276960 [label=MulBackward0]
	13246277152 -> 13246276960
	13246277152 [label=LinearBackward0]
	13246277248 -> 13246277152
	13246277248 [label=ToCopyBackward0]
	13246277440 -> 13246277248
	13234178080 [label="
 (1, 10)" fillcolor=lightblue]
	13234178080 -> 13246277440
	13246277440 [label=AccumulateGrad]
	13246277296 -> 13246277152
	13234078336 [label="layers.0.weight
 (320, 10)" fillcolor=lightblue]
	13234078336 -> 13246277296
	13246277296 [label=AccumulateGrad]
	13246277104 -> 13246277152
	13234078496 [label="layers.0.bias
 (320)" fillcolor=lightblue]
	13234078496 -> 13246277104
	13246277104 [label=AccumulateGrad]
	13246277008 -> 13246276864
	13234079776 [label="layers.3.weight
 (160, 320)" fillcolor=lightblue]
	13234079776 -> 13246277008
	13246277008 [label=AccumulateGrad]
	13246276816 -> 13246276864
	13234078976 [label="layers.3.bias
 (160)" fillcolor=lightblue]
	13234078976 -> 13246276816
	13246276816 [label=AccumulateGrad]
	13246276720 -> 13246276576
	13234078816 [label="layers.6.weight
 (320, 160)" fillcolor=lightblue]
	13234078816 -> 13246276720
	13246276720 [label=AccumulateGrad]
	13246276528 -> 13246276576
	13234085056 [label="layers.6.bias
 (320)" fillcolor=lightblue]
	13234085056 -> 13246276528
	13246276528 [label=AccumulateGrad]
	13246276432 -> 13246276288
	13234092896 [label="layers.9.weight
 (160, 320)" fillcolor=lightblue]
	13234092896 -> 13246276432
	13246276432 [label=AccumulateGrad]
	13246276240 -> 13246276288
	13234089696 [label="layers.9.bias
 (160)" fillcolor=lightblue]
	13234089696 -> 13246276240
	13246276240 [label=AccumulateGrad]
	13246276144 -> 13246276000
	13234086896 [label="layers.12.weight
 (160, 160)" fillcolor=lightblue]
	13234086896 -> 13246276144
	13246276144 [label=AccumulateGrad]
	13246275952 -> 13246276000
	13234086416 [label="layers.12.bias
 (160)" fillcolor=lightblue]
	13234086416 -> 13246275952
	13246275952 [label=AccumulateGrad]
	13246275856 -> 13234376032
	13234085936 [label="layers.15.weight
 (80, 160)" fillcolor=lightblue]
	13234085936 -> 13246275856
	13246275856 [label=AccumulateGrad]
	13246275424 -> 13234376032
	13234084256 [label="layers.15.bias
 (80)" fillcolor=lightblue]
	13234084256 -> 13246275424
	13246275424 [label=AccumulateGrad]
	13246275328 -> 13234333360
	13234178240 [label="layers.18.weight
 (80, 80)" fillcolor=lightblue]
	13234178240 -> 13246275328
	13246275328 [label=AccumulateGrad]
	13246275472 -> 13234333360
	13234177040 [label="layers.18.bias
 (80)" fillcolor=lightblue]
	13234177040 -> 13246275472
	13246275472 [label=AccumulateGrad]
	13234375504 -> 13234266048
	13234190480 [label="layers.21.weight
 (1, 80)" fillcolor=lightblue]
	13234190480 -> 13234375504
	13234375504 [label=AccumulateGrad]
	13056851248 -> 13234266048
	13234190560 [label="layers.21.bias
 (1)" fillcolor=lightblue]
	13234190560 -> 13056851248
	13056851248 [label=AccumulateGrad]
	13234266048 -> 13246226080
}
