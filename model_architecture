digraph {
	graph [size="25.65,25.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	13827049744 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	13844017648 -> 13827049664 [dir=none]
	13827049664 [label="input
 (1, 2)" fillcolor=orange]
	13844017648 -> 14236686512 [dir=none]
	14236686512 [label="weight
 (1, 2)" fillcolor=orange]
	13844017648 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13815110992 -> 13844017648
	13815110992 -> 13827049584 [dir=none]
	13827049584 [label="other
 (1, 2)" fillcolor=orange]
	13815110992 -> 13827049504 [dir=none]
	13827049504 [label="self
 (1, 2)" fillcolor=orange]
	13815110992 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	13815119248 -> 13815110992
	13815119248 -> 13827049424 [dir=none]
	13827049424 [label="input
 (1, 2)" fillcolor=orange]
	13815119248 -> 14236542016 [dir=none]
	14236542016 [label="weight
 (2, 2)" fillcolor=orange]
	13815119248 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13826977808 -> 13815119248
	13826977808 -> 13827049344 [dir=none]
	13827049344 [label="other
 (1, 2)" fillcolor=orange]
	13826977808 -> 13827049264 [dir=none]
	13827049264 [label="self
 (1, 2)" fillcolor=orange]
	13826977808 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	13826977568 -> 13826977808
	13826977568 -> 13827049184 [dir=none]
	13827049184 [label="input
 (1, 2)" fillcolor=orange]
	13826977568 -> 13843675440 [dir=none]
	13843675440 [label="weight
 (2, 2)" fillcolor=orange]
	13826977568 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13826978192 -> 13826977568
	13826978192 -> 13827049104 [dir=none]
	13827049104 [label="other
 (1, 2)" fillcolor=orange]
	13826978192 -> 13827049024 [dir=none]
	13827049024 [label="self
 (1, 2)" fillcolor=orange]
	13826978192 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	13826978048 -> 13826978192
	13826978048 -> 13827048944 [dir=none]
	13827048944 [label="input
 (1, 4)" fillcolor=orange]
	13826978048 -> 14236686912 [dir=none]
	14236686912 [label="weight
 (2, 4)" fillcolor=orange]
	13826978048 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13826978528 -> 13826978048
	13826978528 -> 13827048864 [dir=none]
	13827048864 [label="other
 (1, 4)" fillcolor=orange]
	13826978528 -> 13827048784 [dir=none]
	13827048784 [label="self
 (1, 4)" fillcolor=orange]
	13826978528 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	13826978384 -> 13826978528
	13826978384 -> 13827047824 [dir=none]
	13827047824 [label="input
 (1, 4)" fillcolor=orange]
	13826978384 -> 14236686592 [dir=none]
	14236686592 [label="weight
 (4, 4)" fillcolor=orange]
	13826978384 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13826978864 -> 13826978384
	13826978864 -> 13827048384 [dir=none]
	13827048384 [label="other
 (1, 4)" fillcolor=orange]
	13826978864 -> 14236614192 [dir=none]
	14236614192 [label="self
 (1, 4)" fillcolor=orange]
	13826978864 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	13826978720 -> 13826978864
	13826978720 -> 14236610592 [dir=none]
	14236610592 [label="input
 (1, 8)" fillcolor=orange]
	13826978720 -> 14236686672 [dir=none]
	14236686672 [label="weight
 (4, 8)" fillcolor=orange]
	13826978720 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13826979200 -> 13826978720
	13826979200 -> 14236601792 [dir=none]
	14236601792 [label="other
 (1, 8)" fillcolor=orange]
	13826979200 -> 14236610752 [dir=none]
	14236610752 [label="self
 (1, 8)" fillcolor=orange]
	13826979200 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	13826979056 -> 13826979200
	13826979056 -> 14236611792 [dir=none]
	14236611792 [label="input
 (1, 10)" fillcolor=orange]
	13826979056 -> 14236685792 [dir=none]
	14236685792 [label="weight
 (8, 10)" fillcolor=orange]
	13826979056 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13826979536 -> 13826979056
	13826979536 [label=ToCopyBackward0]
	13826979392 -> 13826979536
	13813846560 [label="
 (1, 10)" fillcolor=lightblue]
	13813846560 -> 13826979392
	13826979392 [label=AccumulateGrad]
	13826979440 -> 13826979056
	14236685792 [label="layers.0.weight
 (8, 10)" fillcolor=lightblue]
	14236685792 -> 13826979440
	13826979440 [label=AccumulateGrad]
	13826979488 -> 13826979056
	14236685632 [label="layers.0.bias
 (8)" fillcolor=lightblue]
	14236685632 -> 13826979488
	13826979488 [label=AccumulateGrad]
	13826979344 -> 13826979200
	13826979344 -> 13827056864 [dir=none]
	13827056864 [label="result
 (1, 8)" fillcolor=orange]
	13826979344 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	13826979056 -> 13826979344
	13826979104 -> 13826978720
	14236686672 [label="layers.3.weight
 (4, 8)" fillcolor=lightblue]
	14236686672 -> 13826979104
	13826979104 [label=AccumulateGrad]
	13826979152 -> 13826978720
	14236686752 [label="layers.3.bias
 (4)" fillcolor=lightblue]
	14236686752 -> 13826979152
	13826979152 [label=AccumulateGrad]
	13826979008 -> 13826978864
	13826979008 -> 13827057664 [dir=none]
	13827057664 [label="result
 (1, 4)" fillcolor=orange]
	13826979008 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	13826978720 -> 13826979008
	13826978768 -> 13826978384
	14236686592 [label="layers.6.weight
 (4, 4)" fillcolor=lightblue]
	14236686592 -> 13826978768
	13826978768 [label=AccumulateGrad]
	13826978816 -> 13826978384
	14236686832 [label="layers.6.bias
 (4)" fillcolor=lightblue]
	14236686832 -> 13826978816
	13826978816 [label=AccumulateGrad]
	13826978672 -> 13826978528
	13826978672 -> 13827058464 [dir=none]
	13827058464 [label="result
 (1, 4)" fillcolor=orange]
	13826978672 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	13826978384 -> 13826978672
	13826978432 -> 13826978048
	14236686912 [label="layers.9.weight
 (2, 4)" fillcolor=lightblue]
	14236686912 -> 13826978432
	13826978432 [label=AccumulateGrad]
	13826978480 -> 13826978048
	14236686992 [label="layers.9.bias
 (2)" fillcolor=lightblue]
	14236686992 -> 13826978480
	13826978480 [label=AccumulateGrad]
	13826978336 -> 13826978192
	13826978336 -> 13827059264 [dir=none]
	13827059264 [label="result
 (1, 2)" fillcolor=orange]
	13826978336 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	13826978048 -> 13826978336
	13826978096 -> 13826977568
	13843675440 [label="layers.12.weight
 (2, 2)" fillcolor=lightblue]
	13843675440 -> 13826978096
	13826978096 [label=AccumulateGrad]
	13826978144 -> 13826977568
	14236545056 [label="layers.12.bias
 (2)" fillcolor=lightblue]
	14236545056 -> 13826978144
	13826978144 [label=AccumulateGrad]
	13826977856 -> 13826977808
	13826977856 -> 13827060064 [dir=none]
	13827060064 [label="result
 (1, 2)" fillcolor=orange]
	13826977856 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	13826977568 -> 13826977856
	13826977760 -> 13815119248
	14236542016 [label="layers.15.weight
 (2, 2)" fillcolor=lightblue]
	14236542016 -> 13826977760
	13826977760 [label=AccumulateGrad]
	13826977904 -> 13815119248
	14236687072 [label="layers.15.bias
 (2)" fillcolor=lightblue]
	14236687072 -> 13826977904
	13826977904 [label=AccumulateGrad]
	13826977616 -> 13815110992
	13826977616 -> 13827060864 [dir=none]
	13827060864 [label="result
 (1, 2)" fillcolor=orange]
	13826977616 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	13815119248 -> 13826977616
	13844015584 -> 13844017648
	14236686512 [label="layers.18.weight
 (1, 2)" fillcolor=lightblue]
	14236686512 -> 13844015584
	13844015584 [label=AccumulateGrad]
	13843919152 -> 13844017648
	14236687152 [label="layers.18.bias
 (1)" fillcolor=lightblue]
	14236687152 -> 13843919152
	13843919152 [label=AccumulateGrad]
	13844017648 -> 13827049744
}
