digraph {
	graph [size="18.3,18.3"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	15416983488 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	15417271360 [label=LinearBackward0]
	15406949632 -> 15417271360
	15406949632 [label=WhereBackward0]
	15668997824 -> 15406949632
	15668997824 [label=LinearBackward0]
	15668997776 -> 15668997824
	15668997776 [label=WhereBackward0]
	15668997968 -> 15668997776
	15668997968 [label=LinearBackward0]
	15668998304 -> 15668997968
	15668998304 [label=WhereBackward0]
	15668998496 -> 15668998304
	15668998496 [label=LinearBackward0]
	15668998640 -> 15668998496
	15668998640 [label=WhereBackward0]
	15668998832 -> 15668998640
	15668998832 [label=LinearBackward0]
	15668998976 -> 15668998832
	15668998976 [label=WhereBackward0]
	15668999168 -> 15668998976
	15668999168 [label=LinearBackward0]
	15668999312 -> 15668999168
	15668999312 [label=WhereBackward0]
	15668999504 -> 15668999312
	15668999504 [label=LinearBackward0]
	15668999648 -> 15668999504
	15668999648 [label=WhereBackward0]
	15668999840 -> 15668999648
	15668999840 [label=LinearBackward0]
	15668999984 -> 15668999840
	15668999984 [label=ToCopyBackward0]
	15669000176 -> 15668999984
	15417419056 [label="
 (1, 10)" fillcolor=lightblue]
	15417419056 -> 15669000176
	15669000176 [label=AccumulateGrad]
	15668999936 -> 15668999840
	15417425856 [label="layers.0.weight
 (320, 10)" fillcolor=lightblue]
	15417425856 -> 15668999936
	15668999936 [label=AccumulateGrad]
	15668999888 -> 15668999840
	15417472128 [label="layers.0.bias
 (320)" fillcolor=lightblue]
	15417472128 -> 15668999888
	15668999888 [label=AccumulateGrad]
	15668999792 -> 15668999648
	15668999792 [label=MulBackward0]
	15668999840 -> 15668999792
	15668999600 -> 15668999504
	15417472208 [label="layers.3.weight
 (160, 320)" fillcolor=lightblue]
	15417472208 -> 15668999600
	15668999600 [label=AccumulateGrad]
	15668999552 -> 15668999504
	15417472288 [label="layers.3.bias
 (160)" fillcolor=lightblue]
	15417472288 -> 15668999552
	15668999552 [label=AccumulateGrad]
	15668999456 -> 15668999312
	15668999456 [label=MulBackward0]
	15668999504 -> 15668999456
	15668999264 -> 15668999168
	15417471648 [label="layers.6.weight
 (320, 160)" fillcolor=lightblue]
	15417471648 -> 15668999264
	15668999264 [label=AccumulateGrad]
	15668999216 -> 15668999168
	15417472368 [label="layers.6.bias
 (320)" fillcolor=lightblue]
	15417472368 -> 15668999216
	15668999216 [label=AccumulateGrad]
	15668999120 -> 15668998976
	15668999120 [label=MulBackward0]
	15668999168 -> 15668999120
	15668998928 -> 15668998832
	15417472448 [label="layers.9.weight
 (160, 320)" fillcolor=lightblue]
	15417472448 -> 15668998928
	15668998928 [label=AccumulateGrad]
	15668998880 -> 15668998832
	15417472528 [label="layers.9.bias
 (160)" fillcolor=lightblue]
	15417472528 -> 15668998880
	15668998880 [label=AccumulateGrad]
	15668998784 -> 15668998640
	15668998784 [label=MulBackward0]
	15668998832 -> 15668998784
	15668998592 -> 15668998496
	15417472608 [label="layers.12.weight
 (160, 160)" fillcolor=lightblue]
	15417472608 -> 15668998592
	15668998592 [label=AccumulateGrad]
	15668998544 -> 15668998496
	15417472688 [label="layers.12.bias
 (160)" fillcolor=lightblue]
	15417472688 -> 15668998544
	15668998544 [label=AccumulateGrad]
	15668998448 -> 15668998304
	15668998448 [label=MulBackward0]
	15668998496 -> 15668998448
	15668998256 -> 15668997968
	15417472768 [label="layers.15.weight
 (80, 160)" fillcolor=lightblue]
	15417472768 -> 15668998256
	15668998256 [label=AccumulateGrad]
	15668998208 -> 15668997968
	15417472848 [label="layers.15.bias
 (80)" fillcolor=lightblue]
	15417472848 -> 15668998208
	15668998208 [label=AccumulateGrad]
	15668998160 -> 15668997776
	15668998160 [label=MulBackward0]
	15668997968 -> 15668998160
	15668997872 -> 15668997824
	15417472928 [label="layers.18.weight
 (80, 80)" fillcolor=lightblue]
	15417472928 -> 15668997872
	15668997872 [label=AccumulateGrad]
	15668997920 -> 15668997824
	15417473008 [label="layers.18.bias
 (80)" fillcolor=lightblue]
	15417473008 -> 15668997920
	15668997920 [label=AccumulateGrad]
	15668997680 -> 15406949632
	15668997680 [label=MulBackward0]
	15668997824 -> 15668997680
	15417277360 -> 15417271360
	15417413136 [label="layers.21.weight
 (1, 80)" fillcolor=lightblue]
	15417413136 -> 15417277360
	15417277360 [label=AccumulateGrad]
	15417476624 -> 15417271360
	15417413296 [label="layers.21.bias
 (1)" fillcolor=lightblue]
	15417413296 -> 15417476624
	15417476624 [label=AccumulateGrad]
	15417271360 -> 15416983488
}
