digraph {
	graph [size="20.55,20.55"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	13508010912 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	13490709568 [label=LinearBackward0]
	13447748704 -> 13490709568
	13447748704 [label=MulBackward0]
	13448246080 -> 13447748704
	13448246080 [label=LinearBackward0]
	13476703168 -> 13448246080
	13476703168 [label=MulBackward0]
	13490487936 -> 13476703168
	13490487936 [label=LinearBackward0]
	13491824208 -> 13490487936
	13491824208 [label=MulBackward0]
	13491824400 -> 13491824208
	13491824400 [label=LinearBackward0]
	13491824496 -> 13491824400
	13491824496 [label=MulBackward0]
	13491824688 -> 13491824496
	13491824688 [label=LinearBackward0]
	13491824784 -> 13491824688
	13491824784 [label=MulBackward0]
	13491824976 -> 13491824784
	13491824976 [label=LinearBackward0]
	13491825072 -> 13491824976
	13491825072 [label=MulBackward0]
	13491825264 -> 13491825072
	13491825264 [label=LinearBackward0]
	13491825360 -> 13491825264
	13491825360 [label=MulBackward0]
	13491825552 -> 13491825360
	13491825552 [label=LinearBackward0]
	13491825648 -> 13491825552
	13491825648 [label=MulBackward0]
	13491825840 -> 13491825648
	13491825840 [label=LinearBackward0]
	13491825936 -> 13491825840
	13491825936 [label=MulBackward0]
	13491826128 -> 13491825936
	13491826128 [label=LinearBackward0]
	13491826224 -> 13491826128
	13491826224 [label=MulBackward0]
	13491826416 -> 13491826224
	13491826416 [label=LinearBackward0]
	13491826512 -> 13491826416
	13491826512 [label=ToCopyBackward0]
	13491826704 -> 13491826512
	13293562896 [label="
 (1, 10)" fillcolor=lightblue]
	13293562896 -> 13491826704
	13491826704 [label=AccumulateGrad]
	13491826464 -> 13491826416
	13508194096 [label="layers.0.weight
 (128, 10)" fillcolor=lightblue]
	13508194096 -> 13491826464
	13491826464 [label=AccumulateGrad]
	13491826320 -> 13491826416
	13508193616 [label="layers.0.bias
 (128)" fillcolor=lightblue]
	13508193616 -> 13491826320
	13491826320 [label=AccumulateGrad]
	13491826176 -> 13491826128
	13508193296 [label="layers.3.weight
 (64, 128)" fillcolor=lightblue]
	13508193296 -> 13491826176
	13491826176 [label=AccumulateGrad]
	13491826032 -> 13491826128
	13508194176 [label="layers.3.bias
 (64)" fillcolor=lightblue]
	13508194176 -> 13491826032
	13491826032 [label=AccumulateGrad]
	13491825888 -> 13491825840
	13508194256 [label="layers.6.weight
 (64, 64)" fillcolor=lightblue]
	13508194256 -> 13491825888
	13491825888 [label=AccumulateGrad]
	13491825744 -> 13491825840
	13508194496 [label="layers.6.bias
 (64)" fillcolor=lightblue]
	13508194496 -> 13491825744
	13491825744 [label=AccumulateGrad]
	13491825600 -> 13491825552
	13508194576 [label="layers.9.weight
 (32, 64)" fillcolor=lightblue]
	13508194576 -> 13491825600
	13491825600 [label=AccumulateGrad]
	13491825456 -> 13491825552
	13508194656 [label="layers.9.bias
 (32)" fillcolor=lightblue]
	13508194656 -> 13491825456
	13491825456 [label=AccumulateGrad]
	13491825312 -> 13491825264
	13508181472 [label="layers.12.weight
 (32, 32)" fillcolor=lightblue]
	13508181472 -> 13491825312
	13491825312 [label=AccumulateGrad]
	13491825168 -> 13491825264
	13508017392 [label="layers.12.bias
 (32)" fillcolor=lightblue]
	13508017392 -> 13491825168
	13491825168 [label=AccumulateGrad]
	13491825024 -> 13491824976
	13508194736 [label="layers.15.weight
 (32, 32)" fillcolor=lightblue]
	13508194736 -> 13491825024
	13491825024 [label=AccumulateGrad]
	13491824880 -> 13491824976
	13508194816 [label="layers.15.bias
 (32)" fillcolor=lightblue]
	13508194816 -> 13491824880
	13491824880 [label=AccumulateGrad]
	13491824736 -> 13491824688
	13508194896 [label="layers.18.weight
 (16, 32)" fillcolor=lightblue]
	13508194896 -> 13491824736
	13491824736 [label=AccumulateGrad]
	13491824592 -> 13491824688
	13508194976 [label="layers.18.bias
 (16)" fillcolor=lightblue]
	13508194976 -> 13491824592
	13491824592 [label=AccumulateGrad]
	13491824448 -> 13491824400
	13508195056 [label="layers.21.weight
 (16, 16)" fillcolor=lightblue]
	13508195056 -> 13491824448
	13491824448 [label=AccumulateGrad]
	13491824304 -> 13491824400
	13508195616 [label="layers.21.bias
 (16)" fillcolor=lightblue]
	13508195616 -> 13491824304
	13491824304 [label=AccumulateGrad]
	13491824064 -> 13490487936
	13508195856 [label="layers.24.weight
 (16, 16)" fillcolor=lightblue]
	13508195856 -> 13491824064
	13491824064 [label=AccumulateGrad]
	13491823728 -> 13490487936
	13508195936 [label="layers.24.bias
 (16)" fillcolor=lightblue]
	13508195936 -> 13491823728
	13491823728 [label=AccumulateGrad]
	13490488176 -> 13448246080
	13508196176 [label="layers.27.weight
 (16, 16)" fillcolor=lightblue]
	13508196176 -> 13490488176
	13490488176 [label=AccumulateGrad]
	13490487888 -> 13448246080
	13508196256 [label="layers.27.bias
 (16)" fillcolor=lightblue]
	13508196256 -> 13490487888
	13490487888 [label=AccumulateGrad]
	13476600976 -> 13490709568
	13508196336 [label="layers.30.weight
 (1, 16)" fillcolor=lightblue]
	13508196336 -> 13476600976
	13476600976 [label=AccumulateGrad]
	13476705280 -> 13490709568
	13508196576 [label="layers.30.bias
 (1)" fillcolor=lightblue]
	13508196576 -> 13476705280
	13476705280 [label=AccumulateGrad]
	13490709568 -> 13508010912
}
