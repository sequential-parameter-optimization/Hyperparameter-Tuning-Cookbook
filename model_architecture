digraph {
	graph [size="18.3,18.3"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	15717610784 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	15717334512 [label=LinearBackward0]
	15717332304 -> 15717334512
	15717332304 [label=WhereBackward0]
	14436685984 -> 15717332304
	14436685984 [label=LinearBackward0]
	15717501248 -> 14436685984
	15717501248 [label=WhereBackward0]
	15730746624 -> 15717501248
	15730746624 [label=LinearBackward0]
	15730746864 -> 15730746624
	15730746864 [label=WhereBackward0]
	15730747056 -> 15730746864
	15730747056 [label=LinearBackward0]
	15730747200 -> 15730747056
	15730747200 [label=WhereBackward0]
	15730747392 -> 15730747200
	15730747392 [label=LinearBackward0]
	15730747536 -> 15730747392
	15730747536 [label=WhereBackward0]
	15730747728 -> 15730747536
	15730747728 [label=LinearBackward0]
	15730747872 -> 15730747728
	15730747872 [label=WhereBackward0]
	15730748064 -> 15730747872
	15730748064 [label=LinearBackward0]
	15730748208 -> 15730748064
	15730748208 [label=WhereBackward0]
	15730748400 -> 15730748208
	15730748400 [label=LinearBackward0]
	15730748544 -> 15730748400
	15730748544 [label=ToCopyBackward0]
	15717329088 -> 15730748544
	15717612704 [label="
 (1, 10)" fillcolor=lightblue]
	15717612704 -> 15717329088
	15717329088 [label=AccumulateGrad]
	15730748496 -> 15730748400
	15717607664 [label="layers.0.weight
 (320, 10)" fillcolor=lightblue]
	15717607664 -> 15730748496
	15730748496 [label=AccumulateGrad]
	15730748448 -> 15730748400
	15717607744 [label="layers.0.bias
 (320)" fillcolor=lightblue]
	15717607744 -> 15730748448
	15730748448 [label=AccumulateGrad]
	15730748352 -> 15730748208
	15730748352 [label=MulBackward0]
	15730748400 -> 15730748352
	15730748160 -> 15730748064
	15717607904 [label="layers.3.weight
 (160, 320)" fillcolor=lightblue]
	15717607904 -> 15730748160
	15730748160 [label=AccumulateGrad]
	15730748112 -> 15730748064
	15717607984 [label="layers.3.bias
 (160)" fillcolor=lightblue]
	15717607984 -> 15730748112
	15730748112 [label=AccumulateGrad]
	15730748016 -> 15730747872
	15730748016 [label=MulBackward0]
	15730748064 -> 15730748016
	15730747824 -> 15730747728
	15717607824 [label="layers.6.weight
 (320, 160)" fillcolor=lightblue]
	15717607824 -> 15730747824
	15730747824 [label=AccumulateGrad]
	15730747776 -> 15730747728
	15717608064 [label="layers.6.bias
 (320)" fillcolor=lightblue]
	15717608064 -> 15730747776
	15730747776 [label=AccumulateGrad]
	15730747680 -> 15730747536
	15730747680 [label=MulBackward0]
	15730747728 -> 15730747680
	15730747488 -> 15730747392
	15717608144 [label="layers.9.weight
 (160, 320)" fillcolor=lightblue]
	15717608144 -> 15730747488
	15730747488 [label=AccumulateGrad]
	15730747440 -> 15730747392
	15717608224 [label="layers.9.bias
 (160)" fillcolor=lightblue]
	15717608224 -> 15730747440
	15730747440 [label=AccumulateGrad]
	15730747344 -> 15730747200
	15730747344 [label=MulBackward0]
	15730747392 -> 15730747344
	15730747152 -> 15730747056
	15717608304 [label="layers.12.weight
 (160, 160)" fillcolor=lightblue]
	15717608304 -> 15730747152
	15730747152 [label=AccumulateGrad]
	15730747104 -> 15730747056
	15717608384 [label="layers.12.bias
 (160)" fillcolor=lightblue]
	15717608384 -> 15730747104
	15730747104 [label=AccumulateGrad]
	15730747008 -> 15730746864
	15730747008 [label=MulBackward0]
	15730747056 -> 15730747008
	15730746768 -> 15730746624
	15717608464 [label="layers.15.weight
 (80, 160)" fillcolor=lightblue]
	15717608464 -> 15730746768
	15730746768 [label=AccumulateGrad]
	15730746720 -> 15730746624
	15717608544 [label="layers.15.bias
 (80)" fillcolor=lightblue]
	15717608544 -> 15730746720
	15730746720 [label=AccumulateGrad]
	15730746576 -> 15717501248
	15730746576 [label=MulBackward0]
	15730746624 -> 15730746576
	15717499808 -> 14436685984
	15717608624 [label="layers.18.weight
 (80, 80)" fillcolor=lightblue]
	15717608624 -> 15717499808
	15717499808 [label=AccumulateGrad]
	15717499136 -> 14436685984
	15717608704 [label="layers.18.bias
 (80)" fillcolor=lightblue]
	15717608704 -> 15717499136
	15717499136 [label=AccumulateGrad]
	14436683200 -> 15717332304
	14436683200 [label=MulBackward0]
	14436685984 -> 14436683200
	15717328416 -> 15717334512
	15717608784 [label="layers.21.weight
 (1, 80)" fillcolor=lightblue]
	15717608784 -> 15717328416
	15717328416 [label=AccumulateGrad]
	15717323856 -> 15717334512
	15717608864 [label="layers.21.bias
 (1)" fillcolor=lightblue]
	15717608864 -> 15717323856
	15717323856 [label=AccumulateGrad]
	15717334512 -> 15717610784
}
