digraph {
	graph [size="18.3,18.3"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	16062636400 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	16118564608 [label=LinearBackward0]
	16062336928 -> 16118564608
	16062336928 [label=WhereBackward0]
	16119782064 -> 16062336928
	16119782064 [label=LinearBackward0]
	16119782208 -> 16119782064
	16119782208 [label=WhereBackward0]
	16119782400 -> 16119782208
	16119782400 [label=LinearBackward0]
	16119782544 -> 16119782400
	16119782544 [label=WhereBackward0]
	16119782736 -> 16119782544
	16119782736 [label=LinearBackward0]
	16119782880 -> 16119782736
	16119782880 [label=WhereBackward0]
	16119783072 -> 16119782880
	16119783072 [label=LinearBackward0]
	16119783216 -> 16119783072
	16119783216 [label=WhereBackward0]
	16119783408 -> 16119783216
	16119783408 [label=LinearBackward0]
	16119783552 -> 16119783408
	16119783552 [label=WhereBackward0]
	16119783744 -> 16119783552
	16119783744 [label=LinearBackward0]
	16119783888 -> 16119783744
	16119783888 [label=WhereBackward0]
	16119784080 -> 16119783888
	16119784080 [label=LinearBackward0]
	16119784224 -> 16119784080
	16119784224 [label=ToCopyBackward0]
	16119784416 -> 16119784224
	16062636640 [label="
 (1, 10)" fillcolor=lightblue]
	16062636640 -> 16119784416
	16119784416 [label=AccumulateGrad]
	16119784176 -> 16119784080
	16062638080 [label="layers.0.weight
 (320, 10)" fillcolor=lightblue]
	16062638080 -> 16119784176
	16119784176 [label=AccumulateGrad]
	16119784128 -> 16119784080
	16062638160 [label="layers.0.bias
 (320)" fillcolor=lightblue]
	16062638160 -> 16119784128
	16119784128 [label=AccumulateGrad]
	16119784032 -> 16119783888
	16119784032 [label=MulBackward0]
	16119784080 -> 16119784032
	16119783840 -> 16119783744
	16062638320 [label="layers.3.weight
 (160, 320)" fillcolor=lightblue]
	16062638320 -> 16119783840
	16119783840 [label=AccumulateGrad]
	16119783792 -> 16119783744
	16062638400 [label="layers.3.bias
 (160)" fillcolor=lightblue]
	16062638400 -> 16119783792
	16119783792 [label=AccumulateGrad]
	16119783696 -> 16119783552
	16119783696 [label=MulBackward0]
	16119783744 -> 16119783696
	16119783504 -> 16119783408
	16062638240 [label="layers.6.weight
 (320, 160)" fillcolor=lightblue]
	16062638240 -> 16119783504
	16119783504 [label=AccumulateGrad]
	16119783456 -> 16119783408
	16062638480 [label="layers.6.bias
 (320)" fillcolor=lightblue]
	16062638480 -> 16119783456
	16119783456 [label=AccumulateGrad]
	16119783360 -> 16119783216
	16119783360 [label=MulBackward0]
	16119783408 -> 16119783360
	16119783168 -> 16119783072
	16062638560 [label="layers.9.weight
 (160, 320)" fillcolor=lightblue]
	16062638560 -> 16119783168
	16119783168 [label=AccumulateGrad]
	16119783120 -> 16119783072
	16062638640 [label="layers.9.bias
 (160)" fillcolor=lightblue]
	16062638640 -> 16119783120
	16119783120 [label=AccumulateGrad]
	16119783024 -> 16119782880
	16119783024 [label=MulBackward0]
	16119783072 -> 16119783024
	16119782832 -> 16119782736
	16062638720 [label="layers.12.weight
 (160, 160)" fillcolor=lightblue]
	16062638720 -> 16119782832
	16119782832 [label=AccumulateGrad]
	16119782784 -> 16119782736
	16062638800 [label="layers.12.bias
 (160)" fillcolor=lightblue]
	16062638800 -> 16119782784
	16119782784 [label=AccumulateGrad]
	16119782688 -> 16119782544
	16119782688 [label=MulBackward0]
	16119782736 -> 16119782688
	16119782496 -> 16119782400
	16062638880 [label="layers.15.weight
 (80, 160)" fillcolor=lightblue]
	16062638880 -> 16119782496
	16119782496 [label=AccumulateGrad]
	16119782448 -> 16119782400
	16062638960 [label="layers.15.bias
 (80)" fillcolor=lightblue]
	16062638960 -> 16119782448
	16119782448 [label=AccumulateGrad]
	16119782352 -> 16119782208
	16119782352 [label=MulBackward0]
	16119782400 -> 16119782352
	16119782016 -> 16119782064
	16062639040 [label="layers.18.weight
 (80, 80)" fillcolor=lightblue]
	16062639040 -> 16119782016
	16119782016 [label=AccumulateGrad]
	16119782112 -> 16119782064
	16062639120 [label="layers.18.bias
 (80)" fillcolor=lightblue]
	16062639120 -> 16119782112
	16119782112 [label=AccumulateGrad]
	16119781872 -> 16062336928
	16119781872 [label=MulBackward0]
	16119782064 -> 16119781872
	16062340480 -> 16118564608
	16062558720 [label="layers.21.weight
 (1, 80)" fillcolor=lightblue]
	16062558720 -> 16062340480
	16062340480 [label=AccumulateGrad]
	16062530320 -> 16118564608
	16062639200 [label="layers.21.bias
 (1)" fillcolor=lightblue]
	16062639200 -> 16062530320
	16062530320 [label=AccumulateGrad]
	16118564608 -> 16062636400
}
