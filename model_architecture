digraph {
	graph [size="18.3,18.3"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	16229245536 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	4352439632 [label=LinearBackward0]
	16229406736 -> 4352439632
	16229406736 [label=WhereBackward0]
	16229730624 -> 16229406736
	16229730624 [label=LinearBackward0]
	16229687856 -> 16229730624
	16229687856 [label=WhereBackward0]
	16231052432 -> 16229687856
	16231052432 [label=LinearBackward0]
	16231052480 -> 16231052432
	16231052480 [label=WhereBackward0]
	16231052768 -> 16231052480
	16231052768 [label=LinearBackward0]
	16231052912 -> 16231052768
	16231052912 [label=WhereBackward0]
	16231053104 -> 16231052912
	16231053104 [label=LinearBackward0]
	16231053248 -> 16231053104
	16231053248 [label=WhereBackward0]
	16231053440 -> 16231053248
	16231053440 [label=LinearBackward0]
	16231053584 -> 16231053440
	16231053584 [label=WhereBackward0]
	16231053776 -> 16231053584
	16231053776 [label=LinearBackward0]
	16231053920 -> 16231053776
	16231053920 [label=WhereBackward0]
	16231054112 -> 16231053920
	16231054112 [label=LinearBackward0]
	16231054256 -> 16231054112
	16231054256 [label=ToCopyBackward0]
	16231054448 -> 16231054256
	16229748640 [label="
 (1, 10)" fillcolor=lightblue]
	16229748640 -> 16231054448
	16231054448 [label=AccumulateGrad]
	16231054208 -> 16231054112
	16229756400 [label="layers.0.weight
 (320, 10)" fillcolor=lightblue]
	16229756400 -> 16231054208
	16231054208 [label=AccumulateGrad]
	16231054160 -> 16231054112
	16229755920 [label="layers.0.bias
 (320)" fillcolor=lightblue]
	16229755920 -> 16231054160
	16231054160 [label=AccumulateGrad]
	16231054064 -> 16231053920
	16231054064 [label=MulBackward0]
	16231054112 -> 16231054064
	16231053872 -> 16231053776
	13498140224 [label="layers.3.weight
 (160, 320)" fillcolor=lightblue]
	13498140224 -> 16231053872
	16231053872 [label=AccumulateGrad]
	16231053824 -> 16231053776
	16229756560 [label="layers.3.bias
 (160)" fillcolor=lightblue]
	16229756560 -> 16231053824
	16231053824 [label=AccumulateGrad]
	16231053728 -> 16231053584
	16231053728 [label=MulBackward0]
	16231053776 -> 16231053728
	16231053536 -> 16231053440
	16229756640 [label="layers.6.weight
 (320, 160)" fillcolor=lightblue]
	16229756640 -> 16231053536
	16231053536 [label=AccumulateGrad]
	16231053488 -> 16231053440
	16229756480 [label="layers.6.bias
 (320)" fillcolor=lightblue]
	16229756480 -> 16231053488
	16231053488 [label=AccumulateGrad]
	16231053392 -> 16231053248
	16231053392 [label=MulBackward0]
	16231053440 -> 16231053392
	16231053200 -> 16231053104
	16229756720 [label="layers.9.weight
 (160, 320)" fillcolor=lightblue]
	16229756720 -> 16231053200
	16231053200 [label=AccumulateGrad]
	16231053152 -> 16231053104
	16229756800 [label="layers.9.bias
 (160)" fillcolor=lightblue]
	16229756800 -> 16231053152
	16231053152 [label=AccumulateGrad]
	16231053056 -> 16231052912
	16231053056 [label=MulBackward0]
	16231053104 -> 16231053056
	16231052864 -> 16231052768
	16229756880 [label="layers.12.weight
 (160, 160)" fillcolor=lightblue]
	16229756880 -> 16231052864
	16231052864 [label=AccumulateGrad]
	16231052816 -> 16231052768
	16229756960 [label="layers.12.bias
 (160)" fillcolor=lightblue]
	16229756960 -> 16231052816
	16231052816 [label=AccumulateGrad]
	16231052720 -> 16231052480
	16231052720 [label=MulBackward0]
	16231052768 -> 16231052720
	16231047920 -> 16231052432
	16229757040 [label="layers.15.weight
 (80, 160)" fillcolor=lightblue]
	16229757040 -> 16231047920
	16231047920 [label=AccumulateGrad]
	16231052576 -> 16231052432
	16229757120 [label="layers.15.bias
 (80)" fillcolor=lightblue]
	16229757120 -> 16231052576
	16231052576 [label=AccumulateGrad]
	16231052384 -> 16229687856
	16231052384 [label=MulBackward0]
	16231052432 -> 16231052384
	16231052288 -> 16229730624
	16229757200 [label="layers.18.weight
 (80, 80)" fillcolor=lightblue]
	16229757200 -> 16231052288
	16231052288 [label=AccumulateGrad]
	16231049984 -> 16229730624
	16229757280 [label="layers.18.bias
 (80)" fillcolor=lightblue]
	16229757280 -> 16231049984
	16231049984 [label=AccumulateGrad]
	16229689296 -> 16229406736
	16229689296 [label=MulBackward0]
	16229730624 -> 16229689296
	16229331440 -> 4352439632
	16229706848 [label="layers.21.weight
 (1, 80)" fillcolor=lightblue]
	16229706848 -> 16229331440
	16229331440 [label=AccumulateGrad]
	16229573696 -> 4352439632
	16229640832 [label="layers.21.bias
 (1)" fillcolor=lightblue]
	16229640832 -> 16229573696
	16229573696 [label=AccumulateGrad]
	4352439632 -> 16229245536
}
