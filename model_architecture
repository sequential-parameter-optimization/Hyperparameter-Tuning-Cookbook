digraph {
	graph [size="40.949999999999996,40.949999999999996"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	13417739312 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	13617154656 -> 13796218656 [dir=none]
	13796218656 [label="input
 (1, 2)" fillcolor=orange]
	13617154656 -> 13796216336 [dir=none]
	13796216336 [label="weight
 (1, 2)" fillcolor=orange]
	13617154656 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13617160080 -> 13617154656
	13617160080 -> 13796218736 [dir=none]
	13796218736 [label="other
 (1, 2)" fillcolor=orange]
	13617160080 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	13617350880 -> 13617160080
	13617350880 -> 13796218496 [dir=none]
	13796218496 [label="input
 (1, 2)" fillcolor=orange]
	13617350880 -> 13796216176 [dir=none]
	13796216176 [label="weight
 (2, 2)" fillcolor=orange]
	13617350880 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13588149680 -> 13617350880
	13588149680 -> 13796218576 [dir=none]
	13796218576 [label="other
 (1, 2)" fillcolor=orange]
	13588149680 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	13617372352 -> 13588149680
	13617372352 -> 13796218336 [dir=none]
	13796218336 [label="input
 (1, 2)" fillcolor=orange]
	13617372352 -> 13796216016 [dir=none]
	13796216016 [label="weight
 (2, 2)" fillcolor=orange]
	13617372352 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13617372544 -> 13617372352
	13617372544 -> 13796218416 [dir=none]
	13796218416 [label="other
 (1, 2)" fillcolor=orange]
	13617372544 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	13617372688 -> 13617372544
	13617372688 -> 13796218176 [dir=none]
	13796218176 [label="input
 (1, 2)" fillcolor=orange]
	13617372688 -> 13796215856 [dir=none]
	13796215856 [label="weight
 (2, 2)" fillcolor=orange]
	13617372688 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13617372976 -> 13617372688
	13617372976 -> 13796218256 [dir=none]
	13796218256 [label="other
 (1, 2)" fillcolor=orange]
	13617372976 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	13617372928 -> 13617372976
	13617372928 -> 13796218016 [dir=none]
	13796218016 [label="input
 (1, 4)" fillcolor=orange]
	13617372928 -> 13796215696 [dir=none]
	13796215696 [label="weight
 (2, 4)" fillcolor=orange]
	13617372928 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13617373264 -> 13617372928
	13617373264 -> 13796218096 [dir=none]
	13796218096 [label="other
 (1, 4)" fillcolor=orange]
	13617373264 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	13617373216 -> 13617373264
	13617373216 -> 13796216816 [dir=none]
	13796216816 [label="input
 (1, 4)" fillcolor=orange]
	13617373216 -> 13796215536 [dir=none]
	13796215536 [label="weight
 (4, 4)" fillcolor=orange]
	13617373216 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13617373552 -> 13617373216
	13617373552 -> 13796216656 [dir=none]
	13796216656 [label="other
 (1, 4)" fillcolor=orange]
	13617373552 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	13617373504 -> 13617373552
	13617373504 -> 13796213776 [dir=none]
	13796213776 [label="input
 (1, 4)" fillcolor=orange]
	13617373504 -> 13796215376 [dir=none]
	13796215376 [label="weight
 (4, 4)" fillcolor=orange]
	13617373504 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13617373840 -> 13617373504
	13617373840 -> 13796213616 [dir=none]
	13796213616 [label="other
 (1, 4)" fillcolor=orange]
	13617373840 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	13617373792 -> 13617373840
	13617373792 -> 13796217536 [dir=none]
	13796217536 [label="input
 (1, 4)" fillcolor=orange]
	13617373792 -> 13796215216 [dir=none]
	13796215216 [label="weight
 (4, 4)" fillcolor=orange]
	13617373792 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13617374128 -> 13617373792
	13617374128 -> 13796217696 [dir=none]
	13796217696 [label="other
 (1, 4)" fillcolor=orange]
	13617374128 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	13617374080 -> 13617374128
	13617374080 -> 13796212896 [dir=none]
	13796212896 [label="input
 (1, 8)" fillcolor=orange]
	13617374080 -> 13796215056 [dir=none]
	13796215056 [label="weight
 (4, 8)" fillcolor=orange]
	13617374080 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13617374416 -> 13617374080
	13617374416 -> 13796212816 [dir=none]
	13796212816 [label="other
 (1, 8)" fillcolor=orange]
	13617374416 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	13617374368 -> 13617374416
	13617374368 -> 13796213216 [dir=none]
	13796213216 [label="input
 (1, 8)" fillcolor=orange]
	13617374368 -> 13796214896 [dir=none]
	13796214896 [label="weight
 (8, 8)" fillcolor=orange]
	13617374368 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13617374704 -> 13617374368
	13617374704 -> 13796212976 [dir=none]
	13796212976 [label="other
 (1, 8)" fillcolor=orange]
	13617374704 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	13617374656 -> 13617374704
	13617374656 -> 13796213056 [dir=none]
	13796213056 [label="input
 (1, 8)" fillcolor=orange]
	13617374656 -> 13796214736 [dir=none]
	13796214736 [label="weight
 (8, 8)" fillcolor=orange]
	13617374656 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13617374992 -> 13617374656
	13617374992 -> 13796213136 [dir=none]
	13796213136 [label="other
 (1, 8)" fillcolor=orange]
	13617374992 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	13617374944 -> 13617374992
	13617374944 -> 13796213376 [dir=none]
	13796213376 [label="input
 (1, 16)" fillcolor=orange]
	13617374944 -> 13796214576 [dir=none]
	13796214576 [label="weight
 (8, 16)" fillcolor=orange]
	13617374944 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13617375280 -> 13617374944
	13617375280 -> 13796213296 [dir=none]
	13796213296 [label="other
 (1, 16)" fillcolor=orange]
	13617375280 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	13617375232 -> 13617375280
	13617375232 -> 13796217616 [dir=none]
	13796217616 [label="input
 (1, 16)" fillcolor=orange]
	13617375232 -> 13796214496 [dir=none]
	13796214496 [label="weight
 (16, 16)" fillcolor=orange]
	13617375232 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13617375520 -> 13617375232
	13617375520 -> 13796213456 [dir=none]
	13796213456 [label="other
 (1, 16)" fillcolor=orange]
	13617375520 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	13617375568 -> 13617375520
	13617375568 -> 13796216976 [dir=none]
	13796216976 [label="input
 (1, 32)" fillcolor=orange]
	13617375568 -> 13567717088 [dir=none]
	13567717088 [label="weight
 (16, 32)" fillcolor=orange]
	13617375568 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13617375808 -> 13617375568
	13617375808 -> 13796217936 [dir=none]
	13796217936 [label="other
 (1, 32)" fillcolor=orange]
	13617375808 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	13617375856 -> 13617375808
	13617375856 -> 13417738592 [dir=none]
	13417738592 [label="input
 (1, 10)" fillcolor=orange]
	13617375856 -> 13796214336 [dir=none]
	13796214336 [label="weight
 (32, 10)" fillcolor=orange]
	13617375856 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13617376096 -> 13617375856
	13617376096 [label=ToCopyBackward0]
	13617376144 -> 13617376096
	13617124432 [label="
 (1, 10)" fillcolor=lightblue]
	13617124432 -> 13617376144
	13617376144 [label=AccumulateGrad]
	13617376192 -> 13617375856
	13796214336 [label="layers.0.weight
 (32, 10)" fillcolor=lightblue]
	13796214336 -> 13617376192
	13617376192 [label=AccumulateGrad]
	13617375952 -> 13617375856
	13796214416 [label="layers.0.bias
 (32)" fillcolor=lightblue]
	13796214416 -> 13617375952
	13617375952 [label=AccumulateGrad]
	13617375904 -> 13617375568
	13567717088 [label="layers.3.weight
 (16, 32)" fillcolor=lightblue]
	13567717088 -> 13617375904
	13617375904 [label=AccumulateGrad]
	13617375664 -> 13617375568
	13796213536 [label="layers.3.bias
 (16)" fillcolor=lightblue]
	13796213536 -> 13617375664
	13617375664 [label=AccumulateGrad]
	13617375616 -> 13617375232
	13796214496 [label="layers.6.weight
 (16, 16)" fillcolor=lightblue]
	13796214496 -> 13617375616
	13617375616 [label=AccumulateGrad]
	13617375376 -> 13617375232
	13796213856 [label="layers.6.bias
 (16)" fillcolor=lightblue]
	13796213856 -> 13617375376
	13617375376 [label=AccumulateGrad]
	13617375328 -> 13617374944
	13796214576 [label="layers.9.weight
 (8, 16)" fillcolor=lightblue]
	13796214576 -> 13617375328
	13617375328 [label=AccumulateGrad]
	13617375088 -> 13617374944
	13796214656 [label="layers.9.bias
 (8)" fillcolor=lightblue]
	13796214656 -> 13617375088
	13617375088 [label=AccumulateGrad]
	13617375040 -> 13617374656
	13796214736 [label="layers.12.weight
 (8, 8)" fillcolor=lightblue]
	13796214736 -> 13617375040
	13617375040 [label=AccumulateGrad]
	13617374800 -> 13617374656
	13796214816 [label="layers.12.bias
 (8)" fillcolor=lightblue]
	13796214816 -> 13617374800
	13617374800 [label=AccumulateGrad]
	13617374752 -> 13617374368
	13796214896 [label="layers.15.weight
 (8, 8)" fillcolor=lightblue]
	13796214896 -> 13617374752
	13617374752 [label=AccumulateGrad]
	13617374512 -> 13617374368
	13796214976 [label="layers.15.bias
 (8)" fillcolor=lightblue]
	13796214976 -> 13617374512
	13617374512 [label=AccumulateGrad]
	13617374464 -> 13617374080
	13796215056 [label="layers.18.weight
 (4, 8)" fillcolor=lightblue]
	13796215056 -> 13617374464
	13617374464 [label=AccumulateGrad]
	13617374224 -> 13617374080
	13796215136 [label="layers.18.bias
 (4)" fillcolor=lightblue]
	13796215136 -> 13617374224
	13617374224 [label=AccumulateGrad]
	13617374176 -> 13617373792
	13796215216 [label="layers.21.weight
 (4, 4)" fillcolor=lightblue]
	13796215216 -> 13617374176
	13617374176 [label=AccumulateGrad]
	13617373936 -> 13617373792
	13796215296 [label="layers.21.bias
 (4)" fillcolor=lightblue]
	13796215296 -> 13617373936
	13617373936 [label=AccumulateGrad]
	13617373888 -> 13617373504
	13796215376 [label="layers.24.weight
 (4, 4)" fillcolor=lightblue]
	13796215376 -> 13617373888
	13617373888 [label=AccumulateGrad]
	13617373648 -> 13617373504
	13796215456 [label="layers.24.bias
 (4)" fillcolor=lightblue]
	13796215456 -> 13617373648
	13617373648 [label=AccumulateGrad]
	13617373600 -> 13617373216
	13796215536 [label="layers.27.weight
 (4, 4)" fillcolor=lightblue]
	13796215536 -> 13617373600
	13617373600 [label=AccumulateGrad]
	13617373360 -> 13617373216
	13796215616 [label="layers.27.bias
 (4)" fillcolor=lightblue]
	13796215616 -> 13617373360
	13617373360 [label=AccumulateGrad]
	13617373312 -> 13617372928
	13796215696 [label="layers.30.weight
 (2, 4)" fillcolor=lightblue]
	13796215696 -> 13617373312
	13617373312 [label=AccumulateGrad]
	13617373072 -> 13617372928
	13796215776 [label="layers.30.bias
 (2)" fillcolor=lightblue]
	13796215776 -> 13617373072
	13617373072 [label=AccumulateGrad]
	13617373024 -> 13617372688
	13796215856 [label="layers.33.weight
 (2, 2)" fillcolor=lightblue]
	13796215856 -> 13617373024
	13617373024 [label=AccumulateGrad]
	13617372784 -> 13617372688
	13796215936 [label="layers.33.bias
 (2)" fillcolor=lightblue]
	13796215936 -> 13617372784
	13617372784 [label=AccumulateGrad]
	13617372736 -> 13617372352
	13796216016 [label="layers.36.weight
 (2, 2)" fillcolor=lightblue]
	13796216016 -> 13617372736
	13617372736 [label=AccumulateGrad]
	13617372448 -> 13617372352
	13796216096 [label="layers.36.bias
 (2)" fillcolor=lightblue]
	13796216096 -> 13617372448
	13617372448 [label=AccumulateGrad]
	13617372400 -> 13617350880
	13796216176 [label="layers.39.weight
 (2, 2)" fillcolor=lightblue]
	13796216176 -> 13617372400
	13617372400 [label=AccumulateGrad]
	13617372304 -> 13617350880
	13796216256 [label="layers.39.bias
 (2)" fillcolor=lightblue]
	13796216256 -> 13617372304
	13617372304 [label=AccumulateGrad]
	13596283312 -> 13617154656
	13796216336 [label="layers.42.weight
 (1, 2)" fillcolor=lightblue]
	13796216336 -> 13596283312
	13596283312 [label=AccumulateGrad]
	13617247712 -> 13617154656
	13796216416 [label="layers.42.bias
 (1)" fillcolor=lightblue]
	13796216416 -> 13617247712
	13617247712 [label=AccumulateGrad]
	13617154656 -> 13417739312
}
