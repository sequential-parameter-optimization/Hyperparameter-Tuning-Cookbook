digraph {
	graph [size="25.65,25.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	13281790384 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	13401595120 -> 13281790304 [dir=none]
	13281790304 [label="input
 (1, 2)" fillcolor=orange]
	13401595120 -> 13498489648 [dir=none]
	13498489648 [label="weight
 (1, 2)" fillcolor=orange]
	13401595120 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13401370928 -> 13401595120
	13401370928 -> 13281790224 [dir=none]
	13281790224 [label="other
 (1, 2)" fillcolor=orange]
	13401370928 -> 13281790144 [dir=none]
	13281790144 [label="self
 (1, 2)" fillcolor=orange]
	13401370928 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	13401305440 -> 13401370928
	13401305440 -> 13281790064 [dir=none]
	13281790064 [label="input
 (1, 2)" fillcolor=orange]
	13401305440 -> 13401455936 [dir=none]
	13401455936 [label="weight
 (2, 2)" fillcolor=orange]
	13401305440 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13281719152 -> 13401305440
	13281719152 -> 13281789984 [dir=none]
	13281789984 [label="other
 (1, 2)" fillcolor=orange]
	13281719152 -> 13281789904 [dir=none]
	13281789904 [label="self
 (1, 2)" fillcolor=orange]
	13281719152 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	13281719056 -> 13281719152
	13281719056 -> 13281789824 [dir=none]
	13281789824 [label="input
 (1, 2)" fillcolor=orange]
	13281719056 -> 13498412048 [dir=none]
	13498412048 [label="weight
 (2, 2)" fillcolor=orange]
	13281719056 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13281719536 -> 13281719056
	13281719536 -> 13281789744 [dir=none]
	13281789744 [label="other
 (1, 2)" fillcolor=orange]
	13281719536 -> 13281789664 [dir=none]
	13281789664 [label="self
 (1, 2)" fillcolor=orange]
	13281719536 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	13281719392 -> 13281719536
	13281719392 -> 13281789584 [dir=none]
	13281789584 [label="input
 (1, 4)" fillcolor=orange]
	13281719392 -> 13498489488 [dir=none]
	13498489488 [label="weight
 (2, 4)" fillcolor=orange]
	13281719392 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13281719872 -> 13281719392
	13281719872 -> 13281789504 [dir=none]
	13281789504 [label="other
 (1, 4)" fillcolor=orange]
	13281719872 -> 13281789424 [dir=none]
	13281789424 [label="self
 (1, 4)" fillcolor=orange]
	13281719872 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	13281719728 -> 13281719872
	13281719728 -> 13281788464 [dir=none]
	13281788464 [label="input
 (1, 4)" fillcolor=orange]
	13281719728 -> 13498489168 [dir=none]
	13498489168 [label="weight
 (4, 4)" fillcolor=orange]
	13281719728 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13281720208 -> 13281719728
	13281720208 -> 13281789024 [dir=none]
	13281789024 [label="other
 (1, 4)" fillcolor=orange]
	13281720208 -> 13498416208 [dir=none]
	13498416208 [label="self
 (1, 4)" fillcolor=orange]
	13281720208 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	13281720064 -> 13281720208
	13281720064 -> 13498413968 [dir=none]
	13498413968 [label="input
 (1, 8)" fillcolor=orange]
	13281720064 -> 13498489248 [dir=none]
	13498489248 [label="weight
 (4, 8)" fillcolor=orange]
	13281720064 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13281720544 -> 13281720064
	13281720544 -> 13498412528 [dir=none]
	13498412528 [label="other
 (1, 8)" fillcolor=orange]
	13281720544 -> 13498404288 [dir=none]
	13498404288 [label="self
 (1, 8)" fillcolor=orange]
	13281720544 [label="MulBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	13281720400 -> 13281720544
	13281720400 -> 13498413488 [dir=none]
	13498413488 [label="input
 (1, 10)" fillcolor=orange]
	13281720400 -> 13498488128 [dir=none]
	13498488128 [label="weight
 (8, 10)" fillcolor=orange]
	13281720400 [label="LinearBackward0
----------------------
input : [saved tensor]
weight: [saved tensor]"]
	13281720880 -> 13281720400
	13281720880 [label=ToCopyBackward0]
	13281720736 -> 13281720880
	13276906992 [label="
 (1, 10)" fillcolor=lightblue]
	13276906992 -> 13281720736
	13281720736 [label=AccumulateGrad]
	13281720784 -> 13281720400
	13498488128 [label="layers.0.weight
 (8, 10)" fillcolor=lightblue]
	13498488128 -> 13281720784
	13281720784 [label=AccumulateGrad]
	13281720832 -> 13281720400
	13498489088 [label="layers.0.bias
 (8)" fillcolor=lightblue]
	13498489088 -> 13281720832
	13281720832 [label=AccumulateGrad]
	13281720688 -> 13281720544
	13281720688 -> 13281797504 [dir=none]
	13281797504 [label="result
 (1, 8)" fillcolor=orange]
	13281720688 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	13281720400 -> 13281720688
	13281720448 -> 13281720064
	13498489248 [label="layers.3.weight
 (4, 8)" fillcolor=lightblue]
	13498489248 -> 13281720448
	13281720448 [label=AccumulateGrad]
	13281720496 -> 13281720064
	13498489328 [label="layers.3.bias
 (4)" fillcolor=lightblue]
	13498489328 -> 13281720496
	13281720496 [label=AccumulateGrad]
	13281720352 -> 13281720208
	13281720352 -> 13281798304 [dir=none]
	13281798304 [label="result
 (1, 4)" fillcolor=orange]
	13281720352 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	13281720064 -> 13281720352
	13281720112 -> 13281719728
	13498489168 [label="layers.6.weight
 (4, 4)" fillcolor=lightblue]
	13498489168 -> 13281720112
	13281720112 [label=AccumulateGrad]
	13281720160 -> 13281719728
	13498489408 [label="layers.6.bias
 (4)" fillcolor=lightblue]
	13498489408 -> 13281720160
	13281720160 [label=AccumulateGrad]
	13281720016 -> 13281719872
	13281720016 -> 13281799104 [dir=none]
	13281799104 [label="result
 (1, 4)" fillcolor=orange]
	13281720016 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	13281719728 -> 13281720016
	13281719776 -> 13281719392
	13498489488 [label="layers.9.weight
 (2, 4)" fillcolor=lightblue]
	13498489488 -> 13281719776
	13281719776 [label=AccumulateGrad]
	13281719824 -> 13281719392
	13498489568 [label="layers.9.bias
 (2)" fillcolor=lightblue]
	13498489568 -> 13281719824
	13281719824 [label=AccumulateGrad]
	13281719680 -> 13281719536
	13281719680 -> 13281799904 [dir=none]
	13281799904 [label="result
 (1, 2)" fillcolor=orange]
	13281719680 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	13281719392 -> 13281719680
	13281719440 -> 13281719056
	13498412048 [label="layers.12.weight
 (2, 2)" fillcolor=lightblue]
	13498412048 -> 13281719440
	13281719440 [label=AccumulateGrad]
	13281719488 -> 13281719056
	13498344352 [label="layers.12.bias
 (2)" fillcolor=lightblue]
	13498344352 -> 13281719488
	13281719488 [label=AccumulateGrad]
	13281719200 -> 13281719152
	13281719200 -> 13281800704 [dir=none]
	13281800704 [label="result
 (1, 2)" fillcolor=orange]
	13281719200 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	13281719056 -> 13281719200
	13281718912 -> 13401305440
	13401455936 [label="layers.15.weight
 (2, 2)" fillcolor=lightblue]
	13401455936 -> 13281718912
	13281718912 [label=AccumulateGrad]
	13281719104 -> 13401305440
	13401439232 [label="layers.15.bias
 (2)" fillcolor=lightblue]
	13401439232 -> 13281719104
	13281719104 [label=AccumulateGrad]
	13281719008 -> 13401370928
	13281719008 -> 13281801504 [dir=none]
	13281801504 [label="result
 (1, 2)" fillcolor=orange]
	13281719008 [label="SigmoidBackward0
----------------------
result: [saved tensor]"]
	13401305440 -> 13281719008
	13401597808 -> 13401595120
	13498489648 [label="layers.18.weight
 (1, 2)" fillcolor=lightblue]
	13498489648 -> 13401597808
	13401597808 [label=AccumulateGrad]
	13401477024 -> 13401595120
	13498488528 [label="layers.18.bias
 (1)" fillcolor=lightblue]
	13498488528 -> 13401477024
	13401477024 [label=AccumulateGrad]
	13401595120 -> 13281790384
}
