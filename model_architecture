digraph {
	graph [size="18.3,18.3"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	16271063424 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	16270956560 [label=LinearBackward0]
	16270843408 -> 16270956560
	16270843408 [label=WhereBackward0]
	15485101360 -> 16270843408
	15485101360 [label=LinearBackward0]
	16270804832 -> 15485101360
	16270804832 [label=WhereBackward0]
	16272993456 -> 16270804832
	16272993456 [label=LinearBackward0]
	16272993696 -> 16272993456
	16272993696 [label=WhereBackward0]
	16272993984 -> 16272993696
	16272993984 [label=LinearBackward0]
	16272994128 -> 16272993984
	16272994128 [label=WhereBackward0]
	16272994320 -> 16272994128
	16272994320 [label=LinearBackward0]
	16272994464 -> 16272994320
	16272994464 [label=WhereBackward0]
	16272994656 -> 16272994464
	16272994656 [label=LinearBackward0]
	16272994800 -> 16272994656
	16272994800 [label=WhereBackward0]
	16272994992 -> 16272994800
	16272994992 [label=LinearBackward0]
	16272995136 -> 16272994992
	16272995136 [label=WhereBackward0]
	16272995328 -> 16272995136
	16272995328 [label=LinearBackward0]
	16272995472 -> 16272995328
	16272995472 [label=ToCopyBackward0]
	16272995664 -> 16272995472
	16271021136 [label="
 (1, 10)" fillcolor=lightblue]
	16271021136 -> 16272995664
	16272995664 [label=AccumulateGrad]
	16272995424 -> 16272995328
	16271026016 [label="layers.0.weight
 (320, 10)" fillcolor=lightblue]
	16271026016 -> 16272995424
	16272995424 [label=AccumulateGrad]
	16272995376 -> 16272995328
	16271175552 [label="layers.0.bias
 (320)" fillcolor=lightblue]
	16271175552 -> 16272995376
	16272995376 [label=AccumulateGrad]
	16272995280 -> 16272995136
	16272995280 [label=MulBackward0]
	16272995328 -> 16272995280
	16272995088 -> 16272994992
	16271175632 [label="layers.3.weight
 (160, 320)" fillcolor=lightblue]
	16271175632 -> 16272995088
	16272995088 [label=AccumulateGrad]
	16272995040 -> 16272994992
	16271175712 [label="layers.3.bias
 (160)" fillcolor=lightblue]
	16271175712 -> 16272995040
	16272995040 [label=AccumulateGrad]
	16272994944 -> 16272994800
	16272994944 [label=MulBackward0]
	16272994992 -> 16272994944
	16272994752 -> 16272994656
	16271175072 [label="layers.6.weight
 (320, 160)" fillcolor=lightblue]
	16271175072 -> 16272994752
	16272994752 [label=AccumulateGrad]
	16272994704 -> 16272994656
	16271175792 [label="layers.6.bias
 (320)" fillcolor=lightblue]
	16271175792 -> 16272994704
	16272994704 [label=AccumulateGrad]
	16272994608 -> 16272994464
	16272994608 [label=MulBackward0]
	16272994656 -> 16272994608
	16272994416 -> 16272994320
	16271175872 [label="layers.9.weight
 (160, 320)" fillcolor=lightblue]
	16271175872 -> 16272994416
	16272994416 [label=AccumulateGrad]
	16272994368 -> 16272994320
	16271175952 [label="layers.9.bias
 (160)" fillcolor=lightblue]
	16271175952 -> 16272994368
	16272994368 [label=AccumulateGrad]
	16272994272 -> 16272994128
	16272994272 [label=MulBackward0]
	16272994320 -> 16272994272
	16272994080 -> 16272993984
	16271176032 [label="layers.12.weight
 (160, 160)" fillcolor=lightblue]
	16271176032 -> 16272994080
	16272994080 [label=AccumulateGrad]
	16272994032 -> 16272993984
	16271176112 [label="layers.12.bias
 (160)" fillcolor=lightblue]
	16271176112 -> 16272994032
	16272994032 [label=AccumulateGrad]
	16272993936 -> 16272993696
	16272993936 [label=MulBackward0]
	16272993984 -> 16272993936
	16272993792 -> 16272993456
	16271176192 [label="layers.15.weight
 (80, 160)" fillcolor=lightblue]
	16271176192 -> 16272993792
	16272993792 [label=AccumulateGrad]
	16272993648 -> 16272993456
	16271176272 [label="layers.15.bias
 (80)" fillcolor=lightblue]
	16271176272 -> 16272993648
	16272993648 [label=AccumulateGrad]
	16272993552 -> 16270804832
	16272993552 [label=MulBackward0]
	16272993456 -> 16272993552
	16270818416 -> 15485101360
	16271176352 [label="layers.18.weight
 (80, 80)" fillcolor=lightblue]
	16271176352 -> 16270818416
	16270818416 [label=AccumulateGrad]
	16270812128 -> 15485101360
	16271176432 [label="layers.18.bias
 (80)" fillcolor=lightblue]
	16271176432 -> 16270812128
	16270812128 [label=AccumulateGrad]
	16271152880 -> 16270843408
	16271152880 [label=MulBackward0]
	15485101360 -> 16271152880
	16270846864 -> 16270956560
	16271028016 [label="layers.21.weight
 (1, 80)" fillcolor=lightblue]
	16271028016 -> 16270846864
	16270846864 [label=AccumulateGrad]
	16270964048 -> 16270956560
	16271030976 [label="layers.21.bias
 (1)" fillcolor=lightblue]
	16271030976 -> 16270964048
	16270964048 [label=AccumulateGrad]
	16270956560 -> 16271063424
}
