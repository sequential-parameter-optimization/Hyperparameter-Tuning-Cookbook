\contentsline {chapter}{Preface: Optimization and Hyperparameter Tuning}{3}{chapter*.2}%
\contentsline {section}{Book Structure}{4}{section*.3}%
\contentsline {section}{Software Used in this Book}{6}{section*.4}%
\contentsline {part}{\numberline {I}Spot as an Optimizer}{7}{part.1}%
\contentsline {chapter}{\numberline {1}Introduction to \texttt {spotPython}}{8}{chapter.1}%
\contentsline {section}{\numberline {1.1}Example: \texttt {Spot} and the Sphere Function}{8}{section.1.1}%
\contentsline {subsection}{\numberline {1.1.1}The Objective Function: Sphere}{9}{subsection.1.1.1}%
\contentsline {section}{\numberline {1.2}\texttt {Spot} Parameters: \texttt {fun\_evals}, \texttt {init\_size} and \texttt {show\_models}}{10}{section.1.2}%
\contentsline {section}{\numberline {1.3}Print the Results}{11}{section.1.3}%
\contentsline {section}{\numberline {1.4}Show the Progress}{12}{section.1.4}%
\contentsline {section}{\numberline {1.5}Visualizing the Optimization and Hyperparameter Tuning Process with TensorBoard}{12}{section.1.5}%
\contentsline {chapter}{\numberline {2}Multi-dimensional Functions}{16}{chapter.2}%
\contentsline {section}{\numberline {2.1}Example: \texttt {Spot} and the 3-dim Sphere Function}{16}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}The Objective Function: 3-dim Sphere}{16}{subsection.2.1.1}%
\contentsline {subsection}{\numberline {2.1.2}Results}{18}{subsection.2.1.2}%
\contentsline {subsection}{\numberline {2.1.3}A Contour Plot}{18}{subsection.2.1.3}%
\contentsline {subsection}{\numberline {2.1.4}TensorBoard}{20}{subsection.2.1.4}%
\contentsline {section}{\numberline {2.2}Conclusion}{20}{section.2.2}%
\contentsline {section}{\numberline {2.3}Exercises}{20}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}The Three Dimensional \texttt {fun\_cubed}}{21}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2}The Ten Dimensional \texttt {fun\_wing\_wt}}{21}{subsection.2.3.2}%
\contentsline {subsection}{\numberline {2.3.3}The Three Dimensional \texttt {fun\_runge}}{22}{subsection.2.3.3}%
\contentsline {subsection}{\numberline {2.3.4}The Three Dimensional \texttt {fun\_linear}}{22}{subsection.2.3.4}%
\contentsline {chapter}{\numberline {3}Isotropic and Anisotropic Kriging}{23}{chapter.3}%
\contentsline {section}{\numberline {3.1}Example: Isotropic \texttt {Spot} Surrogate and the 2-dim Sphere Function}{23}{section.3.1}%
\contentsline {subsection}{\numberline {3.1.1}The Objective Function: 2-dim Sphere}{23}{subsection.3.1.1}%
\contentsline {subsection}{\numberline {3.1.2}Results}{24}{subsection.3.1.2}%
\contentsline {section}{\numberline {3.2}Example With Anisotropic Kriging}{24}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Taking a Look at the \texttt {theta} Values}{26}{subsection.3.2.1}%
\contentsline {subsubsection}{\numberline {3.2.1.1}\texttt {theta} Values from the \texttt {spot} Model}{26}{subsubsection.3.2.1.1}%
\contentsline {subsubsection}{\numberline {3.2.1.2}TensorBoard}{27}{subsubsection.3.2.1.2}%
\contentsline {section}{\numberline {3.3}Exercises}{27}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}\texttt {fun\_branin}}{27}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}\texttt {fun\_sin\_cos}}{28}{subsection.3.3.2}%
\contentsline {subsection}{\numberline {3.3.3}\texttt {fun\_runge}}{28}{subsection.3.3.3}%
\contentsline {subsection}{\numberline {3.3.4}\texttt {fun\_wingwt}}{28}{subsection.3.3.4}%
\contentsline {chapter}{\numberline {4}Using \texttt {sklearn} Surrogates in \texttt {spotPython}}{29}{chapter.4}%
\contentsline {section}{\numberline {4.1}Example: Branin Function with \texttt {spotPython}'s Internal Kriging Surrogate}{29}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1}The Objective Function Branin}{29}{subsection.4.1.1}%
\contentsline {subsection}{\numberline {4.1.2}Running the surrogate model based optimizer \texttt {Spot}:}{30}{subsection.4.1.2}%
\contentsline {subsection}{\numberline {4.1.3}TensorBoard}{31}{subsection.4.1.3}%
\contentsline {subsection}{\numberline {4.1.4}Print the Results}{31}{subsection.4.1.4}%
\contentsline {subsection}{\numberline {4.1.5}Show the Progress and the Surrogate}{31}{subsection.4.1.5}%
\contentsline {section}{\numberline {4.2}Example: Using Surrogates From scikit-learn}{33}{section.4.2}%
\contentsline {subsection}{\numberline {4.2.1}GaussianProcessRegressor as a Surrogate}{34}{subsection.4.2.1}%
\contentsline {section}{\numberline {4.3}Example: One-dimensional Sphere Function With \texttt {spotPython}'s Kriging}{36}{section.4.3}%
\contentsline {subsection}{\numberline {4.3.1}Results}{38}{subsection.4.3.1}%
\contentsline {section}{\numberline {4.4}Example: \texttt {Sklearn} Model GaussianProcess}{39}{section.4.4}%
\contentsline {section}{\numberline {4.5}Exercises}{41}{section.4.5}%
\contentsline {subsection}{\numberline {4.5.1}\texttt {DecisionTreeRegressor}}{41}{subsection.4.5.1}%
\contentsline {subsection}{\numberline {4.5.2}\texttt {RandomForestRegressor}}{42}{subsection.4.5.2}%
\contentsline {subsection}{\numberline {4.5.3}\texttt {linear\_model.LinearRegression}}{42}{subsection.4.5.3}%
\contentsline {subsection}{\numberline {4.5.4}\texttt {linear\_model.Ridge}}{42}{subsection.4.5.4}%
\contentsline {section}{\numberline {4.6}Exercise 2}{42}{section.4.6}%
\contentsline {chapter}{\numberline {5}Sequential Parameter Optimization: Using \texttt {scipy} Optimizers}{43}{chapter.5}%
\contentsline {section}{\numberline {5.1}The Objective Function Branin}{43}{section.5.1}%
\contentsline {section}{\numberline {5.2}The Optimizer}{44}{section.5.2}%
\contentsline {subsection}{\numberline {5.2.1}TensorBoard}{46}{subsection.5.2.1}%
\contentsline {section}{\numberline {5.3}Print the Results}{46}{section.5.3}%
\contentsline {section}{\numberline {5.4}Show the Progress}{46}{section.5.4}%
\contentsline {section}{\numberline {5.5}Exercises}{48}{section.5.5}%
\contentsline {subsection}{\numberline {5.5.1}\texttt {dual\_annealing}}{48}{subsection.5.5.1}%
\contentsline {subsection}{\numberline {5.5.2}\texttt {direct}}{48}{subsection.5.5.2}%
\contentsline {subsection}{\numberline {5.5.3}\texttt {shgo}}{48}{subsection.5.5.3}%
\contentsline {subsection}{\numberline {5.5.4}\texttt {basinhopping}}{48}{subsection.5.5.4}%
\contentsline {subsection}{\numberline {5.5.5}Performance Comparison}{49}{subsection.5.5.5}%
\contentsline {chapter}{\numberline {6}Sequential Parameter Optimization: Gaussian Process Models}{50}{chapter.6}%
\contentsline {section}{\numberline {6.1}Gaussian Processes Regression: Basic Introductory \texttt {scikit-learn} Example}{50}{section.6.1}%
\contentsline {subsection}{\numberline {6.1.1}Train and Test Data}{51}{subsection.6.1.1}%
\contentsline {subsection}{\numberline {6.1.2}Building the Surrogate With \texttt {Sklearn}}{51}{subsection.6.1.2}%
\contentsline {subsection}{\numberline {6.1.3}Plotting the \texttt {Sklearn}Model}{51}{subsection.6.1.3}%
\contentsline {subsection}{\numberline {6.1.4}The \texttt {spotPython} Version}{52}{subsection.6.1.4}%
\contentsline {subsection}{\numberline {6.1.5}Visualizing the Differences Between the \texttt {spotPython} and the \texttt {sklearn} Model Fits}{53}{subsection.6.1.5}%
\contentsline {section}{\numberline {6.2}Exercises}{53}{section.6.2}%
\contentsline {subsection}{\numberline {6.2.1}\texttt {Schonlau\ Example\ Function}}{53}{subsection.6.2.1}%
\contentsline {subsection}{\numberline {6.2.2}\texttt {Forrester\ Example\ Function}}{53}{subsection.6.2.2}%
\contentsline {subsection}{\numberline {6.2.3}\texttt {fun\_runge\ Function\ (1-dim)}}{54}{subsection.6.2.3}%
\contentsline {subsection}{\numberline {6.2.4}\texttt {fun\_cubed\ (1-dim)}}{55}{subsection.6.2.4}%
\contentsline {subsection}{\numberline {6.2.5}The Effect of Noise}{55}{subsection.6.2.5}%
\contentsline {chapter}{\numberline {7}Expected Improvement}{56}{chapter.7}%
\contentsline {section}{\numberline {7.1}Example: \texttt {Spot} and the 1-dim Sphere Function}{56}{section.7.1}%
\contentsline {subsection}{\numberline {7.1.1}The Objective Function: 1-dim Sphere}{56}{subsection.7.1.1}%
\contentsline {subsection}{\numberline {7.1.2}Results}{58}{subsection.7.1.2}%
\contentsline {section}{\numberline {7.2}Same, but with EI as infill\_criterion}{58}{section.7.2}%
\contentsline {section}{\numberline {7.3}Non-isotropic Kriging}{60}{section.7.3}%
\contentsline {section}{\numberline {7.4}Using \texttt {sklearn} Surrogates}{63}{section.7.4}%
\contentsline {subsection}{\numberline {7.4.1}The spot Loop}{63}{subsection.7.4.1}%
\contentsline {subsection}{\numberline {7.4.2}spot: The Initial Model}{64}{subsection.7.4.2}%
\contentsline {subsubsection}{\numberline {7.4.2.1}Example: Modifying the initial design size}{64}{subsubsection.7.4.2.1}%
\contentsline {subsection}{\numberline {7.4.3}Init: Build Initial Design}{65}{subsection.7.4.3}%
\contentsline {subsection}{\numberline {7.4.4}Evaluate}{67}{subsection.7.4.4}%
\contentsline {subsection}{\numberline {7.4.5}Build Surrogate}{67}{subsection.7.4.5}%
\contentsline {subsection}{\numberline {7.4.6}A Simple Predictor}{67}{subsection.7.4.6}%
\contentsline {section}{\numberline {7.5}Gaussian Processes regression: basic introductory example}{68}{section.7.5}%
\contentsline {section}{\numberline {7.6}The Surrogate: Using scikit-learn models}{70}{section.7.6}%
\contentsline {section}{\numberline {7.7}Additional Examples}{72}{section.7.7}%
\contentsline {subsection}{\numberline {7.7.1}Optimize on Surrogate}{75}{subsection.7.7.1}%
\contentsline {subsection}{\numberline {7.7.2}Evaluate on Real Objective}{75}{subsection.7.7.2}%
\contentsline {subsection}{\numberline {7.7.3}Impute / Infill new Points}{75}{subsection.7.7.3}%
\contentsline {section}{\numberline {7.8}Tests}{75}{section.7.8}%
\contentsline {section}{\numberline {7.9}EI: The Famous Schonlau Example}{77}{section.7.9}%
\contentsline {section}{\numberline {7.10}EI: The Forrester Example}{78}{section.7.10}%
\contentsline {section}{\numberline {7.11}Noise}{80}{section.7.11}%
\contentsline {section}{\numberline {7.12}Cubic Function}{82}{section.7.12}%
\contentsline {section}{\numberline {7.13}Factors}{87}{section.7.13}%
\contentsline {chapter}{\numberline {8}Hyperparameter Tuning and Noise}{89}{chapter.8}%
\contentsline {section}{\numberline {8.1}Example: \texttt {Spot} and the Noisy Sphere Function}{89}{section.8.1}%
\contentsline {subsection}{\numberline {8.1.1}The Objective Function: Noisy Sphere}{89}{subsection.8.1.1}%
\contentsline {section}{\numberline {8.2}Print the Results}{92}{section.8.2}%
\contentsline {section}{\numberline {8.3}Noise and Surrogates: The Nugget Effect}{93}{section.8.3}%
\contentsline {subsection}{\numberline {8.3.1}The Noisy Sphere}{93}{subsection.8.3.1}%
\contentsline {subsubsection}{\numberline {8.3.1.1}The Data}{93}{subsubsection.8.3.1.1}%
\contentsline {section}{\numberline {8.4}Exercises}{95}{section.8.4}%
\contentsline {subsection}{\numberline {8.4.1}Noisy \texttt {fun\_cubed}}{95}{subsection.8.4.1}%
\contentsline {subsection}{\numberline {8.4.2}\texttt {fun\_runge}}{96}{subsection.8.4.2}%
\contentsline {subsection}{\numberline {8.4.3}\texttt {fun\_forrester}}{96}{subsection.8.4.3}%
\contentsline {subsection}{\numberline {8.4.4}\texttt {fun\_xsin}}{96}{subsection.8.4.4}%
\contentsline {chapter}{\numberline {9}Handling Noise: Optimal Computational Budget Allocation in \texttt {Spot}}{97}{chapter.9}%
\contentsline {section}{\numberline {9.1}Example: \texttt {Spot}, OCBA, and the Noisy Sphere Function}{97}{section.9.1}%
\contentsline {subsection}{\numberline {9.1.1}The Objective Function: Noisy Sphere}{97}{subsection.9.1.1}%
\contentsline {section}{\numberline {9.2}Print the Results}{100}{section.9.2}%
\contentsline {section}{\numberline {9.3}Noise and Surrogates: The Nugget Effect}{101}{section.9.3}%
\contentsline {subsection}{\numberline {9.3.1}The Noisy Sphere}{101}{subsection.9.3.1}%
\contentsline {subsubsection}{\numberline {9.3.1.1}The Data}{101}{subsubsection.9.3.1.1}%
\contentsline {section}{\numberline {9.4}Exercises}{103}{section.9.4}%
\contentsline {subsection}{\numberline {9.4.1}Noisy \texttt {fun\_cubed}}{103}{subsection.9.4.1}%
\contentsline {subsection}{\numberline {9.4.2}\texttt {fun\_runge}}{103}{subsection.9.4.2}%
\contentsline {subsection}{\numberline {9.4.3}\texttt {fun\_forrester}}{103}{subsection.9.4.3}%
\contentsline {subsection}{\numberline {9.4.4}\texttt {fun\_xsin}}{104}{subsection.9.4.4}%
\contentsline {part}{\numberline {II}Hyperparameter Tuning}{105}{part.2}%
\contentsline {chapter}{\numberline {10}HPT: sklearn SVC on Moons Data}{106}{chapter.10}%
\contentsline {section}{\numberline {10.1}Step 1: Setup}{106}{section.10.1}%
\contentsline {section}{\numberline {10.2}Step 2: Initialization of the Empty \texttt {fun\_control} Dictionary}{106}{section.10.2}%
\contentsline {section}{\numberline {10.3}Step 3: SKlearn Load Data (Classification)}{107}{section.10.3}%
\contentsline {section}{\numberline {10.4}Step 4: Specification of the Preprocessing Model}{108}{section.10.4}%
\contentsline {section}{\numberline {10.5}Step 5: Select Model (\texttt {algorithm}) and \texttt {core\_model\_hyper\_dict}}{109}{section.10.5}%
\contentsline {section}{\numberline {10.6}Step 6: Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{112}{section.10.6}%
\contentsline {subsection}{\numberline {10.6.1}Modify hyperparameter of type numeric and integer (boolean)}{112}{subsection.10.6.1}%
\contentsline {subsection}{\numberline {10.6.2}Modify hyperparameter of type factor}{112}{subsection.10.6.2}%
\contentsline {subsection}{\numberline {10.6.3}Optimizers}{113}{subsection.10.6.3}%
\contentsline {section}{\numberline {10.7}Step 7: Selection of the Objective (Loss) Function}{113}{section.10.7}%
\contentsline {subsection}{\numberline {10.7.1}Predict Classes or Class Probabilities}{113}{subsection.10.7.1}%
\contentsline {section}{\numberline {10.8}Step 8: Calling the SPOT Function}{114}{section.10.8}%
\contentsline {subsection}{\numberline {10.8.1}Preparing the SPOT Call}{114}{subsection.10.8.1}%
\contentsline {subsection}{\numberline {10.8.2}The Objective Function}{115}{subsection.10.8.2}%
\contentsline {subsection}{\numberline {10.8.3}Run the \texttt {Spot} Optimizer}{115}{subsection.10.8.3}%
\contentsline {subsection}{\numberline {10.8.4}Starting the Hyperparameter Tuning}{115}{subsection.10.8.4}%
\contentsline {section}{\numberline {10.9}Step 9: Results}{117}{section.10.9}%
\contentsline {subsection}{\numberline {10.9.1}Show variable importance}{118}{subsection.10.9.1}%
\contentsline {subsection}{\numberline {10.9.2}Get Default Hyperparameters}{118}{subsection.10.9.2}%
\contentsline {subsection}{\numberline {10.9.3}Get SPOT Results}{119}{subsection.10.9.3}%
\contentsline {subsection}{\numberline {10.9.4}Plot: Compare Predictions}{120}{subsection.10.9.4}%
\contentsline {subsection}{\numberline {10.9.5}Detailed Hyperparameter Plots}{121}{subsection.10.9.5}%
\contentsline {subsection}{\numberline {10.9.6}Parallel Coordinates Plot}{121}{subsection.10.9.6}%
\contentsline {subsection}{\numberline {10.9.7}Plot all Combinations of Hyperparameters}{121}{subsection.10.9.7}%
\contentsline {chapter}{\numberline {11}\texttt {river} Hyperparameter Tuning: Hoeffding Adaptive Tree Regressor with Friedman Drift Data}{123}{chapter.11}%
\contentsline {section}{\numberline {11.1}Setup}{123}{section.11.1}%
\contentsline {section}{\numberline {11.2}Initialization of the \texttt {fun\_control} Dictionary}{124}{section.11.2}%
\contentsline {section}{\numberline {11.3}Load Data: The Friedman Drift Data}{125}{section.11.3}%
\contentsline {section}{\numberline {11.4}Specification of the Preprocessing Model}{126}{section.11.4}%
\contentsline {section}{\numberline {11.5}SelectSelect Model (\texttt {algorithm}) and \texttt {core\_model\_hyper\_dict}}{126}{section.11.5}%
\contentsline {section}{\numberline {11.6}Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{127}{section.11.6}%
\contentsline {section}{\numberline {11.7}Selection of the Objective Function}{128}{section.11.7}%
\contentsline {section}{\numberline {11.8}Calling the SPOT Function}{129}{section.11.8}%
\contentsline {subsection}{\numberline {11.8.1}Prepare the SPOT Parameters}{129}{subsection.11.8.1}%
\contentsline {subsection}{\numberline {11.8.2}The Objective Function}{130}{subsection.11.8.2}%
\contentsline {subsection}{\numberline {11.8.3}Run the \texttt {Spot} Optimizer}{130}{subsection.11.8.3}%
\contentsline {subsection}{\numberline {11.8.4}TensorBoard}{132}{subsection.11.8.4}%
\contentsline {subsection}{\numberline {11.8.5}Results}{132}{subsection.11.8.5}%
\contentsline {section}{\numberline {11.9}The Larger Data Set}{135}{section.11.9}%
\contentsline {section}{\numberline {11.10}Get Default Hyperparameters}{136}{section.11.10}%
\contentsline {subsection}{\numberline {11.10.1}Show Predictions}{137}{subsection.11.10.1}%
\contentsline {section}{\numberline {11.11}Get SPOT Results}{137}{section.11.11}%
\contentsline {section}{\numberline {11.12}Visualize Regression Trees}{139}{section.11.12}%
\contentsline {subsection}{\numberline {11.12.1}Spot Model}{139}{subsection.11.12.1}%
\contentsline {section}{\numberline {11.13}Detailed Hyperparameter Plots}{140}{section.11.13}%
\contentsline {section}{\numberline {11.14}Parallel Coordinates Plots}{141}{section.11.14}%
\contentsline {section}{\numberline {11.15}Plot all Combinations of Hyperparameters}{141}{section.11.15}%
\contentsline {chapter}{\numberline {12}HPT: PyTorch With \texttt {spotPython} and Ray Tune on CIFAR10}{143}{chapter.12}%
\contentsline {section}{\numberline {12.1}Step 1: Setup}{144}{section.12.1}%
\contentsline {section}{\numberline {12.2}Step 2: Initialization of the \texttt {fun\_control} Dictionary}{145}{section.12.2}%
\contentsline {section}{\numberline {12.3}Step 3: PyTorch Data Loading}{145}{section.12.3}%
\contentsline {section}{\numberline {12.4}Step 4: Specification of the Preprocessing Model}{146}{section.12.4}%
\contentsline {section}{\numberline {12.5}Step 5: Select Model (\texttt {algorithm}) and \texttt {core\_model\_hyper\_dict}}{147}{section.12.5}%
\contentsline {subsubsection}{\numberline {12.5.0.1}Implementing a Configurable Neural Network With Ray Tune}{147}{subsubsection.12.5.0.1}%
\contentsline {subsubsection}{\numberline {12.5.0.2}Implementing a Configurable Neural Network With spotPython}{147}{subsubsection.12.5.0.2}%
\contentsline {subsection}{\numberline {12.5.1}The \texttt {Net\_Core} class}{148}{subsection.12.5.1}%
\contentsline {subsection}{\numberline {12.5.2}Comparison of the Approach Described in the PyTorch Tutorial With spotPython}{149}{subsection.12.5.2}%
\contentsline {subsection}{\numberline {12.5.3}The Search Space: Hyperparameters}{150}{subsection.12.5.3}%
\contentsline {subsection}{\numberline {12.5.4}Configuring the Search Space With Ray Tune}{150}{subsection.12.5.4}%
\contentsline {subsection}{\numberline {12.5.5}Configuring the Search Space With spotPython}{150}{subsection.12.5.5}%
\contentsline {subsubsection}{\numberline {12.5.5.1}The \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm}{150}{subsubsection.12.5.5.1}%
\contentsline {section}{\numberline {12.6}Step 6: Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{152}{section.12.6}%
\contentsline {subsubsection}{\numberline {12.6.0.1}Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{153}{subsubsection.12.6.0.1}%
\contentsline {subsubsection}{\numberline {12.6.0.2}Modify Hyperparameters of Type numeric and integer (boolean)}{153}{subsubsection.12.6.0.2}%
\contentsline {subsubsection}{\numberline {12.6.0.3}Modify Hyperparameter of Type factor}{153}{subsubsection.12.6.0.3}%
\contentsline {subsection}{\numberline {12.6.1}Optimizers}{154}{subsection.12.6.1}%
\contentsline {section}{\numberline {12.7}Step 7: Selection of the Objective (Loss) Function}{156}{section.12.7}%
\contentsline {subsection}{\numberline {12.7.1}Evaluation: Data Splitting}{156}{subsection.12.7.1}%
\contentsline {subsection}{\numberline {12.7.2}Hold-out Data Split}{156}{subsection.12.7.2}%
\contentsline {subsection}{\numberline {12.7.3}Cross-Validation}{157}{subsection.12.7.3}%
\contentsline {subsection}{\numberline {12.7.4}Overview of the Evaluation Settings}{157}{subsection.12.7.4}%
\contentsline {subsubsection}{\numberline {12.7.4.1}Settings for the Hyperparameter Tuning}{157}{subsubsection.12.7.4.1}%
\contentsline {subsubsection}{\numberline {12.7.4.2}Settings for the Final Evaluation of the Tuned Architecture}{158}{subsubsection.12.7.4.2}%
\contentsline {paragraph}{\numberline {12.7.4.2.1}Training of the Tuned Architecture}{158}{paragraph.12.7.4.2.1}%
\contentsline {paragraph}{\numberline {12.7.4.2.2}Testing of the Tuned Architecture}{158}{paragraph.12.7.4.2.2}%
\contentsline {subsection}{\numberline {12.7.5}Evaluation: Loss Functions and Metrics}{158}{subsection.12.7.5}%
\contentsline {section}{\numberline {12.8}Step 8: Calling the SPOT Function}{159}{section.12.8}%
\contentsline {subsection}{\numberline {12.8.1}Preparing the SPOT Call}{159}{subsection.12.8.1}%
\contentsline {subsection}{\numberline {12.8.2}The Objective Function \texttt {fun\_torch}}{160}{subsection.12.8.2}%
\contentsline {subsection}{\numberline {12.8.3}Using Default Hyperparameters or Results from Previous Runs}{160}{subsection.12.8.3}%
\contentsline {subsection}{\numberline {12.8.4}Starting the Hyperparameter Tuning}{161}{subsection.12.8.4}%
\contentsline {section}{\numberline {12.9}Step 9: Tensorboard}{167}{section.12.9}%
\contentsline {subsection}{\numberline {12.9.1}Tensorboard: Start Tensorboard}{167}{subsection.12.9.1}%
\contentsline {subsection}{\numberline {12.9.2}Saving the State of the Notebook}{167}{subsection.12.9.2}%
\contentsline {section}{\numberline {12.10}Step 10: Results}{169}{section.12.10}%
\contentsline {subsection}{\numberline {12.10.1}Get the Tuned Architecture (SPOT Results)}{171}{subsection.12.10.1}%
\contentsline {subsection}{\numberline {12.10.2}Get Default Hyperparameters}{171}{subsection.12.10.2}%
\contentsline {subsection}{\numberline {12.10.3}Evaluation of the Default Architecture}{172}{subsection.12.10.3}%
\contentsline {subsection}{\numberline {12.10.4}Evaluation of the Tuned Architecture}{173}{subsection.12.10.4}%
\contentsline {subsection}{\numberline {12.10.5}Detailed Hyperparameter Plots}{175}{subsection.12.10.5}%
\contentsline {section}{\numberline {12.11}Summary and Outlook}{177}{section.12.11}%
\contentsline {section}{\numberline {12.12}Appendix}{178}{section.12.12}%
\contentsline {subsection}{\numberline {12.12.1}Sample Output From Ray Tune's Run}{178}{subsection.12.12.1}%
\contentsline {chapter}{\numberline {13}HPT: sklearn RandomForestClassifier VBDP Data}{179}{chapter.13}%
\contentsline {section}{\numberline {13.1}Step 1: Setup}{179}{section.13.1}%
\contentsline {section}{\numberline {13.2}Step 2: Initialization of the Empty \texttt {fun\_control} Dictionary}{180}{section.13.2}%
\contentsline {section}{\numberline {13.3}Step 3: PyTorch Data Loading}{180}{section.13.3}%
\contentsline {subsection}{\numberline {13.3.1}Load Data: Classification VBDP}{180}{subsection.13.3.1}%
\contentsline {subsection}{\numberline {13.3.2}Holdout Train and Test Data}{181}{subsection.13.3.2}%
\contentsline {section}{\numberline {13.4}Step 4: Specification of the Preprocessing Model}{182}{section.13.4}%
\contentsline {section}{\numberline {13.5}Step 5: Select Model (\texttt {algorithm}) and \texttt {core\_model\_hyper\_dict}}{182}{section.13.5}%
\contentsline {section}{\numberline {13.6}Step 6: Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{184}{section.13.6}%
\contentsline {subsection}{\numberline {13.6.1}Modify hyperparameter of type numeric and integer (boolean)}{184}{subsection.13.6.1}%
\contentsline {subsection}{\numberline {13.6.2}Modify hyperparameter of type factor}{184}{subsection.13.6.2}%
\contentsline {subsection}{\numberline {13.6.3}Optimizers}{185}{subsection.13.6.3}%
\contentsline {subsection}{\numberline {13.6.4}Selection of the Objective: Metric and Loss Functions}{185}{subsection.13.6.4}%
\contentsline {section}{\numberline {13.7}Step 7: Selection of the Objective (Loss) Function}{185}{section.13.7}%
\contentsline {subsection}{\numberline {13.7.1}Metric Function}{185}{subsection.13.7.1}%
\contentsline {subsubsection}{\numberline {13.7.1.1}The MAPK Metric}{186}{subsubsection.13.7.1.1}%
\contentsline {subsubsection}{\numberline {13.7.1.2}Other Metrics}{186}{subsubsection.13.7.1.2}%
\contentsline {subsection}{\numberline {13.7.2}Evaluation on Hold-out Data}{187}{subsection.13.7.2}%
\contentsline {subsection}{\numberline {13.7.3}OOB Score}{187}{subsection.13.7.3}%
\contentsline {subsubsection}{\numberline {13.7.3.1}Cross Validation}{187}{subsubsection.13.7.3.1}%
\contentsline {section}{\numberline {13.8}Step 8: Calling the SPOT Function}{188}{section.13.8}%
\contentsline {subsection}{\numberline {13.8.1}Preparing the SPOT Call}{188}{subsection.13.8.1}%
\contentsline {subsection}{\numberline {13.8.2}The Objective Function}{188}{subsection.13.8.2}%
\contentsline {subsection}{\numberline {13.8.3}Run the \texttt {Spot} Optimizer}{189}{subsection.13.8.3}%
\contentsline {section}{\numberline {13.9}Step 9: Tensorboard}{192}{section.13.9}%
\contentsline {section}{\numberline {13.10}Step 10: Results}{192}{section.13.10}%
\contentsline {subsection}{\numberline {13.10.1}Show variable importance}{193}{subsection.13.10.1}%
\contentsline {subsection}{\numberline {13.10.2}Get Default Hyperparameters}{193}{subsection.13.10.2}%
\contentsline {subsection}{\numberline {13.10.3}Get SPOT Results}{194}{subsection.13.10.3}%
\contentsline {subsection}{\numberline {13.10.4}Evaluate SPOT Results}{195}{subsection.13.10.4}%
\contentsline {subsection}{\numberline {13.10.5}Handling Non-deterministic Results}{196}{subsection.13.10.5}%
\contentsline {subsection}{\numberline {13.10.6}Evalution of the Default Hyperparameters}{196}{subsection.13.10.6}%
\contentsline {subsection}{\numberline {13.10.7}Plot: Compare Predictions}{197}{subsection.13.10.7}%
\contentsline {subsection}{\numberline {13.10.8}Cross-validated Evaluations}{197}{subsection.13.10.8}%
\contentsline {subsection}{\numberline {13.10.9}Detailed Hyperparameter Plots}{198}{subsection.13.10.9}%
\contentsline {subsection}{\numberline {13.10.10}Parallel Coordinates Plot}{200}{subsection.13.10.10}%
\contentsline {subsection}{\numberline {13.10.11}Plot all Combinations of Hyperparameters}{200}{subsection.13.10.11}%
\contentsline {chapter}{\numberline {14}HPT: sklearn XGB Classifier VBDP Data}{201}{chapter.14}%
\contentsline {section}{\numberline {14.1}Step 1: Setup}{201}{section.14.1}%
\contentsline {section}{\numberline {14.2}Step 2: Initialization of the Empty \texttt {fun\_control} Dictionary}{202}{section.14.2}%
\contentsline {section}{\numberline {14.3}Step 3: PyTorch Data Loading}{202}{section.14.3}%
\contentsline {subsection}{\numberline {14.3.1}1. Load Data: Classification VBDP}{202}{subsection.14.3.1}%
\contentsline {subsection}{\numberline {14.3.2}Holdout Train and Test Data}{203}{subsection.14.3.2}%
\contentsline {section}{\numberline {14.4}Step 4: Specification of the Preprocessing Model}{204}{section.14.4}%
\contentsline {section}{\numberline {14.5}Step 5: Select Model (\texttt {algorithm}) and \texttt {core\_model\_hyper\_dict}}{204}{section.14.5}%
\contentsline {section}{\numberline {14.6}Step 6: Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{206}{section.14.6}%
\contentsline {subsection}{\numberline {14.6.1}Modify hyperparameter of type numeric and integer (boolean)}{206}{subsection.14.6.1}%
\contentsline {subsection}{\numberline {14.6.2}Modify hyperparameter of type factor}{207}{subsection.14.6.2}%
\contentsline {subsection}{\numberline {14.6.3}Optimizers}{207}{subsection.14.6.3}%
\contentsline {section}{\numberline {14.7}Step 7: Selection of the Objective (Loss) Function}{207}{section.14.7}%
\contentsline {subsection}{\numberline {14.7.1}Evaluation}{207}{subsection.14.7.1}%
\contentsline {subsection}{\numberline {14.7.2}Selection of the Objective: Metric and Loss Functions}{207}{subsection.14.7.2}%
\contentsline {subsection}{\numberline {14.7.3}Loss Function}{208}{subsection.14.7.3}%
\contentsline {subsection}{\numberline {14.7.4}Metric Function}{208}{subsection.14.7.4}%
\contentsline {subsubsection}{\numberline {14.7.4.1}The MAPK Metric}{208}{subsubsection.14.7.4.1}%
\contentsline {subsubsection}{\numberline {14.7.4.2}Other Metrics}{208}{subsubsection.14.7.4.2}%
\contentsline {subsection}{\numberline {14.7.5}Evaluation on Hold-out Data}{209}{subsection.14.7.5}%
\contentsline {subsubsection}{\numberline {14.7.5.1}Cross Validation}{209}{subsubsection.14.7.5.1}%
\contentsline {section}{\numberline {14.8}Step 8: Calling the SPOT Function}{210}{section.14.8}%
\contentsline {subsection}{\numberline {14.8.1}Preparing the SPOT Call}{210}{subsection.14.8.1}%
\contentsline {subsection}{\numberline {14.8.2}The Objective Function}{210}{subsection.14.8.2}%
\contentsline {subsection}{\numberline {14.8.3}Run the \texttt {Spot} Optimizer}{211}{subsection.14.8.3}%
\contentsline {section}{\numberline {14.9}Step 9: Tensorboard}{212}{section.14.9}%
\contentsline {section}{\numberline {14.10}Step 10: Results}{212}{section.14.10}%
\contentsline {subsection}{\numberline {14.10.1}Show variable importance}{213}{subsection.14.10.1}%
\contentsline {subsection}{\numberline {14.10.2}Get Default Hyperparameters}{214}{subsection.14.10.2}%
\contentsline {subsection}{\numberline {14.10.3}Get SPOT Results}{215}{subsection.14.10.3}%
\contentsline {subsection}{\numberline {14.10.4}Evaluate SPOT Results}{215}{subsection.14.10.4}%
\contentsline {subsection}{\numberline {14.10.5}Handling Non-deterministic Results}{216}{subsection.14.10.5}%
\contentsline {subsection}{\numberline {14.10.6}Evalution of the Default Hyperparameters}{217}{subsection.14.10.6}%
\contentsline {subsection}{\numberline {14.10.7}Plot: Compare Predictions}{218}{subsection.14.10.7}%
\contentsline {subsection}{\numberline {14.10.8}Cross-validated Evaluations}{218}{subsection.14.10.8}%
\contentsline {subsection}{\numberline {14.10.9}Detailed Hyperparameter Plots}{219}{subsection.14.10.9}%
\contentsline {subsection}{\numberline {14.10.10}Parallel Coordinates Plot}{220}{subsection.14.10.10}%
\contentsline {subsection}{\numberline {14.10.11}Plot all Combinations of Hyperparameters}{220}{subsection.14.10.11}%
\contentsline {chapter}{\numberline {15}HPT: sklearn SVC VBDP Data}{222}{chapter.15}%
\contentsline {section}{\numberline {15.1}Step 1: Setup}{222}{section.15.1}%
\contentsline {section}{\numberline {15.2}Step 2: Initialization of the Empty \texttt {fun\_control} Dictionary}{223}{section.15.2}%
\contentsline {section}{\numberline {15.3}Step 3: PyTorch Data Loading}{223}{section.15.3}%
\contentsline {subsection}{\numberline {15.3.1}1. Load Data: Classification VBDP}{223}{subsection.15.3.1}%
\contentsline {subsection}{\numberline {15.3.2}Holdout Train and Test Data}{224}{subsection.15.3.2}%
\contentsline {section}{\numberline {15.4}Step 4: Specification of the Preprocessing Model}{225}{section.15.4}%
\contentsline {section}{\numberline {15.5}Step 5: Select Model (\texttt {algorithm}) and \texttt {core\_model\_hyper\_dict}}{225}{section.15.5}%
\contentsline {section}{\numberline {15.6}Step 6: Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{227}{section.15.6}%
\contentsline {subsection}{\numberline {15.6.1}Modify hyperparameter of type numeric and integer (boolean)}{227}{subsection.15.6.1}%
\contentsline {subsection}{\numberline {15.6.2}Modify hyperparameter of type factor}{227}{subsection.15.6.2}%
\contentsline {subsection}{\numberline {15.6.3}Optimizers}{228}{subsection.15.6.3}%
\contentsline {subsection}{\numberline {15.6.4}Selection of the Objective: Metric and Loss Functions}{228}{subsection.15.6.4}%
\contentsline {section}{\numberline {15.7}Step 7: Selection of the Objective (Loss) Function}{228}{section.15.7}%
\contentsline {subsection}{\numberline {15.7.1}Metric Function}{228}{subsection.15.7.1}%
\contentsline {subsubsection}{\numberline {15.7.1.1}The MAPK Metric}{229}{subsubsection.15.7.1.1}%
\contentsline {subsubsection}{\numberline {15.7.1.2}Other Metrics}{229}{subsubsection.15.7.1.2}%
\contentsline {subsection}{\numberline {15.7.2}Evaluation on Hold-out Data}{229}{subsection.15.7.2}%
\contentsline {subsubsection}{\numberline {15.7.2.1}Cross Validation}{230}{subsubsection.15.7.2.1}%
\contentsline {section}{\numberline {15.8}Step 8: Calling the SPOT Function}{230}{section.15.8}%
\contentsline {subsection}{\numberline {15.8.1}Preparing the SPOT Call}{230}{subsection.15.8.1}%
\contentsline {subsection}{\numberline {15.8.2}The Objective Function}{231}{subsection.15.8.2}%
\contentsline {subsection}{\numberline {15.8.3}Run the \texttt {Spot} Optimizer}{231}{subsection.15.8.3}%
\contentsline {section}{\numberline {15.9}Step 9: Tensorboard}{236}{section.15.9}%
\contentsline {section}{\numberline {15.10}Step 10: Results}{236}{section.15.10}%
\contentsline {subsection}{\numberline {15.10.1}Show variable importance}{237}{subsection.15.10.1}%
\contentsline {subsection}{\numberline {15.10.2}Get Default Hyperparameters}{237}{subsection.15.10.2}%
\contentsline {subsection}{\numberline {15.10.3}Get SPOT Results}{238}{subsection.15.10.3}%
\contentsline {subsection}{\numberline {15.10.4}Evaluate SPOT Results}{239}{subsection.15.10.4}%
\contentsline {subsection}{\numberline {15.10.5}Handling Non-deterministic Results}{240}{subsection.15.10.5}%
\contentsline {subsection}{\numberline {15.10.6}Evalution of the Default Hyperparameters}{240}{subsection.15.10.6}%
\contentsline {subsection}{\numberline {15.10.7}Plot: Compare Predictions}{241}{subsection.15.10.7}%
\contentsline {subsection}{\numberline {15.10.8}Cross-validated Evaluations}{241}{subsection.15.10.8}%
\contentsline {subsection}{\numberline {15.10.9}Detailed Hyperparameter Plots}{242}{subsection.15.10.9}%
\contentsline {subsection}{\numberline {15.10.10}Parallel Coordinates Plot}{243}{subsection.15.10.10}%
\contentsline {subsection}{\numberline {15.10.11}Plot all Combinations of Hyperparameters}{243}{subsection.15.10.11}%
\contentsline {chapter}{\numberline {16}HPT: sklearn KNN Classifier VBDP Data}{244}{chapter.16}%
\contentsline {section}{\numberline {16.1}Step 1: Setup}{244}{section.16.1}%
\contentsline {section}{\numberline {16.2}Step 2: Initialization of the Empty \texttt {fun\_control} Dictionary}{245}{section.16.2}%
\contentsline {subsection}{\numberline {16.2.1}Load Data: Classification VBDP}{245}{subsection.16.2.1}%
\contentsline {subsection}{\numberline {16.2.2}Holdout Train and Test Data}{246}{subsection.16.2.2}%
\contentsline {section}{\numberline {16.3}Step 4: Specification of the Preprocessing Model}{247}{section.16.3}%
\contentsline {section}{\numberline {16.4}Step 5: Select Model (\texttt {algorithm}) and \texttt {core\_model\_hyper\_dict}}{247}{section.16.4}%
\contentsline {section}{\numberline {16.5}Step 6: Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{249}{section.16.5}%
\contentsline {subsection}{\numberline {16.5.1}Modify hyperparameter of type numeric and integer (boolean)}{249}{subsection.16.5.1}%
\contentsline {subsection}{\numberline {16.5.2}Modify hyperparameter of type factor}{249}{subsection.16.5.2}%
\contentsline {subsection}{\numberline {16.5.3}Optimizers}{250}{subsection.16.5.3}%
\contentsline {subsection}{\numberline {16.5.4}Selection of the Objective: Metric and Loss Functions}{250}{subsection.16.5.4}%
\contentsline {section}{\numberline {16.6}Step 7: Selection of the Objective (Loss) Function}{250}{section.16.6}%
\contentsline {subsection}{\numberline {16.6.1}Metric Function}{250}{subsection.16.6.1}%
\contentsline {subsubsection}{\numberline {16.6.1.1}The MAPK Metric}{251}{subsubsection.16.6.1.1}%
\contentsline {subsubsection}{\numberline {16.6.1.2}Other Metrics}{251}{subsubsection.16.6.1.2}%
\contentsline {subsection}{\numberline {16.6.2}Evaluation on Hold-out Data}{251}{subsection.16.6.2}%
\contentsline {subsubsection}{\numberline {16.6.2.1}Cross Validation}{252}{subsubsection.16.6.2.1}%
\contentsline {section}{\numberline {16.7}Step 8: Calling the SPOT Function}{252}{section.16.7}%
\contentsline {subsection}{\numberline {16.7.1}Preparing the SPOT Call}{252}{subsection.16.7.1}%
\contentsline {subsection}{\numberline {16.7.2}The Objective Function}{253}{subsection.16.7.2}%
\contentsline {subsection}{\numberline {16.7.3}Run the \texttt {Spot} Optimizer}{253}{subsection.16.7.3}%
\contentsline {section}{\numberline {16.8}Step 9: Tensorboard}{257}{section.16.8}%
\contentsline {section}{\numberline {16.9}Step 10: Results}{257}{section.16.9}%
\contentsline {subsection}{\numberline {16.9.1}Show variable importance}{258}{subsection.16.9.1}%
\contentsline {subsection}{\numberline {16.9.2}Get Default Hyperparameters}{258}{subsection.16.9.2}%
\contentsline {subsection}{\numberline {16.9.3}Get SPOT Results}{259}{subsection.16.9.3}%
\contentsline {subsection}{\numberline {16.9.4}Evaluate SPOT Results}{259}{subsection.16.9.4}%
\contentsline {subsection}{\numberline {16.9.5}Handling Non-deterministic Results}{260}{subsection.16.9.5}%
\contentsline {subsection}{\numberline {16.9.6}Evalution of the Default Hyperparameters}{261}{subsection.16.9.6}%
\contentsline {subsection}{\numberline {16.9.7}Plot: Compare Predictions}{261}{subsection.16.9.7}%
\contentsline {subsection}{\numberline {16.9.8}Cross-validated Evaluations}{262}{subsection.16.9.8}%
\contentsline {subsection}{\numberline {16.9.9}Detailed Hyperparameter Plots}{263}{subsection.16.9.9}%
\contentsline {subsection}{\numberline {16.9.10}Parallel Coordinates Plot}{263}{subsection.16.9.10}%
\contentsline {subsection}{\numberline {16.9.11}Plot all Combinations of Hyperparameters}{263}{subsection.16.9.11}%
\contentsline {chapter}{\numberline {17}HPT PyTorch Lightning: VBDP}{265}{chapter.17}%
\contentsline {section}{\numberline {17.1}Step 1: Setup}{265}{section.17.1}%
\contentsline {section}{\numberline {17.2}Step 2: Initialization of the \texttt {fun\_control} Dictionary}{266}{section.17.2}%
\contentsline {section}{\numberline {17.3}Step 3: PyTorch Data Loading}{267}{section.17.3}%
\contentsline {subsection}{\numberline {17.3.1}Lightning Dataset and DataModule}{267}{subsection.17.3.1}%
\contentsline {section}{\numberline {17.4}Step 4: Preprocessing}{267}{section.17.4}%
\contentsline {section}{\numberline {17.5}Step 5: Select the NN Model (\texttt {algorithm}) and \texttt {core\_model\_hyper\_dict}}{267}{section.17.5}%
\contentsline {section}{\numberline {17.6}Step 6: Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{268}{section.17.6}%
\contentsline {section}{\numberline {17.7}Step 7: Data Splitting, the Objective (Loss) Function and the Metric}{269}{section.17.7}%
\contentsline {subsection}{\numberline {17.7.1}Evaluation}{269}{subsection.17.7.1}%
\contentsline {subsection}{\numberline {17.7.2}Loss Functions and Metrics}{269}{subsection.17.7.2}%
\contentsline {subsection}{\numberline {17.7.3}Metric}{270}{subsection.17.7.3}%
\contentsline {section}{\numberline {17.8}Step 8: Calling the SPOT Function}{270}{section.17.8}%
\contentsline {subsection}{\numberline {17.8.1}Preparing the SPOT Call}{270}{subsection.17.8.1}%
\contentsline {subsection}{\numberline {17.8.2}The Objective Function \texttt {fun}}{270}{subsection.17.8.2}%
\contentsline {subsection}{\numberline {17.8.3}Starting the Hyperparameter Tuning}{271}{subsection.17.8.3}%
\contentsline {section}{\numberline {17.9}Step 9: Tensorboard}{273}{section.17.9}%
\contentsline {section}{\numberline {17.10}Step 10: Results}{273}{section.17.10}%
\contentsline {subsection}{\numberline {17.10.1}Get the Tuned Architecture}{275}{subsection.17.10.1}%
\contentsline {subsection}{\numberline {17.10.2}Cross Validation With Lightning}{275}{subsection.17.10.2}%
\contentsline {subsection}{\numberline {17.10.3}Detailed Hyperparameter Plots}{279}{subsection.17.10.3}%
\contentsline {subsection}{\numberline {17.10.4}Parallel Coordinates Plot}{280}{subsection.17.10.4}%
\contentsline {subsection}{\numberline {17.10.5}Plot all Combinations of Hyperparameters}{280}{subsection.17.10.5}%
\contentsline {subsection}{\numberline {17.10.6}Visualizing the Activation Distribution}{281}{subsection.17.10.6}%
\contentsline {section}{\numberline {17.11}Submission}{282}{section.17.11}%
\contentsline {section}{\numberline {17.12}Appendix}{284}{section.17.12}%
\contentsline {subsection}{\numberline {17.12.1}Differences to the spotPython Approaches for \texttt {torch}, \texttt {sklearn} and \texttt {river}}{284}{subsection.17.12.1}%
\contentsline {subsubsection}{\numberline {17.12.1.1}Specification of the Preprocessing Model}{284}{subsubsection.17.12.1.1}%
\contentsline {subsection}{\numberline {17.12.2}Taking a Look at the Data}{285}{subsection.17.12.2}%
\contentsline {subsection}{\numberline {17.12.3}The MAPK Metric}{286}{subsection.17.12.3}%
\contentsline {part}{Appendices}{287}{section*.170}%
\contentsline {chapter}{\numberline {A}Documentation of the Sequential Parameter Optimization}{287}{appendix.A}%
\contentsline {section}{\numberline {A.1}Example: spot}{287}{section.A.1}%
\contentsline {subsection}{\numberline {A.1.1}The Objective Function}{287}{subsection.A.1.1}%
\contentsline {subsection}{\numberline {A.1.2}External Parameters}{288}{subsection.A.1.2}%
\contentsline {section}{\numberline {A.2}The \texttt {fun\_control} Dictionary}{292}{section.A.2}%
\contentsline {section}{\numberline {A.3}The \texttt {design\_control} Dictionary}{292}{section.A.3}%
\contentsline {section}{\numberline {A.4}The \texttt {surrogate\_control} Dictionary}{293}{section.A.4}%
\contentsline {section}{\numberline {A.5}The \texttt {optimizer\_control} Dictionary}{293}{section.A.5}%
\contentsline {section}{\numberline {A.6}Run}{294}{section.A.6}%
\contentsline {section}{\numberline {A.7}Print the Results}{294}{section.A.7}%
\contentsline {section}{\numberline {A.8}Show the Progress}{295}{section.A.8}%
\contentsline {section}{\numberline {A.9}Visualize the Surrogate}{295}{section.A.9}%
\contentsline {section}{\numberline {A.10}Init: Build Initial Design}{295}{section.A.10}%
\contentsline {section}{\numberline {A.11}Replicability}{296}{section.A.11}%
\contentsline {section}{\numberline {A.12}Surrogates}{297}{section.A.12}%
\contentsline {subsection}{\numberline {A.12.1}A Simple Predictor}{297}{subsection.A.12.1}%
\contentsline {section}{\numberline {A.13}Demo/Test: Objective Function Fails}{297}{section.A.13}%
\contentsline {section}{\numberline {A.14}PyTorch: Detailed Description of the Data Splitting}{300}{section.A.14}%
\contentsline {subsection}{\numberline {A.14.1}Description of the \texttt {"train\_hold\_out"} Setting}{300}{subsection.A.14.1}%
\contentsline {subsubsection}{\numberline {A.14.1.1}Description of the \texttt {"test\_hold\_out"} Setting}{303}{subsubsection.A.14.1.1}%
\contentsline {subsubsection}{\numberline {A.14.1.2}Detailed Description of the \texttt {"train\_cv"} Setting}{304}{subsubsection.A.14.1.2}%
\contentsline {subsubsection}{\numberline {A.14.1.3}Detailed Description of the \texttt {"test\_cv"} Setting}{308}{subsubsection.A.14.1.3}%
\contentsline {subsubsection}{\numberline {A.14.1.4}Detailed Description of the Final Model Training and Evaluation}{308}{subsubsection.A.14.1.4}%
\contentsline {chapter}{References}{311}{chapter*.177}%
\providecommand \tocbasic@end@toc@file {}\tocbasic@end@toc@file 
