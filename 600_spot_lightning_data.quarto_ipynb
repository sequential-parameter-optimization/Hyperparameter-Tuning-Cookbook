{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8565bb4d",
   "metadata": {},
   "source": [
    "---\n",
    "execute:\n",
    "  cache: false\n",
    "  eval: true\n",
    "  echo: true\n",
    "  warning: false\n",
    "---\n",
    "\n",
    "\n",
    "# HPT PyTorch Lightning: Data {#sec-hpt-pytorch-lightning-data-30}\n",
    "\n",
    "In this tutorial, we will show how `spotpython` can be integrated into the `PyTorch` Lightning\n",
    "training workflow. \n",
    "\n",
    "This chapter describes the data preparation and processing in `spotpython`. The Diabetes data set is used as an example. This is a PyTorch Dataset for regression. A toy data set from scikit-learn. Ten baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements were obtained for each of n = 442 diabetes patients,  as well as the response of interest, a quantitative measure of disease progression one year after baseline.\n",
    "\n",
    "\n",
    "## Setup {#sec-setup-30}\n",
    "\n",
    "* Before we consider the detailed experimental setup, we select the parameters that affect run time, initial design size, etc. \n",
    "* The parameter `WORKERS` specifies the number of workers. \n",
    "* The prefix `PREFIX` is used for the experiment name and the name of the log file.\n",
    "* The parameter `DEVICE` specifies the device to use for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e4abc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from spotpython.utils.device import getDevice\n",
    "from math import inf\n",
    "WORKERS = 0\n",
    "PREFIX=\"030\"\n",
    "DEVICE = getDevice()\n",
    "DEVICES = 1\n",
    "TEST_SIZE = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a85bf0",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "### Note: Device selection\n",
    "\n",
    "* Although there are no .cuda() or .to(device) calls required, because Lightning does these for you, see \n",
    "[LIGHTNINGMODULE](https://lightning.ai/docs/pytorch/stable/common/lightning_module.html), we would like to know which device is used. Threrefore, we imitate the LightningModule behaviour which selects the highest device. \n",
    "* The method `spotpython.utils.device.getDevice()` returns the device that is used by Lightning.\n",
    ":::\n",
    "\n",
    "\n",
    "## Initialization of the `fun_control` Dictionary\n",
    "\n",
    "`spotpython` uses a Python dictionary for storing the information required for the hyperparameter tuning process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55949c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 123\n"
     ]
    }
   ],
   "source": [
    "from spotpython.utils.init import fun_control_init\n",
    "import numpy as np\n",
    "fun_control = fun_control_init(\n",
    "    _L_in=10,\n",
    "    _L_out=1,\n",
    "    _torchmetric=\"mean_squared_error\",\n",
    "    PREFIX=PREFIX,\n",
    "    device=DEVICE,\n",
    "    enable_progress_bar=False,\n",
    "    num_workers=WORKERS,\n",
    "    show_progress=True,\n",
    "    test_size=TEST_SIZE,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61913010",
   "metadata": {},
   "source": [
    "## Loading the Diabetes Data Set\n",
    "\n",
    "Here, we load the Diabetes data set from `spotpython`'s `data` module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90a0811a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442\n"
     ]
    }
   ],
   "source": [
    "from spotpython.data.diabetes import Diabetes\n",
    "dataset = Diabetes(target_type=torch.float)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0d1df3",
   "metadata": {},
   "source": [
    "### Data Set and Data Loader\n",
    "\n",
    "As shown below, a DataLoader from `torch.utils.data` can be used to check the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c25d2f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size: 5\n",
      "Inputs Shape: torch.Size([5, 10])\n",
      "Targets Shape: torch.Size([5])\n",
      "---------------\n",
      "Inputs: tensor([[ 0.0381,  0.0507,  0.0617,  0.0219, -0.0442, -0.0348, -0.0434, -0.0026,\n",
      "          0.0199, -0.0176],\n",
      "        [-0.0019, -0.0446, -0.0515, -0.0263, -0.0084, -0.0192,  0.0744, -0.0395,\n",
      "         -0.0683, -0.0922],\n",
      "        [ 0.0853,  0.0507,  0.0445, -0.0057, -0.0456, -0.0342, -0.0324, -0.0026,\n",
      "          0.0029, -0.0259],\n",
      "        [-0.0891, -0.0446, -0.0116, -0.0367,  0.0122,  0.0250, -0.0360,  0.0343,\n",
      "          0.0227, -0.0094],\n",
      "        [ 0.0054, -0.0446, -0.0364,  0.0219,  0.0039,  0.0156,  0.0081, -0.0026,\n",
      "         -0.0320, -0.0466]])\n",
      "Targets: tensor([151.,  75., 141., 206., 135.])\n"
     ]
    }
   ],
   "source": [
    "# Set batch size for DataLoader\n",
    "batch_size = 5\n",
    "# Create DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Iterate over the data in the DataLoader\n",
    "for batch in dataloader:\n",
    "    inputs, targets = batch\n",
    "    print(f\"Batch Size: {inputs.size(0)}\")\n",
    "    print(f\"Inputs Shape: {inputs.shape}\")\n",
    "    print(f\"Targets Shape: {targets.shape}\")\n",
    "    print(\"---------------\")\n",
    "    print(f\"Inputs: {inputs}\")\n",
    "    print(f\"Targets: {targets}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f9df80",
   "metadata": {},
   "source": [
    "### Preparing Training, Validation, and Test Data\n",
    "\n",
    "The following code shows how to split the data into training, validation, and test sets.\n",
    "Then a Lightning Trainer is used to train (`fit`) the model, validate it, and test it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff9c7429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spot312/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spot312/lib/python3.12/site-packages/lightning/pytorch/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "\n",
      "  | Name   | Type       | Params | Mode  | In sizes | Out sizes\n",
      "---------------------------------------------------------------------\n",
      "0 | layers | Sequential | 15.9 K | train | [8, 10]  | [8, 1]   \n",
      "---------------------------------------------------------------------\n",
      "15.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.9 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spot312/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/Users/bartz/miniforge3/envs/spot312/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (20) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_x.shape: torch.Size([8, 10])\n",
      "batch_y.shape: torch.Size([8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spot312/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      32421.490234375      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      32421.490234375      </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     32421.490234375     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     32421.490234375     \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spot312/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       25781.0234375       </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       25781.0234375       </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      25781.0234375      \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      25781.0234375      \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 25781.0234375, 'hp_metric': 25781.0234375}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from spotpython.data.diabetes import Diabetes\n",
    "from spotpython.light.regression.netlightregression import NetLightRegression\n",
    "from torch import nn\n",
    "import lightning as L\n",
    "import torch\n",
    "BATCH_SIZE = 8\n",
    "dataset = Diabetes(target_type=torch.float)\n",
    "train1_set, test_set = torch.utils.data.random_split(dataset, [0.6, 0.4])\n",
    "train_set, val_set = torch.utils.data.random_split(train1_set, [0.6, 0.4])\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, pin_memory=True)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE)\n",
    "batch_x, batch_y = next(iter(train_loader))\n",
    "print(f\"batch_x.shape: {batch_x.shape}\")\n",
    "print(f\"batch_y.shape: {batch_y.shape}\")\n",
    "net_light_base = NetLightRegression(l1=128,\n",
    "                                    epochs=10,\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    initialization='Default',\n",
    "                                    act_fn=nn.ReLU(),\n",
    "                                    optimizer='Adam',\n",
    "                                    dropout_prob=0.1,\n",
    "                                    lr_mult=0.1,\n",
    "                                    patience=5,\n",
    "                                    _L_in=10,\n",
    "                                    _L_out=1,\n",
    "                                    _torchmetric=\"mean_squared_error\")\n",
    "trainer = L.Trainer(max_epochs=10,  enable_progress_bar=False)\n",
    "trainer.fit(net_light_base, train_loader)\n",
    "trainer.validate(net_light_base, val_loader)\n",
    "trainer.test(net_light_base, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd34af3",
   "metadata": {},
   "source": [
    "### Dataset for spotpython\n",
    "\n",
    "`spotpython` handles the data set, which is added to the `fun_control` dictionary with the key `data_set` as follows: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50c8e345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442\n"
     ]
    }
   ],
   "source": [
    "from spotpython.hyperparameters.values import set_control_key_value\n",
    "from spotpython.data.diabetes import Diabetes\n",
    "dataset = Diabetes(target_type=torch.float)\n",
    "set_control_key_value(control_dict=fun_control,\n",
    "                        key=\"data_set\",\n",
    "                        value=dataset,\n",
    "                        replace=True)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda29c80",
   "metadata": {},
   "source": [
    "If the data set is in the `fun_control` dictionary, it is used to create a `LightDataModule` object. This object is used to create the data loaders for the training, validation, and test sets.\n",
    "Therefore, the following information must be provided in the `fun_control` dictionary:\n",
    "\n",
    "* `data_set`: the data set\n",
    "* `batch_size`: the batch size\n",
    "* `num_workers`: the number of workers\n",
    "* `test_size`: the size of the test set\n",
    "* `test_seed`: the seed for the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41f0c9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 123\n"
     ]
    }
   ],
   "source": [
    "from spotpython.utils.init import fun_control_init\n",
    "import numpy as np\n",
    "fun_control = fun_control_init(\n",
    "    data_set=dataset,\n",
    "    device=\"cpu\",\n",
    "    enable_progress_bar=False,\n",
    "    num_workers=0,\n",
    "    show_progress=True,\n",
    "    test_size=0.4,\n",
    "    test_seed=42,    \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ead17946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model(): Test set size: 177\n",
      "train_model(): Train set size: 160\n"
     ]
    }
   ],
   "source": [
    "from spotpython.data.lightdatamodule import LightDataModule\n",
    "dm = LightDataModule(\n",
    "    dataset=fun_control[\"data_set\"],\n",
    "    batch_size=8,\n",
    "    num_workers=fun_control[\"num_workers\"],\n",
    "    test_size=fun_control[\"test_size\"],\n",
    "    test_seed=fun_control[\"test_seed\"],\n",
    ")\n",
    "dm.setup()\n",
    "print(f\"train_model(): Test set size: {len(dm.data_test)}\")\n",
    "print(f\"train_model(): Train set size: {len(dm.data_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a601bd5e",
   "metadata": {},
   "source": [
    "## The LightDataModule\n",
    "\n",
    "The steps described above are handled by the `LightDataModule` class. This class is used to create the data loaders for the training, validation, and test sets. The `LightDataModule` class is part of the `spotpython` package.\n",
    "The `LightDataModule` class provides the following methods:\n",
    "\n",
    "* `prepare_data()`: This method is used to prepare the data set.\n",
    "* `setup()`: This method is used to create the data loaders for the training, validation, and test sets.\n",
    "* `train_dataloader()`: This method is used to return the data loader for the training set.\n",
    "* `val_dataloader()`: This method is used to return the data loader for the validation set.\n",
    "* `test_dataloader()`: This method is used to return the data loader for the test set.\n",
    "* `predict_dataloader()`: This method is used to return the data loader for the prediction set.\n",
    "\n",
    "### The `prepare_data()` Method\n",
    "\n",
    "The `prepare_data()` method is used to prepare the data set. This method is called only once and on a single process. It can be used to download the data set. In our case, the data set is already available, so this method uses a simple `pass` statement.\n",
    "\n",
    "### The `setup()` Method\n",
    "\n",
    "Splits the data for use in training, validation, and testing. It uses `torch.utils.data.random_split()` to split the data.\n",
    "Splitting is based on the `test_size` and `test_seed`. \n",
    "The `test_size` can be a float or an int.\n",
    "\n",
    "#### Determine the Sizes of the Data Sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "139040a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule setup(): full_train_size: 0.6\n",
      "LightDataModule setup(): val_size: 0.24\n",
      "LightDataModule setup(): train_size: 0.36\n",
      "LightDataModule setup(): test_size: 0.4\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "data_full = dataset\n",
    "test_size = fun_control[\"test_size\"]\n",
    "test_seed=fun_control[\"test_seed\"]\n",
    "# if test_size is float, then train_size is 1 - test_size\n",
    "if isinstance(test_size, float):\n",
    "    full_train_size = round(1.0 - test_size, 2)\n",
    "    val_size = round(full_train_size * test_size, 2)\n",
    "    train_size = round(full_train_size - val_size, 2)\n",
    "else:\n",
    "    # if test_size is int, then train_size is len(data_full) - test_size\n",
    "    full_train_size = len(data_full) - test_size\n",
    "    val_size = int(full_train_size * test_size / len(data_full))\n",
    "    train_size = full_train_size - val_size\n",
    "\n",
    "print(f\"LightDataModule setup(): full_train_size: {full_train_size}\")\n",
    "print(f\"LightDataModule setup(): val_size: {val_size}\")\n",
    "print(f\"LightDataModule setup(): train_size: {train_size}\")\n",
    "print(f\"LightDataModule setup(): test_size: {test_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce8c2ac",
   "metadata": {},
   "source": [
    "`stage` is used to define the data set to be returned.\n",
    "The `stage` can be `None`, `fit`, `test`, or `predict`.\n",
    "If `stage` is `None`, the method returns the training (`fit`), testing (`test`) and prediction (`predict`) data sets.\n",
    "\n",
    "#### Stage \"fit\" {#sec-stage-fit-30}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcf01fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule setup(): Train set size: 160\n",
      "LightDataModule setup(): Validation set size: 106\n"
     ]
    }
   ],
   "source": [
    "stage = \"fit\"\n",
    "if stage == \"fit\" or stage is None:\n",
    "    generator_fit = torch.Generator().manual_seed(test_seed)\n",
    "    data_train, data_val, _ = random_split(data_full, [train_size, val_size, test_size], generator=generator_fit)\n",
    "print(f\"LightDataModule setup(): Train set size: {len(data_train)}\")\n",
    "print(f\"LightDataModule setup(): Validation set size: {len(data_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103d019b",
   "metadata": {},
   "source": [
    "#### Stage \"test\" {#sec-stage-test-30}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11fb905e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule setup(): Test set size: 177\n",
      "Batch Size: 5\n",
      "Inputs Shape: torch.Size([5, 10])\n",
      "Targets Shape: torch.Size([5])\n",
      "---------------\n",
      "Inputs: tensor([[ 0.0562, -0.0446, -0.0579, -0.0080,  0.0521,  0.0491,  0.0560, -0.0214,\n",
      "         -0.0283,  0.0445],\n",
      "        [ 0.0018, -0.0446, -0.0709, -0.0229, -0.0016, -0.0010,  0.0266, -0.0395,\n",
      "         -0.0225,  0.0072],\n",
      "        [-0.0527, -0.0446,  0.0542, -0.0263, -0.0552, -0.0339, -0.0139, -0.0395,\n",
      "         -0.0741, -0.0591],\n",
      "        [ 0.0054, -0.0446, -0.0482, -0.0126,  0.0012, -0.0066,  0.0634, -0.0395,\n",
      "         -0.0514, -0.0591],\n",
      "        [-0.0527, -0.0446, -0.0094, -0.0057,  0.0397,  0.0447,  0.0266, -0.0026,\n",
      "         -0.0181, -0.0135]])\n",
      "Targets: tensor([158.,  49., 142.,  96.,  59.])\n"
     ]
    }
   ],
   "source": [
    "stage = \"test\"\n",
    "if stage == \"test\" or stage is None:\n",
    "    generator_test = torch.Generator().manual_seed(test_seed)\n",
    "    data_test, _ = random_split(data_full, [test_size, full_train_size], generator=generator_test)\n",
    "print(f\"LightDataModule setup(): Test set size: {len(data_test)}\")\n",
    "# Set batch size for DataLoader\n",
    "batch_size = 5\n",
    "# Create DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(data_test, batch_size=batch_size, shuffle=False)\n",
    "# Iterate over the data in the DataLoader\n",
    "for batch in dataloader:\n",
    "    inputs, targets = batch\n",
    "    print(f\"Batch Size: {inputs.size(0)}\")\n",
    "    print(f\"Inputs Shape: {inputs.shape}\")\n",
    "    print(f\"Targets Shape: {targets.shape}\")\n",
    "    print(\"---------------\")\n",
    "    print(f\"Inputs: {inputs}\")\n",
    "    print(f\"Targets: {targets}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feae118",
   "metadata": {},
   "source": [
    "#### Stage \"predict\" {#sec-stage-predict-30}\n",
    "\n",
    "Prediction and testing use the same data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41bc77dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule setup(): Predict set size: 177\n",
      "Batch Size: 5\n",
      "Inputs Shape: torch.Size([5, 10])\n",
      "Targets Shape: torch.Size([5])\n",
      "---------------\n",
      "Inputs: tensor([[ 0.0562, -0.0446, -0.0579, -0.0080,  0.0521,  0.0491,  0.0560, -0.0214,\n",
      "         -0.0283,  0.0445],\n",
      "        [ 0.0018, -0.0446, -0.0709, -0.0229, -0.0016, -0.0010,  0.0266, -0.0395,\n",
      "         -0.0225,  0.0072],\n",
      "        [-0.0527, -0.0446,  0.0542, -0.0263, -0.0552, -0.0339, -0.0139, -0.0395,\n",
      "         -0.0741, -0.0591],\n",
      "        [ 0.0054, -0.0446, -0.0482, -0.0126,  0.0012, -0.0066,  0.0634, -0.0395,\n",
      "         -0.0514, -0.0591],\n",
      "        [-0.0527, -0.0446, -0.0094, -0.0057,  0.0397,  0.0447,  0.0266, -0.0026,\n",
      "         -0.0181, -0.0135]])\n",
      "Targets: tensor([158.,  49., 142.,  96.,  59.])\n"
     ]
    }
   ],
   "source": [
    "stage = \"predict\"\n",
    "if stage == \"predict\" or stage is None:\n",
    "    generator_predict = torch.Generator().manual_seed(test_seed)\n",
    "    data_predict, _ = random_split(\n",
    "        data_full, [test_size, full_train_size], generator=generator_predict\n",
    "    )\n",
    "print(f\"LightDataModule setup(): Predict set size: {len(data_predict)}\")\n",
    "# Set batch size for DataLoader\n",
    "batch_size = 5\n",
    "# Create DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(data_predict, batch_size=batch_size, shuffle=False)\n",
    "# Iterate over the data in the DataLoader\n",
    "for batch in dataloader:\n",
    "    inputs, targets = batch\n",
    "    print(f\"Batch Size: {inputs.size(0)}\")\n",
    "    print(f\"Inputs Shape: {inputs.shape}\")\n",
    "    print(f\"Targets Shape: {targets.shape}\")\n",
    "    print(\"---------------\")\n",
    "    print(f\"Inputs: {inputs}\")\n",
    "    print(f\"Targets: {targets}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09e4a8d",
   "metadata": {},
   "source": [
    "### The `train_dataloader()` Method\n",
    "\n",
    "Returns the training dataloader, i.e., a Pytorch DataLoader instance using the training dataset.\n",
    "It simply returns a DataLoader with the `data_train` set that was created in the `setup()` method as described in @sec-stage-fit-30.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85049677",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "def train_dataloader(self) -> DataLoader:\n",
    "    return DataLoader(self.data_train, batch_size=self.batch_size, num_workers=self.num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9d19cd",
   "metadata": {},
   "source": [
    "The `train_dataloader()` method can be used as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8ef37b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 160\n",
      "Batch Size: 5\n",
      "Inputs Shape: torch.Size([5, 10])\n",
      "Targets Shape: torch.Size([5])\n",
      "---------------\n",
      "Inputs: tensor([[ 0.0562, -0.0446, -0.0579, -0.0080,  0.0521,  0.0491,  0.0560, -0.0214,\n",
      "         -0.0283,  0.0445],\n",
      "        [ 0.0018, -0.0446, -0.0709, -0.0229, -0.0016, -0.0010,  0.0266, -0.0395,\n",
      "         -0.0225,  0.0072],\n",
      "        [-0.0527, -0.0446,  0.0542, -0.0263, -0.0552, -0.0339, -0.0139, -0.0395,\n",
      "         -0.0741, -0.0591],\n",
      "        [ 0.0054, -0.0446, -0.0482, -0.0126,  0.0012, -0.0066,  0.0634, -0.0395,\n",
      "         -0.0514, -0.0591],\n",
      "        [-0.0527, -0.0446, -0.0094, -0.0057,  0.0397,  0.0447,  0.0266, -0.0026,\n",
      "         -0.0181, -0.0135]])\n",
      "Targets: tensor([158.,  49., 142.,  96.,  59.])\n"
     ]
    }
   ],
   "source": [
    "from spotpython.data.lightdatamodule import LightDataModule\n",
    "from spotpython.data.diabetes import Diabetes\n",
    "dataset = Diabetes(target_type=torch.float)\n",
    "data_module = LightDataModule(dataset=dataset, batch_size=5, test_size=0.4)\n",
    "data_module.setup()\n",
    "print(f\"Training set size: {len(data_module.data_train)}\")\n",
    "dl = data_module.train_dataloader()\n",
    "# Iterate over the data in the DataLoader\n",
    "for batch in dl:\n",
    "    inputs, targets = batch\n",
    "    print(f\"Batch Size: {inputs.size(0)}\")\n",
    "    print(f\"Inputs Shape: {inputs.shape}\")\n",
    "    print(f\"Targets Shape: {targets.shape}\")\n",
    "    print(\"---------------\")\n",
    "    print(f\"Inputs: {inputs}\")\n",
    "    print(f\"Targets: {targets}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c07e66b",
   "metadata": {},
   "source": [
    "### The `val_dataloader()` Method\n",
    "\n",
    "Returns the validation dataloader, i.e., a Pytorch DataLoader instance using the validation dataset.\n",
    "It simply returns a DataLoader with the `data_val` set that was created in the `setup()` method as desccribed in @sec-stage-fit-30.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33acc0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "def val_dataloader(self) -> DataLoader:\n",
    "    return DataLoader(self.data_val, batch_size=self.batch_size, num_workers=self.num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bf713b",
   "metadata": {},
   "source": [
    "The `val_dataloader()` method can be used as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ba778ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set size: 106\n",
      "Batch Size: 5\n",
      "Inputs Shape: torch.Size([5, 10])\n",
      "Targets Shape: torch.Size([5])\n",
      "---------------\n",
      "Inputs: tensor([[ 0.0163, -0.0446,  0.0736, -0.0412, -0.0043, -0.0135, -0.0139, -0.0011,\n",
      "          0.0429,  0.0445],\n",
      "        [ 0.0453, -0.0446,  0.0714,  0.0012, -0.0098, -0.0010,  0.0155, -0.0395,\n",
      "         -0.0412, -0.0715],\n",
      "        [ 0.0308,  0.0507,  0.0326,  0.0494, -0.0401, -0.0436, -0.0692,  0.0343,\n",
      "          0.0630,  0.0031],\n",
      "        [ 0.0235,  0.0507, -0.0396, -0.0057, -0.0484, -0.0333,  0.0118, -0.0395,\n",
      "         -0.1016, -0.0674],\n",
      "        [-0.0091,  0.0507,  0.0013, -0.0022,  0.0796,  0.0701,  0.0339, -0.0026,\n",
      "          0.0267,  0.0818]])\n",
      "Targets: tensor([275., 141., 208.,  78., 142.])\n"
     ]
    }
   ],
   "source": [
    "from spotpython.data.lightdatamodule import LightDataModule\n",
    "from spotpython.data.diabetes import Diabetes\n",
    "dataset = Diabetes(target_type=torch.float)\n",
    "data_module = LightDataModule(dataset=dataset, batch_size=5, test_size=0.4)\n",
    "data_module.setup()\n",
    "print(f\"Validation set size: {len(data_module.data_val)}\")\n",
    "dl = data_module.val_dataloader()\n",
    "# Iterate over the data in the DataLoader\n",
    "for batch in dl:\n",
    "    inputs, targets = batch\n",
    "    print(f\"Batch Size: {inputs.size(0)}\")\n",
    "    print(f\"Inputs Shape: {inputs.shape}\")\n",
    "    print(f\"Targets Shape: {targets.shape}\")\n",
    "    print(\"---------------\")\n",
    "    print(f\"Inputs: {inputs}\")\n",
    "    print(f\"Targets: {targets}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf078f3",
   "metadata": {},
   "source": [
    "### The `test_dataloader()` Method\n",
    "\n",
    "Returns the test dataloader, i.e., a Pytorch DataLoader instance using the test dataset.\n",
    "It simply returns a DataLoader with the `data_test` set that was created in the `setup()` method as described in @sec-stage-test-30.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79ca3cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "def test_dataloader(self) -> DataLoader:\n",
    "    return DataLoader(self.data_test, batch_size=self.batch_size, num_workers=self.num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede5111a",
   "metadata": {},
   "source": [
    "The `test_dataloader()` method can be used as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bb061bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set size: 177\n",
      "Batch Size: 5\n",
      "Inputs Shape: torch.Size([5, 10])\n",
      "Targets Shape: torch.Size([5])\n",
      "---------------\n",
      "Inputs: tensor([[ 0.0562, -0.0446, -0.0579, -0.0080,  0.0521,  0.0491,  0.0560, -0.0214,\n",
      "         -0.0283,  0.0445],\n",
      "        [ 0.0018, -0.0446, -0.0709, -0.0229, -0.0016, -0.0010,  0.0266, -0.0395,\n",
      "         -0.0225,  0.0072],\n",
      "        [-0.0527, -0.0446,  0.0542, -0.0263, -0.0552, -0.0339, -0.0139, -0.0395,\n",
      "         -0.0741, -0.0591],\n",
      "        [ 0.0054, -0.0446, -0.0482, -0.0126,  0.0012, -0.0066,  0.0634, -0.0395,\n",
      "         -0.0514, -0.0591],\n",
      "        [-0.0527, -0.0446, -0.0094, -0.0057,  0.0397,  0.0447,  0.0266, -0.0026,\n",
      "         -0.0181, -0.0135]])\n",
      "Targets: tensor([158.,  49., 142.,  96.,  59.])\n"
     ]
    }
   ],
   "source": [
    "from spotpython.data.lightdatamodule import LightDataModule\n",
    "from spotpython.data.diabetes import Diabetes\n",
    "dataset = Diabetes(target_type=torch.float)\n",
    "data_module = LightDataModule(dataset=dataset, batch_size=5, test_size=0.4)\n",
    "data_module.setup()\n",
    "print(f\"Test set size: {len(data_module.data_test)}\")\n",
    "dl = data_module.test_dataloader()\n",
    "# Iterate over the data in the DataLoader\n",
    "for batch in dl:\n",
    "    inputs, targets = batch\n",
    "    print(f\"Batch Size: {inputs.size(0)}\")\n",
    "    print(f\"Inputs Shape: {inputs.shape}\")\n",
    "    print(f\"Targets Shape: {targets.shape}\")\n",
    "    print(\"---------------\")\n",
    "    print(f\"Inputs: {inputs}\")\n",
    "    print(f\"Targets: {targets}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994a6069",
   "metadata": {},
   "source": [
    "### The `predict_dataloader()` Method\n",
    "\n",
    "Returns the prediction dataloader, i.e., a Pytorch DataLoader instance using the prediction dataset.\n",
    "It simply returns a DataLoader with the `data_predict` set that was created in the `setup()` method as described in @sec-stage-predict-30.\n",
    "\n",
    "::: {.callout-warning}\n",
    "The `batch_size` is set to the length of the `data_predict` set.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bea77ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "def predict_dataloader(self) -> DataLoader:\n",
    "    return DataLoader(self.data_predict, batch_size=len(self.data_predict), num_workers=self.num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e868e71e",
   "metadata": {},
   "source": [
    "The `predict_dataloader()` method can be used as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64c6f22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set size: 177\n",
      "Batch Size: 177\n",
      "Inputs Shape: torch.Size([177, 10])\n",
      "Targets Shape: torch.Size([177])\n",
      "---------------\n",
      "Inputs: tensor([[ 0.0562, -0.0446, -0.0579,  ..., -0.0214, -0.0283,  0.0445],\n",
      "        [ 0.0018, -0.0446, -0.0709,  ..., -0.0395, -0.0225,  0.0072],\n",
      "        [-0.0527, -0.0446,  0.0542,  ..., -0.0395, -0.0741, -0.0591],\n",
      "        ...,\n",
      "        [ 0.0090, -0.0446, -0.0321,  ..., -0.0764, -0.0119, -0.0384],\n",
      "        [-0.0273, -0.0446, -0.0666,  ..., -0.0395, -0.0358, -0.0094],\n",
      "        [ 0.0817,  0.0507,  0.0067,  ...,  0.0919,  0.0547,  0.0072]])\n",
      "Targets: tensor([158.,  49., 142.,  96.,  59.,  74., 137., 136.,  39.,  66., 310., 198.,\n",
      "        235., 116.,  55., 177.,  59., 246.,  53., 135.,  88., 198., 186., 217.,\n",
      "         51., 118., 153., 180.,  51., 229.,  84.,  72., 237., 142., 185.,  91.,\n",
      "         88., 148., 179., 144.,  25.,  89.,  42.,  60., 124., 170., 215., 263.,\n",
      "        178., 245., 202.,  97., 321.,  71., 123., 220., 132., 243.,  61., 102.,\n",
      "        187.,  70., 242., 134.,  63.,  72.,  88., 219., 127., 146., 122., 143.,\n",
      "        220., 293.,  59., 317.,  60., 140.,  65., 277.,  90.,  96., 109., 190.,\n",
      "         90.,  52., 160., 233., 230., 175.,  68., 272., 144.,  70.,  68., 163.,\n",
      "         71.,  93., 263., 118., 220.,  90., 232., 120., 163.,  88.,  85.,  52.,\n",
      "        181., 232., 212., 332.,  81., 214., 145., 268., 115.,  93.,  64., 156.,\n",
      "        128., 200., 281., 103., 220.,  66.,  48., 246.,  42., 150., 125., 109.,\n",
      "        129.,  97., 265.,  97., 173., 216., 237., 121.,  42., 151.,  31.,  68.,\n",
      "        137., 221., 283., 124., 243., 150.,  69., 306., 182., 252., 132., 258.,\n",
      "        121., 110., 292., 101., 275., 141., 208.,  78., 142., 185., 167., 258.,\n",
      "        144.,  89., 225., 140., 303., 236.,  87.,  77., 131.])\n"
     ]
    }
   ],
   "source": [
    "from spotpython.data.lightdatamodule import LightDataModule\n",
    "from spotpython.data.diabetes import Diabetes\n",
    "dataset = Diabetes(target_type=torch.float)\n",
    "data_module = LightDataModule(dataset=dataset, batch_size=5, test_size=0.4)\n",
    "data_module.setup()\n",
    "print(f\"Test set size: {len(data_module.data_predict)}\")\n",
    "dl = data_module.predict_dataloader()\n",
    "# Iterate over the data in the DataLoader\n",
    "for batch in dl:\n",
    "    inputs, targets = batch\n",
    "    print(f\"Batch Size: {inputs.size(0)}\")\n",
    "    print(f\"Inputs Shape: {inputs.shape}\")\n",
    "    print(f\"Targets Shape: {targets.shape}\")\n",
    "    print(\"---------------\")\n",
    "    print(f\"Inputs: {inputs}\")\n",
    "    print(f\"Targets: {targets}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24421d1b",
   "metadata": {},
   "source": [
    "## Using the `LightDataModule` in the `train_model()` Method\n",
    "\n",
    "First, a `LightDataModule` object is created and the `setup()` method is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9b22cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "dm = LightDataModule(\n",
    "    dataset=fun_control[\"data_set\"],\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    num_workers=fun_control[\"num_workers\"],\n",
    "    test_size=fun_control[\"test_size\"],\n",
    "    test_seed=fun_control[\"test_seed\"],\n",
    ")\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d116096",
   "metadata": {},
   "source": [
    "Then, the `Trainer` is initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc3b5045",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# Init trainer\n",
    "trainer = L.Trainer(\n",
    "    default_root_dir=os.path.join(fun_control[\"CHECKPOINT_PATH\"], config_id),\n",
    "    max_epochs=model.hparams.epochs,\n",
    "    accelerator=fun_control[\"accelerator\"],\n",
    "    devices=fun_control[\"devices\"],\n",
    "    logger=TensorBoardLogger(\n",
    "        save_dir=fun_control[\"TENSORBOARD_PATH\"],\n",
    "        version=config_id,\n",
    "        default_hp_metric=True,\n",
    "        log_graph=fun_control[\"log_graph\"],\n",
    "    ),\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor=\"val_loss\", patience=config[\"patience\"], mode=\"min\", strict=False, verbose=False)\n",
    "    ],\n",
    "    enable_progress_bar=enable_progress_bar,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e46b01",
   "metadata": {},
   "source": [
    "Next, the `fit()` method is called to train the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b22e74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# Pass the datamodule as arg to trainer.fit to override model hooks :)\n",
    "trainer.fit(model=model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef5c4b1",
   "metadata": {},
   "source": [
    "Finally, the `validate()` method is called to validate the model.\n",
    "The `validate()` method returns the validation loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "623d64b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# Test best model on validation and test set\n",
    "# result = trainer.validate(model=model, datamodule=dm, ckpt_path=\"last\")\n",
    "result = trainer.validate(model=model, datamodule=dm)\n",
    "# unlist the result (from a list of one dict)\n",
    "result = result[0]\n",
    "return result[\"val_loss\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af81cc26",
   "metadata": {},
   "source": [
    "## Further Information \n",
    "\n",
    "### Preprocessing {#sec-preprocessing-30}\n",
    "\n",
    "Preprocessing is handled by `Lightning` and `PyTorch`. It is described in the [LIGHTNINGDATAMODULE](https://lightning.ai/docs/pytorch/stable/data/datamodule.html) documentation. Here you can find information about the `transforms` methods.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3",
   "path": "/Users/bartz/miniforge3/envs/spot312/share/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
