act_fn: !!python/object:spotPython.torch.activation.LeakyReLU
  _backward_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _buffers: !!python/object/apply:collections.OrderedDict
  - []
  _forward_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _forward_pre_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _is_full_backward_hook: null
  _load_state_dict_post_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _load_state_dict_pre_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _modules: !!python/object/apply:collections.OrderedDict
  - []
  _non_persistent_buffers_set: !!set {}
  _parameters: !!python/object/apply:collections.OrderedDict
  - []
  _state_dict_hooks: !!python/object/apply:collections.OrderedDict
  - []
  config:
    alpha: 0.1
    name: LeakyReLU
  name: LeakyReLU
  training: true
batch_size: 256
dropout_prob: !!python/object/apply:numpy.core.multiarray.scalar
- &id001 !!python/object/apply:numpy.dtype
  args:
  - f8
  - false
  - true
  state: !!python/tuple
  - 3
  - <
  - null
  - null
  - null
  - -1
  - -1
  - 0
- !!binary |
  8HQ8Pkl5ij8=
epochs: 128
initialization: Kaiming
l1: 32
lr_mult: !!python/object/apply:numpy.core.multiarray.scalar
- *id001
- !!binary |
  9aUdDKGl6j8=
optimizer: Adamax
patience: 8
