{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "execute:\n",
        "  cache: false\n",
        "  eval: true\n",
        "  echo: true\n",
        "  warning: false\n",
        "jupyter: python3\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: false\n",
        "import os\n",
        "import numpy as np\n",
        "from math import inf\n",
        "import warnings\n",
        "if not os.path.exists('./figures'):\n",
        "    os.makedirs('./figures')\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This chapter demonstrates hyperparameter tuning for `river`'s `Mondrian Tree Regressor` [[SOURCE]](https://riverml.xyz/latest/api/forest/AMFRegressor/) with the Friedman drift data set [[SOURCE]](https://riverml.xyz/0.18.0/api/datasets/synth/FriedmanDrift/). The `Mondrian Tree Regressor` is a regression tree, i.e., it predicts a real value for each sample.\n",
        "\n",
        "## The Friedman Drift Data Set {#sec-the-friedman-drift-data-set-25}\n",
        "\n",
        "The data set was introduced in @sec-the-friedman-drift-data-set-24."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: 503_data_set\n",
        "\n",
        "from river.datasets import synth\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from spotriver.utils.data_conversion import convert_to_df\n",
        "\n",
        "n_train = 6_000\n",
        "n_test = 4_000\n",
        "n_samples = n_train + n_test\n",
        "target_column = \"y\"\n",
        "\n",
        "dataset = synth.FriedmanDrift(\n",
        "   drift_type='gra',\n",
        "   position=(n_train/4, n_train/2),\n",
        "   seed=123\n",
        ")\n",
        "\n",
        "train = convert_to_df(dataset, n_total=n_train)\n",
        "train.columns = [f\"x{i}\" for i in range(1, 11)] + [target_column]\n",
        "\n",
        "dataset = synth.FriedmanDrift(\n",
        "   drift_type='gra',\n",
        "   position=(n_test/4, n_test/2),\n",
        "   seed=123\n",
        ")\n",
        "test = convert_to_df(dataset, n_total=n_test)\n",
        "test.columns = [f\"x{i}\" for i in range(1, 11)] + [target_column]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "We will use a general experiment, data, evaluation, river-specific, objective-function, and surrogate setup  similar to the setup from @sec-setup-24.\n",
        "Only the model setup differs from the setup in @sec-setup-24. Here we use the `Mondrian Tree Regressor` from `river`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: 503_model_setup\n",
        "from spotriver.hyperdict.river_hyper_dict import RiverHyperDict\n",
        "core_model_name = \"forest.AMFRegressor\"\n",
        "hyperdict = RiverHyperDict\n",
        "hyperdict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Select a User Hyperdictionary\n",
        "\n",
        "Alternatively, you can load a local hyper_dict from the \"userModel\" folder. Here, we have selected a copy of the JSON `MondrianHyperDict` hyperdictionary from [[SOURCE]](https://github.com/sequential-parameter-optimization/Hyperparameter-Tuning-Cookbook/blob/main/userModel/mondrian_hyper_dict.json) and the `MondrianHyperDict` class from [[SOURCE]](https://github.com/sequential-parameter-optimization/Hyperparameter-Tuning-Cookbook/blob/main/userModel/mondrian_hyper_dict.py).\n",
        "The hyperparameters of the `Mondrian Tree Regressor` are defined in the `MondrianHyperDict` class, i.e., there is an key \"AMFRegressor\" in the `hyperdict` \"[mondrian_hyper_dict.json](https://github.com/sequential-parameter-optimization/Hyperparameter-Tuning-Cookbook/blob/main/userModel/mondrian_hyper_dict.json)\" file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: 503_hyperdict_from_user_model\n",
        "import sys\n",
        "sys.path.insert(0, './userModel')\n",
        "import mondrian_hyper_dict\n",
        "hyperdict = mondrian_hyper_dict.MondrianHyperDict\n",
        "hyperdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: 503_summary_control\n",
        "from spotpython.utils.init import fun_control_init, design_control_init, surrogate_control_init, optimizer_control_init\n",
        "from spotriver.fun.hyperriver import HyperRiver\n",
        "\n",
        "fun = HyperRiver().fun_oml_horizon\n",
        "\n",
        "fun_control = fun_control_init(\n",
        "    PREFIX=\"503\",\n",
        "    fun_evals=inf,\n",
        "    max_time=1,\n",
        "\n",
        "    prep_model_name=\"StandardScaler\",\n",
        "    test=test,\n",
        "    train=train,\n",
        "    target_column=target_column,\n",
        "\n",
        "    metric_sklearn_name=\"mean_absolute_error\",\n",
        "    horizon=7*24,\n",
        "    oml_grace_period=7*24,\n",
        "    weight_coeff=0.0,\n",
        "    weights=np.array([1, 0.01, 0.01]),\n",
        "\n",
        "    core_model_name=\"forest.AMFRegressor\",\n",
        "    hyperdict=hyperdict,\n",
        "   )\n",
        "\n",
        "\n",
        "design_control = design_control_init(\n",
        "    init_size=5,\n",
        ")\n",
        "\n",
        "surrogate_control = surrogate_control_init(\n",
        "    noise=True,\n",
        "    n_theta=2,\n",
        "    min_Lambda=1e-3,\n",
        "    max_Lambda=10,\n",
        ")\n",
        "\n",
        "optimizer_control = optimizer_control_init()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modify `hyper_dict` Hyperparameters for the Selected Algorithm aka `core_model`\n",
        "\n",
        "After the `core_model` and the ``hyperdict`` are added to the `fun_control` dictionary, the hyperparameter tuning can be started.\n",
        "However, in some settings, the user wants to modify the hyperparameters. This can be done with the `set_int_hyperparameter_values`, `set_float_hyperparameter_values`, `set_boolean_hyperparameter_values`, and  `set_factor_hyperparameter_values`  functions, which can be imported from `from spotpython.hyperparameters.values` [[SOURCE]](https://github.com/sequential-parameter-optimization/spotpython/blob/main/src/spotpython/hyperparameters/values.py).\n",
        "\n",
        "The following code shows how hyperparameter of type float and integer can be modified. Additional examples can be found in @sec-modifying-hyperparameter-levels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotpython.utils.eda import gen_design_table\n",
        "print(gen_design_table(fun_control))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotpython.hyperparameters.values import set_int_hyperparameter_values, set_float_hyperparameter_values, set_factor_hyperparameter_values\n",
        "set_int_hyperparameter_values(fun_control, \"n_estimators\", 2, 7)\n",
        "set_float_hyperparameter_values(fun_control, \"step\", 0.1, 15)\n",
        "print(gen_design_table(fun_control))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.callout-note}\n",
        "#### Note: Active and Inactive Hyperparameters\n",
        "Hyperparameters can be excluded from the tuning procedure by selecting identical values for the lower and upper bounds.\n",
        ":::\n",
        "\n",
        "### Run the `Spot` Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: 503_spot_run\n",
        "from spotpython.spot import spot\n",
        "spot_tuner = spot.Spot(\n",
        "    fun=fun,\n",
        "    fun_control=fun_control,\n",
        "    design_control=design_control,\n",
        "    surrogate_control=surrogate_control,\n",
        "    optimizer_control=optimizer_control,\n",
        ")\n",
        "res = spot_tuner.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can start TensorBoard in the background with the following command, where ./runs is the default directory for the TensorBoard log files:\n",
        "\n",
        "`tensorboard --logdir=\"./runs\"`We can access the TensorBoard web server with the following URL:\n",
        "\n",
        "```{raw}\n",
        "http://localhost:6006/\n",
        "```\n",
        "\n",
        "\n",
        "## Results\n",
        "\n",
        "After the hyperparameter tuning run is finished, the progress of the hyperparameter tuning can be visualized with `spotpython`'s method `plot_progress`. The black points represent the performace values (score or metric) of  hyperparameter configurations from the initial design, whereas the red points represents the  hyperparameter configurations found by the surrogate model based optimization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spot_tuner.plot_progress()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results can be printed in tabular form."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotpython.utils.eda import gen_design_table\n",
        "print(gen_design_table(fun_control=fun_control, spot=spot_tuner))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A histogram can be used to visualize the most important hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spot_tuner.plot_importance(threshold=10.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Performance of the Model with Default Hyperparameters\n",
        "\n",
        "### Get Default Hyperparameters and Fit the Model\n",
        "\n",
        "The default hyperparameters, which will be used for a comparion with the tuned hyperparameters, can be obtained with the following commands:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotpython.hyperparameters.values import get_default_hyperparameters_as_array\n",
        "X_start = get_default_hyperparameters_as_array(fun_control)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`spotpython` tunes numpy arrays, i.e., the hyperparameters are stored in a numpy array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from spotpython.hyperparameters.values import get_one_core_model_from_X\n",
        "model_default = get_one_core_model_from_X(X_start, fun_control, default=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate the Model with Default Hyperparameters\n",
        "\n",
        "The model with the default hyperparameters can be trained and evaluated.\n",
        "The evaluation function `eval_oml_horizon` [[SOURCE]](https://github.com/sequential-parameter-optimization/spotriver/blob/main/src/spotriver/evaluation/eval_bml.py) is the same function that was used for the hyperparameter tuning.\n",
        "During the hyperparameter tuning, the evaluation function was called from the objective (or loss) function `fun_oml_horizon` [[SOURCE]](https://github.com/sequential-parameter-optimization/spotriver/blob/main/src/spotriver/fun/hyperriver.py)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: 503_eval_default\n",
        "from spotriver.evaluation.eval_bml import eval_oml_horizon\n",
        "\n",
        "df_eval_default, df_true_default = eval_oml_horizon(\n",
        "                    model=model_default,\n",
        "                    train=fun_control[\"train\"],\n",
        "                    test=fun_control[\"test\"],\n",
        "                    target_column=fun_control[\"target_column\"],\n",
        "                    horizon=fun_control[\"horizon\"],\n",
        "                    oml_grace_period=fun_control[\"oml_grace_period\"],\n",
        "                    metric=fun_control[\"metric_sklearn\"],\n",
        "                )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The three performance criteria, i.e., score (metric), runtime, and memory consumption, can be visualized with the following commands:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: 503_plot_bml_oml_horizon_metrics_default\n",
        "from spotriver.evaluation.eval_bml import plot_bml_oml_horizon_metrics, plot_bml_oml_horizon_predictions\n",
        "df_labels=[\"default\"]\n",
        "plot_bml_oml_horizon_metrics(df_eval = [df_eval_default], log_y=False, df_labels=df_labels, metric=fun_control[\"metric_sklearn\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Show Predictions of the Model with Default Hyperparameters\n",
        "\n",
        "* Select a subset of the data set for the visualization of the predictions:\n",
        "    * We use the mean, $m$, of the data set as the center of the visualization.\n",
        "    * We use 100 data points, i.e., $m \\pm 50$ as the visualization window."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: 503_plot_bml_oml_horizon_predictions_default\n",
        "m = fun_control[\"test\"].shape[0]\n",
        "a = int(m/2)-50\n",
        "b = int(m/2)+50\n",
        "plot_bml_oml_horizon_predictions(df_true = [df_true_default[a:b]], target_column=target_column,  df_labels=df_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get SPOT Results\n",
        "\n",
        "In a similar way, we can obtain the hyperparameters found by `spotpython`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: 503_get_one_core_model_from_X\n",
        "from spotpython.hyperparameters.values import get_one_core_model_from_X\n",
        "X = spot_tuner.to_all_dim(spot_tuner.min_X.reshape(1,-1))\n",
        "model_spot = get_one_core_model_from_X(X, fun_control)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: 503_eval_om_horizon\n",
        "df_eval_spot, df_true_spot = eval_oml_horizon(\n",
        "                    model=model_spot,\n",
        "                    train=fun_control[\"train\"],\n",
        "                    test=fun_control[\"test\"],\n",
        "                    target_column=fun_control[\"target_column\"],\n",
        "                    horizon=fun_control[\"horizon\"],\n",
        "                    oml_grace_period=fun_control[\"oml_grace_period\"],\n",
        "                    metric=fun_control[\"metric_sklearn\"],\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: 503_plot_bml_oml_horizon_metrics\n",
        "df_labels=[\"default\", \"spot\"]\n",
        "plot_bml_oml_horizon_metrics(df_eval = [df_eval_default, df_eval_spot], log_y=False, df_labels=df_labels, metric=fun_control[\"metric_sklearn\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: 503_plot_bml_oml_horizon_predictions\n",
        "plot_bml_oml_horizon_predictions(df_true = [df_true_default[a:b], df_true_spot[a:b]], target_column=target_column,  df_labels=df_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: 503_plot_actual_vs_predicted\n",
        "from spotpython.plot.validation import plot_actual_vs_predicted\n",
        "plot_actual_vs_predicted(y_test=df_true_default[target_column], y_pred=df_true_default[\"Prediction\"], title=\"Default\")\n",
        "plot_actual_vs_predicted(y_test=df_true_spot[target_column], y_pred=df_true_spot[\"Prediction\"], title=\"SPOT\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Detailed Hyperparameter Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: 503_plot_important_hyperparameter_contour\n",
        "spot_tuner.plot_important_hyperparameter_contour(max_imp=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parallel Coordinates Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| label: 503_parallel_plot\n",
        "spot_tuner.parallel_plot()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3",
      "path": "/Users/bartz/miniforge3/envs/spotCondaEnv/share/jupyter/kernels/python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
