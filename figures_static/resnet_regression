digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	5049452976 [label="
 (2, 1)" fillcolor=darkolivegreen1]
	5049483568 [label=AddmmBackward0]
	5049483472 -> 5049483568
	5046880048 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	5046880048 -> 5049483472
	5049483472 [label=AccumulateGrad]
	5049483520 -> 5049483568
	5049483520 [label=ReluBackward0]
	5049231312 -> 5049483520
	5049231312 [label=AddBackward0]
	5049483808 -> 5049231312
	5049483808 [label=NativeBatchNormBackward0]
	5049483952 -> 5049483808
	5049483952 [label=MmBackward0]
	5049484144 -> 5049483952
	5049484144 [label=ReluBackward0]
	5049484288 -> 5049484144
	5049484288 [label=NativeBatchNormBackward0]
	5049484384 -> 5049484288
	5049484384 [label=MmBackward0]
	5049483376 -> 5049484384
	5049483376 [label=ReluBackward0]
	5049484672 -> 5049483376
	5049484672 [label=AddBackward0]
	5049484768 -> 5049484672
	5049484768 [label=NativeBatchNormBackward0]
	5049484912 -> 5049484768
	5049484912 [label=MmBackward0]
	5049485104 -> 5049484912
	5049485104 [label=ReluBackward0]
	5049485248 -> 5049485104
	5049485248 [label=NativeBatchNormBackward0]
	5049485344 -> 5049485248
	5049485344 [label=MmBackward0]
	5049484720 -> 5049485344
	5049484720 [label=AddmmBackward0]
	5049485632 -> 5049484720
	5046696240 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	5046696240 -> 5049485632
	5049485632 [label=AccumulateGrad]
	5049485584 -> 5049484720
	5049485584 [label=TBackward0]
	5049485728 -> 5049485584
	5046692800 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	5046692800 -> 5049485728
	5049485728 [label=AccumulateGrad]
	5049485536 -> 5049485344
	5049485536 [label=TBackward0]
	5049485872 -> 5049485536
	5025758448 [label="blocks.0.net.0.weight
 (64, 64)" fillcolor=lightblue]
	5025758448 -> 5049485872
	5049485872 [label=AccumulateGrad]
	5049485296 -> 5049485248
	5031980128 [label="blocks.0.net.1.weight
 (64)" fillcolor=lightblue]
	5031980128 -> 5049485296
	5049485296 [label=AccumulateGrad]
	5049485152 -> 5049485248
	5035889024 [label="blocks.0.net.1.bias
 (64)" fillcolor=lightblue]
	5035889024 -> 5049485152
	5049485152 [label=AccumulateGrad]
	5049485056 -> 5049484912
	5049485056 [label=TBackward0]
	5049485680 -> 5049485056
	5046697920 [label="blocks.0.net.3.weight
 (64, 64)" fillcolor=lightblue]
	5046697920 -> 5049485680
	5049485680 [label=AccumulateGrad]
	5049484864 -> 5049484768
	5046878288 [label="blocks.0.net.4.weight
 (64)" fillcolor=lightblue]
	5046878288 -> 5049484864
	5049484864 [label=AccumulateGrad]
	5049484816 -> 5049484768
	5046878368 [label="blocks.0.net.4.bias
 (64)" fillcolor=lightblue]
	5046878368 -> 5049484816
	5049484816 [label=AccumulateGrad]
	5049484720 -> 5049484672
	5049484576 -> 5049484384
	5049484576 [label=TBackward0]
	5049484960 -> 5049484576
	5035887344 [label="blocks.1.net.0.weight
 (64, 64)" fillcolor=lightblue]
	5035887344 -> 5049484960
	5049484960 [label=AccumulateGrad]
	5049484336 -> 5049484288
	5046878848 [label="blocks.1.net.1.weight
 (64)" fillcolor=lightblue]
	5046878848 -> 5049484336
	5049484336 [label=AccumulateGrad]
	5049484192 -> 5049484288
	5046878928 [label="blocks.1.net.1.bias
 (64)" fillcolor=lightblue]
	5046878928 -> 5049484192
	5049484192 [label=AccumulateGrad]
	5049484096 -> 5049483952
	5049484096 [label=TBackward0]
	5049484480 -> 5049484096
	5046879328 [label="blocks.1.net.3.weight
 (64, 64)" fillcolor=lightblue]
	5046879328 -> 5049484480
	5049484480 [label=AccumulateGrad]
	5049483904 -> 5049483808
	5046879408 [label="blocks.1.net.4.weight
 (64)" fillcolor=lightblue]
	5046879408 -> 5049483904
	5049483904 [label=AccumulateGrad]
	5049483760 -> 5049483808
	5046879488 [label="blocks.1.net.4.bias
 (64)" fillcolor=lightblue]
	5046879488 -> 5049483760
	5049483760 [label=AccumulateGrad]
	5049483376 -> 5049231312
	5049483664 -> 5049483568
	5049483664 [label=TBackward0]
	5049484000 -> 5049483664
	5046879968 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	5046879968 -> 5049484000
	5049484000 [label=AccumulateGrad]
	5049483568 -> 5049452976
}
