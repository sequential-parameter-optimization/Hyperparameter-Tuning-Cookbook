digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	5062941568 [label="
 (2, 1)" fillcolor=darkolivegreen1]
	5066325248 [label=AddmmBackward0]
	5067922672 -> 5066325248
	5065826992 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	5065826992 -> 5067922672
	5067922672 [label=AccumulateGrad]
	5066554912 -> 5066325248
	5066554912 [label=ReluBackward0]
	4993059760 -> 5066554912
	4993059760 [label=AddBackward0]
	5068227584 -> 4993059760
	5068227584 [label=NativeBatchNormBackward0]
	5068353168 -> 5068227584
	5068353168 [label=MmBackward0]
	5068353216 -> 5068353168
	5068353216 [label=ReluBackward0]
	5068353360 -> 5068353216
	5068353360 [label=NativeBatchNormBackward0]
	5068353552 -> 5068353360
	5068353552 [label=MmBackward0]
	5068237136 -> 5068353552
	5068237136 [label=ReluBackward0]
	5068353840 -> 5068237136
	5068353840 [label=AddBackward0]
	5068353936 -> 5068353840
	5068353936 [label=NativeBatchNormBackward0]
	5068354080 -> 5068353936
	5068354080 [label=MmBackward0]
	5068354272 -> 5068354080
	5068354272 [label=ReluBackward0]
	5068354416 -> 5068354272
	5068354416 [label=NativeBatchNormBackward0]
	5068354512 -> 5068354416
	5068354512 [label=MmBackward0]
	5068353888 -> 5068354512
	5068353888 [label=AddmmBackward0]
	5068354800 -> 5068353888
	5065825632 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	5065825632 -> 5068354800
	5068354800 [label=AccumulateGrad]
	5068354752 -> 5068353888
	5068354752 [label=TBackward0]
	5068354896 -> 5068354752
	5065824512 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	5065824512 -> 5068354896
	5068354896 [label=AccumulateGrad]
	5068354704 -> 5068354512
	5068354704 [label=TBackward0]
	5068355040 -> 5068354704
	5065824432 [label="blocks.0.net.0.weight
 (64, 64)" fillcolor=lightblue]
	5065824432 -> 5068355040
	5068355040 [label=AccumulateGrad]
	5068354464 -> 5068354416
	4433835936 [label="blocks.0.net.1.weight
 (64)" fillcolor=lightblue]
	4433835936 -> 5068354464
	5068354464 [label=AccumulateGrad]
	5068354320 -> 5068354416
	5031020016 [label="blocks.0.net.1.bias
 (64)" fillcolor=lightblue]
	5031020016 -> 5068354320
	5068354320 [label=AccumulateGrad]
	5068354224 -> 5068354080
	5068354224 [label=TBackward0]
	5068354848 -> 5068354224
	4536810816 [label="blocks.0.net.3.weight
 (64, 64)" fillcolor=lightblue]
	4536810816 -> 5068354848
	5068354848 [label=AccumulateGrad]
	5068354032 -> 5068353936
	5062941408 [label="blocks.0.net.4.weight
 (64)" fillcolor=lightblue]
	5062941408 -> 5068354032
	5068354032 [label=AccumulateGrad]
	5068353984 -> 5068353936
	5062942368 [label="blocks.0.net.4.bias
 (64)" fillcolor=lightblue]
	5062942368 -> 5068353984
	5068353984 [label=AccumulateGrad]
	5068353888 -> 5068353840
	5068353744 -> 5068353552
	5068353744 [label=TBackward0]
	5068354128 -> 5068353744
	5065825872 [label="blocks.1.net.0.weight
 (64, 64)" fillcolor=lightblue]
	5065825872 -> 5068354128
	5068354128 [label=AccumulateGrad]
	5068353504 -> 5068353360
	5065825952 [label="blocks.1.net.1.weight
 (64)" fillcolor=lightblue]
	5065825952 -> 5068353504
	5068353504 [label=AccumulateGrad]
	5068353408 -> 5068353360
	5065826032 [label="blocks.1.net.1.bias
 (64)" fillcolor=lightblue]
	5065826032 -> 5068353408
	5068353408 [label=AccumulateGrad]
	5068352976 -> 5068353168
	5068352976 [label=TBackward0]
	5068353648 -> 5068352976
	5065826432 [label="blocks.1.net.3.weight
 (64, 64)" fillcolor=lightblue]
	5065826432 -> 5068353648
	5068353648 [label=AccumulateGrad]
	5068353120 -> 5068227584
	5065826512 [label="blocks.1.net.4.weight
 (64)" fillcolor=lightblue]
	5065826512 -> 5068353120
	5068353120 [label=AccumulateGrad]
	5068353072 -> 5068227584
	5065826592 [label="blocks.1.net.4.bias
 (64)" fillcolor=lightblue]
	5065826592 -> 5068353072
	5068353072 [label=AccumulateGrad]
	5068237136 -> 4993059760
	5066695456 -> 5066325248
	5066695456 [label=TBackward0]
	5068239104 -> 5066695456
	5065826912 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	5065826912 -> 5068239104
	5068239104 [label=AccumulateGrad]
	5066325248 -> 5062941568
}
