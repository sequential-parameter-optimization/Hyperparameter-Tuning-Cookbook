digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	5560912544 [label="
 (2, 1)" fillcolor=darkolivegreen1]
	4466212144 [label=AddmmBackward0]
	5558947600 -> 4466212144
	5556910144 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	5556910144 -> 5558947600
	5558947600 [label=AccumulateGrad]
	5560930496 -> 4466212144
	5560930496 [label=ReluBackward0]
	5558765840 -> 5560930496
	5558765840 [label=AddBackward0]
	5560930688 -> 5558765840
	5560930688 [label=NativeBatchNormBackward0]
	5560930880 -> 5560930688
	5560930880 [label=MmBackward0]
	5560931072 -> 5560930880
	5560931072 [label=ReluBackward0]
	5560931120 -> 5560931072
	5560931120 [label=NativeBatchNormBackward0]
	5560931216 -> 5560931120
	5560931216 [label=MmBackward0]
	5560930640 -> 5560931216
	5560930640 [label=ReluBackward0]
	5560931504 -> 5560930640
	5560931504 [label=AddBackward0]
	5560931600 -> 5560931504
	5560931600 [label=NativeBatchNormBackward0]
	5560931744 -> 5560931600
	5560931744 [label=MmBackward0]
	5560931936 -> 5560931744
	5560931936 [label=ReluBackward0]
	5560932080 -> 5560931936
	5560932080 [label=NativeBatchNormBackward0]
	5560932176 -> 5560932080
	5560932176 [label=MmBackward0]
	5560931648 -> 5560932176
	5560931648 [label=AddmmBackward0]
	5560932464 -> 5560931648
	5087975440 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	5087975440 -> 5560932464
	5560932464 [label=AccumulateGrad]
	5560932512 -> 5560931648
	5560932512 [label=TBackward0]
	5560791920 -> 5560932512
	4366196784 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	4366196784 -> 5560791920
	5560791920 [label=AccumulateGrad]
	5560932368 -> 5560932176
	5560932368 [label=TBackward0]
	5560932656 -> 5560932368
	5556900384 [label="blocks.0.net.0.weight
 (64, 64)" fillcolor=lightblue]
	5556900384 -> 5560932656
	5560932656 [label=AccumulateGrad]
	5560932224 -> 5560932080
	5554814192 [label="blocks.0.net.1.weight
 (64)" fillcolor=lightblue]
	5554814192 -> 5560932224
	5560932224 [label=AccumulateGrad]
	5560932032 -> 5560932080
	5556908624 [label="blocks.0.net.1.bias
 (64)" fillcolor=lightblue]
	5556908624 -> 5560932032
	5560932032 [label=AccumulateGrad]
	5560931984 -> 5560931744
	5560931984 [label=TBackward0]
	5560932272 -> 5560931984
	5556908704 [label="blocks.0.net.3.weight
 (64, 64)" fillcolor=lightblue]
	5556908704 -> 5560932272
	5560932272 [label=AccumulateGrad]
	5560931792 -> 5560931600
	5556907344 [label="blocks.0.net.4.weight
 (64)" fillcolor=lightblue]
	5556907344 -> 5560931792
	5560931792 [label=AccumulateGrad]
	5560931696 -> 5560931600
	5556907424 [label="blocks.0.net.4.bias
 (64)" fillcolor=lightblue]
	5556907424 -> 5560931696
	5560931696 [label=AccumulateGrad]
	5560931648 -> 5560931504
	5560931408 -> 5560931216
	5560931408 [label=TBackward0]
	5560931360 -> 5560931408
	5556909104 [label="blocks.1.net.0.weight
 (64, 64)" fillcolor=lightblue]
	5556909104 -> 5560931360
	5560931360 [label=AccumulateGrad]
	5560931264 -> 5560931120
	5556909184 [label="blocks.1.net.1.weight
 (64)" fillcolor=lightblue]
	5556909184 -> 5560931264
	5560931264 [label=AccumulateGrad]
	5560930832 -> 5560931120
	5556909264 [label="blocks.1.net.1.bias
 (64)" fillcolor=lightblue]
	5556909264 -> 5560930832
	5560930832 [label=AccumulateGrad]
	5560930544 -> 5560930880
	5560930544 [label=TBackward0]
	5560931312 -> 5560930544
	5556909664 [label="blocks.1.net.3.weight
 (64, 64)" fillcolor=lightblue]
	5556909664 -> 5560931312
	5560931312 [label=AccumulateGrad]
	5560930928 -> 5560930688
	5556909744 [label="blocks.1.net.4.weight
 (64)" fillcolor=lightblue]
	5556909744 -> 5560930928
	5560930928 [label=AccumulateGrad]
	5560930784 -> 5560930688
	5556909824 [label="blocks.1.net.4.bias
 (64)" fillcolor=lightblue]
	5556909824 -> 5560930784
	5560930784 [label=AccumulateGrad]
	5560930640 -> 5558765840
	5560930592 -> 4466212144
	5560930592 [label=TBackward0]
	5560930352 -> 5560930592
	5556909424 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	5556909424 -> 5560930352
	5560930352 [label=AccumulateGrad]
	4466212144 -> 5560912544
}
