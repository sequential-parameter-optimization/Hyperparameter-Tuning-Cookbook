digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	5264055008 [label="
 (2, 1)" fillcolor=darkolivegreen1]
	5288585120 [label=AddmmBackward0]
	5260673904 -> 5288585120
	5264054288 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	5264054288 -> 5260673904
	5260673904 [label=AccumulateGrad]
	5288578976 -> 5288585120
	5288578976 [label=ReluBackward0]
	5289618272 -> 5288578976
	5289618272 [label=AddBackward0]
	5289618176 -> 5289618272
	5289618176 [label=NativeBatchNormBackward0]
	5289617984 -> 5289618176
	5289617984 [label=MmBackward0]
	5289618560 -> 5289617984
	5289618560 [label=ReluBackward0]
	5289618752 -> 5289618560
	5289618752 [label=NativeBatchNormBackward0]
	5289618848 -> 5289618752
	5289618848 [label=MmBackward0]
	5289618224 -> 5289618848
	5289618224 [label=ReluBackward0]
	5289619136 -> 5289618224
	5289619136 [label=AddBackward0]
	5289619232 -> 5289619136
	5289619232 [label=NativeBatchNormBackward0]
	5289619376 -> 5289619232
	5289619376 [label=MmBackward0]
	5289619568 -> 5289619376
	5289619568 [label=ReluBackward0]
	5289619712 -> 5289619568
	5289619712 [label=NativeBatchNormBackward0]
	5289619808 -> 5289619712
	5289619808 [label=MmBackward0]
	5289619184 -> 5289619808
	5289619184 [label=AddmmBackward0]
	5289620096 -> 5289619184
	5264050848 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	5264050848 -> 5289620096
	5289620096 [label=AccumulateGrad]
	5289620048 -> 5289619184
	5289620048 [label=TBackward0]
	5289620192 -> 5289620048
	5264050288 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	5264050288 -> 5289620192
	5289620192 [label=AccumulateGrad]
	5289620000 -> 5289619808
	5289620000 [label=TBackward0]
	5289620336 -> 5289620000
	4498013504 [label="blocks.0.net.0.weight
 (64, 64)" fillcolor=lightblue]
	4498013504 -> 5289620336
	5289620336 [label=AccumulateGrad]
	5289619760 -> 5289619712
	5097601328 [label="blocks.0.net.1.weight
 (64)" fillcolor=lightblue]
	5097601328 -> 5289619760
	5289619760 [label=AccumulateGrad]
	5289619616 -> 5289619712
	4537918608 [label="blocks.0.net.1.bias
 (64)" fillcolor=lightblue]
	4537918608 -> 5289619616
	5289619616 [label=AccumulateGrad]
	5289619520 -> 5289619376
	5289619520 [label=TBackward0]
	5289620144 -> 5289619520
	4549772704 [label="blocks.0.net.3.weight
 (64, 64)" fillcolor=lightblue]
	4549772704 -> 5289620144
	5289620144 [label=AccumulateGrad]
	5289619328 -> 5289619232
	5264050208 [label="blocks.0.net.4.weight
 (64)" fillcolor=lightblue]
	5264050208 -> 5289619328
	5289619328 [label=AccumulateGrad]
	5289619280 -> 5289619232
	5264051888 [label="blocks.0.net.4.bias
 (64)" fillcolor=lightblue]
	5264051888 -> 5289619280
	5289619280 [label=AccumulateGrad]
	5289619184 -> 5289619136
	5289619040 -> 5289618848
	5289619040 [label=TBackward0]
	5289619424 -> 5289619040
	5264053168 [label="blocks.1.net.0.weight
 (64, 64)" fillcolor=lightblue]
	5264053168 -> 5289619424
	5289619424 [label=AccumulateGrad]
	5289618800 -> 5289618752
	5264053248 [label="blocks.1.net.1.weight
 (64)" fillcolor=lightblue]
	5264053248 -> 5289618800
	5289618800 [label=AccumulateGrad]
	5289618656 -> 5289618752
	5264053328 [label="blocks.1.net.1.bias
 (64)" fillcolor=lightblue]
	5264053328 -> 5289618656
	5289618656 [label=AccumulateGrad]
	5289618368 -> 5289617984
	5289618368 [label=TBackward0]
	5289618944 -> 5289618368
	5264053728 [label="blocks.1.net.3.weight
 (64, 64)" fillcolor=lightblue]
	5264053728 -> 5289618944
	5289618944 [label=AccumulateGrad]
	5289618512 -> 5289618176
	5264053808 [label="blocks.1.net.4.weight
 (64)" fillcolor=lightblue]
	5264053808 -> 5289618512
	5289618512 [label=AccumulateGrad]
	5289618464 -> 5289618176
	5264053888 [label="blocks.1.net.4.bias
 (64)" fillcolor=lightblue]
	5264053888 -> 5289618464
	5289618464 [label=AccumulateGrad]
	5289618224 -> 5289618272
	5289618080 -> 5288585120
	5289618080 [label=TBackward0]
	5289618032 -> 5289618080
	5264054208 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	5264054208 -> 5289618032
	5289618032 [label=AccumulateGrad]
	5288585120 -> 5264055008
}
