digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	5455280752 [label="
 (2, 1)" fillcolor=darkolivegreen1]
	5455329792 [label=AddmmBackward0]
	5455329696 -> 5455329792
	5448937744 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	5448937744 -> 5455329696
	5455329696 [label=AccumulateGrad]
	5455329744 -> 5455329792
	5455329744 [label=ReluBackward0]
	5421979856 -> 5455329744
	5421979856 [label=AddBackward0]
	5455325184 -> 5421979856
	5455325184 [label=NativeBatchNormBackward0]
	5455330128 -> 5455325184
	5455330128 [label=MmBackward0]
	5455330320 -> 5455330128
	5455330320 [label=ReluBackward0]
	5455330464 -> 5455330320
	5455330464 [label=NativeBatchNormBackward0]
	5455330560 -> 5455330464
	5455330560 [label=MmBackward0]
	5455329936 -> 5455330560
	5455329936 [label=ReluBackward0]
	5455330848 -> 5455329936
	5455330848 [label=AddBackward0]
	5455330944 -> 5455330848
	5455330944 [label=NativeBatchNormBackward0]
	5455331088 -> 5455330944
	5455331088 [label=MmBackward0]
	5455331280 -> 5455331088
	5455331280 [label=ReluBackward0]
	5455462560 -> 5455331280
	5455462560 [label=NativeBatchNormBackward0]
	5455462656 -> 5455462560
	5455462656 [label=MmBackward0]
	5455330896 -> 5455462656
	5455330896 [label=AddmmBackward0]
	5455462944 -> 5455330896
	5448932944 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	5448932944 -> 5455462944
	5455462944 [label=AccumulateGrad]
	5455462896 -> 5455330896
	5455462896 [label=TBackward0]
	5455463040 -> 5455462896
	4650381264 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	4650381264 -> 5455463040
	5455463040 [label=AccumulateGrad]
	5455462848 -> 5455462656
	5455462848 [label=TBackward0]
	5455463184 -> 5455462848
	5448934224 [label="blocks.0.net.0.weight
 (64, 64)" fillcolor=lightblue]
	5448934224 -> 5455463184
	5455463184 [label=AccumulateGrad]
	5455462608 -> 5455462560
	5448934464 [label="blocks.0.net.1.weight
 (64)" fillcolor=lightblue]
	5448934464 -> 5455462608
	5455462608 [label=AccumulateGrad]
	5455462464 -> 5455462560
	5448934544 [label="blocks.0.net.1.bias
 (64)" fillcolor=lightblue]
	5448934544 -> 5455462464
	5455462464 [label=AccumulateGrad]
	5455331232 -> 5455331088
	5455331232 [label=TBackward0]
	5448994048 -> 5455331232
	5448935584 [label="blocks.0.net.3.weight
 (64, 64)" fillcolor=lightblue]
	5448935584 -> 5448994048
	5448994048 [label=AccumulateGrad]
	5455331040 -> 5455330944
	5448935664 [label="blocks.0.net.4.weight
 (64)" fillcolor=lightblue]
	5448935664 -> 5455331040
	5455331040 [label=AccumulateGrad]
	5455330992 -> 5455330944
	5448935744 [label="blocks.0.net.4.bias
 (64)" fillcolor=lightblue]
	5448935744 -> 5455330992
	5455330992 [label=AccumulateGrad]
	5455330896 -> 5455330848
	5455330752 -> 5455330560
	5455330752 [label=TBackward0]
	5455331136 -> 5455330752
	5448936304 [label="blocks.1.net.0.weight
 (64, 64)" fillcolor=lightblue]
	5448936304 -> 5455331136
	5455331136 [label=AccumulateGrad]
	5455330512 -> 5455330464
	5448936384 [label="blocks.1.net.1.weight
 (64)" fillcolor=lightblue]
	5448936384 -> 5455330512
	5455330512 [label=AccumulateGrad]
	5455330368 -> 5455330464
	5448936464 [label="blocks.1.net.1.bias
 (64)" fillcolor=lightblue]
	5448936464 -> 5455330368
	5455330368 [label=AccumulateGrad]
	5455330272 -> 5455330128
	5455330272 [label=TBackward0]
	5455330656 -> 5455330272
	5448936864 [label="blocks.1.net.3.weight
 (64, 64)" fillcolor=lightblue]
	5448936864 -> 5455330656
	5455330656 [label=AccumulateGrad]
	5455329888 -> 5455325184
	5448936944 [label="blocks.1.net.4.weight
 (64)" fillcolor=lightblue]
	5448936944 -> 5455329888
	5455329888 [label=AccumulateGrad]
	5455330080 -> 5455325184
	5448937024 [label="blocks.1.net.4.bias
 (64)" fillcolor=lightblue]
	5448937024 -> 5455330080
	5455330080 [label=AccumulateGrad]
	5455329936 -> 5421979856
	5455329840 -> 5455329792
	5455329840 [label=TBackward0]
	5455330176 -> 5455329840
	5448937664 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	5448937664 -> 5455330176
	5455330176 [label=AccumulateGrad]
	5455329792 -> 5455280752
}
