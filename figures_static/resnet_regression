digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	5370180256 [label="
 (2, 1)" fillcolor=darkolivegreen1]
	5370216400 [label=AddmmBackward0]
	5370204688 -> 5370216400
	5232324160 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	5232324160 -> 5370204688
	5370204688 [label=AccumulateGrad]
	5370205456 -> 5370216400
	5370205456 [label=ReluBackward0]
	5370085872 -> 5370205456
	5370085872 [label=AddBackward0]
	5370331344 -> 5370085872
	5370331344 [label=NativeBatchNormBackward0]
	5370331392 -> 5370331344
	5370331392 [label=MmBackward0]
	5370331728 -> 5370331392
	5370331728 [label=ReluBackward0]
	5370331872 -> 5370331728
	5370331872 [label=NativeBatchNormBackward0]
	5370331968 -> 5370331872
	5370331968 [label=MmBackward0]
	5370331440 -> 5370331968
	5370331440 [label=ReluBackward0]
	5370332256 -> 5370331440
	5370332256 [label=AddBackward0]
	5370332352 -> 5370332256
	5370332352 [label=NativeBatchNormBackward0]
	5370332496 -> 5370332352
	5370332496 [label=MmBackward0]
	5370332688 -> 5370332496
	5370332688 [label=ReluBackward0]
	5370332832 -> 5370332688
	5370332832 [label=NativeBatchNormBackward0]
	5370332928 -> 5370332832
	5370332928 [label=MmBackward0]
	5370332304 -> 5370332928
	5370332304 [label=AddmmBackward0]
	5370333216 -> 5370332304
	5232320480 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	5232320480 -> 5370333216
	5370333216 [label=AccumulateGrad]
	5370333168 -> 5370332304
	5370333168 [label=TBackward0]
	5370333312 -> 5370333168
	5232316560 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	5232316560 -> 5370333312
	5370333312 [label=AccumulateGrad]
	5370333120 -> 5370332928
	5370333120 [label=TBackward0]
	5370333456 -> 5370333120
	5232321200 [label="blocks.0.net.0.weight
 (64, 64)" fillcolor=lightblue]
	5232321200 -> 5370333456
	5370333456 [label=AccumulateGrad]
	5370332880 -> 5370332832
	5204566864 [label="blocks.0.net.1.weight
 (64)" fillcolor=lightblue]
	5204566864 -> 5370332880
	5370332880 [label=AccumulateGrad]
	5370332736 -> 5370332832
	4902973392 [label="blocks.0.net.1.bias
 (64)" fillcolor=lightblue]
	4902973392 -> 5370332736
	5370332736 [label=AccumulateGrad]
	5370332640 -> 5370332496
	5370332640 [label=TBackward0]
	5370333264 -> 5370332640
	5232322000 [label="blocks.0.net.3.weight
 (64, 64)" fillcolor=lightblue]
	5232322000 -> 5370333264
	5370333264 [label=AccumulateGrad]
	5370332448 -> 5370332352
	5232322080 [label="blocks.0.net.4.weight
 (64)" fillcolor=lightblue]
	5232322080 -> 5370332448
	5370332448 [label=AccumulateGrad]
	5370332400 -> 5370332352
	5232322160 [label="blocks.0.net.4.bias
 (64)" fillcolor=lightblue]
	5232322160 -> 5370332400
	5370332400 [label=AccumulateGrad]
	5370332304 -> 5370332256
	5370332160 -> 5370331968
	5370332160 [label=TBackward0]
	5370332544 -> 5370332160
	5232322640 [label="blocks.1.net.0.weight
 (64, 64)" fillcolor=lightblue]
	5232322640 -> 5370332544
	5370332544 [label=AccumulateGrad]
	5370331920 -> 5370331872
	5232322720 [label="blocks.1.net.1.weight
 (64)" fillcolor=lightblue]
	5232322720 -> 5370331920
	5370331920 [label=AccumulateGrad]
	5370331776 -> 5370331872
	5232322800 [label="blocks.1.net.1.bias
 (64)" fillcolor=lightblue]
	5232322800 -> 5370331776
	5370331776 [label=AccumulateGrad]
	5370331680 -> 5370331392
	5370331680 [label=TBackward0]
	5370332064 -> 5370331680
	5232323200 [label="blocks.1.net.3.weight
 (64, 64)" fillcolor=lightblue]
	5232323200 -> 5370332064
	5370332064 [label=AccumulateGrad]
	5370331536 -> 5370331344
	5232323280 [label="blocks.1.net.4.weight
 (64)" fillcolor=lightblue]
	5232323280 -> 5370331536
	5370331536 [label=AccumulateGrad]
	5370331248 -> 5370331344
	5232323360 [label="blocks.1.net.4.bias
 (64)" fillcolor=lightblue]
	5232323360 -> 5370331248
	5370331248 [label=AccumulateGrad]
	5370331440 -> 5370085872
	5370216352 -> 5370216400
	5370216352 [label=TBackward0]
	5370331584 -> 5370216352
	5232324080 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	5232324080 -> 5370331584
	5370331584 [label=AccumulateGrad]
	5370216400 -> 5370180256
}
