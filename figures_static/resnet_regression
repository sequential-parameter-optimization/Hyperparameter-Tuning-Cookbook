digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	4661701088 [label="
 (2, 1)" fillcolor=darkolivegreen1]
	4659847200 [label=AddmmBackward0]
	4662559072 -> 4659847200
	4661700288 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	4661700288 -> 4662559072
	4662559072 [label=AccumulateGrad]
	4662559120 -> 4659847200
	4662559120 [label=ReluBackward0]
	4664224704 -> 4662559120
	4664224704 [label=AddBackward0]
	4664224896 -> 4664224704
	4664224896 [label=NativeBatchNormBackward0]
	4664225328 -> 4664224896
	4664225328 [label=MmBackward0]
	4664225136 -> 4664225328
	4664225136 [label=ReluBackward0]
	4664225520 -> 4664225136
	4664225520 [label=NativeBatchNormBackward0]
	4664225568 -> 4664225520
	4664225568 [label=MmBackward0]
	4664224992 -> 4664225568
	4664224992 [label=ReluBackward0]
	4664225856 -> 4664224992
	4664225856 [label=AddBackward0]
	4664225952 -> 4664225856
	4664225952 [label=NativeBatchNormBackward0]
	4664226096 -> 4664225952
	4664226096 [label=MmBackward0]
	4664226288 -> 4664226096
	4664226288 [label=ReluBackward0]
	4664226432 -> 4664226288
	4664226432 [label=NativeBatchNormBackward0]
	4664226528 -> 4664226432
	4664226528 [label=MmBackward0]
	4664225904 -> 4664226528
	4664225904 [label=AddmmBackward0]
	4664226816 -> 4664225904
	4661692048 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	4661692048 -> 4664226816
	4664226816 [label=AccumulateGrad]
	4664226768 -> 4664225904
	4664226768 [label=TBackward0]
	4664226912 -> 4664226768
	4661698448 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	4661698448 -> 4664226912
	4664226912 [label=AccumulateGrad]
	4664226720 -> 4664226528
	4664226720 [label=TBackward0]
	4664227056 -> 4664226720
	4413716224 [label="blocks.0.net.0.weight
 (64, 64)" fillcolor=lightblue]
	4413716224 -> 4664227056
	4664227056 [label=AccumulateGrad]
	4664226480 -> 4664226432
	4420944832 [label="blocks.0.net.1.weight
 (64)" fillcolor=lightblue]
	4420944832 -> 4664226480
	4664226480 [label=AccumulateGrad]
	4664226336 -> 4664226432
	4414789568 [label="blocks.0.net.1.bias
 (64)" fillcolor=lightblue]
	4414789568 -> 4664226336
	4664226336 [label=AccumulateGrad]
	4664226240 -> 4664226096
	4664226240 [label=TBackward0]
	4664226864 -> 4664226240
	4661697168 [label="blocks.0.net.3.weight
 (64, 64)" fillcolor=lightblue]
	4661697168 -> 4664226864
	4664226864 [label=AccumulateGrad]
	4664226048 -> 4664225952
	4661698688 [label="blocks.0.net.4.weight
 (64)" fillcolor=lightblue]
	4661698688 -> 4664226048
	4664226048 [label=AccumulateGrad]
	4664226000 -> 4664225952
	4661696128 [label="blocks.0.net.4.bias
 (64)" fillcolor=lightblue]
	4661696128 -> 4664226000
	4664226000 [label=AccumulateGrad]
	4664225904 -> 4664225856
	4664225760 -> 4664225568
	4664225760 [label=TBackward0]
	4664226144 -> 4664225760
	4661699088 [label="blocks.1.net.0.weight
 (64, 64)" fillcolor=lightblue]
	4661699088 -> 4664226144
	4664226144 [label=AccumulateGrad]
	4664225472 -> 4664225520
	4661699168 [label="blocks.1.net.1.weight
 (64)" fillcolor=lightblue]
	4661699168 -> 4664225472
	4664225472 [label=AccumulateGrad]
	4664225424 -> 4664225520
	4661699248 [label="blocks.1.net.1.bias
 (64)" fillcolor=lightblue]
	4661699248 -> 4664225424
	4664225424 [label=AccumulateGrad]
	4664225040 -> 4664225328
	4664225040 [label=TBackward0]
	4664225664 -> 4664225040
	4661699648 [label="blocks.1.net.3.weight
 (64, 64)" fillcolor=lightblue]
	4661699648 -> 4664225664
	4664225664 [label=AccumulateGrad]
	4664225280 -> 4664224896
	4661699728 [label="blocks.1.net.4.weight
 (64)" fillcolor=lightblue]
	4661699728 -> 4664225280
	4664225280 [label=AccumulateGrad]
	4664225232 -> 4664224896
	4661699808 [label="blocks.1.net.4.bias
 (64)" fillcolor=lightblue]
	4661699808 -> 4664225232
	4664225232 [label=AccumulateGrad]
	4664224992 -> 4664224704
	4664224800 -> 4659847200
	4664224800 [label=TBackward0]
	4664225376 -> 4664224800
	4661700208 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	4661700208 -> 4664225376
	4664225376 [label=AccumulateGrad]
	4659847200 -> 4661701088
}
