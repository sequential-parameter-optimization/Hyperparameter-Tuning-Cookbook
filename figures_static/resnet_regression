digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	4667320480 [label="
 (2, 1)" fillcolor=darkolivegreen1]
	4668179312 [label=AddmmBackward0]
	4669719072 -> 4668179312
	4667319680 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	4667319680 -> 4669719072
	4669719072 [label=AccumulateGrad]
	4669877136 -> 4668179312
	4669877136 [label=ReluBackward0]
	4668193280 -> 4669877136
	4668193280 [label=AddBackward0]
	4669877472 -> 4668193280
	4669877472 [label=NativeBatchNormBackward0]
	4669877616 -> 4669877472
	4669877616 [label=MmBackward0]
	4669877808 -> 4669877616
	4669877808 [label=ReluBackward0]
	4669877952 -> 4669877808
	4669877952 [label=NativeBatchNormBackward0]
	4669878048 -> 4669877952
	4669878048 [label=MmBackward0]
	4669877568 -> 4669878048
	4669877568 [label=ReluBackward0]
	4669878336 -> 4669877568
	4669878336 [label=AddBackward0]
	4669878432 -> 4669878336
	4669878432 [label=NativeBatchNormBackward0]
	4669878576 -> 4669878432
	4669878576 [label=MmBackward0]
	4669878768 -> 4669878576
	4669878768 [label=ReluBackward0]
	4669878912 -> 4669878768
	4669878912 [label=NativeBatchNormBackward0]
	4669879008 -> 4669878912
	4669879008 [label=MmBackward0]
	4669878384 -> 4669879008
	4669878384 [label=AddmmBackward0]
	4669879296 -> 4669878384
	4667316000 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	4667316000 -> 4669879296
	4669879296 [label=AccumulateGrad]
	4669879248 -> 4669878384
	4669879248 [label=TBackward0]
	4669879392 -> 4669879248
	4667315680 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	4667315680 -> 4669879392
	4669879392 [label=AccumulateGrad]
	4669879200 -> 4669879008
	4669879200 [label=TBackward0]
	4667833120 -> 4669879200
	4663646304 [label="blocks.0.net.0.weight
 (64, 64)" fillcolor=lightblue]
	4663646304 -> 4667833120
	4667833120 [label=AccumulateGrad]
	4669878960 -> 4669878912
	4426269312 [label="blocks.0.net.1.weight
 (64)" fillcolor=lightblue]
	4426269312 -> 4669878960
	4669878960 [label=AccumulateGrad]
	4669878816 -> 4669878912
	4425885376 [label="blocks.0.net.1.bias
 (64)" fillcolor=lightblue]
	4425885376 -> 4669878816
	4669878816 [label=AccumulateGrad]
	4669878720 -> 4669878576
	4669878720 [label=TBackward0]
	4669879344 -> 4669878720
	4667315280 [label="blocks.0.net.3.weight
 (64, 64)" fillcolor=lightblue]
	4667315280 -> 4669879344
	4669879344 [label=AccumulateGrad]
	4669878528 -> 4669878432
	4667311440 [label="blocks.0.net.4.weight
 (64)" fillcolor=lightblue]
	4667311440 -> 4669878528
	4669878528 [label=AccumulateGrad]
	4669878480 -> 4669878432
	4667317280 [label="blocks.0.net.4.bias
 (64)" fillcolor=lightblue]
	4667317280 -> 4669878480
	4669878480 [label=AccumulateGrad]
	4669878384 -> 4669878336
	4669878240 -> 4669878048
	4669878240 [label=TBackward0]
	4669878624 -> 4669878240
	4667318560 [label="blocks.1.net.0.weight
 (64, 64)" fillcolor=lightblue]
	4667318560 -> 4669878624
	4669878624 [label=AccumulateGrad]
	4669878000 -> 4669877952
	4667318640 [label="blocks.1.net.1.weight
 (64)" fillcolor=lightblue]
	4667318640 -> 4669878000
	4669878000 [label=AccumulateGrad]
	4669877856 -> 4669877952
	4667318720 [label="blocks.1.net.1.bias
 (64)" fillcolor=lightblue]
	4667318720 -> 4669877856
	4669877856 [label=AccumulateGrad]
	4669877760 -> 4669877616
	4669877760 [label=TBackward0]
	4669878144 -> 4669877760
	4667319120 [label="blocks.1.net.3.weight
 (64, 64)" fillcolor=lightblue]
	4667319120 -> 4669878144
	4669878144 [label=AccumulateGrad]
	4669877424 -> 4669877472
	4667319200 [label="blocks.1.net.4.weight
 (64)" fillcolor=lightblue]
	4667319200 -> 4669877424
	4669877424 [label=AccumulateGrad]
	4669877328 -> 4669877472
	4667319280 [label="blocks.1.net.4.bias
 (64)" fillcolor=lightblue]
	4667319280 -> 4669877328
	4669877328 [label=AccumulateGrad]
	4669877568 -> 4668193280
	4669877184 -> 4668179312
	4669877184 [label=TBackward0]
	4669877664 -> 4669877184
	4667319600 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	4667319600 -> 4669877664
	4669877664 [label=AccumulateGrad]
	4668179312 -> 4667320480
}
