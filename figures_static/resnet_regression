digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	6114783104 [label="
 (2, 1)" fillcolor=darkolivegreen1]
	6108331216 [label=AddmmBackward0]
	6098310176 -> 6108331216
	6108424592 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	6108424592 -> 6098310176
	6098310176 [label=AccumulateGrad]
	4361868560 -> 6108331216
	4361868560 [label=ReluBackward0]
	6114832976 -> 4361868560
	6114832976 [label=AddBackward0]
	6114832928 -> 6114832976
	6114832928 [label=NativeBatchNormBackward0]
	6107286784 -> 6114832928
	6107286784 [label=MmBackward0]
	6114833408 -> 6107286784
	6114833408 [label=ReluBackward0]
	6114833552 -> 6114833408
	6114833552 [label=NativeBatchNormBackward0]
	6114833648 -> 6114833552
	6114833648 [label=MmBackward0]
	6114833024 -> 6114833648
	6114833024 [label=ReluBackward0]
	6114833936 -> 6114833024
	6114833936 [label=AddBackward0]
	6114834032 -> 6114833936
	6114834032 [label=NativeBatchNormBackward0]
	6114834176 -> 6114834032
	6114834176 [label=MmBackward0]
	6114834368 -> 6114834176
	6114834368 [label=ReluBackward0]
	6114834512 -> 6114834368
	6114834512 [label=NativeBatchNormBackward0]
	6114834608 -> 6114834512
	6114834608 [label=MmBackward0]
	6114833984 -> 6114834608
	6114833984 [label=AddmmBackward0]
	6114834896 -> 6114833984
	6108416672 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	6108416672 -> 6114834896
	6114834896 [label=AccumulateGrad]
	6114834848 -> 6114833984
	6114834848 [label=TBackward0]
	6114834992 -> 6114834848
	6108416032 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	6108416032 -> 6114834992
	6114834992 [label=AccumulateGrad]
	6114834800 -> 6114834608
	6114834800 [label=TBackward0]
	6096429904 -> 6114834800
	6108421072 [label="blocks.0.net.0.weight
 (64, 64)" fillcolor=lightblue]
	6108421072 -> 6096429904
	6096429904 [label=AccumulateGrad]
	6114834560 -> 6114834512
	6108421232 [label="blocks.0.net.1.weight
 (64)" fillcolor=lightblue]
	6108421232 -> 6114834560
	6114834560 [label=AccumulateGrad]
	6114834416 -> 6114834512
	6108421312 [label="blocks.0.net.1.bias
 (64)" fillcolor=lightblue]
	6108421312 -> 6114834416
	6114834416 [label=AccumulateGrad]
	6114834320 -> 6114834176
	6114834320 [label=TBackward0]
	6114834944 -> 6114834320
	6108422352 [label="blocks.0.net.3.weight
 (64, 64)" fillcolor=lightblue]
	6108422352 -> 6114834944
	6114834944 [label=AccumulateGrad]
	6114834128 -> 6114834032
	6108422432 [label="blocks.0.net.4.weight
 (64)" fillcolor=lightblue]
	6108422432 -> 6114834128
	6114834128 [label=AccumulateGrad]
	6114834080 -> 6114834032
	6108422512 [label="blocks.0.net.4.bias
 (64)" fillcolor=lightblue]
	6108422512 -> 6114834080
	6114834080 [label=AccumulateGrad]
	6114833984 -> 6114833936
	6114833840 -> 6114833648
	6114833840 [label=TBackward0]
	6114834224 -> 6114833840
	6108423072 [label="blocks.1.net.0.weight
 (64, 64)" fillcolor=lightblue]
	6108423072 -> 6114834224
	6114834224 [label=AccumulateGrad]
	6114833600 -> 6114833552
	6108423152 [label="blocks.1.net.1.weight
 (64)" fillcolor=lightblue]
	6108423152 -> 6114833600
	6114833600 [label=AccumulateGrad]
	6114833456 -> 6114833552
	6108423232 [label="blocks.1.net.1.bias
 (64)" fillcolor=lightblue]
	6108423232 -> 6114833456
	6114833456 [label=AccumulateGrad]
	6114833360 -> 6107286784
	6114833360 [label=TBackward0]
	6114833744 -> 6114833360
	6108423632 [label="blocks.1.net.3.weight
 (64, 64)" fillcolor=lightblue]
	6108423632 -> 6114833744
	6114833744 [label=AccumulateGrad]
	6114833120 -> 6114832928
	6108423712 [label="blocks.1.net.4.weight
 (64)" fillcolor=lightblue]
	6108423712 -> 6114833120
	6114833120 [label=AccumulateGrad]
	6114833264 -> 6114832928
	6108423792 [label="blocks.1.net.4.bias
 (64)" fillcolor=lightblue]
	6108423792 -> 6114833264
	6114833264 [label=AccumulateGrad]
	6114833024 -> 6114832976
	6108182512 -> 6108331216
	6108182512 [label=TBackward0]
	6114833168 -> 6108182512
	6108424512 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	6108424512 -> 6114833168
	6114833168 [label=AccumulateGrad]
	6108331216 -> 6114783104
}
