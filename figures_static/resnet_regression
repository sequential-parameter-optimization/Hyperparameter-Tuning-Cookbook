digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	6113733648 [label="
 (2, 1)" fillcolor=darkolivegreen1]
	6113357456 [label=AddmmBackward0]
	6113799632 -> 6113357456
	6109503136 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	6109503136 -> 6113799632
	6113799632 [label=AccumulateGrad]
	6113799728 -> 6113357456
	6113799728 [label=ReluBackward0]
	6113799920 -> 6113799728
	6113799920 [label=AddBackward0]
	6113799824 -> 6113799920
	6113799824 [label=NativeBatchNormBackward0]
	6113800112 -> 6113799824
	6113800112 [label=MmBackward0]
	6110469600 -> 6113800112
	6110469600 [label=ReluBackward0]
	6113800400 -> 6110469600
	6113800400 [label=NativeBatchNormBackward0]
	6113800496 -> 6113800400
	6113800496 [label=MmBackward0]
	6113799776 -> 6113800496
	6113799776 [label=ReluBackward0]
	6113800784 -> 6113799776
	6113800784 [label=AddBackward0]
	6113800880 -> 6113800784
	6113800880 [label=NativeBatchNormBackward0]
	6113801024 -> 6113800880
	6113801024 [label=MmBackward0]
	6113801216 -> 6113801024
	6113801216 [label=ReluBackward0]
	6113801360 -> 6113801216
	6113801360 [label=NativeBatchNormBackward0]
	6113801456 -> 6113801360
	6113801456 [label=MmBackward0]
	6113800832 -> 6113801456
	6113800832 [label=AddmmBackward0]
	6113801744 -> 6113800832
	6109499136 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	6109499136 -> 6113801744
	6113801744 [label=AccumulateGrad]
	6113801696 -> 6113800832
	6113801696 [label=TBackward0]
	6113801840 -> 6113801696
	6109498896 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	6109498896 -> 6113801840
	6113801840 [label=AccumulateGrad]
	6113801648 -> 6113801456
	6113801648 [label=TBackward0]
	6113801984 -> 6113801648
	6109497056 [label="blocks.0.net.0.weight
 (64, 64)" fillcolor=lightblue]
	6109497056 -> 6113801984
	6113801984 [label=AccumulateGrad]
	6113801408 -> 6113801360
	6109499856 [label="blocks.0.net.1.weight
 (64)" fillcolor=lightblue]
	6109499856 -> 6113801408
	6113801408 [label=AccumulateGrad]
	6113801264 -> 6113801360
	6109499936 [label="blocks.0.net.1.bias
 (64)" fillcolor=lightblue]
	6109499936 -> 6113801264
	6113801264 [label=AccumulateGrad]
	6113801168 -> 6113801024
	6113801168 [label=TBackward0]
	6113801792 -> 6113801168
	6109500976 [label="blocks.0.net.3.weight
 (64, 64)" fillcolor=lightblue]
	6109500976 -> 6113801792
	6113801792 [label=AccumulateGrad]
	6113800976 -> 6113800880
	6109501056 [label="blocks.0.net.4.weight
 (64)" fillcolor=lightblue]
	6109501056 -> 6113800976
	6113800976 [label=AccumulateGrad]
	6113800928 -> 6113800880
	6109501136 [label="blocks.0.net.4.bias
 (64)" fillcolor=lightblue]
	6109501136 -> 6113800928
	6113800928 [label=AccumulateGrad]
	6113800832 -> 6113800784
	6113800688 -> 6113800496
	6113800688 [label=TBackward0]
	6113801072 -> 6113800688
	6109501616 [label="blocks.1.net.0.weight
 (64, 64)" fillcolor=lightblue]
	6109501616 -> 6113801072
	6113801072 [label=AccumulateGrad]
	6113800448 -> 6113800400
	6109501696 [label="blocks.1.net.1.weight
 (64)" fillcolor=lightblue]
	6109501696 -> 6113800448
	6113800448 [label=AccumulateGrad]
	6113800304 -> 6113800400
	6109501776 [label="blocks.1.net.1.bias
 (64)" fillcolor=lightblue]
	6109501776 -> 6113800304
	6113800304 [label=AccumulateGrad]
	6113800256 -> 6113800112
	6113800256 [label=TBackward0]
	6113800592 -> 6113800256
	6109502176 [label="blocks.1.net.3.weight
 (64, 64)" fillcolor=lightblue]
	6109502176 -> 6113800592
	6113800592 [label=AccumulateGrad]
	6113800064 -> 6113799824
	6109502256 [label="blocks.1.net.4.weight
 (64)" fillcolor=lightblue]
	6109502256 -> 6113800064
	6113800064 [label=AccumulateGrad]
	6113800016 -> 6113799824
	6109502336 [label="blocks.1.net.4.bias
 (64)" fillcolor=lightblue]
	6109502336 -> 6113800016
	6113800016 [label=AccumulateGrad]
	6113799776 -> 6113799920
	6113799680 -> 6113357456
	6113799680 [label=TBackward0]
	6113800160 -> 6113799680
	6109503056 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	6109503056 -> 6113800160
	6113800160 [label=AccumulateGrad]
	6113357456 -> 6113733648
}
