digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	4668331968 [label="
 (2, 1)" fillcolor=darkolivegreen1]
	4670735216 [label=AddmmBackward0]
	4670860800 -> 4670735216
	4668336128 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	4668336128 -> 4670860800
	4670860800 [label=AccumulateGrad]
	4670860896 -> 4670735216
	4670860896 [label=ReluBackward0]
	4670861040 -> 4670860896
	4670861040 [label=AddBackward0]
	4670860944 -> 4670861040
	4670860944 [label=NativeBatchNormBackward0]
	4670861280 -> 4670860944
	4670861280 [label=MmBackward0]
	4670861472 -> 4670861280
	4670861472 [label=ReluBackward0]
	4670861616 -> 4670861472
	4670861616 [label=NativeBatchNormBackward0]
	4670861712 -> 4670861616
	4670861712 [label=MmBackward0]
	4670861136 -> 4670861712
	4670861136 [label=ReluBackward0]
	4670862000 -> 4670861136
	4670862000 [label=AddBackward0]
	4670862096 -> 4670862000
	4670862096 [label=NativeBatchNormBackward0]
	4670862240 -> 4670862096
	4670862240 [label=MmBackward0]
	4670862432 -> 4670862240
	4670862432 [label=ReluBackward0]
	4670862576 -> 4670862432
	4670862576 [label=NativeBatchNormBackward0]
	4670862672 -> 4670862576
	4670862672 [label=MmBackward0]
	4670862048 -> 4670862672
	4670862048 [label=AddmmBackward0]
	4670862960 -> 4670862048
	4668334528 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	4668334528 -> 4670862960
	4670862960 [label=AccumulateGrad]
	4670862912 -> 4670862048
	4670862912 [label=TBackward0]
	4669199968 -> 4670862912
	4668332288 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	4668332288 -> 4669199968
	4669199968 [label=AccumulateGrad]
	4670862864 -> 4670862672
	4670862864 [label=TBackward0]
	4670863152 -> 4670862864
	4420837664 [label="blocks.0.net.0.weight
 (64, 64)" fillcolor=lightblue]
	4420837664 -> 4670863152
	4670863152 [label=AccumulateGrad]
	4670862624 -> 4670862576
	4426605152 [label="blocks.0.net.1.weight
 (64)" fillcolor=lightblue]
	4426605152 -> 4670862624
	4670862624 [label=AccumulateGrad]
	4670862480 -> 4670862576
	4524912032 [label="blocks.0.net.1.bias
 (64)" fillcolor=lightblue]
	4524912032 -> 4670862480
	4670862480 [label=AccumulateGrad]
	4670862384 -> 4670862240
	4670862384 [label=TBackward0]
	4670863008 -> 4670862384
	4668331648 [label="blocks.0.net.3.weight
 (64, 64)" fillcolor=lightblue]
	4668331648 -> 4670863008
	4670863008 [label=AccumulateGrad]
	4670862192 -> 4670862096
	4668331568 [label="blocks.0.net.4.weight
 (64)" fillcolor=lightblue]
	4668331568 -> 4670862192
	4670862192 [label=AccumulateGrad]
	4670862144 -> 4670862096
	4668334688 [label="blocks.0.net.4.bias
 (64)" fillcolor=lightblue]
	4668334688 -> 4670862144
	4670862144 [label=AccumulateGrad]
	4670862048 -> 4670862000
	4670861904 -> 4670861712
	4670861904 [label=TBackward0]
	4670862288 -> 4670861904
	4668334928 [label="blocks.1.net.0.weight
 (64, 64)" fillcolor=lightblue]
	4668334928 -> 4670862288
	4670862288 [label=AccumulateGrad]
	4670861664 -> 4670861616
	4668335008 [label="blocks.1.net.1.weight
 (64)" fillcolor=lightblue]
	4668335008 -> 4670861664
	4670861664 [label=AccumulateGrad]
	4670861520 -> 4670861616
	4668335088 [label="blocks.1.net.1.bias
 (64)" fillcolor=lightblue]
	4668335088 -> 4670861520
	4670861520 [label=AccumulateGrad]
	4670861424 -> 4670861280
	4670861424 [label=TBackward0]
	4670861808 -> 4670861424
	4668335488 [label="blocks.1.net.3.weight
 (64, 64)" fillcolor=lightblue]
	4668335488 -> 4670861808
	4670861808 [label=AccumulateGrad]
	4670861232 -> 4670860944
	4668335568 [label="blocks.1.net.4.weight
 (64)" fillcolor=lightblue]
	4668335568 -> 4670861232
	4670861232 [label=AccumulateGrad]
	4670861184 -> 4670860944
	4668335648 [label="blocks.1.net.4.bias
 (64)" fillcolor=lightblue]
	4668335648 -> 4670861184
	4670861184 [label=AccumulateGrad]
	4670861136 -> 4670861040
	4670860848 -> 4670735216
	4670860848 [label=TBackward0]
	4670861328 -> 4670860848
	4668336048 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	4668336048 -> 4670861328
	4670861328 [label=AccumulateGrad]
	4670735216 -> 4668331968
}
