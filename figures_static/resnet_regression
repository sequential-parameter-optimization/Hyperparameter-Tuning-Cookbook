digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	4723788608 [label="
 (2, 1)" fillcolor=darkolivegreen1]
	4723328960 [label=AddmmBackward0]
	4723775312 -> 4723328960
	4720818960 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	4720818960 -> 4723775312
	4723775312 [label=AccumulateGrad]
	4723775264 -> 4723328960
	4723775264 [label=ReluBackward0]
	4723775600 -> 4723775264
	4723775600 [label=AddBackward0]
	4723775456 -> 4723775600
	4723775456 [label=NativeBatchNormBackward0]
	4723775840 -> 4723775456
	4723775840 [label=MmBackward0]
	4723775504 -> 4723775840
	4723775504 [label=ReluBackward0]
	4723776032 -> 4723775504
	4723776032 [label=NativeBatchNormBackward0]
	4723776128 -> 4723776032
	4723776128 [label=MmBackward0]
	4723775696 -> 4723776128
	4723775696 [label=ReluBackward0]
	4723776416 -> 4723775696
	4723776416 [label=AddBackward0]
	4723776512 -> 4723776416
	4723776512 [label=NativeBatchNormBackward0]
	4723776656 -> 4723776512
	4723776656 [label=MmBackward0]
	4723776848 -> 4723776656
	4723776848 [label=ReluBackward0]
	4723776992 -> 4723776848
	4723776992 [label=NativeBatchNormBackward0]
	4723777088 -> 4723776992
	4723777088 [label=MmBackward0]
	4723776560 -> 4723777088
	4723776560 [label=AddmmBackward0]
	4723777376 -> 4723776560
	4720815920 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	4720815920 -> 4723777376
	4723777376 [label=AccumulateGrad]
	4723777424 -> 4723776560
	4723777424 [label=TBackward0]
	4723777568 -> 4723777424
	4720601328 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	4720601328 -> 4723777568
	4723777568 [label=AccumulateGrad]
	4723777280 -> 4723777088
	4723777280 [label=TBackward0]
	4723777472 -> 4723777280
	4701440592 [label="blocks.0.net.0.weight
 (64, 64)" fillcolor=lightblue]
	4701440592 -> 4723777472
	4723777472 [label=AccumulateGrad]
	4723777136 -> 4723776992
	4718656352 [label="blocks.0.net.1.weight
 (64)" fillcolor=lightblue]
	4718656352 -> 4723777136
	4723777136 [label=AccumulateGrad]
	4723776944 -> 4723776992
	4718643072 [label="blocks.0.net.1.bias
 (64)" fillcolor=lightblue]
	4718643072 -> 4723776944
	4723776944 [label=AccumulateGrad]
	4723776896 -> 4723776656
	4723776896 [label=TBackward0]
	4722280576 -> 4723776896
	4720817440 [label="blocks.0.net.3.weight
 (64, 64)" fillcolor=lightblue]
	4720817440 -> 4722280576
	4722280576 [label=AccumulateGrad]
	4723776704 -> 4723776512
	4720816000 [label="blocks.0.net.4.weight
 (64)" fillcolor=lightblue]
	4720816000 -> 4723776704
	4723776704 [label=AccumulateGrad]
	4723776608 -> 4723776512
	4720817280 [label="blocks.0.net.4.bias
 (64)" fillcolor=lightblue]
	4720817280 -> 4723776608
	4723776608 [label=AccumulateGrad]
	4723776560 -> 4723776416
	4723776320 -> 4723776128
	4723776320 [label=TBackward0]
	4723776272 -> 4723776320
	4720817760 [label="blocks.1.net.0.weight
 (64, 64)" fillcolor=lightblue]
	4720817760 -> 4723776272
	4723776272 [label=AccumulateGrad]
	4723776176 -> 4723776032
	4720817840 [label="blocks.1.net.1.weight
 (64)" fillcolor=lightblue]
	4720817840 -> 4723776176
	4723776176 [label=AccumulateGrad]
	4723775984 -> 4723776032
	4720817920 [label="blocks.1.net.1.bias
 (64)" fillcolor=lightblue]
	4720817920 -> 4723775984
	4723775984 [label=AccumulateGrad]
	4723775744 -> 4723775840
	4723775744 [label=TBackward0]
	4723776224 -> 4723775744
	4720818320 [label="blocks.1.net.3.weight
 (64, 64)" fillcolor=lightblue]
	4720818320 -> 4723776224
	4723776224 [label=AccumulateGrad]
	4723775888 -> 4723775456
	4720818400 [label="blocks.1.net.4.weight
 (64)" fillcolor=lightblue]
	4720818400 -> 4723775888
	4723775888 [label=AccumulateGrad]
	4723775792 -> 4723775456
	4720818480 [label="blocks.1.net.4.bias
 (64)" fillcolor=lightblue]
	4720818480 -> 4723775792
	4723775792 [label=AccumulateGrad]
	4723775696 -> 4723775600
	4723775408 -> 4723328960
	4723775408 [label=TBackward0]
	4723775648 -> 4723775408
	4720818880 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	4720818880 -> 4723775648
	4723775648 [label=AccumulateGrad]
	4723328960 -> 4723788608
}
