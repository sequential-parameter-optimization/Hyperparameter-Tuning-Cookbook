digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	5299561936 [label="
 (2, 1)" fillcolor=darkolivegreen1]
	5299334656 [label=AddmmBackward0]
	5295733296 -> 5299334656
	5295922208 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	5295922208 -> 5295733296
	5295733296 [label=AccumulateGrad]
	4436098352 -> 5299334656
	4436098352 [label=ReluBackward0]
	5296030672 -> 4436098352
	5296030672 [label=AddBackward0]
	5296671184 -> 5296030672
	5296671184 [label=NativeBatchNormBackward0]
	5299636016 -> 5296671184
	5299636016 [label=MmBackward0]
	5299636112 -> 5299636016
	5299636112 [label=ReluBackward0]
	5299636400 -> 5299636112
	5299636400 [label=NativeBatchNormBackward0]
	5299636496 -> 5299636400
	5299636496 [label=MmBackward0]
	5299635968 -> 5299636496
	5299635968 [label=ReluBackward0]
	5299636784 -> 5299635968
	5299636784 [label=AddBackward0]
	5299636880 -> 5299636784
	5299636880 [label=NativeBatchNormBackward0]
	5299637024 -> 5299636880
	5299637024 [label=MmBackward0]
	5299637216 -> 5299637024
	5299637216 [label=ReluBackward0]
	5299637360 -> 5299637216
	5299637360 [label=NativeBatchNormBackward0]
	5299637456 -> 5299637360
	5299637456 [label=MmBackward0]
	5299636832 -> 5299637456
	5299636832 [label=AddmmBackward0]
	5299637744 -> 5299636832
	5295915088 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	5295915088 -> 5299637744
	5299637744 [label=AccumulateGrad]
	5299637696 -> 5299636832
	5299637696 [label=TBackward0]
	5299637840 -> 5299637696
	5295918528 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	5295918528 -> 5299637840
	5299637840 [label=AccumulateGrad]
	5299637648 -> 5299637456
	5299637648 [label=TBackward0]
	5299637984 -> 5299637648
	4472563872 [label="blocks.0.net.0.weight
 (64, 64)" fillcolor=lightblue]
	4472563872 -> 5299637984
	5299637984 [label=AccumulateGrad]
	5299637408 -> 5299637360
	5286677072 [label="blocks.0.net.1.weight
 (64)" fillcolor=lightblue]
	5286677072 -> 5299637408
	5299637408 [label=AccumulateGrad]
	5299637264 -> 5299637360
	5285793216 [label="blocks.0.net.1.bias
 (64)" fillcolor=lightblue]
	5285793216 -> 5299637264
	5299637264 [label=AccumulateGrad]
	5299637168 -> 5299637024
	5299637168 [label=TBackward0]
	5299637792 -> 5299637168
	5295920048 [label="blocks.0.net.3.weight
 (64, 64)" fillcolor=lightblue]
	5295920048 -> 5299637792
	5299637792 [label=AccumulateGrad]
	5299636976 -> 5299636880
	5295920128 [label="blocks.0.net.4.weight
 (64)" fillcolor=lightblue]
	5295920128 -> 5299636976
	5299636976 [label=AccumulateGrad]
	5299636928 -> 5299636880
	5295920208 [label="blocks.0.net.4.bias
 (64)" fillcolor=lightblue]
	5295920208 -> 5299636928
	5299636928 [label=AccumulateGrad]
	5299636832 -> 5299636784
	5299636688 -> 5299636496
	5299636688 [label=TBackward0]
	5299637072 -> 5299636688
	5295920768 [label="blocks.1.net.0.weight
 (64, 64)" fillcolor=lightblue]
	5295920768 -> 5299637072
	5299637072 [label=AccumulateGrad]
	5299636448 -> 5299636400
	5295920848 [label="blocks.1.net.1.weight
 (64)" fillcolor=lightblue]
	5295920848 -> 5299636448
	5299636448 [label=AccumulateGrad]
	5299636304 -> 5299636400
	5295920928 [label="blocks.1.net.1.bias
 (64)" fillcolor=lightblue]
	5295920928 -> 5299636304
	5299636304 [label=AccumulateGrad]
	5299636256 -> 5299636016
	5299636256 [label=TBackward0]
	5299636592 -> 5299636256
	5295921328 [label="blocks.1.net.3.weight
 (64, 64)" fillcolor=lightblue]
	5295921328 -> 5299636592
	5299636592 [label=AccumulateGrad]
	5299635824 -> 5296671184
	5295921408 [label="blocks.1.net.4.weight
 (64)" fillcolor=lightblue]
	5295921408 -> 5299635824
	5299635824 [label=AccumulateGrad]
	5299635920 -> 5296671184
	5295921488 [label="blocks.1.net.4.bias
 (64)" fillcolor=lightblue]
	5295921488 -> 5299635920
	5299635920 [label=AccumulateGrad]
	5299635968 -> 5296030672
	4402980912 -> 5299334656
	4402980912 [label=TBackward0]
	4710861072 -> 4402980912
	5295922128 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	5295922128 -> 4710861072
	4710861072 [label=AccumulateGrad]
	5299334656 -> 5299561936
}
