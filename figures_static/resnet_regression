digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	4721070544 [label="
 (2, 1)" fillcolor=darkolivegreen1]
	4720519744 [label=AddmmBackward0]
	4662149280 -> 4720519744
	4718215968 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	4718215968 -> 4662149280
	4662149280 [label=AccumulateGrad]
	4719360608 -> 4720519744
	4719360608 [label=ReluBackward0]
	4721028944 -> 4719360608
	4721028944 [label=AddBackward0]
	4721028848 -> 4721028944
	4721028848 [label=NativeBatchNormBackward0]
	4721029232 -> 4721028848
	4721029232 [label=MmBackward0]
	4721029424 -> 4721029232
	4721029424 [label=ReluBackward0]
	4721028992 -> 4721029424
	4721028992 [label=NativeBatchNormBackward0]
	4721029568 -> 4721028992
	4721029568 [label=MmBackward0]
	4721029136 -> 4721029568
	4721029136 [label=ReluBackward0]
	4721029904 -> 4721029136
	4721029904 [label=AddBackward0]
	4721030000 -> 4721029904
	4721030000 [label=NativeBatchNormBackward0]
	4721030144 -> 4721030000
	4721030144 [label=MmBackward0]
	4721030336 -> 4721030144
	4721030336 [label=ReluBackward0]
	4721030480 -> 4721030336
	4721030480 [label=NativeBatchNormBackward0]
	4721030576 -> 4721030480
	4721030576 [label=MmBackward0]
	4721030048 -> 4721030576
	4721030048 [label=AddmmBackward0]
	4721030864 -> 4721030048
	4718065648 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	4718065648 -> 4721030864
	4721030864 [label=AccumulateGrad]
	4721030912 -> 4721030048
	4721030912 [label=TBackward0]
	4721031056 -> 4721030912
	4703313328 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	4703313328 -> 4721031056
	4721031056 [label=AccumulateGrad]
	4721030768 -> 4721030576
	4721030768 [label=TBackward0]
	4719348320 -> 4721030768
	4717593056 [label="blocks.0.net.0.weight
 (64, 64)" fillcolor=lightblue]
	4717593056 -> 4719348320
	4719348320 [label=AccumulateGrad]
	4721030624 -> 4721030480
	4718067008 [label="blocks.0.net.1.weight
 (64)" fillcolor=lightblue]
	4718067008 -> 4721030624
	4721030624 [label=AccumulateGrad]
	4721030432 -> 4721030480
	4718065408 [label="blocks.0.net.1.bias
 (64)" fillcolor=lightblue]
	4718065408 -> 4721030432
	4721030432 [label=AccumulateGrad]
	4721030384 -> 4721030144
	4721030384 [label=TBackward0]
	4721030672 -> 4721030384
	4718065808 [label="blocks.0.net.3.weight
 (64, 64)" fillcolor=lightblue]
	4718065808 -> 4721030672
	4721030672 [label=AccumulateGrad]
	4721030192 -> 4721030000
	4718066848 [label="blocks.0.net.4.weight
 (64)" fillcolor=lightblue]
	4718066848 -> 4721030192
	4721030192 [label=AccumulateGrad]
	4721030096 -> 4721030000
	4718067088 [label="blocks.0.net.4.bias
 (64)" fillcolor=lightblue]
	4718067088 -> 4721030096
	4721030096 [label=AccumulateGrad]
	4721030048 -> 4721029904
	4721029808 -> 4721029568
	4721029808 [label=TBackward0]
	4721029760 -> 4721029808
	4718067408 [label="blocks.1.net.0.weight
 (64, 64)" fillcolor=lightblue]
	4718067408 -> 4721029760
	4721029760 [label=AccumulateGrad]
	4721029664 -> 4721028992
	4718067488 [label="blocks.1.net.1.weight
 (64)" fillcolor=lightblue]
	4718067488 -> 4721029664
	4721029664 [label=AccumulateGrad]
	4721029520 -> 4721028992
	4718067568 [label="blocks.1.net.1.bias
 (64)" fillcolor=lightblue]
	4718067568 -> 4721029520
	4721029520 [label=AccumulateGrad]
	4721029472 -> 4721029232
	4721029472 [label=TBackward0]
	4721029712 -> 4721029472
	4718215488 [label="blocks.1.net.3.weight
 (64, 64)" fillcolor=lightblue]
	4718215488 -> 4721029712
	4721029712 [label=AccumulateGrad]
	4721029280 -> 4721028848
	4718215568 [label="blocks.1.net.4.weight
 (64)" fillcolor=lightblue]
	4718215568 -> 4721029280
	4721029280 [label=AccumulateGrad]
	4721029184 -> 4721028848
	4718215648 [label="blocks.1.net.4.bias
 (64)" fillcolor=lightblue]
	4718215648 -> 4721029184
	4721029184 [label=AccumulateGrad]
	4721029136 -> 4721028944
	4721028800 -> 4720519744
	4721028800 [label=TBackward0]
	4721029088 -> 4721028800
	4716001584 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	4716001584 -> 4721029088
	4721029088 [label=AccumulateGrad]
	4720519744 -> 4721070544
}
