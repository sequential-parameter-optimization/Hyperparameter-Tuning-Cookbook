digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	4647707872 [label="
 (2, 1)" fillcolor=darkolivegreen1]
	4419593616 [label=AddmmBackward0]
	4647524992 -> 4419593616
	4645135184 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	4645135184 -> 4647524992
	4647524992 [label=AccumulateGrad]
	4485831584 -> 4419593616
	4485831584 [label=ReluBackward0]
	4647719632 -> 4485831584
	4647719632 [label=AddBackward0]
	4647719584 -> 4647719632
	4647719584 [label=NativeBatchNormBackward0]
	4647719968 -> 4647719584
	4647719968 [label=MmBackward0]
	4647720112 -> 4647719968
	4647720112 [label=ReluBackward0]
	4647720256 -> 4647720112
	4647720256 [label=NativeBatchNormBackward0]
	4647720352 -> 4647720256
	4647720352 [label=MmBackward0]
	4647719680 -> 4647720352
	4647719680 [label=ReluBackward0]
	4647720640 -> 4647719680
	4647720640 [label=AddBackward0]
	4647720736 -> 4647720640
	4647720736 [label=NativeBatchNormBackward0]
	4647720880 -> 4647720736
	4647720880 [label=MmBackward0]
	4647721072 -> 4647720880
	4647721072 [label=ReluBackward0]
	4647721216 -> 4647721072
	4647721216 [label=NativeBatchNormBackward0]
	4647721312 -> 4647721216
	4647721312 [label=MmBackward0]
	4647720688 -> 4647721312
	4647720688 [label=AddmmBackward0]
	4647721600 -> 4647720688
	4645128464 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	4645128464 -> 4647721600
	4647721600 [label=AccumulateGrad]
	4647721552 -> 4647720688
	4647721552 [label=TBackward0]
	4647721696 -> 4647721552
	4645131744 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	4645131744 -> 4647721696
	4647721696 [label=AccumulateGrad]
	4647721504 -> 4647721312
	4647721504 [label=TBackward0]
	4647721840 -> 4647721504
	4645132464 [label="blocks.0.net.0.weight
 (64, 64)" fillcolor=lightblue]
	4645132464 -> 4647721840
	4647721840 [label=AccumulateGrad]
	4647721264 -> 4647721216
	4489828048 [label="blocks.0.net.1.weight
 (64)" fillcolor=lightblue]
	4489828048 -> 4647721264
	4647721264 [label=AccumulateGrad]
	4647721120 -> 4647721216
	4634009488 [label="blocks.0.net.1.bias
 (64)" fillcolor=lightblue]
	4634009488 -> 4647721120
	4647721120 [label=AccumulateGrad]
	4647721024 -> 4647720880
	4647721024 [label=TBackward0]
	4647721648 -> 4647721024
	4645133184 [label="blocks.0.net.3.weight
 (64, 64)" fillcolor=lightblue]
	4645133184 -> 4647721648
	4647721648 [label=AccumulateGrad]
	4647720832 -> 4647720736
	4645133264 [label="blocks.0.net.4.weight
 (64)" fillcolor=lightblue]
	4645133264 -> 4647720832
	4647720832 [label=AccumulateGrad]
	4647720784 -> 4647720736
	4645133344 [label="blocks.0.net.4.bias
 (64)" fillcolor=lightblue]
	4645133344 -> 4647720784
	4647720784 [label=AccumulateGrad]
	4647720688 -> 4647720640
	4647720544 -> 4647720352
	4647720544 [label=TBackward0]
	4647720928 -> 4647720544
	4637818336 [label="blocks.1.net.0.weight
 (64, 64)" fillcolor=lightblue]
	4637818336 -> 4647720928
	4647720928 [label=AccumulateGrad]
	4647720304 -> 4647720256
	4645133824 [label="blocks.1.net.1.weight
 (64)" fillcolor=lightblue]
	4645133824 -> 4647720304
	4647720304 [label=AccumulateGrad]
	4647720160 -> 4647720256
	4645133904 [label="blocks.1.net.1.bias
 (64)" fillcolor=lightblue]
	4645133904 -> 4647720160
	4647720160 [label=AccumulateGrad]
	4647720064 -> 4647719968
	4647720064 [label=TBackward0]
	4647720448 -> 4647720064
	4645134304 [label="blocks.1.net.3.weight
 (64, 64)" fillcolor=lightblue]
	4645134304 -> 4647720448
	4647720448 [label=AccumulateGrad]
	4647719872 -> 4647719584
	4645134384 [label="blocks.1.net.4.weight
 (64)" fillcolor=lightblue]
	4645134384 -> 4647719872
	4647719872 [label=AccumulateGrad]
	4647719776 -> 4647719584
	4645134464 [label="blocks.1.net.4.bias
 (64)" fillcolor=lightblue]
	4645134464 -> 4647719776
	4647719776 [label=AccumulateGrad]
	4647719680 -> 4647719632
	4485824912 -> 4419593616
	4485824912 [label=TBackward0]
	4647719824 -> 4485824912
	4645135104 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	4645135104 -> 4647719824
	4647719824 [label=AccumulateGrad]
	4419593616 -> 4647707872
}
