digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	4674857120 [label="
 (2, 1)" fillcolor=darkolivegreen1]
	4676191088 [label=AddmmBackward0]
	4676392256 -> 4676191088
	4673034736 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	4673034736 -> 4676392256
	4676392256 [label=AccumulateGrad]
	4677413920 -> 4676191088
	4677413920 [label=ReluBackward0]
	4677414064 -> 4677413920
	4677414064 [label=AddBackward0]
	4677413968 -> 4677414064
	4677413968 [label=NativeBatchNormBackward0]
	4675599856 -> 4677413968
	4675599856 [label=MmBackward0]
	4677414400 -> 4675599856
	4677414400 [label=ReluBackward0]
	4677414496 -> 4677414400
	4677414496 [label=NativeBatchNormBackward0]
	4677414592 -> 4677414496
	4677414592 [label=MmBackward0]
	4677414160 -> 4677414592
	4677414160 [label=ReluBackward0]
	4677414880 -> 4677414160
	4677414880 [label=AddBackward0]
	4677414976 -> 4677414880
	4677414976 [label=NativeBatchNormBackward0]
	4677415120 -> 4677414976
	4677415120 [label=MmBackward0]
	4677415312 -> 4677415120
	4677415312 [label=ReluBackward0]
	4677415456 -> 4677415312
	4677415456 [label=NativeBatchNormBackward0]
	4677415552 -> 4677415456
	4677415552 [label=MmBackward0]
	4677414928 -> 4677415552
	4677414928 [label=AddmmBackward0]
	4677415840 -> 4677414928
	4674853520 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	4674853520 -> 4677415840
	4677415840 [label=AccumulateGrad]
	4677415792 -> 4677414928
	4677415792 [label=TBackward0]
	4677415888 -> 4677415792
	4674854240 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	4674854240 -> 4677415888
	4677415888 [label=AccumulateGrad]
	4677415744 -> 4677415552
	4677415744 [label=TBackward0]
	4677416032 -> 4677415744
	4433127344 [label="blocks.0.net.0.weight
 (64, 64)" fillcolor=lightblue]
	4433127344 -> 4677416032
	4677416032 [label=AccumulateGrad]
	4677415504 -> 4677415456
	4433129664 [label="blocks.0.net.1.weight
 (64)" fillcolor=lightblue]
	4433129664 -> 4677415504
	4677415504 [label=AccumulateGrad]
	4677415360 -> 4677415456
	4433512000 [label="blocks.0.net.1.bias
 (64)" fillcolor=lightblue]
	4433512000 -> 4677415360
	4677415360 [label=AccumulateGrad]
	4677415264 -> 4677415120
	4677415264 [label=TBackward0]
	4677415984 -> 4677415264
	4673035936 [label="blocks.0.net.3.weight
 (64, 64)" fillcolor=lightblue]
	4673035936 -> 4677415984
	4677415984 [label=AccumulateGrad]
	4677415072 -> 4677414976
	4674854160 [label="blocks.0.net.4.weight
 (64)" fillcolor=lightblue]
	4674854160 -> 4677415072
	4677415072 [label=AccumulateGrad]
	4677415024 -> 4677414976
	4674854320 [label="blocks.0.net.4.bias
 (64)" fillcolor=lightblue]
	4674854320 -> 4677415024
	4677415024 [label=AccumulateGrad]
	4677414928 -> 4677414880
	4677414784 -> 4677414592
	4677414784 [label=TBackward0]
	4677415168 -> 4677414784
	4674855440 [label="blocks.1.net.0.weight
 (64, 64)" fillcolor=lightblue]
	4674855440 -> 4677415168
	4677415168 [label=AccumulateGrad]
	4677414544 -> 4677414496
	4674855600 [label="blocks.1.net.1.weight
 (64)" fillcolor=lightblue]
	4674855600 -> 4677414544
	4677414544 [label=AccumulateGrad]
	4677414352 -> 4677414496
	4674855680 [label="blocks.1.net.1.bias
 (64)" fillcolor=lightblue]
	4674855680 -> 4677414352
	4677414352 [label=AccumulateGrad]
	4677413872 -> 4675599856
	4677413872 [label=TBackward0]
	4677414688 -> 4677413872
	4674856080 [label="blocks.1.net.3.weight
 (64, 64)" fillcolor=lightblue]
	4674856080 -> 4677414688
	4677414688 [label=AccumulateGrad]
	4677414304 -> 4677413968
	4674856160 [label="blocks.1.net.4.weight
 (64)" fillcolor=lightblue]
	4674856160 -> 4677414304
	4677414304 [label=AccumulateGrad]
	4677414256 -> 4677413968
	4674856240 [label="blocks.1.net.4.bias
 (64)" fillcolor=lightblue]
	4674856240 -> 4677414256
	4677414256 [label=AccumulateGrad]
	4677414160 -> 4677414064
	4677413824 -> 4676191088
	4677413824 [label=TBackward0]
	4677414208 -> 4677413824
	4673034656 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	4673034656 -> 4677414208
	4677414208 [label=AccumulateGrad]
	4676191088 -> 4674857120
}
