digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	5356729152 [label="
 (2, 1)" fillcolor=darkolivegreen1]
	4554097424 [label=AddmmBackward0]
	5355196512 -> 4554097424
	5343013184 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	5343013184 -> 5355196512
	5355196512 [label=AccumulateGrad]
	4427031424 -> 4554097424
	4427031424 [label=ReluBackward0]
	5356763504 -> 4427031424
	5356763504 [label=AddBackward0]
	5356763648 -> 5356763504
	5356763648 [label=NativeBatchNormBackward0]
	5356763888 -> 5356763648
	5356763888 [label=MmBackward0]
	5356764032 -> 5356763888
	5356764032 [label=ReluBackward0]
	5356764176 -> 5356764032
	5356764176 [label=NativeBatchNormBackward0]
	5356764272 -> 5356764176
	5356764272 [label=MmBackward0]
	5356763696 -> 5356764272
	5356763696 [label=ReluBackward0]
	5356764560 -> 5356763696
	5356764560 [label=AddBackward0]
	5356764656 -> 5356764560
	5356764656 [label=NativeBatchNormBackward0]
	5356764800 -> 5356764656
	5356764800 [label=MmBackward0]
	5356764992 -> 5356764800
	5356764992 [label=ReluBackward0]
	5356765136 -> 5356764992
	5356765136 [label=NativeBatchNormBackward0]
	5356765040 -> 5356765136
	5356765040 [label=MmBackward0]
	5356764608 -> 5356765040
	5356764608 [label=AddmmBackward0]
	5356896656 -> 5356764608
	5343009504 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	5343009504 -> 5356896656
	5356896656 [label=AccumulateGrad]
	5356896608 -> 5356764608
	5356896608 [label=TBackward0]
	5356896752 -> 5356896608
	5343006144 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	5343006144 -> 5356896752
	5356896752 [label=AccumulateGrad]
	5356896560 -> 5356765040
	5356896560 [label=TBackward0]
	5356896896 -> 5356896560
	5343010384 [label="blocks.0.net.0.weight
 (64, 64)" fillcolor=lightblue]
	5343010384 -> 5356896896
	5356896896 [label=AccumulateGrad]
	5356896368 -> 5356765136
	5343010064 [label="blocks.0.net.1.weight
 (64)" fillcolor=lightblue]
	5343010064 -> 5356896368
	5356896368 [label=AccumulateGrad]
	5356896320 -> 5356765136
	5343010544 [label="blocks.0.net.1.bias
 (64)" fillcolor=lightblue]
	5343010544 -> 5356896320
	5356896320 [label=AccumulateGrad]
	5356764944 -> 5356764800
	5356764944 [label=TBackward0]
	5356765088 -> 5356764944
	5343010944 [label="blocks.0.net.3.weight
 (64, 64)" fillcolor=lightblue]
	5343010944 -> 5356765088
	5356765088 [label=AccumulateGrad]
	5356764752 -> 5356764656
	5343011024 [label="blocks.0.net.4.weight
 (64)" fillcolor=lightblue]
	5343011024 -> 5356764752
	5356764752 [label=AccumulateGrad]
	5356764704 -> 5356764656
	5343011104 [label="blocks.0.net.4.bias
 (64)" fillcolor=lightblue]
	5343011104 -> 5356764704
	5356764704 [label=AccumulateGrad]
	5356764608 -> 5356764560
	5356764464 -> 5356764272
	5356764464 [label=TBackward0]
	5356764848 -> 5356764464
	5343011664 [label="blocks.1.net.0.weight
 (64, 64)" fillcolor=lightblue]
	5343011664 -> 5356764848
	5356764848 [label=AccumulateGrad]
	5356764224 -> 5356764176
	5343011744 [label="blocks.1.net.1.weight
 (64)" fillcolor=lightblue]
	5343011744 -> 5356764224
	5356764224 [label=AccumulateGrad]
	5356764080 -> 5356764176
	5343011824 [label="blocks.1.net.1.bias
 (64)" fillcolor=lightblue]
	5343011824 -> 5356764080
	5356764080 [label=AccumulateGrad]
	5356763984 -> 5356763888
	5356763984 [label=TBackward0]
	5356764368 -> 5356763984
	5343012224 [label="blocks.1.net.3.weight
 (64, 64)" fillcolor=lightblue]
	5343012224 -> 5356764368
	5356764368 [label=AccumulateGrad]
	5356763792 -> 5356763648
	5343012304 [label="blocks.1.net.4.weight
 (64)" fillcolor=lightblue]
	5343012304 -> 5356763792
	5356763792 [label=AccumulateGrad]
	5356763552 -> 5356763648
	5343012384 [label="blocks.1.net.4.bias
 (64)" fillcolor=lightblue]
	5343012384 -> 5356763552
	5356763552 [label=AccumulateGrad]
	5356763696 -> 5356763504
	5314755264 -> 4554097424
	5314755264 [label=TBackward0]
	5356763744 -> 5314755264
	5343013104 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	5343013104 -> 5356763744
	5356763744 [label=AccumulateGrad]
	4554097424 -> 5356729152
}
