digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	5074215840 [label="
 (2, 1)" fillcolor=darkolivegreen1]
	5075059232 [label=AddmmBackward0]
	5075074448 -> 5075059232
	5074215120 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	5074215120 -> 5075074448
	5075074448 [label=AccumulateGrad]
	5074281584 -> 5075059232
	5074281584 [label=ReluBackward0]
	5294845584 -> 5074281584
	5294845584 [label=AddBackward0]
	5294846016 -> 5294845584
	5294846016 [label=NativeBatchNormBackward0]
	5294846064 -> 5294846016
	5294846064 [label=MmBackward0]
	5294846256 -> 5294846064
	5294846256 [label=ReluBackward0]
	5294846304 -> 5294846256
	5294846304 [label=NativeBatchNormBackward0]
	5294846448 -> 5294846304
	5294846448 [label=MmBackward0]
	5294845968 -> 5294846448
	5294845968 [label=ReluBackward0]
	5294846736 -> 5294845968
	5294846736 [label=AddBackward0]
	5294846832 -> 5294846736
	5294846832 [label=NativeBatchNormBackward0]
	5294846976 -> 5294846832
	5294846976 [label=MmBackward0]
	5294847168 -> 5294846976
	5294847168 [label=ReluBackward0]
	5294847312 -> 5294847168
	5294847312 [label=NativeBatchNormBackward0]
	5294847408 -> 5294847312
	5294847408 [label=MmBackward0]
	5294846784 -> 5294847408
	5294846784 [label=AddmmBackward0]
	5294847696 -> 5294846784
	5049892560 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	5049892560 -> 5294847696
	5294847696 [label=AccumulateGrad]
	5294847648 -> 5294846784
	5294847648 [label=TBackward0]
	4400207456 -> 5294847648
	4394260256 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	4394260256 -> 4400207456
	4400207456 [label=AccumulateGrad]
	5294847600 -> 5294847408
	5294847600 [label=TBackward0]
	5294847888 -> 5294847600
	4718445024 [label="blocks.0.net.0.weight
 (64, 64)" fillcolor=lightblue]
	4718445024 -> 5294847888
	5294847888 [label=AccumulateGrad]
	5294847360 -> 5294847312
	4400062512 [label="blocks.0.net.1.weight
 (64)" fillcolor=lightblue]
	4400062512 -> 5294847360
	5294847360 [label=AccumulateGrad]
	5294847216 -> 5294847312
	4552269712 [label="blocks.0.net.1.bias
 (64)" fillcolor=lightblue]
	4552269712 -> 5294847216
	5294847216 [label=AccumulateGrad]
	5294847120 -> 5294846976
	5294847120 [label=TBackward0]
	5294847744 -> 5294847120
	5074213360 [label="blocks.0.net.3.weight
 (64, 64)" fillcolor=lightblue]
	5074213360 -> 5294847744
	5294847744 [label=AccumulateGrad]
	5294846928 -> 5294846832
	5074213600 [label="blocks.0.net.4.weight
 (64)" fillcolor=lightblue]
	5074213600 -> 5294846928
	5294846928 [label=AccumulateGrad]
	5294846880 -> 5294846832
	5074213680 [label="blocks.0.net.4.bias
 (64)" fillcolor=lightblue]
	5074213680 -> 5294846880
	5294846880 [label=AccumulateGrad]
	5294846784 -> 5294846736
	5294846640 -> 5294846448
	5294846640 [label=TBackward0]
	5294847024 -> 5294846640
	5074214000 [label="blocks.1.net.0.weight
 (64, 64)" fillcolor=lightblue]
	5074214000 -> 5294847024
	5294847024 [label=AccumulateGrad]
	5294846352 -> 5294846304
	5074214080 [label="blocks.1.net.1.weight
 (64)" fillcolor=lightblue]
	5074214080 -> 5294846352
	5294846352 [label=AccumulateGrad]
	5294845728 -> 5294846304
	5074214160 [label="blocks.1.net.1.bias
 (64)" fillcolor=lightblue]
	5074214160 -> 5294845728
	5294845728 [label=AccumulateGrad]
	5294846208 -> 5294846064
	5294846208 [label=TBackward0]
	5294846544 -> 5294846208
	5074214560 [label="blocks.1.net.3.weight
 (64, 64)" fillcolor=lightblue]
	5074214560 -> 5294846544
	5294846544 [label=AccumulateGrad]
	5294845872 -> 5294846016
	5074214640 [label="blocks.1.net.4.weight
 (64)" fillcolor=lightblue]
	5074214640 -> 5294845872
	5294845872 [label=AccumulateGrad]
	5294845824 -> 5294846016
	5074214720 [label="blocks.1.net.4.bias
 (64)" fillcolor=lightblue]
	5074214720 -> 5294845824
	5294845824 [label=AccumulateGrad]
	5294845968 -> 5294845584
	5294845776 -> 5075059232
	5294845776 [label=TBackward0]
	5294846112 -> 5294845776
	5074215040 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	5074215040 -> 5294846112
	5294846112 [label=AccumulateGrad]
	5075059232 -> 5074215840
}
