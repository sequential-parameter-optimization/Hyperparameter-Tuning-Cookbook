digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	4987716624 [label="
 (2, 1)" fillcolor=darkolivegreen1]
	4988191024 [label=AddmmBackward0]
	4987449744 -> 4988191024
	4987715744 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	4987715744 -> 4987449744
	4987449744 [label=AccumulateGrad]
	4988392480 -> 4988191024
	4988392480 [label=ReluBackward0]
	5008785264 -> 4988392480
	5008785264 [label=AddBackward0]
	5008785168 -> 5008785264
	5008785168 [label=NativeBatchNormBackward0]
	5008785072 -> 5008785168
	5008785072 [label=MmBackward0]
	5008900256 -> 5008785072
	5008900256 [label=ReluBackward0]
	5008900448 -> 5008900256
	5008900448 [label=NativeBatchNormBackward0]
	5008900544 -> 5008900448
	5008900544 [label=MmBackward0]
	5008785360 -> 5008900544
	5008785360 [label=ReluBackward0]
	5008900832 -> 5008785360
	5008900832 [label=AddBackward0]
	5008900928 -> 5008900832
	5008900928 [label=NativeBatchNormBackward0]
	5008901072 -> 5008900928
	5008901072 [label=MmBackward0]
	5008901264 -> 5008901072
	5008901264 [label=ReluBackward0]
	5008901408 -> 5008901264
	5008901408 [label=NativeBatchNormBackward0]
	5008901504 -> 5008901408
	5008901504 [label=MmBackward0]
	5008900880 -> 5008901504
	5008900880 [label=AddmmBackward0]
	5008901792 -> 5008900880
	4987352752 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	4987352752 -> 5008901792
	5008901792 [label=AccumulateGrad]
	5008901744 -> 5008900880
	5008901744 [label=TBackward0]
	5008901888 -> 5008901744
	4987342432 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	4987342432 -> 5008901888
	5008901888 [label=AccumulateGrad]
	5008901696 -> 5008901504
	5008901696 [label=TBackward0]
	5008902032 -> 5008901696
	4829505216 [label="blocks.0.net.0.weight
 (64, 64)" fillcolor=lightblue]
	4829505216 -> 5008902032
	5008902032 [label=AccumulateGrad]
	5008901456 -> 5008901408
	4346163232 [label="blocks.0.net.1.weight
 (64)" fillcolor=lightblue]
	4346163232 -> 5008901456
	5008901456 [label=AccumulateGrad]
	5008901312 -> 5008901408
	4352195424 [label="blocks.0.net.1.bias
 (64)" fillcolor=lightblue]
	4352195424 -> 5008901312
	5008901312 [label=AccumulateGrad]
	5008901216 -> 5008901072
	5008901216 [label=TBackward0]
	5008901840 -> 5008901216
	4981755808 [label="blocks.0.net.3.weight
 (64, 64)" fillcolor=lightblue]
	4981755808 -> 5008901840
	5008901840 [label=AccumulateGrad]
	5008901024 -> 5008900928
	4987352512 [label="blocks.0.net.4.weight
 (64)" fillcolor=lightblue]
	4987352512 -> 5008901024
	5008901024 [label=AccumulateGrad]
	5008900976 -> 5008900928
	4987352672 [label="blocks.0.net.4.bias
 (64)" fillcolor=lightblue]
	4987352672 -> 5008900976
	5008900976 [label=AccumulateGrad]
	5008900880 -> 5008900832
	5008900736 -> 5008900544
	5008900736 [label=TBackward0]
	5008901120 -> 5008900736
	4987354032 [label="blocks.1.net.0.weight
 (64, 64)" fillcolor=lightblue]
	4987354032 -> 5008901120
	5008901120 [label=AccumulateGrad]
	5008900496 -> 5008900448
	4987354112 [label="blocks.1.net.1.weight
 (64)" fillcolor=lightblue]
	4987354112 -> 5008900496
	5008900496 [label=AccumulateGrad]
	5008900352 -> 5008900448
	4987354192 [label="blocks.1.net.1.bias
 (64)" fillcolor=lightblue]
	4987354192 -> 5008900352
	5008900352 [label=AccumulateGrad]
	5008900304 -> 5008785072
	5008900304 [label=TBackward0]
	5008900640 -> 5008900304
	4987354592 [label="blocks.1.net.3.weight
 (64, 64)" fillcolor=lightblue]
	4987354592 -> 5008900640
	5008900640 [label=AccumulateGrad]
	5008785024 -> 5008785168
	4987354672 [label="blocks.1.net.4.weight
 (64)" fillcolor=lightblue]
	4987354672 -> 5008785024
	5008785024 [label=AccumulateGrad]
	5008785216 -> 5008785168
	4987354752 [label="blocks.1.net.4.bias
 (64)" fillcolor=lightblue]
	4987354752 -> 5008785216
	5008785216 [label=AccumulateGrad]
	5008785360 -> 5008785264
	5008784976 -> 4988191024
	5008784976 [label=TBackward0]
	5008784928 -> 5008784976
	4987715664 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	4987715664 -> 5008784928
	5008784928 [label=AccumulateGrad]
	4988191024 -> 4987716624
}
