digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	5278562048 [label="
 (2, 1)" fillcolor=darkolivegreen1]
	5258682208 [label=AddmmBackward0]
	5278746272 -> 5258682208
	5276301456 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	5276301456 -> 5278746272
	5278746272 [label=AccumulateGrad]
	5278746368 -> 5258682208
	5278746368 [label=ReluBackward0]
	5262801696 -> 5278746368
	5262801696 [label=AddBackward0]
	5278746608 -> 5262801696
	5278746608 [label=NativeBatchNormBackward0]
	5278746704 -> 5278746608
	5278746704 [label=MmBackward0]
	5278746896 -> 5278746704
	5278746896 [label=ReluBackward0]
	5278747040 -> 5278746896
	5278747040 [label=NativeBatchNormBackward0]
	5278747136 -> 5278747040
	5278747136 [label=MmBackward0]
	5278746512 -> 5278747136
	5278746512 [label=ReluBackward0]
	5278747424 -> 5278746512
	5278747424 [label=AddBackward0]
	5278747520 -> 5278747424
	5278747520 [label=NativeBatchNormBackward0]
	5278747664 -> 5278747520
	5278747664 [label=MmBackward0]
	5278747856 -> 5278747664
	5278747856 [label=ReluBackward0]
	5278748000 -> 5278747856
	5278748000 [label=NativeBatchNormBackward0]
	5278748096 -> 5278748000
	5278748096 [label=MmBackward0]
	5278747472 -> 5278748096
	5278747472 [label=AddmmBackward0]
	5278748384 -> 5278747472
	5276296736 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	5276296736 -> 5278748384
	5278748384 [label=AccumulateGrad]
	5278748336 -> 5278747472
	5278748336 [label=TBackward0]
	5278748480 -> 5278748336
	4531398656 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	4531398656 -> 5278748480
	5278748480 [label=AccumulateGrad]
	5278748288 -> 5278748096
	5278748288 [label=TBackward0]
	5278748624 -> 5278748288
	5276297936 [label="blocks.0.net.0.weight
 (64, 64)" fillcolor=lightblue]
	5276297936 -> 5278748624
	5278748624 [label=AccumulateGrad]
	5278748048 -> 5278748000
	5276298016 [label="blocks.0.net.1.weight
 (64)" fillcolor=lightblue]
	5276298016 -> 5278748048
	5278748048 [label=AccumulateGrad]
	5278747904 -> 5278748000
	5276298176 [label="blocks.0.net.1.bias
 (64)" fillcolor=lightblue]
	5276298176 -> 5278747904
	5278747904 [label=AccumulateGrad]
	5278747808 -> 5278747664
	5278747808 [label=TBackward0]
	5278748432 -> 5278747808
	5276299216 [label="blocks.0.net.3.weight
 (64, 64)" fillcolor=lightblue]
	5276299216 -> 5278748432
	5278748432 [label=AccumulateGrad]
	5278747616 -> 5278747520
	5276299296 [label="blocks.0.net.4.weight
 (64)" fillcolor=lightblue]
	5276299296 -> 5278747616
	5278747616 [label=AccumulateGrad]
	5278747568 -> 5278747520
	5276299376 [label="blocks.0.net.4.bias
 (64)" fillcolor=lightblue]
	5276299376 -> 5278747568
	5278747568 [label=AccumulateGrad]
	5278747472 -> 5278747424
	5278747328 -> 5278747136
	5278747328 [label=TBackward0]
	5278747712 -> 5278747328
	5276299936 [label="blocks.1.net.0.weight
 (64, 64)" fillcolor=lightblue]
	5276299936 -> 5278747712
	5278747712 [label=AccumulateGrad]
	5278747088 -> 5278747040
	5276300016 [label="blocks.1.net.1.weight
 (64)" fillcolor=lightblue]
	5276300016 -> 5278747088
	5278747088 [label=AccumulateGrad]
	5278746944 -> 5278747040
	5276300096 [label="blocks.1.net.1.bias
 (64)" fillcolor=lightblue]
	5276300096 -> 5278746944
	5278746944 [label=AccumulateGrad]
	5278746848 -> 5278746704
	5278746848 [label=TBackward0]
	5278747232 -> 5278746848
	5276300496 [label="blocks.1.net.3.weight
 (64, 64)" fillcolor=lightblue]
	5276300496 -> 5278747232
	5278747232 [label=AccumulateGrad]
	5278746656 -> 5278746608
	5276300576 [label="blocks.1.net.4.weight
 (64)" fillcolor=lightblue]
	5276300576 -> 5278746656
	5278746656 [label=AccumulateGrad]
	5278746416 -> 5278746608
	5276300656 [label="blocks.1.net.4.bias
 (64)" fillcolor=lightblue]
	5276300656 -> 5278746416
	5278746416 [label=AccumulateGrad]
	5278746512 -> 5262801696
	5278746320 -> 5258682208
	5278746320 [label=TBackward0]
	5278746752 -> 5278746320
	5276301376 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	5276301376 -> 5278746752
	5278746752 [label=AccumulateGrad]
	5258682208 -> 5278562048
}
