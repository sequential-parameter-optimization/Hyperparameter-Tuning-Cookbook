digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	4661247696 [label="
 (2, 1)" fillcolor=darkolivegreen1]
	4548373008 [label=AddmmBackward0]
	4658351984 -> 4548373008
	4661246976 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	4661246976 -> 4658351984
	4658351984 [label=AccumulateGrad]
	4659308640 -> 4548373008
	4659308640 [label=ReluBackward0]
	4663919856 -> 4659308640
	4663919856 [label=AddBackward0]
	4663919760 -> 4663919856
	4663919760 [label=NativeBatchNormBackward0]
	4658350064 -> 4663919760
	4658350064 [label=MmBackward0]
	4663919712 -> 4658350064
	4663919712 [label=ReluBackward0]
	4663920288 -> 4663919712
	4663920288 [label=NativeBatchNormBackward0]
	4663920384 -> 4663920288
	4663920384 [label=MmBackward0]
	4663919952 -> 4663920384
	4663919952 [label=ReluBackward0]
	4663920672 -> 4663919952
	4663920672 [label=AddBackward0]
	4663920768 -> 4663920672
	4663920768 [label=NativeBatchNormBackward0]
	4663920912 -> 4663920768
	4663920912 [label=MmBackward0]
	4663921104 -> 4663920912
	4663921104 [label=ReluBackward0]
	4663921248 -> 4663921104
	4663921248 [label=NativeBatchNormBackward0]
	4663921344 -> 4663921248
	4663921344 [label=MmBackward0]
	4663920720 -> 4663921344
	4663920720 [label=AddmmBackward0]
	4663921632 -> 4663920720
	4661237696 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	4661237696 -> 4663921632
	4663921632 [label=AccumulateGrad]
	4663921584 -> 4663920720
	4663921584 [label=TBackward0]
	4663921728 -> 4663921584
	4661242496 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	4661242496 -> 4663921728
	4663921728 [label=AccumulateGrad]
	4663921536 -> 4663921344
	4663921536 [label=TBackward0]
	4663921872 -> 4663921536
	4655541504 [label="blocks.0.net.0.weight
 (64, 64)" fillcolor=lightblue]
	4655541504 -> 4663921872
	4663921872 [label=AccumulateGrad]
	4663921296 -> 4663921248
	4399122224 [label="blocks.0.net.1.weight
 (64)" fillcolor=lightblue]
	4399122224 -> 4663921296
	4663921296 [label=AccumulateGrad]
	4663921152 -> 4663921248
	4526547312 [label="blocks.0.net.1.bias
 (64)" fillcolor=lightblue]
	4526547312 -> 4663921152
	4663921152 [label=AccumulateGrad]
	4663921056 -> 4663920912
	4663921056 [label=TBackward0]
	4663921680 -> 4663921056
	4655542144 [label="blocks.0.net.3.weight
 (64, 64)" fillcolor=lightblue]
	4655542144 -> 4663921680
	4663921680 [label=AccumulateGrad]
	4663920864 -> 4663920768
	4661244336 [label="blocks.0.net.4.weight
 (64)" fillcolor=lightblue]
	4661244336 -> 4663920864
	4663920864 [label=AccumulateGrad]
	4663920816 -> 4663920768
	4661245296 [label="blocks.0.net.4.bias
 (64)" fillcolor=lightblue]
	4661245296 -> 4663920816
	4663920816 [label=AccumulateGrad]
	4663920720 -> 4663920672
	4663920576 -> 4663920384
	4663920576 [label=TBackward0]
	4663920960 -> 4663920576
	4661245776 [label="blocks.1.net.0.weight
 (64, 64)" fillcolor=lightblue]
	4661245776 -> 4663920960
	4663920960 [label=AccumulateGrad]
	4663920336 -> 4663920288
	4661245856 [label="blocks.1.net.1.weight
 (64)" fillcolor=lightblue]
	4661245856 -> 4663920336
	4663920336 [label=AccumulateGrad]
	4663920000 -> 4663920288
	4661245936 [label="blocks.1.net.1.bias
 (64)" fillcolor=lightblue]
	4661245936 -> 4663920000
	4663920000 [label=AccumulateGrad]
	4663919520 -> 4658350064
	4663919520 [label=TBackward0]
	4663920480 -> 4663919520
	4661246336 [label="blocks.1.net.3.weight
 (64, 64)" fillcolor=lightblue]
	4661246336 -> 4663920480
	4663920480 [label=AccumulateGrad]
	4663920096 -> 4663919760
	4661246416 [label="blocks.1.net.4.weight
 (64)" fillcolor=lightblue]
	4661246416 -> 4663920096
	4663920096 [label=AccumulateGrad]
	4663920048 -> 4663919760
	4661246496 [label="blocks.1.net.4.bias
 (64)" fillcolor=lightblue]
	4661246496 -> 4663920048
	4663920048 [label=AccumulateGrad]
	4663919952 -> 4663919856
	4663919616 -> 4548373008
	4663919616 [label=TBackward0]
	4663920144 -> 4663919616
	4661246896 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	4661246896 -> 4663920144
	4663920144 [label=AccumulateGrad]
	4548373008 -> 4661247696
}
