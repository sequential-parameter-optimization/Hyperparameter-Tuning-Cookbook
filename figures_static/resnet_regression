digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	4755311184 [label="
 (2, 1)" fillcolor=darkolivegreen1]
	4752948528 [label=AddmmBackward0]
	4752510352 -> 4752948528
	4752340656 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	4752340656 -> 4752510352
	4752510352 [label=AccumulateGrad]
	4755299424 -> 4752948528
	4755299424 [label=ReluBackward0]
	4755299616 -> 4755299424
	4755299616 [label=AddBackward0]
	4755299520 -> 4755299616
	4755299520 [label=NativeBatchNormBackward0]
	4755299760 -> 4755299520
	4755299760 [label=MmBackward0]
	4755299952 -> 4755299760
	4755299952 [label=ReluBackward0]
	4755300096 -> 4755299952
	4755300096 [label=NativeBatchNormBackward0]
	4755300192 -> 4755300096
	4755300192 [label=MmBackward0]
	4755299664 -> 4755300192
	4755299664 [label=ReluBackward0]
	4755300480 -> 4755299664
	4755300480 [label=AddBackward0]
	4755300576 -> 4755300480
	4755300576 [label=NativeBatchNormBackward0]
	4755300720 -> 4755300576
	4755300720 [label=MmBackward0]
	4755300912 -> 4755300720
	4755300912 [label=ReluBackward0]
	4755301056 -> 4755300912
	4755301056 [label=NativeBatchNormBackward0]
	4755301152 -> 4755301056
	4755301152 [label=MmBackward0]
	4755300624 -> 4755301152
	4755300624 [label=AddmmBackward0]
	4755301440 -> 4755300624
	4436754128 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	4436754128 -> 4755301440
	4755301440 [label=AccumulateGrad]
	4755301488 -> 4755300624
	4755301488 [label=TBackward0]
	4755301632 -> 4755301488
	4582184656 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	4582184656 -> 4755301632
	4755301632 [label=AccumulateGrad]
	4755301344 -> 4755301152
	4755301344 [label=TBackward0]
	4755301536 -> 4755301344
	4752338016 [label="blocks.0.net.0.weight
 (64, 64)" fillcolor=lightblue]
	4752338016 -> 4755301536
	4755301536 [label=AccumulateGrad]
	4755301200 -> 4755301056
	4752330816 [label="blocks.0.net.1.weight
 (64)" fillcolor=lightblue]
	4752330816 -> 4755301200
	4755301200 [label=AccumulateGrad]
	4755301008 -> 4755301056
	4752337536 [label="blocks.0.net.1.bias
 (64)" fillcolor=lightblue]
	4752337536 -> 4755301008
	4755301008 [label=AccumulateGrad]
	4755300960 -> 4755300720
	4755300960 [label=TBackward0]
	4754837840 -> 4755300960
	4752337696 [label="blocks.0.net.3.weight
 (64, 64)" fillcolor=lightblue]
	4752337696 -> 4754837840
	4754837840 [label=AccumulateGrad]
	4755300768 -> 4755300576
	4752338096 [label="blocks.0.net.4.weight
 (64)" fillcolor=lightblue]
	4752338096 -> 4755300768
	4755300768 [label=AccumulateGrad]
	4755300672 -> 4755300576
	4752339136 [label="blocks.0.net.4.bias
 (64)" fillcolor=lightblue]
	4752339136 -> 4755300672
	4755300672 [label=AccumulateGrad]
	4755300624 -> 4755300480
	4755300384 -> 4755300192
	4755300384 [label=TBackward0]
	4755300336 -> 4755300384
	4750311744 [label="blocks.1.net.0.weight
 (64, 64)" fillcolor=lightblue]
	4750311744 -> 4755300336
	4755300336 [label=AccumulateGrad]
	4755300240 -> 4755300096
	4752339536 [label="blocks.1.net.1.weight
 (64)" fillcolor=lightblue]
	4752339536 -> 4755300240
	4755300240 [label=AccumulateGrad]
	4755300048 -> 4755300096
	4752339616 [label="blocks.1.net.1.bias
 (64)" fillcolor=lightblue]
	4752339616 -> 4755300048
	4755300048 [label=AccumulateGrad]
	4755300000 -> 4755299760
	4755300000 [label=TBackward0]
	4755300288 -> 4755300000
	4752340016 [label="blocks.1.net.3.weight
 (64, 64)" fillcolor=lightblue]
	4752340016 -> 4755300288
	4755300288 [label=AccumulateGrad]
	4755299808 -> 4755299520
	4752340096 [label="blocks.1.net.4.weight
 (64)" fillcolor=lightblue]
	4752340096 -> 4755299808
	4755299808 [label=AccumulateGrad]
	4755299712 -> 4755299520
	4752340176 [label="blocks.1.net.4.bias
 (64)" fillcolor=lightblue]
	4752340176 -> 4755299712
	4755299712 [label=AccumulateGrad]
	4755299664 -> 4755299616
	4755299472 -> 4752948528
	4755299472 [label=TBackward0]
	4755299568 -> 4755299472
	4752340576 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	4752340576 -> 4755299568
	4755299568 [label=AccumulateGrad]
	4752948528 -> 4755311184
}
