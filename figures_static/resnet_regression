digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	5231483056 [label="
 (2, 1)" fillcolor=darkolivegreen1]
	5231594176 [label=AddmmBackward0]
	5231594080 -> 5231594176
	5229254992 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	5229254992 -> 5231594080
	5231594080 [label=AccumulateGrad]
	5231594128 -> 5231594176
	5231594128 [label=ReluBackward0]
	5231593984 -> 5231594128
	5231593984 [label=AddBackward0]
	5231594320 -> 5231593984
	5231594320 [label=NativeBatchNormBackward0]
	5199246336 -> 5231594320
	5199246336 [label=MmBackward0]
	5231594752 -> 5199246336
	5231594752 [label=ReluBackward0]
	5231594896 -> 5231594752
	5231594896 [label=NativeBatchNormBackward0]
	5231594992 -> 5231594896
	5231594992 [label=MmBackward0]
	5231594272 -> 5231594992
	5231594272 [label=ReluBackward0]
	5231595280 -> 5231594272
	5231595280 [label=AddBackward0]
	5231595376 -> 5231595280
	5231595376 [label=NativeBatchNormBackward0]
	5231595520 -> 5231595376
	5231595520 [label=MmBackward0]
	5231595712 -> 5231595520
	5231595712 [label=ReluBackward0]
	5231595856 -> 5231595712
	5231595856 [label=NativeBatchNormBackward0]
	5231595952 -> 5231595856
	5231595952 [label=MmBackward0]
	5231595328 -> 5231595952
	5231595328 [label=AddmmBackward0]
	5231596240 -> 5231595328
	5229251312 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	5229251312 -> 5231596240
	5231596240 [label=AccumulateGrad]
	5231596192 -> 5231595328
	5231596192 [label=TBackward0]
	5231596336 -> 5231596192
	5229250992 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	5229250992 -> 5231596336
	5231596336 [label=AccumulateGrad]
	5231596144 -> 5231595952
	5231596144 [label=TBackward0]
	5231596480 -> 5231596144
	5229252192 [label="blocks.0.net.0.weight
 (64, 64)" fillcolor=lightblue]
	5229252192 -> 5231596480
	5231596480 [label=AccumulateGrad]
	5231595904 -> 5231595856
	5229252272 [label="blocks.0.net.1.weight
 (64)" fillcolor=lightblue]
	5229252272 -> 5231595904
	5231595904 [label=AccumulateGrad]
	5231595760 -> 5231595856
	5229252432 [label="blocks.0.net.1.bias
 (64)" fillcolor=lightblue]
	5229252432 -> 5231595760
	5231595760 [label=AccumulateGrad]
	5231595664 -> 5231595520
	5231595664 [label=TBackward0]
	5231596288 -> 5231595664
	5229252992 [label="blocks.0.net.3.weight
 (64, 64)" fillcolor=lightblue]
	5229252992 -> 5231596288
	5231596288 [label=AccumulateGrad]
	5231595472 -> 5231595376
	5229252912 [label="blocks.0.net.4.weight
 (64)" fillcolor=lightblue]
	5229252912 -> 5231595472
	5231595472 [label=AccumulateGrad]
	5231595424 -> 5231595376
	5229253072 [label="blocks.0.net.4.bias
 (64)" fillcolor=lightblue]
	5229253072 -> 5231595424
	5231595424 [label=AccumulateGrad]
	5231595328 -> 5231595280
	5231595184 -> 5231594992
	5231595184 [label=TBackward0]
	5231595568 -> 5231595184
	5229253632 [label="blocks.1.net.0.weight
 (64, 64)" fillcolor=lightblue]
	5229253632 -> 5231595568
	5231595568 [label=AccumulateGrad]
	5231594944 -> 5231594896
	5229253712 [label="blocks.1.net.1.weight
 (64)" fillcolor=lightblue]
	5229253712 -> 5231594944
	5231594944 [label=AccumulateGrad]
	5231594800 -> 5231594896
	5229253792 [label="blocks.1.net.1.bias
 (64)" fillcolor=lightblue]
	5229253792 -> 5231594800
	5231594800 [label=AccumulateGrad]
	5231594704 -> 5199246336
	5231594704 [label=TBackward0]
	5231595088 -> 5231594704
	5229254192 [label="blocks.1.net.3.weight
 (64, 64)" fillcolor=lightblue]
	5229254192 -> 5231595088
	5231595088 [label=AccumulateGrad]
	5231594560 -> 5231594320
	5229254272 [label="blocks.1.net.4.weight
 (64)" fillcolor=lightblue]
	5229254272 -> 5231594560
	5231594560 [label=AccumulateGrad]
	5231594512 -> 5231594320
	5229254352 [label="blocks.1.net.4.bias
 (64)" fillcolor=lightblue]
	5229254352 -> 5231594512
	5231594512 [label=AccumulateGrad]
	5231594272 -> 5231593984
	5231594224 -> 5231594176
	5231594224 [label=TBackward0]
	5231594608 -> 5231594224
	5229254912 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	5229254912 -> 5231594608
	5231594608 [label=AccumulateGrad]
	5231594176 -> 5231483056
}
