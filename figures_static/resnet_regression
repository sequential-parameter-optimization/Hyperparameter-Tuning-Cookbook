digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	4674182336 [label="
 (2, 1)" fillcolor=darkolivegreen1]
	4676742320 [label=AddmmBackward0]
	4675069040 -> 4676742320
	4674185136 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	4674185136 -> 4675069040
	4675069040 [label=AccumulateGrad]
	4676742464 -> 4676742320
	4676742464 [label=ReluBackward0]
	4676731280 -> 4676742464
	4676731280 [label=AddBackward0]
	4676742608 -> 4676731280
	4676742608 [label=NativeBatchNormBackward0]
	4676742752 -> 4676742608
	4676742752 [label=MmBackward0]
	4676742848 -> 4676742752
	4676742848 [label=ReluBackward0]
	4676743040 -> 4676742848
	4676743040 [label=NativeBatchNormBackward0]
	4676743136 -> 4676743040
	4676743136 [label=MmBackward0]
	4676742656 -> 4676743136
	4676742656 [label=ReluBackward0]
	4676743424 -> 4676742656
	4676743424 [label=AddBackward0]
	4676743520 -> 4676743424
	4676743520 [label=NativeBatchNormBackward0]
	4676743664 -> 4676743520
	4676743664 [label=MmBackward0]
	4676743856 -> 4676743664
	4676743856 [label=ReluBackward0]
	4676744000 -> 4676743856
	4676744000 [label=NativeBatchNormBackward0]
	4676744096 -> 4676744000
	4676744096 [label=MmBackward0]
	4676743472 -> 4676744096
	4676743472 [label=AddmmBackward0]
	4676744384 -> 4676743472
	4674182656 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	4674182656 -> 4676744384
	4676744384 [label=AccumulateGrad]
	4676744336 -> 4676743472
	4676744336 [label=TBackward0]
	4676744480 -> 4676744336
	4674182416 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	4674182416 -> 4676744480
	4676744480 [label=AccumulateGrad]
	4676744288 -> 4676744096
	4676744288 [label=TBackward0]
	4676744624 -> 4676744288
	4425627552 [label="blocks.0.net.0.weight
 (64, 64)" fillcolor=lightblue]
	4425627552 -> 4676744624
	4676744624 [label=AccumulateGrad]
	4676744048 -> 4676744000
	4426702576 [label="blocks.0.net.1.weight
 (64)" fillcolor=lightblue]
	4426702576 -> 4676744048
	4676744048 [label=AccumulateGrad]
	4676743904 -> 4676744000
	4432864080 [label="blocks.0.net.1.bias
 (64)" fillcolor=lightblue]
	4432864080 -> 4676743904
	4676743904 [label=AccumulateGrad]
	4676743808 -> 4676743664
	4676743808 [label=TBackward0]
	4676744432 -> 4676743808
	4674181616 [label="blocks.0.net.3.weight
 (64, 64)" fillcolor=lightblue]
	4674181616 -> 4676744432
	4676744432 [label=AccumulateGrad]
	4676743616 -> 4676743520
	4674182816 [label="blocks.0.net.4.weight
 (64)" fillcolor=lightblue]
	4674182816 -> 4676743616
	4676743616 [label=AccumulateGrad]
	4676743568 -> 4676743520
	4674182736 [label="blocks.0.net.4.bias
 (64)" fillcolor=lightblue]
	4674182736 -> 4676743568
	4676743568 [label=AccumulateGrad]
	4676743472 -> 4676743424
	4676743328 -> 4676743136
	4676743328 [label=TBackward0]
	4676743712 -> 4676743328
	4674183936 [label="blocks.1.net.0.weight
 (64, 64)" fillcolor=lightblue]
	4674183936 -> 4676743712
	4676743712 [label=AccumulateGrad]
	4676743088 -> 4676743040
	4674184016 [label="blocks.1.net.1.weight
 (64)" fillcolor=lightblue]
	4674184016 -> 4676743088
	4676743088 [label=AccumulateGrad]
	4676742944 -> 4676743040
	4674184096 [label="blocks.1.net.1.bias
 (64)" fillcolor=lightblue]
	4674184096 -> 4676742944
	4676742944 [label=AccumulateGrad]
	4676742896 -> 4676742752
	4676742896 [label=TBackward0]
	4676743232 -> 4676742896
	4674184496 [label="blocks.1.net.3.weight
 (64, 64)" fillcolor=lightblue]
	4674184496 -> 4676743232
	4676743232 [label=AccumulateGrad]
	4676742704 -> 4676742608
	4674184576 [label="blocks.1.net.4.weight
 (64)" fillcolor=lightblue]
	4674184576 -> 4676742704
	4676742704 [label=AccumulateGrad]
	4676742560 -> 4676742608
	4674184656 [label="blocks.1.net.4.bias
 (64)" fillcolor=lightblue]
	4674184656 -> 4676742560
	4676742560 [label=AccumulateGrad]
	4676742656 -> 4676731280
	4676742512 -> 4676742320
	4676742512 [label=TBackward0]
	4676742800 -> 4676742512
	4674185056 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	4674185056 -> 4676742800
	4676742800 [label=AccumulateGrad]
	4676742320 -> 4674182336
}
