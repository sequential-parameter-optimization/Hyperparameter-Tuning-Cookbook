digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	5247229760 [label="
 (2, 1)" fillcolor=darkolivegreen1]
	5250805104 [label=AddmmBackward0]
	5250804960 -> 5250805104
	5247229040 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	5247229040 -> 5250804960
	5250804960 [label=AccumulateGrad]
	5250805008 -> 5250805104
	5250805008 [label=ReluBackward0]
	5250804816 -> 5250805008
	5250804816 [label=AddBackward0]
	5250805056 -> 5250804816
	5250805056 [label=NativeBatchNormBackward0]
	5250805536 -> 5250805056
	5250805536 [label=MmBackward0]
	5250805632 -> 5250805536
	5250805632 [label=ReluBackward0]
	5250805776 -> 5250805632
	5250805776 [label=NativeBatchNormBackward0]
	5250805872 -> 5250805776
	5250805872 [label=MmBackward0]
	5250805296 -> 5250805872
	5250805296 [label=ReluBackward0]
	5250806160 -> 5250805296
	5250806160 [label=AddBackward0]
	5250806256 -> 5250806160
	5250806256 [label=NativeBatchNormBackward0]
	5250806400 -> 5250806256
	5250806400 [label=MmBackward0]
	5250806592 -> 5250806400
	5250806592 [label=ReluBackward0]
	5250806736 -> 5250806592
	5250806736 [label=NativeBatchNormBackward0]
	5250806832 -> 5250806736
	5250806832 [label=MmBackward0]
	5250806208 -> 5250806832
	5250806208 [label=AddmmBackward0]
	5250807120 -> 5250806208
	5247226400 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	5247226400 -> 5250807120
	5250807120 [label=AccumulateGrad]
	5250807072 -> 5250806208
	5250807072 [label=TBackward0]
	5250807216 -> 5250807072
	5247226560 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	5247226560 -> 5250807216
	5250807216 [label=AccumulateGrad]
	5250807024 -> 5250806832
	5250807024 [label=TBackward0]
	5250807360 -> 5250807024
	5247225440 [label="blocks.0.net.0.weight
 (64, 64)" fillcolor=lightblue]
	5247225440 -> 5250807360
	5250807360 [label=AccumulateGrad]
	5250806784 -> 5250806736
	5079460400 [label="blocks.0.net.1.weight
 (64)" fillcolor=lightblue]
	5079460400 -> 5250806784
	5250806784 [label=AccumulateGrad]
	5250806640 -> 5250806736
	5099920416 [label="blocks.0.net.1.bias
 (64)" fillcolor=lightblue]
	5099920416 -> 5250806640
	5250806640 [label=AccumulateGrad]
	5250806544 -> 5250806400
	5250806544 [label=TBackward0]
	5250807168 -> 5250806544
	5077151376 [label="blocks.0.net.3.weight
 (64, 64)" fillcolor=lightblue]
	5077151376 -> 5250807168
	5250807168 [label=AccumulateGrad]
	5250806352 -> 5250806256
	5247226640 [label="blocks.0.net.4.weight
 (64)" fillcolor=lightblue]
	5247226640 -> 5250806352
	5250806352 [label=AccumulateGrad]
	5250806304 -> 5250806256
	5247225920 [label="blocks.0.net.4.bias
 (64)" fillcolor=lightblue]
	5247225920 -> 5250806304
	5250806304 [label=AccumulateGrad]
	5250806208 -> 5250806160
	5250806064 -> 5250805872
	5250806064 [label=TBackward0]
	5250806448 -> 5250806064
	5247227920 [label="blocks.1.net.0.weight
 (64, 64)" fillcolor=lightblue]
	5247227920 -> 5250806448
	5250806448 [label=AccumulateGrad]
	5250805824 -> 5250805776
	5247228000 [label="blocks.1.net.1.weight
 (64)" fillcolor=lightblue]
	5247228000 -> 5250805824
	5250805824 [label=AccumulateGrad]
	5250805680 -> 5250805776
	5247228080 [label="blocks.1.net.1.bias
 (64)" fillcolor=lightblue]
	5247228080 -> 5250805680
	5250805680 [label=AccumulateGrad]
	5250805344 -> 5250805536
	5250805344 [label=TBackward0]
	5250805968 -> 5250805344
	5247228480 [label="blocks.1.net.3.weight
 (64, 64)" fillcolor=lightblue]
	5247228480 -> 5250805968
	5250805968 [label=AccumulateGrad]
	5250805488 -> 5250805056
	5247228560 [label="blocks.1.net.4.weight
 (64)" fillcolor=lightblue]
	5247228560 -> 5250805488
	5250805488 [label=AccumulateGrad]
	5250805440 -> 5250805056
	5247228640 [label="blocks.1.net.4.bias
 (64)" fillcolor=lightblue]
	5247228640 -> 5250805440
	5250805440 [label=AccumulateGrad]
	5250805296 -> 5250804816
	5250805200 -> 5250805104
	5250805200 [label=TBackward0]
	5250805584 -> 5250805200
	5247228960 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	5247228960 -> 5250805584
	5250805584 [label=AccumulateGrad]
	5250805104 -> 5247229760
}
