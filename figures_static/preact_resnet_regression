digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	4881320688 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	4908540320 [label=AddmmBackward0]
	4908990176 -> 4908540320
	4909077264 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	4909077264 -> 4908990176
	4908990176 [label=AccumulateGrad]
	4908990320 -> 4908540320
	4908990320 [label=AddBackward0]
	4908987008 -> 4908990320
	4908987008 [label=MmBackward0]
	4908990032 -> 4908987008
	4908990032 [label=ReluBackward0]
	4908990272 -> 4908990032
	4908990272 [label=NativeLayerNormBackward0]
	4908988880 -> 4908990272
	4908988880 [label=MmBackward0]
	4898097328 -> 4908988880
	4898097328 [label=ReluBackward0]
	4898097424 -> 4898097328
	4898097424 [label=NativeLayerNormBackward0]
	4908985280 -> 4898097424
	4908985280 [label=AddBackward0]
	4898098528 -> 4908985280
	4898098528 [label=MmBackward0]
	4898098960 -> 4898098528
	4898098960 [label=ReluBackward0]
	4898097568 -> 4898098960
	4898097568 [label=NativeLayerNormBackward0]
	4898096320 -> 4898097568
	4898096320 [label=MmBackward0]
	4898098672 -> 4898096320
	4898098672 [label=ReluBackward0]
	4898098816 -> 4898098672
	4898098816 [label=NativeLayerNormBackward0]
	4898096176 -> 4898098816
	4898096176 [label=AddmmBackward0]
	4909252816 -> 4898096176
	4909074784 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	4909074784 -> 4909252816
	4909252816 [label=AccumulateGrad]
	4909252768 -> 4898096176
	4909252768 [label=TBackward0]
	4909252912 -> 4909252768
	4909075584 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	4909075584 -> 4909252912
	4909252912 [label=AccumulateGrad]
	4898099392 -> 4898098816
	4370061488 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	4370061488 -> 4898099392
	4898099392 [label=AccumulateGrad]
	4898098624 -> 4898098816
	4370061648 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	4370061648 -> 4898098624
	4898098624 [label=AccumulateGrad]
	4898102368 -> 4898096320
	4898102368 [label=TBackward0]
	4898095984 -> 4898102368
	4897914576 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4897914576 -> 4898095984
	4898095984 [label=AccumulateGrad]
	4898098288 -> 4898097568
	4898148736 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	4898148736 -> 4898098288
	4898098288 [label=AccumulateGrad]
	4898096080 -> 4898097568
	4870343248 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	4870343248 -> 4898096080
	4898096080 [label=AccumulateGrad]
	4898104096 -> 4898098528
	4898104096 [label=TBackward0]
	4898099536 -> 4898104096
	4869199408 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4869199408 -> 4898099536
	4898099536 [label=AccumulateGrad]
	4898096176 -> 4908985280
	4898097712 -> 4898097424
	4909075744 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	4909075744 -> 4898097712
	4898097712 [label=AccumulateGrad]
	4898098912 -> 4898097424
	4909074224 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	4909074224 -> 4898098912
	4898098912 [label=AccumulateGrad]
	4898098336 -> 4908988880
	4898098336 [label=TBackward0]
	4898095600 -> 4898098336
	4909073664 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4909073664 -> 4898095600
	4898095600 [label=AccumulateGrad]
	4908989840 -> 4908990272
	4909073824 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	4909073824 -> 4908989840
	4908989840 [label=AccumulateGrad]
	4908990080 -> 4908990272
	4909075664 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	4909075664 -> 4908990080
	4908990080 [label=AccumulateGrad]
	4908990416 -> 4908987008
	4908990416 [label=TBackward0]
	4908989360 -> 4908990416
	4909074464 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4909074464 -> 4908989360
	4908989360 [label=AccumulateGrad]
	4908985280 -> 4908990320
	4908986240 -> 4908540320
	4908986240 [label=TBackward0]
	4908986384 -> 4908986240
	4909075824 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	4909075824 -> 4908986384
	4908986384 [label=AccumulateGrad]
	4908540320 -> 4881320688
}
