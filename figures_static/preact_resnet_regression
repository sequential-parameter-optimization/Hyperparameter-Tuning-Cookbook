digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	4636469248 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	4636342976 [label=AddmmBackward0]
	4636343648 -> 4636342976
	4636465168 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	4636465168 -> 4636343648
	4636343648 [label=AccumulateGrad]
	4636343696 -> 4636342976
	4636343696 [label=AddBackward0]
	4636343168 -> 4636343696
	4636343168 [label=MmBackward0]
	4636339664 -> 4636343168
	4636339664 [label=ReluBackward0]
	4636340288 -> 4636339664
	4636340288 [label=NativeLayerNormBackward0]
	4636344176 -> 4636340288
	4636344176 [label=MmBackward0]
	4636344080 -> 4636344176
	4636344080 [label=ReluBackward0]
	4636342880 -> 4636344080
	4636342880 [label=NativeLayerNormBackward0]
	4636343120 -> 4636342880
	4636343120 [label=AddBackward0]
	4636341296 -> 4636343120
	4636341296 [label=MmBackward0]
	4636623056 -> 4636341296
	4636623056 [label=ReluBackward0]
	4636622912 -> 4636623056
	4636622912 [label=NativeLayerNormBackward0]
	4636623248 -> 4636622912
	4636623248 [label=MmBackward0]
	4636623440 -> 4636623248
	4636623440 [label=ReluBackward0]
	4636623584 -> 4636623440
	4636623584 [label=NativeLayerNormBackward0]
	4636342688 -> 4636623584
	4636342688 [label=AddmmBackward0]
	4636623824 -> 4636342688
	4632762464 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	4632762464 -> 4636623824
	4636623824 [label=AccumulateGrad]
	4636623776 -> 4636342688
	4636623776 [label=TBackward0]
	4636623920 -> 4636623776
	4632766064 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	4632766064 -> 4636623920
	4636623920 [label=AccumulateGrad]
	4636623680 -> 4636623584
	4368706256 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	4368706256 -> 4636623680
	4636623680 [label=AccumulateGrad]
	4636623632 -> 4636623584
	4368706176 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	4368706176 -> 4636623632
	4636623632 [label=AccumulateGrad]
	4636623392 -> 4636623248
	4636623392 [label=TBackward0]
	4636623872 -> 4636623392
	4627326896 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4627326896 -> 4636623872
	4636623872 [label=AccumulateGrad]
	4636623200 -> 4636622912
	4491194400 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	4491194400 -> 4636623200
	4636623200 [label=AccumulateGrad]
	4636623008 -> 4636622912
	4632765984 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	4632765984 -> 4636623008
	4636623008 [label=AccumulateGrad]
	4636623104 -> 4636341296
	4636623104 [label=TBackward0]
	4636623488 -> 4636623104
	4632762144 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4632762144 -> 4636623488
	4636623488 [label=AccumulateGrad]
	4636342688 -> 4636343120
	4636343504 -> 4636342880
	4632762384 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	4632762384 -> 4636343504
	4636343504 [label=AccumulateGrad]
	4636342496 -> 4636342880
	4636466048 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	4636466048 -> 4636342496
	4636342496 [label=AccumulateGrad]
	4636343984 -> 4636344176
	4636343984 [label=TBackward0]
	4636340432 -> 4636343984
	4636464928 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4636464928 -> 4636340432
	4636340432 [label=AccumulateGrad]
	4636344224 -> 4636340288
	4636464768 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	4636464768 -> 4636344224
	4636344224 [label=AccumulateGrad]
	4636340048 -> 4636340288
	4636465568 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	4636465568 -> 4636340048
	4636340048 [label=AccumulateGrad]
	4636343936 -> 4636343168
	4636343936 [label=TBackward0]
	4636344032 -> 4636343936
	4636465008 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4636465008 -> 4636344032
	4636344032 [label=AccumulateGrad]
	4636343120 -> 4636343696
	4636343744 -> 4636342976
	4636343744 [label=TBackward0]
	4636343600 -> 4636343744
	4608461232 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	4608461232 -> 4636343600
	4636343600 [label=AccumulateGrad]
	4636342976 -> 4636469248
}
