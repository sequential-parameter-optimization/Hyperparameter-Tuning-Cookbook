digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	4356390848 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	4597850528 [label=AddmmBackward0]
	4598757504 -> 4597850528
	4600879840 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	4600879840 -> 4598757504
	4598757504 [label=AccumulateGrad]
	4600789360 -> 4597850528
	4600789360 [label=AddBackward0]
	4600789936 -> 4600789360
	4600789936 [label=MmBackward0]
	4600789312 -> 4600789936
	4600789312 [label=ReluBackward0]
	4600786624 -> 4600789312
	4600786624 [label=NativeLayerNormBackward0]
	4600788208 -> 4600786624
	4600788208 [label=MmBackward0]
	4600789216 -> 4600788208
	4600789216 [label=ReluBackward0]
	4600790368 -> 4600789216
	4600790368 [label=NativeLayerNormBackward0]
	4600789984 -> 4600790368
	4600789984 [label=AddBackward0]
	4600790704 -> 4600789984
	4600790704 [label=MmBackward0]
	4600790848 -> 4600790704
	4600790848 [label=ReluBackward0]
	4600787728 -> 4600790848
	4600787728 [label=NativeLayerNormBackward0]
	4600786864 -> 4600787728
	4600786864 [label=MmBackward0]
	4598618608 -> 4600786864
	4598618608 [label=ReluBackward0]
	4601053392 -> 4598618608
	4601053392 [label=NativeLayerNormBackward0]
	4600790656 -> 4601053392
	4600790656 [label=AddmmBackward0]
	4601053632 -> 4600790656
	4600878240 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	4600878240 -> 4601053632
	4601053632 [label=AccumulateGrad]
	4601053584 -> 4600790656
	4601053584 [label=TBackward0]
	4601053728 -> 4601053584
	4600878160 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	4600878160 -> 4601053728
	4601053728 [label=AccumulateGrad]
	4601053488 -> 4601053392
	4337016160 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	4337016160 -> 4601053488
	4601053488 [label=AccumulateGrad]
	4601053440 -> 4601053392
	4337016400 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	4337016400 -> 4601053440
	4601053440 [label=AccumulateGrad]
	4600790992 -> 4600786864
	4600790992 [label=TBackward0]
	4601053680 -> 4600790992
	4600876640 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4600876640 -> 4601053680
	4601053680 [label=AccumulateGrad]
	4600790944 -> 4600787728
	4598291168 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	4598291168 -> 4600790944
	4600790944 [label=AccumulateGrad]
	4600790896 -> 4600787728
	4598291408 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	4598291408 -> 4600790896
	4600790896 [label=AccumulateGrad]
	4600790800 -> 4600790704
	4600790800 [label=TBackward0]
	4600786912 -> 4600790800
	4598287408 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4598287408 -> 4600786912
	4600786912 [label=AccumulateGrad]
	4600790656 -> 4600789984
	4600790512 -> 4600790368
	4598291328 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	4598291328 -> 4600790512
	4600790512 [label=AccumulateGrad]
	4600790464 -> 4600790368
	4600876480 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	4600876480 -> 4600790464
	4600790464 [label=AccumulateGrad]
	4600789840 -> 4600788208
	4600789840 [label=TBackward0]
	4600790752 -> 4600789840
	4600876240 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4600876240 -> 4600790752
	4600790752 [label=AccumulateGrad]
	4600789888 -> 4600786624
	4600879680 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	4600879680 -> 4600789888
	4600789888 [label=AccumulateGrad]
	4600786720 -> 4600786624
	4600878000 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	4600878000 -> 4600786720
	4600786720 [label=AccumulateGrad]
	4600789456 -> 4600789936
	4600789456 [label=TBackward0]
	4600789120 -> 4600789456
	4600879760 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4600879760 -> 4600789120
	4600789120 [label=AccumulateGrad]
	4600789984 -> 4600789360
	4600788016 -> 4597850528
	4600788016 [label=TBackward0]
	4600788976 -> 4600788016
	4596404608 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	4596404608 -> 4600788976
	4600788976 [label=AccumulateGrad]
	4597850528 -> 4356390848
}
