digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	5304155136 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	5308158960 [label=AddmmBackward0]
	5308156608 -> 5308158960
	5309695232 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	5309695232 -> 5308156608
	5308156608 [label=AccumulateGrad]
	5308166784 -> 5308158960
	5308166784 [label=AddBackward0]
	5309559424 -> 5308166784
	5309559424 [label=MmBackward0]
	5309561440 -> 5309559424
	5309561440 [label=ReluBackward0]
	5309561584 -> 5309561440
	5309561584 [label=NativeLayerNormBackward0]
	5309559040 -> 5309561584
	5309559040 [label=MmBackward0]
	5309559760 -> 5309559040
	5309559760 [label=ReluBackward0]
	5309561728 -> 5309559760
	5309561728 [label=NativeLayerNormBackward0]
	5309559136 -> 5309561728
	5309559136 [label=AddBackward0]
	5309562064 -> 5309559136
	5309562064 [label=MmBackward0]
	5309562208 -> 5309562064
	5309562208 [label=ReluBackward0]
	5309562352 -> 5309562208
	5309562352 [label=NativeLayerNormBackward0]
	5309562448 -> 5309562352
	5309562448 [label=MmBackward0]
	5309562640 -> 5309562448
	5309562640 [label=ReluBackward0]
	5309562784 -> 5309562640
	5309562784 [label=NativeLayerNormBackward0]
	5309561968 -> 5309562784
	5309561968 [label=AddmmBackward0]
	5309558944 -> 5309561968
	5304155216 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	5304155216 -> 5309558944
	5309558944 [label=AccumulateGrad]
	5309560960 -> 5309561968
	5309560960 [label=TBackward0]
	5309116672 -> 5309560960
	5309642256 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	5309642256 -> 5309116672
	5309116672 [label=AccumulateGrad]
	5309560336 -> 5309562784
	4461137504 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	4461137504 -> 5309560336
	5309560336 [label=AccumulateGrad]
	5309562832 -> 5309562784
	5268255552 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	5268255552 -> 5309562832
	5309562832 [label=AccumulateGrad]
	5309562592 -> 5309562448
	5309562592 [label=TBackward0]
	5309562688 -> 5309562592
	5282112656 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	5282112656 -> 5309562688
	5309562688 [label=AccumulateGrad]
	5309562400 -> 5309562352
	4461137824 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	4461137824 -> 5309562400
	5309562400 [label=AccumulateGrad]
	5309562256 -> 5309562352
	5309642576 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	5309642576 -> 5309562256
	5309562256 [label=AccumulateGrad]
	5309562160 -> 5309562064
	5309562160 [label=TBackward0]
	5309562544 -> 5309562160
	5309643536 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	5309643536 -> 5309562544
	5309562544 [label=AccumulateGrad]
	5309561968 -> 5309559136
	5309561824 -> 5309561728
	5309642416 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	5309642416 -> 5309561824
	5309561824 [label=AccumulateGrad]
	5309561776 -> 5309561728
	5309642656 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	5309642656 -> 5309561776
	5309561776 [label=AccumulateGrad]
	5309561104 -> 5309559040
	5309561104 [label=TBackward0]
	5309562112 -> 5309561104
	5309644176 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	5309644176 -> 5309562112
	5309562112 [label=AccumulateGrad]
	5309558848 -> 5309561584
	5309694912 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	5309694912 -> 5309558848
	5309558848 [label=AccumulateGrad]
	5309561488 -> 5309561584
	5309694992 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	5309694992 -> 5309561488
	5309561488 [label=AccumulateGrad]
	5309561344 -> 5309559424
	5309561344 [label=TBackward0]
	5309559376 -> 5309561344
	5309695072 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	5309695072 -> 5309559376
	5309559376 [label=AccumulateGrad]
	5309559136 -> 5308166784
	5309559952 -> 5308158960
	5309559952 [label=TBackward0]
	5309561008 -> 5309559952
	5309695152 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	5309695152 -> 5309561008
	5309561008 [label=AccumulateGrad]
	5308158960 -> 5304155136
}
