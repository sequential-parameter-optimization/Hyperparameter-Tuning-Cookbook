digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	5145887360 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	5145682672 [label=AddmmBackward0]
	5145685216 -> 5145682672
	5145886800 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	5145886800 -> 5145685216
	5145685216 [label=AccumulateGrad]
	5145683344 -> 5145682672
	5145683344 [label=AddBackward0]
	5145685264 -> 5145683344
	5145685264 [label=MmBackward0]
	5145684544 -> 5145685264
	5145684544 [label=ReluBackward0]
	5145684832 -> 5145684544
	5145684832 [label=NativeLayerNormBackward0]
	5145685552 -> 5145684832
	5145685552 [label=MmBackward0]
	5145685984 -> 5145685552
	5145685984 [label=ReluBackward0]
	5145686128 -> 5145685984
	5145686128 [label=NativeLayerNormBackward0]
	5145685408 -> 5145686128
	5145685408 [label=AddBackward0]
	5145686368 -> 5145685408
	5145686368 [label=MmBackward0]
	5145686512 -> 5145686368
	5145686512 [label=ReluBackward0]
	5145686656 -> 5145686512
	5145686656 [label=NativeLayerNormBackward0]
	5145686752 -> 5145686656
	5145686752 [label=MmBackward0]
	5145686944 -> 5145686752
	5145686944 [label=ReluBackward0]
	5145687088 -> 5145686944
	5145687088 [label=NativeLayerNormBackward0]
	5145686416 -> 5145687088
	5145686416 [label=AddmmBackward0]
	5145687328 -> 5145686416
	5145703632 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	5145703632 -> 5145687328
	5145687328 [label=AccumulateGrad]
	5145687376 -> 5145686416
	5145687376 [label=TBackward0]
	5145687520 -> 5145687376
	5145703312 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	5145703312 -> 5145687520
	5145687520 [label=AccumulateGrad]
	5145687184 -> 5145687088
	4391916544 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	4391916544 -> 5145687184
	5145687184 [label=AccumulateGrad]
	5145687232 -> 5145687088
	4391917424 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	4391917424 -> 5145687232
	5145687232 [label=AccumulateGrad]
	5145686992 -> 5145686752
	5145686992 [label=TBackward0]
	5145687040 -> 5145686992
	5142673152 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	5142673152 -> 5145687040
	5145687040 [label=AccumulateGrad]
	5145686800 -> 5145686656
	5145702912 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	5145702912 -> 5145686800
	5145686800 [label=AccumulateGrad]
	5145686608 -> 5145686656
	5145704432 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	5145704432 -> 5145686608
	5145686608 [label=AccumulateGrad]
	5145686560 -> 5145686368
	5145686560 [label=TBackward0]
	5145686848 -> 5145686560
	5145704272 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	5145704272 -> 5145686848
	5145686848 [label=AccumulateGrad]
	5145686416 -> 5145685408
	5145686224 -> 5145686128
	5145704512 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	5145704512 -> 5145686224
	5145686224 [label=AccumulateGrad]
	5145686272 -> 5145686128
	5145704592 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	5145704592 -> 5145686272
	5145686272 [label=AccumulateGrad]
	5145686032 -> 5145685552
	5145686032 [label=TBackward0]
	5145686080 -> 5145686032
	5145706112 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	5145706112 -> 5145686080
	5145686080 [label=AccumulateGrad]
	5145685504 -> 5145684832
	5145706272 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	5145706272 -> 5145685504
	5145685504 [label=AccumulateGrad]
	5145684880 -> 5145684832
	5145706192 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	5145706192 -> 5145684880
	5145684880 [label=AccumulateGrad]
	5145684928 -> 5145685264
	5145684928 [label=TBackward0]
	5145685744 -> 5145684928
	5145706352 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	5145706352 -> 5145685744
	5145685744 [label=AccumulateGrad]
	5145685408 -> 5145683344
	5145682720 -> 5145682672
	5145682720 [label=TBackward0]
	5145682480 -> 5145682720
	5145706432 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	5145706432 -> 5145682480
	5145682480 [label=AccumulateGrad]
	5145682672 -> 5145887360
}
