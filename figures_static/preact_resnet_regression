digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	5074214880 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	5294847024 [label=AddmmBackward0]
	5075074448 -> 5294847024
	5294973536 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	5294973536 -> 5075074448
	5075074448 [label=AccumulateGrad]
	5294847744 -> 5294847024
	5294847744 [label=AddBackward0]
	5294848080 -> 5294847744
	5294848080 [label=MmBackward0]
	5074281104 -> 5294848080
	5074281104 [label=ReluBackward0]
	5074274864 -> 5074281104
	5074274864 [label=NativeLayerNormBackward0]
	5074275680 -> 5074274864
	5074275680 [label=MmBackward0]
	5074275872 -> 5074275680
	5074275872 [label=ReluBackward0]
	5074274768 -> 5074275872
	5074274768 [label=NativeLayerNormBackward0]
	5074281584 -> 5074274768
	5074281584 [label=AddBackward0]
	5295128880 -> 5074281584
	5295128880 [label=MmBackward0]
	5295129024 -> 5295128880
	5295129024 [label=ReluBackward0]
	5295129264 -> 5295129024
	5295129264 [label=NativeLayerNormBackward0]
	5295129360 -> 5295129264
	5295129360 [label=MmBackward0]
	5295129552 -> 5295129360
	5295129552 [label=ReluBackward0]
	5295129696 -> 5295129552
	5295129696 [label=NativeLayerNormBackward0]
	5295128832 -> 5295129696
	5295128832 [label=AddmmBackward0]
	5295129936 -> 5295128832
	5074215280 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	5074215280 -> 5295129936
	5295129936 [label=AccumulateGrad]
	5295129888 -> 5295128832
	5295129888 [label=TBackward0]
	4400207456 -> 5295129888
	5294969616 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	5294969616 -> 4400207456
	4400207456 [label=AccumulateGrad]
	5295129792 -> 5295129696
	4380716048 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	4380716048 -> 5295129792
	5295129792 [label=AccumulateGrad]
	5295129744 -> 5295129696
	5048808576 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	5048808576 -> 5295129744
	5295129744 [label=AccumulateGrad]
	5295129504 -> 5295129360
	5295129504 [label=TBackward0]
	5294849856 -> 5295129504
	4380716128 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4380716128 -> 5294849856
	5294849856 [label=AccumulateGrad]
	5295129312 -> 5295129264
	5074215680 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	5074215680 -> 5295129312
	5295129312 [label=AccumulateGrad]
	5295129120 -> 5295129264
	5074215760 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	5074215760 -> 5295129120
	5295129120 [label=AccumulateGrad]
	5295128976 -> 5295128880
	5295128976 [label=TBackward0]
	5295129600 -> 5295128976
	4400068512 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4400068512 -> 5295129600
	5295129600 [label=AccumulateGrad]
	5295128832 -> 5074281584
	5295128736 -> 5074274768
	5294969936 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	5294969936 -> 5295128736
	5295128736 [label=AccumulateGrad]
	5295128688 -> 5074274768
	5294969856 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	5294969856 -> 5295128688
	5295128688 [label=AccumulateGrad]
	5074276592 -> 5074275680
	5074276592 [label=TBackward0]
	5074274432 -> 5074276592
	5294971936 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	5294971936 -> 5074274432
	5074274432 [label=AccumulateGrad]
	5074276640 -> 5074274864
	5294971456 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	5294971456 -> 5074276640
	5074276640 [label=AccumulateGrad]
	5074274144 -> 5074274864
	5294971856 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	5294971856 -> 5074274144
	5074274144 [label=AccumulateGrad]
	5074281392 -> 5294848080
	5074281392 [label=TBackward0]
	5074278368 -> 5074281392
	5294973376 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	5294973376 -> 5074278368
	5074278368 [label=AccumulateGrad]
	5074281584 -> 5294847744
	5294846736 -> 5294847024
	5294846736 [label=TBackward0]
	5074276352 -> 5294846736
	5294973456 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	5294973456 -> 5074276352
	5074276352 [label=AccumulateGrad]
	5294847024 -> 5074214880
}
