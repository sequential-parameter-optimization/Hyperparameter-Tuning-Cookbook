digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	6061821696 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	6219997600 [label=AddmmBackward0]
	6267803952 -> 6219997600
	6268051104 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	6268051104 -> 6267803952
	6267803952 [label=AccumulateGrad]
	6267927664 -> 6219997600
	6267927664 [label=AddBackward0]
	6267928144 -> 6267927664
	6267928144 [label=MmBackward0]
	6267924256 -> 6267928144
	6267924256 [label=ReluBackward0]
	6267928336 -> 6267924256
	6267928336 [label=NativeLayerNormBackward0]
	6267927472 -> 6267928336
	6267927472 [label=MmBackward0]
	6267927712 -> 6267927472
	6267927712 [label=ReluBackward0]
	6267927856 -> 6267927712
	6267927856 [label=NativeLayerNormBackward0]
	6267928240 -> 6267927856
	6267928240 [label=AddBackward0]
	6267918304 -> 6267928240
	6267918304 [label=MmBackward0]
	6268207312 -> 6267918304
	6268207312 [label=ReluBackward0]
	6268207456 -> 6268207312
	6268207456 [label=NativeLayerNormBackward0]
	6268207552 -> 6268207456
	6268207552 [label=MmBackward0]
	6268207744 -> 6268207552
	6268207744 [label=ReluBackward0]
	6268207888 -> 6268207744
	6268207888 [label=NativeLayerNormBackward0]
	6267924016 -> 6268207888
	6267924016 [label=AddmmBackward0]
	6268208128 -> 6267924016
	6268050704 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	6268050704 -> 6268208128
	6268208128 [label=AccumulateGrad]
	6268208080 -> 6267924016
	6268208080 [label=TBackward0]
	6268208224 -> 6268208080
	6268049024 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	6268049024 -> 6268208224
	6268208224 [label=AccumulateGrad]
	6268207984 -> 6268207888
	6219932576 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	6219932576 -> 6268207984
	6268207984 [label=AccumulateGrad]
	6268207936 -> 6268207888
	6219932736 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	6219932736 -> 6268207936
	6268207936 [label=AccumulateGrad]
	6268207696 -> 6268207552
	6268207696 [label=TBackward0]
	6268208176 -> 6268207696
	6219928256 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	6219928256 -> 6268208176
	6268208176 [label=AccumulateGrad]
	6268207504 -> 6268207456
	4390611824 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	4390611824 -> 6268207504
	6268207504 [label=AccumulateGrad]
	6268207360 -> 6268207456
	4390611904 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	4390611904 -> 6268207360
	6268207360 [label=AccumulateGrad]
	6268207264 -> 6267918304
	6268207264 [label=TBackward0]
	6268207792 -> 6268207264
	4390613744 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4390613744 -> 6268207792
	6268207792 [label=AccumulateGrad]
	6267924016 -> 6267928240
	6267926224 -> 6267927856
	4419198304 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	4419198304 -> 6267926224
	6267926224 [label=AccumulateGrad]
	6267924208 -> 6267927856
	6051533184 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	6051533184 -> 6267924208
	6267924208 [label=AccumulateGrad]
	6267927760 -> 6267927472
	6267927760 [label=TBackward0]
	6267926128 -> 6267927760
	6268049104 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	6268049104 -> 6267926128
	6267926128 [label=AccumulateGrad]
	6267924928 -> 6267928336
	6268050944 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	6268050944 -> 6267924928
	6267924928 [label=AccumulateGrad]
	6267925792 -> 6267928336
	6268049264 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	6268049264 -> 6267925792
	6267925792 [label=AccumulateGrad]
	6267927376 -> 6267928144
	6267927376 [label=TBackward0]
	6267924160 -> 6267927376
	6268050864 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	6268050864 -> 6267924160
	6267924160 [label=AccumulateGrad]
	6267928240 -> 6267927664
	6267927568 -> 6219997600
	6267927568 [label=TBackward0]
	6267928432 -> 6267927568
	6268051024 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	6268051024 -> 6267928432
	6267928432 [label=AccumulateGrad]
	6219997600 -> 6061821696
}
