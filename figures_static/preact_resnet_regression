digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	5196032240 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	5194695920 [label=AddmmBackward0]
	5196001056 -> 5194695920
	5196035520 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	5196035520 -> 5196001056
	5196001056 [label=AccumulateGrad]
	5196003984 -> 5194695920
	5196003984 [label=AddBackward0]
	5153132016 -> 5196003984
	5153132016 [label=MmBackward0]
	5196003648 -> 5153132016
	5196003648 [label=ReluBackward0]
	5196004272 -> 5196003648
	5196004272 [label=NativeLayerNormBackward0]
	5196003552 -> 5196004272
	5196003552 [label=MmBackward0]
	5196003216 -> 5196003552
	5196003216 [label=ReluBackward0]
	5196004800 -> 5196003216
	5196004800 [label=NativeLayerNormBackward0]
	5196002880 -> 5196004800
	5196002880 [label=AddBackward0]
	5196005040 -> 5196002880
	5196005040 [label=MmBackward0]
	5196005184 -> 5196005040
	5196005184 [label=ReluBackward0]
	5196005328 -> 5196005184
	5196005328 [label=NativeLayerNormBackward0]
	5196001920 -> 5196005328
	5196001920 [label=MmBackward0]
	5196001152 -> 5196001920
	5196001152 [label=ReluBackward0]
	5196000912 -> 5196001152
	5196000912 [label=NativeLayerNormBackward0]
	5196005088 -> 5196000912
	5196005088 [label=AddmmBackward0]
	5196000624 -> 5196005088
	5196035120 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	5196035120 -> 5196000624
	5196000624 [label=AccumulateGrad]
	5196000576 -> 5196005088
	5196000576 [label=TBackward0]
	5196000384 -> 5196000576
	5196032800 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	5196032800 -> 5196000384
	5196000384 [label=AccumulateGrad]
	5196000816 -> 5196000912
	4364899728 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	4364899728 -> 5196000816
	5196000816 [label=AccumulateGrad]
	5196000768 -> 5196000912
	4364898928 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	4364898928 -> 5196000768
	5196000768 [label=AccumulateGrad]
	5196001104 -> 5196001920
	5196001104 [label=TBackward0]
	5196001008 -> 5196001104
	4364899648 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4364899648 -> 5196001008
	5196001008 [label=AccumulateGrad]
	5196000192 -> 5196005328
	5188781952 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	5188781952 -> 5196000192
	5196000192 [label=AccumulateGrad]
	5196005280 -> 5196005328
	5163182160 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	5163182160 -> 5196005280
	5196005280 [label=AccumulateGrad]
	5196005232 -> 5196005040
	5196005232 [label=TBackward0]
	5196001248 -> 5196005232
	5196033280 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	5196033280 -> 5196001248
	5196001248 [label=AccumulateGrad]
	5196005088 -> 5196002880
	5196004896 -> 5196004800
	5196032000 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	5196032000 -> 5196004896
	5196004896 [label=AccumulateGrad]
	5196004944 -> 5196004800
	5196033520 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	5196033520 -> 5196004944
	5196004944 [label=AccumulateGrad]
	5196004656 -> 5196003552
	5196004656 [label=TBackward0]
	5196004752 -> 5196004656
	5196033600 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	5196033600 -> 5196004752
	5196004752 [label=AccumulateGrad]
	5196004368 -> 5196004272
	5196035200 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	5196035200 -> 5196004368
	5196004368 [label=AccumulateGrad]
	5196004224 -> 5196004272
	5196035360 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	5196035360 -> 5196004224
	5196004224 [label=AccumulateGrad]
	5196004320 -> 5153132016
	5196004320 [label=TBackward0]
	5196004416 -> 5196004320
	5196035280 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	5196035280 -> 5196004416
	5196004416 [label=AccumulateGrad]
	5196002880 -> 5196003984
	5196000480 -> 5194695920
	5196000480 [label=TBackward0]
	5196002592 -> 5196000480
	5196035440 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	5196035440 -> 5196002592
	5196002592 [label=AccumulateGrad]
	5194695920 -> 5196032240
}
