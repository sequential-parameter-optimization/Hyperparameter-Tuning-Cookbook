digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	4718588816 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	4714627616 [label=AddmmBackward0]
	4718575184 -> 4714627616
	4718588656 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	4718588656 -> 4718575184
	4718575184 [label=AccumulateGrad]
	4718574560 -> 4714627616
	4718574560 [label=AddBackward0]
	4718570768 -> 4718574560
	4718570768 [label=MmBackward0]
	4718574512 -> 4718570768
	4718574512 [label=ReluBackward0]
	4718573072 -> 4718574512
	4718573072 [label=NativeLayerNormBackward0]
	4718574704 -> 4718573072
	4718574704 [label=MmBackward0]
	4718575568 -> 4718574704
	4718575568 [label=ReluBackward0]
	4718571296 -> 4718575568
	4718571296 [label=NativeLayerNormBackward0]
	4718575040 -> 4718571296
	4718575040 [label=AddBackward0]
	4718570048 -> 4718575040
	4718570048 [label=MmBackward0]
	4718571344 -> 4718570048
	4718571344 [label=ReluBackward0]
	4718571152 -> 4718571344
	4718571152 [label=NativeLayerNormBackward0]
	4718571056 -> 4718571152
	4718571056 [label=MmBackward0]
	4718570816 -> 4718571056
	4718570816 [label=ReluBackward0]
	4718570576 -> 4718570816
	4718570576 [label=NativeLayerNormBackward0]
	4718571488 -> 4718570576
	4718571488 [label=AddmmBackward0]
	4718570288 -> 4718571488
	4718586496 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	4718586496 -> 4718570288
	4718570288 [label=AccumulateGrad]
	4718572400 -> 4718571488
	4718572400 [label=TBackward0]
	4718572304 -> 4718572400
	4718585776 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	4718585776 -> 4718572304
	4718572304 [label=AccumulateGrad]
	4718570480 -> 4718570576
	4357281168 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	4357281168 -> 4718570480
	4718570480 [label=AccumulateGrad]
	4718572496 -> 4718570576
	4357281248 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	4357281248 -> 4718572496
	4718572496 [label=AccumulateGrad]
	4718570672 -> 4718571056
	4718570672 [label=TBackward0]
	4718570624 -> 4718570672
	4713509696 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4713509696 -> 4718570624
	4718570624 [label=AccumulateGrad]
	4718570960 -> 4718571152
	4715791056 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	4715791056 -> 4718570960
	4718570960 [label=AccumulateGrad]
	4718571200 -> 4718571152
	4718585136 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	4718585136 -> 4718571200
	4718571200 [label=AccumulateGrad]
	4718571248 -> 4718570048
	4718571248 [label=TBackward0]
	4718570912 -> 4718571248
	4718586176 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4718586176 -> 4718570912
	4718570912 [label=AccumulateGrad]
	4718571488 -> 4718575040
	4718569952 -> 4718571296
	4718586656 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	4718586656 -> 4718569952
	4718569952 [label=AccumulateGrad]
	4718570000 -> 4718571296
	4718586736 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	4718586736 -> 4718570000
	4718570000 [label=AccumulateGrad]
	4718572448 -> 4718574704
	4718572448 [label=TBackward0]
	4718571008 -> 4718572448
	4718588256 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4718588256 -> 4718571008
	4718571008 [label=AccumulateGrad]
	4718575232 -> 4718573072
	4718588416 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	4718588416 -> 4718575232
	4718575232 [label=AccumulateGrad]
	4718574800 -> 4718573072
	4718588336 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	4718588336 -> 4718574800
	4718574800 [label=AccumulateGrad]
	4718575136 -> 4718570768
	4718575136 [label=TBackward0]
	4718572880 -> 4718575136
	4718588496 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4718588496 -> 4718572880
	4718572880 [label=AccumulateGrad]
	4718575040 -> 4718574560
	4718574896 -> 4714627616
	4718574896 [label=TBackward0]
	4718573024 -> 4718574896
	4718588576 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	4718588576 -> 4718573024
	4718573024 [label=AccumulateGrad]
	4714627616 -> 4718588816
}
