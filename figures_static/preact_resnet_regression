digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	5246162160 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	5244881024 [label=AddmmBackward0]
	5249328240 -> 5244881024
	5249885168 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	5249885168 -> 5249328240
	5249328240 [label=AccumulateGrad]
	5249760800 -> 5244881024
	5249760800 [label=AddBackward0]
	5249760752 -> 5249760800
	5249760752 [label=MmBackward0]
	5249757536 -> 5249760752
	5249757536 [label=ReluBackward0]
	5249761184 -> 5249757536
	5249761184 [label=NativeLayerNormBackward0]
	5246242480 -> 5249761184
	5246242480 [label=MmBackward0]
	5246243392 -> 5246242480
	5246243392 [label=ReluBackward0]
	5246242048 -> 5246243392
	5246242048 [label=NativeLayerNormBackward0]
	5249757008 -> 5246242048
	5249757008 [label=AddBackward0]
	5246244160 -> 5249757008
	5246244160 [label=MmBackward0]
	5248891344 -> 5246244160
	5248891344 [label=ReluBackward0]
	5250040112 -> 5248891344
	5250040112 [label=NativeLayerNormBackward0]
	5250040256 -> 5250040112
	5250040256 [label=MmBackward0]
	5250040448 -> 5250040256
	5250040448 [label=ReluBackward0]
	5250040592 -> 5250040448
	5250040592 [label=NativeLayerNormBackward0]
	5246240512 -> 5250040592
	5246240512 [label=AddmmBackward0]
	5250040832 -> 5246240512
	5246163440 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	5246163440 -> 5250040832
	5250040832 [label=AccumulateGrad]
	5250040784 -> 5246240512
	5250040784 [label=TBackward0]
	5250040928 -> 5250040784
	5246165200 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	5246165200 -> 5250040928
	5250040928 [label=AccumulateGrad]
	5250040688 -> 5250040592
	4397265888 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	4397265888 -> 5250040688
	5250040688 [label=AccumulateGrad]
	5250040640 -> 5250040592
	4397265088 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	4397265088 -> 5250040640
	5250040640 [label=AccumulateGrad]
	5250040400 -> 5250040256
	5250040400 [label=TBackward0]
	5250040880 -> 5250040400
	4940866944 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4940866944 -> 5250040880
	5250040880 [label=AccumulateGrad]
	5250040208 -> 5250040112
	4939787760 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	4939787760 -> 5250040208
	5250040208 [label=AccumulateGrad]
	5250039968 -> 5250040112
	4949263216 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	4949263216 -> 5250039968
	5250039968 [label=AccumulateGrad]
	5250039920 -> 5246244160
	5250039920 [label=TBackward0]
	5250040496 -> 5250039920
	4424760480 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4424760480 -> 5250040496
	5250040496 [label=AccumulateGrad]
	5246240512 -> 5249757008
	5246244304 -> 5246242048
	5246166720 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	5246166720 -> 5246244304
	5246244304 [label=AccumulateGrad]
	5246247568 -> 5246242048
	5246167040 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	5246167040 -> 5246247568
	5246247568 [label=AccumulateGrad]
	5246243440 -> 5246242480
	5246243440 [label=TBackward0]
	5246242720 -> 5246243440
	5249883008 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	5249883008 -> 5246242720
	5246242720 [label=AccumulateGrad]
	5246247760 -> 5249761184
	5249883568 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	5249883568 -> 5246247760
	5246247760 [label=AccumulateGrad]
	5246241040 -> 5249761184
	5249883248 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	5249883248 -> 5246241040
	5246241040 [label=AccumulateGrad]
	5249757920 -> 5249760752
	5249757920 [label=TBackward0]
	5246243584 -> 5249757920
	5249883728 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	5249883728 -> 5246243584
	5246243584 [label=AccumulateGrad]
	5249757008 -> 5249760800
	5249758256 -> 5244881024
	5249758256 [label=TBackward0]
	5249758784 -> 5249758256
	5249885248 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	5249885248 -> 5249758784
	5249758784 [label=AccumulateGrad]
	5244881024 -> 5246162160
}
