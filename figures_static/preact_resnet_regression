digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	4385497456 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	4421132704 [label=AddmmBackward0]
	4949134160 -> 4421132704
	4949094992 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	4949094992 -> 4949134160
	4949134160 [label=AccumulateGrad]
	4949135168 -> 4421132704
	4949135168 [label=AddBackward0]
	4949135072 -> 4949135168
	4949135072 [label=MmBackward0]
	4949135312 -> 4949135072
	4949135312 [label=ReluBackward0]
	4949135360 -> 4949135312
	4949135360 [label=NativeLayerNormBackward0]
	4949135552 -> 4949135360
	4949135552 [label=MmBackward0]
	4949134976 -> 4949135552
	4949134976 [label=ReluBackward0]
	4949133392 -> 4949134976
	4949133392 [label=NativeLayerNormBackward0]
	4949135120 -> 4949133392
	4949135120 [label=AddBackward0]
	4949135840 -> 4949135120
	4949135840 [label=MmBackward0]
	4949135984 -> 4949135840
	4949135984 [label=ReluBackward0]
	4949136128 -> 4949135984
	4949136128 [label=NativeLayerNormBackward0]
	4949136224 -> 4949136128
	4949136224 [label=MmBackward0]
	4949136416 -> 4949136224
	4949136416 [label=ReluBackward0]
	4949136560 -> 4949136416
	4949136560 [label=NativeLayerNormBackward0]
	4949135792 -> 4949136560
	4949135792 [label=AddmmBackward0]
	4949136800 -> 4949135792
	4949094752 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	4949094752 -> 4949136800
	4949136800 [label=AccumulateGrad]
	4949136752 -> 4949135792
	4949136752 [label=TBackward0]
	4945503296 -> 4949136752
	4949094832 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	4949094832 -> 4945503296
	4945503296 [label=AccumulateGrad]
	4949136656 -> 4949136560
	4357131072 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	4357131072 -> 4949136656
	4949136656 [label=AccumulateGrad]
	4949136608 -> 4949136560
	4861899584 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	4861899584 -> 4949136608
	4949136608 [label=AccumulateGrad]
	4949136368 -> 4949136224
	4949136368 [label=TBackward0]
	4949136848 -> 4949136368
	4945439120 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4945439120 -> 4949136848
	4949136848 [label=AccumulateGrad]
	4949136176 -> 4949136128
	4449871312 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	4449871312 -> 4949136176
	4949136176 [label=AccumulateGrad]
	4949136032 -> 4949136128
	4916090176 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	4916090176 -> 4949136032
	4949136032 [label=AccumulateGrad]
	4949135936 -> 4949135840
	4949135936 [label=TBackward0]
	4949136464 -> 4949135936
	4450167584 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4450167584 -> 4949136464
	4949136464 [label=AccumulateGrad]
	4949135792 -> 4949135120
	4949134832 -> 4949133392
	4357130192 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	4357130192 -> 4949134832
	4949134832 [label=AccumulateGrad]
	4949135024 -> 4949133392
	4357130992 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	4357130992 -> 4949135024
	4949135024 [label=AccumulateGrad]
	4949132816 -> 4949135552
	4949132816 [label=TBackward0]
	4949135888 -> 4949132816
	4949092912 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4949092912 -> 4949135888
	4949135888 [label=AccumulateGrad]
	4949135504 -> 4949135360
	4949092832 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	4949092832 -> 4949135504
	4949135504 [label=AccumulateGrad]
	4949134208 -> 4949135360
	4949092672 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	4949092672 -> 4949134208
	4949134208 [label=AccumulateGrad]
	4949134448 -> 4949135072
	4949134448 [label=TBackward0]
	4949131760 -> 4949134448
	4949092752 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4949092752 -> 4949131760
	4949131760 [label=AccumulateGrad]
	4949135120 -> 4949135168
	4949134256 -> 4421132704
	4949134256 [label=TBackward0]
	4949135648 -> 4949134256
	4949094912 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	4949094912 -> 4949135648
	4949135648 [label=AccumulateGrad]
	4421132704 -> 4385497456
}
