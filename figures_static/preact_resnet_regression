digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	4531398736 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	5278747376 [label=AddmmBackward0]
	5278749488 -> 5278747376
	5278812672 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	5278812672 -> 5278749488
	5278749488 [label=AccumulateGrad]
	5278746512 -> 5278747376
	5278746512 [label=AddBackward0]
	5278746416 -> 5278746512
	5278746416 [label=MmBackward0]
	5278748576 -> 5278746416
	5278748576 [label=ReluBackward0]
	5278747664 -> 5278748576
	5278747664 [label=NativeLayerNormBackward0]
	5278747568 -> 5278747664
	5278747568 [label=MmBackward0]
	5278748480 -> 5278747568
	5278748480 [label=ReluBackward0]
	5278748336 -> 5278748480
	5278748336 [label=NativeLayerNormBackward0]
	5278748528 -> 5278748336
	5278748528 [label=AddBackward0]
	5278747136 -> 5278748528
	5278747136 [label=MmBackward0]
	5278746896 -> 5278747136
	5278746896 [label=ReluBackward0]
	5278746656 -> 5278746896
	5278746656 [label=NativeLayerNormBackward0]
	5278750304 -> 5278746656
	5278750304 [label=MmBackward0]
	5278750496 -> 5278750304
	5278750496 [label=ReluBackward0]
	5278750640 -> 5278750496
	5278750640 [label=NativeLayerNormBackward0]
	5278747232 -> 5278750640
	5278747232 [label=AddmmBackward0]
	5278750880 -> 5278747232
	5254350560 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	5254350560 -> 5278750880
	5278750880 [label=AccumulateGrad]
	5278750832 -> 5278747232
	5278750832 [label=TBackward0]
	5278750976 -> 5278750832
	5266977600 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	5266977600 -> 5278750976
	5278750976 [label=AccumulateGrad]
	5278750736 -> 5278750640
	5278775520 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	5278775520 -> 5278750736
	5278750736 [label=AccumulateGrad]
	5278750688 -> 5278750640
	5278776480 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	5278776480 -> 5278750688
	5278750688 [label=AccumulateGrad]
	5278750448 -> 5278750304
	5278750448 [label=TBackward0]
	5278750928 -> 5278750448
	4429425440 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4429425440 -> 5278750928
	5278750928 [label=AccumulateGrad]
	5278750256 -> 5278746656
	5276295936 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	5276295936 -> 5278750256
	5278750256 [label=AccumulateGrad]
	5278746752 -> 5278746656
	5257442032 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	5257442032 -> 5278746752
	5278746752 [label=AccumulateGrad]
	5278746944 -> 5278747136
	5278746944 [label=TBackward0]
	5278750544 -> 5278746944
	4395982176 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4395982176 -> 5278750544
	5278750544 [label=AccumulateGrad]
	5278747232 -> 5278748528
	5278747424 -> 5278748336
	5266123952 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	5266123952 -> 5278747424
	5278747424 [label=AccumulateGrad]
	5278746320 -> 5278748336
	4395982096 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	4395982096 -> 5278746320
	5278746320 [label=AccumulateGrad]
	5278746368 -> 5278747568
	5278746368 [label=TBackward0]
	5278747088 -> 5278746368
	4395981216 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4395981216 -> 5278747088
	5278747088 [label=AccumulateGrad]
	5278747616 -> 5278747664
	5278810672 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	5278810672 -> 5278747616
	5278747616 [label=AccumulateGrad]
	5278747904 -> 5278747664
	5278811152 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	5278811152 -> 5278747904
	5278747904 [label=AccumulateGrad]
	5278749968 -> 5278746416
	5278749968 [label=TBackward0]
	5278748432 -> 5278749968
	5278811072 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	5278811072 -> 5278748432
	5278748432 [label=AccumulateGrad]
	5278748528 -> 5278746512
	5278750112 -> 5278747376
	5278750112 [label=TBackward0]
	5278747520 -> 5278750112
	5278811232 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	5278811232 -> 5278747520
	5278747520 [label=AccumulateGrad]
	5278747376 -> 4531398736
}
