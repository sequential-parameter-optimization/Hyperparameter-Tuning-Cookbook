digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	4664372720 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	4664226480 [label=AddmmBackward0]
	4664228832 -> 4664226480
	4664370160 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	4664370160 -> 4664228832
	4664228832 [label=AccumulateGrad]
	4664229120 -> 4664226480
	4664229120 [label=AddBackward0]
	4664226288 -> 4664229120
	4664226288 [label=MmBackward0]
	4661760000 -> 4664226288
	4661760000 [label=ReluBackward0]
	4661758944 -> 4661760000
	4661758944 [label=NativeLayerNormBackward0]
	4661757072 -> 4661758944
	4661757072 [label=MmBackward0]
	4661758848 -> 4661757072
	4661758848 [label=ReluBackward0]
	4661759856 -> 4661758848
	4661759856 [label=NativeLayerNormBackward0]
	4664224752 -> 4661759856
	4664224752 [label=AddBackward0]
	4661764320 -> 4664224752
	4661764320 [label=MmBackward0]
	4661759232 -> 4661764320
	4661759232 [label=ReluBackward0]
	4661760096 -> 4661759232
	4661760096 [label=NativeLayerNormBackward0]
	4661760192 -> 4661760096
	4661760192 [label=MmBackward0]
	4661767056 -> 4661760192
	4661767056 [label=ReluBackward0]
	4664508672 -> 4661767056
	4664508672 [label=NativeLayerNormBackward0]
	4661757312 -> 4664508672
	4661757312 [label=AddmmBackward0]
	4664508912 -> 4661757312
	4664368640 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	4664368640 -> 4664508912
	4664508912 [label=AccumulateGrad]
	4664508864 -> 4661757312
	4664508864 [label=TBackward0]
	4664509008 -> 4664508864
	4661700928 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	4661700928 -> 4664509008
	4664509008 [label=AccumulateGrad]
	4664508768 -> 4664508672
	4386222192 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	4386222192 -> 4664508768
	4664508768 [label=AccumulateGrad]
	4664508720 -> 4664508672
	4386224032 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	4386224032 -> 4664508720
	4664508720 [label=AccumulateGrad]
	4664508528 -> 4661760192
	4664508528 [label=TBackward0]
	4664508960 -> 4664508528
	4661696048 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4661696048 -> 4664508960
	4664508960 [label=AccumulateGrad]
	4661760048 -> 4661760096
	4386222032 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	4386222032 -> 4661760048
	4661760048 [label=AccumulateGrad]
	4661764224 -> 4661760096
	4659861120 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	4659861120 -> 4661764224
	4661764224 [label=AccumulateGrad]
	4661757360 -> 4661764320
	4661757360 [label=TBackward0]
	4661765232 -> 4661757360
	4664368080 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4664368080 -> 4661765232
	4661765232 [label=AccumulateGrad]
	4661757312 -> 4664224752
	4661756928 -> 4661759856
	4664368720 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	4664368720 -> 4661756928
	4661756928 [label=AccumulateGrad]
	4661758368 -> 4661759856
	4664369840 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	4664369840 -> 4661758368
	4661758368 [label=AccumulateGrad]
	4661759328 -> 4661757072
	4661759328 [label=TBackward0]
	4661757120 -> 4661759328
	4664367920 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4664367920 -> 4661757120
	4661757120 [label=AccumulateGrad]
	4661770656 -> 4661758944
	4664368400 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	4664368400 -> 4661770656
	4661770656 [label=AccumulateGrad]
	4661759520 -> 4661758944
	4664370000 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	4664370000 -> 4661759520
	4661759520 [label=AccumulateGrad]
	4661759616 -> 4664226288
	4661759616 [label=TBackward0]
	4661759184 -> 4661759616
	4664369920 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4664369920 -> 4661759184
	4661759184 [label=AccumulateGrad]
	4664224752 -> 4664229120
	4664226576 -> 4664226480
	4664226576 [label=TBackward0]
	4664225136 -> 4664226576
	4664370080 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	4664370080 -> 4664225136
	4664225136 [label=AccumulateGrad]
	4664226480 -> 4664372720
}
