digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	4865996304 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	5465586752 [label=AddmmBackward0]
	5472073280 -> 5465586752
	5472173696 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	5472173696 -> 5472073280
	5472073280 [label=AccumulateGrad]
	5472072272 -> 5465586752
	5472072272 [label=AddBackward0]
	5472071888 -> 5472072272
	5472071888 [label=MmBackward0]
	5465415136 -> 5472071888
	5465415136 [label=ReluBackward0]
	5472074816 -> 5465415136
	5472074816 [label=NativeLayerNormBackward0]
	5472074000 -> 5472074816
	5472074000 [label=MmBackward0]
	5472074192 -> 5472074000
	5472074192 [label=ReluBackward0]
	5472074960 -> 5472074192
	5472074960 [label=NativeLayerNormBackward0]
	5472073328 -> 5472074960
	5472073328 [label=AddBackward0]
	5472075248 -> 5472073328
	5472075248 [label=MmBackward0]
	5472075440 -> 5472075248
	5472075440 [label=ReluBackward0]
	5472075584 -> 5472075440
	5472075584 [label=NativeLayerNormBackward0]
	5472075680 -> 5472075584
	5472075680 [label=MmBackward0]
	5472073712 -> 5472075680
	5472073712 [label=ReluBackward0]
	5469623328 -> 5472073712
	5469623328 [label=NativeLayerNormBackward0]
	5472075152 -> 5469623328
	5472075152 [label=AddmmBackward0]
	5442865424 -> 5472075152
	5472171856 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	5472171856 -> 5442865424
	5442865424 [label=AccumulateGrad]
	5465693424 -> 5472075152
	5465693424 [label=TBackward0]
	4836986400 -> 5465693424
	5472170176 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	5472170176 -> 4836986400
	4836986400 [label=AccumulateGrad]
	5471887920 -> 5469623328
	5465667408 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	5465667408 -> 5471887920
	5471887920 [label=AccumulateGrad]
	5471884272 -> 5469623328
	5465667328 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	5465667328 -> 5471884272
	5471884272 [label=AccumulateGrad]
	5472073616 -> 5472075680
	5472073616 [label=TBackward0]
	5465686416 -> 5472073616
	4585605072 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4585605072 -> 5465686416
	5465686416 [label=AccumulateGrad]
	5472075632 -> 5472075584
	4585604672 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	4585604672 -> 5472075632
	5472075632 [label=AccumulateGrad]
	5472075488 -> 5472075584
	5472171536 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	5472171536 -> 5472075488
	5472075488 [label=AccumulateGrad]
	5472075392 -> 5472075248
	5472075392 [label=TBackward0]
	4639685792 -> 5472075392
	4585604992 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4585604992 -> 4639685792
	4639685792 [label=AccumulateGrad]
	5472075152 -> 5472073328
	5472075056 -> 5472074960
	5472171776 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	5472171776 -> 5472075056
	5472075056 [label=AccumulateGrad]
	5472075008 -> 5472074960
	5472169136 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	5472169136 -> 5472075008
	5472075008 [label=AccumulateGrad]
	5472074240 -> 5472074000
	5472074240 [label=TBackward0]
	5471885328 -> 5472074240
	5472171936 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	5472171936 -> 5471885328
	5471885328 [label=AccumulateGrad]
	5472074864 -> 5472074816
	5472173376 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	5472173376 -> 5472074864
	5472074864 [label=AccumulateGrad]
	5472074720 -> 5472074816
	5472173456 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	5472173456 -> 5472074720
	5472074720 [label=AccumulateGrad]
	5472074624 -> 5472071888
	5472074624 [label=TBackward0]
	5472074144 -> 5472074624
	5472173536 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	5472173536 -> 5472074144
	5472074144 [label=AccumulateGrad]
	5472073328 -> 5472072272
	5472074096 -> 5465586752
	5472074096 [label=TBackward0]
	5472073904 -> 5472074096
	5472173616 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	5472173616 -> 5472073904
	5472073904 [label=AccumulateGrad]
	5465586752 -> 4865996304
}
