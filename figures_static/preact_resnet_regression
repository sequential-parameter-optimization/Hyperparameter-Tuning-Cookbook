digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	5612769504 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	5612617200 [label=AddmmBackward0]
	5612617008 -> 5612617200
	5612769424 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	5612769424 -> 5612617008
	5612617008 [label=AccumulateGrad]
	5612617440 -> 5612617200
	5612617440 [label=AddBackward0]
	5612815264 -> 5612617440
	5612815264 [label=MmBackward0]
	5578710496 -> 5612815264
	5578710496 [label=ReluBackward0]
	5612816368 -> 5578710496
	5612816368 [label=NativeLayerNormBackward0]
	5612816464 -> 5612816368
	5612816464 [label=MmBackward0]
	5612816656 -> 5612816464
	5612816656 [label=ReluBackward0]
	5612815984 -> 5612816656
	5612815984 [label=NativeLayerNormBackward0]
	5612815552 -> 5612815984
	5612815552 [label=AddBackward0]
	5612816992 -> 5612815552
	5612816992 [label=MmBackward0]
	5612817184 -> 5612816992
	5612817184 [label=ReluBackward0]
	5612817328 -> 5612817184
	5612817328 [label=NativeLayerNormBackward0]
	5612817424 -> 5612817328
	5612817424 [label=MmBackward0]
	5612817616 -> 5612817424
	5612817616 [label=ReluBackward0]
	5612817760 -> 5612817616
	5612817760 [label=NativeLayerNormBackward0]
	5612816896 -> 5612817760
	5612816896 [label=AddmmBackward0]
	5612818000 -> 5612816896
	5579147296 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	5579147296 -> 5612818000
	5612818000 [label=AccumulateGrad]
	5612817952 -> 5612816896
	5612817952 [label=TBackward0]
	5612818096 -> 5612817952
	5579147216 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	5579147216 -> 5612818096
	5612818096 [label=AccumulateGrad]
	5612817856 -> 5612817760
	4414683840 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	4414683840 -> 5612817856
	5612817856 [label=AccumulateGrad]
	5612817808 -> 5612817760
	4414683440 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	4414683440 -> 5612817808
	5612817808 [label=AccumulateGrad]
	5612817568 -> 5612817424
	5612817568 [label=TBackward0]
	5612617680 -> 5612817568
	5612766144 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	5612766144 -> 5612617680
	5612617680 [label=AccumulateGrad]
	5612817376 -> 5612817328
	5612765984 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	5612765984 -> 5612817376
	5612817376 [label=AccumulateGrad]
	5612817232 -> 5612817328
	5612767424 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	5612767424 -> 5612817232
	5612817232 [label=AccumulateGrad]
	5612817136 -> 5612816992
	5612817136 [label=TBackward0]
	5612817664 -> 5612817136
	5612767264 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	5612767264 -> 5612817664
	5612817664 [label=AccumulateGrad]
	5612816896 -> 5612815552
	5612816800 -> 5612815984
	5612767504 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	5612767504 -> 5612816800
	5612816800 [label=AccumulateGrad]
	5612816032 -> 5612815984
	5612767584 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	5612767584 -> 5612816032
	5612816032 [label=AccumulateGrad]
	5612816608 -> 5612816464
	5612816608 [label=TBackward0]
	5612817040 -> 5612816608
	5612767664 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	5612767664 -> 5612817040
	5612817040 [label=AccumulateGrad]
	5612816416 -> 5612816368
	5612767744 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	5612767744 -> 5612816416
	5612816416 [label=AccumulateGrad]
	5612816272 -> 5612816368
	5612767824 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	5612767824 -> 5612816272
	5612816272 [label=AccumulateGrad]
	5612816224 -> 5612815264
	5612816224 [label=TBackward0]
	5612816704 -> 5612816224
	5612769264 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	5612769264 -> 5612816704
	5612816704 [label=AccumulateGrad]
	5612815552 -> 5612617440
	5612815888 -> 5612617200
	5612815888 [label=TBackward0]
	5612816512 -> 5612815888
	5612769344 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	5612769344 -> 5612816512
	5612816512 [label=AccumulateGrad]
	5612617200 -> 5612769504
}
