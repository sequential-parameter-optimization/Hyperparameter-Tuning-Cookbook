digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	5096496240 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	5249642752 [label=AddmmBackward0]
	5099439824 -> 5249642752
	5249899712 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	5249899712 -> 5099439824
	5099439824 [label=AccumulateGrad]
	5099440976 -> 5249642752
	5099440976 [label=AddBackward0]
	5249775504 -> 5099440976
	5249775504 [label=MmBackward0]
	5249776320 -> 5249775504
	5249776320 [label=ReluBackward0]
	5249776608 -> 5249776320
	5249776608 [label=NativeLayerNormBackward0]
	5249776704 -> 5249776608
	5249776704 [label=MmBackward0]
	5249775552 -> 5249776704
	5249775552 [label=ReluBackward0]
	5249775696 -> 5249775552
	5249775696 [label=NativeLayerNormBackward0]
	5249775408 -> 5249775696
	5249775408 [label=AddBackward0]
	5249776992 -> 5249775408
	5249776992 [label=MmBackward0]
	5249777136 -> 5249776992
	5249777136 [label=ReluBackward0]
	5249777280 -> 5249777136
	5249777280 [label=NativeLayerNormBackward0]
	5249777376 -> 5249777280
	5249777376 [label=MmBackward0]
	5249777568 -> 5249777376
	5249777568 [label=ReluBackward0]
	5249773248 -> 5249777568
	5249773248 [label=NativeLayerNormBackward0]
	5249775744 -> 5249773248
	5249775744 [label=AddmmBackward0]
	5250039968 -> 5249775744
	5249899472 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	5249899472 -> 5250039968
	5250039968 [label=AccumulateGrad]
	5250039920 -> 5249775744
	5250039920 [label=TBackward0]
	5248263232 -> 5250039920
	5249899392 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	5249899392 -> 5248263232
	5248263232 [label=AccumulateGrad]
	5249773392 -> 5249773248
	4317194320 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	4317194320 -> 5249773392
	5249773392 [label=AccumulateGrad]
	5249773296 -> 5249773248
	4317195120 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	4317195120 -> 5249773296
	5249773296 [label=AccumulateGrad]
	5249777520 -> 5249777376
	5249777520 [label=TBackward0]
	5099442896 -> 5249777520
	5099381184 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	5099381184 -> 5099442896
	5099442896 [label=AccumulateGrad]
	5249777328 -> 5249777280
	5099381264 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	5099381264 -> 5249777328
	5249777328 [label=AccumulateGrad]
	5249777184 -> 5249777280
	5099377184 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	5099377184 -> 5249777184
	5249777184 [label=AccumulateGrad]
	5249777088 -> 5249776992
	5249777088 [label=TBackward0]
	5249777616 -> 5249777088
	5099381024 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	5099381024 -> 5249777616
	5249777616 [label=AccumulateGrad]
	5249775744 -> 5249775408
	5249775312 -> 5249775696
	5099379824 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	5099379824 -> 5249775312
	5249775312 [label=AccumulateGrad]
	5249774304 -> 5249775696
	4345728288 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	4345728288 -> 5249774304
	5249774304 [label=AccumulateGrad]
	5249776512 -> 5249776704
	5249776512 [label=TBackward0]
	5249777040 -> 5249776512
	5249897712 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	5249897712 -> 5249777040
	5249777040 [label=AccumulateGrad]
	5249776656 -> 5249776608
	5249899632 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	5249899632 -> 5249776656
	5249776656 [label=AccumulateGrad]
	5249776368 -> 5249776608
	5249899072 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	5249899072 -> 5249776368
	5249776368 [label=AccumulateGrad]
	5249776224 -> 5249775504
	5249776224 [label=TBackward0]
	5249775648 -> 5249776224
	5249899552 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	5249899552 -> 5249775648
	5249775648 [label=AccumulateGrad]
	5249775408 -> 5099440976
	5099439920 -> 5249642752
	5099439920 [label=TBackward0]
	5249776752 -> 5099439920
	5249897792 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	5249897792 -> 5249776752
	5249776752 [label=AccumulateGrad]
	5249642752 -> 5096496240
}
