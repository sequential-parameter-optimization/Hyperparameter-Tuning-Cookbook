digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	4955212528 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	4952654368 [label=AddmmBackward0]
	4952470576 -> 4952654368
	4955212368 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	4955212368 -> 4952470576
	4952470576 [label=AccumulateGrad]
	4955110128 -> 4952654368
	4955110128 [label=AddBackward0]
	4955109936 -> 4955110128
	4955109936 [label=MmBackward0]
	4955109456 -> 4955109936
	4955109456 [label=ReluBackward0]
	4955110272 -> 4955109456
	4955110272 [label=NativeLayerNormBackward0]
	4955109312 -> 4955110272
	4955109312 [label=MmBackward0]
	4955110752 -> 4955109312
	4955110752 [label=ReluBackward0]
	4955110560 -> 4955110752
	4955110560 [label=NativeLayerNormBackward0]
	4955109984 -> 4955110560
	4955109984 [label=AddBackward0]
	4955101920 -> 4955109984
	4955101920 [label=MmBackward0]
	4955109840 -> 4955101920
	4955109840 [label=ReluBackward0]
	4955110992 -> 4955109840
	4955110992 [label=NativeLayerNormBackward0]
	4955111088 -> 4955110992
	4955111088 [label=MmBackward0]
	4955111280 -> 4955111088
	4955111280 [label=ReluBackward0]
	4955106864 -> 4955111280
	4955106864 [label=NativeLayerNormBackward0]
	4955109792 -> 4955106864
	4955109792 [label=AddmmBackward0]
	4938128864 -> 4955109792
	4955210528 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	4955210528 -> 4938128864
	4938128864 [label=AccumulateGrad]
	4955106768 -> 4955109792
	4955106768 [label=TBackward0]
	4954678000 -> 4955106768
	4955210288 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	4955210288 -> 4954678000
	4954678000 [label=AccumulateGrad]
	4955106720 -> 4955106864
	4355137904 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	4355137904 -> 4955106720
	4955106720 [label=AccumulateGrad]
	4955106816 -> 4955106864
	4946843984 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	4946843984 -> 4955106816
	4955106816 [label=AccumulateGrad]
	4955111232 -> 4955111088
	4955111232 [label=TBackward0]
	4955111328 -> 4955111232
	4952622016 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4952622016 -> 4955111328
	4955111328 [label=AccumulateGrad]
	4955111040 -> 4955110992
	4952625136 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	4952625136 -> 4955111040
	4955111040 [label=AccumulateGrad]
	4955109744 -> 4955110992
	4514337232 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	4514337232 -> 4955109744
	4955109744 [label=AccumulateGrad]
	4955107440 -> 4955101920
	4955107440 [label=TBackward0]
	4955111184 -> 4955107440
	4355136144 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4355136144 -> 4955111184
	4955111184 [label=AccumulateGrad]
	4955109792 -> 4955109984
	4955109168 -> 4955110560
	4355138064 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	4355138064 -> 4955109168
	4955109168 [label=AccumulateGrad]
	4955109072 -> 4955110560
	4948238304 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	4948238304 -> 4955109072
	4955109072 [label=AccumulateGrad]
	4955110800 -> 4955109312
	4955110800 [label=TBackward0]
	4955107056 -> 4955110800
	4932368688 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4932368688 -> 4955107056
	4955107056 [label=AccumulateGrad]
	4955109216 -> 4955110272
	4428082672 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	4428082672 -> 4955109216
	4955109216 [label=AccumulateGrad]
	4955110224 -> 4955110272
	4955210688 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	4955210688 -> 4955110224
	4955110224 [label=AccumulateGrad]
	4955110176 -> 4955109936
	4955110176 [label=TBackward0]
	4955110704 -> 4955110176
	4955211008 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4955211008 -> 4955110704
	4955110704 [label=AccumulateGrad]
	4955109984 -> 4955110128
	4955110080 -> 4952654368
	4955110080 [label=TBackward0]
	4955109264 -> 4955110080
	4955212448 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	4955212448 -> 4955109264
	4955109264 [label=AccumulateGrad]
	4952654368 -> 4955212528
}
