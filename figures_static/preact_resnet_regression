digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	4654530016 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	4654550848 [label=AddmmBackward0]
	4654550800 -> 4654550848
	4651875088 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	4651875088 -> 4654550800
	4654550800 [label=AccumulateGrad]
	4654549984 -> 4654550848
	4654549984 [label=AddBackward0]
	4654550128 -> 4654549984
	4654550128 [label=MmBackward0]
	4654551520 -> 4654550128
	4654551520 [label=ReluBackward0]
	4654551376 -> 4654551520
	4654551376 [label=NativeLayerNormBackward0]
	4654550608 -> 4654551376
	4654550608 [label=MmBackward0]
	4654549792 -> 4654550608
	4654549792 [label=ReluBackward0]
	4654551808 -> 4654549792
	4654551808 [label=NativeLayerNormBackward0]
	4654550896 -> 4654551808
	4654550896 [label=AddBackward0]
	4654551184 -> 4654550896
	4654551184 [label=MmBackward0]
	4654554496 -> 4654551184
	4654554496 [label=ReluBackward0]
	4654552000 -> 4654554496
	4654552000 [label=NativeLayerNormBackward0]
	4654552096 -> 4654552000
	4654552096 [label=MmBackward0]
	4654552288 -> 4654552096
	4654552288 [label=ReluBackward0]
	4654552432 -> 4654552288
	4654552432 [label=NativeLayerNormBackward0]
	4654551712 -> 4654552432
	4654551712 [label=AddmmBackward0]
	4654554160 -> 4654551712
	4654526256 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	4654526256 -> 4654554160
	4654554160 [label=AccumulateGrad]
	4654554208 -> 4654551712
	4654554208 [label=TBackward0]
	4654552624 -> 4654554208
	4654527776 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	4654527776 -> 4654552624
	4654552624 [label=AccumulateGrad]
	4654552528 -> 4654552432
	4386000000 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	4386000000 -> 4654552528
	4654552528 [label=AccumulateGrad]
	4654552480 -> 4654552432
	4385999920 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	4385999920 -> 4654552480
	4654552480 [label=AccumulateGrad]
	4654552240 -> 4654552096
	4654552240 [label=TBackward0]
	4654552576 -> 4654552240
	4385999200 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4385999200 -> 4654552576
	4654552576 [label=AccumulateGrad]
	4654552048 -> 4654552000
	4651871248 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	4651871248 -> 4654552048
	4654552048 [label=AccumulateGrad]
	4654549072 -> 4654552000
	4651875408 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	4651875408 -> 4654549072
	4654549072 [label=AccumulateGrad]
	4654551088 -> 4654551184
	4654551088 [label=TBackward0]
	4654552336 -> 4654551088
	4651871328 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4651871328 -> 4654552336
	4654552336 [label=AccumulateGrad]
	4654551712 -> 4654550896
	4654551904 -> 4654551808
	4648235200 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	4648235200 -> 4654551904
	4654551904 [label=AccumulateGrad]
	4654551856 -> 4654551808
	4654526496 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	4654526496 -> 4654551856
	4654551856 [label=AccumulateGrad]
	4654549840 -> 4654550608
	4654549840 [label=TBackward0]
	4654551232 -> 4654549840
	4654526016 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4654526016 -> 4654551232
	4654551232 [label=AccumulateGrad]
	4654551328 -> 4654551376
	4654526096 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	4654526096 -> 4654551328
	4654551328 [label=AccumulateGrad]
	4654551472 -> 4654551376
	4654527536 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	4654527536 -> 4654551472
	4654551472 [label=AccumulateGrad]
	4654551040 -> 4654550128
	4654551040 [label=TBackward0]
	4654550704 -> 4654551040
	4654525856 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4654525856 -> 4654550704
	4654550704 [label=AccumulateGrad]
	4654550896 -> 4654549984
	4654549888 -> 4654550848
	4654549888 [label=TBackward0]
	4654549744 -> 4654549888
	4651874688 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	4651874688 -> 4654549744
	4654549744 [label=AccumulateGrad]
	4654550848 -> 4654530016
}
