digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	5554812912 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	5560933424 [label=AddmmBackward0]
	5560933376 -> 5560933424
	5560924224 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	5560924224 -> 5560933376
	5560933376 [label=AccumulateGrad]
	5560933328 -> 5560933424
	5560933328 [label=AddBackward0]
	5560932848 -> 5560933328
	5560932848 [label=MmBackward0]
	5560933712 -> 5560932848
	5560933712 [label=ReluBackward0]
	5560933184 -> 5560933712
	5560933184 [label=NativeLayerNormBackward0]
	5560933904 -> 5560933184
	5560933904 [label=MmBackward0]
	5560934192 -> 5560933904
	5560934192 [label=ReluBackward0]
	5560934336 -> 5560934192
	5560934336 [label=NativeLayerNormBackward0]
	5560931840 -> 5560934336
	5560931840 [label=AddBackward0]
	5560934576 -> 5560931840
	5560934576 [label=MmBackward0]
	5560934720 -> 5560934576
	5560934720 [label=ReluBackward0]
	5560934864 -> 5560934720
	5560934864 [label=NativeLayerNormBackward0]
	5560934960 -> 5560934864
	5560934960 [label=MmBackward0]
	5560935152 -> 5560934960
	5560935152 [label=ReluBackward0]
	5560935296 -> 5560935152
	5560935296 [label=NativeLayerNormBackward0]
	5560934624 -> 5560935296
	5560934624 [label=AddmmBackward0]
	5560935536 -> 5560934624
	5560921264 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	5560921264 -> 5560935536
	5560935536 [label=AccumulateGrad]
	5560935584 -> 5560934624
	5560935584 [label=TBackward0]
	5560935728 -> 5560935584
	5560922224 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	5560922224 -> 5560935728
	5560935728 [label=AccumulateGrad]
	5560935392 -> 5560935296
	4329017888 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	4329017888 -> 5560935392
	5560935392 [label=AccumulateGrad]
	5560935440 -> 5560935296
	4329017968 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	4329017968 -> 5560935440
	5560935440 [label=AccumulateGrad]
	5560935200 -> 5560934960
	5560935200 [label=TBackward0]
	5560935248 -> 5560935200
	5518788160 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	5518788160 -> 5560935248
	5560935248 [label=AccumulateGrad]
	5560935008 -> 5560934864
	5556397440 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	5556397440 -> 5560935008
	5560935008 [label=AccumulateGrad]
	5560934816 -> 5560934864
	5560920624 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	5560920624 -> 5560934816
	5560934816 [label=AccumulateGrad]
	5560934768 -> 5560934576
	5560934768 [label=TBackward0]
	5560935056 -> 5560934768
	5560922064 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	5560922064 -> 5560935056
	5560935056 [label=AccumulateGrad]
	5560934624 -> 5560931840
	5560934432 -> 5560934336
	5560923744 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	5560923744 -> 5560934432
	5560934432 [label=AccumulateGrad]
	5560934480 -> 5560934336
	5560923904 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	5560923904 -> 5560934480
	5560934480 [label=AccumulateGrad]
	5560934240 -> 5560933904
	5560934240 [label=TBackward0]
	5560934288 -> 5560934240
	5560923824 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	5560923824 -> 5560934288
	5560934288 [label=AccumulateGrad]
	5560933136 -> 5560933184
	5560923984 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	5560923984 -> 5560933136
	5560933136 [label=AccumulateGrad]
	5560933280 -> 5560933184
	5560924064 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	5560924064 -> 5560933280
	5560933280 [label=AccumulateGrad]
	5560933232 -> 5560932848
	5560933232 [label=TBackward0]
	5560934048 -> 5560933232
	5560924144 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	5560924144 -> 5560934048
	5560934048 [label=AccumulateGrad]
	5560931840 -> 5560933328
	5560933472 -> 5560933424
	5560933472 [label=TBackward0]
	5560933616 -> 5560933472
	4329017808 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	4329017808 -> 5560933616
	5560933616 [label=AccumulateGrad]
	5560933424 -> 5554812912
}
