digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	4752380048 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	5068353552 [label=AddmmBackward0]
	5068353792 -> 5068353552
	5068482320 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	5068482320 -> 5068353792
	5068353792 [label=AccumulateGrad]
	5068357152 -> 5068353552
	5068357152 [label=AddBackward0]
	5068356720 -> 5068357152
	5068356720 [label=MmBackward0]
	5065886016 -> 5068356720
	5065886016 [label=ReluBackward0]
	5065886352 -> 5065886016
	5065886352 [label=NativeLayerNormBackward0]
	5065888416 -> 5065886352
	5065888416 [label=MmBackward0]
	5065887696 -> 5065888416
	5065887696 [label=ReluBackward0]
	5065885968 -> 5065887696
	5065885968 [label=NativeLayerNormBackward0]
	5068355088 -> 5065885968
	5068355088 [label=AddBackward0]
	5065886688 -> 5068355088
	5065886688 [label=MmBackward0]
	5065887456 -> 5065886688
	5065887456 [label=ReluBackward0]
	5065885824 -> 5065887456
	5065885824 [label=NativeLayerNormBackward0]
	5068239104 -> 5065885824
	5068239104 [label=MmBackward0]
	5068636512 -> 5068239104
	5068636512 [label=ReluBackward0]
	5068636656 -> 5068636512
	5068636656 [label=NativeLayerNormBackward0]
	5065897872 -> 5068636656
	5065897872 [label=AddmmBackward0]
	5068636896 -> 5065897872
	5065822992 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	5065822992 -> 5068636896
	5068636896 [label=AccumulateGrad]
	5068636848 -> 5065897872
	5068636848 [label=TBackward0]
	5068636992 -> 5068636848
	5065824112 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	5065824112 -> 5068636992
	5068636992 [label=AccumulateGrad]
	5068636752 -> 5068636656
	4414500416 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	4414500416 -> 5068636752
	5068636752 [label=AccumulateGrad]
	5068636704 -> 5068636656
	4414500576 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	4414500576 -> 5068636704
	5068636704 [label=AccumulateGrad]
	5068636464 -> 5068239104
	5068636464 [label=TBackward0]
	5068636944 -> 5068636464
	5065827632 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	5065827632 -> 5068636944
	5068636944 [label=AccumulateGrad]
	5068239824 -> 5065885824
	5065827472 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	5065827472 -> 5068239824
	5068239824 [label=AccumulateGrad]
	5068636272 -> 5065885824
	5065827712 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	5065827712 -> 5068636272
	5068636272 [label=AccumulateGrad]
	5065887504 -> 5065886688
	5065887504 [label=TBackward0]
	5068239680 -> 5065887504
	4428044304 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4428044304 -> 5068239680
	5068239680 [label=AccumulateGrad]
	5065897872 -> 5068355088
	5065886112 -> 5065885968
	5068479280 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	5068479280 -> 5065886112
	5065886112 [label=AccumulateGrad]
	5065885680 -> 5065885968
	5068478800 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	5068478800 -> 5065885680
	5065885680 [label=AccumulateGrad]
	5065884960 -> 5065888416
	5065884960 [label=TBackward0]
	5065884672 -> 5065884960
	5068479040 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	5068479040 -> 5065884672
	5065884672 [label=AccumulateGrad]
	5065886064 -> 5065886352
	5068480720 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	5068480720 -> 5065886064
	5065886064 [label=AccumulateGrad]
	5065887840 -> 5065886352
	5068480640 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	5068480640 -> 5065887840
	5065887840 [label=AccumulateGrad]
	5065886496 -> 5068356720
	5065886496 [label=TBackward0]
	5065891344 -> 5065886496
	5068480800 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	5068480800 -> 5065891344
	5065891344 [label=AccumulateGrad]
	5068355088 -> 5068357152
	5068355424 -> 5068353552
	5068355424 [label=TBackward0]
	5065887408 -> 5068355424
	5068480880 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	5068480880 -> 5065887408
	5065887408 [label=AccumulateGrad]
	5068353552 -> 4752380048
}
