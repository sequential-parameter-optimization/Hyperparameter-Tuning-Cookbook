digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	5079924896 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	5071802464 [label=AddmmBackward0]
	5093555792 -> 5071802464
	5093673312 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	5093673312 -> 5093555792
	5093555792 [label=AccumulateGrad]
	5093555744 -> 5071802464
	5093555744 [label=AddBackward0]
	5093555936 -> 5093555744
	5093555936 [label=MmBackward0]
	5093555264 -> 5093555936
	5093555264 [label=ReluBackward0]
	5093556128 -> 5093555264
	5093556128 [label=NativeLayerNormBackward0]
	5093555456 -> 5093556128
	5093555456 [label=MmBackward0]
	5093553008 -> 5093555456
	5093553008 [label=ReluBackward0]
	5093552240 -> 5093553008
	5093552240 [label=NativeLayerNormBackward0]
	5093555888 -> 5093552240
	5093555888 [label=AddBackward0]
	5079710832 -> 5093555888
	5079710832 [label=MmBackward0]
	5092317440 -> 5079710832
	5092317440 [label=ReluBackward0]
	4441009184 -> 5092317440
	4441009184 [label=NativeLayerNormBackward0]
	5093110112 -> 4441009184
	5093110112 [label=MmBackward0]
	5093802192 -> 5093110112
	5093802192 [label=ReluBackward0]
	5093802336 -> 5093802192
	5093802336 [label=NativeLayerNormBackward0]
	5079711072 -> 5093802336
	5079711072 [label=AddmmBackward0]
	5093802576 -> 5079711072
	5093636640 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	5093636640 -> 5093802576
	5093802576 [label=AccumulateGrad]
	5093802528 -> 5079711072
	5093802528 [label=TBackward0]
	5093802672 -> 5093802528
	5093671232 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	5093671232 -> 5093802672
	5093802672 [label=AccumulateGrad]
	5093802432 -> 5093802336
	4322931440 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	4322931440 -> 5093802432
	5093802432 [label=AccumulateGrad]
	5093802384 -> 5093802336
	4322931360 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	4322931360 -> 5093802384
	5093802384 [label=AccumulateGrad]
	5093802144 -> 5093110112
	5093802144 [label=TBackward0]
	5093802624 -> 5093802144
	5079751952 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	5079751952 -> 5093802624
	5093802624 [label=AccumulateGrad]
	5093110160 -> 4441009184
	5079760672 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	5079760672 -> 5093110160
	5093110160 [label=AccumulateGrad]
	5093110832 -> 4441009184
	5079750672 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	5079750672 -> 5093110832
	5093110832 [label=AccumulateGrad]
	5092314992 -> 5079710832
	5092314992 [label=TBackward0]
	5093112752 -> 5092314992
	5093670992 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	5093670992 -> 5093112752
	5093112752 [label=AccumulateGrad]
	5079711072 -> 5093555888
	5079709344 -> 5093552240
	5093671392 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	5093671392 -> 5079709344
	5079709344 [label=AccumulateGrad]
	5079705408 -> 5093552240
	5093672832 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	5093672832 -> 5079705408
	5079705408 [label=AccumulateGrad]
	5093553776 -> 5093555456
	5093553776 [label=TBackward0]
	5079697536 -> 5093553776
	5093672912 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	5093672912 -> 5079697536
	5079697536 [label=AccumulateGrad]
	5093555504 -> 5093556128
	5093672992 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	5093672992 -> 5093555504
	5093555504 [label=AccumulateGrad]
	5093555168 -> 5093556128
	5093673072 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	5093673072 -> 5093555168
	5093555168 [label=AccumulateGrad]
	5093556080 -> 5093555936
	5093556080 [label=TBackward0]
	5093556176 -> 5093556080
	5093673152 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	5093673152 -> 5093556176
	5093556176 [label=AccumulateGrad]
	5093555888 -> 5093555744
	5093554352 -> 5071802464
	5093554352 [label=TBackward0]
	5079710736 -> 5093554352
	5093673232 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	5093673232 -> 5079710736
	5079710736 [label=AccumulateGrad]
	5071802464 -> 5079924896
}
