digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	4426117312 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	5250807840 [label=AddmmBackward0]
	5247289616 -> 5250807840
	5250931584 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	5250931584 -> 5247289616
	5247289616 [label=AccumulateGrad]
	5250808080 -> 5250807840
	5250808080 [label=AddBackward0]
	5250806976 -> 5250808080
	5250806976 [label=MmBackward0]
	5250808944 -> 5250806976
	5250808944 [label=ReluBackward0]
	5250808224 -> 5250808944
	5250808224 [label=NativeLayerNormBackward0]
	5250808176 -> 5250808224
	5250808176 [label=MmBackward0]
	5250808368 -> 5250808176
	5250808368 [label=ReluBackward0]
	5250809232 -> 5250808368
	5250809232 [label=NativeLayerNormBackward0]
	5250808032 -> 5250809232
	5250808032 [label=AddBackward0]
	5250809568 -> 5250808032
	5250809568 [label=MmBackward0]
	5250809712 -> 5250809568
	5250809712 [label=ReluBackward0]
	5250805680 -> 5250809712
	5250805680 [label=NativeLayerNormBackward0]
	5250804768 -> 5250805680
	5250804768 [label=MmBackward0]
	5250683456 -> 5250804768
	5250683456 [label=ReluBackward0]
	5249612240 -> 5250683456
	5249612240 [label=NativeLayerNormBackward0]
	5250809472 -> 5249612240
	5250809472 [label=AddmmBackward0]
	5251088688 -> 5250809472
	5250931344 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	5250931344 -> 5251088688
	5251088688 [label=AccumulateGrad]
	5251088640 -> 5250809472
	5251088640 [label=TBackward0]
	5251088784 -> 5251088640
	5250929504 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	5250929504 -> 5251088784
	5251088784 [label=AccumulateGrad]
	5251088544 -> 5249612240
	4391743280 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	4391743280 -> 5251088544
	5251088544 [label=AccumulateGrad]
	5251088496 -> 5249612240
	4391741360 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	4391741360 -> 5251088496
	5251088496 [label=AccumulateGrad]
	5250805536 -> 5250804768
	5250805536 [label=TBackward0]
	5247289568 -> 5250805536
	5099925616 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	5099925616 -> 5247289568
	5247289568 [label=AccumulateGrad]
	5250807312 -> 5250805680
	5247225120 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	5247225120 -> 5250807312
	5250807312 [label=AccumulateGrad]
	5250809760 -> 5250805680
	5247226000 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	5247226000 -> 5250809760
	5250809760 [label=AccumulateGrad]
	5250809664 -> 5250809568
	5250809664 [label=TBackward0]
	5250805488 -> 5250809664
	5247225600 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	5247225600 -> 5250805488
	5250805488 [label=AccumulateGrad]
	5250809472 -> 5250808032
	5250809328 -> 5250809232
	4391743360 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	4391743360 -> 5250809328
	5250809328 [label=AccumulateGrad]
	5250809280 -> 5250809232
	5247229120 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	5247229120 -> 5250809280
	5250809280 [label=AccumulateGrad]
	5250808416 -> 5250808176
	5250808416 [label=TBackward0]
	5250809616 -> 5250808416
	5250929184 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	5250929184 -> 5250809616
	5250809616 [label=AccumulateGrad]
	5250807648 -> 5250808224
	5250929824 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	5250929824 -> 5250807648
	5250807648 [label=AccumulateGrad]
	5250808992 -> 5250808224
	5250931504 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	5250931504 -> 5250808992
	5250808992 [label=AccumulateGrad]
	5250807360 -> 5250806976
	5250807360 [label=TBackward0]
	5250809136 -> 5250807360
	5250931424 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	5250931424 -> 5250809136
	5250809136 [label=AccumulateGrad]
	5250808032 -> 5250808080
	5250807984 -> 5250807840
	5250807984 [label=TBackward0]
	5250809088 -> 5250807984
	5250929344 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	5250929344 -> 5250809088
	5250809088 [label=AccumulateGrad]
	5250807840 -> 4426117312
}
