digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	4843055744 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	4842910048 [label=AddmmBackward0]
	4842910816 -> 4842910048
	4843054704 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	4843054704 -> 4842910816
	4842910816 [label=AccumulateGrad]
	4842910960 -> 4842910048
	4842910960 [label=AddBackward0]
	4842913264 -> 4842910960
	4842913264 [label=MmBackward0]
	4840442272 -> 4842913264
	4840442272 [label=ReluBackward0]
	4840443280 -> 4840442272
	4840443280 [label=NativeLayerNormBackward0]
	4840454272 -> 4840443280
	4840454272 [label=MmBackward0]
	4840446592 -> 4840454272
	4840446592 [label=ReluBackward0]
	4840444144 -> 4840446592
	4840444144 [label=NativeLayerNormBackward0]
	4842910768 -> 4840444144
	4842910768 [label=AddBackward0]
	4840444048 -> 4842910768
	4840444048 [label=MmBackward0]
	4840443808 -> 4840444048
	4840443808 [label=ReluBackward0]
	4842788832 -> 4840443808
	4842788832 [label=NativeLayerNormBackward0]
	4840441984 -> 4842788832
	4840441984 [label=MmBackward0]
	4843192624 -> 4840441984
	4843192624 [label=ReluBackward0]
	4843192768 -> 4843192624
	4843192768 [label=NativeLayerNormBackward0]
	4840444000 -> 4843192768
	4840444000 [label=AddmmBackward0]
	4843193008 -> 4840444000
	4843053104 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	4843053104 -> 4843193008
	4843193008 [label=AccumulateGrad]
	4843192960 -> 4840444000
	4843192960 [label=TBackward0]
	4843193104 -> 4843192960
	4843050944 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	4843050944 -> 4843193104
	4843193104 [label=AccumulateGrad]
	4843192864 -> 4843192768
	4331926416 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	4331926416 -> 4843192864
	4843192864 [label=AccumulateGrad]
	4843192816 -> 4843192768
	4331925616 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	4331925616 -> 4843192816
	4843192816 [label=AccumulateGrad]
	4843192576 -> 4840441984
	4843192576 [label=TBackward0]
	4843193056 -> 4843192576
	4331926336 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4331926336 -> 4843193056
	4843193056 [label=AccumulateGrad]
	4843192432 -> 4842788832
	4674870624 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	4674870624 -> 4843192432
	4843192432 [label=AccumulateGrad]
	4843192384 -> 4842788832
	4503293776 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	4503293776 -> 4843192384
	4843192384 [label=AccumulateGrad]
	4840441744 -> 4840444048
	4840441744 [label=TBackward0]
	4842784704 -> 4840441744
	4359370496 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4359370496 -> 4842784704
	4842784704 [label=AccumulateGrad]
	4840444000 -> 4842910768
	4840443952 -> 4840444144
	4840379072 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	4840379072 -> 4840443952
	4840443952 [label=AccumulateGrad]
	4840443136 -> 4840444144
	4840383312 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	4840383312 -> 4840443136
	4840443136 [label=AccumulateGrad]
	4840447216 -> 4840454272
	4840447216 [label=TBackward0]
	4840443520 -> 4840447216
	4843051344 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4843051344 -> 4840443520
	4840443520 [label=AccumulateGrad]
	4840454512 -> 4840443280
	4843051424 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	4843051424 -> 4840454512
	4840454512 [label=AccumulateGrad]
	4840442800 -> 4840443280
	4843053024 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	4843053024 -> 4840442800
	4840442800 [label=AccumulateGrad]
	4840442032 -> 4842913264
	4840442032 [label=TBackward0]
	4840444864 -> 4840442032
	4843053184 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4843053184 -> 4840444864
	4840444864 [label=AccumulateGrad]
	4842910768 -> 4842910960
	4842909904 -> 4842910048
	4842909904 [label=TBackward0]
	4842911056 -> 4842909904
	4843054624 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	4843054624 -> 4842911056
	4842911056 [label=AccumulateGrad]
	4842910048 -> 4843055744
}
