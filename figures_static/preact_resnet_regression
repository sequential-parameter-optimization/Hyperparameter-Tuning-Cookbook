digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	5795726112 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	5795694336 [label=AddmmBackward0]
	5792877488 -> 5795694336
	5795729472 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	5795729472 -> 5792877488
	5792877488 [label=AccumulateGrad]
	5795697888 -> 5795694336
	5795697888 [label=AddBackward0]
	5795694432 -> 5795697888
	5795694432 [label=MmBackward0]
	5795695200 -> 5795694432
	5795695200 [label=ReluBackward0]
	5795694288 -> 5795695200
	5795694288 [label=NativeLayerNormBackward0]
	5795696064 -> 5795694288
	5795696064 [label=MmBackward0]
	5795695008 -> 5795696064
	5795695008 [label=ReluBackward0]
	5795694624 -> 5795695008
	5795694624 [label=NativeLayerNormBackward0]
	5795695776 -> 5795694624
	5795695776 [label=AddBackward0]
	5795698080 -> 5795695776
	5795698080 [label=MmBackward0]
	5795698224 -> 5795698080
	5795698224 [label=ReluBackward0]
	5795698368 -> 5795698224
	5795698368 [label=NativeLayerNormBackward0]
	5795698464 -> 5795698368
	5795698464 [label=MmBackward0]
	5795698656 -> 5795698464
	5795698656 [label=ReluBackward0]
	5795698800 -> 5795698656
	5795698800 [label=NativeLayerNormBackward0]
	5795698032 -> 5795698800
	5795698032 [label=AddmmBackward0]
	5795699040 -> 5795698032
	5795727392 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	5795727392 -> 5795699040
	5795699040 [label=AccumulateGrad]
	5795698992 -> 5795698032
	5795698992 [label=TBackward0]
	5795699136 -> 5795698992
	5795727472 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	5795727472 -> 5795699136
	5795699136 [label=AccumulateGrad]
	5795698896 -> 5795698800
	4319945072 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	4319945072 -> 5795698896
	5795698896 [label=AccumulateGrad]
	5795698848 -> 5795698800
	4319944992 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	4319944992 -> 5795698848
	5795698848 [label=AccumulateGrad]
	5795698608 -> 5795698464
	5795698608 [label=TBackward0]
	5795699088 -> 5795698608
	5795729072 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	5795729072 -> 5795699088
	5795699088 [label=AccumulateGrad]
	5795698416 -> 5795698368
	5795729232 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	5795729232 -> 5795698416
	5795698416 [label=AccumulateGrad]
	5795698272 -> 5795698368
	5795729312 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	5795729312 -> 5795698272
	5795698272 [label=AccumulateGrad]
	5795698176 -> 5795698080
	5795698176 [label=TBackward0]
	5795698704 -> 5795698176
	5795729392 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	5795729392 -> 5795698704
	5795698704 [label=AccumulateGrad]
	5795698032 -> 5795695776
	5795697936 -> 5795694624
	5795728992 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	5795728992 -> 5795697936
	5795697936 [label=AccumulateGrad]
	5795694672 -> 5795694624
	5795729152 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	5795729152 -> 5795694672
	5795694672 [label=AccumulateGrad]
	5795695056 -> 5795696064
	5795695056 [label=TBackward0]
	5795698128 -> 5795695056
	5795727312 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	5795727312 -> 5795698128
	5795698128 [label=AccumulateGrad]
	5795696016 -> 5795694288
	5795729552 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	5795729552 -> 5795696016
	5795696016 [label=AccumulateGrad]
	5795696304 -> 5795694288
	5795729632 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	5795729632 -> 5795696304
	5795696304 [label=AccumulateGrad]
	5795695296 -> 5795694432
	5795695296 [label=TBackward0]
	5795694864 -> 5795695296
	5795729712 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	5795729712 -> 5795694864
	5795694864 [label=AccumulateGrad]
	5795695776 -> 5795697888
	5795700816 -> 5795694336
	5795700816 [label=TBackward0]
	5795696256 -> 5795700816
	5795729792 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	5795729792 -> 5795696256
	5795696256 [label=AccumulateGrad]
	5795694336 -> 5795726112
}
