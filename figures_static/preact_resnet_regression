digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	4628851008 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	4628924256 [label=AddmmBackward0]
	4631378816 -> 4628924256
	4631505696 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	4631505696 -> 4631378816
	4631378816 [label=AccumulateGrad]
	4631375072 -> 4628924256
	4631375072 [label=AddBackward0]
	4631379680 -> 4631375072
	4631379680 [label=MmBackward0]
	4631375552 -> 4631379680
	4631375552 [label=ReluBackward0]
	4631377376 -> 4631375552
	4631377376 [label=NativeLayerNormBackward0]
	4631379008 -> 4631377376
	4631379008 [label=MmBackward0]
	4631379392 -> 4631379008
	4631379392 [label=ReluBackward0]
	4631377424 -> 4631379392
	4631377424 [label=NativeLayerNormBackward0]
	4631379776 -> 4631377424
	4631379776 [label=AddBackward0]
	4631658704 -> 4631379776
	4631658704 [label=MmBackward0]
	4631658896 -> 4631658704
	4631658896 [label=ReluBackward0]
	4631659040 -> 4631658896
	4631659040 [label=NativeLayerNormBackward0]
	4631659136 -> 4631659040
	4631659136 [label=MmBackward0]
	4631659328 -> 4631659136
	4631659328 [label=ReluBackward0]
	4631659472 -> 4631659328
	4631659472 [label=NativeLayerNormBackward0]
	4631658656 -> 4631659472
	4631658656 [label=AddmmBackward0]
	4631659712 -> 4631658656
	4628850928 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	4628850928 -> 4631659712
	4631659712 [label=AccumulateGrad]
	4631659664 -> 4631658656
	4631659664 [label=TBackward0]
	4631659808 -> 4631659664
	4628846368 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	4628846368 -> 4631659808
	4631659808 [label=AccumulateGrad]
	4631659568 -> 4631659472
	4352423840 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	4352423840 -> 4631659568
	4631659568 [label=AccumulateGrad]
	4631659520 -> 4631659472
	4352423760 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	4352423760 -> 4631659520
	4631659520 [label=AccumulateGrad]
	4631659280 -> 4631659136
	4631659280 [label=TBackward0]
	4631659760 -> 4631659280
	4352422880 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4352422880 -> 4631659760
	4631659760 [label=AccumulateGrad]
	4631659088 -> 4631659040
	4615061280 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	4615061280 -> 4631659088
	4631659088 [label=AccumulateGrad]
	4631658944 -> 4631659040
	4631501856 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	4631501856 -> 4631658944
	4631658944 [label=AccumulateGrad]
	4631658848 -> 4631658704
	4631658848 [label=TBackward0]
	4631659376 -> 4631658848
	4631502496 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4631502496 -> 4631659376
	4631659376 [label=AccumulateGrad]
	4631658656 -> 4631379776
	4426540672 -> 4631377424
	4631502576 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	4631502576 -> 4426540672
	4426540672 [label=AccumulateGrad]
	4442753152 -> 4631377424
	4631501776 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	4631501776 -> 4442753152
	4442753152 [label=AccumulateGrad]
	4631379440 -> 4631379008
	4631379440 [label=TBackward0]
	4631379344 -> 4631379440
	4631504016 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4631504016 -> 4631379344
	4631379344 [label=AccumulateGrad]
	4631375312 -> 4631377376
	4631503936 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	4631503936 -> 4631375312
	4631375312 [label=AccumulateGrad]
	4631377520 -> 4631377376
	4631504096 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	4631504096 -> 4631377520
	4631377520 [label=AccumulateGrad]
	4631379056 -> 4631379680
	4631379056 [label=TBackward0]
	4631379152 -> 4631379056
	4631504176 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4631504176 -> 4631379152
	4631379152 [label=AccumulateGrad]
	4631379776 -> 4631375072
	4631375696 -> 4628924256
	4631375696 [label=TBackward0]
	4631379200 -> 4631375696
	4631505616 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	4631505616 -> 4631379200
	4631379200 [label=AccumulateGrad]
	4628924256 -> 4628851008
}
