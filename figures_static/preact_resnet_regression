digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	4380551968 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	4630929824 [label=AddmmBackward0]
	4628891200 -> 4630929824
	4631484272 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	4631484272 -> 4628891200
	4628891200 [label=AccumulateGrad]
	4628898544 -> 4630929824
	4628898544 [label=AddBackward0]
	4631377088 -> 4628898544
	4631377088 [label=MmBackward0]
	4631378240 -> 4631377088
	4631378240 [label=ReluBackward0]
	4631378432 -> 4631378240
	4631378432 [label=NativeLayerNormBackward0]
	4631378528 -> 4631378432
	4631378528 [label=MmBackward0]
	4631377280 -> 4631378528
	4631377280 [label=ReluBackward0]
	4631375840 -> 4631377280
	4631375840 [label=NativeLayerNormBackward0]
	4631376992 -> 4631375840
	4631376992 [label=AddBackward0]
	4631378816 -> 4631376992
	4631378816 [label=MmBackward0]
	4631378960 -> 4631378816
	4631378960 [label=ReluBackward0]
	4631379104 -> 4631378960
	4631379104 [label=NativeLayerNormBackward0]
	4631379200 -> 4631379104
	4631379200 [label=MmBackward0]
	4631379392 -> 4631379200
	4631379392 [label=ReluBackward0]
	4631379536 -> 4631379392
	4631379536 [label=NativeLayerNormBackward0]
	4631378720 -> 4631379536
	4631378720 [label=AddmmBackward0]
	4631379776 -> 4631378720
	4631482432 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	4631482432 -> 4631379776
	4631379776 [label=AccumulateGrad]
	4631379728 -> 4631378720
	4631379728 [label=TBackward0]
	4631241792 -> 4631379728
	4631482352 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	4631482352 -> 4631241792
	4631241792 [label=AccumulateGrad]
	4631379632 -> 4631379536
	4353582304 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	4353582304 -> 4631379632
	4631379632 [label=AccumulateGrad]
	4631379584 -> 4631379536
	4353582144 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	4353582144 -> 4631379584
	4631379584 [label=AccumulateGrad]
	4631379344 -> 4631379200
	4631379344 [label=TBackward0]
	4631379824 -> 4631379344
	4628830464 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4628830464 -> 4631379824
	4631379824 [label=AccumulateGrad]
	4631379152 -> 4631379104
	4628831904 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	4628831904 -> 4631379152
	4631379152 [label=AccumulateGrad]
	4631379008 -> 4631379104
	4628827824 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	4628827824 -> 4631379008
	4631379008 [label=AccumulateGrad]
	4631378912 -> 4631378816
	4631378912 [label=TBackward0]
	4631379440 -> 4631378912
	4628831424 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4628831424 -> 4631379440
	4631379440 [label=AccumulateGrad]
	4631378720 -> 4631376992
	4631377616 -> 4631375840
	4628828304 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	4628828304 -> 4631377616
	4631377616 [label=AccumulateGrad]
	4631375216 -> 4631375840
	4600524352 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	4600524352 -> 4631375216
	4631375216 [label=AccumulateGrad]
	4631377184 -> 4631378528
	4631377184 [label=TBackward0]
	4631378864 -> 4631377184
	4631482112 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4631482112 -> 4631378864
	4631378864 [label=AccumulateGrad]
	4631378480 -> 4631378432
	4631484192 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	4631484192 -> 4631378480
	4631378480 [label=AccumulateGrad]
	4631377424 -> 4631378432
	4631484112 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	4631484112 -> 4631377424
	4631377424 [label=AccumulateGrad]
	4631378192 -> 4631377088
	4631378192 [label=TBackward0]
	4631377232 -> 4631378192
	4631483072 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4631483072 -> 4631377232
	4631377232 [label=AccumulateGrad]
	4631376992 -> 4628898544
	4628892976 -> 4630929824
	4628892976 [label=TBackward0]
	4631378576 -> 4628892976
	4631482912 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	4631482912 -> 4631378576
	4631378576 [label=AccumulateGrad]
	4630929824 -> 4380551968
}
