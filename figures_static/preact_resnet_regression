digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	4665043104 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	4489961600 [label=AddmmBackward0]
	4663912400 -> 4489961600
	4665042064 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	4665042064 -> 4663912400
	4663912400 [label=AccumulateGrad]
	4664931376 -> 4489961600
	4664931376 [label=AddBackward0]
	4664932048 -> 4664931376
	4664932048 [label=MmBackward0]
	4664932096 -> 4664932048
	4664932096 [label=ReluBackward0]
	4664932480 -> 4664932096
	4664932480 [label=NativeLayerNormBackward0]
	4664932384 -> 4664932480
	4664932384 [label=MmBackward0]
	4664932912 -> 4664932384
	4664932912 [label=ReluBackward0]
	4664932768 -> 4664932912
	4664932768 [label=NativeLayerNormBackward0]
	4664929792 -> 4664932768
	4664929792 [label=AddBackward0]
	4664932240 -> 4664929792
	4664932240 [label=MmBackward0]
	4664930176 -> 4664932240
	4664930176 [label=ReluBackward0]
	4664933152 -> 4664930176
	4664933152 [label=NativeLayerNormBackward0]
	4664933248 -> 4664933152
	4664933248 [label=MmBackward0]
	4664933440 -> 4664933248
	4664933440 [label=ReluBackward0]
	4664933584 -> 4664933440
	4664933584 [label=NativeLayerNormBackward0]
	4664929600 -> 4664933584
	4664929600 [label=AddmmBackward0]
	4664933824 -> 4664929600
	4665040304 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	4665040304 -> 4664933824
	4664933824 [label=AccumulateGrad]
	4664933776 -> 4664929600
	4664933776 [label=TBackward0]
	4664933920 -> 4664933776
	4665040384 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	4665040384 -> 4664933920
	4664933920 [label=AccumulateGrad]
	4664933680 -> 4664933584
	4400835120 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	4400835120 -> 4664933680
	4664933680 [label=AccumulateGrad]
	4664933632 -> 4664933584
	4662366992 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	4662366992 -> 4664933632
	4664933632 [label=AccumulateGrad]
	4664933392 -> 4664933248
	4664933392 [label=TBackward0]
	4664933872 -> 4664933392
	4662370752 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4662370752 -> 4664933872
	4664933872 [label=AccumulateGrad]
	4664933200 -> 4664933152
	4400835360 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	4400835360 -> 4664933200
	4664933200 [label=AccumulateGrad]
	4664933104 -> 4664933152
	4662370832 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	4662370832 -> 4664933104
	4664933104 [label=AccumulateGrad]
	4664931568 -> 4664932240
	4664931568 [label=TBackward0]
	4664933488 -> 4664931568
	4662367072 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4662367072 -> 4664933488
	4664933488 [label=AccumulateGrad]
	4664929600 -> 4664929792
	4664926624 -> 4664932768
	4665038944 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	4665038944 -> 4664926624
	4664926624 [label=AccumulateGrad]
	4664931472 -> 4664932768
	4665038864 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	4665038864 -> 4664931472
	4664931472 [label=AccumulateGrad]
	4664932960 -> 4664932384
	4664932960 [label=TBackward0]
	4664930416 -> 4664932960
	4665038704 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4665038704 -> 4664930416
	4664930416 [label=AccumulateGrad]
	4664932432 -> 4664932480
	4665037984 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	4665037984 -> 4664932432
	4664932432 [label=AccumulateGrad]
	4664932144 -> 4664932480
	4665040544 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	4665040544 -> 4664932144
	4664932144 [label=AccumulateGrad]
	4664930464 -> 4664932048
	4664930464 [label=TBackward0]
	4664932864 -> 4664930464
	4665040464 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4665040464 -> 4664932864
	4664932864 [label=AccumulateGrad]
	4664929792 -> 4664931376
	4664931808 -> 4489961600
	4664931808 [label=TBackward0]
	4664932336 -> 4664931808
	4665041984 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	4665041984 -> 4664932336
	4664932336 [label=AccumulateGrad]
	4489961600 -> 4665043104
}
