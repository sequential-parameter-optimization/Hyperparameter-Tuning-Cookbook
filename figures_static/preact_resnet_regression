digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	4352934848 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	5029560176 [label=AddmmBackward0]
	5004678416 -> 5029560176
	5029685168 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	5029685168 -> 5004678416
	5004678416 [label=AccumulateGrad]
	5029559360 -> 5029560176
	5029559360 [label=AddBackward0]
	5029558640 -> 5029559360
	5029558640 [label=MmBackward0]
	5029557008 -> 5029558640
	5029557008 [label=ReluBackward0]
	5029559840 -> 5029557008
	5029559840 [label=NativeLayerNormBackward0]
	5029559792 -> 5029559840
	5029559792 [label=MmBackward0]
	5029557584 -> 5029559792
	5029557584 [label=ReluBackward0]
	5029555952 -> 5029557584
	5029555952 [label=NativeLayerNormBackward0]
	5029560080 -> 5029555952
	5029560080 [label=AddBackward0]
	5029839056 -> 5029560080
	5029839056 [label=MmBackward0]
	5029839200 -> 5029839056
	5029839200 [label=ReluBackward0]
	5029839344 -> 5029839200
	5029839344 [label=NativeLayerNormBackward0]
	5029839440 -> 5029839344
	5029839440 [label=MmBackward0]
	5029839632 -> 5029839440
	5029839632 [label=ReluBackward0]
	5029839776 -> 5029839632
	5029839776 [label=NativeLayerNormBackward0]
	5029838960 -> 5029839776
	5029838960 [label=AddmmBackward0]
	5029840016 -> 5029838960
	5029683648 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	5029683648 -> 5029840016
	5029840016 [label=AccumulateGrad]
	5029839968 -> 5029838960
	5029839968 [label=TBackward0]
	5029840112 -> 5029839968
	5029681408 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	5029681408 -> 5029840112
	5029840112 [label=AccumulateGrad]
	5029839872 -> 5029839776
	4333236016 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	4333236016 -> 5029839872
	5029839872 [label=AccumulateGrad]
	5029839824 -> 5029839776
	4333235776 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	4333235776 -> 5029839824
	5029839824 [label=AccumulateGrad]
	5029839584 -> 5029839440
	5029839584 [label=TBackward0]
	5004836096 -> 5029839584
	5003961808 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	5003961808 -> 5004836096
	5004836096 [label=AccumulateGrad]
	5029839392 -> 5029839344
	5003959888 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	5003959888 -> 5029839392
	5029839392 [label=AccumulateGrad]
	5029839248 -> 5029839344
	5003961728 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	5003961728 -> 5029839248
	5029839248 [label=AccumulateGrad]
	5029839152 -> 5029839056
	5029839152 [label=TBackward0]
	5029839680 -> 5029839152
	4333235936 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4333235936 -> 5029839680
	5029839680 [label=AccumulateGrad]
	5029838960 -> 5029560080
	5029560272 -> 5029555952
	4489514112 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	4489514112 -> 5029560272
	5029560272 [label=AccumulateGrad]
	5029557824 -> 5029555952
	5029681728 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	5029681728 -> 5029557824
	5029557824 [label=AccumulateGrad]
	5029559552 -> 5029559792
	5029559552 [label=TBackward0]
	5029558448 -> 5029559552
	5029681328 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	5029681328 -> 5029558448
	5029558448 [label=AccumulateGrad]
	5029556480 -> 5029559840
	5029683488 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	5029683488 -> 5029556480
	5029556480 [label=AccumulateGrad]
	5029558208 -> 5029559840
	5029682288 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	5029682288 -> 5029558208
	5029558208 [label=AccumulateGrad]
	5029560128 -> 5029558640
	5029560128 [label=TBackward0]
	5029559504 -> 5029560128
	5029683568 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	5029683568 -> 5029559504
	5029559504 [label=AccumulateGrad]
	5029560080 -> 5029559360
	5029559264 -> 5029560176
	5029559264 [label=TBackward0]
	5029550048 -> 5029559264
	5029683728 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	5029683728 -> 5029550048
	5029550048 [label=AccumulateGrad]
	5029560176 -> 4352934848
}
