digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	4967257408 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	4973835312 [label=AddmmBackward0]
	4973532048 -> 4973835312
	5008728432 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	5008728432 -> 4973532048
	4973532048 [label=AccumulateGrad]
	4434872400 -> 4973835312
	4434872400 [label=AddBackward0]
	4365395008 -> 4434872400
	4365395008 [label=MmBackward0]
	5008588080 -> 4365395008
	5008588080 [label=ReluBackward0]
	5008587024 -> 5008588080
	5008587024 [label=NativeLayerNormBackward0]
	5008587120 -> 5008587024
	5008587120 [label=MmBackward0]
	5008587360 -> 5008587120
	5008587360 [label=ReluBackward0]
	5008587696 -> 5008587360
	5008587696 [label=NativeLayerNormBackward0]
	5008584432 -> 5008587696
	5008584432 [label=AddBackward0]
	5008588464 -> 5008584432
	5008588464 [label=MmBackward0]
	5008588656 -> 5008588464
	5008588656 [label=ReluBackward0]
	5008585344 -> 5008588656
	5008585344 [label=NativeLayerNormBackward0]
	5008586640 -> 5008585344
	5008586640 [label=MmBackward0]
	5008867488 -> 5008586640
	5008867488 [label=ReluBackward0]
	5008867632 -> 5008867488
	5008867632 [label=NativeLayerNormBackward0]
	5008588416 -> 5008867632
	5008588416 [label=AddmmBackward0]
	5008867872 -> 5008588416
	5008726752 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	5008726752 -> 5008867872
	5008867872 [label=AccumulateGrad]
	5008867824 -> 5008588416
	5008867824 [label=TBackward0]
	5008867968 -> 5008867824
	5008726832 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	5008726832 -> 5008867968
	5008867968 [label=AccumulateGrad]
	5008867728 -> 5008867632
	4967258208 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	4967258208 -> 5008867728
	5008867728 [label=AccumulateGrad]
	5008867680 -> 5008867632
	4967260928 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	4967260928 -> 5008867680
	5008867680 [label=AccumulateGrad]
	5008867440 -> 5008586640
	5008867440 [label=TBackward0]
	5008463168 -> 5008867440
	4358368992 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4358368992 -> 5008463168
	5008463168 [label=AccumulateGrad]
	5008586544 -> 5008585344
	4331252592 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	4331252592 -> 5008586544
	5008586544 [label=AccumulateGrad]
	5008588752 -> 5008585344
	4331252672 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	4331252672 -> 5008588752
	5008588752 [label=AccumulateGrad]
	5008588608 -> 5008588464
	5008588608 [label=TBackward0]
	5008584624 -> 5008588608
	4331251872 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4331251872 -> 5008584624
	5008584624 [label=AccumulateGrad]
	5008588416 -> 5008584432
	5008587600 -> 5008587696
	4359461520 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	4359461520 -> 5008587600
	5008587600 [label=AccumulateGrad]
	5008587648 -> 5008587696
	5008724672 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	5008724672 -> 5008587648
	5008587648 [label=AccumulateGrad]
	5008587456 -> 5008587120
	5008587456 [label=TBackward0]
	5008588512 -> 5008587456
	5008724752 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	5008724752 -> 5008588512
	5008588512 [label=AccumulateGrad]
	5008584816 -> 5008587024
	5008724992 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	5008724992 -> 5008584816
	5008584816 [label=AccumulateGrad]
	5008588128 -> 5008587024
	5008724592 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	5008724592 -> 5008588128
	5008588128 [label=AccumulateGrad]
	5008587312 -> 4365395008
	5008587312 [label=TBackward0]
	5008587408 -> 5008587312
	5008726912 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	5008726912 -> 5008587408
	5008587408 [label=AccumulateGrad]
	5008584432 -> 4434872400
	4434874368 -> 4973835312
	4434874368 [label=TBackward0]
	5008584960 -> 4434874368
	5008728352 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	5008728352 -> 5008584960
	5008584960 [label=AccumulateGrad]
	4973835312 -> 4967257408
}
