digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	4362827360 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	5296030672 [label=AddmmBackward0]
	5296671184 -> 5296030672
	5299713472 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	5299713472 -> 5296671184
	5296671184 [label=AccumulateGrad]
	5299640048 -> 5296030672
	5299640048 [label=AddBackward0]
	4710861072 -> 5299640048
	4710861072 [label=MmBackward0]
	5299640912 -> 4710861072
	5299640912 [label=ReluBackward0]
	5299641056 -> 5299640912
	5299641056 [label=NativeLayerNormBackward0]
	5299641152 -> 5299641056
	5299641152 [label=MmBackward0]
	5299640528 -> 5299641152
	5299640528 [label=ReluBackward0]
	5299641248 -> 5299640528
	5299641248 [label=NativeLayerNormBackward0]
	5299639040 -> 5299641248
	5299639040 [label=AddBackward0]
	5299635920 -> 5299639040
	5299635920 [label=MmBackward0]
	5299637792 -> 5299635920
	5299637792 [label=ReluBackward0]
	5299637648 -> 5299637792
	5299637648 [label=NativeLayerNormBackward0]
	5299637408 -> 5299637648
	5299637408 [label=MmBackward0]
	5299637168 -> 5299637408
	5299637168 [label=ReluBackward0]
	5299636976 -> 5299637168
	5299636976 [label=NativeLayerNormBackward0]
	5299637984 -> 5299636976
	5299637984 [label=AddmmBackward0]
	5299636688 -> 5299637984
	5299713072 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	5299713072 -> 5299636688
	5299636688 [label=AccumulateGrad]
	5299636784 -> 5299637984
	5299636784 [label=TBackward0]
	5296988192 -> 5299636784
	5299711632 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	5299711632 -> 5296988192
	5296988192 [label=AccumulateGrad]
	5299636880 -> 5299636976
	4379912992 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	4379912992 -> 5299636880
	5299636880 [label=AccumulateGrad]
	5299636928 -> 5299636976
	4379912672 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	4379912672 -> 5299636928
	5299636928 [label=AccumulateGrad]
	5299637216 -> 5299637408
	5299637216 [label=TBackward0]
	5299638224 -> 5299637216
	5295926688 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	5295926688 -> 5299638224
	5299638224 [label=AccumulateGrad]
	5299637456 -> 5299637648
	5295927168 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	5295927168 -> 5299637456
	5299637456 [label=AccumulateGrad]
	5299637744 -> 5299637648
	4436208816 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	4436208816 -> 5299637744
	5299637744 [label=AccumulateGrad]
	5299637840 -> 5299635920
	5299637840 [label=TBackward0]
	5299637264 -> 5299637840
	4436205056 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4436205056 -> 5299637264
	5299637264 [label=AccumulateGrad]
	5299637984 -> 5299639040
	5299636112 -> 5299641248
	5299713232 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	5299713232 -> 5299636112
	5299636112 [label=AccumulateGrad]
	5299641296 -> 5299641248
	5299713152 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	5299713152 -> 5299641296
	5299641296 [label=AccumulateGrad]
	5299641200 -> 5299641152
	5299641200 [label=TBackward0]
	5299635824 -> 5299641200
	5299710352 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	5299710352 -> 5299635824
	5299635824 [label=AccumulateGrad]
	5299641104 -> 5299641056
	5299709952 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	5299709952 -> 5299641104
	5299641104 [label=AccumulateGrad]
	5299640960 -> 5299641056
	5299713312 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	5299713312 -> 5299640960
	5299640960 [label=AccumulateGrad]
	5299640864 -> 4710861072
	5299640864 [label=TBackward0]
	5299640480 -> 5299640864
	5299713392 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	5299713392 -> 5299640480
	5299640480 [label=AccumulateGrad]
	5299639040 -> 5299640048
	5299640000 -> 5296030672
	5299640000 [label=TBackward0]
	5299640336 -> 5299640000
	5285794976 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	5285794976 -> 5299640336
	5299640336 [label=AccumulateGrad]
	5296030672 -> 4362827360
}
