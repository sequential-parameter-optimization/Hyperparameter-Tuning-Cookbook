digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	5306601536 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	5306713136 [label=AddmmBackward0]
	5306713040 -> 5306713136
	5306600736 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	5306600736 -> 5306713040
	5306713040 [label=AccumulateGrad]
	5306713088 -> 5306713136
	5306713088 [label=AddBackward0]
	5306713760 -> 5306713088
	5306713760 [label=MmBackward0]
	5306713952 -> 5306713760
	5306713952 [label=ReluBackward0]
	5306714048 -> 5306713952
	5306714048 [label=NativeLayerNormBackward0]
	5306713280 -> 5306714048
	5306713280 [label=MmBackward0]
	5306714240 -> 5306713280
	5306714240 [label=ReluBackward0]
	5306714432 -> 5306714240
	5306714432 [label=NativeLayerNormBackward0]
	5306713712 -> 5306714432
	5306713712 [label=AddBackward0]
	5306714720 -> 5306713712
	5306714720 [label=MmBackward0]
	5306714864 -> 5306714720
	5306714864 [label=ReluBackward0]
	5306715008 -> 5306714864
	5306715008 [label=NativeLayerNormBackward0]
	5306715104 -> 5306715008
	5306715104 [label=MmBackward0]
	5306715296 -> 5306715104
	5306715296 [label=ReluBackward0]
	5306715440 -> 5306715296
	5306715440 [label=NativeLayerNormBackward0]
	5306714672 -> 5306715440
	5306714672 [label=AddmmBackward0]
	5306715680 -> 5306714672
	5306598816 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	5306598816 -> 5306715680
	5306715680 [label=AccumulateGrad]
	5306715632 -> 5306714672
	5306715632 [label=TBackward0]
	5306715776 -> 5306715632
	5306598656 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	5306598656 -> 5306715776
	5306715776 [label=AccumulateGrad]
	5306715536 -> 5306715440
	4500664992 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	4500664992 -> 5306715536
	5306715536 [label=AccumulateGrad]
	5306715488 -> 5306715440
	4500665312 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	4500665312 -> 5306715488
	5306715488 [label=AccumulateGrad]
	5306715248 -> 5306715104
	5306715248 [label=TBackward0]
	5306715728 -> 5306715248
	4500665392 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4500665392 -> 5306715728
	5306715728 [label=AccumulateGrad]
	5306715056 -> 5306715008
	5306563984 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	5306563984 -> 5306715056
	5306715056 [label=AccumulateGrad]
	5306714912 -> 5306715008
	4525602160 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	4525602160 -> 5306714912
	5306714912 [label=AccumulateGrad]
	5306714816 -> 5306714720
	5306714816 [label=TBackward0]
	5306715344 -> 5306714816
	5301273136 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	5301273136 -> 5306715344
	5306715344 [label=AccumulateGrad]
	5306714672 -> 5306713712
	5306714576 -> 5306714432
	5301273456 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	5301273456 -> 5306714576
	5306714576 [label=AccumulateGrad]
	5306714480 -> 5306714432
	5306598736 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	5306598736 -> 5306714480
	5306714480 [label=AccumulateGrad]
	5306714192 -> 5306713280
	5306714192 [label=TBackward0]
	5306714768 -> 5306714192
	5306600256 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	5306600256 -> 5306714768
	5306714768 [label=AccumulateGrad]
	5306713328 -> 5306714048
	5306600416 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	5306600416 -> 5306713328
	5306713328 [label=AccumulateGrad]
	5306714000 -> 5306714048
	5306600496 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	5306600496 -> 5306714000
	5306714000 [label=AccumulateGrad]
	5306713904 -> 5306713760
	5306713904 [label=TBackward0]
	5306714288 -> 5306713904
	5306600576 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	5306600576 -> 5306714288
	5306714288 [label=AccumulateGrad]
	5306713712 -> 5306713088
	5306712944 -> 5306713136
	5306712944 [label=TBackward0]
	5306714096 -> 5306712944
	5306600656 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	5306600656 -> 5306714096
	5306714096 [label=AccumulateGrad]
	5306713136 -> 5306601536
}
