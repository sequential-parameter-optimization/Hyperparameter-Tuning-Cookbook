digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	6305792240 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	6305665120 [label=AddmmBackward0]
	13165659088 -> 6305665120
	13165644768 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	13165644768 -> 13165659088
	13165659088 [label=AccumulateGrad]
	13165658848 -> 6305665120
	13165658848 [label=AddBackward0]
	13165660144 -> 13165658848
	13165660144 [label=MmBackward0]
	4433731040 -> 13165660144
	4433731040 [label=ReluBackward0]
	13165660288 -> 4433731040
	13165660288 [label=NativeLayerNormBackward0]
	13165659616 -> 13165660288
	13165659616 [label=MmBackward0]
	13165660432 -> 13165659616
	13165660432 [label=ReluBackward0]
	13165660624 -> 13165660432
	13165660624 [label=NativeLayerNormBackward0]
	13165660000 -> 13165660624
	13165660000 [label=AddBackward0]
	13165660912 -> 13165660000
	13165660912 [label=MmBackward0]
	13165661056 -> 13165660912
	13165661056 [label=ReluBackward0]
	13165661200 -> 13165661056
	13165661200 [label=NativeLayerNormBackward0]
	13165661296 -> 13165661200
	13165661296 [label=MmBackward0]
	13165661488 -> 13165661296
	13165661488 [label=ReluBackward0]
	13165661632 -> 13165661488
	13165661632 [label=NativeLayerNormBackward0]
	13165660864 -> 13165661632
	13165660864 [label=AddmmBackward0]
	13165661872 -> 13165660864
	13165640864 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	13165640864 -> 13165661872
	13165661872 [label=AccumulateGrad]
	13165661824 -> 13165660864
	13165661824 [label=TBackward0]
	13165661968 -> 13165661824
	13165640944 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	13165640944 -> 13165661968
	13165661968 [label=AccumulateGrad]
	13165661728 -> 13165661632
	4520440000 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	4520440000 -> 13165661728
	13165661728 [label=AccumulateGrad]
	13165661680 -> 13165661632
	4520439600 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	4520439600 -> 13165661680
	13165661680 [label=AccumulateGrad]
	13165661440 -> 13165661296
	13165661440 [label=TBackward0]
	13165661920 -> 13165661440
	6305792400 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	6305792400 -> 13165661920
	13165661920 [label=AccumulateGrad]
	13165661248 -> 13165661200
	6305792320 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	6305792320 -> 13165661248
	13165661248 [label=AccumulateGrad]
	13165661104 -> 13165661200
	13165642768 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	13165642768 -> 13165661104
	13165661104 [label=AccumulateGrad]
	13165661008 -> 13165660912
	13165661008 [label=TBackward0]
	13165661536 -> 13165661008
	13165642688 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	13165642688 -> 13165661536
	13165661536 [label=AccumulateGrad]
	13165660864 -> 13165660000
	13165660768 -> 13165660624
	13165644208 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	13165644208 -> 13165660768
	13165660768 [label=AccumulateGrad]
	13165660672 -> 13165660624
	13165644288 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	13165644288 -> 13165660672
	13165660672 [label=AccumulateGrad]
	13165660384 -> 13165659616
	13165660384 [label=TBackward0]
	13165660960 -> 13165660384
	13165644368 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	13165644368 -> 13165660960
	13165660960 [label=AccumulateGrad]
	13165659664 -> 13165660288
	13165644448 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	13165644448 -> 13165659664
	13165659664 [label=AccumulateGrad]
	13165659328 -> 13165660288
	13165644528 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	13165644528 -> 13165659328
	13165659328 [label=AccumulateGrad]
	13165659424 -> 13165660144
	13165659424 [label=TBackward0]
	13165660480 -> 13165659424
	13165644608 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	13165644608 -> 13165660480
	13165660480 [label=AccumulateGrad]
	13165660000 -> 13165658848
	13165658944 -> 6305665120
	13165658944 [label=TBackward0]
	13165659568 -> 13165658944
	13165644688 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	13165644688 -> 13165659568
	13165659568 [label=AccumulateGrad]
	6305665120 -> 6305792240
}
