digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	5343018224 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	5355196512 [label=AddmmBackward0]
	5343087584 -> 5355196512
	5356914640 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	5356914640 -> 5343087584
	5343087584 [label=AccumulateGrad]
	5357060880 -> 5355196512
	5357060880 [label=AddBackward0]
	5357060736 -> 5357060880
	5357060736 [label=MmBackward0]
	5357061552 -> 5357060736
	5357061552 [label=ReluBackward0]
	5357061696 -> 5357061552
	5357061696 [label=NativeLayerNormBackward0]
	5357061792 -> 5357061696
	5357061792 [label=MmBackward0]
	5357060976 -> 5357061792
	5357060976 [label=ReluBackward0]
	5357061024 -> 5357060976
	5357061024 [label=NativeLayerNormBackward0]
	5357060688 -> 5357061024
	5357060688 [label=AddBackward0]
	5357062176 -> 5357060688
	5357062176 [label=MmBackward0]
	5357062368 -> 5357062176
	5357062368 [label=ReluBackward0]
	5357062512 -> 5357062368
	5357062512 [label=NativeLayerNormBackward0]
	5357062608 -> 5357062512
	5357062608 [label=MmBackward0]
	5357062800 -> 5357062608
	5357062800 [label=ReluBackward0]
	5357062944 -> 5357062800
	5357062944 [label=NativeLayerNormBackward0]
	5357062080 -> 5357062944
	5357062080 [label=AddmmBackward0]
	5357063184 -> 5357062080
	5356914160 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	5356914160 -> 5357063184
	5357063184 [label=AccumulateGrad]
	5357063136 -> 5357062080
	5357063136 [label=TBackward0]
	5357063280 -> 5357063136
	5356914240 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	5356914240 -> 5357063280
	5357063280 [label=AccumulateGrad]
	5357063040 -> 5357062944
	5296196256 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	5296196256 -> 5357063040
	5357063040 [label=AccumulateGrad]
	5357062992 -> 5357062944
	4483870992 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	4483870992 -> 5357062992
	5357062992 [label=AccumulateGrad]
	5357062752 -> 5357062608
	5357062752 [label=TBackward0]
	5357063232 -> 5357062752
	4483870592 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4483870592 -> 5357063232
	5357063232 [label=AccumulateGrad]
	5357062560 -> 5357062512
	5343017824 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	5343017824 -> 5357062560
	5357062560 [label=AccumulateGrad]
	5357062416 -> 5357062512
	5343017664 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	5343017664 -> 5357062416
	5357062416 [label=AccumulateGrad]
	5357062320 -> 5357062176
	5357062320 [label=TBackward0]
	5357062848 -> 5357062320
	5343018064 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	5343018064 -> 5357062848
	5357062848 [label=AccumulateGrad]
	5357062080 -> 5357060688
	5357061984 -> 5357061024
	5343011264 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	5343011264 -> 5357061984
	5357061984 [label=AccumulateGrad]
	5357061936 -> 5357061024
	5314911824 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	5314911824 -> 5357061936
	5357061936 [label=AccumulateGrad]
	5357061072 -> 5357061792
	5357061072 [label=TBackward0]
	5357062224 -> 5357061072
	5356914080 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	5356914080 -> 5357062224
	5357062224 [label=AccumulateGrad]
	5357061744 -> 5357061696
	5356914400 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	5356914400 -> 5357061744
	5357061744 [label=AccumulateGrad]
	5357061600 -> 5357061696
	5356914320 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	5356914320 -> 5357061600
	5357061600 [label=AccumulateGrad]
	5357061456 -> 5357060736
	5357061456 [label=TBackward0]
	5357061216 -> 5357061456
	5356914480 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	5356914480 -> 5357061216
	5357061216 [label=AccumulateGrad]
	5357060688 -> 5357060880
	5357060496 -> 5355196512
	5357060496 [label=TBackward0]
	5357061840 -> 5357060496
	5356914560 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	5356914560 -> 5357061840
	5357061840 [label=AccumulateGrad]
	5355196512 -> 5343018224
}
