digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	5319905504 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	5325289408 [label=AddmmBackward0]
	5321363360 -> 5325289408
	5325424112 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	5325424112 -> 5321363360
	5321363360 [label=AccumulateGrad]
	5325286960 -> 5325289408
	5325286960 [label=AddBackward0]
	5325289600 -> 5325286960
	5325289600 [label=MmBackward0]
	5325290416 -> 5325289600
	5325290416 [label=ReluBackward0]
	5325290560 -> 5325290416
	5325290560 [label=NativeLayerNormBackward0]
	5325290656 -> 5325290560
	5325290656 [label=MmBackward0]
	5325290032 -> 5325290656
	5325290032 [label=ReluBackward0]
	5325290800 -> 5325290032
	5325290800 [label=NativeLayerNormBackward0]
	5325289024 -> 5325290800
	5325289024 [label=AddBackward0]
	5325287488 -> 5325289024
	5325287488 [label=MmBackward0]
	5325291232 -> 5325287488
	5325291232 [label=ReluBackward0]
	5325291376 -> 5325291232
	5325291376 [label=NativeLayerNormBackward0]
	5325291472 -> 5325291376
	5325291472 [label=MmBackward0]
	5325288064 -> 5325291472
	5325288064 [label=ReluBackward0]
	5296238752 -> 5325288064
	5296238752 [label=NativeLayerNormBackward0]
	5325291040 -> 5296238752
	5325291040 [label=AddmmBackward0]
	5319934304 -> 5325291040
	5319915104 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	5319915104 -> 5319934304
	5319934304 [label=AccumulateGrad]
	5319934496 -> 5325291040
	5319934496 [label=TBackward0]
	5319937136 -> 5319934496
	5319915264 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	5319915264 -> 5319937136
	5319937136 [label=AccumulateGrad]
	5325107744 -> 5296238752
	4481264096 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	4481264096 -> 5325107744
	5325107744 [label=AccumulateGrad]
	5325101744 -> 5296238752
	4481264176 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	4481264176 -> 5325101744
	5325101744 [label=AccumulateGrad]
	5325287872 -> 5325291472
	5325287872 [label=TBackward0]
	5325096608 -> 5325287872
	5325372656 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	5325372656 -> 5325096608
	5325096608 [label=AccumulateGrad]
	5325291424 -> 5325291376
	5325370736 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	5325370736 -> 5325291424
	5325291424 [label=AccumulateGrad]
	5325291280 -> 5325291376
	5325372816 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	5325372816 -> 5325291280
	5325291280 [label=AccumulateGrad]
	5325291184 -> 5325287488
	5325291184 [label=TBackward0]
	5325284080 -> 5325291184
	5325423472 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	5325423472 -> 5325284080
	5325284080 [label=AccumulateGrad]
	5325291040 -> 5325289024
	5325290896 -> 5325290800
	5325423552 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	5325423552 -> 5325290896
	5325290896 [label=AccumulateGrad]
	5325290848 -> 5325290800
	5325423632 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	5325423632 -> 5325290848
	5325290848 [label=AccumulateGrad]
	5325290704 -> 5325290656
	5325290704 [label=TBackward0]
	5325291136 -> 5325290704
	5325423712 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	5325423712 -> 5325291136
	5325291136 [label=AccumulateGrad]
	5325290608 -> 5325290560
	5325423792 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	5325423792 -> 5325290608
	5325290608 [label=AccumulateGrad]
	5325290464 -> 5325290560
	5325423872 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	5325423872 -> 5325290464
	5325290464 [label=AccumulateGrad]
	5325290368 -> 5325289600
	5325290368 [label=TBackward0]
	5325289984 -> 5325290368
	5325423952 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	5325423952 -> 5325289984
	5325289984 [label=AccumulateGrad]
	5325289024 -> 5325286960
	5325288832 -> 5325289408
	5325288832 [label=TBackward0]
	5325289840 -> 5325288832
	5325424032 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	5325424032 -> 5325289840
	5325289840 [label=AccumulateGrad]
	5325289408 -> 5319905504
}
