digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	4721081024 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	4662149280 [label=AddmmBackward0]
	4721032496 -> 4662149280
	4721081344 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	4721081344 -> 4721032496
	4721032496 [label=AccumulateGrad]
	4721032880 -> 4662149280
	4721032880 [label=AddBackward0]
	4721032448 -> 4721032880
	4721032448 [label=MmBackward0]
	4721032928 -> 4721032448
	4721032928 [label=ReluBackward0]
	4721029856 -> 4721032928
	4721029856 [label=NativeLayerNormBackward0]
	4721032016 -> 4721029856
	4721032016 [label=MmBackward0]
	4721031296 -> 4721032016
	4721031296 [label=ReluBackward0]
	4721028992 -> 4721031296
	4721028992 [label=NativeLayerNormBackward0]
	4721032736 -> 4721028992
	4721032736 [label=AddBackward0]
	4721028800 -> 4721032736
	4721028800 [label=MmBackward0]
	4721030624 -> 4721028800
	4721030624 [label=ReluBackward0]
	4721030432 -> 4721030624
	4721030432 [label=NativeLayerNormBackward0]
	4721030336 -> 4721030432
	4721030336 [label=MmBackward0]
	4721030048 -> 4721030336
	4721030048 [label=ReluBackward0]
	4721029808 -> 4721030048
	4721029808 [label=NativeLayerNormBackward0]
	4721030768 -> 4721029808
	4721030768 [label=AddmmBackward0]
	4721029520 -> 4721030768
	4721079024 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	4721079024 -> 4721029520
	4721029520 [label=AccumulateGrad]
	4721029472 -> 4721030768
	4721029472 [label=TBackward0]
	4721029232 -> 4721029472
	4721079184 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	4721079184 -> 4721029232
	4721029232 [label=AccumulateGrad]
	4721029712 -> 4721029808
	4453703488 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	4453703488 -> 4721029712
	4721029712 [label=AccumulateGrad]
	4721029664 -> 4721029808
	4718220048 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	4718220048 -> 4721029664
	4721029664 [label=AccumulateGrad]
	4721030000 -> 4721030336
	4721030000 [label=TBackward0]
	4721029904 -> 4721030000
	4453703728 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4453703728 -> 4721029904
	4721029904 [label=AccumulateGrad]
	4721030192 -> 4721030432
	4716322064 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	4716322064 -> 4721030192
	4721030192 [label=AccumulateGrad]
	4721030480 -> 4721030432
	4453702528 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	4453702528 -> 4721030480
	4721030480 [label=AccumulateGrad]
	4721030576 -> 4721028800
	4721030576 [label=TBackward0]
	4721030144 -> 4721030576
	4721078624 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4721078624 -> 4721030144
	4721030144 [label=AccumulateGrad]
	4721030768 -> 4721032736
	4721030912 -> 4721028992
	4717069408 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	4717069408 -> 4721030912
	4721030912 [label=AccumulateGrad]
	4721028848 -> 4721028992
	4721078864 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	4721078864 -> 4721028848
	4721028848 [label=AccumulateGrad]
	4721029088 -> 4721032016
	4721029088 [label=TBackward0]
	4721031056 -> 4721029088
	4721079264 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4721079264 -> 4721031056
	4721031056 [label=AccumulateGrad]
	4721032976 -> 4721029856
	4721079344 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	4721079344 -> 4721032976
	4721032976 [label=AccumulateGrad]
	4721032400 -> 4721029856
	4721079424 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	4721079424 -> 4721032400
	4721032400 [label=AccumulateGrad]
	4721032832 -> 4721032448
	4721032832 [label=TBackward0]
	4721031488 -> 4721032832
	4721081184 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4721081184 -> 4721031488
	4721031488 [label=AccumulateGrad]
	4721032736 -> 4721032880
	4721032544 -> 4662149280
	4721032544 [label=TBackward0]
	4721028752 -> 4721032544
	4716711920 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	4716711920 -> 4721028752
	4721028752 [label=AccumulateGrad]
	4662149280 -> 4721081024
}
