digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	4675525264 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	4675417136 [label=AddmmBackward0]
	4675415216 -> 4675417136
	4675524304 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	4675524304 -> 4675415216
	4675415216 [label=AccumulateGrad]
	4675419968 -> 4675417136
	4675419968 [label=AddBackward0]
	4675416752 -> 4675419968
	4675416752 [label=MmBackward0]
	4675415504 -> 4675416752
	4675415504 [label=ReluBackward0]
	4675415696 -> 4675415504
	4675415696 [label=NativeLayerNormBackward0]
	4675416848 -> 4675415696
	4675416848 [label=MmBackward0]
	4672949024 -> 4675416848
	4672949024 [label=ReluBackward0]
	4672947680 -> 4672949024
	4672947680 [label=NativeLayerNormBackward0]
	4675419152 -> 4672947680
	4675419152 [label=AddBackward0]
	4672954160 -> 4675419152
	4672954160 [label=MmBackward0]
	4672947296 -> 4672954160
	4672947296 [label=ReluBackward0]
	4672948832 -> 4672947296
	4672948832 [label=NativeLayerNormBackward0]
	4672948976 -> 4672948832
	4672948976 [label=MmBackward0]
	4672953872 -> 4672948976
	4672953872 [label=ReluBackward0]
	4672954352 -> 4672953872
	4672954352 [label=NativeLayerNormBackward0]
	4672948400 -> 4672954352
	4672948400 [label=AddmmBackward0]
	4675682608 -> 4672948400
	4672914288 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	4672914288 -> 4675682608
	4675682608 [label=AccumulateGrad]
	4675682560 -> 4672948400
	4675682560 [label=TBackward0]
	4675682704 -> 4675682560
	4675520704 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	4675520704 -> 4675682704
	4675682704 [label=AccumulateGrad]
	4675682464 -> 4672954352
	4397457376 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	4397457376 -> 4675682464
	4675682464 [label=AccumulateGrad]
	4675682416 -> 4672954352
	4397458176 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	4397458176 -> 4675682416
	4675682416 [label=AccumulateGrad]
	4672949552 -> 4672948976
	4672949552 [label=TBackward0]
	4672953824 -> 4672949552
	4672918528 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4672918528 -> 4672953824
	4672953824 [label=AccumulateGrad]
	4672949792 -> 4672948832
	4672914608 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	4672914608 -> 4672949792
	4672949792 [label=AccumulateGrad]
	4672948592 -> 4672948832
	4672918368 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	4672918368 -> 4672948592
	4672948592 [label=AccumulateGrad]
	4672947584 -> 4672954160
	4672947584 [label=TBackward0]
	4672949600 -> 4672947584
	4675521104 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4675521104 -> 4672949600
	4672949600 [label=AccumulateGrad]
	4672948400 -> 4675419152
	4672953920 -> 4672947680
	4675521184 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	4675521184 -> 4672953920
	4672953920 [label=AccumulateGrad]
	4672949744 -> 4672947680
	4675522224 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	4675522224 -> 4672949744
	4672949744 [label=AccumulateGrad]
	4672949696 -> 4675416848
	4672949696 [label=TBackward0]
	4672948112 -> 4672949696
	4675522544 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	4675522544 -> 4672948112
	4672948112 [label=AccumulateGrad]
	4675415456 -> 4675415696
	4675522704 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	4675522704 -> 4675415456
	4675415456 [label=AccumulateGrad]
	4672947632 -> 4675415696
	4675522624 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	4675522624 -> 4672947632
	4672947632 [label=AccumulateGrad]
	4675416032 -> 4675416752
	4675416032 [label=TBackward0]
	4675416656 -> 4675416032
	4675524144 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	4675524144 -> 4675416656
	4675416656 [label=AccumulateGrad]
	4675419152 -> 4675419968
	4675418912 -> 4675417136
	4675418912 [label=TBackward0]
	4675417184 -> 4675418912
	4675524224 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	4675524224 -> 4675417184
	4675417184 [label=AccumulateGrad]
	4675417136 -> 4675525264
}
