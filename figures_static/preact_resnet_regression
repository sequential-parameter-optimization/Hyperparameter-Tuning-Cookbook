digraph {
	graph [size="16.65,16.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	6117838592 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	6117654384 [label=AddmmBackward0]
	6117652704 -> 6117654384
	6117837952 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	6117837952 -> 6117652704
	6117652704 [label=AccumulateGrad]
	6117653760 -> 6117654384
	6117653760 [label=AddBackward0]
	6117653472 -> 6117653760
	6117653472 [label=MmBackward0]
	6117651072 -> 6117653472
	6117651072 [label=ReluBackward0]
	5941076720 -> 6117651072
	5941076720 [label=NativeLayerNormBackward0]
	6117916832 -> 5941076720
	6117916832 [label=MmBackward0]
	6117917024 -> 6117916832
	6117917024 [label=ReluBackward0]
	6117917168 -> 6117917024
	6117917168 [label=NativeLayerNormBackward0]
	6117653424 -> 6117917168
	6117653424 [label=AddBackward0]
	6117917504 -> 6117653424
	6117917504 [label=MmBackward0]
	6117917648 -> 6117917504
	6117917648 [label=ReluBackward0]
	6117917792 -> 6117917648
	6117917792 [label=NativeLayerNormBackward0]
	6117917888 -> 6117917792
	6117917888 [label=MmBackward0]
	6117918080 -> 6117917888
	6117918080 [label=ReluBackward0]
	6117918224 -> 6117918080
	6117918224 [label=NativeLayerNormBackward0]
	6117917456 -> 6117918224
	6117917456 [label=AddmmBackward0]
	6117918464 -> 6117917456
	6117836112 [label="input_layer.bias
 (64)" fillcolor=lightblue]
	6117836112 -> 6117918464
	6117918464 [label=AccumulateGrad]
	6117918416 -> 6117917456
	6117918416 [label=TBackward0]
	6117051504 -> 6117918416
	6117835952 [label="input_layer.weight
 (64, 10)" fillcolor=lightblue]
	6117835952 -> 6117051504
	6117051504 [label=AccumulateGrad]
	6117918320 -> 6117918224
	4328534608 [label="blocks.0.net.0.weight
 (64)" fillcolor=lightblue]
	4328534608 -> 6117918320
	6117918320 [label=AccumulateGrad]
	6117918272 -> 6117918224
	4328534528 [label="blocks.0.net.0.bias
 (64)" fillcolor=lightblue]
	4328534528 -> 6117918272
	6117918272 [label=AccumulateGrad]
	6117918032 -> 6117917888
	6117918032 [label=TBackward0]
	5227924208 -> 6117918032
	6117837712 [label="blocks.0.net.2.weight
 (64, 64)" fillcolor=lightblue]
	6117837712 -> 5227924208
	5227924208 [label=AccumulateGrad]
	6117917840 -> 6117917792
	5927208032 [label="blocks.0.net.3.weight
 (64)" fillcolor=lightblue]
	5927208032 -> 6117917840
	6117917840 [label=AccumulateGrad]
	6117917696 -> 6117917792
	5927207952 [label="blocks.0.net.3.bias
 (64)" fillcolor=lightblue]
	5927207952 -> 6117917696
	6117917696 [label=AccumulateGrad]
	6117917600 -> 6117917504
	6117917600 [label=TBackward0]
	6117918128 -> 6117917600
	5233446896 [label="blocks.0.net.5.weight
 (64, 64)" fillcolor=lightblue]
	5233446896 -> 6117918128
	6117918128 [label=AccumulateGrad]
	6117917456 -> 6117653424
	6117917312 -> 6117917168
	6117751728 [label="blocks.1.net.0.weight
 (64)" fillcolor=lightblue]
	6117751728 -> 6117917312
	6117917312 [label=AccumulateGrad]
	6117917264 -> 6117917168
	6117752768 [label="blocks.1.net.0.bias
 (64)" fillcolor=lightblue]
	6117752768 -> 6117917264
	6117917264 [label=AccumulateGrad]
	6117916976 -> 6117916832
	6117916976 [label=TBackward0]
	6117917552 -> 6117916976
	6117751488 [label="blocks.1.net.2.weight
 (64, 64)" fillcolor=lightblue]
	6117751488 -> 6117917552
	6117917552 [label=AccumulateGrad]
	6117916784 -> 5941076720
	6117837792 [label="blocks.1.net.3.weight
 (64)" fillcolor=lightblue]
	6117837792 -> 6117916784
	6117916784 [label=AccumulateGrad]
	6117916736 -> 5941076720
	6117837632 [label="blocks.1.net.3.bias
 (64)" fillcolor=lightblue]
	6117837632 -> 6117916736
	6117916736 [label=AccumulateGrad]
	4372350240 -> 6117653472
	4372350240 [label=TBackward0]
	4372352256 -> 4372350240
	6117835792 [label="blocks.1.net.5.weight
 (64, 64)" fillcolor=lightblue]
	6117835792 -> 4372352256
	4372352256 [label=AccumulateGrad]
	6117653424 -> 6117653760
	6117651792 -> 6117654384
	6117651792 [label=TBackward0]
	4372355088 -> 6117651792
	6117837872 [label="output_layer.weight
 (1, 64)" fillcolor=lightblue]
	6117837872 -> 4372355088
	4372355088 [label=AccumulateGrad]
	6117654384 -> 6117838592
}
