\contentsline {chapter}{Preface: Optimization and Hyperparameter Tuning}{3}{chapter*.2}%
\contentsline {section}{Book Structure}{4}{section*.3}%
\contentsline {section}{Software Used in this Book}{6}{section*.4}%
\contentsline {part}{\numberline {I}Spot as an Optimizer}{7}{part.1}%
\contentsline {chapter}{\numberline {1}Introduction to \texttt {spotpython}}{8}{chapter.1}%
\contentsline {section}{\numberline {1.1}Example: \texttt {Spot} and the Sphere Function}{8}{section.1.1}%
\contentsline {subsection}{\numberline {1.1.1}The Objective Function: Sphere}{9}{subsection.1.1.1}%
\contentsline {section}{\numberline {1.2}\texttt {Spot} Parameters: \texttt {fun\_evals}, \texttt {init\_size} and \texttt {show\_models}}{10}{section.1.2}%
\contentsline {section}{\numberline {1.3}Print the Results}{11}{section.1.3}%
\contentsline {section}{\numberline {1.4}Show the Progress}{12}{section.1.4}%
\contentsline {section}{\numberline {1.5}Visualizing the Optimization and Hyperparameter Tuning Process with TensorBoard}{12}{section.1.5}%
\contentsline {chapter}{\numberline {2}Multi-dimensional Functions}{15}{chapter.2}%
\contentsline {section}{\numberline {2.1}Example: \texttt {Spot} and the 3-dim Sphere Function}{15}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}The Objective Function: 3-dim Sphere}{15}{subsection.2.1.1}%
\contentsline {subsection}{\numberline {2.1.2}Results}{17}{subsection.2.1.2}%
\contentsline {subsection}{\numberline {2.1.3}A Contour Plot}{17}{subsection.2.1.3}%
\contentsline {subsection}{\numberline {2.1.4}TensorBoard}{19}{subsection.2.1.4}%
\contentsline {section}{\numberline {2.2}Conclusion}{19}{section.2.2}%
\contentsline {section}{\numberline {2.3}Exercises}{19}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}The Three Dimensional \texttt {fun\_cubed}}{21}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2}The Ten Dimensional \texttt {fun\_wing\_wt}}{21}{subsection.2.3.2}%
\contentsline {subsection}{\numberline {2.3.3}The Three Dimensional \texttt {fun\_runge}}{21}{subsection.2.3.3}%
\contentsline {subsection}{\numberline {2.3.4}The Three Dimensional \texttt {fun\_linear}}{21}{subsection.2.3.4}%
\contentsline {chapter}{\numberline {3}Isotropic and Anisotropic Kriging}{23}{chapter.3}%
\contentsline {section}{\numberline {3.1}Example: Isotropic \texttt {Spot} Surrogate and the 2-dim Sphere Function}{23}{section.3.1}%
\contentsline {subsection}{\numberline {3.1.1}The Objective Function: 2-dim Sphere}{23}{subsection.3.1.1}%
\contentsline {subsection}{\numberline {3.1.2}Results}{24}{subsection.3.1.2}%
\contentsline {section}{\numberline {3.2}Example With Anisotropic Kriging}{24}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Taking a Look at the \texttt {theta} Values}{26}{subsection.3.2.1}%
\contentsline {subsubsection}{\numberline {3.2.1.1}\texttt {theta} Values from the \texttt {spot} Model}{26}{subsubsection.3.2.1.1}%
\contentsline {subsubsection}{\numberline {3.2.1.2}TensorBoard}{27}{subsubsection.3.2.1.2}%
\contentsline {section}{\numberline {3.3}Exercises}{27}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}\texttt {fun\_branin}}{27}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}\texttt {fun\_sin\_cos}}{29}{subsection.3.3.2}%
\contentsline {subsection}{\numberline {3.3.3}\texttt {fun\_runge}}{29}{subsection.3.3.3}%
\contentsline {subsection}{\numberline {3.3.4}\texttt {fun\_wingwt}}{29}{subsection.3.3.4}%
\contentsline {chapter}{\numberline {4}Using \texttt {sklearn} Surrogates in \texttt {spotpython}}{30}{chapter.4}%
\contentsline {section}{\numberline {4.1}Example: Branin Function with \texttt {spotpython}'s Internal Kriging Surrogate}{30}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1}The Objective Function Branin}{30}{subsection.4.1.1}%
\contentsline {subsection}{\numberline {4.1.2}Running the surrogate model based optimizer \texttt {Spot}:}{31}{subsection.4.1.2}%
\contentsline {subsection}{\numberline {4.1.3}TensorBoard}{32}{subsection.4.1.3}%
\contentsline {subsection}{\numberline {4.1.4}Print the Results}{32}{subsection.4.1.4}%
\contentsline {subsection}{\numberline {4.1.5}Show the Progress and the Surrogate}{32}{subsection.4.1.5}%
\contentsline {section}{\numberline {4.2}Example: Using Surrogates From scikit-learn}{34}{section.4.2}%
\contentsline {subsection}{\numberline {4.2.1}GaussianProcessRegressor as a Surrogate}{35}{subsection.4.2.1}%
\contentsline {section}{\numberline {4.3}Example: One-dimensional Sphere Function With \texttt {spotpython}'s Kriging}{37}{section.4.3}%
\contentsline {subsection}{\numberline {4.3.1}Results}{39}{subsection.4.3.1}%
\contentsline {section}{\numberline {4.4}Example: \texttt {Sklearn} Model GaussianProcess}{40}{section.4.4}%
\contentsline {section}{\numberline {4.5}Exercises}{42}{section.4.5}%
\contentsline {subsection}{\numberline {4.5.1}\texttt {DecisionTreeRegressor}}{42}{subsection.4.5.1}%
\contentsline {subsection}{\numberline {4.5.2}\texttt {RandomForestRegressor}}{43}{subsection.4.5.2}%
\contentsline {subsection}{\numberline {4.5.3}\texttt {linear\_model.LinearRegression}}{43}{subsection.4.5.3}%
\contentsline {subsection}{\numberline {4.5.4}\texttt {linear\_model.Ridge}}{43}{subsection.4.5.4}%
\contentsline {section}{\numberline {4.6}Exercise 2}{43}{section.4.6}%
\contentsline {chapter}{\numberline {5}Sequential Parameter Optimization: Using \texttt {scipy} Optimizers}{44}{chapter.5}%
\contentsline {section}{\numberline {5.1}The Objective Function Branin}{44}{section.5.1}%
\contentsline {section}{\numberline {5.2}The Optimizer}{45}{section.5.2}%
\contentsline {subsection}{\numberline {5.2.1}TensorBoard}{47}{subsection.5.2.1}%
\contentsline {section}{\numberline {5.3}Print the Results}{47}{section.5.3}%
\contentsline {section}{\numberline {5.4}Show the Progress}{47}{section.5.4}%
\contentsline {section}{\numberline {5.5}Exercises}{49}{section.5.5}%
\contentsline {subsection}{\numberline {5.5.1}\texttt {dual\_annealing}}{49}{subsection.5.5.1}%
\contentsline {subsection}{\numberline {5.5.2}\texttt {direct}}{49}{subsection.5.5.2}%
\contentsline {subsection}{\numberline {5.5.3}\texttt {shgo}}{49}{subsection.5.5.3}%
\contentsline {subsection}{\numberline {5.5.4}\texttt {basinhopping}}{49}{subsection.5.5.4}%
\contentsline {subsection}{\numberline {5.5.5}Performance Comparison}{50}{subsection.5.5.5}%
\contentsline {chapter}{\numberline {6}Sequential Parameter Optimization: Gaussian Process Models}{51}{chapter.6}%
\contentsline {section}{\numberline {6.1}Gaussian Processes Regression: Basic Introductory \texttt {scikit-learn} Example}{51}{section.6.1}%
\contentsline {subsection}{\numberline {6.1.1}Train and Test Data}{52}{subsection.6.1.1}%
\contentsline {subsection}{\numberline {6.1.2}Building the Surrogate With \texttt {Sklearn}}{52}{subsection.6.1.2}%
\contentsline {subsection}{\numberline {6.1.3}Plotting the \texttt {Sklearn}Model}{52}{subsection.6.1.3}%
\contentsline {subsection}{\numberline {6.1.4}The \texttt {spotpython} Version}{53}{subsection.6.1.4}%
\contentsline {subsection}{\numberline {6.1.5}Visualizing the Differences Between the \texttt {spotpython} and the \texttt {sklearn} Model Fits}{54}{subsection.6.1.5}%
\contentsline {section}{\numberline {6.2}Exercises}{54}{section.6.2}%
\contentsline {subsection}{\numberline {6.2.1}\texttt {Schonlau\ Example\ Function}}{54}{subsection.6.2.1}%
\contentsline {subsection}{\numberline {6.2.2}\texttt {Forrester\ Example\ Function}}{54}{subsection.6.2.2}%
\contentsline {subsection}{\numberline {6.2.3}\texttt {fun\_runge\ Function\ (1-dim)}}{55}{subsection.6.2.3}%
\contentsline {subsection}{\numberline {6.2.4}\texttt {fun\_cubed\ (1-dim)}}{56}{subsection.6.2.4}%
\contentsline {subsection}{\numberline {6.2.5}The Effect of Noise}{56}{subsection.6.2.5}%
\contentsline {chapter}{\numberline {7}Expected Improvement}{57}{chapter.7}%
\contentsline {section}{\numberline {7.1}Example: \texttt {Spot} and the 1-dim Sphere Function}{57}{section.7.1}%
\contentsline {subsection}{\numberline {7.1.1}The Objective Function: 1-dim Sphere}{57}{subsection.7.1.1}%
\contentsline {subsection}{\numberline {7.1.2}Results}{59}{subsection.7.1.2}%
\contentsline {section}{\numberline {7.2}Same, but with EI as infill\_criterion}{59}{section.7.2}%
\contentsline {section}{\numberline {7.3}Non-isotropic Kriging}{62}{section.7.3}%
\contentsline {section}{\numberline {7.4}Using \texttt {sklearn} Surrogates}{66}{section.7.4}%
\contentsline {subsection}{\numberline {7.4.1}The spot Loop}{66}{subsection.7.4.1}%
\contentsline {subsection}{\numberline {7.4.2}spot: The Initial Model}{66}{subsection.7.4.2}%
\contentsline {subsubsection}{\numberline {7.4.2.1}Example: Modifying the initial design size}{66}{subsubsection.7.4.2.1}%
\contentsline {subsection}{\numberline {7.4.3}Init: Build Initial Design}{69}{subsection.7.4.3}%
\contentsline {subsection}{\numberline {7.4.4}Evaluate}{70}{subsection.7.4.4}%
\contentsline {subsection}{\numberline {7.4.5}Build Surrogate}{70}{subsection.7.4.5}%
\contentsline {subsection}{\numberline {7.4.6}A Simple Predictor}{70}{subsection.7.4.6}%
\contentsline {section}{\numberline {7.5}Gaussian Processes regression: basic introductory example}{71}{section.7.5}%
\contentsline {section}{\numberline {7.6}The Surrogate: Using scikit-learn models}{73}{section.7.6}%
\contentsline {section}{\numberline {7.7}Additional Examples}{76}{section.7.7}%
\contentsline {subsection}{\numberline {7.7.1}Optimize on Surrogate}{78}{subsection.7.7.1}%
\contentsline {subsection}{\numberline {7.7.2}Evaluate on Real Objective}{78}{subsection.7.7.2}%
\contentsline {subsection}{\numberline {7.7.3}Impute / Infill new Points}{78}{subsection.7.7.3}%
\contentsline {section}{\numberline {7.8}Tests}{78}{section.7.8}%
\contentsline {section}{\numberline {7.9}EI: The Famous Schonlau Example}{80}{section.7.9}%
\contentsline {section}{\numberline {7.10}EI: The Forrester Example}{81}{section.7.10}%
\contentsline {section}{\numberline {7.11}Noise}{83}{section.7.11}%
\contentsline {section}{\numberline {7.12}Cubic Function}{85}{section.7.12}%
\contentsline {section}{\numberline {7.13}Factors}{90}{section.7.13}%
\contentsline {chapter}{\numberline {8}Hyperparameter Tuning and Noise}{92}{chapter.8}%
\contentsline {section}{\numberline {8.1}Example: \texttt {Spot} and the Noisy Sphere Function}{92}{section.8.1}%
\contentsline {subsection}{\numberline {8.1.1}The Objective Function: Noisy Sphere}{92}{subsection.8.1.1}%
\contentsline {section}{\numberline {8.2}Print the Results}{95}{section.8.2}%
\contentsline {section}{\numberline {8.3}Noise and Surrogates: The Nugget Effect}{96}{section.8.3}%
\contentsline {subsection}{\numberline {8.3.1}The Noisy Sphere}{96}{subsection.8.3.1}%
\contentsline {subsubsection}{\numberline {8.3.1.1}The Data}{96}{subsubsection.8.3.1.1}%
\contentsline {section}{\numberline {8.4}Exercises}{98}{section.8.4}%
\contentsline {subsection}{\numberline {8.4.1}Noisy \texttt {fun\_cubed}}{98}{subsection.8.4.1}%
\contentsline {subsection}{\numberline {8.4.2}\texttt {fun\_runge}}{99}{subsection.8.4.2}%
\contentsline {subsection}{\numberline {8.4.3}\texttt {fun\_forrester}}{99}{subsection.8.4.3}%
\contentsline {subsection}{\numberline {8.4.4}\texttt {fun\_xsin}}{99}{subsection.8.4.4}%
\contentsline {chapter}{\numberline {9}Handling Noise: Optimal Computational Budget Allocation in \texttt {Spot}}{100}{chapter.9}%
\contentsline {section}{\numberline {9.1}Example: \texttt {Spot}, OCBA, and the Noisy Sphere Function}{100}{section.9.1}%
\contentsline {subsection}{\numberline {9.1.1}The Objective Function: Noisy Sphere}{100}{subsection.9.1.1}%
\contentsline {section}{\numberline {9.2}Print the Results}{103}{section.9.2}%
\contentsline {section}{\numberline {9.3}Noise and Surrogates: The Nugget Effect}{104}{section.9.3}%
\contentsline {subsection}{\numberline {9.3.1}The Noisy Sphere}{104}{subsection.9.3.1}%
\contentsline {subsubsection}{\numberline {9.3.1.1}The Data}{104}{subsubsection.9.3.1.1}%
\contentsline {section}{\numberline {9.4}Exercises}{106}{section.9.4}%
\contentsline {subsection}{\numberline {9.4.1}Noisy \texttt {fun\_cubed}}{106}{subsection.9.4.1}%
\contentsline {subsection}{\numberline {9.4.2}\texttt {fun\_runge}}{106}{subsection.9.4.2}%
\contentsline {subsection}{\numberline {9.4.3}\texttt {fun\_forrester}}{106}{subsection.9.4.3}%
\contentsline {subsection}{\numberline {9.4.4}\texttt {fun\_xsin}}{107}{subsection.9.4.4}%
\contentsline {part}{\numberline {II}Hyperparameter Tuning}{108}{part.2}%
\contentsline {chapter}{\numberline {10}HPT: sklearn SVC on Moons Data}{109}{chapter.10}%
\contentsline {section}{\numberline {10.1}Step 1: Setup}{109}{section.10.1}%
\contentsline {section}{\numberline {10.2}Step 2: Initialization of the Empty \texttt {fun\_control} Dictionary}{109}{section.10.2}%
\contentsline {section}{\numberline {10.3}Step 3: SKlearn Load Data (Classification)}{110}{section.10.3}%
\contentsline {section}{\numberline {10.4}Step 4: Specification of the Preprocessing Model}{111}{section.10.4}%
\contentsline {section}{\numberline {10.5}Step 5: Select Model (\texttt {algorithm}) and \texttt {core\_model\_hyper\_dict}}{112}{section.10.5}%
\contentsline {section}{\numberline {10.6}Step 6: Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{115}{section.10.6}%
\contentsline {subsection}{\numberline {10.6.1}Modify hyperparameter of type numeric and integer (boolean)}{115}{subsection.10.6.1}%
\contentsline {subsection}{\numberline {10.6.2}Modify hyperparameter of type factor}{115}{subsection.10.6.2}%
\contentsline {subsection}{\numberline {10.6.3}Optimizers}{116}{subsection.10.6.3}%
\contentsline {section}{\numberline {10.7}Step 7: Selection of the Objective (Loss) Function}{116}{section.10.7}%
\contentsline {subsection}{\numberline {10.7.1}Predict Classes or Class Probabilities}{116}{subsection.10.7.1}%
\contentsline {section}{\numberline {10.8}Step 8: Calling the SPOT Function}{117}{section.10.8}%
\contentsline {subsection}{\numberline {10.8.1}Preparing the SPOT Call}{117}{subsection.10.8.1}%
\contentsline {subsection}{\numberline {10.8.2}The Objective Function}{118}{subsection.10.8.2}%
\contentsline {subsection}{\numberline {10.8.3}Run the \texttt {Spot} Optimizer}{118}{subsection.10.8.3}%
\contentsline {subsection}{\numberline {10.8.4}Starting the Hyperparameter Tuning}{118}{subsection.10.8.4}%
\contentsline {section}{\numberline {10.9}Step 9: Results}{120}{section.10.9}%
\contentsline {subsection}{\numberline {10.9.1}Show variable importance}{121}{subsection.10.9.1}%
\contentsline {subsection}{\numberline {10.9.2}Get Default Hyperparameters}{121}{subsection.10.9.2}%
\contentsline {subsection}{\numberline {10.9.3}Get SPOT Results}{122}{subsection.10.9.3}%
\contentsline {subsection}{\numberline {10.9.4}Plot: Compare Predictions}{123}{subsection.10.9.4}%
\contentsline {subsection}{\numberline {10.9.5}Detailed Hyperparameter Plots}{124}{subsection.10.9.5}%
\contentsline {subsection}{\numberline {10.9.6}Parallel Coordinates Plot}{124}{subsection.10.9.6}%
\contentsline {subsection}{\numberline {10.9.7}Plot all Combinations of Hyperparameters}{124}{subsection.10.9.7}%
\contentsline {chapter}{\numberline {11}\texttt {river} Hyperparameter Tuning: Hoeffding Adaptive Tree Regressor with Friedman Drift Data}{126}{chapter.11}%
\contentsline {section}{\numberline {11.1}Setup}{126}{section.11.1}%
\contentsline {section}{\numberline {11.2}Initialization of the \texttt {fun\_control} Dictionary}{127}{section.11.2}%
\contentsline {section}{\numberline {11.3}Load Data: The Friedman Drift Data}{128}{section.11.3}%
\contentsline {section}{\numberline {11.4}Specification of the Preprocessing Model}{129}{section.11.4}%
\contentsline {section}{\numberline {11.5}SelectSelect Model (\texttt {algorithm}) and \texttt {core\_model\_hyper\_dict}}{129}{section.11.5}%
\contentsline {section}{\numberline {11.6}Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{130}{section.11.6}%
\contentsline {section}{\numberline {11.7}Selection of the Objective Function}{131}{section.11.7}%
\contentsline {section}{\numberline {11.8}Calling the SPOT Function}{132}{section.11.8}%
\contentsline {subsection}{\numberline {11.8.1}Prepare the SPOT Parameters}{132}{subsection.11.8.1}%
\contentsline {subsection}{\numberline {11.8.2}The Objective Function}{133}{subsection.11.8.2}%
\contentsline {subsection}{\numberline {11.8.3}Run the \texttt {Spot} Optimizer}{133}{subsection.11.8.3}%
\contentsline {subsection}{\numberline {11.8.4}TensorBoard}{135}{subsection.11.8.4}%
\contentsline {subsection}{\numberline {11.8.5}Results}{135}{subsection.11.8.5}%
\contentsline {section}{\numberline {11.9}The Larger Data Set}{138}{section.11.9}%
\contentsline {section}{\numberline {11.10}Get Default Hyperparameters}{139}{section.11.10}%
\contentsline {subsection}{\numberline {11.10.1}Show Predictions}{140}{subsection.11.10.1}%
\contentsline {section}{\numberline {11.11}Get SPOT Results}{140}{section.11.11}%
\contentsline {section}{\numberline {11.12}Visualize Regression Trees}{142}{section.11.12}%
\contentsline {subsection}{\numberline {11.12.1}Spot Model}{142}{subsection.11.12.1}%
\contentsline {section}{\numberline {11.13}Detailed Hyperparameter Plots}{143}{section.11.13}%
\contentsline {section}{\numberline {11.14}Parallel Coordinates Plots}{144}{section.11.14}%
\contentsline {section}{\numberline {11.15}Plot all Combinations of Hyperparameters}{144}{section.11.15}%
\contentsline {chapter}{\numberline {12}HPT: PyTorch With \texttt {spotpython} and Ray Tune on CIFAR10}{146}{chapter.12}%
\contentsline {section}{\numberline {12.1}Step 1: Setup}{147}{section.12.1}%
\contentsline {section}{\numberline {12.2}Step 2: Initialization of the \texttt {fun\_control} Dictionary}{148}{section.12.2}%
\contentsline {section}{\numberline {12.3}Step 3: PyTorch Data Loading}{148}{section.12.3}%
\contentsline {section}{\numberline {12.4}Step 4: Specification of the Preprocessing Model}{149}{section.12.4}%
\contentsline {section}{\numberline {12.5}Step 5: Select Model (\texttt {algorithm}) and \texttt {core\_model\_hyper\_dict}}{150}{section.12.5}%
\contentsline {subsubsection}{\numberline {12.5.0.1}Implementing a Configurable Neural Network With Ray Tune}{150}{subsubsection.12.5.0.1}%
\contentsline {subsubsection}{\numberline {12.5.0.2}Implementing a Configurable Neural Network With spotpython}{150}{subsubsection.12.5.0.2}%
\contentsline {subsection}{\numberline {12.5.1}The \texttt {Net\_Core} class}{151}{subsection.12.5.1}%
\contentsline {subsection}{\numberline {12.5.2}Comparison of the Approach Described in the PyTorch Tutorial With spotpython}{152}{subsection.12.5.2}%
\contentsline {subsection}{\numberline {12.5.3}The Search Space: Hyperparameters}{153}{subsection.12.5.3}%
\contentsline {subsection}{\numberline {12.5.4}Configuring the Search Space With Ray Tune}{153}{subsection.12.5.4}%
\contentsline {subsection}{\numberline {12.5.5}Configuring the Search Space With spotpython}{153}{subsection.12.5.5}%
\contentsline {subsubsection}{\numberline {12.5.5.1}The \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm}{153}{subsubsection.12.5.5.1}%
\contentsline {section}{\numberline {12.6}Step 6: Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{155}{section.12.6}%
\contentsline {subsubsection}{\numberline {12.6.0.1}Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{156}{subsubsection.12.6.0.1}%
\contentsline {subsubsection}{\numberline {12.6.0.2}Modify Hyperparameters of Type numeric and integer (boolean)}{156}{subsubsection.12.6.0.2}%
\contentsline {subsubsection}{\numberline {12.6.0.3}Modify Hyperparameter of Type factor}{156}{subsubsection.12.6.0.3}%
\contentsline {subsection}{\numberline {12.6.1}Optimizers}{157}{subsection.12.6.1}%
\contentsline {section}{\numberline {12.7}Step 7: Selection of the Objective (Loss) Function}{159}{section.12.7}%
\contentsline {subsection}{\numberline {12.7.1}Evaluation: Data Splitting}{159}{subsection.12.7.1}%
\contentsline {subsection}{\numberline {12.7.2}Hold-out Data Split}{159}{subsection.12.7.2}%
\contentsline {subsection}{\numberline {12.7.3}Cross-Validation}{160}{subsection.12.7.3}%
\contentsline {subsection}{\numberline {12.7.4}Overview of the Evaluation Settings}{160}{subsection.12.7.4}%
\contentsline {subsubsection}{\numberline {12.7.4.1}Settings for the Hyperparameter Tuning}{160}{subsubsection.12.7.4.1}%
\contentsline {subsubsection}{\numberline {12.7.4.2}Settings for the Final Evaluation of the Tuned Architecture}{161}{subsubsection.12.7.4.2}%
\contentsline {paragraph}{\numberline {12.7.4.2.1}Training of the Tuned Architecture}{161}{paragraph.12.7.4.2.1}%
\contentsline {paragraph}{\numberline {12.7.4.2.2}Testing of the Tuned Architecture}{161}{paragraph.12.7.4.2.2}%
\contentsline {subsection}{\numberline {12.7.5}Evaluation: Loss Functions and Metrics}{161}{subsection.12.7.5}%
\contentsline {section}{\numberline {12.8}Step 8: Calling the SPOT Function}{162}{section.12.8}%
\contentsline {subsection}{\numberline {12.8.1}Preparing the SPOT Call}{162}{subsection.12.8.1}%
\contentsline {subsection}{\numberline {12.8.2}The Objective Function \texttt {fun\_torch}}{163}{subsection.12.8.2}%
\contentsline {subsection}{\numberline {12.8.3}Using Default Hyperparameters or Results from Previous Runs}{163}{subsection.12.8.3}%
\contentsline {subsection}{\numberline {12.8.4}Starting the Hyperparameter Tuning}{164}{subsection.12.8.4}%
\contentsline {section}{\numberline {12.9}Step 9: Tensorboard}{170}{section.12.9}%
\contentsline {subsection}{\numberline {12.9.1}Tensorboard: Start Tensorboard}{170}{subsection.12.9.1}%
\contentsline {subsection}{\numberline {12.9.2}Saving the State of the Notebook}{170}{subsection.12.9.2}%
\contentsline {section}{\numberline {12.10}Step 10: Results}{171}{section.12.10}%
\contentsline {subsection}{\numberline {12.10.1}Get the Tuned Architecture (SPOT Results)}{173}{subsection.12.10.1}%
\contentsline {subsection}{\numberline {12.10.2}Get Default Hyperparameters}{173}{subsection.12.10.2}%
\contentsline {subsection}{\numberline {12.10.3}Evaluation of the Default Architecture}{174}{subsection.12.10.3}%
\contentsline {subsection}{\numberline {12.10.4}Evaluation of the Tuned Architecture}{176}{subsection.12.10.4}%
\contentsline {subsection}{\numberline {12.10.5}Detailed Hyperparameter Plots}{178}{subsection.12.10.5}%
\contentsline {section}{\numberline {12.11}Summary and Outlook}{179}{section.12.11}%
\contentsline {section}{\numberline {12.12}Appendix}{180}{section.12.12}%
\contentsline {subsection}{\numberline {12.12.1}Sample Output From Ray Tune's Run}{180}{subsection.12.12.1}%
\contentsline {chapter}{\numberline {13}HPT: sklearn RandomForestClassifier VBDP Data}{182}{chapter.13}%
\contentsline {section}{\numberline {13.1}Step 1: Setup}{182}{section.13.1}%
\contentsline {section}{\numberline {13.2}Step 2: Initialization of the Empty \texttt {fun\_control} Dictionary}{183}{section.13.2}%
\contentsline {section}{\numberline {13.3}Step 3: PyTorch Data Loading}{183}{section.13.3}%
\contentsline {subsection}{\numberline {13.3.1}Load Data: Classification VBDP}{183}{subsection.13.3.1}%
\contentsline {subsection}{\numberline {13.3.2}Holdout Train and Test Data}{184}{subsection.13.3.2}%
\contentsline {section}{\numberline {13.4}Step 4: Specification of the Preprocessing Model}{185}{section.13.4}%
\contentsline {section}{\numberline {13.5}Step 5: Select Model (\texttt {algorithm}) and \texttt {core\_model\_hyper\_dict}}{185}{section.13.5}%
\contentsline {section}{\numberline {13.6}Step 6: Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{187}{section.13.6}%
\contentsline {subsection}{\numberline {13.6.1}Modify hyperparameter of type numeric and integer (boolean)}{187}{subsection.13.6.1}%
\contentsline {subsection}{\numberline {13.6.2}Modify hyperparameter of type factor}{187}{subsection.13.6.2}%
\contentsline {subsection}{\numberline {13.6.3}Optimizers}{188}{subsection.13.6.3}%
\contentsline {subsection}{\numberline {13.6.4}Selection of the Objective: Metric and Loss Functions}{188}{subsection.13.6.4}%
\contentsline {section}{\numberline {13.7}Step 7: Selection of the Objective (Loss) Function}{188}{section.13.7}%
\contentsline {subsection}{\numberline {13.7.1}Metric Function}{188}{subsection.13.7.1}%
\contentsline {subsubsection}{\numberline {13.7.1.1}The MAPK Metric}{189}{subsubsection.13.7.1.1}%
\contentsline {subsubsection}{\numberline {13.7.1.2}Other Metrics}{189}{subsubsection.13.7.1.2}%
\contentsline {subsection}{\numberline {13.7.2}Evaluation on Hold-out Data}{190}{subsection.13.7.2}%
\contentsline {subsection}{\numberline {13.7.3}OOB Score}{190}{subsection.13.7.3}%
\contentsline {subsubsection}{\numberline {13.7.3.1}Cross Validation}{190}{subsubsection.13.7.3.1}%
\contentsline {section}{\numberline {13.8}Step 8: Calling the SPOT Function}{191}{section.13.8}%
\contentsline {subsection}{\numberline {13.8.1}Preparing the SPOT Call}{191}{subsection.13.8.1}%
\contentsline {subsection}{\numberline {13.8.2}The Objective Function}{191}{subsection.13.8.2}%
\contentsline {subsection}{\numberline {13.8.3}Run the \texttt {Spot} Optimizer}{192}{subsection.13.8.3}%
\contentsline {section}{\numberline {13.9}Step 9: Tensorboard}{195}{section.13.9}%
\contentsline {section}{\numberline {13.10}Step 10: Results}{195}{section.13.10}%
\contentsline {subsection}{\numberline {13.10.1}Show variable importance}{196}{subsection.13.10.1}%
\contentsline {subsection}{\numberline {13.10.2}Get Default Hyperparameters}{196}{subsection.13.10.2}%
\contentsline {subsection}{\numberline {13.10.3}Get SPOT Results}{197}{subsection.13.10.3}%
\contentsline {subsection}{\numberline {13.10.4}Evaluate SPOT Results}{198}{subsection.13.10.4}%
\contentsline {subsection}{\numberline {13.10.5}Handling Non-deterministic Results}{199}{subsection.13.10.5}%
\contentsline {subsection}{\numberline {13.10.6}Evalution of the Default Hyperparameters}{199}{subsection.13.10.6}%
\contentsline {subsection}{\numberline {13.10.7}Plot: Compare Predictions}{200}{subsection.13.10.7}%
\contentsline {subsection}{\numberline {13.10.8}Cross-validated Evaluations}{200}{subsection.13.10.8}%
\contentsline {subsection}{\numberline {13.10.9}Detailed Hyperparameter Plots}{201}{subsection.13.10.9}%
\contentsline {subsection}{\numberline {13.10.10}Parallel Coordinates Plot}{203}{subsection.13.10.10}%
\contentsline {subsection}{\numberline {13.10.11}Plot all Combinations of Hyperparameters}{203}{subsection.13.10.11}%
\contentsline {chapter}{\numberline {14}HPT: sklearn XGB Classifier VBDP Data}{204}{chapter.14}%
\contentsline {section}{\numberline {14.1}Step 1: Setup}{204}{section.14.1}%
\contentsline {section}{\numberline {14.2}Step 2: Initialization of the Empty \texttt {fun\_control} Dictionary}{205}{section.14.2}%
\contentsline {section}{\numberline {14.3}Step 3: PyTorch Data Loading}{205}{section.14.3}%
\contentsline {subsection}{\numberline {14.3.1}1. Load Data: Classification VBDP}{205}{subsection.14.3.1}%
\contentsline {subsection}{\numberline {14.3.2}Holdout Train and Test Data}{206}{subsection.14.3.2}%
\contentsline {section}{\numberline {14.4}Step 4: Specification of the Preprocessing Model}{207}{section.14.4}%
\contentsline {section}{\numberline {14.5}Step 5: Select Model (\texttt {algorithm}) and \texttt {core\_model\_hyper\_dict}}{207}{section.14.5}%
\contentsline {section}{\numberline {14.6}Step 6: Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{209}{section.14.6}%
\contentsline {subsection}{\numberline {14.6.1}Modify hyperparameter of type numeric and integer (boolean)}{209}{subsection.14.6.1}%
\contentsline {subsection}{\numberline {14.6.2}Modify hyperparameter of type factor}{210}{subsection.14.6.2}%
\contentsline {subsection}{\numberline {14.6.3}Optimizers}{210}{subsection.14.6.3}%
\contentsline {section}{\numberline {14.7}Step 7: Selection of the Objective (Loss) Function}{210}{section.14.7}%
\contentsline {subsection}{\numberline {14.7.1}Evaluation}{210}{subsection.14.7.1}%
\contentsline {subsection}{\numberline {14.7.2}Selection of the Objective: Metric and Loss Functions}{210}{subsection.14.7.2}%
\contentsline {subsection}{\numberline {14.7.3}Loss Function}{211}{subsection.14.7.3}%
\contentsline {subsection}{\numberline {14.7.4}Metric Function}{211}{subsection.14.7.4}%
\contentsline {subsubsection}{\numberline {14.7.4.1}The MAPK Metric}{211}{subsubsection.14.7.4.1}%
\contentsline {subsubsection}{\numberline {14.7.4.2}Other Metrics}{211}{subsubsection.14.7.4.2}%
\contentsline {subsection}{\numberline {14.7.5}Evaluation on Hold-out Data}{212}{subsection.14.7.5}%
\contentsline {subsubsection}{\numberline {14.7.5.1}Cross Validation}{212}{subsubsection.14.7.5.1}%
\contentsline {section}{\numberline {14.8}Step 8: Calling the SPOT Function}{213}{section.14.8}%
\contentsline {subsection}{\numberline {14.8.1}Preparing the SPOT Call}{213}{subsection.14.8.1}%
\contentsline {subsection}{\numberline {14.8.2}The Objective Function}{213}{subsection.14.8.2}%
\contentsline {subsection}{\numberline {14.8.3}Run the \texttt {Spot} Optimizer}{214}{subsection.14.8.3}%
\contentsline {section}{\numberline {14.9}Step 9: Tensorboard}{215}{section.14.9}%
\contentsline {section}{\numberline {14.10}Step 10: Results}{215}{section.14.10}%
\contentsline {subsection}{\numberline {14.10.1}Show variable importance}{216}{subsection.14.10.1}%
\contentsline {subsection}{\numberline {14.10.2}Get Default Hyperparameters}{217}{subsection.14.10.2}%
\contentsline {subsection}{\numberline {14.10.3}Get SPOT Results}{218}{subsection.14.10.3}%
\contentsline {subsection}{\numberline {14.10.4}Evaluate SPOT Results}{218}{subsection.14.10.4}%
\contentsline {subsection}{\numberline {14.10.5}Handling Non-deterministic Results}{219}{subsection.14.10.5}%
\contentsline {subsection}{\numberline {14.10.6}Evalution of the Default Hyperparameters}{220}{subsection.14.10.6}%
\contentsline {subsection}{\numberline {14.10.7}Plot: Compare Predictions}{221}{subsection.14.10.7}%
\contentsline {subsection}{\numberline {14.10.8}Cross-validated Evaluations}{221}{subsection.14.10.8}%
\contentsline {subsection}{\numberline {14.10.9}Detailed Hyperparameter Plots}{222}{subsection.14.10.9}%
\contentsline {subsection}{\numberline {14.10.10}Parallel Coordinates Plot}{223}{subsection.14.10.10}%
\contentsline {subsection}{\numberline {14.10.11}Plot all Combinations of Hyperparameters}{223}{subsection.14.10.11}%
\contentsline {chapter}{\numberline {15}HPT: sklearn SVC VBDP Data}{225}{chapter.15}%
\contentsline {section}{\numberline {15.1}Step 1: Setup}{225}{section.15.1}%
\contentsline {section}{\numberline {15.2}Step 2: Initialization of the Empty \texttt {fun\_control} Dictionary}{226}{section.15.2}%
\contentsline {section}{\numberline {15.3}Step 3: PyTorch Data Loading}{226}{section.15.3}%
\contentsline {subsection}{\numberline {15.3.1}1. Load Data: Classification VBDP}{226}{subsection.15.3.1}%
\contentsline {subsection}{\numberline {15.3.2}Holdout Train and Test Data}{227}{subsection.15.3.2}%
\contentsline {section}{\numberline {15.4}Step 4: Specification of the Preprocessing Model}{228}{section.15.4}%
\contentsline {section}{\numberline {15.5}Step 5: Select Model (\texttt {algorithm}) and \texttt {core\_model\_hyper\_dict}}{228}{section.15.5}%
\contentsline {section}{\numberline {15.6}Step 6: Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{230}{section.15.6}%
\contentsline {subsection}{\numberline {15.6.1}Modify hyperparameter of type numeric and integer (boolean)}{230}{subsection.15.6.1}%
\contentsline {subsection}{\numberline {15.6.2}Modify hyperparameter of type factor}{230}{subsection.15.6.2}%
\contentsline {subsection}{\numberline {15.6.3}Optimizers}{231}{subsection.15.6.3}%
\contentsline {subsection}{\numberline {15.6.4}Selection of the Objective: Metric and Loss Functions}{231}{subsection.15.6.4}%
\contentsline {section}{\numberline {15.7}Step 7: Selection of the Objective (Loss) Function}{231}{section.15.7}%
\contentsline {subsection}{\numberline {15.7.1}Metric Function}{231}{subsection.15.7.1}%
\contentsline {subsubsection}{\numberline {15.7.1.1}The MAPK Metric}{232}{subsubsection.15.7.1.1}%
\contentsline {subsubsection}{\numberline {15.7.1.2}Other Metrics}{232}{subsubsection.15.7.1.2}%
\contentsline {subsection}{\numberline {15.7.2}Evaluation on Hold-out Data}{232}{subsection.15.7.2}%
\contentsline {subsubsection}{\numberline {15.7.2.1}Cross Validation}{233}{subsubsection.15.7.2.1}%
\contentsline {section}{\numberline {15.8}Step 8: Calling the SPOT Function}{233}{section.15.8}%
\contentsline {subsection}{\numberline {15.8.1}Preparing the SPOT Call}{233}{subsection.15.8.1}%
\contentsline {subsection}{\numberline {15.8.2}The Objective Function}{234}{subsection.15.8.2}%
\contentsline {subsection}{\numberline {15.8.3}Run the \texttt {Spot} Optimizer}{234}{subsection.15.8.3}%
\contentsline {section}{\numberline {15.9}Step 9: Tensorboard}{239}{section.15.9}%
\contentsline {section}{\numberline {15.10}Step 10: Results}{239}{section.15.10}%
\contentsline {subsection}{\numberline {15.10.1}Show variable importance}{240}{subsection.15.10.1}%
\contentsline {subsection}{\numberline {15.10.2}Get Default Hyperparameters}{240}{subsection.15.10.2}%
\contentsline {subsection}{\numberline {15.10.3}Get SPOT Results}{241}{subsection.15.10.3}%
\contentsline {subsection}{\numberline {15.10.4}Evaluate SPOT Results}{242}{subsection.15.10.4}%
\contentsline {subsection}{\numberline {15.10.5}Handling Non-deterministic Results}{243}{subsection.15.10.5}%
\contentsline {subsection}{\numberline {15.10.6}Evalution of the Default Hyperparameters}{243}{subsection.15.10.6}%
\contentsline {subsection}{\numberline {15.10.7}Plot: Compare Predictions}{244}{subsection.15.10.7}%
\contentsline {subsection}{\numberline {15.10.8}Cross-validated Evaluations}{244}{subsection.15.10.8}%
\contentsline {subsection}{\numberline {15.10.9}Detailed Hyperparameter Plots}{245}{subsection.15.10.9}%
\contentsline {subsection}{\numberline {15.10.10}Parallel Coordinates Plot}{246}{subsection.15.10.10}%
\contentsline {subsection}{\numberline {15.10.11}Plot all Combinations of Hyperparameters}{246}{subsection.15.10.11}%
\contentsline {chapter}{\numberline {16}HPT: sklearn KNN Classifier VBDP Data}{247}{chapter.16}%
\contentsline {section}{\numberline {16.1}Step 1: Setup}{247}{section.16.1}%
\contentsline {section}{\numberline {16.2}Step 2: Initialization of the Empty \texttt {fun\_control} Dictionary}{248}{section.16.2}%
\contentsline {subsection}{\numberline {16.2.1}Load Data: Classification VBDP}{248}{subsection.16.2.1}%
\contentsline {subsection}{\numberline {16.2.2}Holdout Train and Test Data}{249}{subsection.16.2.2}%
\contentsline {section}{\numberline {16.3}Step 4: Specification of the Preprocessing Model}{250}{section.16.3}%
\contentsline {section}{\numberline {16.4}Step 5: Select Model (\texttt {algorithm}) and \texttt {core\_model\_hyper\_dict}}{250}{section.16.4}%
\contentsline {section}{\numberline {16.5}Step 6: Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{252}{section.16.5}%
\contentsline {subsection}{\numberline {16.5.1}Modify hyperparameter of type numeric and integer (boolean)}{252}{subsection.16.5.1}%
\contentsline {subsection}{\numberline {16.5.2}Modify hyperparameter of type factor}{252}{subsection.16.5.2}%
\contentsline {subsection}{\numberline {16.5.3}Optimizers}{253}{subsection.16.5.3}%
\contentsline {subsection}{\numberline {16.5.4}Selection of the Objective: Metric and Loss Functions}{253}{subsection.16.5.4}%
\contentsline {section}{\numberline {16.6}Step 7: Selection of the Objective (Loss) Function}{253}{section.16.6}%
\contentsline {subsection}{\numberline {16.6.1}Metric Function}{253}{subsection.16.6.1}%
\contentsline {subsubsection}{\numberline {16.6.1.1}The MAPK Metric}{254}{subsubsection.16.6.1.1}%
\contentsline {subsubsection}{\numberline {16.6.1.2}Other Metrics}{254}{subsubsection.16.6.1.2}%
\contentsline {subsection}{\numberline {16.6.2}Evaluation on Hold-out Data}{254}{subsection.16.6.2}%
\contentsline {subsubsection}{\numberline {16.6.2.1}Cross Validation}{255}{subsubsection.16.6.2.1}%
\contentsline {section}{\numberline {16.7}Step 8: Calling the SPOT Function}{255}{section.16.7}%
\contentsline {subsection}{\numberline {16.7.1}Preparing the SPOT Call}{255}{subsection.16.7.1}%
\contentsline {subsection}{\numberline {16.7.2}The Objective Function}{256}{subsection.16.7.2}%
\contentsline {subsection}{\numberline {16.7.3}Run the \texttt {Spot} Optimizer}{256}{subsection.16.7.3}%
\contentsline {section}{\numberline {16.8}Step 9: Tensorboard}{260}{section.16.8}%
\contentsline {section}{\numberline {16.9}Step 10: Results}{260}{section.16.9}%
\contentsline {subsection}{\numberline {16.9.1}Show variable importance}{261}{subsection.16.9.1}%
\contentsline {subsection}{\numberline {16.9.2}Get Default Hyperparameters}{261}{subsection.16.9.2}%
\contentsline {subsection}{\numberline {16.9.3}Get SPOT Results}{262}{subsection.16.9.3}%
\contentsline {subsection}{\numberline {16.9.4}Evaluate SPOT Results}{262}{subsection.16.9.4}%
\contentsline {subsection}{\numberline {16.9.5}Handling Non-deterministic Results}{263}{subsection.16.9.5}%
\contentsline {subsection}{\numberline {16.9.6}Evalution of the Default Hyperparameters}{264}{subsection.16.9.6}%
\contentsline {subsection}{\numberline {16.9.7}Plot: Compare Predictions}{264}{subsection.16.9.7}%
\contentsline {subsection}{\numberline {16.9.8}Cross-validated Evaluations}{265}{subsection.16.9.8}%
\contentsline {subsection}{\numberline {16.9.9}Detailed Hyperparameter Plots}{266}{subsection.16.9.9}%
\contentsline {subsection}{\numberline {16.9.10}Parallel Coordinates Plot}{266}{subsection.16.9.10}%
\contentsline {subsection}{\numberline {16.9.11}Plot all Combinations of Hyperparameters}{266}{subsection.16.9.11}%
\contentsline {chapter}{\numberline {17}HPT PyTorch Lightning: VBDP}{268}{chapter.17}%
\contentsline {section}{\numberline {17.1}Step 1: Setup}{268}{section.17.1}%
\contentsline {section}{\numberline {17.2}Step 2: Initialization of the \texttt {fun\_control} Dictionary}{269}{section.17.2}%
\contentsline {section}{\numberline {17.3}Step 3: PyTorch Data Loading}{270}{section.17.3}%
\contentsline {subsection}{\numberline {17.3.1}Lightning Dataset and DataModule}{270}{subsection.17.3.1}%
\contentsline {section}{\numberline {17.4}Step 4: Preprocessing}{270}{section.17.4}%
\contentsline {section}{\numberline {17.5}Step 5: Select the NN Model (\texttt {algorithm}) and \texttt {core\_model\_hyper\_dict}}{270}{section.17.5}%
\contentsline {section}{\numberline {17.6}Step 6: Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{271}{section.17.6}%
\contentsline {section}{\numberline {17.7}Step 7: Data Splitting, the Objective (Loss) Function and the Metric}{272}{section.17.7}%
\contentsline {subsection}{\numberline {17.7.1}Evaluation}{272}{subsection.17.7.1}%
\contentsline {subsection}{\numberline {17.7.2}Loss Functions and Metrics}{272}{subsection.17.7.2}%
\contentsline {subsection}{\numberline {17.7.3}Metric}{273}{subsection.17.7.3}%
\contentsline {section}{\numberline {17.8}Step 8: Calling the SPOT Function}{273}{section.17.8}%
\contentsline {subsection}{\numberline {17.8.1}Preparing the SPOT Call}{273}{subsection.17.8.1}%
\contentsline {subsection}{\numberline {17.8.2}The Objective Function \texttt {fun}}{273}{subsection.17.8.2}%
\contentsline {subsection}{\numberline {17.8.3}Starting the Hyperparameter Tuning}{274}{subsection.17.8.3}%
\contentsline {section}{\numberline {17.9}Step 9: Tensorboard}{276}{section.17.9}%
\contentsline {section}{\numberline {17.10}Step 10: Results}{276}{section.17.10}%
\contentsline {subsection}{\numberline {17.10.1}Get the Tuned Architecture}{278}{subsection.17.10.1}%
\contentsline {subsection}{\numberline {17.10.2}Cross Validation With Lightning}{278}{subsection.17.10.2}%
\contentsline {subsection}{\numberline {17.10.3}Detailed Hyperparameter Plots}{282}{subsection.17.10.3}%
\contentsline {subsection}{\numberline {17.10.4}Parallel Coordinates Plot}{283}{subsection.17.10.4}%
\contentsline {subsection}{\numberline {17.10.5}Plot all Combinations of Hyperparameters}{283}{subsection.17.10.5}%
\contentsline {subsection}{\numberline {17.10.6}Visualizing the Activation Distribution}{284}{subsection.17.10.6}%
\contentsline {section}{\numberline {17.11}Submission}{285}{section.17.11}%
\contentsline {section}{\numberline {17.12}Appendix}{287}{section.17.12}%
\contentsline {subsection}{\numberline {17.12.1}Differences to the spotpython Approaches for \texttt {torch}, \texttt {sklearn} and \texttt {river}}{287}{subsection.17.12.1}%
\contentsline {subsubsection}{\numberline {17.12.1.1}Specification of the Preprocessing Model}{287}{subsubsection.17.12.1.1}%
\contentsline {subsection}{\numberline {17.12.2}Taking a Look at the Data}{288}{subsection.17.12.2}%
\contentsline {subsection}{\numberline {17.12.3}The MAPK Metric}{289}{subsection.17.12.3}%
\contentsline {part}{Appendices}{290}{section*.170}%
\contentsline {chapter}{\numberline {A}Documentation of the Sequential Parameter Optimization}{290}{appendix.A}%
\contentsline {section}{\numberline {A.1}Example: spot}{290}{section.A.1}%
\contentsline {subsection}{\numberline {A.1.1}The Objective Function}{290}{subsection.A.1.1}%
\contentsline {subsection}{\numberline {A.1.2}External Parameters}{291}{subsection.A.1.2}%
\contentsline {section}{\numberline {A.2}The \texttt {fun\_control} Dictionary}{295}{section.A.2}%
\contentsline {section}{\numberline {A.3}The \texttt {design\_control} Dictionary}{295}{section.A.3}%
\contentsline {section}{\numberline {A.4}The \texttt {surrogate\_control} Dictionary}{296}{section.A.4}%
\contentsline {section}{\numberline {A.5}The \texttt {optimizer\_control} Dictionary}{296}{section.A.5}%
\contentsline {section}{\numberline {A.6}Run}{297}{section.A.6}%
\contentsline {section}{\numberline {A.7}Print the Results}{297}{section.A.7}%
\contentsline {section}{\numberline {A.8}Show the Progress}{298}{section.A.8}%
\contentsline {section}{\numberline {A.9}Visualize the Surrogate}{298}{section.A.9}%
\contentsline {section}{\numberline {A.10}Init: Build Initial Design}{298}{section.A.10}%
\contentsline {section}{\numberline {A.11}Replicability}{299}{section.A.11}%
\contentsline {section}{\numberline {A.12}Surrogates}{300}{section.A.12}%
\contentsline {subsection}{\numberline {A.12.1}A Simple Predictor}{300}{subsection.A.12.1}%
\contentsline {section}{\numberline {A.13}Demo/Test: Objective Function Fails}{300}{section.A.13}%
\contentsline {section}{\numberline {A.14}PyTorch: Detailed Description of the Data Splitting}{303}{section.A.14}%
\contentsline {subsection}{\numberline {A.14.1}Description of the \texttt {"train\_hold\_out"} Setting}{303}{subsection.A.14.1}%
\contentsline {subsubsection}{\numberline {A.14.1.1}Description of the \texttt {"test\_hold\_out"} Setting}{306}{subsubsection.A.14.1.1}%
\contentsline {subsubsection}{\numberline {A.14.1.2}Detailed Description of the \texttt {"train\_cv"} Setting}{307}{subsubsection.A.14.1.2}%
\contentsline {subsubsection}{\numberline {A.14.1.3}Detailed Description of the \texttt {"test\_cv"} Setting}{311}{subsubsection.A.14.1.3}%
\contentsline {subsubsection}{\numberline {A.14.1.4}Detailed Description of the Final Model Training and Evaluation}{311}{subsubsection.A.14.1.4}%
\contentsline {chapter}{References}{314}{chapter*.177}%
\providecommand \tocbasic@end@toc@file {}\tocbasic@end@toc@file 
