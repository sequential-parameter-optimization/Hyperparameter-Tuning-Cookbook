digraph {
	graph [size="12.15,12.15"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	14962525680 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	14859803648 [label=AddmmBackward0]
	14812904080 -> 14859803648
	6216863968 [label="layers.12.bias
 (1)" fillcolor=lightblue]
	6216863968 -> 14812904080
	14812904080 [label=AccumulateGrad]
	6216515344 -> 14859803648
	6216515344 [label=MulBackward0]
	14841508912 -> 6216515344
	14841508912 [label=ReluBackward0]
	6216202896 -> 14841508912
	6216202896 [label=AddmmBackward0]
	14962407600 -> 6216202896
	6216863248 [label="layers.9.bias
 (5)" fillcolor=lightblue]
	6216863248 -> 14962407600
	14962407600 [label=AccumulateGrad]
	14962399008 -> 6216202896
	14962399008 [label=MulBackward0]
	14962408224 -> 14962399008
	14962408224 [label=ReluBackward0]
	14962408368 -> 14962408224
	14962408368 [label=AddmmBackward0]
	14962408464 -> 14962408368
	6216863728 [label="layers.6.bias
 (10)" fillcolor=lightblue]
	6216863728 -> 14962408464
	14962408464 [label=AccumulateGrad]
	14962408416 -> 14962408368
	14962408416 [label=MulBackward0]
	14962408608 -> 14962408416
	14962408608 [label=ReluBackward0]
	14962408752 -> 14962408608
	14962408752 [label=AddmmBackward0]
	14962408848 -> 14962408752
	6216863568 [label="layers.3.bias
 (10)" fillcolor=lightblue]
	6216863568 -> 14962408848
	14962408848 [label=AccumulateGrad]
	14962408800 -> 14962408752
	14962408800 [label=MulBackward0]
	14962408992 -> 14962408800
	14962408992 [label=ReluBackward0]
	14962409136 -> 14962408992
	14962409136 [label=AddmmBackward0]
	14962409232 -> 14962409136
	6216863328 [label="layers.0.bias
 (20)" fillcolor=lightblue]
	6216863328 -> 14962409232
	14962409232 [label=AccumulateGrad]
	14962409184 -> 14962409136
	14962524960 [label="
 (1, 10)" fillcolor=lightblue]
	14962524960 -> 14962409184
	14962409184 [label=AccumulateGrad]
	14962409040 -> 14962409136
	14962409040 [label=TBackward0]
	14962409424 -> 14962409040
	6216640592 [label="layers.0.weight
 (20, 10)" fillcolor=lightblue]
	6216640592 -> 14962409424
	14962409424 [label=AccumulateGrad]
	14962408656 -> 14962408752
	14962408656 [label=TBackward0]
	14962409280 -> 14962408656
	6216863488 [label="layers.3.weight
 (10, 20)" fillcolor=lightblue]
	6216863488 -> 14962409280
	14962409280 [label=AccumulateGrad]
	14962408272 -> 14962408368
	14962408272 [label=TBackward0]
	14962408896 -> 14962408272
	6216863408 [label="layers.6.weight
 (10, 10)" fillcolor=lightblue]
	6216863408 -> 14962408896
	14962408896 [label=AccumulateGrad]
	14962407648 -> 6216202896
	14962407648 [label=TBackward0]
	14962408512 -> 14962407648
	6216863808 [label="layers.9.weight
 (5, 10)" fillcolor=lightblue]
	6216863808 -> 14962408512
	14962408512 [label=AccumulateGrad]
	6216510544 -> 14859803648
	6216510544 [label=TBackward0]
	6216195264 -> 6216510544
	6216863888 [label="layers.12.weight
 (1, 5)" fillcolor=lightblue]
	6216863888 -> 6216195264
	6216195264 [label=AccumulateGrad]
	14859803648 -> 14962525680
}
