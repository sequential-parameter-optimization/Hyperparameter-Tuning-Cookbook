digraph {
	graph [size="12.15,12.15"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	15232469984 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	5108590928 [label=AddmmBackward0]
	15228857664 -> 5108590928
	5132283136 [label="layers.12.bias
 (1)" fillcolor=lightblue]
	5132283136 -> 15228857664
	15228857664 [label=AccumulateGrad]
	5108535200 -> 5108590928
	5108535200 [label=MulBackward0]
	14878676528 -> 5108535200
	14878676528 [label=ReluBackward0]
	15232156288 -> 14878676528
	15232156288 [label=AddmmBackward0]
	15232322432 -> 15232156288
	5132282896 [label="layers.9.bias
 (5)" fillcolor=lightblue]
	5132282896 -> 15232322432
	15232322432 [label=AccumulateGrad]
	15232334816 -> 15232156288
	15232334816 [label=MulBackward0]
	15232335152 -> 15232334816
	15232335152 [label=ReluBackward0]
	15232335296 -> 15232335152
	15232335296 [label=AddmmBackward0]
	15232335392 -> 15232335296
	5132436816 [label="layers.6.bias
 (10)" fillcolor=lightblue]
	5132436816 -> 15232335392
	15232335392 [label=AccumulateGrad]
	15232335344 -> 15232335296
	15232335344 [label=MulBackward0]
	15232335536 -> 15232335344
	15232335536 [label=ReluBackward0]
	15232335680 -> 15232335536
	15232335680 [label=AddmmBackward0]
	15232335776 -> 15232335680
	5132436656 [label="layers.3.bias
 (10)" fillcolor=lightblue]
	5132436656 -> 15232335776
	15232335776 [label=AccumulateGrad]
	15232335728 -> 15232335680
	15232335728 [label=MulBackward0]
	15232598128 -> 15232335728
	15232598128 [label=ReluBackward0]
	15232598272 -> 15232598128
	15232598272 [label=AddmmBackward0]
	15232598368 -> 15232598272
	5132436336 [label="layers.0.bias
 (20)" fillcolor=lightblue]
	5132436336 -> 15232598368
	15232598368 [label=AccumulateGrad]
	15232598320 -> 15232598272
	15232469264 [label="
 (1, 10)" fillcolor=lightblue]
	15232469264 -> 15232598320
	15232598320 [label=AccumulateGrad]
	15232598176 -> 15232598272
	15232598176 [label=TBackward0]
	15232598560 -> 15232598176
	5132436176 [label="layers.0.weight
 (20, 10)" fillcolor=lightblue]
	5132436176 -> 15232598560
	15232598560 [label=AccumulateGrad]
	15232335584 -> 15232335680
	15232335584 [label=TBackward0]
	15223991520 -> 15232335584
	5132436576 [label="layers.3.weight
 (10, 20)" fillcolor=lightblue]
	5132436576 -> 15223991520
	15223991520 [label=AccumulateGrad]
	15232335200 -> 15232335296
	15232335200 [label=TBackward0]
	15232335824 -> 15232335200
	5132436496 [label="layers.6.weight
 (10, 10)" fillcolor=lightblue]
	5132436496 -> 15232335824
	15232335824 [label=AccumulateGrad]
	15232334912 -> 15232156288
	15232334912 [label=TBackward0]
	15232335440 -> 15232334912
	5132282976 [label="layers.9.weight
 (5, 10)" fillcolor=lightblue]
	5132282976 -> 15232335440
	15232335440 [label=AccumulateGrad]
	5108545808 -> 5108590928
	5108545808 [label=TBackward0]
	14866572256 -> 5108545808
	5132279296 [label="layers.12.weight
 (1, 5)" fillcolor=lightblue]
	5132279296 -> 14866572256
	14866572256 [label=AccumulateGrad]
	5108590928 -> 15232469984
}
