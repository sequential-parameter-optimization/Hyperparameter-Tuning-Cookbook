{
 "cells": [
  {
   "cell_type": "raw",
   "id": "05d6fdb6",
   "metadata": {},
   "source": [
    "---\n",
    "execute:\n",
    "  cache: false\n",
    "  eval: true\n",
    "  echo: true\n",
    "  warning: false\n",
    "title: 'HPT PyTorch Lightning: Diabetes Using a Recurrent Neural Network'\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06062bdb",
   "metadata": {},
   "source": [
    "In this tutorial, we will show how `spotPython` can be integrated into the `PyTorch` Lightning\n",
    "training workflow for a regression task.\n",
    "\n",
    "This chapter describes the hyperparameter tuning of a `PyTorch Lightning` network on the Diabetes data set. This is a PyTorch Dataset for regression. A toy data set from scikit-learn. Ten baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements were obtained for each of n = 442 diabetes patients,  as well as the response of interest, a quantitative measure of disease progression one year after baseline.\n",
    "\n",
    "\n",
    "## Step 1: Setup {#sec-setup-32}\n",
    "\n",
    "* Before we consider the detailed experimental setup, we select the parameters that affect run time, initial design size, etc. \n",
    "* The parameter `MAX_TIME` specifies the maximum run time in seconds.\n",
    "* The parameter `INIT_SIZE` specifies the initial design size.\n",
    "* The parameter `WORKERS` specifies the number of workers. \n",
    "* The prefix `PREFIX` is used for the experiment name and the name of the log file.\n",
    "* The parameter `DEVICE` specifies the device to use for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd14a216",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotPython.utils.device import getDevice\n",
    "from math import inf\n",
    "MAX_TIME = 1\n",
    "FUN_EVALS = inf\n",
    "INIT_SIZE = 5\n",
    "WORKERS = 0\n",
    "PREFIX=\"032\"\n",
    "DEVICE = getDevice()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238fac5d",
   "metadata": {},
   "source": [
    "::: {.callout-caution}\n",
    "### Caution: Run time and initial design size should be increased for real experiments\n",
    "\n",
    "* `MAX_TIME` is set to one minute for demonstration purposes. For real experiments, this should be increased to at least 1 hour.\n",
    "* `FUN_EVALS` is set to infinity.\n",
    "* `INIT_SIZE` is set to 5 for demonstration purposes. For real experiments, this should be increased to at least 10.\n",
    "* `WORKERS` is set to 0 for demonstration purposes. For real experiments, this should be increased. See the warnings that are printed when the number of workers is set to 0.\n",
    "* `PREFIX` is set to \"032\". This is used for the experiment name and the name of the log file.\n",
    "* `DEVICE` is set to the device that is returned by `getDevice()`, e.g., `gpu`.\n",
    ":::\n",
    "\n",
    "::: {.callout-note}\n",
    "### Note: Device selection\n",
    "\n",
    "* Although there are no .cuda() or .to(device) calls required, because Lightning does these for you, see \n",
    "[LIGHTNINGMODULE](https://lightning.ai/docs/pytorch/stable/common/lightning_module.html), we would like to know which device is used. Threrefore, we imitate the LightningModule behaviour which selects the highest device. \n",
    "* The method `spotPython.utils.device.getDevice()` returns the device that is used by Lightning.\n",
    ":::\n",
    "\n",
    "\n",
    "## Step 2: Initialization of the `fun_control` Dictionary\n",
    "\n",
    "`spotPython` uses a Python dictionary for storing the information required for the hyperparameter tuning process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7af111fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning:\n",
      "\n",
      "Failed to load image Python extension: 'dlopen(/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <F6236B89-E4CA-3330-B665-E463D537EAF3> /Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <E854E4B4-D8A9-321E-9852-69F8F3B956BB> /Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving TENSORBOARD_PATH: runs/ to TENSORBOARD_PATH_OLD: runs_OLD/runs_2024_02_27_03_07_50\n",
      "Created spot_tensorboard_path: runs/spot_logs/032_p040025_2024-02-27_03-07-50 for SummaryWriter()\n"
     ]
    }
   ],
   "source": [
    "from spotPython.utils.init import fun_control_init\n",
    "import numpy as np\n",
    "\n",
    "fun_control = fun_control_init(\n",
    "    _L_in=10,\n",
    "    _L_out=1,\n",
    "    PREFIX=PREFIX,\n",
    "    TENSORBOARD_CLEAN=True,\n",
    "    device=DEVICE,\n",
    "    enable_progress_bar=False,\n",
    "    fun_evals=FUN_EVALS,\n",
    "    log_level=10,\n",
    "    max_time=MAX_TIME,\n",
    "    num_workers=WORKERS,\n",
    "    show_progress=True,\n",
    "    test_size=0.1,\n",
    "    tolerance_x=np.sqrt(np.spacing(1)),\n",
    "    verbosity=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df93c22d",
   "metadata": {},
   "source": [
    "## Step 3: Loading the Diabetes Data Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a1ed92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442\n"
     ]
    }
   ],
   "source": [
    "from spotPython.hyperparameters.values import set_control_key_value\n",
    "from spotPython.data.diabetes import Diabetes\n",
    "dataset = Diabetes()\n",
    "set_control_key_value(control_dict=fun_control,\n",
    "                        key=\"data_set\",\n",
    "                        value=dataset,\n",
    "                        replace=True)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d28bd2",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "### Note: Data Set and Data Loader\n",
    "\n",
    "* As shown below, a DataLoader from `torch.utils.data` can be used to check the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5ae78d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size: 5\n",
      "Inputs Shape: torch.Size([5, 10])\n",
      "Targets Shape: torch.Size([5])\n",
      "---------------\n",
      "Inputs: tensor([[ 0.0381,  0.0507,  0.0617,  0.0219, -0.0442, -0.0348, -0.0434, -0.0026,\n",
      "          0.0199, -0.0176],\n",
      "        [-0.0019, -0.0446, -0.0515, -0.0263, -0.0084, -0.0192,  0.0744, -0.0395,\n",
      "         -0.0683, -0.0922],\n",
      "        [ 0.0853,  0.0507,  0.0445, -0.0057, -0.0456, -0.0342, -0.0324, -0.0026,\n",
      "          0.0029, -0.0259],\n",
      "        [-0.0891, -0.0446, -0.0116, -0.0367,  0.0122,  0.0250, -0.0360,  0.0343,\n",
      "          0.0227, -0.0094],\n",
      "        [ 0.0054, -0.0446, -0.0364,  0.0219,  0.0039,  0.0156,  0.0081, -0.0026,\n",
      "         -0.0320, -0.0466]])\n",
      "Targets: tensor([151.,  75., 141., 206., 135.])\n"
     ]
    }
   ],
   "source": [
    "# Set batch size for DataLoader\n",
    "batch_size = 5\n",
    "# Create DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Iterate over the data in the DataLoader\n",
    "for batch in dataloader:\n",
    "    inputs, targets = batch\n",
    "    print(f\"Batch Size: {inputs.size(0)}\")\n",
    "    print(f\"Inputs Shape: {inputs.shape}\")\n",
    "    print(f\"Targets Shape: {targets.shape}\")\n",
    "    print(\"---------------\")\n",
    "    print(f\"Inputs: {inputs}\")\n",
    "    print(f\"Targets: {targets}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cccd859",
   "metadata": {},
   "source": [
    ":::\n",
    "## Step 4: Preprocessing {#sec-preprocessing-32}\n",
    "\n",
    "Preprocessing is handled by `Lightning` and `PyTorch`. It is described in the [LIGHTNINGDATAMODULE](https://lightning.ai/docs/pytorch/stable/data/datamodule.html) documentation. Here you can find information about the `transforms` methods.\n",
    "\n",
    "## Step 5: Select the Core Model (`algorithm`) and `core_model_hyper_dict` {#sec-selection-of-the-algorithm-32}\n",
    "\n",
    "`spotPython` includes the `NetLightRegression` class [[SOURCE]](https://github.com/sequential-parameter-optimization/spotPython/blob/main/src/spotPython/light/netlightregression.py) for configurable neural networks. \n",
    "The class is imported here. It inherits from the class `Lightning.LightningModule`, which is the base class for all models in `Lightning`. `Lightning.LightningModule` is a subclass of `torch.nn.Module` and provides additional functionality for the training and testing of neural networks. The class `Lightning.LightningModule` is described in the [Lightning documentation](https://lightning.ai/docs/pytorch/stable/common/lightning_module.html).\n",
    "\n",
    "* Here we simply add the NN Model to the fun_control dictionary by calling the function `add_core_model_to_fun_control`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19ab32cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotPython.light.regression.rnnlightregression import RNNLightRegression\n",
    "from spotPython.hyperdict.light_hyper_dict import LightHyperDict\n",
    "from spotPython.hyperparameters.values import add_core_model_to_fun_control\n",
    "add_core_model_to_fun_control(fun_control=fun_control,\n",
    "                              core_model=RNNLightRegression,\n",
    "                              hyper_dict=LightHyperDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4f8c0d",
   "metadata": {},
   "source": [
    "The hyperparameters of the model are specified in the `core_model_hyper_dict` dictionary [[SOURCE]](https://github.com/sequential-parameter-optimization/spotPython/blob/main/src/spotPython/hyperdict/light_hyper_dict.json).\n",
    "\n",
    "\n",
    "::: {.callout-note}\n",
    "#### Note: User specified models and hyperparameter dictionaries\n",
    "\n",
    "* The user can specify a model and a hyperparameter dictionary in a subfolder, e.g., `userRNN` in the current working directory.\n",
    "* The model and the hyperparameter dictionary are imported with the following code:\n",
    "\n",
    "\n",
    "\n",
    "```{raw}\n",
    "from spotPython.hyperparameters.values import add_core_model_to_fun_control\n",
    "import sys\n",
    "sys.path.insert(0, './userRNN')\n",
    "import userrnn\n",
    "import user_hyper_dict\n",
    "add_core_model_to_fun_control(fun_control=fun_control,\n",
    "                              core_model=userrnn.RNNLightRegression,\n",
    "                              hyper_dict=user_hyper_dict.UserHyperDict)\n",
    "```\n",
    "\n",
    "\n",
    "* Example files can be found in the [userRNN](https://github.com/sequential-parameter-optimization/Hyperparameter-Tuning-Cookbook/tree/main/userRNN) folder.\n",
    "* These files can be modified by the user.\n",
    "* They can be used without re-compilation of the `spotPython` source code, if they are located in a subfolder of the current working directory.\n",
    "\n",
    ":::\n",
    "\n",
    "\n",
    "## Step 6: Modify `hyper_dict` Hyperparameters for the Selected Algorithm aka `core_model` {#sec-modification-of-hyperparameters-32}\n",
    "\n",
    " `spotPython` provides functions for modifying the hyperparameters, their bounds and factors as well as for activating and de-activating hyperparameters without re-compilation of the Python source code. \n",
    "\n",
    "::: {.callout-caution}\n",
    "### Caution: Small number of epochs for demonstration purposes\n",
    "\n",
    "* `epochs` and `patience` are set to small values for demonstration purposes. These values are too small for a real application.\n",
    "* More resonable values are, e.g.:\n",
    "  * `set_control_hyperparameter_value(fun_control, \"epochs\", [7, 9])` and\n",
    "  * `set_control_hyperparameter_value(fun_control, \"patience\", [2, 7])`\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0726c133",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotPython.hyperparameters.values import set_control_hyperparameter_value\n",
    "\n",
    "set_control_hyperparameter_value(fun_control, \"l1\", [3, 8])\n",
    "set_control_hyperparameter_value(fun_control, \"epochs\", [7, 9])\n",
    "set_control_hyperparameter_value(fun_control, \"batch_size\", [2, 6])\n",
    "set_control_hyperparameter_value(fun_control, \"optimizer\", [\n",
    "                \"Adadelta\",\n",
    "                \"Adagrad\",\n",
    "                \"Adam\",\n",
    "                \"Adamax\"])\n",
    "set_control_hyperparameter_value(fun_control, \"dropout_prob\", [0.01, 0.25])\n",
    "set_control_hyperparameter_value(fun_control, \"lr_mult\", [0.5, 5.0])\n",
    "set_control_hyperparameter_value(fun_control, \"patience\", [3, 9])\n",
    "set_control_hyperparameter_value(fun_control, \"act_fn\",[\"ReLU\"] )\n",
    "set_control_hyperparameter_value(fun_control, \"initialization\",[\"Default\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710b68a7",
   "metadata": {},
   "source": [
    "Now, the dictionary `fun_control` contains all information needed for the hyperparameter tuning. Before the hyperparameter tuning is started, it is recommended to take a look at the experimental design. The method `gen_design_table` [[SOURCE]](https://github.com/sequential-parameter-optimization/spotPython/blob/main/src/spotPython/utils/eda.py) generates a design table as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97df1d63",
   "metadata": {
    "fig-label": "tbl-design-32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| name           | type   | default   |   lower |   upper | transform             |\n",
      "|----------------|--------|-----------|---------|---------|-----------------------|\n",
      "| l1             | int    | 3         |    3    |    8    | transform_power_2_int |\n",
      "| epochs         | int    | 4         |    7    |    9    | transform_power_2_int |\n",
      "| batch_size     | int    | 4         |    2    |    6    | transform_power_2_int |\n",
      "| act_fn         | factor | ReLU      |    0    |    0    | None                  |\n",
      "| optimizer      | factor | SGD       |    0    |    3    | None                  |\n",
      "| dropout_prob   | float  | 0.01      |    0.01 |    0.25 | None                  |\n",
      "| lr_mult        | float  | 1.0       |    0.5  |    5    | None                  |\n",
      "| patience       | int    | 2         |    3    |    9    | transform_power_2_int |\n",
      "| initialization | factor | Default   |    0    |    0    | None                  |\n"
     ]
    }
   ],
   "source": [
    "#| fig-cap: Experimental design for the hyperparameter tuning.\n",
    "from spotPython.utils.eda import gen_design_table\n",
    "print(gen_design_table(fun_control))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ea90a1",
   "metadata": {},
   "source": [
    "This allows to check if all information is available and if the information is correct.\n",
    "\n",
    "::: {.callout-note}\n",
    "### Note: Hyperparameters of the Tuned Model and the `fun_control` Dictionary\n",
    "The updated `fun_control` dictionary can be shown with the command `fun_control[\"core_model_hyper_dict\"]`.\n",
    ":::\n",
    "\n",
    "\n",
    "## Step 7: Data Splitting, the Objective (Loss) Function and the Metric\n",
    "\n",
    "### Evaluation  {#sec-selection-of-target-function-32}\n",
    "\n",
    "The evaluation procedure requires the specification of two elements:\n",
    "\n",
    "1. the way how the data is split into a train and a test set\n",
    "2. the loss function (and a metric).\n",
    "\n",
    "::: {.callout-caution}\n",
    "### Caution: Data Splitting in Lightning\n",
    "\n",
    "The data splitting is handled by `Lightning`.\n",
    "\n",
    ":::\n",
    "\n",
    "### Loss Function {#sec-loss-function-32}\n",
    "\n",
    "The loss function is specified in the configurable network class [[SOURCE]](https://github.com/sequential-parameter-optimization/spotPython/blob/main/src/spotPython/light/regression/netlightregression.py)\n",
    "We will use MSE.\n",
    "\n",
    "### Metric {#sec-metric-32}\n",
    "\n",
    "* Similar to the loss function, the metric is specified in the configurable network class [[SOURCE]](https://github.com/sequential-parameter-optimization/spotPython/blob/main/src/spotPython/light/regression/netlightregression.py).\n",
    "\n",
    "::: {.callout-caution}\n",
    "### Caution: Loss Function and Metric in Lightning\n",
    "\n",
    "* The loss function and the metric are not hyperparameters that can be tuned with `spotPython`.\n",
    "* They are handled by `Lightning`.\n",
    "\n",
    ":::\n",
    "\n",
    "\n",
    "## Step 8: Calling the SPOT Function\n",
    "\n",
    "### Preparing the SPOT Call {#sec-prepare-spot-call-32}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1148cfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotPython.utils.init import design_control_init, surrogate_control_init\n",
    "design_control = design_control_init()\n",
    "set_control_key_value(control_dict=design_control,\n",
    "                        key=\"init_size\",\n",
    "                        value=INIT_SIZE,\n",
    "                        replace=True)\n",
    "\n",
    "surrogate_control = surrogate_control_init()\n",
    "set_control_key_value(control_dict=surrogate_control,\n",
    "                        key=\"noise\",\n",
    "                        value=True,\n",
    "                        replace=True)                       \n",
    "set_control_key_value(control_dict=surrogate_control,\n",
    "                        key=\"n_theta\",\n",
    "                        value=2,\n",
    "                        replace=True)      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f08162",
   "metadata": {},
   "source": [
    "### The Objective Function `fun` {#sec-the-objective-function-32}\n",
    "\n",
    "The objective function `fun` from the class `HyperLight` [[SOURCE]](https://github.com/sequential-parameter-optimization/spotPython/blob/main/src/spotPython/fun/hyperlight.py) is selected next. It implements an interface from `PyTorch`'s training, validation, and testing methods to `spotPython`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2882444",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotPython.fun.hyperlight import HyperLight\n",
    "fun = HyperLight(log_level=10).fun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6293141f",
   "metadata": {},
   "source": [
    "### Showing the fun_control Dictionary {#sec-show-fun-control-32}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49f42e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CHECKPOINT_PATH': 'runs/saved_models/',\n",
      " 'DATASET_PATH': 'data/',\n",
      " 'PREFIX': '032',\n",
      " 'RESULTS_PATH': 'results/',\n",
      " 'TENSORBOARD_PATH': 'runs/',\n",
      " '_L_in': 10,\n",
      " '_L_out': 1,\n",
      " 'accelerator': 'auto',\n",
      " 'converters': None,\n",
      " 'core_model': <class 'spotPython.light.regression.rnnlightregression.RNNLightRegression'>,\n",
      " 'core_model_hyper_dict': {'act_fn': {'class_name': 'spotPython.torch.activation',\n",
      "                                      'core_model_parameter_type': 'instance()',\n",
      "                                      'default': 'ReLU',\n",
      "                                      'levels': ['ReLU'],\n",
      "                                      'lower': 0,\n",
      "                                      'transform': 'None',\n",
      "                                      'type': 'factor',\n",
      "                                      'upper': 0},\n",
      "                           'batch_size': {'default': 4,\n",
      "                                          'lower': 2,\n",
      "                                          'transform': 'transform_power_2_int',\n",
      "                                          'type': 'int',\n",
      "                                          'upper': 6},\n",
      "                           'dropout_prob': {'default': 0.01,\n",
      "                                            'lower': 0.01,\n",
      "                                            'transform': 'None',\n",
      "                                            'type': 'float',\n",
      "                                            'upper': 0.25},\n",
      "                           'epochs': {'default': 4,\n",
      "                                      'lower': 7,\n",
      "                                      'transform': 'transform_power_2_int',\n",
      "                                      'type': 'int',\n",
      "                                      'upper': 9},\n",
      "                           'initialization': {'core_model_parameter_type': 'str',\n",
      "                                              'default': 'Default',\n",
      "                                              'levels': ['Default'],\n",
      "                                              'lower': 0,\n",
      "                                              'transform': 'None',\n",
      "                                              'type': 'factor',\n",
      "                                              'upper': 0},\n",
      "                           'l1': {'default': 3,\n",
      "                                  'lower': 3,\n",
      "                                  'transform': 'transform_power_2_int',\n",
      "                                  'type': 'int',\n",
      "                                  'upper': 8},\n",
      "                           'lr_mult': {'default': 1.0,\n",
      "                                       'lower': 0.5,\n",
      "                                       'transform': 'None',\n",
      "                                       'type': 'float',\n",
      "                                       'upper': 5.0},\n",
      "                           'optimizer': {'class_name': 'torch.optim',\n",
      "                                         'core_model_parameter_type': 'str',\n",
      "                                         'default': 'SGD',\n",
      "                                         'levels': ['Adadelta',\n",
      "                                                    'Adagrad',\n",
      "                                                    'Adam',\n",
      "                                                    'Adamax'],\n",
      "                                         'lower': 0,\n",
      "                                         'transform': 'None',\n",
      "                                         'type': 'factor',\n",
      "                                         'upper': 3},\n",
      "                           'patience': {'default': 2,\n",
      "                                        'lower': 3,\n",
      "                                        'transform': 'transform_power_2_int',\n",
      "                                        'type': 'int',\n",
      "                                        'upper': 9}},\n",
      " 'counter': 0,\n",
      " 'data': None,\n",
      " 'data_dir': './data',\n",
      " 'data_module': None,\n",
      " 'data_set': <spotPython.data.diabetes.Diabetes object at 0x2cd4563d0>,\n",
      " 'design': None,\n",
      " 'device': 'mps',\n",
      " 'devices': 1,\n",
      " 'enable_progress_bar': False,\n",
      " 'eval': None,\n",
      " 'fun_evals': inf,\n",
      " 'fun_repeats': 1,\n",
      " 'horizon': None,\n",
      " 'infill_criterion': 'y',\n",
      " 'k_folds': 3,\n",
      " 'log_graph': False,\n",
      " 'log_level': 10,\n",
      " 'loss_function': None,\n",
      " 'lower': array([3. , 4. , 1. , 0. , 0. , 0. , 0.1, 2. , 0. ]),\n",
      " 'max_time': 1,\n",
      " 'metric_params': {},\n",
      " 'metric_river': None,\n",
      " 'metric_sklearn': None,\n",
      " 'metric_torch': None,\n",
      " 'model_dict': {},\n",
      " 'n_points': 1,\n",
      " 'n_samples': None,\n",
      " 'noise': False,\n",
      " 'num_workers': 0,\n",
      " 'ocba_delta': 0,\n",
      " 'oml_grace_period': None,\n",
      " 'optimizer': None,\n",
      " 'path': None,\n",
      " 'prep_model': None,\n",
      " 'save_model': False,\n",
      " 'seed': 123,\n",
      " 'show_batch_interval': 1000000,\n",
      " 'show_models': False,\n",
      " 'show_progress': True,\n",
      " 'shuffle': None,\n",
      " 'sigma': 0.0,\n",
      " 'spot_tensorboard_path': 'runs/spot_logs/032_p040025_2024-02-27_03-07-50',\n",
      " 'spot_writer': <torch.utils.tensorboard.writer.SummaryWriter object at 0x2c24a6710>,\n",
      " 'target_column': None,\n",
      " 'task': None,\n",
      " 'test': None,\n",
      " 'test_seed': 1234,\n",
      " 'test_size': 0.1,\n",
      " 'tolerance_x': 1.4901161193847656e-08,\n",
      " 'train': None,\n",
      " 'upper': array([ 8.  ,  9.  ,  4.  ,  1.  , 11.  ,  0.25, 10.  ,  6.  ,  2.  ]),\n",
      " 'var_name': ['l1',\n",
      "              'epochs',\n",
      "              'batch_size',\n",
      "              'act_fn',\n",
      "              'optimizer',\n",
      "              'dropout_prob',\n",
      "              'lr_mult',\n",
      "              'patience',\n",
      "              'initialization'],\n",
      " 'var_type': ['int',\n",
      "              'int',\n",
      "              'int',\n",
      "              'factor',\n",
      "              'factor',\n",
      "              'float',\n",
      "              'float',\n",
      "              'int',\n",
      "              'factor'],\n",
      " 'verbosity': 1,\n",
      " 'weight_coeff': 0.0,\n",
      " 'weights': 1.0}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(fun_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7a49b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'init_size': 5, 'repeats': 1}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(design_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "786d5738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'log_level': 50,\n",
      " 'max_Lambda': 1,\n",
      " 'max_theta': 2.0,\n",
      " 'min_Lambda': 1e-09,\n",
      " 'min_theta': -3.0,\n",
      " 'model_fun_evals': 10000,\n",
      " 'model_optimizer': <function differential_evolution at 0x29957a3e0>,\n",
      " 'n_p': 1,\n",
      " 'n_theta': 2,\n",
      " 'noise': True,\n",
      " 'optim_p': False,\n",
      " 'p_val': 2.0,\n",
      " 'seed': 124,\n",
      " 'theta_init_zero': True,\n",
      " 'var_type': None}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(surrogate_control)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5f9678",
   "metadata": {},
   "source": [
    "### Starting the Hyperparameter Tuning {#sec-call-the-hyperparameter-tuner-32}\n",
    "\n",
    "The `spotPython` hyperparameter tuning is started by calling the `Spot` function [[SOURCE]](https://github.com/sequential-parameter-optimization/spotPython/blob/main/src/spotPython/spot/spot.py).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a10af6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In fun(): config:\n",
      "{'act_fn': ReLU(),\n",
      " 'batch_size': 64,\n",
      " 'dropout_prob': 0.19355651674791854,\n",
      " 'epochs': 256,\n",
      " 'initialization': 'Default',\n",
      " 'l1': 16,\n",
      " 'lr_mult': 1.5691149440098038,\n",
      " 'optimizer': 'Adam',\n",
      " 'patience': 32}\n",
      "LightDataModule: setup(). stage: None\n",
      "LightDataModule setup(): full_train_size: 0.9\n",
      "LightDataModule setup(): val_size: 0.09\n",
      "LightDataModule setup(): train_size: 0.81\n",
      "LightDataModule setup(): test_size: 0.1\n",
      "LightDataModule: setup(). stage: fit\n",
      "LightDataModule: setup(). stage: test\n",
      "LightDataModule: setup(). stage: predict\n",
      "train_model(): Test set size: 45\n",
      "train_model(): Train set size: 359\n",
      "train_model(): Batch size: 64\n",
      "LightDataModule: setup(). stage: TrainerFn.FITTING\n",
      "LightDataModule setup(): full_train_size: 0.9\n",
      "LightDataModule setup(): val_size: 0.09\n",
      "LightDataModule setup(): train_size: 0.81\n",
      "LightDataModule setup(): test_size: 0.1\n",
      "LightDataModule: setup(). stage: fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type    | Params | In sizes | Out sizes          \n",
      "----------------------------------------------------------------------------\n",
      "0 | rnn_layer      | RNN     | 448    | [64, 10] | [[64, 16], [1, 16]]\n",
      "1 | fc             | Linear  | 272    | [64, 16] | [64, 16]           \n",
      "2 | output_layer   | Linear  | 17     | [64, 16] | [64, 1]            \n",
      "3 | dropout1       | Dropout | 0      | [64, 10] | [64, 10]           \n",
      "4 | dropout2       | Dropout | 0      | [64, 16] | [64, 16]           \n",
      "5 | dropout3       | Dropout | 0      | [64, 16] | [64, 16]           \n",
      "6 | activation_fct | ReLU    | 0      | [64, 16] | [64, 16]           \n",
      "----------------------------------------------------------------------------\n",
      "737       Trainable params\n",
      "0         Non-trainable params\n",
      "737       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule: val_dataloader(). Training set size: 39\n",
      "LightDataModule: val_dataloader(). batch_size: 64\n",
      "LightDataModule: val_dataloader(). num_workers: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule: train_dataloader(). Training set size: 359\n",
      "LightDataModule: train_dataloader(). batch_size: 64\n",
      "LightDataModule: train_dataloader(). num_workers: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=256` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule: setup(). stage: TrainerFn.VALIDATING\n",
      "LightDataModule setup(): full_train_size: 0.9\n",
      "LightDataModule setup(): val_size: 0.09\n",
      "LightDataModule setup(): train_size: 0.81\n",
      "LightDataModule setup(): test_size: 0.1\n",
      "LightDataModule: val_dataloader(). Training set size: 39\n",
      "LightDataModule: val_dataloader(). batch_size: 64\n",
      "LightDataModule: val_dataloader(). num_workers: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     5832.97998046875      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     5832.97998046875      </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    5832.97998046875     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    5832.97998046875     \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type    | Params | In sizes  | Out sizes            \n",
      "-------------------------------------------------------------------------------\n",
      "0 | rnn_layer      | RNN     | 17.9 K | [16, 10]  | [[16, 128], [1, 128]]\n",
      "1 | fc             | Linear  | 16.5 K | [16, 128] | [16, 128]            \n",
      "2 | output_layer   | Linear  | 129    | [16, 128] | [16, 1]              \n",
      "3 | dropout1       | Dropout | 0      | [16, 10]  | [16, 10]             \n",
      "4 | dropout2       | Dropout | 0      | [16, 128] | [16, 128]            \n",
      "5 | dropout3       | Dropout | 0      | [16, 128] | [16, 128]            \n",
      "6 | activation_fct | ReLU    | 0      | [16, 128] | [16, 128]            \n",
      "-------------------------------------------------------------------------------\n",
      "34.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "34.6 K    Total params\n",
      "0.138     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (23) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 5832.97998046875, 'hp_metric': 5832.97998046875}\n",
      "\n",
      "In fun(): config:\n",
      "{'act_fn': ReLU(),\n",
      " 'batch_size': 16,\n",
      " 'dropout_prob': 0.09424169914869776,\n",
      " 'epochs': 256,\n",
      " 'initialization': 'Default',\n",
      " 'l1': 128,\n",
      " 'lr_mult': 3.35818256351233,\n",
      " 'optimizer': 'Adadelta',\n",
      " 'patience': 512}\n",
      "LightDataModule: setup(). stage: None\n",
      "LightDataModule setup(): full_train_size: 0.9\n",
      "LightDataModule setup(): val_size: 0.09\n",
      "LightDataModule setup(): train_size: 0.81\n",
      "LightDataModule setup(): test_size: 0.1\n",
      "LightDataModule: setup(). stage: fit\n",
      "LightDataModule: setup(). stage: test\n",
      "LightDataModule: setup(). stage: predict\n",
      "train_model(): Test set size: 45\n",
      "train_model(): Train set size: 359\n",
      "train_model(): Batch size: 16\n",
      "LightDataModule: setup(). stage: TrainerFn.FITTING\n",
      "LightDataModule setup(): full_train_size: 0.9\n",
      "LightDataModule setup(): val_size: 0.09\n",
      "LightDataModule setup(): train_size: 0.81\n",
      "LightDataModule setup(): test_size: 0.1\n",
      "LightDataModule: setup(). stage: fit\n",
      "LightDataModule: val_dataloader(). Training set size: 39\n",
      "LightDataModule: val_dataloader(). batch_size: 16\n",
      "LightDataModule: val_dataloader(). num_workers: 0\n",
      "LightDataModule: train_dataloader(). Training set size: 359\n",
      "LightDataModule: train_dataloader(). batch_size: 16\n",
      "LightDataModule: train_dataloader(). num_workers: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=256` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule: setup(). stage: TrainerFn.VALIDATING\n",
      "LightDataModule setup(): full_train_size: 0.9\n",
      "LightDataModule setup(): val_size: 0.09\n",
      "LightDataModule setup(): train_size: 0.81\n",
      "LightDataModule setup(): test_size: 0.1\n",
      "LightDataModule: val_dataloader(). Training set size: 39\n",
      "LightDataModule: val_dataloader(). batch_size: 16\n",
      "LightDataModule: val_dataloader(). num_workers: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      3765.2763671875      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      3765.2763671875      </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     3765.2763671875     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     3765.2763671875     \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type    | Params | In sizes | Out sizes           \n",
      "-----------------------------------------------------------------------------\n",
      "0 | rnn_layer      | RNN     | 17.9 K | [4, 10]  | [[4, 128], [1, 128]]\n",
      "1 | fc             | Linear  | 16.5 K | [4, 128] | [4, 128]            \n",
      "2 | output_layer   | Linear  | 129    | [4, 128] | [4, 1]              \n",
      "3 | dropout1       | Dropout | 0      | [4, 10]  | [4, 10]             \n",
      "4 | dropout2       | Dropout | 0      | [4, 128] | [4, 128]            \n",
      "5 | dropout3       | Dropout | 0      | [4, 128] | [4, 128]            \n",
      "6 | activation_fct | ReLU    | 0      | [4, 128] | [4, 128]            \n",
      "-----------------------------------------------------------------------------\n",
      "34.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "34.6 K    Total params\n",
      "0.138     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 3765.2763671875, 'hp_metric': 3765.2763671875}\n",
      "\n",
      "In fun(): config:\n",
      "{'act_fn': ReLU(),\n",
      " 'batch_size': 4,\n",
      " 'dropout_prob': 0.21164199382623602,\n",
      " 'epochs': 512,\n",
      " 'initialization': 'Default',\n",
      " 'l1': 128,\n",
      " 'lr_mult': 0.9336514668325573,\n",
      " 'optimizer': 'Adamax',\n",
      " 'patience': 16}\n",
      "LightDataModule: setup(). stage: None\n",
      "LightDataModule setup(): full_train_size: 0.9\n",
      "LightDataModule setup(): val_size: 0.09\n",
      "LightDataModule setup(): train_size: 0.81\n",
      "LightDataModule setup(): test_size: 0.1\n",
      "LightDataModule: setup(). stage: fit\n",
      "LightDataModule: setup(). stage: test\n",
      "LightDataModule: setup(). stage: predict\n",
      "train_model(): Test set size: 45\n",
      "train_model(): Train set size: 359\n",
      "train_model(): Batch size: 4\n",
      "LightDataModule: setup(). stage: TrainerFn.FITTING\n",
      "LightDataModule setup(): full_train_size: 0.9\n",
      "LightDataModule setup(): val_size: 0.09\n",
      "LightDataModule setup(): train_size: 0.81\n",
      "LightDataModule setup(): test_size: 0.1\n",
      "LightDataModule: setup(). stage: fit\n",
      "LightDataModule: val_dataloader(). Training set size: 39\n",
      "LightDataModule: val_dataloader(). batch_size: 4\n",
      "LightDataModule: val_dataloader(). num_workers: 0\n",
      "LightDataModule: train_dataloader(). Training set size: 359\n",
      "LightDataModule: train_dataloader(). batch_size: 4\n",
      "LightDataModule: train_dataloader(). num_workers: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule: setup(). stage: TrainerFn.VALIDATING\n",
      "LightDataModule setup(): full_train_size: 0.9\n",
      "LightDataModule setup(): val_size: 0.09\n",
      "LightDataModule setup(): train_size: 0.81\n",
      "LightDataModule setup(): test_size: 0.1\n",
      "LightDataModule: val_dataloader(). Training set size: 39\n",
      "LightDataModule: val_dataloader(). batch_size: 4\n",
      "LightDataModule: val_dataloader(). num_workers: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     2651.450439453125     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     2651.450439453125     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    2651.450439453125    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    2651.450439453125    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type    | Params | In sizes | Out sizes         \n",
      "---------------------------------------------------------------------------\n",
      "0 | rnn_layer      | RNN     | 4.9 K  | [8, 10]  | [[8, 64], [1, 64]]\n",
      "1 | fc             | Linear  | 4.2 K  | [8, 64]  | [8, 64]           \n",
      "2 | output_layer   | Linear  | 65     | [8, 64]  | [8, 1]            \n",
      "3 | dropout1       | Dropout | 0      | [8, 10]  | [8, 10]           \n",
      "4 | dropout2       | Dropout | 0      | [8, 64]  | [8, 64]           \n",
      "5 | dropout3       | Dropout | 0      | [8, 64]  | [8, 64]           \n",
      "6 | activation_fct | ReLU    | 0      | [8, 64]  | [8, 64]           \n",
      "---------------------------------------------------------------------------\n",
      "9.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "9.1 K     Total params\n",
      "0.036     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 2651.450439453125, 'hp_metric': 2651.450439453125}\n",
      "\n",
      "In fun(): config:\n",
      "{'act_fn': ReLU(),\n",
      " 'batch_size': 8,\n",
      " 'dropout_prob': 0.05728504399550885,\n",
      " 'epochs': 128,\n",
      " 'initialization': 'Default',\n",
      " 'l1': 64,\n",
      " 'lr_mult': 4.575980093998586,\n",
      " 'optimizer': 'Adam',\n",
      " 'patience': 32}\n",
      "LightDataModule: setup(). stage: None\n",
      "LightDataModule setup(): full_train_size: 0.9\n",
      "LightDataModule setup(): val_size: 0.09\n",
      "LightDataModule setup(): train_size: 0.81\n",
      "LightDataModule setup(): test_size: 0.1\n",
      "LightDataModule: setup(). stage: fit\n",
      "LightDataModule: setup(). stage: test\n",
      "LightDataModule: setup(). stage: predict\n",
      "train_model(): Test set size: 45\n",
      "train_model(): Train set size: 359\n",
      "train_model(): Batch size: 8\n",
      "LightDataModule: setup(). stage: TrainerFn.FITTING\n",
      "LightDataModule setup(): full_train_size: 0.9\n",
      "LightDataModule setup(): val_size: 0.09\n",
      "LightDataModule setup(): train_size: 0.81\n",
      "LightDataModule setup(): test_size: 0.1\n",
      "LightDataModule: setup(). stage: fit\n",
      "LightDataModule: val_dataloader(). Training set size: 39\n",
      "LightDataModule: val_dataloader(). batch_size: 8\n",
      "LightDataModule: val_dataloader(). num_workers: 0\n",
      "LightDataModule: train_dataloader(). Training set size: 359\n",
      "LightDataModule: train_dataloader(). batch_size: 8\n",
      "LightDataModule: train_dataloader(). num_workers: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (45) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule: setup(). stage: TrainerFn.VALIDATING\n",
      "LightDataModule setup(): full_train_size: 0.9\n",
      "LightDataModule setup(): val_size: 0.09\n",
      "LightDataModule setup(): train_size: 0.81\n",
      "LightDataModule setup(): test_size: 0.1\n",
      "LightDataModule: val_dataloader(). Training set size: 39\n",
      "LightDataModule: val_dataloader(). batch_size: 8\n",
      "LightDataModule: val_dataloader(). num_workers: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      4523.0830078125      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      4523.0830078125      </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     4523.0830078125     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     4523.0830078125     \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type    | Params | In sizes | Out sizes        \n",
      "--------------------------------------------------------------------------\n",
      "0 | rnn_layer      | RNN     | 160    | [16, 10] | [[16, 8], [1, 8]]\n",
      "1 | fc             | Linear  | 72     | [16, 8]  | [16, 8]          \n",
      "2 | output_layer   | Linear  | 9      | [16, 8]  | [16, 1]          \n",
      "3 | dropout1       | Dropout | 0      | [16, 10] | [16, 10]         \n",
      "4 | dropout2       | Dropout | 0      | [16, 8]  | [16, 8]          \n",
      "5 | dropout3       | Dropout | 0      | [16, 8]  | [16, 8]          \n",
      "6 | activation_fct | ReLU    | 0      | [16, 8]  | [16, 8]          \n",
      "--------------------------------------------------------------------------\n",
      "241       Trainable params\n",
      "0         Non-trainable params\n",
      "241       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 4523.0830078125, 'hp_metric': 4523.0830078125}\n",
      "\n",
      "In fun(): config:\n",
      "{'act_fn': ReLU(),\n",
      " 'batch_size': 16,\n",
      " 'dropout_prob': 0.14352914208400058,\n",
      " 'epochs': 256,\n",
      " 'initialization': 'Default',\n",
      " 'l1': 8,\n",
      " 'lr_mult': 2.4204853123355816,\n",
      " 'optimizer': 'Adagrad',\n",
      " 'patience': 128}\n",
      "LightDataModule: setup(). stage: None\n",
      "LightDataModule setup(): full_train_size: 0.9\n",
      "LightDataModule setup(): val_size: 0.09\n",
      "LightDataModule setup(): train_size: 0.81\n",
      "LightDataModule setup(): test_size: 0.1\n",
      "LightDataModule: setup(). stage: fit\n",
      "LightDataModule: setup(). stage: test\n",
      "LightDataModule: setup(). stage: predict\n",
      "train_model(): Test set size: 45\n",
      "train_model(): Train set size: 359\n",
      "train_model(): Batch size: 16\n",
      "LightDataModule: setup(). stage: TrainerFn.FITTING\n",
      "LightDataModule setup(): full_train_size: 0.9\n",
      "LightDataModule setup(): val_size: 0.09\n",
      "LightDataModule setup(): train_size: 0.81\n",
      "LightDataModule setup(): test_size: 0.1\n",
      "LightDataModule: setup(). stage: fit\n",
      "LightDataModule: val_dataloader(). Training set size: 39\n",
      "LightDataModule: val_dataloader(). batch_size: 16\n",
      "LightDataModule: val_dataloader(). num_workers: 0\n",
      "LightDataModule: train_dataloader(). Training set size: 359\n",
      "LightDataModule: train_dataloader(). batch_size: 16\n",
      "LightDataModule: train_dataloader(). num_workers: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=256` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule: setup(). stage: TrainerFn.VALIDATING\n",
      "LightDataModule setup(): full_train_size: 0.9\n",
      "LightDataModule setup(): val_size: 0.09\n",
      "LightDataModule setup(): train_size: 0.81\n",
      "LightDataModule setup(): test_size: 0.1\n",
      "LightDataModule: val_dataloader(). Training set size: 39\n",
      "LightDataModule: val_dataloader(). batch_size: 16\n",
      "LightDataModule: val_dataloader(). num_workers: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      8449.935546875       </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      8449.935546875       </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     8449.935546875      \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     8449.935546875      \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 8449.935546875, 'hp_metric': 8449.935546875}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type    | Params | In sizes | Out sizes           \n",
      "-----------------------------------------------------------------------------\n",
      "0 | rnn_layer      | RNN     | 17.9 K | [4, 10]  | [[4, 128], [1, 128]]\n",
      "1 | fc             | Linear  | 16.5 K | [4, 128] | [4, 128]            \n",
      "2 | output_layer   | Linear  | 129    | [4, 128] | [4, 1]              \n",
      "3 | dropout1       | Dropout | 0      | [4, 10]  | [4, 10]             \n",
      "4 | dropout2       | Dropout | 0      | [4, 128] | [4, 128]            \n",
      "5 | dropout3       | Dropout | 0      | [4, 128] | [4, 128]            \n",
      "6 | activation_fct | ReLU    | 0      | [4, 128] | [4, 128]            \n",
      "-----------------------------------------------------------------------------\n",
      "34.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "34.6 K    Total params\n",
      "0.138     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In fun(): config:\n",
      "{'act_fn': ReLU(),\n",
      " 'batch_size': 4,\n",
      " 'dropout_prob': 0.20258177417814544,\n",
      " 'epochs': 512,\n",
      " 'initialization': 'Default',\n",
      " 'l1': 128,\n",
      " 'lr_mult': 1.120935246611504,\n",
      " 'optimizer': 'Adamax',\n",
      " 'patience': 16}\n",
      "LightDataModule: setup(). stage: None\n",
      "LightDataModule setup(): full_train_size: 0.9\n",
      "LightDataModule setup(): val_size: 0.09\n",
      "LightDataModule setup(): train_size: 0.81\n",
      "LightDataModule setup(): test_size: 0.1\n",
      "LightDataModule: setup(). stage: fit\n",
      "LightDataModule: setup(). stage: test\n",
      "LightDataModule: setup(). stage: predict\n",
      "train_model(): Test set size: 45\n",
      "train_model(): Train set size: 359\n",
      "train_model(): Batch size: 4\n",
      "LightDataModule: setup(). stage: TrainerFn.FITTING\n",
      "LightDataModule setup(): full_train_size: 0.9\n",
      "LightDataModule setup(): val_size: 0.09\n",
      "LightDataModule setup(): train_size: 0.81\n",
      "LightDataModule setup(): test_size: 0.1\n",
      "LightDataModule: setup(). stage: fit\n",
      "LightDataModule: val_dataloader(). Training set size: 39\n",
      "LightDataModule: val_dataloader(). batch_size: 4\n",
      "LightDataModule: val_dataloader(). num_workers: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule: train_dataloader(). Training set size: 359\n",
      "LightDataModule: train_dataloader(). batch_size: 4\n",
      "LightDataModule: train_dataloader(). num_workers: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule: setup(). stage: TrainerFn.VALIDATING\n",
      "LightDataModule setup(): full_train_size: 0.9\n",
      "LightDataModule setup(): val_size: 0.09\n",
      "LightDataModule setup(): train_size: 0.81\n",
      "LightDataModule setup(): test_size: 0.1\n",
      "LightDataModule: val_dataloader(). Training set size: 39\n",
      "LightDataModule: val_dataloader(). batch_size: 4\n",
      "LightDataModule: val_dataloader(). num_workers: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     4371.36474609375      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     4371.36474609375      </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    4371.36474609375     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    4371.36474609375     \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 4371.36474609375, 'hp_metric': 4371.36474609375}\n",
      "spotPython tuning: 2651.450439453125 [##########] 100.00% Done...\r\n",
      "\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spotPython.spot.spot.Spot at 0x2cf058290>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spotPython.spot import spot\n",
    "spot_tuner = spot.Spot(fun=fun,\n",
    "                       fun_control=fun_control,\n",
    "                       design_control=design_control,\n",
    "                       surrogate_control=surrogate_control)\n",
    "spot_tuner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc3cae4",
   "metadata": {},
   "source": [
    "## Step 9: Tensorboard {#sec-tensorboard-32}\n",
    "\n",
    "The textual output shown in the console (or code cell) can be visualized with Tensorboard.\n",
    "\n",
    "\n",
    "\n",
    "```{raw}\n",
    "tensorboard --logdir=\"runs/\"\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "Further information can be found in the [PyTorch Lightning documentation](https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.loggers.tensorboard.html) for Tensorboard.\n",
    "\n",
    "\n",
    "\n",
    "## Step 10: Results {#sec-results-32}\n",
    "\n",
    "After the hyperparameter tuning run is finished, the results can be analyzed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fddd94c",
   "metadata": {
    "fig-label": "fig-progress-32"
   },
   "outputs": [
    {
     "data": {
      "application/pdf": "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",
      "text/plain": [
       "<Figure size 2700x1800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| fig-cap: Progress plot. *Black* dots denote results from the initial design. *Red* dots  illustrate the improvement found by the surrogate model based optimization.\n",
    "spot_tuner.plot_progress(log_y=False,\n",
    "    filename=\"./figures/\" + PREFIX + \"_progress.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cad74c1",
   "metadata": {
    "fig-label": "tbl-results-32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| name           | type   | default   |   lower |   upper | tuned               | transform             |   importance | stars   |\n",
      "|----------------|--------|-----------|---------|---------|---------------------|-----------------------|--------------|---------|\n",
      "| l1             | int    | 3         |     3.0 |     8.0 | 7.0                 | transform_power_2_int |         0.54 | .       |\n",
      "| epochs         | int    | 4         |     7.0 |     9.0 | 9.0                 | transform_power_2_int |         0.00 |         |\n",
      "| batch_size     | int    | 4         |     2.0 |     6.0 | 2.0                 | transform_power_2_int |         0.00 |         |\n",
      "| act_fn         | factor | ReLU      |     0.0 |     0.0 | ReLU                | None                  |         0.00 |         |\n",
      "| optimizer      | factor | SGD       |     0.0 |     3.0 | Adamax              | None                  |       100.00 | ***     |\n",
      "| dropout_prob   | float  | 0.01      |    0.01 |    0.25 | 0.21164199382623602 | None                  |         0.00 |         |\n",
      "| lr_mult        | float  | 1.0       |     0.5 |     5.0 | 0.9336514668325573  | None                  |         0.00 |         |\n",
      "| patience       | int    | 2         |     3.0 |     9.0 | 4.0                 | transform_power_2_int |         0.00 |         |\n",
      "| initialization | factor | Default   |     0.0 |     0.0 | Default             | None                  |         0.00 |         |\n"
     ]
    }
   ],
   "source": [
    "#| fig-cap: Results of the hyperparameter tuning.\n",
    "from spotPython.utils.eda import gen_design_table\n",
    "print(gen_design_table(fun_control=fun_control, spot=spot_tuner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07aeb424",
   "metadata": {
    "fig-label": "fig-importance-32"
   },
   "outputs": [
    {
     "data": {
      "application/pdf": "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",
      "text/plain": [
       "<Figure size 1650x1050 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| fig-cap: 'Variable importance plot, threshold 0.025.'\n",
    "spot_tuner.plot_importance(threshold=0.025,\n",
    "    filename=\"./figures/\" + PREFIX + \"_importance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f566b46",
   "metadata": {},
   "source": [
    "### Get the Tuned Architecture {#sec-get-spot-results-32}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c627baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'l1': 128, 'epochs': 512, 'batch_size': 4, 'act_fn': ReLU(), 'optimizer': 'Adamax', 'dropout_prob': 0.21164199382623602, 'lr_mult': 0.9336514668325573, 'patience': 16, 'initialization': 'Default'}\n"
     ]
    }
   ],
   "source": [
    "from spotPython.hyperparameters.values import get_tuned_architecture\n",
    "config = get_tuned_architecture(spot_tuner, fun_control)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68af427c",
   "metadata": {},
   "source": [
    "* Test on the full data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23830953",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type    | Params | In sizes | Out sizes           \n",
      "-----------------------------------------------------------------------------\n",
      "0 | rnn_layer      | RNN     | 17.9 K | [4, 10]  | [[4, 128], [1, 128]]\n",
      "1 | fc             | Linear  | 16.5 K | [4, 128] | [4, 128]            \n",
      "2 | output_layer   | Linear  | 129    | [4, 128] | [4, 1]              \n",
      "3 | dropout1       | Dropout | 0      | [4, 10]  | [4, 10]             \n",
      "4 | dropout2       | Dropout | 0      | [4, 128] | [4, 128]            \n",
      "5 | dropout3       | Dropout | 0      | [4, 128] | [4, 128]            \n",
      "6 | activation_fct | ReLU    | 0      | [4, 128] | [4, 128]            \n",
      "-----------------------------------------------------------------------------\n",
      "34.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "34.6 K    Total params\n",
      "0.138     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule: setup(). stage: None\n",
      "LightDataModule setup(): full_train_size: 0.9\n",
      "LightDataModule setup(): val_size: 0.09\n",
      "LightDataModule setup(): train_size: 0.81\n",
      "LightDataModule setup(): test_size: 0.1\n",
      "LightDataModule: setup(). stage: fit\n",
      "LightDataModule: setup(). stage: test\n",
      "LightDataModule: setup(). stage: predict\n",
      "LightDataModule: setup(). stage: TrainerFn.FITTING\n",
      "LightDataModule setup(): full_train_size: 0.9\n",
      "LightDataModule setup(): val_size: 0.09\n",
      "LightDataModule setup(): train_size: 0.81\n",
      "LightDataModule setup(): test_size: 0.1\n",
      "LightDataModule: setup(). stage: fit\n",
      "LightDataModule: val_dataloader(). Training set size: 39\n",
      "LightDataModule: val_dataloader(). batch_size: 4\n",
      "LightDataModule: val_dataloader(). num_workers: 0\n",
      "LightDataModule: train_dataloader(). Training set size: 359\n",
      "LightDataModule: train_dataloader(). batch_size: 4\n",
      "LightDataModule: train_dataloader(). num_workers: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /Users/bartz/workspace/Hyperparameter-Tuning-Cookbook/runs/saved_models/128_512_4_ReLU_Adamax_0.2116_0.9337_16_Default_TEST/last.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded model weights from the checkpoint at /Users/bartz/workspace/Hyperparameter-Tuning-Cookbook/runs/saved_models/128_512_4_ReLU_Adamax_0.2116_0.9337_16_Default_TEST/last.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule: setup(). stage: TrainerFn.TESTING\n",
      "LightDataModule setup(): full_train_size: 0.9\n",
      "LightDataModule setup(): val_size: 0.09\n",
      "LightDataModule setup(): train_size: 0.81\n",
      "LightDataModule setup(): test_size: 0.1\n",
      "LightDataModule: setup(). stage: test\n",
      "LightDataModule: test_dataloader(). Test set size: 45\n",
      "LightDataModule: test_dataloader(). batch_size: 4\n",
      "LightDataModule: test_dataloader(). num_workers: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     3670.98876953125      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     3670.98876953125      </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    3670.98876953125     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    3670.98876953125     \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_model result: {'val_loss': 3670.98876953125, 'hp_metric': 3670.98876953125}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3670.98876953125, 3670.98876953125)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spotPython.light.testmodel import test_model\n",
    "test_model(config, fun_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5b55a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config: {'l1': 128, 'epochs': 512, 'batch_size': 4, 'act_fn': ReLU(), 'optimizer': 'Adamax', 'dropout_prob': 0.21164199382623602, 'lr_mult': 0.9336514668325573, 'patience': 16, 'initialization': 'Default'}\n",
      "Loading model with 128_512_4_ReLU_Adamax_0.2116_0.9337_16_Default_TEST from runs/saved_models/128_512_4_ReLU_Adamax_0.2116_0.9337_16_Default_TEST/last.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RNNLightRegression(\n",
      "  (rnn_layer): RNN(10, 128, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (output_layer): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (dropout1): Dropout(p=0.21164199382623602, inplace=False)\n",
      "  (dropout2): Dropout(p=0.0, inplace=False)\n",
      "  (dropout3): Dropout(p=0.0, inplace=False)\n",
      "  (activation_fct): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from spotPython.light.loadmodel import load_light_from_checkpoint\n",
    "\n",
    "model_loaded = load_light_from_checkpoint(config, fun_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ee8c514",
   "metadata": {
    "fig-label": "fig-contour-32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1:  0.5431038158307683\n",
      "optimizer:  100.0\n",
      "impo: [['l1', 0.5431038158307683], ['epochs', 0.0026254086940176256], ['batch_size', 0.0026254086940176256], ['optimizer', 100.0], ['dropout_prob', 0.0026254086940176256], ['lr_mult', 0.0026254086940176256], ['patience', 0.0026254086940176256]]\n",
      "impo after select: [['l1', 0.5431038158307683], ['epochs', 0.0026254086940176256], ['batch_size', 0.0026254086940176256], ['optimizer', 100.0], ['dropout_prob', 0.0026254086940176256], ['lr_mult', 0.0026254086940176256], ['patience', 0.0026254086940176256]]\n"
     ]
    },
    {
     "data": {
      "application/pdf": "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",
      "text/plain": [
       "<Figure size 2700x1800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| fig-cap: Contour plots.\n",
    "filename = \"./figures/\" + PREFIX\n",
    "spot_tuner.plot_important_hyperparameter_contour(filename=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32bf99a",
   "metadata": {},
   "source": [
    "### Parallel Coordinates Plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87f91519",
   "metadata": {
    "fig-label": "fig-parallel-32"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.27.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"3a89299a-e921-4c0a-a457-c24bbf243b13\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3a89299a-e921-4c0a-a457-c24bbf243b13\")) {                    Plotly.newPlot(                        \"3a89299a-e921-4c0a-a457-c24bbf243b13\",                        [{\"dimensions\":[{\"label\":\"l1\",\"range\":[3.0,7.0],\"values\":[4.0,7.0,7.0,6.0,3.0,7.0]},{\"label\":\"epochs\",\"range\":[7.0,9.0],\"values\":[8.0,8.0,9.0,7.0,8.0,9.0]},{\"label\":\"batch_size\",\"range\":[2.0,6.0],\"values\":[6.0,4.0,2.0,3.0,4.0,2.0]},{\"label\":\"optimizer\",\"range\":[0.0,3.0],\"values\":[2.0,0.0,3.0,2.0,1.0,3.0]},{\"label\":\"dropout_prob\",\"range\":[0.05728504399550885,0.21164199382623602],\"values\":[0.19355651674791854,0.09424169914869776,0.21164199382623602,0.05728504399550885,0.14352914208400058,0.20258177417814544]},{\"label\":\"lr_mult\",\"range\":[0.9336514668325573,4.575980093998586],\"values\":[1.5691149440098038,3.35818256351233,0.9336514668325573,4.575980093998586,2.4204853123355816,1.120935246611504]},{\"label\":\"patience\",\"range\":[4.0,9.0],\"values\":[5.0,9.0,4.0,5.0,7.0,4.0]}],\"line\":{\"cmax\":8449.935546875,\"cmin\":2651.450439453125,\"color\":[5832.97998046875,3765.2763671875,2651.450439453125,4523.0830078125,8449.935546875,4371.36474609375],\"colorscale\":[[0.0,\"rgb(0,0,131)\"],[0.2,\"rgb(0,60,170)\"],[0.4,\"rgb(5,255,255)\"],[0.6,\"rgb(255,255,0)\"],[0.8,\"rgb(250,0,0)\"],[1.0,\"rgb(128,0,0)\"]],\"showscale\":true},\"type\":\"parcoords\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"},\"margin\":{\"b\":0,\"l\":0,\"r\":0,\"t\":30}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('3a89299a-e921-4c0a-a457-c24bbf243b13');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| fig-cap: Parallel coordinates plots\n",
    "spot_tuner.parallel_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bc96ee",
   "metadata": {},
   "source": [
    "### Cross Validation With Lightning\n",
    "\n",
    "* The `KFold` class from `sklearn.model_selection` is used to generate the folds for cross-validation.\n",
    "* These mechanism is used to generate the folds for the final evaluation of the model.\n",
    "* The `CrossValidationDataModule` class [[SOURCE]](https://github.com/sequential-parameter-optimization/spotPython/blob/main/src/spotPython/data/lightcrossvalidationdatamodule.py) is used to generate the folds for the hyperparameter tuning process.\n",
    "* It is called from the `cv_model` function [[SOURCE]](https://github.com/sequential-parameter-optimization/spotPython/blob/main/src/spotPython/light/cvmodel.py).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c693b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type    | Params | In sizes | Out sizes           \n",
      "-----------------------------------------------------------------------------\n",
      "0 | rnn_layer      | RNN     | 17.9 K | [4, 10]  | [[4, 128], [1, 128]]\n",
      "1 | fc             | Linear  | 16.5 K | [4, 128] | [4, 128]            \n",
      "2 | output_layer   | Linear  | 129    | [4, 128] | [4, 1]              \n",
      "3 | dropout1       | Dropout | 0      | [4, 10]  | [4, 10]             \n",
      "4 | dropout2       | Dropout | 0      | [4, 128] | [4, 128]            \n",
      "5 | dropout3       | Dropout | 0      | [4, 128] | [4, 128]            \n",
      "6 | activation_fct | ReLU    | 0      | [4, 128] | [4, 128]            \n",
      "-----------------------------------------------------------------------------\n",
      "34.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "34.6 K    Total params\n",
      "0.138     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 0\n",
      "Train Dataset Size: 221\n",
      "Val Dataset Size: 221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      3672.435546875       </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      3672.435546875       </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     3672.435546875      \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     3672.435546875      \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:639: Checkpoint directory runs/lightning_logs/20240227031544858258_128_512_4_ReLU_Adamax_0.2116_0.9337_16_Default_CV/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name           | Type    | Params | In sizes | Out sizes           \n",
      "-----------------------------------------------------------------------------\n",
      "0 | rnn_layer      | RNN     | 17.9 K | [4, 10]  | [[4, 128], [1, 128]]\n",
      "1 | fc             | Linear  | 16.5 K | [4, 128] | [4, 128]            \n",
      "2 | output_layer   | Linear  | 129    | [4, 128] | [4, 1]              \n",
      "3 | dropout1       | Dropout | 0      | [4, 10]  | [4, 10]             \n",
      "4 | dropout2       | Dropout | 0      | [4, 128] | [4, 128]            \n",
      "5 | dropout3       | Dropout | 0      | [4, 128] | [4, 128]            \n",
      "6 | activation_fct | ReLU    | 0      | [4, 128] | [4, 128]            \n",
      "-----------------------------------------------------------------------------\n",
      "34.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "34.6 K    Total params\n",
      "0.138     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 3672.435546875, 'hp_metric': 3672.435546875}\n",
      "k: 1\n",
      "Train Dataset Size: 221\n",
      "Val Dataset Size: 221\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      3101.556640625       </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      3101.556640625       </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     3101.556640625      \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     3101.556640625      \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 3101.556640625, 'hp_metric': 3101.556640625}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3386.99609375"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spotPython.light.cvmodel import cv_model\n",
    "set_control_key_value(control_dict=fun_control,\n",
    "                        key=\"k_folds\",\n",
    "                        value=2,\n",
    "                        replace=True)\n",
    "set_control_key_value(control_dict=fun_control,\n",
    "                        key=\"test_size\",\n",
    "                        value=0.1,\n",
    "                        replace=True)\n",
    "cv_model(config, fun_control)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5d3b9f",
   "metadata": {},
   "source": [
    "### Plot all Combinations of Hyperparameters\n",
    "\n",
    "* Warning: this may take a while.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3a9f6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_ALL = False\n",
    "if PLOT_ALL:\n",
    "    n = spot_tuner.k\n",
    "    for i in range(n-1):\n",
    "        for j in range(i+1, n):\n",
    "            spot_tuner.plot_contour(i=i, j=j, min_z=min_z, max_z = max_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8335dfbb",
   "metadata": {},
   "source": [
    "### Visualizing the Activation Distribution (Under Development)\n",
    "\n",
    "::: {.callout-note}\n",
    "### Reference:\n",
    "\n",
    "* The following code is based on [[PyTorch Lightning TUTORIAL 2: ACTIVATION FUNCTIONS]](https://lightning.ai/docs/pytorch/stable/notebooks/course_UvA-DL/02-activation-functions.html), Author: Phillip Lippe, License: [[CC BY-SA]](https://creativecommons.org/licenses/by-sa/3.0/), Generated: 2023-03-15T09:52:39.179933.\n",
    "\n",
    ":::\n",
    "\n",
    "After we have trained the models, we can look at the actual activation values that find inside the model. For instance, how many neurons are set to zero in ReLU? Where do we find most values in Tanh? To answer these questions, we can write a simple function which takes a trained model, applies it to a batch of images, and plots the histogram of the activations inside the network:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62458624",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotPython.torch.activation import Sigmoid, Tanh, ReLU, LeakyReLU, ELU, Swish\n",
    "act_fn_by_name = {\"sigmoid\": Sigmoid, \"tanh\": Tanh, \"relu\": ReLU, \"leakyrelu\": LeakyReLU, \"elu\": ELU, \"swish\": Swish}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99680f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLightRegression(\n",
       "  (rnn_layer): RNN(64, 128, batch_first=True)\n",
       "  (fc): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (output_layer): Linear(in_features=128, out_features=11, bias=True)\n",
       "  (dropout1): Dropout(p=0.21164199382623602, inplace=False)\n",
       "  (dropout2): Dropout(p=0.0, inplace=False)\n",
       "  (dropout3): Dropout(p=0.0, inplace=False)\n",
       "  (activation_fct): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spotPython.hyperparameters.values import get_one_config_from_X\n",
    "X = spot_tuner.to_all_dim(spot_tuner.min_X.reshape(1,-1))\n",
    "config = get_one_config_from_X(X, fun_control)\n",
    "model = fun_control[\"core_model\"](**config, _L_in=64, _L_out=11)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aff616b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from spotPython.utils.eda import visualize_activations\n",
    "# visualize_activations(model, color=f\"C{0}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
