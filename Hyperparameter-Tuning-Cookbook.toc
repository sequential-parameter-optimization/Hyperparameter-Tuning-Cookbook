\contentsline {chapter}{Preface: Optimization and Hyperparameter Tuning}{3}{chapter*.2}%
\contentsline {section}{Book Structure}{4}{section*.3}%
\contentsline {section}{Software Used in this Book}{6}{section*.4}%
\contentsline {part}{\numberline {I}Spot as an Optimizer}{7}{part.1}%
\contentsline {chapter}{\numberline {1}Introduction to \texttt {spotPython}}{8}{chapter.1}%
\contentsline {section}{\numberline {1.1}Example: \texttt {Spot} and the Sphere Function}{8}{section.1.1}%
\contentsline {subsection}{\numberline {1.1.1}The Objective Function: Sphere}{9}{subsection.1.1.1}%
\contentsline {section}{\numberline {1.2}\texttt {Spot} Parameters: \texttt {fun\_evals}, \texttt {init\_size} and \texttt {show\_models}}{11}{section.1.2}%
\contentsline {section}{\numberline {1.3}Print the Results}{13}{section.1.3}%
\contentsline {section}{\numberline {1.4}Show the Progress}{13}{section.1.4}%
\contentsline {section}{\numberline {1.5}Visualizing the Optimization and Hyperparameter Tuning Process with TensorBoard}{13}{section.1.5}%
\contentsline {chapter}{\numberline {2}Multi-dimensional Functions}{17}{chapter.2}%
\contentsline {section}{\numberline {2.1}Example: \texttt {Spot} and the 3-dim Sphere Function}{17}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}The Objective Function: 3-dim Sphere}{17}{subsection.2.1.1}%
\contentsline {subsection}{\numberline {2.1.2}Results}{19}{subsection.2.1.2}%
\contentsline {subsection}{\numberline {2.1.3}A Contour Plot}{19}{subsection.2.1.3}%
\contentsline {subsection}{\numberline {2.1.4}TensorBoard}{21}{subsection.2.1.4}%
\contentsline {section}{\numberline {2.2}Conclusion}{22}{section.2.2}%
\contentsline {section}{\numberline {2.3}Exercises}{23}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}The Three Dimensional \texttt {fun\_cubed}}{23}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2}The Ten Dimensional \texttt {fun\_wing\_wt}}{23}{subsection.2.3.2}%
\contentsline {subsection}{\numberline {2.3.3}The Three Dimensional \texttt {fun\_runge}}{23}{subsection.2.3.3}%
\contentsline {subsection}{\numberline {2.3.4}The Three Dimensional \texttt {fun\_linear}}{24}{subsection.2.3.4}%
\contentsline {chapter}{\numberline {3}Isotropic and Anisotropic Kriging}{25}{chapter.3}%
\contentsline {section}{\numberline {3.1}Example: Isotropic \texttt {Spot} Surrogate and the 2-dim Sphere Function}{25}{section.3.1}%
\contentsline {subsection}{\numberline {3.1.1}The Objective Function: 2-dim Sphere}{25}{subsection.3.1.1}%
\contentsline {subsection}{\numberline {3.1.2}Results}{26}{subsection.3.1.2}%
\contentsline {section}{\numberline {3.2}Example With Anisotropic Kriging}{27}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Taking a Look at the \texttt {theta} Values}{29}{subsection.3.2.1}%
\contentsline {subsubsection}{\numberline {3.2.1.1}\texttt {theta} Values from the \texttt {spot} Model}{29}{subsubsection.3.2.1.1}%
\contentsline {subsubsection}{\numberline {3.2.1.2}TensorBoard}{30}{subsubsection.3.2.1.2}%
\contentsline {section}{\numberline {3.3}Exercises}{30}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}\texttt {fun\_branin}}{30}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}\texttt {fun\_sin\_cos}}{31}{subsection.3.3.2}%
\contentsline {subsection}{\numberline {3.3.3}\texttt {fun\_runge}}{31}{subsection.3.3.3}%
\contentsline {subsection}{\numberline {3.3.4}\texttt {fun\_wingwt}}{31}{subsection.3.3.4}%
\contentsline {chapter}{\numberline {4}Using \texttt {sklearn} Surrogates in \texttt {spotPython}}{32}{chapter.4}%
\contentsline {section}{\numberline {4.1}Example: Branin Function with \texttt {spotPython}'s Internal Kriging Surrogate}{32}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1}The Objective Function Branin}{32}{subsection.4.1.1}%
\contentsline {subsection}{\numberline {4.1.2}Running the surrogate model based optimizer \texttt {Spot}:}{33}{subsection.4.1.2}%
\contentsline {subsection}{\numberline {4.1.3}TensorBoard}{34}{subsection.4.1.3}%
\contentsline {subsection}{\numberline {4.1.4}Print the Results}{34}{subsection.4.1.4}%
\contentsline {subsection}{\numberline {4.1.5}Show the Progress and the Surrogate}{34}{subsection.4.1.5}%
\contentsline {section}{\numberline {4.2}Example: Using Surrogates From scikit-learn}{37}{section.4.2}%
\contentsline {subsection}{\numberline {4.2.1}GaussianProcessRegressor as a Surrogate}{37}{subsection.4.2.1}%
\contentsline {section}{\numberline {4.3}Example: One-dimensional Sphere Function With \texttt {spotPython}'s Kriging}{39}{section.4.3}%
\contentsline {subsection}{\numberline {4.3.1}Results}{45}{subsection.4.3.1}%
\contentsline {section}{\numberline {4.4}Example: \texttt {Sklearn} Model GaussianProcess}{46}{section.4.4}%
\contentsline {section}{\numberline {4.5}Exercises}{53}{section.4.5}%
\contentsline {subsection}{\numberline {4.5.1}\texttt {DecisionTreeRegressor}}{53}{subsection.4.5.1}%
\contentsline {subsection}{\numberline {4.5.2}\texttt {RandomForestRegressor}}{54}{subsection.4.5.2}%
\contentsline {subsection}{\numberline {4.5.3}\texttt {linear\_model.LinearRegression}}{54}{subsection.4.5.3}%
\contentsline {subsection}{\numberline {4.5.4}\texttt {linear\_model.Ridge}}{54}{subsection.4.5.4}%
\contentsline {section}{\numberline {4.6}Exercise 2}{54}{section.4.6}%
\contentsline {chapter}{\numberline {5}Sequential Parameter Optimization: Using \texttt {scipy} Optimizers}{55}{chapter.5}%
\contentsline {section}{\numberline {5.1}The Objective Function Branin}{55}{section.5.1}%
\contentsline {section}{\numberline {5.2}The Optimizer}{56}{section.5.2}%
\contentsline {subsection}{\numberline {5.2.1}TensorBoard}{58}{subsection.5.2.1}%
\contentsline {section}{\numberline {5.3}Print the Results}{58}{section.5.3}%
\contentsline {section}{\numberline {5.4}Show the Progress}{58}{section.5.4}%
\contentsline {section}{\numberline {5.5}Exercises}{61}{section.5.5}%
\contentsline {subsection}{\numberline {5.5.1}\texttt {dual\_annealing}}{61}{subsection.5.5.1}%
\contentsline {subsection}{\numberline {5.5.2}\texttt {direct}}{61}{subsection.5.5.2}%
\contentsline {subsection}{\numberline {5.5.3}\texttt {shgo}}{61}{subsection.5.5.3}%
\contentsline {subsection}{\numberline {5.5.4}\texttt {basinhopping}}{61}{subsection.5.5.4}%
\contentsline {subsection}{\numberline {5.5.5}Performance Comparison}{61}{subsection.5.5.5}%
\contentsline {chapter}{\numberline {6}Sequential Parameter Optimization: Gaussian Process Models}{63}{chapter.6}%
\contentsline {section}{\numberline {6.1}Gaussian Processes Regression: Basic Introductory \texttt {scikit-learn} Example}{63}{section.6.1}%
\contentsline {subsection}{\numberline {6.1.1}Train and Test Data}{64}{subsection.6.1.1}%
\contentsline {subsection}{\numberline {6.1.2}Building the Surrogate With \texttt {Sklearn}}{64}{subsection.6.1.2}%
\contentsline {subsection}{\numberline {6.1.3}Plotting the \texttt {Sklearn}Model}{64}{subsection.6.1.3}%
\contentsline {subsection}{\numberline {6.1.4}The \texttt {spotPython} Version}{65}{subsection.6.1.4}%
\contentsline {subsection}{\numberline {6.1.5}Visualizing the Differences Between the \texttt {spotPython} and the \texttt {sklearn} Model Fits}{66}{subsection.6.1.5}%
\contentsline {section}{\numberline {6.2}Exercises}{67}{section.6.2}%
\contentsline {subsection}{\numberline {6.2.1}\texttt {Schonlau\ Example\ Function}}{67}{subsection.6.2.1}%
\contentsline {subsection}{\numberline {6.2.2}\texttt {Forrester\ Example\ Function}}{67}{subsection.6.2.2}%
\contentsline {subsection}{\numberline {6.2.3}\texttt {fun\_runge\ Function\ (1-dim)}}{68}{subsection.6.2.3}%
\contentsline {subsection}{\numberline {6.2.4}\texttt {fun\_cubed\ (1-dim)}}{69}{subsection.6.2.4}%
\contentsline {subsection}{\numberline {6.2.5}The Effect of Noise}{69}{subsection.6.2.5}%
\contentsline {chapter}{\numberline {7}Expected Improvement}{70}{chapter.7}%
\contentsline {section}{\numberline {7.1}Example: \texttt {Spot} and the 1-dim Sphere Function}{70}{section.7.1}%
\contentsline {subsection}{\numberline {7.1.1}The Objective Function: 1-dim Sphere}{70}{subsection.7.1.1}%
\contentsline {subsection}{\numberline {7.1.2}Results}{72}{subsection.7.1.2}%
\contentsline {section}{\numberline {7.2}Same, but with EI as infill\_criterion}{73}{section.7.2}%
\contentsline {section}{\numberline {7.3}Non-isotropic Kriging}{75}{section.7.3}%
\contentsline {section}{\numberline {7.4}Using \texttt {sklearn} Surrogates}{78}{section.7.4}%
\contentsline {subsection}{\numberline {7.4.1}The spot Loop}{78}{subsection.7.4.1}%
\contentsline {subsection}{\numberline {7.4.2}spot: The Initial Model}{79}{subsection.7.4.2}%
\contentsline {subsubsection}{\numberline {7.4.2.1}Example: Modifying the initial design size}{79}{subsubsection.7.4.2.1}%
\contentsline {subsection}{\numberline {7.4.3}Init: Build Initial Design}{81}{subsection.7.4.3}%
\contentsline {subsection}{\numberline {7.4.4}Evaluate}{83}{subsection.7.4.4}%
\contentsline {subsection}{\numberline {7.4.5}Build Surrogate}{83}{subsection.7.4.5}%
\contentsline {subsection}{\numberline {7.4.6}A Simple Predictor}{83}{subsection.7.4.6}%
\contentsline {section}{\numberline {7.5}Gaussian Processes regression: basic introductory example}{83}{section.7.5}%
\contentsline {section}{\numberline {7.6}The Surrogate: Using scikit-learn models}{86}{section.7.6}%
\contentsline {section}{\numberline {7.7}Additional Examples}{89}{section.7.7}%
\contentsline {subsection}{\numberline {7.7.1}Optimize on Surrogate}{93}{subsection.7.7.1}%
\contentsline {subsection}{\numberline {7.7.2}Evaluate on Real Objective}{93}{subsection.7.7.2}%
\contentsline {subsection}{\numberline {7.7.3}Impute / Infill new Points}{93}{subsection.7.7.3}%
\contentsline {section}{\numberline {7.8}Tests}{93}{section.7.8}%
\contentsline {section}{\numberline {7.9}EI: The Famous Schonlau Example}{94}{section.7.9}%
\contentsline {section}{\numberline {7.10}EI: The Forrester Example}{96}{section.7.10}%
\contentsline {section}{\numberline {7.11}Noise}{99}{section.7.11}%
\contentsline {section}{\numberline {7.12}Cubic Function}{102}{section.7.12}%
\contentsline {section}{\numberline {7.13}Factors}{108}{section.7.13}%
\contentsline {chapter}{\numberline {8}Hyperparameter Tuning and Noise}{110}{chapter.8}%
\contentsline {section}{\numberline {8.1}Example: \texttt {Spot} and the Noisy Sphere Function}{110}{section.8.1}%
\contentsline {subsection}{\numberline {8.1.1}The Objective Function: Noisy Sphere}{110}{subsection.8.1.1}%
\contentsline {section}{\numberline {8.2}Print the Results}{117}{section.8.2}%
\contentsline {section}{\numberline {8.3}Noise and Surrogates: The Nugget Effect}{118}{section.8.3}%
\contentsline {subsection}{\numberline {8.3.1}The Noisy Sphere}{118}{subsection.8.3.1}%
\contentsline {subsubsection}{\numberline {8.3.1.1}The Data}{118}{subsubsection.8.3.1.1}%
\contentsline {section}{\numberline {8.4}Exercises}{121}{section.8.4}%
\contentsline {subsection}{\numberline {8.4.1}Noisy \texttt {fun\_cubed}}{121}{subsection.8.4.1}%
\contentsline {subsection}{\numberline {8.4.2}\texttt {fun\_runge}}{122}{subsection.8.4.2}%
\contentsline {subsection}{\numberline {8.4.3}\texttt {fun\_forrester}}{122}{subsection.8.4.3}%
\contentsline {subsection}{\numberline {8.4.4}\texttt {fun\_xsin}}{122}{subsection.8.4.4}%
\contentsline {chapter}{\numberline {9}Handling Noise: Optimal Computational Budget Allocation in \texttt {Spot}}{123}{chapter.9}%
\contentsline {section}{\numberline {9.1}Example: \texttt {Spot}, OCBA, and the Noisy Sphere Function}{123}{section.9.1}%
\contentsline {subsection}{\numberline {9.1.1}The Objective Function: Noisy Sphere}{123}{subsection.9.1.1}%
\contentsline {section}{\numberline {9.2}Print the Results}{129}{section.9.2}%
\contentsline {section}{\numberline {9.3}Noise and Surrogates: The Nugget Effect}{129}{section.9.3}%
\contentsline {subsection}{\numberline {9.3.1}The Noisy Sphere}{129}{subsection.9.3.1}%
\contentsline {subsubsection}{\numberline {9.3.1.1}The Data}{129}{subsubsection.9.3.1.1}%
\contentsline {section}{\numberline {9.4}Exercises}{132}{section.9.4}%
\contentsline {subsection}{\numberline {9.4.1}Noisy \texttt {fun\_cubed}}{132}{subsection.9.4.1}%
\contentsline {subsection}{\numberline {9.4.2}\texttt {fun\_runge}}{133}{subsection.9.4.2}%
\contentsline {subsection}{\numberline {9.4.3}\texttt {fun\_forrester}}{133}{subsection.9.4.3}%
\contentsline {subsection}{\numberline {9.4.4}\texttt {fun\_xsin}}{133}{subsection.9.4.4}%
\contentsline {part}{\numberline {II}Hyperparameter Tuning}{134}{part.2}%
\contentsline {chapter}{\numberline {10}HPT: sklearn SVC on Moons Data}{135}{chapter.10}%
\contentsline {section}{\numberline {10.1}Step 1: Setup}{135}{section.10.1}%
\contentsline {section}{\numberline {10.2}Step 2: Initialization of the Empty \texttt {fun\_control} Dictionary}{135}{section.10.2}%
\contentsline {section}{\numberline {10.3}Step 3: SKlearn Load Data (Classification)}{136}{section.10.3}%
\contentsline {section}{\numberline {10.4}Step 4: Specification of the Preprocessing Model}{138}{section.10.4}%
\contentsline {section}{\numberline {10.5}Step 5: Select Model (\texttt {algorithm}) and \texttt {core\_model\_hyper\_dict}}{138}{section.10.5}%
\contentsline {section}{\numberline {10.6}Step 6: Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{141}{section.10.6}%
\contentsline {subsection}{\numberline {10.6.1}Modify hyperparameter of type numeric and integer (boolean)}{141}{subsection.10.6.1}%
\contentsline {subsection}{\numberline {10.6.2}Modify hyperparameter of type factor}{142}{subsection.10.6.2}%
\contentsline {subsection}{\numberline {10.6.3}Optimizers}{142}{subsection.10.6.3}%
\contentsline {section}{\numberline {10.7}Step 7: Selection of the Objective (Loss) Function}{142}{section.10.7}%
\contentsline {subsection}{\numberline {10.7.1}Predict Classes or Class Probabilities}{143}{subsection.10.7.1}%
\contentsline {section}{\numberline {10.8}Step 8: Calling the SPOT Function}{143}{section.10.8}%
\contentsline {subsection}{\numberline {10.8.1}Preparing the SPOT Call}{143}{subsection.10.8.1}%
\contentsline {subsection}{\numberline {10.8.2}The Objective Function}{144}{subsection.10.8.2}%
\contentsline {subsection}{\numberline {10.8.3}Run the \texttt {Spot} Optimizer}{144}{subsection.10.8.3}%
\contentsline {subsection}{\numberline {10.8.4}Starting the Hyperparameter Tuning}{145}{subsection.10.8.4}%
\contentsline {section}{\numberline {10.9}Step 9: Results}{146}{section.10.9}%
\contentsline {subsection}{\numberline {10.9.1}Show variable importance}{148}{subsection.10.9.1}%
\contentsline {subsection}{\numberline {10.9.2}Get Default Hyperparameters}{148}{subsection.10.9.2}%
\contentsline {subsection}{\numberline {10.9.3}Get SPOT Results}{149}{subsection.10.9.3}%
\contentsline {subsection}{\numberline {10.9.4}Plot: Compare Predictions}{150}{subsection.10.9.4}%
\contentsline {subsection}{\numberline {10.9.5}Detailed Hyperparameter Plots}{152}{subsection.10.9.5}%
\contentsline {subsection}{\numberline {10.9.6}Parallel Coordinates Plot}{153}{subsection.10.9.6}%
\contentsline {subsection}{\numberline {10.9.7}Plot all Combinations of Hyperparameters}{153}{subsection.10.9.7}%
\contentsline {chapter}{\numberline {11}\texttt {river} Hyperparameter Tuning: Hoeffding Adaptive Tree Regressor with Friedman Drift Data}{154}{chapter.11}%
\contentsline {section}{\numberline {11.1}Setup}{154}{section.11.1}%
\contentsline {section}{\numberline {11.2}Initialization of the \texttt {fun\_control} Dictionary}{155}{section.11.2}%
\contentsline {section}{\numberline {11.3}Load Data: The Friedman Drift Data}{156}{section.11.3}%
\contentsline {section}{\numberline {11.4}Specification of the Preprocessing Model}{157}{section.11.4}%
\contentsline {section}{\numberline {11.5}SelectSelect Model (\texttt {algorithm}) and \texttt {core\_model\_hyper\_dict}}{157}{section.11.5}%
\contentsline {section}{\numberline {11.6}Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{158}{section.11.6}%
\contentsline {section}{\numberline {11.7}Selection of the Objective Function}{159}{section.11.7}%
\contentsline {section}{\numberline {11.8}Calling the SPOT Function}{160}{section.11.8}%
\contentsline {subsection}{\numberline {11.8.1}Prepare the SPOT Parameters}{160}{subsection.11.8.1}%
\contentsline {subsection}{\numberline {11.8.2}The Objective Function}{161}{subsection.11.8.2}%
\contentsline {subsection}{\numberline {11.8.3}Run the \texttt {Spot} Optimizer}{161}{subsection.11.8.3}%
\contentsline {subsection}{\numberline {11.8.4}TensorBoard}{163}{subsection.11.8.4}%
\contentsline {subsection}{\numberline {11.8.5}Results}{163}{subsection.11.8.5}%
\contentsline {section}{\numberline {11.9}The Larger Data Set}{166}{section.11.9}%
\contentsline {section}{\numberline {11.10}Get Default Hyperparameters}{167}{section.11.10}%
\contentsline {subsection}{\numberline {11.10.1}Show Predictions}{168}{subsection.11.10.1}%
\contentsline {section}{\numberline {11.11}Get SPOT Results}{169}{section.11.11}%
\contentsline {section}{\numberline {11.12}Visualize Regression Trees}{172}{section.11.12}%
\contentsline {subsection}{\numberline {11.12.1}Spot Model}{172}{subsection.11.12.1}%
\contentsline {section}{\numberline {11.13}Detailed Hyperparameter Plots}{173}{section.11.13}%
\contentsline {section}{\numberline {11.14}Parallel Coordinates Plots}{175}{section.11.14}%
\contentsline {section}{\numberline {11.15}Plot all Combinations of Hyperparameters}{175}{section.11.15}%
\contentsline {chapter}{\numberline {12}HPT: PyTorch With \texttt {spotPython} and Ray Tune on CIFAR10}{176}{chapter.12}%
\contentsline {section}{\numberline {12.1}Step 1: Setup}{177}{section.12.1}%
\contentsline {section}{\numberline {12.2}Step 2: Initialization of the \texttt {fun\_control} Dictionary}{178}{section.12.2}%
\contentsline {section}{\numberline {12.3}Step 3: PyTorch Data Loading}{178}{section.12.3}%
\contentsline {section}{\numberline {12.4}Step 4: Specification of the Preprocessing Model}{179}{section.12.4}%
\contentsline {section}{\numberline {12.5}Step 5: Select Model (\texttt {algorithm}) and \texttt {core\_model\_hyper\_dict}}{180}{section.12.5}%
\contentsline {subsubsection}{\numberline {12.5.0.1}Implementing a Configurable Neural Network With Ray Tune}{180}{subsubsection.12.5.0.1}%
\contentsline {subsubsection}{\numberline {12.5.0.2}Implementing a Configurable Neural Network With spotPython}{180}{subsubsection.12.5.0.2}%
\contentsline {subsection}{\numberline {12.5.1}The \texttt {Net\_Core} class}{181}{subsection.12.5.1}%
\contentsline {subsection}{\numberline {12.5.2}Comparison of the Approach Described in the PyTorch Tutorial With spotPython}{182}{subsection.12.5.2}%
\contentsline {subsection}{\numberline {12.5.3}The Search Space: Hyperparameters}{183}{subsection.12.5.3}%
\contentsline {subsection}{\numberline {12.5.4}Configuring the Search Space With Ray Tune}{183}{subsection.12.5.4}%
\contentsline {subsection}{\numberline {12.5.5}Configuring the Search Space With spotPython}{183}{subsection.12.5.5}%
\contentsline {subsubsection}{\numberline {12.5.5.1}The \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm}{183}{subsubsection.12.5.5.1}%
\contentsline {section}{\numberline {12.6}Step 6: Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{185}{section.12.6}%
\contentsline {subsubsection}{\numberline {12.6.0.1}Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{186}{subsubsection.12.6.0.1}%
\contentsline {subsubsection}{\numberline {12.6.0.2}Modify Hyperparameters of Type numeric and integer (boolean)}{186}{subsubsection.12.6.0.2}%
\contentsline {subsubsection}{\numberline {12.6.0.3}Modify Hyperparameter of Type factor}{186}{subsubsection.12.6.0.3}%
\contentsline {subsection}{\numberline {12.6.1}Optimizers}{187}{subsection.12.6.1}%
\contentsline {section}{\numberline {12.7}Step 7: Selection of the Objective (Loss) Function}{189}{section.12.7}%
\contentsline {subsection}{\numberline {12.7.1}Evaluation: Data Splitting}{189}{subsection.12.7.1}%
\contentsline {subsection}{\numberline {12.7.2}Hold-out Data Split}{189}{subsection.12.7.2}%
\contentsline {subsection}{\numberline {12.7.3}Cross-Validation}{190}{subsection.12.7.3}%
\contentsline {subsection}{\numberline {12.7.4}Overview of the Evaluation Settings}{190}{subsection.12.7.4}%
\contentsline {subsubsection}{\numberline {12.7.4.1}Settings for the Hyperparameter Tuning}{190}{subsubsection.12.7.4.1}%
\contentsline {subsubsection}{\numberline {12.7.4.2}Settings for the Final Evaluation of the Tuned Architecture}{191}{subsubsection.12.7.4.2}%
\contentsline {paragraph}{\numberline {12.7.4.2.1}Training of the Tuned Architecture}{191}{paragraph.12.7.4.2.1}%
\contentsline {paragraph}{\numberline {12.7.4.2.2}Testing of the Tuned Architecture}{191}{paragraph.12.7.4.2.2}%
\contentsline {subsection}{\numberline {12.7.5}Evaluation: Loss Functions and Metrics}{191}{subsection.12.7.5}%
\contentsline {section}{\numberline {12.8}Step 8: Calling the SPOT Function}{192}{section.12.8}%
\contentsline {subsection}{\numberline {12.8.1}Preparing the SPOT Call}{192}{subsection.12.8.1}%
\contentsline {subsection}{\numberline {12.8.2}The Objective Function \texttt {fun\_torch}}{193}{subsection.12.8.2}%
\contentsline {subsection}{\numberline {12.8.3}Using Default Hyperparameters or Results from Previous Runs}{193}{subsection.12.8.3}%
\contentsline {subsection}{\numberline {12.8.4}Starting the Hyperparameter Tuning}{194}{subsection.12.8.4}%
\contentsline {section}{\numberline {12.9}Step 9: Tensorboard}{200}{section.12.9}%
\contentsline {subsection}{\numberline {12.9.1}Tensorboard: Start Tensorboard}{200}{subsection.12.9.1}%
\contentsline {subsection}{\numberline {12.9.2}Saving the State of the Notebook}{200}{subsection.12.9.2}%
\contentsline {section}{\numberline {12.10}Step 10: Results}{202}{section.12.10}%
\contentsline {subsection}{\numberline {12.10.1}Get the Tuned Architecture (SPOT Results)}{204}{subsection.12.10.1}%
\contentsline {subsection}{\numberline {12.10.2}Get Default Hyperparameters}{204}{subsection.12.10.2}%
\contentsline {subsection}{\numberline {12.10.3}Evaluation of the Default Architecture}{205}{subsection.12.10.3}%
\contentsline {subsection}{\numberline {12.10.4}Evaluation of the Tuned Architecture}{206}{subsection.12.10.4}%
\contentsline {subsection}{\numberline {12.10.5}Detailed Hyperparameter Plots}{208}{subsection.12.10.5}%
\contentsline {section}{\numberline {12.11}Summary and Outlook}{210}{section.12.11}%
\contentsline {section}{\numberline {12.12}Appendix}{211}{section.12.12}%
\contentsline {subsection}{\numberline {12.12.1}Sample Output From Ray Tune's Run}{211}{subsection.12.12.1}%
\contentsline {chapter}{\numberline {13}HPT: sklearn RandomForestClassifier VBDP Data}{212}{chapter.13}%
\contentsline {section}{\numberline {13.1}Step 1: Setup}{212}{section.13.1}%
\contentsline {section}{\numberline {13.2}Step 2: Initialization of the Empty \texttt {fun\_control} Dictionary}{213}{section.13.2}%
\contentsline {section}{\numberline {13.3}Step 3: PyTorch Data Loading}{213}{section.13.3}%
\contentsline {subsection}{\numberline {13.3.1}Load Data: Classification VBDP}{213}{subsection.13.3.1}%
\contentsline {subsection}{\numberline {13.3.2}Holdout Train and Test Data}{214}{subsection.13.3.2}%
\contentsline {section}{\numberline {13.4}Step 4: Specification of the Preprocessing Model}{215}{section.13.4}%
\contentsline {section}{\numberline {13.5}Step 5: Select Model (\texttt {algorithm}) and \texttt {core\_model\_hyper\_dict}}{215}{section.13.5}%
\contentsline {section}{\numberline {13.6}Step 6: Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{217}{section.13.6}%
\contentsline {subsection}{\numberline {13.6.1}Modify hyperparameter of type numeric and integer (boolean)}{217}{subsection.13.6.1}%
\contentsline {subsection}{\numberline {13.6.2}Modify hyperparameter of type factor}{217}{subsection.13.6.2}%
\contentsline {subsection}{\numberline {13.6.3}Optimizers}{218}{subsection.13.6.3}%
\contentsline {subsection}{\numberline {13.6.4}Selection of the Objective: Metric and Loss Functions}{218}{subsection.13.6.4}%
\contentsline {section}{\numberline {13.7}Step 7: Selection of the Objective (Loss) Function}{218}{section.13.7}%
\contentsline {subsection}{\numberline {13.7.1}Metric Function}{218}{subsection.13.7.1}%
\contentsline {subsubsection}{\numberline {13.7.1.1}The MAPK Metric}{219}{subsubsection.13.7.1.1}%
\contentsline {subsubsection}{\numberline {13.7.1.2}Other Metrics}{219}{subsubsection.13.7.1.2}%
\contentsline {subsection}{\numberline {13.7.2}Evaluation on Hold-out Data}{220}{subsection.13.7.2}%
\contentsline {subsection}{\numberline {13.7.3}OOB Score}{220}{subsection.13.7.3}%
\contentsline {subsubsection}{\numberline {13.7.3.1}Cross Validation}{220}{subsubsection.13.7.3.1}%
\contentsline {section}{\numberline {13.8}Step 8: Calling the SPOT Function}{221}{section.13.8}%
\contentsline {subsection}{\numberline {13.8.1}Preparing the SPOT Call}{221}{subsection.13.8.1}%
\contentsline {subsection}{\numberline {13.8.2}The Objective Function}{221}{subsection.13.8.2}%
\contentsline {subsection}{\numberline {13.8.3}Run the \texttt {Spot} Optimizer}{222}{subsection.13.8.3}%
\contentsline {section}{\numberline {13.9}Step 9: Tensorboard}{225}{section.13.9}%
\contentsline {section}{\numberline {13.10}Step 10: Results}{225}{section.13.10}%
\contentsline {subsection}{\numberline {13.10.1}Show variable importance}{226}{subsection.13.10.1}%
\contentsline {subsection}{\numberline {13.10.2}Get Default Hyperparameters}{226}{subsection.13.10.2}%
\contentsline {subsection}{\numberline {13.10.3}Get SPOT Results}{227}{subsection.13.10.3}%
\contentsline {subsection}{\numberline {13.10.4}Evaluate SPOT Results}{228}{subsection.13.10.4}%
\contentsline {subsection}{\numberline {13.10.5}Handling Non-deterministic Results}{229}{subsection.13.10.5}%
\contentsline {subsection}{\numberline {13.10.6}Evalution of the Default Hyperparameters}{229}{subsection.13.10.6}%
\contentsline {subsection}{\numberline {13.10.7}Plot: Compare Predictions}{230}{subsection.13.10.7}%
\contentsline {subsection}{\numberline {13.10.8}Cross-validated Evaluations}{230}{subsection.13.10.8}%
\contentsline {subsection}{\numberline {13.10.9}Detailed Hyperparameter Plots}{231}{subsection.13.10.9}%
\contentsline {subsection}{\numberline {13.10.10}Parallel Coordinates Plot}{233}{subsection.13.10.10}%
\contentsline {subsection}{\numberline {13.10.11}Plot all Combinations of Hyperparameters}{233}{subsection.13.10.11}%
\contentsline {chapter}{\numberline {14}HPT: sklearn XGB Classifier VBDP Data}{234}{chapter.14}%
\contentsline {section}{\numberline {14.1}Step 1: Setup}{234}{section.14.1}%
\contentsline {section}{\numberline {14.2}Step 2: Initialization of the Empty \texttt {fun\_control} Dictionary}{235}{section.14.2}%
\contentsline {section}{\numberline {14.3}Step 3: PyTorch Data Loading}{235}{section.14.3}%
\contentsline {subsection}{\numberline {14.3.1}1. Load Data: Classification VBDP}{235}{subsection.14.3.1}%
\contentsline {subsection}{\numberline {14.3.2}Holdout Train and Test Data}{236}{subsection.14.3.2}%
\contentsline {section}{\numberline {14.4}Step 4: Specification of the Preprocessing Model}{237}{section.14.4}%
\contentsline {section}{\numberline {14.5}Step 5: Select Model (\texttt {algorithm}) and \texttt {core\_model\_hyper\_dict}}{237}{section.14.5}%
\contentsline {section}{\numberline {14.6}Step 6: Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{239}{section.14.6}%
\contentsline {subsection}{\numberline {14.6.1}Modify hyperparameter of type numeric and integer (boolean)}{239}{subsection.14.6.1}%
\contentsline {subsection}{\numberline {14.6.2}Modify hyperparameter of type factor}{240}{subsection.14.6.2}%
\contentsline {subsection}{\numberline {14.6.3}Optimizers}{240}{subsection.14.6.3}%
\contentsline {section}{\numberline {14.7}Step 7: Selection of the Objective (Loss) Function}{240}{section.14.7}%
\contentsline {subsection}{\numberline {14.7.1}Evaluation}{240}{subsection.14.7.1}%
\contentsline {subsection}{\numberline {14.7.2}Selection of the Objective: Metric and Loss Functions}{240}{subsection.14.7.2}%
\contentsline {subsection}{\numberline {14.7.3}Loss Function}{241}{subsection.14.7.3}%
\contentsline {subsection}{\numberline {14.7.4}Metric Function}{241}{subsection.14.7.4}%
\contentsline {subsubsection}{\numberline {14.7.4.1}The MAPK Metric}{241}{subsubsection.14.7.4.1}%
\contentsline {subsubsection}{\numberline {14.7.4.2}Other Metrics}{241}{subsubsection.14.7.4.2}%
\contentsline {subsection}{\numberline {14.7.5}Evaluation on Hold-out Data}{242}{subsection.14.7.5}%
\contentsline {subsubsection}{\numberline {14.7.5.1}Cross Validation}{242}{subsubsection.14.7.5.1}%
\contentsline {section}{\numberline {14.8}Step 8: Calling the SPOT Function}{243}{section.14.8}%
\contentsline {subsection}{\numberline {14.8.1}Preparing the SPOT Call}{243}{subsection.14.8.1}%
\contentsline {subsection}{\numberline {14.8.2}The Objective Function}{243}{subsection.14.8.2}%
\contentsline {subsection}{\numberline {14.8.3}Run the \texttt {Spot} Optimizer}{244}{subsection.14.8.3}%
\contentsline {section}{\numberline {14.9}Step 9: Tensorboard}{245}{section.14.9}%
\contentsline {section}{\numberline {14.10}Step 10: Results}{245}{section.14.10}%
\contentsline {subsection}{\numberline {14.10.1}Show variable importance}{246}{subsection.14.10.1}%
\contentsline {subsection}{\numberline {14.10.2}Get Default Hyperparameters}{247}{subsection.14.10.2}%
\contentsline {subsection}{\numberline {14.10.3}Get SPOT Results}{248}{subsection.14.10.3}%
\contentsline {subsection}{\numberline {14.10.4}Evaluate SPOT Results}{248}{subsection.14.10.4}%
\contentsline {subsection}{\numberline {14.10.5}Handling Non-deterministic Results}{249}{subsection.14.10.5}%
\contentsline {subsection}{\numberline {14.10.6}Evalution of the Default Hyperparameters}{250}{subsection.14.10.6}%
\contentsline {subsection}{\numberline {14.10.7}Plot: Compare Predictions}{251}{subsection.14.10.7}%
\contentsline {subsection}{\numberline {14.10.8}Cross-validated Evaluations}{251}{subsection.14.10.8}%
\contentsline {subsection}{\numberline {14.10.9}Detailed Hyperparameter Plots}{252}{subsection.14.10.9}%
\contentsline {subsection}{\numberline {14.10.10}Parallel Coordinates Plot}{253}{subsection.14.10.10}%
\contentsline {subsection}{\numberline {14.10.11}Plot all Combinations of Hyperparameters}{253}{subsection.14.10.11}%
\contentsline {chapter}{\numberline {15}HPT: sklearn SVC VBDP Data}{255}{chapter.15}%
\contentsline {section}{\numberline {15.1}Step 1: Setup}{255}{section.15.1}%
\contentsline {section}{\numberline {15.2}Step 2: Initialization of the Empty \texttt {fun\_control} Dictionary}{256}{section.15.2}%
\contentsline {section}{\numberline {15.3}Step 3: PyTorch Data Loading}{256}{section.15.3}%
\contentsline {subsection}{\numberline {15.3.1}1. Load Data: Classification VBDP}{256}{subsection.15.3.1}%
\contentsline {subsection}{\numberline {15.3.2}Holdout Train and Test Data}{257}{subsection.15.3.2}%
\contentsline {section}{\numberline {15.4}Step 4: Specification of the Preprocessing Model}{258}{section.15.4}%
\contentsline {section}{\numberline {15.5}Step 5: Select Model (\texttt {algorithm}) and \texttt {core\_model\_hyper\_dict}}{258}{section.15.5}%
\contentsline {section}{\numberline {15.6}Step 6: Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{260}{section.15.6}%
\contentsline {subsection}{\numberline {15.6.1}Modify hyperparameter of type numeric and integer (boolean)}{260}{subsection.15.6.1}%
\contentsline {subsection}{\numberline {15.6.2}Modify hyperparameter of type factor}{260}{subsection.15.6.2}%
\contentsline {subsection}{\numberline {15.6.3}Optimizers}{261}{subsection.15.6.3}%
\contentsline {subsection}{\numberline {15.6.4}Selection of the Objective: Metric and Loss Functions}{261}{subsection.15.6.4}%
\contentsline {section}{\numberline {15.7}Step 7: Selection of the Objective (Loss) Function}{261}{section.15.7}%
\contentsline {subsection}{\numberline {15.7.1}Metric Function}{261}{subsection.15.7.1}%
\contentsline {subsubsection}{\numberline {15.7.1.1}The MAPK Metric}{262}{subsubsection.15.7.1.1}%
\contentsline {subsubsection}{\numberline {15.7.1.2}Other Metrics}{262}{subsubsection.15.7.1.2}%
\contentsline {subsection}{\numberline {15.7.2}Evaluation on Hold-out Data}{262}{subsection.15.7.2}%
\contentsline {subsubsection}{\numberline {15.7.2.1}Cross Validation}{263}{subsubsection.15.7.2.1}%
\contentsline {section}{\numberline {15.8}Step 8: Calling the SPOT Function}{263}{section.15.8}%
\contentsline {subsection}{\numberline {15.8.1}Preparing the SPOT Call}{263}{subsection.15.8.1}%
\contentsline {subsection}{\numberline {15.8.2}The Objective Function}{264}{subsection.15.8.2}%
\contentsline {subsection}{\numberline {15.8.3}Run the \texttt {Spot} Optimizer}{264}{subsection.15.8.3}%
\contentsline {section}{\numberline {15.9}Step 9: Tensorboard}{269}{section.15.9}%
\contentsline {section}{\numberline {15.10}Step 10: Results}{269}{section.15.10}%
\contentsline {subsection}{\numberline {15.10.1}Show variable importance}{270}{subsection.15.10.1}%
\contentsline {subsection}{\numberline {15.10.2}Get Default Hyperparameters}{270}{subsection.15.10.2}%
\contentsline {subsection}{\numberline {15.10.3}Get SPOT Results}{271}{subsection.15.10.3}%
\contentsline {subsection}{\numberline {15.10.4}Evaluate SPOT Results}{272}{subsection.15.10.4}%
\contentsline {subsection}{\numberline {15.10.5}Handling Non-deterministic Results}{273}{subsection.15.10.5}%
\contentsline {subsection}{\numberline {15.10.6}Evalution of the Default Hyperparameters}{273}{subsection.15.10.6}%
\contentsline {subsection}{\numberline {15.10.7}Plot: Compare Predictions}{274}{subsection.15.10.7}%
\contentsline {subsection}{\numberline {15.10.8}Cross-validated Evaluations}{274}{subsection.15.10.8}%
\contentsline {subsection}{\numberline {15.10.9}Detailed Hyperparameter Plots}{275}{subsection.15.10.9}%
\contentsline {subsection}{\numberline {15.10.10}Parallel Coordinates Plot}{276}{subsection.15.10.10}%
\contentsline {subsection}{\numberline {15.10.11}Plot all Combinations of Hyperparameters}{276}{subsection.15.10.11}%
\contentsline {chapter}{\numberline {16}HPT: sklearn KNN Classifier VBDP Data}{277}{chapter.16}%
\contentsline {section}{\numberline {16.1}Step 1: Setup}{277}{section.16.1}%
\contentsline {section}{\numberline {16.2}Step 2: Initialization of the Empty \texttt {fun\_control} Dictionary}{278}{section.16.2}%
\contentsline {subsection}{\numberline {16.2.1}Load Data: Classification VBDP}{278}{subsection.16.2.1}%
\contentsline {subsection}{\numberline {16.2.2}Holdout Train and Test Data}{279}{subsection.16.2.2}%
\contentsline {section}{\numberline {16.3}Step 4: Specification of the Preprocessing Model}{280}{section.16.3}%
\contentsline {section}{\numberline {16.4}Step 5: Select Model (\texttt {algorithm}) and \texttt {core\_model\_hyper\_dict}}{280}{section.16.4}%
\contentsline {section}{\numberline {16.5}Step 6: Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{282}{section.16.5}%
\contentsline {subsection}{\numberline {16.5.1}Modify hyperparameter of type numeric and integer (boolean)}{282}{subsection.16.5.1}%
\contentsline {subsection}{\numberline {16.5.2}Modify hyperparameter of type factor}{282}{subsection.16.5.2}%
\contentsline {subsection}{\numberline {16.5.3}Optimizers}{283}{subsection.16.5.3}%
\contentsline {subsection}{\numberline {16.5.4}Selection of the Objective: Metric and Loss Functions}{283}{subsection.16.5.4}%
\contentsline {section}{\numberline {16.6}Step 7: Selection of the Objective (Loss) Function}{283}{section.16.6}%
\contentsline {subsection}{\numberline {16.6.1}Metric Function}{283}{subsection.16.6.1}%
\contentsline {subsubsection}{\numberline {16.6.1.1}The MAPK Metric}{284}{subsubsection.16.6.1.1}%
\contentsline {subsubsection}{\numberline {16.6.1.2}Other Metrics}{284}{subsubsection.16.6.1.2}%
\contentsline {subsection}{\numberline {16.6.2}Evaluation on Hold-out Data}{284}{subsection.16.6.2}%
\contentsline {subsubsection}{\numberline {16.6.2.1}Cross Validation}{285}{subsubsection.16.6.2.1}%
\contentsline {section}{\numberline {16.7}Step 8: Calling the SPOT Function}{285}{section.16.7}%
\contentsline {subsection}{\numberline {16.7.1}Preparing the SPOT Call}{285}{subsection.16.7.1}%
\contentsline {subsection}{\numberline {16.7.2}The Objective Function}{286}{subsection.16.7.2}%
\contentsline {subsection}{\numberline {16.7.3}Run the \texttt {Spot} Optimizer}{286}{subsection.16.7.3}%
\contentsline {section}{\numberline {16.8}Step 9: Tensorboard}{290}{section.16.8}%
\contentsline {section}{\numberline {16.9}Step 10: Results}{290}{section.16.9}%
\contentsline {subsection}{\numberline {16.9.1}Show variable importance}{291}{subsection.16.9.1}%
\contentsline {subsection}{\numberline {16.9.2}Get Default Hyperparameters}{291}{subsection.16.9.2}%
\contentsline {subsection}{\numberline {16.9.3}Get SPOT Results}{292}{subsection.16.9.3}%
\contentsline {subsection}{\numberline {16.9.4}Evaluate SPOT Results}{292}{subsection.16.9.4}%
\contentsline {subsection}{\numberline {16.9.5}Handling Non-deterministic Results}{293}{subsection.16.9.5}%
\contentsline {subsection}{\numberline {16.9.6}Evalution of the Default Hyperparameters}{294}{subsection.16.9.6}%
\contentsline {subsection}{\numberline {16.9.7}Plot: Compare Predictions}{294}{subsection.16.9.7}%
\contentsline {subsection}{\numberline {16.9.8}Cross-validated Evaluations}{295}{subsection.16.9.8}%
\contentsline {subsection}{\numberline {16.9.9}Detailed Hyperparameter Plots}{296}{subsection.16.9.9}%
\contentsline {subsection}{\numberline {16.9.10}Parallel Coordinates Plot}{296}{subsection.16.9.10}%
\contentsline {subsection}{\numberline {16.9.11}Plot all Combinations of Hyperparameters}{296}{subsection.16.9.11}%
\contentsline {chapter}{\numberline {17}HPT PyTorch Lightning: VBDP}{298}{chapter.17}%
\contentsline {section}{\numberline {17.1}Step 1: Setup}{298}{section.17.1}%
\contentsline {section}{\numberline {17.2}Step 2: Initialization of the \texttt {fun\_control} Dictionary}{299}{section.17.2}%
\contentsline {section}{\numberline {17.3}Step 3: PyTorch Data Loading}{300}{section.17.3}%
\contentsline {subsection}{\numberline {17.3.1}Lightning Dataset and DataModule}{300}{subsection.17.3.1}%
\contentsline {section}{\numberline {17.4}Step 4: Preprocessing}{300}{section.17.4}%
\contentsline {section}{\numberline {17.5}Step 5: Select the NN Model (\texttt {algorithm}) and \texttt {core\_model\_hyper\_dict}}{300}{section.17.5}%
\contentsline {section}{\numberline {17.6}Step 6: Modify \texttt {hyper\_dict} Hyperparameters for the Selected Algorithm aka \texttt {core\_model}}{301}{section.17.6}%
\contentsline {section}{\numberline {17.7}Step 7: Data Splitting, the Objective (Loss) Function and the Metric}{302}{section.17.7}%
\contentsline {subsection}{\numberline {17.7.1}Evaluation}{302}{subsection.17.7.1}%
\contentsline {subsection}{\numberline {17.7.2}Loss Functions and Metrics}{302}{subsection.17.7.2}%
\contentsline {subsection}{\numberline {17.7.3}Metric}{303}{subsection.17.7.3}%
\contentsline {section}{\numberline {17.8}Step 8: Calling the SPOT Function}{303}{section.17.8}%
\contentsline {subsection}{\numberline {17.8.1}Preparing the SPOT Call}{303}{subsection.17.8.1}%
\contentsline {subsection}{\numberline {17.8.2}The Objective Function \texttt {fun}}{303}{subsection.17.8.2}%
\contentsline {subsection}{\numberline {17.8.3}Starting the Hyperparameter Tuning}{304}{subsection.17.8.3}%
\contentsline {section}{\numberline {17.9}Step 9: Tensorboard}{306}{section.17.9}%
\contentsline {section}{\numberline {17.10}Step 10: Results}{306}{section.17.10}%
\contentsline {subsection}{\numberline {17.10.1}Get the Tuned Architecture}{308}{subsection.17.10.1}%
\contentsline {subsection}{\numberline {17.10.2}Cross Validation With Lightning}{308}{subsection.17.10.2}%
\contentsline {subsection}{\numberline {17.10.3}Detailed Hyperparameter Plots}{312}{subsection.17.10.3}%
\contentsline {subsection}{\numberline {17.10.4}Parallel Coordinates Plot}{313}{subsection.17.10.4}%
\contentsline {subsection}{\numberline {17.10.5}Plot all Combinations of Hyperparameters}{313}{subsection.17.10.5}%
\contentsline {subsection}{\numberline {17.10.6}Visualizing the Activation Distribution}{314}{subsection.17.10.6}%
\contentsline {section}{\numberline {17.11}Submission}{315}{section.17.11}%
\contentsline {section}{\numberline {17.12}Appendix}{317}{section.17.12}%
\contentsline {subsection}{\numberline {17.12.1}Differences to the spotPython Approaches for \texttt {torch}, \texttt {sklearn} and \texttt {river}}{317}{subsection.17.12.1}%
\contentsline {subsubsection}{\numberline {17.12.1.1}Specification of the Preprocessing Model}{317}{subsubsection.17.12.1.1}%
\contentsline {subsection}{\numberline {17.12.2}Taking a Look at the Data}{318}{subsection.17.12.2}%
\contentsline {subsection}{\numberline {17.12.3}The MAPK Metric}{319}{subsection.17.12.3}%
\contentsline {part}{Appendices}{320}{section*.170}%
\contentsline {chapter}{\numberline {A}Documentation of the Sequential Parameter Optimization}{320}{appendix.A}%
\contentsline {section}{\numberline {A.1}Example: spot}{320}{section.A.1}%
\contentsline {subsection}{\numberline {A.1.1}The Objective Function}{320}{subsection.A.1.1}%
\contentsline {subsection}{\numberline {A.1.2}External Parameters}{321}{subsection.A.1.2}%
\contentsline {section}{\numberline {A.2}The \texttt {fun\_control} Dictionary}{325}{section.A.2}%
\contentsline {section}{\numberline {A.3}The \texttt {design\_control} Dictionary}{325}{section.A.3}%
\contentsline {section}{\numberline {A.4}The \texttt {surrogate\_control} Dictionary}{326}{section.A.4}%
\contentsline {section}{\numberline {A.5}The \texttt {optimizer\_control} Dictionary}{326}{section.A.5}%
\contentsline {section}{\numberline {A.6}Run}{327}{section.A.6}%
\contentsline {section}{\numberline {A.7}Print the Results}{327}{section.A.7}%
\contentsline {section}{\numberline {A.8}Show the Progress}{328}{section.A.8}%
\contentsline {section}{\numberline {A.9}Visualize the Surrogate}{328}{section.A.9}%
\contentsline {section}{\numberline {A.10}Init: Build Initial Design}{328}{section.A.10}%
\contentsline {section}{\numberline {A.11}Replicability}{329}{section.A.11}%
\contentsline {section}{\numberline {A.12}Surrogates}{330}{section.A.12}%
\contentsline {subsection}{\numberline {A.12.1}A Simple Predictor}{330}{subsection.A.12.1}%
\contentsline {section}{\numberline {A.13}Demo/Test: Objective Function Fails}{330}{section.A.13}%
\contentsline {section}{\numberline {A.14}PyTorch: Detailed Description of the Data Splitting}{333}{section.A.14}%
\contentsline {subsection}{\numberline {A.14.1}Description of the \texttt {"train\_hold\_out"} Setting}{333}{subsection.A.14.1}%
\contentsline {subsubsection}{\numberline {A.14.1.1}Description of the \texttt {"test\_hold\_out"} Setting}{336}{subsubsection.A.14.1.1}%
\contentsline {subsubsection}{\numberline {A.14.1.2}Detailed Description of the \texttt {"train\_cv"} Setting}{337}{subsubsection.A.14.1.2}%
\contentsline {subsubsection}{\numberline {A.14.1.3}Detailed Description of the \texttt {"test\_cv"} Setting}{341}{subsubsection.A.14.1.3}%
\contentsline {subsubsection}{\numberline {A.14.1.4}Detailed Description of the Final Model Training and Evaluation}{341}{subsubsection.A.14.1.4}%
\contentsline {chapter}{References}{344}{chapter*.177}%
\providecommand \tocbasic@end@toc@file {}\tocbasic@end@toc@file 
