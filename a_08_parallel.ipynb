{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "execute:\n",
        "  cache: false\n",
        "  eval: true\n",
        "  echo: true\n",
        "  warning: false\n",
        "jupyter: python3\n",
        "---\n",
        "\n",
        "# Parallelism in Initial Design\n",
        "\n",
        "In `spotpython`, we provide a wrapper function, that encapsulates the objective function to enable its parallel execution via `multiprocessing` or `joblib`, allowing multiple configurations to be evaluated at the same time.\n",
        "\n",
        "\n",
        "## Setup\n",
        "\n",
        "To demonstrate the performance gain enabled by parallelization, we use a similar example to that in Section 47, where we perform hyperparameter tuning with `spotpython`and `PyTorch` Lightning on the Diabetes dataset using a ResNet model. We compare the time required with and without parallelization.\n",
        "First, we import the necessary libraries, including the wrapper function `make_parallel`. We then define the `fun_control` and `design_control` settings. For `design_control`, we deliberately choose an initial design size of `10` for demonstration purposes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: setup-a_08\n",
        "import time\n",
        "from math import inf\n",
        "import multiprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from spotpython.data.diabetes import Diabetes\n",
        "from spotpython.hyperdict.light_hyper_dict import LightHyperDict\n",
        "from spotpython.fun.hyperlight import HyperLight\n",
        "from spotpython.utils.init import (fun_control_init, design_control_init)\n",
        "from spotpython.hyperparameters.values import set_hyperparameter\n",
        "from spotpython.spot import Spot\n",
        "from spotpython.utils.parallel import make_parallel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: setup-a_08-spot\n",
        "dataset = Diabetes()\n",
        "fun_control = fun_control_init(\n",
        "    fun_evals=10,\n",
        "    max_time=inf,\n",
        "    data_set=dataset,\n",
        "    core_model_name=\"light.regression.NNResNetRegressor\",\n",
        "    hyperdict=LightHyperDict,\n",
        "    _L_in=10,\n",
        "    _L_out=1,\n",
        "    seed=125,\n",
        "    tensorboard_log=False,\n",
        "    TENSORBOARD_CLEAN=False,\n",
        ")\n",
        "set_hyperparameter(fun_control, \"optimizer\", [\"Adadelta\", \"Adam\", \"Adamax\"])\n",
        "set_hyperparameter(fun_control, \"l1\", [2, 5])\n",
        "set_hyperparameter(fun_control, \"epochs\", [5, 8])\n",
        "set_hyperparameter(fun_control, \"batch_size\", [5, 8])\n",
        "set_hyperparameter(fun_control, \"dropout_prob\", [0.0, 0.5])\n",
        "set_hyperparameter(fun_control, \"patience\", [2, 3])\n",
        "set_hyperparameter(fun_control, \"lr_mult\", [0.1, 10.0])\n",
        "\n",
        "design_control = design_control_init(\n",
        "    init_size=10\n",
        ")\n",
        "\n",
        "fun = HyperLight().fun"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiments\n",
        "\n",
        "We now measure the time required for sequential and parallel evaluation, beginning with the sequential approach.\n",
        "\n",
        "### Sequential Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: run-a_08_sequential\n",
        "tic = time.perf_counter()\n",
        "spot_tuner = Spot(fun=fun, fun_control=fun_control, design_control=design_control)\n",
        "res = spot_tuner.run()\n",
        "toc = time.perf_counter()\n",
        "time_seq = toc - tic\n",
        "print(f\"Time taken for sequential execution: {time_seq:.2f} seconds\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parallel Execution\n",
        "\n",
        "To use `make_parallel`, the number of cores must be specified via the `num_cores` parameter.\n",
        "By default, the function utilizes `multiprocessing`, but other parallelization methods can be selected using the `method` argument.\n",
        "The following two lines of code demonstrate how to set up the parallel function and run the `Spot` tuner with it.\n",
        "\n",
        "* `parallel_fun = make_parallel(fun, num_cores=num_cores)`\n",
        "* `spot_parallel_tuner = Spot(fun=parallel_fun, fun_control=fun_control, design_control=design_control)`\n",
        "\n",
        "We consider parallel efficiency, a metric that measures how effectively additional computational resources (cores/processors) are being utilized in a parallel computation. It's calculated as:\n",
        "$$\n",
        "\\text{Efficiency} = \\frac{\\text{Speedup}}{\\text{Number of Processors}},\n",
        "$$\n",
        "where:\n",
        "\n",
        "* Speedup = Time(Sequential) / Time(Parallel)\n",
        "* Number of Processors = Number of cores used\n",
        "\n",
        "It can be interpreted as follows:\n",
        "\n",
        "* 1.0 (100%): Perfect linear scaling - doubling cores halves execution time\n",
        "* 0.8-0.9 (80-90%): Excellent scaling - minimal parallelization overhead\n",
        "* 0.5-0.7 (50-70%): Good scaling - reasonable utilization of additional cores\n",
        "* <0.5 (<50%): Poor scaling - diminishing returns from adding more cores\n",
        "\n",
        "When efficiency drops significantly as you add cores, it indicates:\n",
        "\n",
        "* Communication overhead increasing\n",
        "* Synchronization bottlenecks\n",
        "* Load imbalance between cores\n",
        "* Portions of code that remain sequential (Amdahl's Law limitation)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: run-a_08-parallel-comparison\n",
        "# Get available cores\n",
        "available_cores = multiprocessing.cpu_count()\n",
        "print(f\"Available cores: {available_cores}\")\n",
        "\n",
        "# Generate list of cores to test (powers of 2 up to available cores)\n",
        "cores_to_test = []\n",
        "power = 0\n",
        "while 2**(power+1) < available_cores:\n",
        "    cores_to_test.append(2**power)\n",
        "    power += 1\n",
        "\n",
        "# If the number of available cores is not a power of 2, add it to the list\n",
        "if available_cores not in cores_to_test:\n",
        "    cores_to_test.append(available_cores)\n",
        "\n",
        "# Prepare DataFrame to store results\n",
        "results_df = pd.DataFrame(columns=[\"number_of_cores\", \"time\"])\n",
        "\n",
        "# Run the experiment for each core count\n",
        "for num_cores in cores_to_test:\n",
        "    print(f\"\\nTesting with {num_cores} cores...\")\n",
        "    tic = time.perf_counter()\n",
        "    parallel_fun = make_parallel(fun, num_cores=num_cores)\n",
        "    spot_parallel_tuner = Spot(fun=parallel_fun, fun_control=fun_control, design_control=design_control)\n",
        "    res = spot_parallel_tuner.run()\n",
        "    toc = time.perf_counter()\n",
        "    time_taken = toc - tic\n",
        "\n",
        "    # Add result to DataFrame\n",
        "    results_df = pd.concat([results_df, pd.DataFrame({\n",
        "        \"number_of_cores\": [num_cores],\n",
        "        \"time\": [time_taken]\n",
        "    })], ignore_index=True)\n",
        "\n",
        "    print(f\"Time taken with {num_cores} cores: {time_taken:.2f} seconds\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"\\nPerformance comparison across different numbers of cores:\")\n",
        "results_df[\"speedup_vs_sequential\"] = time_seq / results_df[\"time\"]\n",
        "results_df[\"efficiency\"] = results_df[\"speedup_vs_sequential\"] / results_df[\"number_of_cores\"]\n",
        "print(results_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: run-a_08-parallel-comparison-plot\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Execution time vs number of cores\n",
        "ax1.plot(results_df[\"number_of_cores\"], results_df[\"time\"], marker='o', linestyle='-')\n",
        "ax1.set_xlabel(\"Number of cores\")\n",
        "ax1.set_ylabel(\"Execution time (seconds)\")\n",
        "ax1.set_title(\"Execution Time vs Number of Cores\")\n",
        "ax1.grid(True)\n",
        "\n",
        "# Speedup vs number of cores\n",
        "ax1.axhline(y=time_seq, color='r', linestyle='--', label=f'Sequential ({time_seq:.2f}s)')\n",
        "ax1.legend()\n",
        "\n",
        "# Parallel efficiency\n",
        "ax2.plot(results_df[\"number_of_cores\"], results_df[\"efficiency\"], marker='o', linestyle='-')\n",
        "ax2.set_xlabel(\"Number of cores\")\n",
        "ax2.set_ylabel(\"Parallel efficiency\")\n",
        "ax2.set_title(\"Parallel Efficiency vs Number of Cores\")\n",
        "ax2.set_ylim(0, 1.1)\n",
        "ax2.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::{.callout-note}\n",
        "#### Operating-system Differences in Parallelization Methods\n",
        "\n",
        "Linux uses the `fork` method by default to start new processes, whereas macOS and Windows use the `spawn` method. This leads to differences in how processes are handled across operating systems. We use the functionality of `set_all_seeds` to ensure that the evaluation remains reproducible across all operating systems.\n",
        "\n",
        ":::\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/bartz/miniforge3/envs/spot313/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}