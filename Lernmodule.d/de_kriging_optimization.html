<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="de" xml:lang="de"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>de_kriging_optimization</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="de_kriging_optimization_files/libs/clipboard/clipboard.min.js"></script>
<script src="de_kriging_optimization_files/libs/quarto-html/quarto.js" type="module"></script>
<script src="de_kriging_optimization_files/libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="de_kriging_optimization_files/libs/quarto-html/popper.min.js"></script>
<script src="de_kriging_optimization_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="de_kriging_optimization_files/libs/quarto-html/anchor.min.js"></script>
<link href="de_kriging_optimization_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="de_kriging_optimization_files/libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="de_kriging_optimization_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="de_kriging_optimization_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="de_kriging_optimization_files/libs/bootstrap/bootstrap-81267100e462c21b3d6c0d5bf76a3417.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent quarto-light">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Kriging-Basisfunktionen (Definition der Korrelation)</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="lernmodul-erweiterung-des-kriging-modells-numerische-optimierung-der-hyperparameter" class="level1">
<h1>Lernmodul: Erweiterung des Kriging-Modells: Numerische Optimierung der Hyperparameter</h1>
<section id="einleitung" class="level2">
<h2 class="anchored" data-anchor-id="einleitung">Einleitung</h2>
<p>Das vorhergehende Lernmodul hat die konzeptionellen Grundlagen und die mathematische Architektur von Kriging-Modellen vorgestellt, illustriert am Beispiel der Sinusfunktion. In dieser Einführung wurde der Aktivitätsparameter <span class="math inline">\(\theta\)</span> aus Gründen der Einfachheit auf einen festen Wert (1.0) gesetzt. In realen Anwendungen ist es jedoch entscheidend, diese Parameter optimal aus den vorliegenden Daten zu bestimmen, um die bestmögliche Modellgüte zu erzielen.</p>
<p>Dieses Dokument baut auf dem bestehenden Wissen auf und erläutert, wie die Kriging-Hyperparameter, insbesondere der Aktivitätsparameter <span class="math inline">\(\theta\)</span>, numerisch optimiert werden können. Wir werden uns auf die Maximierung der sogenannten “konzentrierten Log-Likelihood-Funktion” konzentrieren, einem gängigen Ansatz zur Parameterschätzung in Kriging-Modellen. Die gezeigte Python-Code-Erweiterung des Sinusfunktions-Beispiels verdeutlicht die praktische Umsetzung.</p>
</section>
<section id="kriging-hyperparameter-theta-vectheta-und-p-vecp" class="level2">
<h2 class="anchored" data-anchor-id="kriging-hyperparameter-theta-vectheta-und-p-vecp">Kriging-Hyperparameter: Theta (<span class="math inline">\(\vec{\theta}\)</span>) und p (<span class="math inline">\(\vec{p}\)</span>)</h2>
<p>Im Kriging-Modell steuern zwei wichtige Vektoren von Hyperparametern die Form und die Eigenschaften der Korrelationsfunktion:</p>
<ul>
<li><strong>Aktivitätsparameter <span class="math inline">\(\vec{\theta} = (\theta_1, \theta_2, \ldots, \theta_k)^T\)</span></strong>: Dieser Vektor regelt, wie schnell die Korrelation zwischen zwei Punkten mit zunehmendem Abstand in jeder Dimension abfällt. Ein großer Wert für <span class="math inline">\(\theta_j\)</span> in einer Dimension <span class="math inline">\(j\)</span> bedeutet, dass die Funktion in dieser Dimension sehr “aktiv” ist oder sich schnell ändert, und somit nur Punkte in unmittelbarer Nähe stark korrelieren. Dies ermöglicht eine automatische Relevanzbestimmung, bei der wichtige Variablen durch höhere <span class="math inline">\(\theta\)</span>-Werte identifiziert werden können.</li>
<li><strong>Glattheitsparameter <span class="math inline">\(\vec{p} = (p_1, p_2, \ldots, p_k)^T\)</span></strong>: Dieser Vektor beeinflusst die Glattheit der Vorhersagefunktion in jeder Dimension. Üblicherweise liegen die Werte für <span class="math inline">\(p_j\)</span> zwischen 1 und 2. Im vorherigen Lernmodul wurde implizit <span class="math inline">\(p_j=2\)</span> verwendet (durch die “sqeuclidean”-Distanzmetrik), was zu unendlich differenzierbaren, sehr glatten Funktionen führt. Eine Optimierung von <span class="math inline">\(\vec{p}\)</span> ist möglich, wird aber in diesem Beispiel aus Gründen der Komplexität ausgeklammert, da <span class="math inline">\(p_j=2\)</span> oft als Standard für glatte Funktionen angenommen wird.</li>
</ul>
</section>
<section id="die-notwendigkeit-der-optimierung-die-konzentrierte-log-likelihood" class="level2">
<h2 class="anchored" data-anchor-id="die-notwendigkeit-der-optimierung-die-konzentrierte-log-likelihood">Die Notwendigkeit der Optimierung: Die konzentrierte Log-Likelihood</h2>
<p>Um die optimalen Werte für <span class="math inline">\(\vec{\theta}\)</span> (und <span class="math inline">\(\vec{p}\)</span>) zu finden, wird häufig die Maximum-Likelihood-Schätzung (MLE) verwendet. Die Grundidee der MLE besteht darin, diejenigen Parameterwerte zu finden, die die Wahrscheinlichkeit maximieren, die tatsächlich beobachteten Daten zu erhalten.</p>
<p>Die zu maximierende Funktion ist die <strong>Log-Likelihood-Funktion</strong>. Für gegebene <span class="math inline">\(\vec{\theta}\)</span> und <span class="math inline">\(\vec{p}\)</span> (und somit eine feste Korrelationsmatrix <span class="math inline">\(\Psi\)</span>) können die Schätzer für den globalen Mittelwert <span class="math inline">\(\hat{\mu}\)</span> und die Prozessvarianz <span class="math inline">\(\hat{\sigma}^2\)</span> analytisch abgeleitet werden. Durch Einsetzen dieser Schätzer in die Log-Likelihood-Funktion erhalten wir die sogenannte <strong>konzentrierte Log-Likelihood-Funktion</strong>:</p>
<p><span class="math display">\[
\ln(L) \approx - \frac{n}{2} \ln(\hat{\sigma}^2) - \frac{1}{2} \ln |\vec{\Psi}|
\]</span></p>
<p>Hierbei ist:</p>
<ul>
<li><span class="math inline">\(n\)</span>: Die Anzahl der Beobachtungspunkte.</li>
<li><span class="math inline">\(\hat{\sigma}^2\)</span>: Der Maximum-Likelihood-Schätzer der Prozessvarianz.</li>
<li><span class="math inline">\(|\vec{\Psi}|\)</span>: Die Determinante der Korrelationsmatrix <span class="math inline">\(\vec{\Psi}\)</span>.</li>
</ul>
<p>Die direkte Maximierung dieser Funktion ist mathematisch schwierig, da sie bezüglich <span class="math inline">\(\vec{\theta}\)</span> und <span class="math inline">\(\vec{p}\)</span> nicht analytisch differenzierbar ist. Daher wird eine <strong>numerische Optimierung</strong> eingesetzt, um die Parameter zu finden, die die konzentrierte Log-Likelihood maximieren.</p>
</section>
<section id="numerische-optimierungsalgorithmen" class="level2">
<h2 class="anchored" data-anchor-id="numerische-optimierungsalgorithmen">Numerische Optimierungsalgorithmen</h2>
<p>Für die numerische Optimierung der Parameter <span class="math inline">\(\vec{\theta}\)</span> und <span class="math inline">\(\vec{p}\)</span> können verschiedene Algorithmen verwendet werden, darunter:</p>
<ul>
<li>Nelder-Mead-Simplex-Verfahren</li>
<li>Konjugierte Gradienten-Verfahren</li>
<li>Simulated Annealing</li>
<li>Differential Evolution</li>
</ul>
<p>Die <code>scipy.optimize</code>-Bibliothek in Python bietet eine umfassende Sammlung solcher Optimierungsfunktionen. Da die meisten Optimierungsalgorithmen in <code>scipy.optimize</code> auf Minimierung ausgelegt sind, wird die <strong>negative</strong> konzentrierte Log-Likelihood-Funktion als Optimierungsziel verwendet.</p>
<p>Ein wichtiger numerischer Aspekt bei der Berechnung der Log-Likelihood ist die Determinante von <span class="math inline">\(\Psi\)</span>. Für schlecht konditionierte Matrizen kann <span class="math inline">\(|\Psi|\)</span> gegen Null gehen, was zu numerischer Instabilität führen kann. Um dies zu vermeiden, wird der Logarithmus der Determinante <span class="math inline">\(\ln(|\Psi|)\)</span> stabiler berechnet, indem man die Cholesky-Zerlegung <span class="math inline">\(\Psi = L L^T\)</span> nutzt und dann <span class="math inline">\(\ln(|\Psi|) = 2 \sum_{i=1}^{n} \ln(L_{ii})\)</span> berechnet.</p>
<p>Für die Suche nach <span class="math inline">\(\theta\)</span> ist es sinnvoll, Suchbereiche auf einer logarithmischen Skala zu definieren, typischerweise von <span class="math inline">\(10^{-3}\)</span> bis <span class="math inline">\(10^2\)</span>. Es ist auch ratsam, die Eingabedaten auf den Bereich zwischen Null und Eins zu skalieren, um die Konsistenz der <span class="math inline">\(\theta\)</span>-Werte über verschiedene Probleme hinweg zu gewährleisten.</p>
</section>
<section id="erweiterung-des-sinusfunktions-beispiels-mit-hyperparameter-optimierung" class="level2">
<h2 class="anchored" data-anchor-id="erweiterung-des-sinusfunktions-beispiels-mit-hyperparameter-optimierung">Erweiterung des Sinusfunktions-Beispiels mit Hyperparameter-Optimierung</h2>
<p>Wir erweitern nun den Beispielcode aus dem “Lernmodul: Eine Einführung in Kriging” (Kriging-Anpassung an eine Sinusfunktion mit 8 Punkten), um den Aktivitätsparameter <span class="math inline">\(\theta\)</span> numerisch zu optimieren. Hier verwenden wir nur vier statt der ursprünglichen acht Trainingspunkte, um die Kriging-Vorhersage mit den optimierten und festen <span class="math inline">\(\theta\)</span>-Werten zu vergleichen.</p>
<p>Die Hauptänderung besteht in der Definition einer neuen Zielfunktion, <code>neg_log_likelihood</code>, die von <code>scipy.optimize.minimize</code> minimiert wird. Diese Funktion nimmt die zu optimierenden Parameter (hier <code>theta</code>) entgegen und berechnet die negative konzentrierte Log-Likelihood basierend auf den Trainingsdaten.</p>
<div id="f8f948c1" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> (exp, multiply, eye, linspace, spacing, sqrt)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy.linalg <span class="im">import</span> cholesky, solve</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.spatial.distance <span class="im">import</span> squareform, pdist, cdist</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.optimize <span class="im">import</span> minimize <span class="co"># Für die Optimierung</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Der Kernel von Kriging verwendet eine spezialisierte Basisfunktion für die Korrelation: <span class="math display">\[
\psi(x^{(i)}, x) = \exp(- \sum_{j=1}^k \theta_j |x_j^{(i)} - x_j|^{p_j}).
\]</span></p>
<p>Für dieses 1D-Beispiel (<span class="math inline">\(k=1\)</span>) und mit <span class="math inline">\(p_j=2\)</span> (quadratische euklidische Distanz implizit durch <code>pdist</code>-Nutzung) und <span class="math inline">\(\theta_j = \theta\)</span> (ein einzelner Wert) vereinfacht es sich.</p>
<div id="a1f036fb" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_Psi(X, theta, eps<span class="op">=</span>sqrt(spacing(<span class="dv">1</span>))):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Berechnet die Korrelationsmatrix Psi basierend auf paarweisen quadratischen</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co">    euklidischen Distanzen zwischen Eingabelokationen, skaliert mit theta.</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Fügt ein kleines Epsilon zur Diagonalen für numerische Stabilität hinzu (Nugget-Effekt).</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Hinweis: p_j ist implizit 2 aufgrund der 'sqeuclidean'-Metrik.</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sicherstellen, dass theta ein 1D-Array für das 'w'-Argument von cdist/pdist ist</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(theta, np.ndarray) <span class="kw">or</span> theta.ndim <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>        theta <span class="op">=</span> np.array([theta])</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    D <span class="op">=</span> squareform(pdist(X, metric<span class="op">=</span><span class="st">'sqeuclidean'</span>, w<span class="op">=</span>theta))</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    Psi <span class="op">=</span> exp(<span class="op">-</span>D)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ein kleiner Wert wird zur Diagonalen hinzugefügt für numerische Stabilität (Nugget)</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Korrektur: X.shape für die Anzahl der Zeilen der Identitätsmatrix</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    Psi <span class="op">+=</span> multiply(eye(X.shape[<span class="dv">0</span>]), eps)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Psi</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_psi(X_train, x_predict, theta):</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="co">    Berechnet den Korrelationsvektor (oder Matrix) psi zwischen neuen Vorhersageorten</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="co">    und Trainingsdatenlokationen.</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sicherstellen, dass theta ein 1D-Array für das 'w'-Argument von cdist/pdist ist</span></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(theta, np.ndarray) <span class="kw">or</span> theta.ndim <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>        theta <span class="op">=</span> np.array([theta])</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>    D <span class="op">=</span> cdist(x_predict, X_train, metric<span class="op">=</span><span class="st">'sqeuclidean'</span>, w<span class="op">=</span>theta)</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>    psi <span class="op">=</span> exp(<span class="op">-</span>D)</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> psi.T <span class="co"># Transponieren, um konsistent mit der Literatur zu sein (n x m oder n x 1)</span></span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="zielfunktion-für-die-hyperparameter-optimierung-negative-log-likelihood" class="level3">
<h3 class="anchored" data-anchor-id="zielfunktion-für-die-hyperparameter-optimierung-negative-log-likelihood">Zielfunktion für die Hyperparameter-Optimierung (Negative Log-Likelihood)</h3>
<div id="59fa84fa" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> neg_log_likelihood(params, X_train, y_train):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Berechnet die negative konzentrierte Log-Likelihood für das Kriging-Modell.</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co">    params: ein 1D-Numpy-Array, wobei params theta ist.</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co">            (Falls auch p optimiert würde, wäre es params usw.)</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co">    X_train: (n, k)-Matrix der Trainings-Eingabelokationen</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co">    y_train: (n, 1)-Vektor der Trainings-Ausgabewerte</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    theta <span class="op">=</span> params</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Für dieses Beispiel ist p implizit auf 2 festgelegt (durch 'sqeuclidean' in build_Psi)</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Falls p optimiert würde, müsste es hier aus 'params' extrahiert und an build_Psi übergeben werden</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> X_train.shape[<span class="dv">0</span>]</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1. Korrelationsmatrix Psi aufbauen</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    Psi <span class="op">=</span> build_Psi(X_train, theta)</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2. mu_hat berechnen (MLE des Mittelwerts)</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Verwendung der Cholesky-Zerlegung für stabile Inversion</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># numpy.cholesky gibt L (untere Dreiecksmatrix) zurück, daher transponieren für U (obere)</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>        U <span class="op">=</span> cholesky(Psi).T</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> np.linalg.LinAlgError:</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Bei Fehlern (z.B. wenn Psi nicht positiv definit ist, durch schlechte theta-Werte)</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># einen sehr großen Wert zurückgeben, um diese Parameter zu bestrafen</span></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="fl">1e15</span></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>    one <span class="op">=</span> np.ones(n).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Stabile Berechnung von Psi_inv @ y und Psi_inv @ one</span></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>    Psi_inv_y <span class="op">=</span> solve(U, solve(U.T, y_train))</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>    Psi_inv_one <span class="op">=</span> solve(U, solve(U.T, one))</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Berechnung von mu_hat</span></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>    mu_hat <span class="op">=</span> (one.T <span class="op">@</span> Psi_inv_y) <span class="op">/</span> (one.T <span class="op">@</span> Psi_inv_one)</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>    mu_hat <span class="op">=</span> mu_hat.item() <span class="co"># Skalaren Wert extrahieren</span></span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3. sigma_hat_sq berechnen (MLE der Prozessvarianz)</span></span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>    y_minus_mu_one <span class="op">=</span> y_train <span class="op">-</span> one <span class="op">*</span> mu_hat</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Korrekte Berechnung: (y-1*mu_hat).T @ Psi_inv @ (y-1*mu_hat) / n</span></span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>    sigma_hat_sq <span class="op">=</span> (y_minus_mu_one.T <span class="op">@</span> solve(U, solve(U.T, y_minus_mu_one))) <span class="op">/</span> n</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>    sigma_hat_sq <span class="op">=</span> sigma_hat_sq.item()</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> sigma_hat_sq <span class="op">&lt;</span> <span class="fl">1e-10</span>: <span class="co"># Sicherstellen, dass sigma_hat_sq nicht-negativ und nicht zu klein ist</span></span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="fl">1e15</span> <span class="co"># Sehr großen Wert zurückgeben zur Bestrafung</span></span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 4. Log-Determinante von Psi mittels Cholesky-Zerlegung für Stabilität berechnen</span></span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ln(|Psi|) = 2 * Summe(ln(L_ii)) wobei L die untere Dreiecksmatrix der Cholesky-Zerlegung ist</span></span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a>    log_det_Psi <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> np.<span class="bu">sum</span>(np.log(np.diag(U.T))) <span class="co"># U.T ist L</span></span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 5. Negative konzentrierte Log-Likelihood berechnen</span></span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ln(L) = - (n/2) * ln(sigma_hat_sq) - (1/2) * ln(|Psi|)</span></span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Zu minimieren ist -ln(L)</span></span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a>    nll <span class="op">=</span> <span class="fl">0.5</span> <span class="op">*</span> n <span class="op">*</span> np.log(sigma_hat_sq) <span class="op">+</span> <span class="fl">0.5</span> <span class="op">*</span> log_det_Psi</span>
<span id="cb3-53"><a href="#cb3-53" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> nll</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="datenpunkte-für-das-sinusfunktions-beispiel" class="level3">
<h3 class="anchored" data-anchor-id="datenpunkte-für-das-sinusfunktions-beispiel">Datenpunkte für das Sinusfunktions-Beispiel</h3>
<p>Das Beispiel verwendet eine 1D-Sinusfunktion, gemessen an vier gleichmäßig verteilten x-Lokationen. Wir verwenden nur vier Trainingspunkte, um die Kriging-Vorhersage mit den optimierten und festen <span class="math inline">\(\theta\)</span>-Werten zu vergleichen.</p>
<div id="c2262f9a" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>n_train <span class="op">=</span> <span class="dv">4</span> <span class="co"># Anzahl der Stichprobenlokationen</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">2</span> <span class="op">*</span> np.pi, n_train, endpoint<span class="op">=</span><span class="va">False</span>).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>) <span class="co"># x-Lokationen generieren</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> np.sin(X_train) <span class="co"># Zugehörige y-Werte (Sinus von x)</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Originale Vorhersage-Einrichtung (festes theta=1.0) ---</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>theta_fixed <span class="op">=</span> np.array([<span class="fl">1.0</span>])</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>Psi_fixed <span class="op">=</span> build_Psi(X_train, theta_fixed)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>U_fixed <span class="op">=</span> cholesky(Psi_fixed).T</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>one_fixed <span class="op">=</span> np.ones(n_train).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>mu_hat_fixed <span class="op">=</span> (one_fixed.T <span class="op">@</span> solve(U_fixed, solve(U_fixed.T, y_train))) <span class="op">/</span> <span class="op">\</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>               (one_fixed.T <span class="op">@</span> solve(U_fixed, solve(U_fixed.T, one_fixed)))</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>mu_hat_fixed <span class="op">=</span> mu_hat_fixed.item()</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>m_predict <span class="op">=</span> <span class="dv">100</span> <span class="co"># Anzahl der neuen Lokationen für die Vorhersage</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>x_predict <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">2</span> <span class="op">*</span> np.pi, m_predict, endpoint<span class="op">=</span><span class="va">True</span>).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>psi_fixed <span class="op">=</span> build_psi(X_train, x_predict, theta_fixed)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>f_predict_fixed <span class="op">=</span> mu_hat_fixed <span class="op">*</span> np.ones(m_predict).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>) <span class="op">+</span> <span class="op">\</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>                  psi_fixed.T <span class="op">@</span> solve(U_fixed, solve(U_fixed.T, y_train <span class="op">-</span> one_fixed <span class="op">*</span> mu_hat_fixed))</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="optimierung-von-theta" class="level3">
<h3 class="anchored" data-anchor-id="optimierung-von-theta">Optimierung von Theta</h3>
<div id="b472fd32" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>initial_theta_guess <span class="op">=</span> np.array([<span class="fl">1.0</span>]) <span class="co"># Startwert für Theta</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Suchbereiche für Theta (z.B. von 1e-3 bis 1e2 auf linearer Skala, wie in den Quellen empfohlen)</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># SciPy minimize erwartet Suchbereiche als Tupel von (min, max) für jeden Parameter</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>bounds <span class="op">=</span> [(<span class="fl">0.001</span>, <span class="fl">100.0</span>)] <span class="co"># Für Theta</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Starte Hyperparameter-Optimierung für Theta ---"</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 'L-BFGS-B' wird verwendet, da es Beschränkungen (bounds) unterstützt und gut für kontinuierliche Optimierung ist.</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> minimize(neg_log_likelihood, initial_theta_guess, args<span class="op">=</span>(X_train, y_train),</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>                  method<span class="op">=</span><span class="st">'L-BFGS-B'</span>, bounds<span class="op">=</span>bounds)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>optimized_theta <span class="op">=</span> result.x</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>optimized_nll <span class="op">=</span> result.fun</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Optimierung erfolgreich: </span><span class="sc">{</span>result<span class="sc">.</span>success<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Optimales Theta: </span><span class="sc">{</span>optimized_theta[<span class="dv">0</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)  <span class="co"># Extract the first element if it's a single value</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Minimaler Negativer Log-Likelihood: </span><span class="sc">{</span>optimized_nll<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
--- Starte Hyperparameter-Optimierung für Theta ---
Optimierung erfolgreich: True
Optimales Theta: 0.3157
Minimaler Negativer Log-Likelihood: -1.4767</code></pre>
</div>
</div>
</section>
<section id="vorhersage-mit-optimiertem-theta" class="level3">
<h3 class="anchored" data-anchor-id="vorhersage-mit-optimiertem-theta">Vorhersage mit optimiertem Theta</h3>
<div id="ac80c796" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>Psi_optimized <span class="op">=</span> build_Psi(X_train, optimized_theta)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>U_optimized <span class="op">=</span> cholesky(Psi_optimized).T</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>one_optimized <span class="op">=</span> np.ones(n_train).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>mu_hat_optimized <span class="op">=</span> (one_optimized.T <span class="op">@</span> solve(U_optimized, solve(U_optimized.T, y_train))) <span class="op">/</span> <span class="op">\</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>                   (one_optimized.T <span class="op">@</span> solve(U_optimized, solve(U_optimized.T, one_optimized)))</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>mu_hat_optimized <span class="op">=</span> mu_hat_optimized.item()</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>psi_optimized <span class="op">=</span> build_psi(X_train, x_predict, optimized_theta)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>f_predict_optimized <span class="op">=</span> mu_hat_optimized <span class="op">*</span> np.ones(m_predict).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>) <span class="op">+</span> <span class="op">\</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>                      psi_optimized.T <span class="op">@</span> solve(U_optimized, solve(U_optimized.T, y_train <span class="op">-</span> one_optimized <span class="op">*</span> mu_hat_optimized))</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="visualisierung-der-ergebnisse" class="level3">
<h3 class="anchored" data-anchor-id="visualisierung-der-ergebnisse">Visualisierung der Ergebnisse</h3>
<div id="c8e2b329" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>plt.plot(x_predict, np.sin(x_predict), color<span class="op">=</span><span class="st">"grey"</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="st">"Wahre Sinusfunktion"</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>plt.plot(X_train, y_train, <span class="st">"bo"</span>, markersize<span class="op">=</span><span class="dv">8</span>, label<span class="op">=</span><span class="ss">f"Messpunkte (</span><span class="sc">{</span>n_train<span class="sc">}</span><span class="ss"> Punkte)"</span>)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>plt.plot(x_predict, f_predict_fixed, color<span class="op">=</span><span class="st">"red"</span>, linestyle<span class="op">=</span><span class="st">':'</span>, label<span class="op">=</span><span class="ss">f"Kriging-Vorhersage (Fixes Theta=</span><span class="sc">{</span>theta_fixed[<span class="dv">0</span>]<span class="sc">:.1f}</span><span class="ss">)"</span>)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>plt.plot(x_predict, f_predict_optimized, color<span class="op">=</span><span class="st">"orange"</span>, label<span class="op">=</span><span class="ss">f"Kriging-Vorhersage (Optimiertes Theta=</span><span class="sc">{</span>optimized_theta[<span class="dv">0</span>]<span class="sc">:.2f}</span><span class="ss">)"</span>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f"Kriging-Vorhersage der Sinusfunktion mit </span><span class="sc">{</span>n_train<span class="sc">}</span><span class="ss"> Punkten</span><span class="ch">\n</span><span class="ss">Optimierung des Aktivitätsparameters Theta"</span>)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"x"</span>)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"y"</span>)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">'upper right'</span>)</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="de_kriging_optimization_files/figure-html/cell-8-output-1.png" width="832" height="541" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="ergebnisse-und-diskussion" class="level3">
<h3 class="anchored" data-anchor-id="ergebnisse-und-diskussion">6. Ergebnisse und Diskussion</h3>
<p>Die grafische Darstellung der Ergebnisse zeigt die Verbesserung der Kriging-Vorhersage nach der Optimierung des Aktivitätsparameters <span class="math inline">\(\theta\)</span>. Die Kurve, die mit dem optimierten <span class="math inline">\(\theta\)</span>-Wert generiert wurde, passt sich in der Regel besser an die Trainingsdaten an und bildet den wahren Funktionsverlauf präziser ab, als dies mit einem willkürlich gewählten <span class="math inline">\(\theta\)</span>-Wert der Fall wäre. Der Optimierungsalgorithmus findet den <span class="math inline">\(\theta\)</span>-Wert, der die Korrelationsstruktur der Daten am besten erklärt und somit ein “realistischeres” Modell der zugrunde liegenden Funktion liefert.</p>
<p>In diesem 1D-Beispiel ist der Unterschied möglicherweise subtil, aber in höherdimensionalen Problemen, wo Variablen unterschiedliche “Aktivitäten” aufweisen, ist die automatische Bestimmung von <span class="math inline">\(\vec{\theta}\)</span> entscheidend für die Modellgenauigkeit und die Identifizierung wichtiger Input-Variablen.</p>
</section>
<section id="fazit" class="level3">
<h3 class="anchored" data-anchor-id="fazit">7. Fazit</h3>
<p>Dieses Lernmodul hat gezeigt, wie die Maximum-Likelihood-Schätzung in Verbindung mit numerischen Optimierungsverfahren genutzt werden kann, um die Hyperparameter eines Kriging-Modells optimal an die Daten anzupassen. Die Optimierung der konzentrierten Log-Likelihood-Funktion ist ein Standardansatz, der die Robustheit und Genauigkeit von Kriging-Modellen erheblich verbessert.</p>
</section>
<section id="aufgaben" class="level3">
<h3 class="anchored" data-anchor-id="aufgaben">8: Aufgaben</h3>
<p>Für fortgeschrittenere Anwendungen könnten weitere Schritte unternommen werden:</p>
<ul>
<li><strong>Optimierung von <span class="math inline">\(\vec{p}\)</span></strong>: Der Glattheitsparameter <span class="math inline">\(\vec{p}\)</span> könnte ebenfalls in den Optimierungsprozess einbezogen werden, um noch flexiblere Anpassungen zu ermöglichen.</li>
<li><strong>Kriging-Regression für verrauschte Daten</strong>: Falls die Trainingsdaten Rauschen enthalten (z.B. aus physikalischen Experimenten), kann ein zusätzlicher “Nugget”-Parameter <span class="math inline">\(\lambda\)</span> in der Korrelationsmatrix optimiert werden. Dies transformiert das interpolierende Kriging in ein regressives Kriging, das Rauschen explizit modelliert und eine glattere Vorhersagekurve liefert.</li>
</ul>
<p>Implementieren Sie diese Erweiterungen in Ihrem Jupyter-Notebook, um ein tieferes Verständnis für die Optimierung von Kriging-Modellen zu erlangen.</p>
</section>
</section>
<section id="zusatzmaterialien" class="level2">
<h2 class="anchored" data-anchor-id="zusatzmaterialien">Zusatzmaterialien</h2>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Interaktive Webseite
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Eine interaktive Webseite zum Thema <strong>Kriging: Optimierung der Hyperparameter</strong> ist hier zu finden: <a href="https://advm1.gm.fh-koeln.de/~bartz/bart21i/de_kriging_optimization_interactive.html">Kriging Interaktiv</a>.</li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Jupyter-Notebook
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Das Jupyter-Notebook für dieses Lernmodul ist auf GitHub im <a href="https://github.com/sequential-parameter-optimization/Hyperparameter-Tuning-Cookbook/blob/main/de_kriging_optimization.ipynb">Hyperparameter-Tuning-Cookbook Repository</a> verfügbar.</li>
</ul>
</div>
</div>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Kopiert");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Kopiert");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>