{
 "cells": [
  {
   "cell_type": "raw",
   "id": "43316b50",
   "metadata": {},
   "source": [
    "---\n",
    "execute:\n",
    "  cache: false\n",
    "  eval: true\n",
    "  echo: true\n",
    "  warning: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaaafee",
   "metadata": {},
   "source": [
    "# HPT PyTorch Lightning: Diabetes\n",
    "\n",
    "In this tutorial, we will show how `spotPython` can be integrated into the `PyTorch` Lightning\n",
    "training workflow for a regression task.\n",
    "\n",
    "This chapter describes the hyperparameter tuning of a `PyTorch Lightning` network on the Diabetes data set. This is a PyTorch Dataset for regression. A toy data set from scikit-learn. Ten baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements were obtained for each of n = 442 diabetes patients,  as well as the response of interest, a quantitative measure of disease progression one year after baseline.\n",
    "\n",
    "\n",
    "## Step 1: Setup {#sec-setup-31}\n",
    "\n",
    "* Before we consider the detailed experimental setup, we select the parameters that affect run time, initial design size, etc. \n",
    "* The parameter `MAX_TIME` specifies the maximum run time in seconds.\n",
    "* The parameter `INIT_SIZE` specifies the initial design size.\n",
    "* The parameter `WORKERS` specifies the number of workers. \n",
    "* The prefix `PREFIX` is used for the experiment name and the name of the log file.\n",
    "* The parameter `DEVICE` specifies the device to use for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ebe525d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotPython.utils.device import getDevice\n",
    "from math import inf\n",
    "\n",
    "MAX_TIME = 1\n",
    "FUN_EVALS = inf\n",
    "INIT_SIZE = 5\n",
    "WORKERS = 0\n",
    "PREFIX=\"031\"\n",
    "DEVICE = getDevice()\n",
    "DEVICES = 1\n",
    "TEST_SIZE = 0.1\n",
    "TORCH_METRIC = \"mean_squared_error\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9849cc78",
   "metadata": {},
   "source": [
    "::: {.callout-caution}\n",
    "### Caution: Run time and initial design size should be increased for real experiments\n",
    "\n",
    "* `MAX_TIME` is set to one minute for demonstration purposes. For real experiments, this should be increased to at least 1 hour.\n",
    "* `INIT_SIZE` is set to 5 for demonstration purposes. For real experiments, this should be increased to at least 10.\n",
    "* `WORKERS` is set to 0 for demonstration purposes. For real experiments, this should be increased. See the warnings that are printed when the number of workers is set to 0.\n",
    "\n",
    ":::\n",
    "\n",
    "::: {.callout-note}\n",
    "### Note: Device selection\n",
    "\n",
    "* Although there are no .cuda() or .to(device) calls required, because Lightning does these for you, see \n",
    "[LIGHTNINGMODULE](https://lightning.ai/docs/pytorch/stable/common/lightning_module.html), we would like to know which device is used. Threrefore, we imitate the LightningModule behaviour which selects the highest device. \n",
    "* The method `spotPython.utils.device.getDevice()` returns the device that is used by Lightning.\n",
    ":::\n",
    "\n",
    "\n",
    "## Step 2: Initialization of the `fun_control` Dictionary\n",
    "\n",
    "`spotPython` uses a Python dictionary for storing the information required for the hyperparameter tuning process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ae3c9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving TENSORBOARD_PATH: runs/ to TENSORBOARD_PATH_OLD: runs_OLD/runs_2024_03_04_14_59_51\n",
      "Created spot_tensorboard_path: runs/spot_logs/031_maans14_2024-03-04_14-59-51 for SummaryWriter()\n"
     ]
    }
   ],
   "source": [
    "from spotPython.utils.init import fun_control_init\n",
    "import numpy as np\n",
    "fun_control = fun_control_init(\n",
    "    _L_in=10,\n",
    "    _L_out=1,\n",
    "    _torchmetric=TORCH_METRIC,\n",
    "    PREFIX=PREFIX,\n",
    "    TENSORBOARD_CLEAN=True,\n",
    "    device=DEVICE,\n",
    "    enable_progress_bar=False,\n",
    "    fun_evals=FUN_EVALS,\n",
    "    log_level=10,\n",
    "    max_time=MAX_TIME,\n",
    "    num_workers=WORKERS,\n",
    "    show_progress=True,\n",
    "    test_size=0.1,\n",
    "    tolerance_x=np.sqrt(np.spacing(1)),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45cd641",
   "metadata": {},
   "source": [
    "## Step 3: Loading the Diabetes Data Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0617f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442\n"
     ]
    }
   ],
   "source": [
    "from spotPython.hyperparameters.values import set_control_key_value\n",
    "from spotPython.data.diabetes import Diabetes\n",
    "dataset = Diabetes()\n",
    "set_control_key_value(control_dict=fun_control,\n",
    "                        key=\"data_set\",\n",
    "                        value=dataset,\n",
    "                        replace=True)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1907b7e",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "### Note: Data Set and Data Loader\n",
    "\n",
    "* As shown below, a DataLoader from `torch.utils.data` can be used to check the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86061ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size: 5\n",
      "Inputs Shape: torch.Size([5, 10])\n",
      "Targets Shape: torch.Size([5])\n",
      "---------------\n",
      "Inputs: tensor([[ 0.0381,  0.0507,  0.0617,  0.0219, -0.0442, -0.0348, -0.0434, -0.0026,\n",
      "          0.0199, -0.0176],\n",
      "        [-0.0019, -0.0446, -0.0515, -0.0263, -0.0084, -0.0192,  0.0744, -0.0395,\n",
      "         -0.0683, -0.0922],\n",
      "        [ 0.0853,  0.0507,  0.0445, -0.0057, -0.0456, -0.0342, -0.0324, -0.0026,\n",
      "          0.0029, -0.0259],\n",
      "        [-0.0891, -0.0446, -0.0116, -0.0367,  0.0122,  0.0250, -0.0360,  0.0343,\n",
      "          0.0227, -0.0094],\n",
      "        [ 0.0054, -0.0446, -0.0364,  0.0219,  0.0039,  0.0156,  0.0081, -0.0026,\n",
      "         -0.0320, -0.0466]])\n",
      "Targets: tensor([151.,  75., 141., 206., 135.])\n"
     ]
    }
   ],
   "source": [
    "# Set batch size for DataLoader\n",
    "batch_size = 5\n",
    "# Create DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Iterate over the data in the DataLoader\n",
    "for batch in dataloader:\n",
    "    inputs, targets = batch\n",
    "    print(f\"Batch Size: {inputs.size(0)}\")\n",
    "    print(f\"Inputs Shape: {inputs.shape}\")\n",
    "    print(f\"Targets Shape: {targets.shape}\")\n",
    "    print(\"---------------\")\n",
    "    print(f\"Inputs: {inputs}\")\n",
    "    print(f\"Targets: {targets}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99536514",
   "metadata": {},
   "source": [
    ":::\n",
    "## Step 4: Preprocessing {#sec-preprocessing-31}\n",
    "\n",
    "Preprocessing is handled by `Lightning` and `PyTorch`. It is described in the [LIGHTNINGDATAMODULE](https://lightning.ai/docs/pytorch/stable/data/datamodule.html) documentation. Here you can find information about the `transforms` methods.\n",
    "\n",
    "## Step 5: Select the Core Model (`algorithm`) and `core_model_hyper_dict` {#sec-selection-of-the-algorithm-31}\n",
    "\n",
    "`spotPython` includes the `NetLightRegression` class [[SOURCE]](https://github.com/sequential-parameter-optimization/spotPython/blob/main/src/spotPython/light/netlightregression.py) for configurable neural networks. \n",
    "The class is imported here. It inherits from the class `Lightning.LightningModule`, which is the base class for all models in `Lightning`. `Lightning.LightningModule` is a subclass of `torch.nn.Module` and provides additional functionality for the training and testing of neural networks. The class `Lightning.LightningModule` is described in the [Lightning documentation](https://lightning.ai/docs/pytorch/stable/common/lightning_module.html).\n",
    "\n",
    "* Here we simply add the NN Model to the fun_control dictionary by calling the function `add_core_model_to_fun_control`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd783727",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotPython.light.regression.netlightregression import NetLightRegression\n",
    "from spotPython.hyperdict.light_hyper_dict import LightHyperDict\n",
    "from spotPython.hyperparameters.values import add_core_model_to_fun_control\n",
    "add_core_model_to_fun_control(fun_control=fun_control,\n",
    "                              core_model=NetLightRegression,\n",
    "                              hyper_dict=LightHyperDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6b5d2a",
   "metadata": {},
   "source": [
    "The hyperparameters of the model are specified in the `core_model_hyper_dict` dictionary [[SOURCE]](https://github.com/sequential-parameter-optimization/spotPython/blob/main/src/spotPython/hyperdict/light_hyper_dict.json).\n",
    "\n",
    "\n",
    "\n",
    "## Step 6: Modify `hyper_dict` Hyperparameters for the Selected Algorithm aka `core_model` {#sec-modification-of-hyperparameters-31}\n",
    "\n",
    " `spotPython` provides functions for modifying the hyperparameters, their bounds and factors as well as for activating and de-activating hyperparameters without re-compilation of the Python source code. \n",
    "\n",
    "::: {.callout-caution}\n",
    "### Caution: Small number of epochs for demonstration purposes\n",
    "\n",
    "* `epochs` and `patience` are set to small values for demonstration purposes. These values are too small for a real application.\n",
    "* More resonable values are, e.g.:\n",
    "  * `set_control_hyperparameter_value(fun_control, \"epochs\", [7, 9])` and\n",
    "  * `set_control_hyperparameter_value(fun_control, \"patience\", [2, 7])`\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3822ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotPython.hyperparameters.values import set_control_hyperparameter_value\n",
    "\n",
    "set_control_hyperparameter_value(fun_control, \"l1\", [4, 6])\n",
    "set_control_hyperparameter_value(fun_control, \"epochs\", [9, 10])\n",
    "set_control_hyperparameter_value(fun_control, \"batch_size\", [4, 5])\n",
    "set_control_hyperparameter_value(fun_control, \"optimizer\", [\n",
    "                \"Adadelta\",\n",
    "                \"Adagrad\",\n",
    "                \"Adam\",\n",
    "                \"AdamW\",\n",
    "                \"Adamax\",                \n",
    "                \"NAdam\",\n",
    "                \"RAdam\",\n",
    "                \"RMSprop\",\n",
    "                \"Rprop\"\n",
    "            ])\n",
    "set_control_hyperparameter_value(fun_control, \"dropout_prob\", [0.01, 0.1])\n",
    "set_control_hyperparameter_value(fun_control, \"lr_mult\", [0.5, 5.0])\n",
    "set_control_hyperparameter_value(fun_control, \"patience\", [5, 7])\n",
    "set_control_hyperparameter_value(fun_control, \"act_fn\",[\n",
    "                \"Sigmoid\",\n",
    "                \"ReLU\",\n",
    "                \"LeakyReLU\",\n",
    "                \"Swish\"\n",
    "            ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199da2ec",
   "metadata": {},
   "source": [
    "Now, the dictionary `fun_control` contains all information needed for the hyperparameter tuning. Before the hyperparameter tuning is started, it is recommended to take a look at the experimental design. The method `gen_design_table` [[SOURCE]](https://github.com/sequential-parameter-optimization/spotPython/blob/main/src/spotPython/utils/eda.py) generates a design table as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d77cd952",
   "metadata": {
    "fig-label": "tbl-design-31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| name           | type   | default   |   lower |   upper | transform             |\n",
      "|----------------|--------|-----------|---------|---------|-----------------------|\n",
      "| l1             | int    | 3         |    4    |     6   | transform_power_2_int |\n",
      "| epochs         | int    | 4         |    9    |    10   | transform_power_2_int |\n",
      "| batch_size     | int    | 4         |    4    |     5   | transform_power_2_int |\n",
      "| act_fn         | factor | ReLU      |    0    |     3   | None                  |\n",
      "| optimizer      | factor | SGD       |    0    |     8   | None                  |\n",
      "| dropout_prob   | float  | 0.01      |    0.01 |     0.1 | None                  |\n",
      "| lr_mult        | float  | 1.0       |    0.5  |     5   | None                  |\n",
      "| patience       | int    | 2         |    5    |     7   | transform_power_2_int |\n",
      "| initialization | factor | Default   |    0    |     2   | None                  |\n"
     ]
    }
   ],
   "source": [
    "#| fig-cap: Experimental design for the hyperparameter tuning.\n",
    "from spotPython.utils.eda import gen_design_table\n",
    "print(gen_design_table(fun_control))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc6a154",
   "metadata": {},
   "source": [
    "This allows to check if all information is available and if the information is correct.\n",
    "\n",
    "::: {.callout-note}\n",
    "### Note: Hyperparameters of the Tuned Model and the `fun_control` Dictionary\n",
    "The updated `fun_control` dictionary can be shown with the command `fun_control[\"core_model_hyper_dict\"]`.\n",
    ":::\n",
    "\n",
    "\n",
    "## Step 7: Data Splitting, the Objective (Loss) Function and the Metric\n",
    "\n",
    "### Evaluation  {#sec-selection-of-target-function-31}\n",
    "\n",
    "The evaluation procedure requires the specification of two elements:\n",
    "\n",
    "1. the way how the data is split into a train and a test set\n",
    "2. the loss function (and a metric).\n",
    "\n",
    "::: {.callout-caution}\n",
    "### Caution: Data Splitting in Lightning\n",
    "\n",
    "The data splitting is handled by `Lightning`.\n",
    "\n",
    ":::\n",
    "\n",
    "### Loss Function {#sec-loss-function-31}\n",
    "\n",
    "The loss function is specified in the configurable network class [[SOURCE]](https://github.com/sequential-parameter-optimization/spotPython/blob/main/src/spotPython/light/regression/netlightregression.py)\n",
    "We will use MSE.\n",
    "\n",
    "### Metric {#sec-metric-31}\n",
    "\n",
    "* Similar to the loss function, the metric is specified in the configurable network class [[SOURCE]](https://github.com/sequential-parameter-optimization/spotPython/blob/main/src/spotPython/light/regression/netlightregression.py).\n",
    "\n",
    "::: {.callout-caution}\n",
    "### Caution: Loss Function and Metric in Lightning\n",
    "\n",
    "* The loss function and the metric are not hyperparameters that can be tuned with `spotPython`.\n",
    "* They are handled by `Lightning`.\n",
    "\n",
    ":::\n",
    "\n",
    "\n",
    "## Step 8: Calling the SPOT Function\n",
    "\n",
    "### Preparing the SPOT Call {#sec-prepare-spot-call-31}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efdd37da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotPython.utils.init import design_control_init, surrogate_control_init\n",
    "design_control = design_control_init(init_size=INIT_SIZE)\n",
    "\n",
    "surrogate_control = surrogate_control_init(noise=True,\n",
    "                                            n_theta=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbf0475",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "### Note: Modifying Values in the Control Dictionaries \n",
    "\n",
    "* The values in the control dictionaries can be modified with the function `set_control_key_value` [[SOURCE]](https://github.com/sequential-parameter-optimization/spotPython/blob/main/src/spotPython/hyperparameters/values.py), for example:\n",
    "\n",
    "\n",
    "\n",
    "```{raw}\n",
    "set_control_key_value(control_dict=surrogate_control,\n",
    "                        key=\"noise\",\n",
    "                        value=True,\n",
    "                        replace=True)                       \n",
    "set_control_key_value(control_dict=surrogate_control,\n",
    "                        key=\"n_theta\",\n",
    "                        value=2,\n",
    "                        replace=True)      \n",
    "\n",
    "```\n",
    "\n",
    "\n",
    ":::\n",
    "\n",
    "### The Objective Function `fun` {#sec-the-objective-function-31}\n",
    "\n",
    "The objective function `fun` from the class `HyperLight` [[SOURCE]](https://github.com/sequential-parameter-optimization/spotPython/blob/main/src/spotPython/fun/hyperlight.py) is selected next. It implements an interface from `PyTorch`'s training, validation, and testing methods to `spotPython`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd227f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotPython.fun.hyperlight import HyperLight\n",
    "fun = HyperLight(log_level=50).fun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc38e83a",
   "metadata": {},
   "source": [
    "### Showing the fun_control Dictionary {#sec-show-fun-control-31}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46274254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CHECKPOINT_PATH': 'runs/saved_models/',\n",
      " 'DATASET_PATH': 'data/',\n",
      " 'PREFIX': '031',\n",
      " 'RESULTS_PATH': 'results/',\n",
      " 'TENSORBOARD_PATH': 'runs/',\n",
      " '_L_in': 10,\n",
      " '_L_out': 1,\n",
      " '_torchmetric': 'mean_squared_error',\n",
      " 'accelerator': 'auto',\n",
      " 'converters': None,\n",
      " 'core_model': <class 'spotPython.light.regression.netlightregression.NetLightRegression'>,\n",
      " 'core_model_hyper_dict': {'act_fn': {'class_name': 'spotPython.torch.activation',\n",
      "                                      'core_model_parameter_type': 'instance()',\n",
      "                                      'default': 'ReLU',\n",
      "                                      'levels': ['Sigmoid',\n",
      "                                                 'ReLU',\n",
      "                                                 'LeakyReLU',\n",
      "                                                 'Swish'],\n",
      "                                      'lower': 0,\n",
      "                                      'transform': 'None',\n",
      "                                      'type': 'factor',\n",
      "                                      'upper': 3},\n",
      "                           'batch_size': {'default': 4,\n",
      "                                          'lower': 4,\n",
      "                                          'transform': 'transform_power_2_int',\n",
      "                                          'type': 'int',\n",
      "                                          'upper': 5},\n",
      "                           'dropout_prob': {'default': 0.01,\n",
      "                                            'lower': 0.01,\n",
      "                                            'transform': 'None',\n",
      "                                            'type': 'float',\n",
      "                                            'upper': 0.1},\n",
      "                           'epochs': {'default': 4,\n",
      "                                      'lower': 9,\n",
      "                                      'transform': 'transform_power_2_int',\n",
      "                                      'type': 'int',\n",
      "                                      'upper': 10},\n",
      "                           'initialization': {'core_model_parameter_type': 'str',\n",
      "                                              'default': 'Default',\n",
      "                                              'levels': ['Default',\n",
      "                                                         'Kaiming',\n",
      "                                                         'Xavier'],\n",
      "                                              'lower': 0,\n",
      "                                              'transform': 'None',\n",
      "                                              'type': 'factor',\n",
      "                                              'upper': 2},\n",
      "                           'l1': {'default': 3,\n",
      "                                  'lower': 4,\n",
      "                                  'transform': 'transform_power_2_int',\n",
      "                                  'type': 'int',\n",
      "                                  'upper': 6},\n",
      "                           'lr_mult': {'default': 1.0,\n",
      "                                       'lower': 0.5,\n",
      "                                       'transform': 'None',\n",
      "                                       'type': 'float',\n",
      "                                       'upper': 5.0},\n",
      "                           'optimizer': {'class_name': 'torch.optim',\n",
      "                                         'core_model_parameter_type': 'str',\n",
      "                                         'default': 'SGD',\n",
      "                                         'levels': ['Adadelta',\n",
      "                                                    'Adagrad',\n",
      "                                                    'Adam',\n",
      "                                                    'AdamW',\n",
      "                                                    'Adamax',\n",
      "                                                    'NAdam',\n",
      "                                                    'RAdam',\n",
      "                                                    'RMSprop',\n",
      "                                                    'Rprop'],\n",
      "                                         'lower': 0,\n",
      "                                         'transform': 'None',\n",
      "                                         'type': 'factor',\n",
      "                                         'upper': 8},\n",
      "                           'patience': {'default': 2,\n",
      "                                        'lower': 5,\n",
      "                                        'transform': 'transform_power_2_int',\n",
      "                                        'type': 'int',\n",
      "                                        'upper': 7}},\n",
      " 'counter': 0,\n",
      " 'data': None,\n",
      " 'data_dir': './data',\n",
      " 'data_module': None,\n",
      " 'data_set': <spotPython.data.diabetes.Diabetes object at 0x3095c0350>,\n",
      " 'design': None,\n",
      " 'device': 'mps',\n",
      " 'devices': 1,\n",
      " 'enable_progress_bar': False,\n",
      " 'eval': None,\n",
      " 'fun_evals': inf,\n",
      " 'fun_repeats': 1,\n",
      " 'horizon': None,\n",
      " 'infill_criterion': 'y',\n",
      " 'k_folds': 3,\n",
      " 'log_graph': False,\n",
      " 'log_level': 10,\n",
      " 'loss_function': None,\n",
      " 'lower': array([3. , 4. , 1. , 0. , 0. , 0. , 0.1, 2. , 0. ]),\n",
      " 'max_time': 1,\n",
      " 'metric_params': {},\n",
      " 'metric_river': None,\n",
      " 'metric_sklearn': None,\n",
      " 'metric_torch': None,\n",
      " 'model_dict': {},\n",
      " 'n_points': 1,\n",
      " 'n_samples': None,\n",
      " 'n_total': None,\n",
      " 'noise': False,\n",
      " 'num_workers': 0,\n",
      " 'ocba_delta': 0,\n",
      " 'oml_grace_period': None,\n",
      " 'optimizer': None,\n",
      " 'path': None,\n",
      " 'prep_model': None,\n",
      " 'save_model': False,\n",
      " 'seed': 123,\n",
      " 'show_batch_interval': 1000000,\n",
      " 'show_models': False,\n",
      " 'show_progress': True,\n",
      " 'shuffle': None,\n",
      " 'sigma': 0.0,\n",
      " 'spot_tensorboard_path': 'runs/spot_logs/031_maans14_2024-03-04_14-59-51',\n",
      " 'spot_writer': <torch.utils.tensorboard.writer.SummaryWriter object at 0x306a6ae50>,\n",
      " 'target_column': None,\n",
      " 'task': None,\n",
      " 'test': None,\n",
      " 'test_seed': 1234,\n",
      " 'test_size': 0.1,\n",
      " 'tolerance_x': 1.4901161193847656e-08,\n",
      " 'train': None,\n",
      " 'upper': array([ 8.  ,  9.  ,  4.  ,  5.  , 11.  ,  0.25, 10.  ,  6.  ,  2.  ]),\n",
      " 'var_name': ['l1',\n",
      "              'epochs',\n",
      "              'batch_size',\n",
      "              'act_fn',\n",
      "              'optimizer',\n",
      "              'dropout_prob',\n",
      "              'lr_mult',\n",
      "              'patience',\n",
      "              'initialization'],\n",
      " 'var_type': ['int',\n",
      "              'int',\n",
      "              'int',\n",
      "              'factor',\n",
      "              'factor',\n",
      "              'float',\n",
      "              'float',\n",
      "              'int',\n",
      "              'factor'],\n",
      " 'verbosity': 0,\n",
      " 'weight_coeff': 0.0,\n",
      " 'weights': 1.0}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(fun_control)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360be7fc",
   "metadata": {},
   "source": [
    "### Starting the Hyperparameter Tuning {#sec-call-the-hyperparameter-tuner-31}\n",
    "\n",
    "The `spotPython` hyperparameter tuning is started by calling the `Spot` function [[SOURCE]](https://github.com/sequential-parameter-optimization/spotPython/blob/main/src/spotPython/spot/spot.py).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "444bc864",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------\n",
      "0 | layers | Sequential | 4.4 K  | [32, 10] | [32, 1]  \n",
      "-------------------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.018     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule.setup(): stage: TrainerFn.FITTING\n",
      "train_size: 0.81, val_size: 0.09 used for train & val data.\n",
      "LightDataModule.val_dataloader(). Val. set size: 39\n",
      "LightDataModule.train_dataloader(). data_train size: 359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (12) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule.setup(): stage: TrainerFn.VALIDATING\n",
      "LightDataModule.val_dataloader(). Val. set size: 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        2462.921875        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        2462.921875        </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       2462.921875       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       2462.921875       \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------\n",
      "0 | layers | Sequential | 425    | [32, 10] | [32, 1]  \n",
      "-------------------------------------------------------------\n",
      "425       Trainable params\n",
      "0         Non-trainable params\n",
      "425       Total params\n",
      "0.002     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 2462.921875, 'hp_metric': 2462.921875}\n",
      "LightDataModule.setup(): stage: TrainerFn.FITTING\n",
      "train_size: 0.81, val_size: 0.09 used for train & val data.\n",
      "LightDataModule.val_dataloader(). Val. set size: 39\n",
      "LightDataModule.train_dataloader(). data_train size: 359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule.setup(): stage: TrainerFn.VALIDATING\n",
      "LightDataModule.val_dataloader(). Val. set size: 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     2856.306884765625     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     2856.306884765625     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    2856.306884765625    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    2856.306884765625    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------\n",
      "0 | layers | Sequential | 1.3 K  | [16, 10] | [16, 1]  \n",
      "-------------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 2856.306884765625, 'hp_metric': 2856.306884765625}\n",
      "LightDataModule.setup(): stage: TrainerFn.FITTING\n",
      "train_size: 0.81, val_size: 0.09 used for train & val data.\n",
      "LightDataModule.val_dataloader(). Val. set size: 39\n",
      "LightDataModule.train_dataloader(). data_train size: 359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (23) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule.setup(): stage: TrainerFn.VALIDATING\n",
      "LightDataModule.val_dataloader(). Val. set size: 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       3400.53515625       </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       3400.53515625       </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      3400.53515625      \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      3400.53515625      \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------\n",
      "0 | layers | Sequential | 1.3 K  | [16, 10] | [16, 1]  \n",
      "-------------------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 3400.53515625, 'hp_metric': 3400.53515625}\n",
      "LightDataModule.setup(): stage: TrainerFn.FITTING\n",
      "train_size: 0.81, val_size: 0.09 used for train & val data.\n",
      "LightDataModule.val_dataloader(). Val. set size: 39\n",
      "LightDataModule.train_dataloader(). data_train size: 359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule.setup(): stage: TrainerFn.VALIDATING\n",
      "LightDataModule.val_dataloader(). Val. set size: 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     5122.52880859375      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     5122.52880859375      </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    5122.52880859375     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    5122.52880859375     \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------\n",
      "0 | layers | Sequential | 425    | [32, 10] | [32, 1]  \n",
      "-------------------------------------------------------------\n",
      "425       Trainable params\n",
      "0         Non-trainable params\n",
      "425       Total params\n",
      "0.002     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 5122.52880859375, 'hp_metric': 5122.52880859375}\n",
      "LightDataModule.setup(): stage: TrainerFn.FITTING\n",
      "train_size: 0.81, val_size: 0.09 used for train & val data.\n",
      "LightDataModule.val_dataloader(). Val. set size: 39\n",
      "LightDataModule.train_dataloader(). data_train size: 359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule.setup(): stage: TrainerFn.VALIDATING\n",
      "LightDataModule.val_dataloader(). Val. set size: 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     2631.704833984375     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     2631.704833984375     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    2631.704833984375    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    2631.704833984375    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 2631.704833984375, 'hp_metric': 2631.704833984375}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------\n",
      "0 | layers | Sequential | 4.4 K  | [32, 10] | [32, 1]  \n",
      "-------------------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.018     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (12) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule.setup(): stage: TrainerFn.FITTING\n",
      "train_size: 0.81, val_size: 0.09 used for train & val data.\n",
      "LightDataModule.val_dataloader(). Val. set size: 39\n",
      "LightDataModule.train_dataloader(). data_train size: 359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule.setup(): stage: TrainerFn.VALIDATING\n",
      "LightDataModule.val_dataloader(). Val. set size: 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     2604.744384765625     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     2604.744384765625     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    2604.744384765625    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    2604.744384765625    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 2604.744384765625, 'hp_metric': 2604.744384765625}\n",
      "spotPython tuning: 2462.921875 [#####-----] 50.81% \r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------\n",
      "0 | layers | Sequential | 4.4 K  | [32, 10] | [32, 1]  \n",
      "-------------------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.018     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (12) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule.setup(): stage: TrainerFn.FITTING\n",
      "train_size: 0.81, val_size: 0.09 used for train & val data.\n",
      "LightDataModule.val_dataloader(). Val. set size: 39\n",
      "LightDataModule.train_dataloader(). data_train size: 359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule.setup(): stage: TrainerFn.VALIDATING\n",
      "LightDataModule.val_dataloader(). Val. set size: 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     2687.331787109375     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     2687.331787109375     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    2687.331787109375    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    2687.331787109375    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 2687.331787109375, 'hp_metric': 2687.331787109375}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotPython tuning: 2462.921875 [#########-] 94.55% \r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------\n",
      "0 | layers | Sequential | 4.4 K  | [32, 10] | [32, 1]  \n",
      "-------------------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.018     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule.setup(): stage: TrainerFn.FITTING\n",
      "train_size: 0.81, val_size: 0.09 used for train & val data.\n",
      "LightDataModule.val_dataloader(). Val. set size: 39\n",
      "LightDataModule.train_dataloader(). data_train size: 359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (12) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule.setup(): stage: TrainerFn.VALIDATING\n",
      "LightDataModule.val_dataloader(). Val. set size: 39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     2574.81201171875      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     2574.81201171875      </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    2574.81201171875     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    2574.81201171875     \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 2574.81201171875, 'hp_metric': 2574.81201171875}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spotPython tuning: 2462.921875 [##########] 100.00% Done...\r\n",
      "\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spotPython.spot.spot.Spot at 0x30c7f7610>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spotPython.spot import spot\n",
    "spot_tuner = spot.Spot(fun=fun,\n",
    "                       fun_control=fun_control,\n",
    "                       design_control=design_control,\n",
    "                       surrogate_control=surrogate_control)\n",
    "spot_tuner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9346af",
   "metadata": {},
   "source": [
    "## Step 9: Tensorboard {#sec-tensorboard-31}\n",
    "\n",
    "The textual output shown in the console (or code cell) can be visualized with Tensorboard.\n",
    "\n",
    "\n",
    "\n",
    "```{raw}\n",
    "tensorboard --logdir=\"runs/\"\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "Further information can be found in the [PyTorch Lightning documentation](https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.loggers.tensorboard.html) for Tensorboard.\n",
    "\n",
    "\n",
    "\n",
    "## Step 10: Results {#sec-results-31}\n",
    "\n",
    "After the hyperparameter tuning run is finished, the results can be analyzed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86b8743e",
   "metadata": {
    "fig-label": "fig-progress-31"
   },
   "outputs": [
    {
     "data": {
      "application/pdf": "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",
      "text/plain": [
       "<Figure size 2700x1800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| fig-cap: Progress plot. *Black* dots denote results from the initial design. *Red* dots  illustrate the improvement found by the surrogate model based optimization.\n",
    "spot_tuner.plot_progress(log_y=False,\n",
    "    filename=\"./figures/\" + PREFIX +\"_progress.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4164b35",
   "metadata": {
    "fig-label": "tbl-results-31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| name           | type   | default   |   lower |   upper | tuned               | transform             |   importance | stars   |\n",
      "|----------------|--------|-----------|---------|---------|---------------------|-----------------------|--------------|---------|\n",
      "| l1             | int    | 3         |     4.0 |     6.0 | 6.0                 | transform_power_2_int |         0.00 |         |\n",
      "| epochs         | int    | 4         |     9.0 |    10.0 | 10.0                | transform_power_2_int |         0.00 |         |\n",
      "| batch_size     | int    | 4         |     4.0 |     5.0 | 5.0                 | transform_power_2_int |        12.02 | *       |\n",
      "| act_fn         | factor | ReLU      |     0.0 |     3.0 | ReLU                | None                  |       100.00 | ***     |\n",
      "| optimizer      | factor | SGD       |     0.0 |     8.0 | AdamW               | None                  |         0.00 |         |\n",
      "| dropout_prob   | float  | 0.01      |    0.01 |     0.1 | 0.04938229888019609 | None                  |         0.01 |         |\n",
      "| lr_mult        | float  | 1.0       |     0.5 |     5.0 | 2.3689895017756495  | None                  |         0.00 |         |\n",
      "| patience       | int    | 2         |     5.0 |     7.0 | 6.0                 | transform_power_2_int |         0.00 |         |\n",
      "| initialization | factor | Default   |     0.0 |     2.0 | Default             | None                  |         0.00 |         |\n"
     ]
    }
   ],
   "source": [
    "#| fig-cap: Results of the hyperparameter tuning.\n",
    "from spotPython.utils.eda import gen_design_table\n",
    "print(gen_design_table(fun_control=fun_control, spot=spot_tuner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bee75bfe",
   "metadata": {
    "fig-label": "fig-importance-31"
   },
   "outputs": [
    {
     "data": {
      "application/pdf": "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",
      "text/plain": [
       "<Figure size 1650x1050 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| fig-cap: 'Variable importance plot, threshold 0.025.'\n",
    "spot_tuner.plot_importance(threshold=0.025,\n",
    "    filename=\"./figures/\" + PREFIX + \"_importance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8a7caa",
   "metadata": {},
   "source": [
    "### Get the Tuned Architecture {#sec-get-spot-results-31}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23aee197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'l1': 64, 'epochs': 1024, 'batch_size': 32, 'act_fn': ReLU(), 'optimizer': 'AdamW', 'dropout_prob': 0.04938229888019609, 'lr_mult': 2.3689895017756495, 'patience': 64, 'initialization': 'Default'}\n"
     ]
    }
   ],
   "source": [
    "from spotPython.hyperparameters.values import get_tuned_architecture\n",
    "config = get_tuned_architecture(spot_tuner, fun_control)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e628d9",
   "metadata": {},
   "source": [
    "* Test on the full data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0ab3b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------\n",
      "0 | layers | Sequential | 4.4 K  | [32, 10] | [32, 1]  \n",
      "-------------------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.018     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule.setup(): stage: TrainerFn.FITTING\n",
      "train_size: 0.81, val_size: 0.09 used for train & val data.\n",
      "LightDataModule.val_dataloader(). Val. set size: 39\n",
      "LightDataModule.train_dataloader(). data_train size: 359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (12) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /Users/bartz/workspace/Hyperparameter-Tuning-Cookbook/runs/saved_models/64_1024_32_ReLU_AdamW_0.0494_2.369_64_Default_TEST/last.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded model weights from the checkpoint at /Users/bartz/workspace/Hyperparameter-Tuning-Cookbook/runs/saved_models/64_1024_32_ReLU_AdamW_0.0494_2.369_64_Default_TEST/last.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightDataModule.setup(): stage: TrainerFn.TESTING\n",
      "test_size: 0.1 used for test dataset.\n",
      "LightDataModule.test_dataloader(). Test set size: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     2923.08056640625      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     2923.08056640625      </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    2923.08056640625     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    2923.08056640625     \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_model result: {'val_loss': 2923.08056640625, 'hp_metric': 2923.08056640625}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2923.08056640625, 2923.08056640625)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spotPython.light.testmodel import test_model\n",
    "test_model(config, fun_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f329e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config: {'l1': 64, 'epochs': 1024, 'batch_size': 32, 'act_fn': ReLU(), 'optimizer': 'AdamW', 'dropout_prob': 0.04938229888019609, 'lr_mult': 2.3689895017756495, 'patience': 64, 'initialization': 'Default'}\n",
      "Loading model with 64_1024_32_ReLU_AdamW_0.0494_2.369_64_Default_TEST from runs/saved_models/64_1024_32_ReLU_AdamW_0.0494_2.369_64_Default_TEST/last.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: NetLightRegression(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.04938229888019609, inplace=False)\n",
      "    (3): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.04938229888019609, inplace=False)\n",
      "    (6): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.04938229888019609, inplace=False)\n",
      "    (9): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.04938229888019609, inplace=False)\n",
      "    (12): Linear(in_features=16, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from spotPython.light.loadmodel import load_light_from_checkpoint\n",
    "\n",
    "model_loaded = load_light_from_checkpoint(config, fun_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "682c7195",
   "metadata": {
    "fig-label": "fig-contour-31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size:  12.017357419374173\n",
      "act_fn:  100.0\n",
      "impo: [['l1', 0.001], ['epochs', 0.0034616730958547132], ['batch_size', 12.017357419374173], ['act_fn', 100.0], ['optimizer', 0.001], ['dropout_prob', 0.008732975025007764], ['lr_mult', 0.001], ['patience', 0.001], ['initialization', 0.0010165818437224688]]\n",
      "impo after select: [['l1', 0.001], ['epochs', 0.0034616730958547132], ['batch_size', 12.017357419374173], ['act_fn', 100.0], ['optimizer', 0.001], ['dropout_prob', 0.008732975025007764], ['lr_mult', 0.001], ['patience', 0.001], ['initialization', 0.0010165818437224688]]\n"
     ]
    },
    {
     "data": {
      "application/pdf": "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",
      "text/plain": [
       "<Figure size 2700x1800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| fig-cap: Contour plots.\n",
    "filename = \"./figures/\" + PREFIX\n",
    "spot_tuner.plot_important_hyperparameter_contour(filename=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaa405f",
   "metadata": {},
   "source": [
    "### Parallel Coordinates Plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1a804d0",
   "metadata": {
    "fig-label": "fig-parallel-31"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.27.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"7694f981-e32c-4987-a8a4-b44dcb11cc03\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7694f981-e32c-4987-a8a4-b44dcb11cc03\")) {                    Plotly.newPlot(                        \"7694f981-e32c-4987-a8a4-b44dcb11cc03\",                        [{\"dimensions\":[{\"label\":\"l1\",\"range\":[4.0,6.0],\"values\":[6.0,4.0,5.0,5.0,4.0,6.0,6.0,6.0]},{\"label\":\"epochs\",\"range\":[9.0,10.0],\"values\":[10.0,9.0,9.0,9.0,10.0,10.0,10.0,10.0]},{\"label\":\"batch_size\",\"range\":[4.0,5.0],\"values\":[5.0,5.0,4.0,4.0,5.0,5.0,5.0,5.0]},{\"label\":\"act_fn\",\"range\":[0.0,3.0],\"values\":[1.0,2.0,3.0,0.0,1.0,1.0,1.0,1.0]},{\"label\":\"optimizer\",\"range\":[0.0,7.0],\"values\":[3.0,4.0,7.0,0.0,6.0,2.0,3.0,3.0]},{\"label\":\"dropout_prob\",\"range\":[0.01,0.1],\"values\":[0.04938229888019609,0.014653593059775226,0.08951095646892425,0.07807342828150021,0.035501708617280955,0.1,0.01,0.1]},{\"label\":\"lr_mult\",\"range\":[0.5,5.0],\"values\":[2.3689895017756495,0.8330538158692873,3.9340958113143683,1.5204853123355815,4.785884240333345,0.5,1.6330281878000812,5.0]},{\"label\":\"patience\",\"range\":[5.0,7.0],\"values\":[6.0,5.0,7.0,6.0,5.0,7.0,5.0,7.0]},{\"label\":\"initialization\",\"range\":[0.0,2.0],\"values\":[0.0,1.0,2.0,1.0,2.0,1.0,0.0,0.0]}],\"line\":{\"cmax\":5122.52880859375,\"cmin\":2462.921875,\"color\":[2462.921875,2856.306884765625,3400.53515625,5122.52880859375,2631.704833984375,2604.744384765625,2687.331787109375,2574.81201171875],\"colorscale\":[[0.0,\"rgb(0,0,131)\"],[0.2,\"rgb(0,60,170)\"],[0.4,\"rgb(5,255,255)\"],[0.6,\"rgb(255,255,0)\"],[0.8,\"rgb(250,0,0)\"],[1.0,\"rgb(128,0,0)\"]],\"showscale\":true},\"type\":\"parcoords\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"},\"margin\":{\"b\":0,\"l\":0,\"r\":0,\"t\":30}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('7694f981-e32c-4987-a8a4-b44dcb11cc03');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| fig-cap: Parallel coordinates plots\n",
    "spot_tuner.parallel_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa87835",
   "metadata": {},
   "source": [
    "### Cross Validation With Lightning\n",
    "\n",
    "* The `KFold` class from `sklearn.model_selection` is used to generate the folds for cross-validation.\n",
    "* These mechanism is used to generate the folds for the final evaluation of the model.\n",
    "* The `CrossValidationDataModule` class [[SOURCE]](https://github.com/sequential-parameter-optimization/spotPython/blob/main/src/spotPython/data/lightcrossvalidationdatamodule.py) is used to generate the folds for the hyperparameter tuning process.\n",
    "* It is called from the `cv_model` function [[SOURCE]](https://github.com/sequential-parameter-optimization/spotPython/blob/main/src/spotPython/light/cvmodel.py).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95c463bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'act_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['act_fn'])`.\n",
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name   | Type       | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------\n",
      "0 | layers | Sequential | 4.4 K  | [32, 10] | [32, 1]  \n",
      "-------------------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.018     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 0\n",
      "Train Dataset Size: 221\n",
      "Val Dataset Size: 221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     3042.691162109375     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     3042.691162109375     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    3042.691162109375    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    3042.691162109375    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartz/miniforge3/envs/spotCondaEnv/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:652: Checkpoint directory runs/lightning_logs/20240304150424299033_64_1024_32_ReLU_AdamW_0.0494_2.369_64_Default_CV/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name   | Type       | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------\n",
      "0 | layers | Sequential | 4.4 K  | [32, 10] | [32, 1]  \n",
      "-------------------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.018     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 3042.691162109375, 'hp_metric': 3042.691162109375}\n",
      "k: 1\n",
      "Train Dataset Size: 221\n",
      "Val Dataset Size: 221\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         hp_metric         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     2942.557861328125     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     2942.557861328125     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        hp_metric        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    2942.557861328125    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    2942.557861328125    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model result: {'val_loss': 2942.557861328125, 'hp_metric': 2942.557861328125}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2992.62451171875"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spotPython.light.cvmodel import cv_model\n",
    "set_control_key_value(control_dict=fun_control,\n",
    "                        key=\"k_folds\",\n",
    "                        value=2,\n",
    "                        replace=True)\n",
    "set_control_key_value(control_dict=fun_control,\n",
    "                        key=\"test_size\",\n",
    "                        value=0.6,\n",
    "                        replace=True)\n",
    "cv_model(config, fun_control)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ae6a06",
   "metadata": {},
   "source": [
    "### Plot all Combinations of Hyperparameters\n",
    "\n",
    "* Warning: this may take a while.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58e7d76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_ALL = False\n",
    "if PLOT_ALL:\n",
    "    n = spot_tuner.k\n",
    "    for i in range(n-1):\n",
    "        for j in range(i+1, n):\n",
    "            spot_tuner.plot_contour(i=i, j=j, min_z=min_z, max_z = max_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff6cccf",
   "metadata": {},
   "source": [
    "### Visualizing the Activation Distribution (Under Development)\n",
    "\n",
    "::: {.callout-note}\n",
    "### Reference:\n",
    "\n",
    "* The following code is based on [[PyTorch Lightning TUTORIAL 2: ACTIVATION FUNCTIONS]](https://lightning.ai/docs/pytorch/stable/notebooks/course_UvA-DL/02-activation-functions.html), Author: Phillip Lippe, License: [[CC BY-SA]](https://creativecommons.org/licenses/by-sa/3.0/), Generated: 2023-03-15T09:52:39.179933.\n",
    "\n",
    ":::\n",
    "\n",
    "After we have trained the models, we can look at the actual activation values that find inside the model. For instance, how many neurons are set to zero in ReLU? Where do we find most values in Tanh? To answer these questions, we can write a simple function which takes a trained model, applies it to a batch of images, and plots the histogram of the activations inside the network:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19353284",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotPython.torch.activation import Sigmoid, Tanh, ReLU, LeakyReLU, ELU, Swish\n",
    "act_fn_by_name = {\"sigmoid\": Sigmoid, \"tanh\": Tanh, \"relu\": ReLU, \"leakyrelu\": LeakyReLU, \"elu\": ELU, \"swish\": Swish}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd1f33a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NetLightRegression(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.04938229888019609, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.04938229888019609, inplace=False)\n",
       "    (6): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.04938229888019609, inplace=False)\n",
       "    (9): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout(p=0.04938229888019609, inplace=False)\n",
       "    (12): Linear(in_features=16, out_features=11, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spotPython.hyperparameters.values import get_one_config_from_X\n",
    "X = spot_tuner.to_all_dim(spot_tuner.min_X.reshape(1,-1))\n",
    "config = get_one_config_from_X(X, fun_control)\n",
    "model = fun_control[\"core_model\"](**config, _L_in=64, _L_out=11, _torchmetric=TORCH_METRIC)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "513bed24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from spotPython.utils.eda import visualize_activations\n",
    "# visualize_activations(model, color=f\"C{0}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
